[2022-04-04 23:45:58 large] (main.py 347): INFO Full config saved to output/large/default/config.json
[2022-04-04 23:45:58 large] (main.py 350): INFO AMP_OPT_LEVEL: O1
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: ../../Data/raw-data/imagenet-data/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 16
  PIN_MEMORY: true
  ZIP_MODE: false
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DFvT:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 128
    IN_CHANS: 3
    MLP_RATIO: 2.0
    NUM_HEADS:
    - 4
    - 8
    - 16
    - 32
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    SIZE: large
    WINDOW_SIZE: 7
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: large
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: DFvT
OUTPUT: output/large/default
PRINT_FREQ: 100
SAVE_FREQ: 1000
SEED: 0
TAG: default
TEST:
  CROP: true
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: true
  BASE_LR: 0.0005
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MIN_LR: 5.0e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 5.0e-07
  WEIGHT_DECAY: 0.05

[2022-04-04 23:46:02 large] (main.py 80): INFO Creating model:DFvT/large
[2022-04-04 23:46:03 large] (main.py 85): INFO DFvT(
  (patch_embed): PatchEmbed(
    (proj1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (proj2): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (silu): SiLU(inplace=True)
    (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=128, input_resolution=(28, 28), depth=2
      (blocks): ModuleList(
        (0): TransformerBlock(
          dim=128, input_resolution=(28, 28), num_heads=4, window_size=7, shift_size=0, mlp_ratio=2.0
          (select): DANE(
            (fc_spatial): Sequential(
              (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=128, out_features=1, bias=False)
            )
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc_channel): Sequential(
              (0): Linear(in_features=128, out_features=8, bias=False)
              (1): SiLU(inplace=True)
              (2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)
              (3): Linear(in_features=8, out_features=128, bias=False)
            )
            (sigmoid): Sigmoid()
          )
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=256, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=256, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): TransformerBlock(
          dim=128, input_resolution=(28, 28), num_heads=4, window_size=7, shift_size=3, mlp_ratio=2.0
          (select): DANE(
            (fc_spatial): Sequential(
              (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=128, out_features=1, bias=False)
            )
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc_channel): Sequential(
              (0): Linear(in_features=128, out_features=8, bias=False)
              (1): SiLU(inplace=True)
              (2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)
              (3): Linear(in_features=8, out_features=128, bias=False)
            )
            (sigmoid): Sigmoid()
          )
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=256, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=256, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(28, 28), dim=128
        (reduction): Linear(in_features=128, out_features=256, bias=False)
        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=256, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): TransformerBlock(
          dim=256, input_resolution=(14, 14), num_heads=8, window_size=7, shift_size=0, mlp_ratio=2.0
          (select): DANE(
            (fc_spatial): Sequential(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=256, out_features=1, bias=False)
            )
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc_channel): Sequential(
              (0): Linear(in_features=256, out_features=16, bias=False)
              (1): SiLU(inplace=True)
              (2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
              (3): Linear(in_features=16, out_features=256, bias=False)
            )
            (sigmoid): Sigmoid()
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): TransformerBlock(
          dim=256, input_resolution=(14, 14), num_heads=8, window_size=7, shift_size=3, mlp_ratio=2.0
          (select): DANE(
            (fc_spatial): Sequential(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=256, out_features=1, bias=False)
            )
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc_channel): Sequential(
              (0): Linear(in_features=256, out_features=16, bias=False)
              (1): SiLU(inplace=True)
              (2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
              (3): Linear(in_features=16, out_features=256, bias=False)
            )
            (sigmoid): Sigmoid()
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=256
        (reduction): Linear(in_features=256, out_features=512, bias=False)
        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): BasicLayer(
      dim=512, input_resolution=(7, 7), depth=6
      (blocks): ModuleList(
        (0): TransformerBlock(
          dim=512, input_resolution=(7, 7), num_heads=16, window_size=7, shift_size=0, mlp_ratio=2.0
          (select): DANE(
            (fc_spatial): Sequential(
              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=512, out_features=1, bias=False)
            )
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc_channel): Sequential(
              (0): Linear(in_features=512, out_features=32, bias=False)
              (1): SiLU(inplace=True)
              (2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
              (3): Linear(in_features=32, out_features=512, bias=False)
            )
            (sigmoid): Sigmoid()
          )
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): TransformerBlock(
          dim=512, input_resolution=(7, 7), num_heads=16, window_size=7, shift_size=0, mlp_ratio=2.0
          (select): DANE(
            (fc_spatial): Sequential(
              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=512, out_features=1, bias=False)
            )
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc_channel): Sequential(
              (0): Linear(in_features=512, out_features=32, bias=False)
              (1): SiLU(inplace=True)
              (2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
              (3): Linear(in_features=32, out_features=512, bias=False)
            )
            (sigmoid): Sigmoid()
          )
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): TransformerBlock(
          dim=512, input_resolution=(7, 7), num_heads=16, window_size=7, shift_size=0, mlp_ratio=2.0
          (select): DANE(
            (fc_spatial): Sequential(
              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=512, out_features=1, bias=False)
            )
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc_channel): Sequential(
              (0): Linear(in_features=512, out_features=32, bias=False)
              (1): SiLU(inplace=True)
              (2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
              (3): Linear(in_features=32, out_features=512, bias=False)
            )
            (sigmoid): Sigmoid()
          )
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): TransformerBlock(
          dim=512, input_resolution=(7, 7), num_heads=16, window_size=7, shift_size=0, mlp_ratio=2.0
          (select): DANE(
            (fc_spatial): Sequential(
              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=512, out_features=1, bias=False)
            )
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc_channel): Sequential(
              (0): Linear(in_features=512, out_features=32, bias=False)
              (1): SiLU(inplace=True)
              (2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
              (3): Linear(in_features=32, out_features=512, bias=False)
            )
            (sigmoid): Sigmoid()
          )
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): TransformerBlock(
          dim=512, input_resolution=(7, 7), num_heads=16, window_size=7, shift_size=0, mlp_ratio=2.0
          (select): DANE(
            (fc_spatial): Sequential(
              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=512, out_features=1, bias=False)
            )
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc_channel): Sequential(
              (0): Linear(in_features=512, out_features=32, bias=False)
              (1): SiLU(inplace=True)
              (2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
              (3): Linear(in_features=32, out_features=512, bias=False)
            )
            (sigmoid): Sigmoid()
          )
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): TransformerBlock(
          dim=512, input_resolution=(7, 7), num_heads=16, window_size=7, shift_size=0, mlp_ratio=2.0
          (select): DANE(
            (fc_spatial): Sequential(
              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=512, out_features=1, bias=False)
            )
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc_channel): Sequential(
              (0): Linear(in_features=512, out_features=32, bias=False)
              (1): SiLU(inplace=True)
              (2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
              (3): Linear(in_features=32, out_features=512, bias=False)
            )
            (sigmoid): Sigmoid()
          )
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(7, 7), dim=512
        (reduction): Linear(in_features=512, out_features=1024, bias=False)
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (3): BasicLayer(
      dim=1024, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0): TransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=2.0
          (select): DANE(
            (fc_spatial): Sequential(
              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=1024, out_features=1, bias=False)
            )
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc_channel): Sequential(
              (0): Linear(in_features=1024, out_features=64, bias=False)
              (1): SiLU(inplace=True)
              (2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (3): Linear(in_features=64, out_features=1024, bias=False)
            )
            (sigmoid): Sigmoid()
          )
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): TransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=2.0
          (select): DANE(
            (fc_spatial): Sequential(
              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=1024, out_features=1, bias=False)
            )
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc_channel): Sequential(
              (0): Linear(in_features=1024, out_features=64, bias=False)
              (1): SiLU(inplace=True)
              (2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (3): Linear(in_features=64, out_features=1024, bias=False)
            )
            (sigmoid): Sigmoid()
          )
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (convlayers): ModuleList(
    (0): ConvBlock(
      (conv1x1_1): Sequential(
        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): SiLU(inplace=True)
        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (8): SiLU(inplace=True)
      )
      (conv1): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
      (conv1x1_2): Sequential(
        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
    )
    (1): ConvBlock(
      (conv1x1_1): Sequential(
        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): SiLU(inplace=True)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (8): SiLU(inplace=True)
      )
      (conv1): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
      (conv1x1_2): Sequential(
        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
    )
    (2): ConvBlock(
      (conv1x1_1): Sequential(
        (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): SiLU(inplace=True)
        (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
        (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (8): SiLU(inplace=True)
      )
      (conv1): Sequential(
        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
      (conv1x1_2): Sequential(
        (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
    )
    (3): ConvBlock(
      (conv1x1_1): Sequential(
        (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
        (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
        (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): SiLU(inplace=True)
        (6): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (8): SiLU(inplace=True)
      )
      (conv1): Sequential(
        (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
      (conv1x1_2): Sequential(
        (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
    )
  )
  (multiresolution_conv): ModuleList(
    (0): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Sequential(
      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): Sequential(
      (0): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048, bias=False)
      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2022-04-04 23:46:03 large] (main.py 94): INFO number of params: 37331136
[2022-04-04 23:46:03 large] (main.py 97): INFO number of GFLOPs: 2.503752704
[2022-04-04 23:46:03 large] (main.py 121): INFO no checkpoint found in output/large/default, ignoring auto resume
[2022-04-04 23:46:03 large] (main.py 134): INFO Start training
[2022-04-04 23:46:14 large] (main.py 226): INFO Train: [0/300][0/2502]	eta 7:59:37 lr 0.000000	time 11.5016 (11.5016)	loss 6.9139 (6.9139)	grad_norm 1.5922 (1.5922)	mem 8476MB
[2022-04-04 23:47:01 large] (main.py 226): INFO Train: [0/300][100/2502]	eta 0:22:59 lr 0.000001	time 0.4370 (0.5744)	loss 6.9360 (6.9302)	grad_norm 1.4937 (1.5432)	mem 8925MB
[2022-04-04 23:47:48 large] (main.py 226): INFO Train: [0/300][200/2502]	eta 0:20:03 lr 0.000002	time 0.4737 (0.5228)	loss 6.9135 (6.9280)	grad_norm 1.6593 (1.5421)	mem 8925MB
[2022-04-04 23:48:35 large] (main.py 226): INFO Train: [0/300][300/2502]	eta 0:18:36 lr 0.000003	time 0.4830 (0.5072)	loss 6.9065 (6.9252)	grad_norm 1.5140 (1.5439)	mem 8925MB
[2022-04-04 23:49:26 large] (main.py 226): INFO Train: [0/300][400/2502]	eta 0:17:47 lr 0.000004	time 0.4982 (0.5079)	loss 6.9162 (6.9227)	grad_norm 1.3908 (1.5377)	mem 8925MB
[2022-04-04 23:50:24 large] (main.py 226): INFO Train: [0/300][500/2502]	eta 0:17:23 lr 0.000005	time 0.6051 (0.5212)	loss 6.9007 (6.9205)	grad_norm 1.5681 (1.5302)	mem 8925MB
[2022-04-04 23:51:23 large] (main.py 226): INFO Train: [0/300][600/2502]	eta 0:16:52 lr 0.000006	time 0.6488 (0.5324)	loss 6.9018 (6.9177)	grad_norm 1.5176 (1.5253)	mem 8925MB
[2022-04-04 23:52:23 large] (main.py 226): INFO Train: [0/300][700/2502]	eta 0:16:18 lr 0.000007	time 0.6608 (0.5428)	loss 6.8877 (6.9147)	grad_norm 1.3917 (1.5208)	mem 8925MB
[2022-04-04 23:53:24 large] (main.py 226): INFO Train: [0/300][800/2502]	eta 0:15:37 lr 0.000008	time 0.6956 (0.5507)	loss 6.9013 (6.9112)	grad_norm 1.4364 (1.5190)	mem 8926MB
[2022-04-04 23:54:24 large] (main.py 226): INFO Train: [0/300][900/2502]	eta 0:14:52 lr 0.000009	time 0.6046 (0.5569)	loss 6.8646 (6.9069)	grad_norm 1.4839 (1.5215)	mem 8926MB
[2022-04-04 23:55:26 large] (main.py 226): INFO Train: [0/300][1000/2502]	eta 0:14:04 lr 0.000010	time 0.6325 (0.5626)	loss 6.8675 (6.9016)	grad_norm 1.5509 (1.5299)	mem 8926MB
[2022-04-04 23:56:27 large] (main.py 226): INFO Train: [0/300][1100/2502]	eta 0:13:15 lr 0.000011	time 0.6391 (0.5671)	loss 6.8112 (6.8952)	grad_norm 1.7150 (1.5426)	mem 8926MB
[2022-04-04 23:57:29 large] (main.py 226): INFO Train: [0/300][1200/2502]	eta 0:12:23 lr 0.000012	time 0.5432 (0.5711)	loss 6.7913 (6.8883)	grad_norm 1.6111 (1.5602)	mem 8926MB
[2022-04-04 23:58:29 large] (main.py 226): INFO Train: [0/300][1300/2502]	eta 0:11:29 lr 0.000013	time 0.6706 (0.5737)	loss 6.9014 (6.8816)	grad_norm 1.6591 (1.5816)	mem 8926MB
[2022-04-04 23:59:31 large] (main.py 226): INFO Train: [0/300][1400/2502]	eta 0:10:35 lr 0.000014	time 0.6830 (0.5766)	loss 6.8356 (6.8748)	grad_norm 1.9364 (1.6088)	mem 8926MB
[2022-04-05 00:00:31 large] (main.py 226): INFO Train: [0/300][1500/2502]	eta 0:09:39 lr 0.000015	time 0.7685 (0.5785)	loss 6.6678 (6.8673)	grad_norm 2.4340 (1.6464)	mem 8926MB
[2022-04-05 00:01:31 large] (main.py 226): INFO Train: [0/300][1600/2502]	eta 0:08:43 lr 0.000016	time 0.6110 (0.5800)	loss 6.7229 (6.8590)	grad_norm 2.0686 (inf)	mem 8927MB
[2022-04-05 00:02:32 large] (main.py 226): INFO Train: [0/300][1700/2502]	eta 0:07:46 lr 0.000017	time 0.6117 (0.5814)	loss 6.7795 (6.8501)	grad_norm 2.5413 (inf)	mem 8927MB
[2022-04-05 00:03:31 large] (main.py 226): INFO Train: [0/300][1800/2502]	eta 0:06:48 lr 0.000018	time 0.4835 (0.5821)	loss 6.6465 (6.8416)	grad_norm 2.6878 (inf)	mem 8927MB
[2022-04-05 00:04:32 large] (main.py 226): INFO Train: [0/300][1900/2502]	eta 0:05:51 lr 0.000019	time 0.6537 (0.5833)	loss 6.7764 (6.8329)	grad_norm 2.4196 (inf)	mem 8927MB
[2022-04-05 00:05:34 large] (main.py 226): INFO Train: [0/300][2000/2502]	eta 0:04:53 lr 0.000020	time 0.5741 (0.5851)	loss 6.7177 (6.8235)	grad_norm 3.1125 (inf)	mem 8927MB
[2022-04-05 00:06:34 large] (main.py 226): INFO Train: [0/300][2100/2502]	eta 0:03:55 lr 0.000021	time 0.5623 (0.5861)	loss 6.6758 (6.8160)	grad_norm 2.8883 (inf)	mem 8927MB
[2022-04-05 00:07:35 large] (main.py 226): INFO Train: [0/300][2200/2502]	eta 0:02:57 lr 0.000022	time 0.6823 (0.5871)	loss 6.7251 (6.8080)	grad_norm 2.2647 (inf)	mem 8927MB
[2022-04-05 00:08:35 large] (main.py 226): INFO Train: [0/300][2300/2502]	eta 0:01:58 lr 0.000023	time 0.6596 (0.5879)	loss 6.5943 (6.7996)	grad_norm 3.1020 (inf)	mem 8927MB
[2022-04-05 00:09:38 large] (main.py 226): INFO Train: [0/300][2400/2502]	eta 0:01:00 lr 0.000024	time 0.5570 (0.5893)	loss 6.6677 (6.7919)	grad_norm 2.8127 (inf)	mem 8927MB
[2022-04-05 00:10:40 large] (main.py 226): INFO Train: [0/300][2500/2502]	eta 0:00:01 lr 0.000025	time 0.6117 (0.5907)	loss 6.6570 (6.7844)	grad_norm 2.8378 (inf)	mem 8928MB
[2022-04-05 00:10:41 large] (main.py 233): INFO EPOCH 0 training takes 0:24:38
[2022-04-05 00:10:41 large] (utils.py 57): INFO output/large/default/ckpt_epoch_0.pth saving......
[2022-04-05 00:10:42 large] (utils.py 59): INFO output/large/default/ckpt_epoch_0.pth saved !!!
[2022-04-05 00:10:48 large] (main.py 273): INFO Test: [0/98]	Time 6.452 (6.452)	Loss 6.0091 (6.0091)	Acc@1 3.320 (3.320)	Acc@5 10.156 (10.156)	Mem 8928MB
[2022-04-05 00:11:14 large] (main.py 279): INFO  * Acc@1 3.272 Acc@5 10.272
[2022-04-05 00:11:14 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 3.3%
[2022-04-05 00:11:14 large] (utils.py 57): INFO output/large/default/ckpt_epoch_0.pth saving......
[2022-04-05 00:11:15 large] (utils.py 59): INFO output/large/default/ckpt_epoch_0.pth saved !!!
[2022-04-05 00:11:15 large] (main.py 148): INFO Max accuracy: 3.27%
[2022-04-05 00:11:24 large] (main.py 226): INFO Train: [1/300][0/2502]	eta 5:51:18 lr 0.000025	time 8.4246 (8.4246)	loss 6.4730 (6.4730)	grad_norm 3.0676 (3.0676)	mem 8928MB
[2022-04-05 00:12:16 large] (main.py 226): INFO Train: [1/300][100/2502]	eta 0:24:00 lr 0.000026	time 0.5684 (0.5998)	loss 6.5923 (6.5962)	grad_norm 3.2652 (3.2297)	mem 8928MB
[2022-04-05 00:13:19 large] (main.py 226): INFO Train: [1/300][200/2502]	eta 0:23:35 lr 0.000027	time 0.6158 (0.6149)	loss 6.5888 (6.5943)	grad_norm 2.9362 (3.2280)	mem 8928MB
[2022-04-05 00:14:22 large] (main.py 226): INFO Train: [1/300][300/2502]	eta 0:22:47 lr 0.000028	time 0.6402 (0.6211)	loss 6.8438 (6.5780)	grad_norm 3.1983 (3.2412)	mem 8928MB
[2022-04-05 00:15:14 large] (main.py 226): INFO Train: [1/300][400/2502]	eta 0:20:50 lr 0.000029	time 0.4996 (0.5949)	loss 6.2890 (6.5652)	grad_norm 3.3143 (3.2649)	mem 8928MB
[2022-04-05 00:16:12 large] (main.py 226): INFO Train: [1/300][500/2502]	eta 0:19:46 lr 0.000030	time 0.6340 (0.5927)	loss 6.6968 (6.5591)	grad_norm 2.5784 (3.2742)	mem 8928MB
[2022-04-05 00:17:13 large] (main.py 226): INFO Train: [1/300][600/2502]	eta 0:18:52 lr 0.000031	time 0.6509 (0.5952)	loss 6.4953 (6.5539)	grad_norm 3.8585 (3.2812)	mem 8928MB
[2022-04-05 00:18:14 large] (main.py 226): INFO Train: [1/300][700/2502]	eta 0:17:57 lr 0.000032	time 0.6495 (0.5980)	loss 6.5988 (6.5483)	grad_norm 2.6544 (3.2863)	mem 8928MB
[2022-04-05 00:19:16 large] (main.py 226): INFO Train: [1/300][800/2502]	eta 0:17:01 lr 0.000033	time 0.4875 (0.6000)	loss 6.5075 (6.5427)	grad_norm 3.7434 (3.2882)	mem 8928MB
[2022-04-05 00:20:17 large] (main.py 226): INFO Train: [1/300][900/2502]	eta 0:16:03 lr 0.000034	time 0.6402 (0.6017)	loss 6.6356 (6.5363)	grad_norm 2.7720 (3.2950)	mem 8928MB
[2022-04-05 00:21:19 large] (main.py 226): INFO Train: [1/300][1000/2502]	eta 0:15:05 lr 0.000035	time 0.5956 (0.6029)	loss 6.7348 (6.5293)	grad_norm 3.4771 (3.3194)	mem 8928MB
[2022-04-05 00:22:20 large] (main.py 226): INFO Train: [1/300][1100/2502]	eta 0:14:06 lr 0.000036	time 0.5288 (0.6035)	loss 6.0788 (6.5225)	grad_norm 4.3764 (3.3316)	mem 8928MB
[2022-04-05 00:23:20 large] (main.py 226): INFO Train: [1/300][1200/2502]	eta 0:13:05 lr 0.000037	time 0.5924 (0.6035)	loss 6.4691 (6.5182)	grad_norm 3.4122 (3.3366)	mem 8928MB
[2022-04-05 00:24:21 large] (main.py 226): INFO Train: [1/300][1300/2502]	eta 0:12:06 lr 0.000038	time 0.6803 (0.6041)	loss 6.5744 (6.5146)	grad_norm 3.2747 (3.3501)	mem 8928MB
[2022-04-05 00:25:21 large] (main.py 226): INFO Train: [1/300][1400/2502]	eta 0:11:05 lr 0.000039	time 0.6236 (0.6040)	loss 6.6174 (6.5068)	grad_norm 3.7763 (3.3651)	mem 8928MB
[2022-04-05 00:26:21 large] (main.py 226): INFO Train: [1/300][1500/2502]	eta 0:10:04 lr 0.000040	time 0.6536 (0.6034)	loss 6.0823 (6.4999)	grad_norm 3.1701 (inf)	mem 8928MB
[2022-04-05 00:27:21 large] (main.py 226): INFO Train: [1/300][1600/2502]	eta 0:09:04 lr 0.000041	time 0.6660 (0.6033)	loss 6.0941 (6.4929)	grad_norm 3.7704 (inf)	mem 8928MB
[2022-04-05 00:28:22 large] (main.py 226): INFO Train: [1/300][1700/2502]	eta 0:08:04 lr 0.000042	time 0.6250 (0.6038)	loss 6.4851 (6.4867)	grad_norm 3.4240 (inf)	mem 8928MB
[2022-04-05 00:29:24 large] (main.py 226): INFO Train: [1/300][1800/2502]	eta 0:07:04 lr 0.000043	time 0.6636 (0.6047)	loss 6.1332 (6.4794)	grad_norm 3.9070 (inf)	mem 8928MB
[2022-04-05 00:30:25 large] (main.py 226): INFO Train: [1/300][1900/2502]	eta 0:06:03 lr 0.000044	time 0.5755 (0.6046)	loss 6.3805 (6.4742)	grad_norm 3.2883 (inf)	mem 8928MB
[2022-04-05 00:31:26 large] (main.py 226): INFO Train: [1/300][2000/2502]	eta 0:05:03 lr 0.000045	time 0.6518 (0.6049)	loss 6.5890 (6.4680)	grad_norm 3.0105 (inf)	mem 8928MB
[2022-04-05 00:32:27 large] (main.py 226): INFO Train: [1/300][2100/2502]	eta 0:04:03 lr 0.000046	time 0.6026 (0.6052)	loss 6.6006 (6.4632)	grad_norm 3.1206 (inf)	mem 8928MB
[2022-04-05 00:33:28 large] (main.py 226): INFO Train: [1/300][2200/2502]	eta 0:03:02 lr 0.000047	time 0.5652 (0.6054)	loss 6.0889 (6.4584)	grad_norm 3.8865 (inf)	mem 8928MB
[2022-04-05 00:34:29 large] (main.py 226): INFO Train: [1/300][2300/2502]	eta 0:02:02 lr 0.000048	time 0.5849 (0.6056)	loss 6.2680 (6.4518)	grad_norm 4.2309 (inf)	mem 8928MB
[2022-04-05 00:35:29 large] (main.py 226): INFO Train: [1/300][2400/2502]	eta 0:01:01 lr 0.000049	time 0.5557 (0.6057)	loss 6.4137 (6.4432)	grad_norm 3.1172 (inf)	mem 8928MB
[2022-04-05 00:36:31 large] (main.py 226): INFO Train: [1/300][2500/2502]	eta 0:00:01 lr 0.000050	time 0.6083 (0.6061)	loss 5.8984 (6.4379)	grad_norm 3.9602 (inf)	mem 8928MB
[2022-04-05 00:36:32 large] (main.py 233): INFO EPOCH 1 training takes 0:25:16
[2022-04-05 00:36:39 large] (main.py 273): INFO Test: [0/98]	Time 6.778 (6.778)	Loss 5.1779 (5.1779)	Acc@1 8.203 (8.203)	Acc@5 26.172 (26.172)	Mem 8928MB
[2022-04-05 00:37:04 large] (main.py 279): INFO  * Acc@1 8.980 Acc@5 23.524
[2022-04-05 00:37:04 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 9.0%
[2022-04-05 00:37:04 large] (utils.py 57): INFO output/large/default/ckpt_epoch_1.pth saving......
[2022-04-05 00:37:05 large] (utils.py 59): INFO output/large/default/ckpt_epoch_1.pth saved !!!
[2022-04-05 00:37:05 large] (main.py 148): INFO Max accuracy: 8.98%
[2022-04-05 00:37:13 large] (main.py 226): INFO Train: [2/300][0/2502]	eta 5:27:19 lr 0.000050	time 7.8495 (7.8495)	loss 6.4110 (6.4110)	grad_norm 3.7308 (3.7308)	mem 8928MB
[2022-04-05 00:38:07 large] (main.py 226): INFO Train: [2/300][100/2502]	eta 0:24:32 lr 0.000051	time 0.5854 (0.6131)	loss 6.6178 (6.2490)	grad_norm 4.3323 (3.6603)	mem 8928MB
[2022-04-05 00:39:09 large] (main.py 226): INFO Train: [2/300][200/2502]	eta 0:23:36 lr 0.000052	time 0.5680 (0.6152)	loss 6.4314 (6.2539)	grad_norm 3.6754 (3.7651)	mem 8928MB
[2022-04-05 00:40:11 large] (main.py 226): INFO Train: [2/300][300/2502]	eta 0:22:40 lr 0.000053	time 0.5319 (0.6177)	loss 5.9891 (6.2643)	grad_norm 3.5468 (3.7607)	mem 8928MB
[2022-04-05 00:41:14 large] (main.py 226): INFO Train: [2/300][400/2502]	eta 0:21:44 lr 0.000054	time 0.6869 (0.6207)	loss 6.5689 (6.2555)	grad_norm 3.7432 (3.7695)	mem 8928MB
[2022-04-05 00:42:15 large] (main.py 226): INFO Train: [2/300][500/2502]	eta 0:20:40 lr 0.000055	time 0.6190 (0.6197)	loss 6.4006 (6.2440)	grad_norm 3.3662 (3.7892)	mem 8928MB
[2022-04-05 00:43:18 large] (main.py 226): INFO Train: [2/300][600/2502]	eta 0:19:39 lr 0.000056	time 0.6544 (0.6201)	loss 5.8981 (6.2294)	grad_norm 3.6171 (3.7724)	mem 8929MB
[2022-04-05 00:44:19 large] (main.py 226): INFO Train: [2/300][700/2502]	eta 0:18:36 lr 0.000057	time 0.6672 (0.6195)	loss 6.0112 (6.2250)	grad_norm 4.2853 (3.7545)	mem 8929MB
[2022-04-05 00:45:20 large] (main.py 226): INFO Train: [2/300][800/2502]	eta 0:17:31 lr 0.000058	time 0.6271 (0.6175)	loss 6.3970 (6.2153)	grad_norm 3.6608 (3.7590)	mem 8929MB
[2022-04-05 00:46:20 large] (main.py 226): INFO Train: [2/300][900/2502]	eta 0:16:27 lr 0.000059	time 0.5237 (0.6164)	loss 6.4810 (6.2130)	grad_norm 3.6633 (3.7609)	mem 8929MB
[2022-04-05 00:47:22 large] (main.py 226): INFO Train: [2/300][1000/2502]	eta 0:15:26 lr 0.000060	time 0.5635 (0.6166)	loss 6.2902 (6.2105)	grad_norm 3.1996 (inf)	mem 8929MB
[2022-04-05 00:48:23 large] (main.py 226): INFO Train: [2/300][1100/2502]	eta 0:14:23 lr 0.000061	time 0.6554 (0.6161)	loss 6.1070 (6.2043)	grad_norm 4.0659 (inf)	mem 8929MB
[2022-04-05 00:49:23 large] (main.py 226): INFO Train: [2/300][1200/2502]	eta 0:13:20 lr 0.000062	time 0.5519 (0.6148)	loss 5.8822 (6.1984)	grad_norm 3.4759 (inf)	mem 8929MB
[2022-04-05 00:50:24 large] (main.py 226): INFO Train: [2/300][1300/2502]	eta 0:12:18 lr 0.000063	time 0.5760 (0.6143)	loss 6.3431 (6.1946)	grad_norm 3.0705 (inf)	mem 8929MB
[2022-04-05 00:51:26 large] (main.py 226): INFO Train: [2/300][1400/2502]	eta 0:11:17 lr 0.000064	time 0.5347 (0.6147)	loss 5.8994 (6.1892)	grad_norm 3.9128 (inf)	mem 8929MB
[2022-04-05 00:52:26 large] (main.py 226): INFO Train: [2/300][1500/2502]	eta 0:10:15 lr 0.000065	time 0.6788 (0.6139)	loss 6.2105 (6.1792)	grad_norm 3.6839 (inf)	mem 8929MB
[2022-04-05 00:53:28 large] (main.py 226): INFO Train: [2/300][1600/2502]	eta 0:09:13 lr 0.000066	time 0.5421 (0.6137)	loss 5.8227 (6.1738)	grad_norm 3.6083 (inf)	mem 8929MB
[2022-04-05 00:54:29 large] (main.py 226): INFO Train: [2/300][1700/2502]	eta 0:08:12 lr 0.000067	time 0.6387 (0.6137)	loss 6.0757 (6.1663)	grad_norm 3.3549 (inf)	mem 8929MB
[2022-04-05 00:55:31 large] (main.py 226): INFO Train: [2/300][1800/2502]	eta 0:07:11 lr 0.000068	time 0.6218 (0.6140)	loss 6.2131 (6.1605)	grad_norm 3.1188 (inf)	mem 8929MB
[2022-04-05 00:56:32 large] (main.py 226): INFO Train: [2/300][1900/2502]	eta 0:06:09 lr 0.000069	time 0.5282 (0.6139)	loss 5.7358 (6.1518)	grad_norm 4.3202 (inf)	mem 8929MB
[2022-04-05 00:57:34 large] (main.py 226): INFO Train: [2/300][2000/2502]	eta 0:05:08 lr 0.000070	time 0.6641 (0.6144)	loss 5.8671 (6.1420)	grad_norm 3.7315 (inf)	mem 8929MB
[2022-04-05 00:58:35 large] (main.py 226): INFO Train: [2/300][2100/2502]	eta 0:04:06 lr 0.000071	time 0.5132 (0.6142)	loss 6.0459 (6.1356)	grad_norm 3.2644 (inf)	mem 8929MB
[2022-04-05 00:59:37 large] (main.py 226): INFO Train: [2/300][2200/2502]	eta 0:03:05 lr 0.000072	time 0.6108 (0.6143)	loss 6.2646 (6.1300)	grad_norm 3.6483 (inf)	mem 8929MB
[2022-04-05 01:00:38 large] (main.py 226): INFO Train: [2/300][2300/2502]	eta 0:02:03 lr 0.000073	time 0.5290 (0.6139)	loss 6.0546 (6.1248)	grad_norm 3.2976 (inf)	mem 8929MB
[2022-04-05 01:01:39 large] (main.py 226): INFO Train: [2/300][2400/2502]	eta 0:01:02 lr 0.000074	time 0.6161 (0.6139)	loss 6.1244 (6.1176)	grad_norm 4.6928 (inf)	mem 8929MB
[2022-04-05 01:02:41 large] (main.py 226): INFO Train: [2/300][2500/2502]	eta 0:00:01 lr 0.000075	time 0.5876 (0.6140)	loss 6.2966 (6.1107)	grad_norm 3.2871 (inf)	mem 8929MB
[2022-04-05 01:02:42 large] (main.py 233): INFO EPOCH 2 training takes 0:25:36
[2022-04-05 01:02:48 large] (main.py 273): INFO Test: [0/98]	Time 5.939 (5.939)	Loss 4.3092 (4.3092)	Acc@1 20.117 (20.117)	Acc@5 42.188 (42.188)	Mem 8929MB
[2022-04-05 01:03:14 large] (main.py 279): INFO  * Acc@1 18.194 Acc@5 39.282
[2022-04-05 01:03:14 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 18.2%
[2022-04-05 01:03:14 large] (utils.py 57): INFO output/large/default/ckpt_epoch_2.pth saving......
[2022-04-05 01:03:15 large] (utils.py 59): INFO output/large/default/ckpt_epoch_2.pth saved !!!
[2022-04-05 01:03:15 large] (main.py 148): INFO Max accuracy: 18.19%
[2022-04-05 01:03:23 large] (main.py 226): INFO Train: [3/300][0/2502]	eta 5:17:23 lr 0.000075	time 7.6111 (7.6111)	loss 5.2368 (5.2368)	grad_norm 3.7608 (3.7608)	mem 8929MB
[2022-04-05 01:04:12 large] (main.py 226): INFO Train: [3/300][100/2502]	eta 0:22:43 lr 0.000076	time 0.4806 (0.5675)	loss 6.2656 (5.9109)	grad_norm 3.9356 (3.6796)	mem 8929MB
[2022-04-05 01:05:09 large] (main.py 226): INFO Train: [3/300][200/2502]	eta 0:21:46 lr 0.000077	time 0.5869 (0.5676)	loss 5.8288 (5.9368)	grad_norm 3.6387 (3.6770)	mem 8929MB
[2022-04-05 01:06:11 large] (main.py 226): INFO Train: [3/300][300/2502]	eta 0:21:25 lr 0.000078	time 0.6032 (0.5836)	loss 5.8724 (5.9151)	grad_norm 3.5450 (3.6892)	mem 8929MB
[2022-04-05 01:07:12 large] (main.py 226): INFO Train: [3/300][400/2502]	eta 0:20:43 lr 0.000079	time 0.5754 (0.5917)	loss 6.2573 (5.9220)	grad_norm 3.8826 (3.6803)	mem 8929MB
[2022-04-05 01:08:14 large] (main.py 226): INFO Train: [3/300][500/2502]	eta 0:19:55 lr 0.000080	time 0.6912 (0.5970)	loss 5.9730 (5.9076)	grad_norm 3.0917 (inf)	mem 8929MB
[2022-04-05 01:09:16 large] (main.py 226): INFO Train: [3/300][600/2502]	eta 0:19:03 lr 0.000081	time 0.6697 (0.6014)	loss 6.1541 (5.8969)	grad_norm 3.3338 (inf)	mem 8929MB
[2022-04-05 01:10:18 large] (main.py 226): INFO Train: [3/300][700/2502]	eta 0:18:06 lr 0.000082	time 0.6381 (0.6030)	loss 6.3126 (5.8943)	grad_norm 3.1760 (inf)	mem 8929MB
[2022-04-05 01:11:19 large] (main.py 226): INFO Train: [3/300][800/2502]	eta 0:17:07 lr 0.000083	time 0.5808 (0.6040)	loss 5.2306 (5.8891)	grad_norm 3.5636 (inf)	mem 8929MB
[2022-04-05 01:12:20 large] (main.py 226): INFO Train: [3/300][900/2502]	eta 0:16:09 lr 0.000084	time 0.6197 (0.6052)	loss 5.6652 (5.8855)	grad_norm 3.2000 (inf)	mem 8929MB
[2022-04-05 01:13:22 large] (main.py 226): INFO Train: [3/300][1000/2502]	eta 0:15:10 lr 0.000085	time 0.5711 (0.6062)	loss 6.1677 (5.8846)	grad_norm 4.1315 (inf)	mem 8929MB
[2022-04-05 01:14:23 large] (main.py 226): INFO Train: [3/300][1100/2502]	eta 0:14:10 lr 0.000086	time 0.5912 (0.6065)	loss 5.9026 (5.8822)	grad_norm 3.1755 (inf)	mem 8929MB
[2022-04-05 01:15:23 large] (main.py 226): INFO Train: [3/300][1200/2502]	eta 0:13:09 lr 0.000087	time 0.6302 (0.6065)	loss 5.4322 (5.8745)	grad_norm 3.5811 (inf)	mem 8929MB
[2022-04-05 01:16:24 large] (main.py 226): INFO Train: [3/300][1300/2502]	eta 0:12:09 lr 0.000088	time 0.5595 (0.6066)	loss 5.8201 (5.8720)	grad_norm 3.8231 (inf)	mem 8929MB
[2022-04-05 01:17:25 large] (main.py 226): INFO Train: [3/300][1400/2502]	eta 0:11:08 lr 0.000089	time 0.5879 (0.6068)	loss 5.4512 (5.8680)	grad_norm 3.2933 (inf)	mem 8929MB
[2022-04-05 01:18:27 large] (main.py 226): INFO Train: [3/300][1500/2502]	eta 0:10:08 lr 0.000090	time 0.6160 (0.6076)	loss 6.0911 (5.8627)	grad_norm 3.2380 (inf)	mem 8929MB
[2022-04-05 01:19:27 large] (main.py 226): INFO Train: [3/300][1600/2502]	eta 0:09:07 lr 0.000091	time 0.6658 (0.6074)	loss 6.0629 (5.8554)	grad_norm 3.5986 (inf)	mem 8929MB
[2022-04-05 01:20:29 large] (main.py 226): INFO Train: [3/300][1700/2502]	eta 0:08:07 lr 0.000092	time 0.4914 (0.6078)	loss 5.2436 (5.8479)	grad_norm 3.6749 (inf)	mem 8929MB
[2022-04-05 01:21:30 large] (main.py 226): INFO Train: [3/300][1800/2502]	eta 0:07:06 lr 0.000093	time 0.5614 (0.6082)	loss 6.1963 (5.8437)	grad_norm 3.5154 (inf)	mem 8929MB
[2022-04-05 01:22:33 large] (main.py 226): INFO Train: [3/300][1900/2502]	eta 0:06:06 lr 0.000094	time 0.5150 (0.6093)	loss 6.0131 (5.8371)	grad_norm 3.3427 (inf)	mem 8929MB
[2022-04-05 01:23:34 large] (main.py 226): INFO Train: [3/300][2000/2502]	eta 0:05:05 lr 0.000095	time 0.6276 (0.6092)	loss 4.9792 (5.8330)	grad_norm 3.7776 (inf)	mem 8929MB
[2022-04-05 01:24:35 large] (main.py 226): INFO Train: [3/300][2100/2502]	eta 0:04:04 lr 0.000096	time 0.6311 (0.6092)	loss 5.2548 (5.8256)	grad_norm 3.6416 (inf)	mem 8929MB
[2022-04-05 01:25:37 large] (main.py 226): INFO Train: [3/300][2200/2502]	eta 0:03:04 lr 0.000097	time 0.6411 (0.6096)	loss 5.8649 (5.8225)	grad_norm 3.3812 (inf)	mem 8929MB
[2022-04-05 01:26:37 large] (main.py 226): INFO Train: [3/300][2300/2502]	eta 0:02:03 lr 0.000098	time 0.5674 (0.6093)	loss 5.8460 (5.8176)	grad_norm 3.6032 (inf)	mem 8929MB
[2022-04-05 01:27:38 large] (main.py 226): INFO Train: [3/300][2400/2502]	eta 0:01:02 lr 0.000099	time 0.6872 (0.6092)	loss 5.0605 (5.8114)	grad_norm 3.4841 (inf)	mem 8929MB
[2022-04-05 01:28:38 large] (main.py 226): INFO Train: [3/300][2500/2502]	eta 0:00:01 lr 0.000100	time 0.5537 (0.6089)	loss 6.0000 (5.8064)	grad_norm 3.3724 (inf)	mem 8929MB
[2022-04-05 01:28:39 large] (main.py 233): INFO EPOCH 3 training takes 0:25:23
[2022-04-05 01:28:45 large] (main.py 273): INFO Test: [0/98]	Time 6.628 (6.628)	Loss 3.7943 (3.7943)	Acc@1 26.367 (26.367)	Acc@5 49.023 (49.023)	Mem 8929MB
[2022-04-05 01:29:11 large] (main.py 279): INFO  * Acc@1 27.174 Acc@5 51.508
[2022-04-05 01:29:11 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 27.2%
[2022-04-05 01:29:11 large] (utils.py 57): INFO output/large/default/ckpt_epoch_3.pth saving......
[2022-04-05 01:29:12 large] (utils.py 59): INFO output/large/default/ckpt_epoch_3.pth saved !!!
[2022-04-05 01:29:12 large] (main.py 148): INFO Max accuracy: 27.17%
[2022-04-05 01:29:20 large] (main.py 226): INFO Train: [4/300][0/2502]	eta 5:43:22 lr 0.000100	time 8.2344 (8.2344)	loss 5.8049 (5.8049)	grad_norm 3.4453 (3.4453)	mem 8929MB
[2022-04-05 01:30:12 large] (main.py 226): INFO Train: [4/300][100/2502]	eta 0:23:46 lr 0.000101	time 0.5286 (0.5940)	loss 5.2842 (5.7151)	grad_norm 4.1315 (3.5682)	mem 8929MB
[2022-04-05 01:31:13 large] (main.py 226): INFO Train: [4/300][200/2502]	eta 0:23:10 lr 0.000102	time 0.6335 (0.6042)	loss 4.9570 (5.6991)	grad_norm 4.1923 (inf)	mem 8929MB
[2022-04-05 01:32:15 large] (main.py 226): INFO Train: [4/300][300/2502]	eta 0:22:18 lr 0.000103	time 0.6506 (0.6080)	loss 5.2671 (5.6955)	grad_norm 3.8680 (inf)	mem 8929MB
[2022-04-05 01:33:17 large] (main.py 226): INFO Train: [4/300][400/2502]	eta 0:21:24 lr 0.000104	time 0.6292 (0.6111)	loss 5.6752 (5.6695)	grad_norm 3.5590 (inf)	mem 8929MB
[2022-04-05 01:34:19 large] (main.py 226): INFO Train: [4/300][500/2502]	eta 0:20:28 lr 0.000105	time 0.5431 (0.6136)	loss 5.5593 (5.6583)	grad_norm 3.7147 (inf)	mem 8929MB
[2022-04-05 01:35:20 large] (main.py 226): INFO Train: [4/300][600/2502]	eta 0:19:23 lr 0.000106	time 0.5835 (0.6119)	loss 6.1159 (5.6449)	grad_norm 3.5238 (inf)	mem 8929MB
[2022-04-05 01:36:21 large] (main.py 226): INFO Train: [4/300][700/2502]	eta 0:18:23 lr 0.000107	time 0.5680 (0.6126)	loss 5.0320 (5.6410)	grad_norm 3.7016 (inf)	mem 8929MB
[2022-04-05 01:37:23 large] (main.py 226): INFO Train: [4/300][800/2502]	eta 0:17:23 lr 0.000108	time 0.6285 (0.6129)	loss 5.8886 (5.6350)	grad_norm 3.3854 (inf)	mem 8929MB
[2022-04-05 01:38:25 large] (main.py 226): INFO Train: [4/300][900/2502]	eta 0:16:22 lr 0.000109	time 0.6442 (0.6133)	loss 5.6785 (5.6346)	grad_norm 3.7491 (inf)	mem 8929MB
[2022-04-05 01:39:25 large] (main.py 226): INFO Train: [4/300][1000/2502]	eta 0:15:20 lr 0.000110	time 0.5911 (0.6128)	loss 5.8456 (5.6296)	grad_norm 3.3403 (inf)	mem 8929MB
[2022-04-05 01:40:27 large] (main.py 226): INFO Train: [4/300][1100/2502]	eta 0:14:19 lr 0.000111	time 0.5223 (0.6128)	loss 5.9506 (5.6270)	grad_norm 3.6925 (inf)	mem 8929MB
[2022-04-05 01:41:27 large] (main.py 226): INFO Train: [4/300][1200/2502]	eta 0:13:17 lr 0.000112	time 0.7067 (0.6122)	loss 4.7545 (5.6226)	grad_norm 3.5498 (inf)	mem 8929MB
[2022-04-05 01:42:30 large] (main.py 226): INFO Train: [4/300][1300/2502]	eta 0:12:16 lr 0.000113	time 0.6374 (0.6131)	loss 5.8605 (5.6179)	grad_norm 3.3943 (inf)	mem 8929MB
[2022-04-05 01:43:30 large] (main.py 226): INFO Train: [4/300][1400/2502]	eta 0:11:15 lr 0.000114	time 0.4799 (0.6127)	loss 5.7133 (5.6141)	grad_norm 2.9466 (inf)	mem 8929MB
[2022-04-05 01:44:32 large] (main.py 226): INFO Train: [4/300][1500/2502]	eta 0:10:13 lr 0.000115	time 0.5863 (0.6128)	loss 5.4675 (5.6180)	grad_norm 3.5179 (inf)	mem 8929MB
[2022-04-05 01:45:33 large] (main.py 226): INFO Train: [4/300][1600/2502]	eta 0:09:12 lr 0.000116	time 0.5743 (0.6130)	loss 5.0827 (5.6108)	grad_norm 3.0134 (inf)	mem 8929MB
[2022-04-05 01:46:27 large] (main.py 226): INFO Train: [4/300][1700/2502]	eta 0:08:08 lr 0.000117	time 0.5880 (0.6086)	loss 5.7545 (5.6062)	grad_norm 3.1068 (inf)	mem 8929MB
[2022-04-05 01:47:28 large] (main.py 226): INFO Train: [4/300][1800/2502]	eta 0:07:07 lr 0.000118	time 0.6174 (0.6088)	loss 5.8444 (5.5985)	grad_norm 3.4820 (inf)	mem 8929MB
[2022-04-05 01:48:30 large] (main.py 226): INFO Train: [4/300][1900/2502]	eta 0:06:06 lr 0.000119	time 0.6173 (0.6094)	loss 5.7660 (5.5930)	grad_norm 3.8930 (inf)	mem 8929MB
[2022-04-05 01:49:31 large] (main.py 226): INFO Train: [4/300][2000/2502]	eta 0:05:05 lr 0.000120	time 0.5045 (0.6094)	loss 5.7005 (5.5879)	grad_norm 2.8386 (inf)	mem 8929MB
[2022-04-05 01:50:32 large] (main.py 226): INFO Train: [4/300][2100/2502]	eta 0:04:04 lr 0.000121	time 0.5881 (0.6093)	loss 5.1831 (5.5816)	grad_norm 3.3273 (inf)	mem 8929MB
[2022-04-05 01:51:34 large] (main.py 226): INFO Train: [4/300][2200/2502]	eta 0:03:04 lr 0.000122	time 0.6159 (0.6098)	loss 4.4351 (5.5705)	grad_norm 3.4786 (inf)	mem 8929MB
[2022-04-05 01:52:35 large] (main.py 226): INFO Train: [4/300][2300/2502]	eta 0:02:03 lr 0.000123	time 0.6249 (0.6097)	loss 5.4658 (5.5664)	grad_norm 3.6657 (inf)	mem 8929MB
[2022-04-05 01:53:36 large] (main.py 226): INFO Train: [4/300][2400/2502]	eta 0:01:02 lr 0.000124	time 0.5892 (0.6099)	loss 6.1191 (5.5612)	grad_norm 2.9487 (inf)	mem 8929MB
[2022-04-05 01:54:37 large] (main.py 226): INFO Train: [4/300][2500/2502]	eta 0:00:01 lr 0.000125	time 0.5906 (0.6100)	loss 4.5964 (5.5544)	grad_norm 3.9327 (inf)	mem 8929MB
[2022-04-05 01:54:38 large] (main.py 233): INFO EPOCH 4 training takes 0:25:26
[2022-04-05 01:54:45 large] (main.py 273): INFO Test: [0/98]	Time 6.374 (6.374)	Loss 3.1894 (3.1894)	Acc@1 37.109 (37.109)	Acc@5 60.156 (60.156)	Mem 8929MB
[2022-04-05 01:55:11 large] (main.py 279): INFO  * Acc@1 34.700 Acc@5 60.256
[2022-04-05 01:55:11 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 34.7%
[2022-04-05 01:55:11 large] (utils.py 57): INFO output/large/default/ckpt_epoch_4.pth saving......
[2022-04-05 01:55:11 large] (utils.py 59): INFO output/large/default/ckpt_epoch_4.pth saved !!!
[2022-04-05 01:55:11 large] (main.py 148): INFO Max accuracy: 34.70%
[2022-04-05 01:55:20 large] (main.py 226): INFO Train: [5/300][0/2502]	eta 5:36:33 lr 0.000125	time 8.0710 (8.0710)	loss 5.9968 (5.9968)	grad_norm 3.0684 (3.0684)	mem 8929MB
[2022-04-05 01:56:15 large] (main.py 226): INFO Train: [5/300][100/2502]	eta 0:25:10 lr 0.000126	time 0.5922 (0.6290)	loss 5.2710 (5.4808)	grad_norm 3.8044 (3.5643)	mem 8929MB
[2022-04-05 01:57:17 large] (main.py 226): INFO Train: [5/300][200/2502]	eta 0:23:54 lr 0.000127	time 0.6561 (0.6232)	loss 5.6437 (5.5017)	grad_norm 2.8504 (3.5269)	mem 8929MB
[2022-04-05 01:58:19 large] (main.py 226): INFO Train: [5/300][300/2502]	eta 0:22:54 lr 0.000128	time 0.6255 (0.6241)	loss 5.8197 (5.4724)	grad_norm 3.3865 (3.5160)	mem 8929MB
[2022-04-05 01:59:21 large] (main.py 226): INFO Train: [5/300][400/2502]	eta 0:21:46 lr 0.000129	time 0.6381 (0.6214)	loss 4.4542 (5.4704)	grad_norm 4.4071 (3.5364)	mem 8929MB
[2022-04-05 02:00:23 large] (main.py 226): INFO Train: [5/300][500/2502]	eta 0:20:43 lr 0.000130	time 0.5425 (0.6210)	loss 5.9847 (5.4594)	grad_norm 3.5761 (3.5253)	mem 8929MB
[2022-04-05 02:01:23 large] (main.py 226): INFO Train: [5/300][600/2502]	eta 0:19:36 lr 0.000131	time 0.5946 (0.6184)	loss 5.3377 (5.4587)	grad_norm 4.3049 (3.5223)	mem 8929MB
[2022-04-05 02:02:25 large] (main.py 226): INFO Train: [5/300][700/2502]	eta 0:18:33 lr 0.000132	time 0.6277 (0.6179)	loss 6.0680 (5.4529)	grad_norm 3.1699 (3.5110)	mem 8929MB
[2022-04-05 02:03:25 large] (main.py 226): INFO Train: [5/300][800/2502]	eta 0:17:28 lr 0.000133	time 0.6143 (0.6162)	loss 4.4901 (5.4373)	grad_norm 4.0617 (3.5150)	mem 8929MB
[2022-04-05 02:04:26 large] (main.py 226): INFO Train: [5/300][900/2502]	eta 0:16:26 lr 0.000134	time 0.7055 (0.6156)	loss 4.2992 (5.4277)	grad_norm 3.4584 (3.5130)	mem 8929MB
[2022-04-05 02:05:29 large] (main.py 226): INFO Train: [5/300][1000/2502]	eta 0:15:26 lr 0.000135	time 0.6804 (0.6166)	loss 5.7503 (5.4299)	grad_norm 3.3905 (3.5140)	mem 8929MB
[2022-04-05 02:06:30 large] (main.py 226): INFO Train: [5/300][1100/2502]	eta 0:14:23 lr 0.000136	time 0.6175 (0.6161)	loss 5.8305 (5.4144)	grad_norm 3.1044 (3.5282)	mem 8929MB
[2022-04-05 02:07:31 large] (main.py 226): INFO Train: [5/300][1200/2502]	eta 0:13:21 lr 0.000137	time 0.5819 (0.6156)	loss 5.9408 (5.4065)	grad_norm 3.2544 (3.5178)	mem 8929MB
[2022-04-05 02:08:31 large] (main.py 226): INFO Train: [5/300][1300/2502]	eta 0:12:18 lr 0.000138	time 0.6503 (0.6142)	loss 5.7825 (5.4033)	grad_norm 4.0545 (3.5206)	mem 8929MB
[2022-04-05 02:09:31 large] (main.py 226): INFO Train: [5/300][1400/2502]	eta 0:11:16 lr 0.000139	time 0.5769 (0.6138)	loss 5.9371 (5.3979)	grad_norm 4.5979 (3.5304)	mem 8929MB
[2022-04-05 02:10:33 large] (main.py 226): INFO Train: [5/300][1500/2502]	eta 0:10:14 lr 0.000140	time 0.6016 (0.6137)	loss 5.7944 (5.3938)	grad_norm 3.1253 (3.5398)	mem 8929MB
[2022-04-05 02:11:34 large] (main.py 226): INFO Train: [5/300][1600/2502]	eta 0:09:13 lr 0.000141	time 0.6102 (0.6134)	loss 5.8723 (5.3938)	grad_norm 3.4582 (3.5426)	mem 8929MB
[2022-04-05 02:12:35 large] (main.py 226): INFO Train: [5/300][1700/2502]	eta 0:08:11 lr 0.000142	time 0.5119 (0.6132)	loss 5.4413 (5.3913)	grad_norm 3.3976 (3.5353)	mem 8929MB
[2022-04-05 02:13:36 large] (main.py 226): INFO Train: [5/300][1800/2502]	eta 0:07:10 lr 0.000143	time 0.6169 (0.6133)	loss 4.3173 (5.3835)	grad_norm 4.0875 (inf)	mem 8929MB
[2022-04-05 02:14:38 large] (main.py 226): INFO Train: [5/300][1900/2502]	eta 0:06:09 lr 0.000144	time 0.6108 (0.6135)	loss 5.5480 (5.3848)	grad_norm 3.5542 (inf)	mem 8929MB
[2022-04-05 02:15:39 large] (main.py 226): INFO Train: [5/300][2000/2502]	eta 0:05:08 lr 0.000145	time 0.5470 (0.6137)	loss 5.6104 (5.3850)	grad_norm 3.5276 (inf)	mem 8929MB
[2022-04-05 02:16:41 large] (main.py 226): INFO Train: [5/300][2100/2502]	eta 0:04:06 lr 0.000146	time 0.5632 (0.6138)	loss 5.7809 (5.3835)	grad_norm 3.2862 (inf)	mem 8929MB
[2022-04-05 02:17:42 large] (main.py 226): INFO Train: [5/300][2200/2502]	eta 0:03:05 lr 0.000147	time 0.6062 (0.6136)	loss 4.7232 (5.3735)	grad_norm 3.9170 (inf)	mem 8929MB
[2022-04-05 02:18:44 large] (main.py 226): INFO Train: [5/300][2300/2502]	eta 0:02:03 lr 0.000148	time 0.6006 (0.6136)	loss 4.3775 (5.3683)	grad_norm 3.3666 (inf)	mem 8929MB
[2022-04-05 02:19:45 large] (main.py 226): INFO Train: [5/300][2400/2502]	eta 0:01:02 lr 0.000149	time 0.6009 (0.6138)	loss 5.8284 (5.3646)	grad_norm 3.6405 (inf)	mem 8929MB
[2022-04-05 02:20:46 large] (main.py 226): INFO Train: [5/300][2500/2502]	eta 0:00:01 lr 0.000150	time 0.6349 (0.6134)	loss 5.5731 (5.3599)	grad_norm 3.2863 (inf)	mem 8929MB
[2022-04-05 02:20:47 large] (main.py 233): INFO EPOCH 5 training takes 0:25:35
[2022-04-05 02:20:54 large] (main.py 273): INFO Test: [0/98]	Time 6.897 (6.897)	Loss 2.9402 (2.9402)	Acc@1 42.188 (42.188)	Acc@5 65.234 (65.234)	Mem 8929MB
[2022-04-05 02:21:19 large] (main.py 279): INFO  * Acc@1 39.812 Acc@5 65.772
[2022-04-05 02:21:19 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 39.8%
[2022-04-05 02:21:19 large] (utils.py 57): INFO output/large/default/ckpt_epoch_5.pth saving......
[2022-04-05 02:21:20 large] (utils.py 59): INFO output/large/default/ckpt_epoch_5.pth saved !!!
[2022-04-05 02:21:20 large] (main.py 148): INFO Max accuracy: 39.81%
[2022-04-05 02:21:28 large] (main.py 226): INFO Train: [6/300][0/2502]	eta 5:46:57 lr 0.000150	time 8.3202 (8.3202)	loss 5.9842 (5.9842)	grad_norm 3.4967 (3.4967)	mem 8929MB
[2022-04-05 02:22:19 large] (main.py 226): INFO Train: [6/300][100/2502]	eta 0:23:39 lr 0.000151	time 0.6370 (0.5909)	loss 5.0347 (5.1938)	grad_norm 2.9321 (3.5960)	mem 8929MB
[2022-04-05 02:23:21 large] (main.py 226): INFO Train: [6/300][200/2502]	eta 0:23:10 lr 0.000152	time 0.6285 (0.6040)	loss 5.7166 (5.2418)	grad_norm 2.9410 (3.5317)	mem 8929MB
[2022-04-05 02:24:24 large] (main.py 226): INFO Train: [6/300][300/2502]	eta 0:22:26 lr 0.000153	time 0.6180 (0.6115)	loss 5.7590 (5.2568)	grad_norm 2.9693 (3.5081)	mem 8929MB
[2022-04-05 02:25:25 large] (main.py 226): INFO Train: [6/300][400/2502]	eta 0:21:26 lr 0.000154	time 0.5817 (0.6121)	loss 5.3208 (5.2366)	grad_norm 3.3126 (3.5172)	mem 8929MB
[2022-04-05 02:26:27 large] (main.py 226): INFO Train: [6/300][500/2502]	eta 0:20:26 lr 0.000155	time 0.5213 (0.6125)	loss 5.7896 (5.2288)	grad_norm 3.0672 (3.5353)	mem 8929MB
[2022-04-05 02:27:28 large] (main.py 226): INFO Train: [6/300][600/2502]	eta 0:19:25 lr 0.000156	time 0.5410 (0.6127)	loss 5.3375 (5.2348)	grad_norm 3.2041 (3.5396)	mem 8929MB
[2022-04-05 02:28:29 large] (main.py 226): INFO Train: [6/300][700/2502]	eta 0:18:23 lr 0.000157	time 0.7146 (0.6126)	loss 5.1244 (5.2349)	grad_norm 3.7377 (3.5419)	mem 8929MB
[2022-04-05 02:29:30 large] (main.py 226): INFO Train: [6/300][800/2502]	eta 0:17:22 lr 0.000158	time 0.5532 (0.6122)	loss 4.4074 (5.2304)	grad_norm 3.2684 (3.5325)	mem 8929MB
[2022-04-05 02:30:32 large] (main.py 226): INFO Train: [6/300][900/2502]	eta 0:16:21 lr 0.000159	time 0.6876 (0.6129)	loss 5.5174 (5.2371)	grad_norm 3.5036 (3.5348)	mem 8929MB
[2022-04-05 02:31:29 large] (main.py 226): INFO Train: [6/300][1000/2502]	eta 0:15:14 lr 0.000160	time 0.5745 (0.6089)	loss 5.3061 (5.2247)	grad_norm 2.9872 (3.5339)	mem 8929MB
[2022-04-05 02:32:28 large] (main.py 226): INFO Train: [6/300][1100/2502]	eta 0:14:10 lr 0.000161	time 0.6502 (0.6068)	loss 4.8443 (5.2177)	grad_norm 4.8426 (3.5308)	mem 8929MB
[2022-04-05 02:33:29 large] (main.py 226): INFO Train: [6/300][1200/2502]	eta 0:13:10 lr 0.000162	time 0.5280 (0.6071)	loss 4.4475 (5.2173)	grad_norm 3.8854 (3.5331)	mem 8929MB
[2022-04-05 02:34:31 large] (main.py 226): INFO Train: [6/300][1300/2502]	eta 0:12:10 lr 0.000163	time 0.5547 (0.6080)	loss 5.7633 (5.2098)	grad_norm 3.6231 (inf)	mem 8929MB
[2022-04-05 02:35:32 large] (main.py 226): INFO Train: [6/300][1400/2502]	eta 0:11:10 lr 0.000164	time 0.6349 (0.6084)	loss 5.5593 (5.2040)	grad_norm 3.3154 (inf)	mem 8929MB
[2022-04-05 02:36:34 large] (main.py 226): INFO Train: [6/300][1500/2502]	eta 0:10:10 lr 0.000165	time 0.6085 (0.6090)	loss 5.4533 (5.2032)	grad_norm 3.5212 (inf)	mem 8929MB
[2022-04-05 02:37:35 large] (main.py 226): INFO Train: [6/300][1600/2502]	eta 0:09:09 lr 0.000166	time 0.6722 (0.6094)	loss 5.5005 (5.1964)	grad_norm 3.9460 (inf)	mem 8929MB
[2022-04-05 02:38:36 large] (main.py 226): INFO Train: [6/300][1700/2502]	eta 0:08:08 lr 0.000167	time 0.5609 (0.6095)	loss 5.8089 (5.1950)	grad_norm 2.9434 (inf)	mem 8929MB
[2022-04-05 02:39:38 large] (main.py 226): INFO Train: [6/300][1800/2502]	eta 0:07:07 lr 0.000168	time 0.6212 (0.6097)	loss 4.7330 (5.1904)	grad_norm 3.5249 (inf)	mem 8929MB
[2022-04-05 02:40:39 large] (main.py 226): INFO Train: [6/300][1900/2502]	eta 0:06:07 lr 0.000169	time 0.4833 (0.6098)	loss 4.3292 (5.1882)	grad_norm 3.3933 (inf)	mem 8929MB
[2022-04-05 02:41:40 large] (main.py 226): INFO Train: [6/300][2000/2502]	eta 0:05:06 lr 0.000170	time 0.6767 (0.6100)	loss 4.5931 (5.1857)	grad_norm 3.5219 (inf)	mem 8929MB
[2022-04-05 02:42:41 large] (main.py 226): INFO Train: [6/300][2100/2502]	eta 0:04:05 lr 0.000171	time 0.4967 (0.6100)	loss 5.5579 (5.1790)	grad_norm 2.8891 (inf)	mem 8929MB
[2022-04-05 02:43:43 large] (main.py 226): INFO Train: [6/300][2200/2502]	eta 0:03:04 lr 0.000172	time 0.6882 (0.6103)	loss 4.7685 (5.1759)	grad_norm 3.8674 (inf)	mem 8929MB
[2022-04-05 02:44:44 large] (main.py 226): INFO Train: [6/300][2300/2502]	eta 0:02:03 lr 0.000173	time 0.5331 (0.6104)	loss 5.8877 (5.1744)	grad_norm 2.6212 (inf)	mem 8929MB
[2022-04-05 02:45:46 large] (main.py 226): INFO Train: [6/300][2400/2502]	eta 0:01:02 lr 0.000174	time 0.5082 (0.6105)	loss 4.5346 (5.1689)	grad_norm 3.3734 (inf)	mem 8929MB
[2022-04-05 02:46:47 large] (main.py 226): INFO Train: [6/300][2500/2502]	eta 0:00:01 lr 0.000175	time 0.6219 (0.6106)	loss 4.2151 (5.1657)	grad_norm 3.3257 (inf)	mem 8929MB
[2022-04-05 02:46:48 large] (main.py 233): INFO EPOCH 6 training takes 0:25:28
[2022-04-05 02:46:54 large] (main.py 273): INFO Test: [0/98]	Time 5.657 (5.657)	Loss 2.7601 (2.7601)	Acc@1 42.578 (42.578)	Acc@5 68.359 (68.359)	Mem 8929MB
[2022-04-05 02:47:20 large] (main.py 279): INFO  * Acc@1 43.912 Acc@5 69.718
[2022-04-05 02:47:20 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 43.9%
[2022-04-05 02:47:20 large] (utils.py 57): INFO output/large/default/ckpt_epoch_6.pth saving......
[2022-04-05 02:47:21 large] (utils.py 59): INFO output/large/default/ckpt_epoch_6.pth saved !!!
[2022-04-05 02:47:21 large] (main.py 148): INFO Max accuracy: 43.91%
[2022-04-05 02:47:29 large] (main.py 226): INFO Train: [7/300][0/2502]	eta 5:48:31 lr 0.000175	time 8.3578 (8.3578)	loss 5.6349 (5.6349)	grad_norm 3.6712 (3.6712)	mem 8929MB
[2022-04-05 02:48:24 large] (main.py 226): INFO Train: [7/300][100/2502]	eta 0:25:02 lr 0.000176	time 0.5668 (0.6257)	loss 4.9716 (5.1300)	grad_norm 3.6627 (3.6443)	mem 8929MB
[2022-04-05 02:49:26 large] (main.py 226): INFO Train: [7/300][200/2502]	eta 0:23:55 lr 0.000177	time 0.5044 (0.6235)	loss 5.5652 (5.0709)	grad_norm 3.4017 (3.5659)	mem 8929MB
[2022-04-05 02:50:27 large] (main.py 226): INFO Train: [7/300][300/2502]	eta 0:22:46 lr 0.000178	time 0.5334 (0.6205)	loss 4.7388 (5.0677)	grad_norm 3.3440 (3.5604)	mem 8929MB
[2022-04-05 02:51:29 large] (main.py 226): INFO Train: [7/300][400/2502]	eta 0:21:41 lr 0.000179	time 0.5906 (0.6193)	loss 5.3811 (5.0699)	grad_norm 4.6356 (3.5402)	mem 8929MB
[2022-04-05 02:52:31 large] (main.py 226): INFO Train: [7/300][500/2502]	eta 0:20:39 lr 0.000180	time 0.4797 (0.6192)	loss 5.8337 (5.0623)	grad_norm 2.8147 (3.5150)	mem 8929MB
[2022-04-05 02:53:33 large] (main.py 226): INFO Train: [7/300][600/2502]	eta 0:19:37 lr 0.000181	time 0.4929 (0.6191)	loss 4.9137 (5.0708)	grad_norm 2.9398 (3.5225)	mem 8929MB
[2022-04-05 02:54:34 large] (main.py 226): INFO Train: [7/300][700/2502]	eta 0:18:35 lr 0.000182	time 0.6016 (0.6188)	loss 5.1180 (5.0733)	grad_norm 3.5997 (3.5280)	mem 8929MB
[2022-04-05 02:55:36 large] (main.py 226): INFO Train: [7/300][800/2502]	eta 0:17:32 lr 0.000183	time 0.6334 (0.6181)	loss 3.8109 (5.0837)	grad_norm 3.8441 (3.5106)	mem 8929MB
[2022-04-05 02:56:38 large] (main.py 226): INFO Train: [7/300][900/2502]	eta 0:16:30 lr 0.000184	time 0.6061 (0.6181)	loss 4.5068 (5.0843)	grad_norm 3.5381 (inf)	mem 8929MB
[2022-04-05 02:57:39 large] (main.py 226): INFO Train: [7/300][1000/2502]	eta 0:15:28 lr 0.000185	time 0.6342 (0.6180)	loss 4.6160 (5.0768)	grad_norm 3.2840 (inf)	mem 8929MB
[2022-04-05 02:58:41 large] (main.py 226): INFO Train: [7/300][1100/2502]	eta 0:14:26 lr 0.000186	time 0.6369 (0.6177)	loss 5.4000 (5.0674)	grad_norm 2.8443 (inf)	mem 8929MB
[2022-04-05 02:59:43 large] (main.py 226): INFO Train: [7/300][1200/2502]	eta 0:13:24 lr 0.000187	time 0.5418 (0.6179)	loss 4.7830 (5.0600)	grad_norm 2.9425 (inf)	mem 8929MB
[2022-04-05 03:00:44 large] (main.py 226): INFO Train: [7/300][1300/2502]	eta 0:12:22 lr 0.000188	time 0.5913 (0.6174)	loss 5.4266 (5.0571)	grad_norm 5.1151 (inf)	mem 8929MB
[2022-04-05 03:01:45 large] (main.py 226): INFO Train: [7/300][1400/2502]	eta 0:11:19 lr 0.000189	time 0.5805 (0.6169)	loss 5.8328 (5.0536)	grad_norm 3.4851 (inf)	mem 8929MB
[2022-04-05 03:02:47 large] (main.py 226): INFO Train: [7/300][1500/2502]	eta 0:10:18 lr 0.000190	time 0.6066 (0.6170)	loss 5.2147 (5.0471)	grad_norm 4.0150 (inf)	mem 8929MB
[2022-04-05 03:03:48 large] (main.py 226): INFO Train: [7/300][1600/2502]	eta 0:09:16 lr 0.000191	time 0.6266 (0.6164)	loss 5.1029 (5.0485)	grad_norm 3.3445 (inf)	mem 8929MB
[2022-04-05 03:04:48 large] (main.py 226): INFO Train: [7/300][1700/2502]	eta 0:08:14 lr 0.000192	time 0.6219 (0.6160)	loss 5.3262 (5.0465)	grad_norm 2.9092 (inf)	mem 8929MB
[2022-04-05 03:05:50 large] (main.py 226): INFO Train: [7/300][1800/2502]	eta 0:07:12 lr 0.000193	time 0.5955 (0.6162)	loss 4.5578 (5.0427)	grad_norm 9.1759 (inf)	mem 8929MB
[2022-04-05 03:06:51 large] (main.py 226): INFO Train: [7/300][1900/2502]	eta 0:06:10 lr 0.000194	time 0.5277 (0.6156)	loss 4.4149 (5.0374)	grad_norm 3.6239 (inf)	mem 8929MB
[2022-04-05 03:07:52 large] (main.py 226): INFO Train: [7/300][2000/2502]	eta 0:05:08 lr 0.000195	time 0.5117 (0.6152)	loss 5.5268 (5.0390)	grad_norm 3.5004 (inf)	mem 8929MB
[2022-04-05 03:08:53 large] (main.py 226): INFO Train: [7/300][2100/2502]	eta 0:04:07 lr 0.000196	time 0.6031 (0.6151)	loss 5.2065 (5.0404)	grad_norm 2.8850 (inf)	mem 8929MB
[2022-04-05 03:09:54 large] (main.py 226): INFO Train: [7/300][2200/2502]	eta 0:03:05 lr 0.000197	time 0.6515 (0.6148)	loss 4.6983 (5.0357)	grad_norm 2.4262 (inf)	mem 8929MB
[2022-04-05 03:10:55 large] (main.py 226): INFO Train: [7/300][2300/2502]	eta 0:02:04 lr 0.000198	time 0.6047 (0.6146)	loss 4.8936 (5.0319)	grad_norm 2.8989 (inf)	mem 8929MB
[2022-04-05 03:11:57 large] (main.py 226): INFO Train: [7/300][2400/2502]	eta 0:01:02 lr 0.000199	time 0.6720 (0.6148)	loss 5.2826 (5.0291)	grad_norm 3.3884 (inf)	mem 8929MB
[2022-04-05 03:12:58 large] (main.py 226): INFO Train: [7/300][2500/2502]	eta 0:00:01 lr 0.000200	time 0.5516 (0.6146)	loss 4.6921 (5.0256)	grad_norm 5.5276 (inf)	mem 8929MB
[2022-04-05 03:12:59 large] (main.py 233): INFO EPOCH 7 training takes 0:25:38
[2022-04-05 03:13:05 large] (main.py 273): INFO Test: [0/98]	Time 6.410 (6.410)	Loss 2.3395 (2.3395)	Acc@1 51.562 (51.562)	Acc@5 74.805 (74.805)	Mem 8929MB
[2022-04-05 03:13:31 large] (main.py 279): INFO  * Acc@1 47.806 Acc@5 73.374
[2022-04-05 03:13:31 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 47.8%
[2022-04-05 03:13:31 large] (utils.py 57): INFO output/large/default/ckpt_epoch_7.pth saving......
[2022-04-05 03:13:31 large] (utils.py 59): INFO output/large/default/ckpt_epoch_7.pth saved !!!
[2022-04-05 03:13:31 large] (main.py 148): INFO Max accuracy: 47.81%
[2022-04-05 03:13:40 large] (main.py 226): INFO Train: [8/300][0/2502]	eta 5:38:31 lr 0.000200	time 8.1182 (8.1182)	loss 5.3691 (5.3691)	grad_norm 3.4878 (3.4878)	mem 8929MB
[2022-04-05 03:14:31 large] (main.py 226): INFO Train: [8/300][100/2502]	eta 0:23:24 lr 0.000201	time 0.6441 (0.5846)	loss 5.0671 (5.0637)	grad_norm 2.8202 (3.5198)	mem 8929MB
[2022-04-05 03:15:33 large] (main.py 226): INFO Train: [8/300][200/2502]	eta 0:23:07 lr 0.000202	time 0.5379 (0.6026)	loss 5.4878 (4.9651)	grad_norm 2.9036 (3.5914)	mem 8929MB
[2022-04-05 03:16:36 large] (main.py 226): INFO Train: [8/300][300/2502]	eta 0:22:26 lr 0.000203	time 0.5811 (0.6114)	loss 4.6936 (4.9551)	grad_norm 3.0999 (3.5237)	mem 8929MB
[2022-04-05 03:17:37 large] (main.py 226): INFO Train: [8/300][400/2502]	eta 0:21:28 lr 0.000204	time 0.6031 (0.6128)	loss 5.4085 (4.9375)	grad_norm 3.3987 (3.4736)	mem 8929MB
[2022-04-05 03:18:39 large] (main.py 226): INFO Train: [8/300][500/2502]	eta 0:20:28 lr 0.000205	time 0.7204 (0.6135)	loss 5.0810 (4.9472)	grad_norm 2.5786 (3.4965)	mem 8929MB
[2022-04-05 03:19:40 large] (main.py 226): INFO Train: [8/300][600/2502]	eta 0:19:26 lr 0.000206	time 0.6750 (0.6135)	loss 5.3581 (4.9645)	grad_norm 4.0928 (3.5172)	mem 8929MB
[2022-04-05 03:20:42 large] (main.py 226): INFO Train: [8/300][700/2502]	eta 0:18:26 lr 0.000207	time 0.6513 (0.6140)	loss 5.4045 (4.9627)	grad_norm 2.9370 (3.5185)	mem 8929MB
[2022-04-05 03:21:43 large] (main.py 226): INFO Train: [8/300][800/2502]	eta 0:17:25 lr 0.000208	time 0.7291 (0.6141)	loss 5.4041 (4.9576)	grad_norm 2.9140 (3.5122)	mem 8929MB
[2022-04-05 03:22:45 large] (main.py 226): INFO Train: [8/300][900/2502]	eta 0:16:25 lr 0.000209	time 0.6007 (0.6149)	loss 5.1560 (4.9526)	grad_norm 2.6031 (inf)	mem 8929MB
[2022-04-05 03:23:47 large] (main.py 226): INFO Train: [8/300][1000/2502]	eta 0:15:23 lr 0.000210	time 0.5499 (0.6146)	loss 5.0532 (4.9435)	grad_norm 2.6123 (inf)	mem 8929MB
[2022-04-05 03:24:48 large] (main.py 226): INFO Train: [8/300][1100/2502]	eta 0:14:22 lr 0.000211	time 0.5332 (0.6149)	loss 5.1089 (4.9338)	grad_norm 2.5214 (inf)	mem 8929MB
[2022-04-05 03:25:49 large] (main.py 226): INFO Train: [8/300][1200/2502]	eta 0:13:19 lr 0.000212	time 0.5628 (0.6141)	loss 5.0863 (4.9322)	grad_norm 3.0334 (inf)	mem 8929MB
[2022-04-05 03:26:51 large] (main.py 226): INFO Train: [8/300][1300/2502]	eta 0:12:18 lr 0.000213	time 0.6259 (0.6142)	loss 4.3728 (4.9232)	grad_norm 3.7888 (inf)	mem 8929MB
[2022-04-05 03:27:51 large] (main.py 226): INFO Train: [8/300][1400/2502]	eta 0:11:16 lr 0.000214	time 0.6438 (0.6136)	loss 3.8162 (4.9253)	grad_norm 2.9848 (inf)	mem 8929MB
[2022-04-05 03:28:52 large] (main.py 226): INFO Train: [8/300][1500/2502]	eta 0:10:14 lr 0.000215	time 0.5249 (0.6131)	loss 3.7944 (4.9150)	grad_norm 3.9407 (inf)	mem 8929MB
[2022-04-05 03:29:53 large] (main.py 226): INFO Train: [8/300][1600/2502]	eta 0:09:13 lr 0.000216	time 0.6386 (0.6132)	loss 4.6067 (4.9065)	grad_norm 3.0338 (inf)	mem 8929MB
[2022-04-05 03:30:54 large] (main.py 226): INFO Train: [8/300][1700/2502]	eta 0:08:11 lr 0.000217	time 0.5618 (0.6130)	loss 4.1774 (4.9100)	grad_norm 3.5704 (inf)	mem 8929MB
[2022-04-05 03:31:55 large] (main.py 226): INFO Train: [8/300][1800/2502]	eta 0:07:10 lr 0.000218	time 0.6596 (0.6127)	loss 5.6228 (4.9110)	grad_norm 2.8772 (inf)	mem 8929MB
[2022-04-05 03:32:55 large] (main.py 226): INFO Train: [8/300][1900/2502]	eta 0:06:08 lr 0.000219	time 0.5800 (0.6123)	loss 4.8913 (4.9110)	grad_norm 4.2451 (inf)	mem 8929MB
[2022-04-05 03:33:56 large] (main.py 226): INFO Train: [8/300][2000/2502]	eta 0:05:07 lr 0.000220	time 0.6406 (0.6121)	loss 5.4821 (4.9120)	grad_norm 2.9773 (inf)	mem 8929MB
[2022-04-05 03:34:56 large] (main.py 226): INFO Train: [8/300][2100/2502]	eta 0:04:05 lr 0.000221	time 0.5825 (0.6116)	loss 4.5445 (4.9067)	grad_norm 2.8756 (inf)	mem 8929MB
[2022-04-05 03:35:58 large] (main.py 226): INFO Train: [8/300][2200/2502]	eta 0:03:04 lr 0.000222	time 0.5041 (0.6117)	loss 5.8138 (4.9048)	grad_norm 3.2719 (inf)	mem 8929MB
[2022-04-05 03:36:59 large] (main.py 226): INFO Train: [8/300][2300/2502]	eta 0:02:03 lr 0.000223	time 0.6025 (0.6116)	loss 5.1224 (4.9074)	grad_norm 3.8130 (inf)	mem 8929MB
[2022-04-05 03:37:59 large] (main.py 226): INFO Train: [8/300][2400/2502]	eta 0:01:02 lr 0.000224	time 0.6444 (0.6112)	loss 5.0773 (4.9102)	grad_norm 3.7186 (inf)	mem 8929MB
[2022-04-05 03:39:00 large] (main.py 226): INFO Train: [8/300][2500/2502]	eta 0:00:01 lr 0.000225	time 0.7879 (0.6112)	loss 5.5795 (4.9119)	grad_norm 2.8899 (inf)	mem 8929MB
[2022-04-05 03:39:01 large] (main.py 233): INFO EPOCH 8 training takes 0:25:29
[2022-04-05 03:39:07 large] (main.py 273): INFO Test: [0/98]	Time 6.103 (6.103)	Loss 2.2814 (2.2814)	Acc@1 50.977 (50.977)	Acc@5 76.953 (76.953)	Mem 8929MB
[2022-04-05 03:39:34 large] (main.py 279): INFO  * Acc@1 50.988 Acc@5 76.218
[2022-04-05 03:39:34 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 51.0%
[2022-04-05 03:39:34 large] (utils.py 57): INFO output/large/default/ckpt_epoch_8.pth saving......
[2022-04-05 03:39:34 large] (utils.py 59): INFO output/large/default/ckpt_epoch_8.pth saved !!!
[2022-04-05 03:39:34 large] (main.py 148): INFO Max accuracy: 50.99%
[2022-04-05 03:39:42 large] (main.py 226): INFO Train: [9/300][0/2502]	eta 5:32:33 lr 0.000225	time 7.9752 (7.9752)	loss 5.1212 (5.1212)	grad_norm 3.4392 (3.4392)	mem 8929MB
[2022-04-05 03:40:40 large] (main.py 226): INFO Train: [9/300][100/2502]	eta 0:25:52 lr 0.000226	time 0.6001 (0.6465)	loss 4.2423 (4.7801)	grad_norm 3.5621 (3.4035)	mem 8929MB
[2022-04-05 03:41:40 large] (main.py 226): INFO Train: [9/300][200/2502]	eta 0:23:59 lr 0.000227	time 0.6478 (0.6252)	loss 5.6144 (4.7861)	grad_norm 2.8555 (3.4678)	mem 8929MB
[2022-04-05 03:42:42 large] (main.py 226): INFO Train: [9/300][300/2502]	eta 0:22:52 lr 0.000228	time 0.6373 (0.6235)	loss 4.9553 (4.8260)	grad_norm 3.4251 (3.4274)	mem 8929MB
[2022-04-05 03:43:43 large] (main.py 226): INFO Train: [9/300][400/2502]	eta 0:21:42 lr 0.000229	time 0.5796 (0.6195)	loss 5.3397 (4.8126)	grad_norm 3.3529 (3.4027)	mem 8929MB
[2022-04-05 03:44:44 large] (main.py 226): INFO Train: [9/300][500/2502]	eta 0:20:38 lr 0.000230	time 0.6098 (0.6186)	loss 5.3029 (4.8216)	grad_norm 2.5614 (3.3760)	mem 8929MB
[2022-04-05 03:45:46 large] (main.py 226): INFO Train: [9/300][600/2502]	eta 0:19:34 lr 0.000231	time 0.5836 (0.6177)	loss 5.4253 (4.8078)	grad_norm 2.4334 (3.3744)	mem 8929MB
[2022-04-05 03:46:46 large] (main.py 226): INFO Train: [9/300][700/2502]	eta 0:18:29 lr 0.000232	time 0.5499 (0.6157)	loss 5.3153 (4.8092)	grad_norm 6.0213 (3.3694)	mem 8929MB
[2022-04-05 03:47:47 large] (main.py 226): INFO Train: [9/300][800/2502]	eta 0:17:26 lr 0.000233	time 0.7172 (0.6150)	loss 4.3472 (4.8153)	grad_norm 3.1338 (3.3915)	mem 8929MB
[2022-04-05 03:48:48 large] (main.py 226): INFO Train: [9/300][900/2502]	eta 0:16:23 lr 0.000234	time 0.5991 (0.6141)	loss 5.1919 (4.8039)	grad_norm 3.4404 (3.4065)	mem 8929MB
[2022-04-05 03:49:49 large] (main.py 226): INFO Train: [9/300][1000/2502]	eta 0:15:22 lr 0.000235	time 0.5911 (0.6143)	loss 5.3055 (4.8053)	grad_norm 2.8609 (3.4050)	mem 8929MB
[2022-04-05 03:50:41 large] (main.py 226): INFO Train: [9/300][1100/2502]	eta 0:14:09 lr 0.000236	time 0.5055 (0.6057)	loss 5.1878 (4.8129)	grad_norm 3.0341 (3.4024)	mem 8929MB
[2022-04-05 03:51:34 large] (main.py 226): INFO Train: [9/300][1200/2502]	eta 0:13:00 lr 0.000237	time 0.5861 (0.5995)	loss 5.6339 (4.8140)	grad_norm 3.7956 (3.3975)	mem 8929MB
[2022-04-05 03:52:37 large] (main.py 226): INFO Train: [9/300][1300/2502]	eta 0:12:02 lr 0.000238	time 0.5002 (0.6013)	loss 3.6758 (4.8060)	grad_norm 5.0334 (3.4106)	mem 8929MB
[2022-04-05 03:53:38 large] (main.py 226): INFO Train: [9/300][1400/2502]	eta 0:11:03 lr 0.000239	time 0.7222 (0.6020)	loss 4.9933 (4.8090)	grad_norm 2.7392 (3.4043)	mem 8929MB
[2022-04-05 03:54:40 large] (main.py 226): INFO Train: [9/300][1500/2502]	eta 0:10:04 lr 0.000240	time 0.5595 (0.6032)	loss 5.1675 (4.8130)	grad_norm 2.8844 (3.3965)	mem 8929MB
[2022-04-05 03:55:40 large] (main.py 226): INFO Train: [9/300][1600/2502]	eta 0:09:04 lr 0.000241	time 0.5872 (0.6034)	loss 3.6247 (4.8109)	grad_norm 2.8365 (3.3949)	mem 8929MB
[2022-04-05 03:56:42 large] (main.py 226): INFO Train: [9/300][1700/2502]	eta 0:08:04 lr 0.000242	time 0.6529 (0.6040)	loss 4.0618 (4.8127)	grad_norm 4.0559 (3.3880)	mem 8929MB
[2022-04-05 03:57:43 large] (main.py 226): INFO Train: [9/300][1800/2502]	eta 0:07:04 lr 0.000243	time 0.5700 (0.6042)	loss 5.2817 (4.8135)	grad_norm 3.1082 (3.3885)	mem 8929MB
[2022-04-05 03:58:43 large] (main.py 226): INFO Train: [9/300][1900/2502]	eta 0:06:03 lr 0.000244	time 0.5261 (0.6043)	loss 4.9004 (4.8108)	grad_norm 3.2433 (3.3866)	mem 8929MB
[2022-04-05 03:59:44 large] (main.py 226): INFO Train: [9/300][2000/2502]	eta 0:05:03 lr 0.000245	time 0.6292 (0.6046)	loss 4.9781 (4.8069)	grad_norm 4.0062 (3.3876)	mem 8929MB
[2022-04-05 04:00:40 large] (main.py 226): INFO Train: [9/300][2100/2502]	eta 0:04:02 lr 0.000246	time 0.5194 (0.6023)	loss 3.8359 (4.8058)	grad_norm 6.0916 (3.3885)	mem 8929MB
[2022-04-05 04:01:40 large] (main.py 226): INFO Train: [9/300][2200/2502]	eta 0:03:01 lr 0.000247	time 0.6224 (0.6024)	loss 5.2348 (4.8074)	grad_norm 2.7298 (3.3887)	mem 8929MB
[2022-04-05 04:02:41 large] (main.py 226): INFO Train: [9/300][2300/2502]	eta 0:02:01 lr 0.000248	time 0.5305 (0.6025)	loss 4.7880 (4.8077)	grad_norm 2.8880 (3.3852)	mem 8929MB
[2022-04-05 04:03:42 large] (main.py 226): INFO Train: [9/300][2400/2502]	eta 0:01:01 lr 0.000249	time 0.5550 (0.6030)	loss 4.4307 (4.8055)	grad_norm 2.6532 (inf)	mem 8929MB
[2022-04-05 04:04:43 large] (main.py 226): INFO Train: [9/300][2500/2502]	eta 0:00:01 lr 0.000250	time 0.6490 (0.6032)	loss 3.7740 (4.8077)	grad_norm 3.5540 (inf)	mem 8929MB
[2022-04-05 04:04:44 large] (main.py 233): INFO EPOCH 9 training takes 0:25:09
[2022-04-05 04:04:50 large] (main.py 273): INFO Test: [0/98]	Time 6.478 (6.478)	Loss 2.1486 (2.1486)	Acc@1 53.320 (53.320)	Acc@5 77.539 (77.539)	Mem 8929MB
[2022-04-05 04:05:17 large] (main.py 279): INFO  * Acc@1 52.972 Acc@5 77.992
[2022-04-05 04:05:17 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 53.0%
[2022-04-05 04:05:17 large] (utils.py 57): INFO output/large/default/ckpt_epoch_9.pth saving......
[2022-04-05 04:05:17 large] (utils.py 59): INFO output/large/default/ckpt_epoch_9.pth saved !!!
[2022-04-05 04:05:17 large] (main.py 148): INFO Max accuracy: 52.97%
[2022-04-05 04:05:26 large] (main.py 226): INFO Train: [10/300][0/2502]	eta 6:08:30 lr 0.000250	time 8.8371 (8.8371)	loss 4.2132 (4.2132)	grad_norm 3.6088 (3.6088)	mem 8929MB
[2022-04-05 04:06:23 large] (main.py 226): INFO Train: [10/300][100/2502]	eta 0:26:01 lr 0.000251	time 0.5780 (0.6503)	loss 4.4511 (4.6596)	grad_norm 4.0813 (3.5436)	mem 8929MB
[2022-04-05 04:07:24 large] (main.py 226): INFO Train: [10/300][200/2502]	eta 0:24:08 lr 0.000252	time 0.6133 (0.6291)	loss 4.5094 (4.7220)	grad_norm 5.2692 (3.4922)	mem 8929MB
[2022-04-05 04:08:26 large] (main.py 226): INFO Train: [10/300][300/2502]	eta 0:22:58 lr 0.000253	time 0.6575 (0.6260)	loss 3.4929 (4.7327)	grad_norm 2.9049 (3.4395)	mem 8929MB
[2022-04-05 04:09:26 large] (main.py 226): INFO Train: [10/300][400/2502]	eta 0:21:43 lr 0.000254	time 0.5424 (0.6202)	loss 5.3442 (4.7271)	grad_norm 2.9256 (3.4303)	mem 8929MB
[2022-04-05 04:10:28 large] (main.py 226): INFO Train: [10/300][500/2502]	eta 0:20:40 lr 0.000255	time 0.6791 (0.6199)	loss 5.1156 (4.7182)	grad_norm 3.4792 (3.4392)	mem 8929MB
[2022-04-05 04:11:28 large] (main.py 226): INFO Train: [10/300][600/2502]	eta 0:19:33 lr 0.000256	time 0.6415 (0.6167)	loss 4.9041 (4.7131)	grad_norm 3.3040 (3.4245)	mem 8929MB
[2022-04-05 04:12:29 large] (main.py 226): INFO Train: [10/300][700/2502]	eta 0:18:30 lr 0.000257	time 0.6069 (0.6164)	loss 5.5152 (4.7096)	grad_norm 2.7255 (3.4102)	mem 8929MB
[2022-04-05 04:13:30 large] (main.py 226): INFO Train: [10/300][800/2502]	eta 0:17:26 lr 0.000258	time 0.6144 (0.6151)	loss 4.4995 (4.7109)	grad_norm 3.4899 (3.4156)	mem 8929MB
[2022-04-05 04:14:31 large] (main.py 226): INFO Train: [10/300][900/2502]	eta 0:16:24 lr 0.000259	time 0.7043 (0.6143)	loss 5.2320 (4.7081)	grad_norm 3.2862 (3.4187)	mem 8929MB
[2022-04-05 04:15:32 large] (main.py 226): INFO Train: [10/300][1000/2502]	eta 0:15:21 lr 0.000260	time 0.5752 (0.6137)	loss 5.3977 (4.6991)	grad_norm 2.3659 (3.4040)	mem 8929MB
[2022-04-05 04:16:32 large] (main.py 226): INFO Train: [10/300][1100/2502]	eta 0:14:19 lr 0.000261	time 0.5801 (0.6128)	loss 4.7450 (4.6941)	grad_norm 3.3555 (3.4117)	mem 8929MB
[2022-04-05 04:17:32 large] (main.py 226): INFO Train: [10/300][1200/2502]	eta 0:13:16 lr 0.000262	time 0.5238 (0.6118)	loss 4.8074 (4.6965)	grad_norm 2.6079 (3.4037)	mem 8929MB
[2022-04-05 04:18:33 large] (main.py 226): INFO Train: [10/300][1300/2502]	eta 0:12:15 lr 0.000263	time 0.5048 (0.6116)	loss 5.6689 (4.7034)	grad_norm 2.5095 (3.4148)	mem 8929MB
[2022-04-05 04:19:33 large] (main.py 226): INFO Train: [10/300][1400/2502]	eta 0:11:13 lr 0.000264	time 0.6676 (0.6111)	loss 4.9942 (4.7078)	grad_norm 5.0894 (3.4082)	mem 8929MB
[2022-04-05 04:20:34 large] (main.py 226): INFO Train: [10/300][1500/2502]	eta 0:10:11 lr 0.000265	time 0.6062 (0.6105)	loss 4.2963 (4.7050)	grad_norm 3.4967 (3.4104)	mem 8929MB
[2022-04-05 04:21:34 large] (main.py 226): INFO Train: [10/300][1600/2502]	eta 0:09:10 lr 0.000266	time 0.6731 (0.6104)	loss 4.3195 (4.7074)	grad_norm 2.7061 (3.4080)	mem 8929MB
[2022-04-05 04:22:36 large] (main.py 226): INFO Train: [10/300][1700/2502]	eta 0:08:09 lr 0.000267	time 0.6211 (0.6107)	loss 4.9848 (4.7100)	grad_norm 2.9025 (3.3995)	mem 8929MB
[2022-04-05 04:23:37 large] (main.py 226): INFO Train: [10/300][1800/2502]	eta 0:07:08 lr 0.000268	time 0.5756 (0.6104)	loss 4.8181 (4.7102)	grad_norm 3.5745 (3.3932)	mem 8929MB
[2022-04-05 04:24:37 large] (main.py 226): INFO Train: [10/300][1900/2502]	eta 0:06:07 lr 0.000269	time 0.6673 (0.6102)	loss 5.2744 (4.7129)	grad_norm 3.2080 (3.3876)	mem 8929MB
[2022-04-05 04:25:39 large] (main.py 226): INFO Train: [10/300][2000/2502]	eta 0:05:06 lr 0.000270	time 0.6234 (0.6105)	loss 4.2690 (4.7119)	grad_norm 2.6364 (3.3777)	mem 8929MB
[2022-04-05 04:26:39 large] (main.py 226): INFO Train: [10/300][2100/2502]	eta 0:04:05 lr 0.000271	time 0.5563 (0.6101)	loss 5.4346 (4.7152)	grad_norm 3.2819 (3.3721)	mem 8929MB
[2022-04-05 04:27:40 large] (main.py 226): INFO Train: [10/300][2200/2502]	eta 0:03:04 lr 0.000272	time 0.5242 (0.6099)	loss 3.6733 (4.7141)	grad_norm 2.8831 (3.3665)	mem 8929MB
[2022-04-05 04:28:40 large] (main.py 226): INFO Train: [10/300][2300/2502]	eta 0:02:03 lr 0.000273	time 0.6229 (0.6097)	loss 5.0867 (4.7111)	grad_norm 4.2690 (inf)	mem 8929MB
[2022-04-05 04:29:41 large] (main.py 226): INFO Train: [10/300][2400/2502]	eta 0:01:02 lr 0.000274	time 0.6670 (0.6097)	loss 4.9413 (4.7103)	grad_norm 3.2909 (inf)	mem 8929MB
[2022-04-05 04:30:42 large] (main.py 226): INFO Train: [10/300][2500/2502]	eta 0:00:01 lr 0.000275	time 0.6103 (0.6096)	loss 5.1770 (4.7066)	grad_norm 2.3839 (inf)	mem 8929MB
[2022-04-05 04:30:43 large] (main.py 233): INFO EPOCH 10 training takes 0:25:25
[2022-04-05 04:30:50 large] (main.py 273): INFO Test: [0/98]	Time 6.757 (6.757)	Loss 2.1360 (2.1360)	Acc@1 53.516 (53.516)	Acc@5 78.906 (78.906)	Mem 8929MB
[2022-04-05 04:31:15 large] (main.py 279): INFO  * Acc@1 54.438 Acc@5 79.254
[2022-04-05 04:31:15 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 54.4%
[2022-04-05 04:31:15 large] (utils.py 57): INFO output/large/default/ckpt_epoch_10.pth saving......
[2022-04-05 04:31:16 large] (utils.py 59): INFO output/large/default/ckpt_epoch_10.pth saved !!!
[2022-04-05 04:31:16 large] (main.py 148): INFO Max accuracy: 54.44%
[2022-04-05 04:31:24 large] (main.py 226): INFO Train: [11/300][0/2502]	eta 5:39:27 lr 0.000275	time 8.1404 (8.1404)	loss 5.4913 (5.4913)	grad_norm 3.0390 (3.0390)	mem 8929MB
[2022-04-05 04:32:13 large] (main.py 226): INFO Train: [11/300][100/2502]	eta 0:22:37 lr 0.000276	time 0.4904 (0.5652)	loss 4.8584 (4.6544)	grad_norm 2.7818 (3.3690)	mem 8929MB
[2022-04-05 04:33:10 large] (main.py 226): INFO Train: [11/300][200/2502]	eta 0:21:40 lr 0.000277	time 0.6255 (0.5648)	loss 4.6964 (4.6534)	grad_norm 2.7161 (3.3549)	mem 8929MB
[2022-04-05 04:34:11 large] (main.py 226): INFO Train: [11/300][300/2502]	eta 0:21:22 lr 0.000278	time 0.6406 (0.5823)	loss 4.4332 (4.6562)	grad_norm 3.0686 (3.2961)	mem 8929MB
[2022-04-05 04:35:14 large] (main.py 226): INFO Train: [11/300][400/2502]	eta 0:20:44 lr 0.000279	time 0.6373 (0.5923)	loss 4.7908 (4.6656)	grad_norm 2.7521 (3.3004)	mem 8929MB
[2022-04-05 04:36:15 large] (main.py 226): INFO Train: [11/300][500/2502]	eta 0:19:54 lr 0.000280	time 0.6032 (0.5964)	loss 5.1470 (4.6609)	grad_norm 4.1521 (inf)	mem 8929MB
[2022-04-05 04:37:16 large] (main.py 226): INFO Train: [11/300][600/2502]	eta 0:18:58 lr 0.000281	time 0.5058 (0.5988)	loss 4.6948 (4.6555)	grad_norm 3.7624 (inf)	mem 8929MB
[2022-04-05 04:38:18 large] (main.py 226): INFO Train: [11/300][700/2502]	eta 0:18:04 lr 0.000282	time 0.6797 (0.6017)	loss 5.0806 (4.6500)	grad_norm 4.1622 (inf)	mem 8929MB
[2022-04-05 04:39:19 large] (main.py 226): INFO Train: [11/300][800/2502]	eta 0:17:05 lr 0.000283	time 0.7012 (0.6024)	loss 4.9080 (4.6525)	grad_norm 3.1837 (inf)	mem 8929MB
[2022-04-05 04:40:19 large] (main.py 226): INFO Train: [11/300][900/2502]	eta 0:16:05 lr 0.000284	time 0.6342 (0.6030)	loss 5.0508 (4.6424)	grad_norm 3.3375 (inf)	mem 8929MB
[2022-04-05 04:41:21 large] (main.py 226): INFO Train: [11/300][1000/2502]	eta 0:15:06 lr 0.000285	time 0.5554 (0.6038)	loss 4.8351 (4.6419)	grad_norm 2.8179 (inf)	mem 8929MB
[2022-04-05 04:42:21 large] (main.py 226): INFO Train: [11/300][1100/2502]	eta 0:14:06 lr 0.000286	time 0.5474 (0.6041)	loss 5.5240 (4.6513)	grad_norm 3.7601 (inf)	mem 8929MB
[2022-04-05 04:43:21 large] (main.py 226): INFO Train: [11/300][1200/2502]	eta 0:13:05 lr 0.000287	time 0.6032 (0.6037)	loss 4.7993 (4.6561)	grad_norm 3.8014 (inf)	mem 8929MB
[2022-04-05 04:44:21 large] (main.py 226): INFO Train: [11/300][1300/2502]	eta 0:12:05 lr 0.000288	time 0.5941 (0.6036)	loss 3.5494 (4.6516)	grad_norm 3.0441 (inf)	mem 8929MB
[2022-04-05 04:45:22 large] (main.py 226): INFO Train: [11/300][1400/2502]	eta 0:11:05 lr 0.000289	time 0.5194 (0.6041)	loss 3.3995 (4.6486)	grad_norm 3.3118 (inf)	mem 8929MB
[2022-04-05 04:46:24 large] (main.py 226): INFO Train: [11/300][1500/2502]	eta 0:10:05 lr 0.000290	time 0.5178 (0.6047)	loss 5.0182 (4.6434)	grad_norm 3.0011 (inf)	mem 8929MB
[2022-04-05 04:47:25 large] (main.py 226): INFO Train: [11/300][1600/2502]	eta 0:09:05 lr 0.000291	time 0.5944 (0.6049)	loss 4.4193 (4.6437)	grad_norm 2.6087 (inf)	mem 8929MB
[2022-04-05 04:48:25 large] (main.py 226): INFO Train: [11/300][1700/2502]	eta 0:08:04 lr 0.000292	time 0.6339 (0.6046)	loss 5.3741 (4.6408)	grad_norm 4.3671 (inf)	mem 8929MB
[2022-04-05 04:49:26 large] (main.py 226): INFO Train: [11/300][1800/2502]	eta 0:07:04 lr 0.000293	time 0.6125 (0.6053)	loss 4.0930 (4.6447)	grad_norm 2.8237 (inf)	mem 8929MB
[2022-04-05 04:50:28 large] (main.py 226): INFO Train: [11/300][1900/2502]	eta 0:06:04 lr 0.000294	time 0.6758 (0.6057)	loss 5.0025 (4.6455)	grad_norm 3.5720 (inf)	mem 8929MB
[2022-04-05 04:51:28 large] (main.py 226): INFO Train: [11/300][2000/2502]	eta 0:05:03 lr 0.000295	time 0.5518 (0.6055)	loss 4.0747 (4.6453)	grad_norm 3.0248 (inf)	mem 8929MB
[2022-04-05 04:52:29 large] (main.py 226): INFO Train: [11/300][2100/2502]	eta 0:04:03 lr 0.000296	time 0.5581 (0.6058)	loss 5.1608 (4.6422)	grad_norm 3.0179 (inf)	mem 8929MB
[2022-04-05 04:53:30 large] (main.py 226): INFO Train: [11/300][2200/2502]	eta 0:03:03 lr 0.000297	time 0.6584 (0.6061)	loss 4.6650 (4.6462)	grad_norm 4.2480 (inf)	mem 8929MB
[2022-04-05 04:54:31 large] (main.py 226): INFO Train: [11/300][2300/2502]	eta 0:02:02 lr 0.000298	time 0.6939 (0.6061)	loss 5.2100 (4.6452)	grad_norm 2.8344 (inf)	mem 8929MB
[2022-04-05 04:55:32 large] (main.py 226): INFO Train: [11/300][2400/2502]	eta 0:01:01 lr 0.000299	time 0.5203 (0.6062)	loss 4.3679 (4.6439)	grad_norm 3.1669 (inf)	mem 8929MB
[2022-04-05 04:56:31 large] (main.py 226): INFO Train: [11/300][2500/2502]	eta 0:00:01 lr 0.000300	time 0.5863 (0.6058)	loss 4.4107 (4.6448)	grad_norm 3.6340 (inf)	mem 8929MB
[2022-04-05 04:56:32 large] (main.py 233): INFO EPOCH 11 training takes 0:25:16
[2022-04-05 04:56:39 large] (main.py 273): INFO Test: [0/98]	Time 6.559 (6.559)	Loss 2.2045 (2.2045)	Acc@1 52.930 (52.930)	Acc@5 78.711 (78.711)	Mem 8929MB
[2022-04-05 04:57:05 large] (main.py 279): INFO  * Acc@1 55.978 Acc@5 80.424
[2022-04-05 04:57:05 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 56.0%
[2022-04-05 04:57:05 large] (utils.py 57): INFO output/large/default/ckpt_epoch_11.pth saving......
[2022-04-05 04:57:06 large] (utils.py 59): INFO output/large/default/ckpt_epoch_11.pth saved !!!
[2022-04-05 04:57:06 large] (main.py 148): INFO Max accuracy: 55.98%
[2022-04-05 04:57:13 large] (main.py 226): INFO Train: [12/300][0/2502]	eta 5:22:03 lr 0.000300	time 7.7230 (7.7230)	loss 5.2159 (5.2159)	grad_norm 3.1491 (3.1491)	mem 8929MB
[2022-04-05 04:58:07 large] (main.py 226): INFO Train: [12/300][100/2502]	eta 0:24:26 lr 0.000301	time 0.6157 (0.6105)	loss 5.1855 (4.6284)	grad_norm 2.7509 (3.3054)	mem 8929MB
[2022-04-05 04:59:08 large] (main.py 226): INFO Train: [12/300][200/2502]	eta 0:23:24 lr 0.000302	time 0.6225 (0.6100)	loss 3.4395 (4.6405)	grad_norm 3.1277 (3.1844)	mem 8929MB
[2022-04-05 05:00:10 large] (main.py 226): INFO Train: [12/300][300/2502]	eta 0:22:30 lr 0.000303	time 0.6491 (0.6131)	loss 4.6759 (4.6378)	grad_norm 3.0051 (3.1568)	mem 8929MB
[2022-04-05 05:01:13 large] (main.py 226): INFO Train: [12/300][400/2502]	eta 0:21:34 lr 0.000304	time 0.7182 (0.6159)	loss 4.5718 (4.6186)	grad_norm 2.2842 (3.1390)	mem 8929MB
[2022-04-05 05:02:13 large] (main.py 226): INFO Train: [12/300][500/2502]	eta 0:20:30 lr 0.000305	time 0.6923 (0.6146)	loss 3.5628 (4.6017)	grad_norm 2.9014 (3.1555)	mem 8929MB
[2022-04-05 05:03:15 large] (main.py 226): INFO Train: [12/300][600/2502]	eta 0:19:27 lr 0.000306	time 0.6632 (0.6139)	loss 4.4329 (4.5943)	grad_norm 2.6739 (3.1360)	mem 8929MB
[2022-04-05 05:04:16 large] (main.py 226): INFO Train: [12/300][700/2502]	eta 0:18:25 lr 0.000307	time 0.5749 (0.6136)	loss 5.0877 (4.5883)	grad_norm 2.4922 (3.1527)	mem 8929MB
[2022-04-05 05:05:17 large] (main.py 226): INFO Train: [12/300][800/2502]	eta 0:17:23 lr 0.000308	time 0.7064 (0.6129)	loss 5.1156 (4.6091)	grad_norm 4.0205 (3.1474)	mem 8929MB
[2022-04-05 05:06:17 large] (main.py 226): INFO Train: [12/300][900/2502]	eta 0:16:19 lr 0.000309	time 0.5037 (0.6116)	loss 3.7190 (4.6147)	grad_norm 2.8073 (3.1544)	mem 8929MB
[2022-04-05 05:07:16 large] (main.py 226): INFO Train: [12/300][1000/2502]	eta 0:15:16 lr 0.000310	time 0.5103 (0.6103)	loss 5.1749 (4.6058)	grad_norm 2.5144 (3.1539)	mem 8929MB
[2022-04-05 05:08:18 large] (main.py 226): INFO Train: [12/300][1100/2502]	eta 0:14:16 lr 0.000311	time 0.6134 (0.6111)	loss 5.0349 (4.6183)	grad_norm 3.3347 (3.1520)	mem 8929MB
[2022-04-05 05:09:20 large] (main.py 226): INFO Train: [12/300][1200/2502]	eta 0:13:15 lr 0.000312	time 0.6738 (0.6113)	loss 4.6785 (4.6149)	grad_norm 4.4655 (3.1556)	mem 8929MB
[2022-04-05 05:10:20 large] (main.py 226): INFO Train: [12/300][1300/2502]	eta 0:12:13 lr 0.000313	time 0.6669 (0.6105)	loss 5.0585 (4.6105)	grad_norm 2.5532 (3.1487)	mem 8929MB
[2022-04-05 05:11:20 large] (main.py 226): INFO Train: [12/300][1400/2502]	eta 0:11:12 lr 0.000314	time 0.6868 (0.6100)	loss 5.5098 (4.6138)	grad_norm 4.6005 (3.1331)	mem 8929MB
[2022-04-05 05:12:21 large] (main.py 226): INFO Train: [12/300][1500/2502]	eta 0:10:10 lr 0.000315	time 0.5231 (0.6096)	loss 5.1424 (4.6154)	grad_norm 2.6468 (3.1367)	mem 8929MB
[2022-04-05 05:13:20 large] (main.py 226): INFO Train: [12/300][1600/2502]	eta 0:09:09 lr 0.000316	time 0.5175 (0.6087)	loss 4.8502 (4.6110)	grad_norm 3.2647 (3.1456)	mem 8929MB
[2022-04-05 05:14:21 large] (main.py 226): INFO Train: [12/300][1700/2502]	eta 0:08:08 lr 0.000317	time 0.6384 (0.6090)	loss 5.2572 (4.6142)	grad_norm 2.6213 (3.1377)	mem 8929MB
[2022-04-05 05:15:22 large] (main.py 226): INFO Train: [12/300][1800/2502]	eta 0:07:07 lr 0.000318	time 0.5853 (0.6087)	loss 5.2042 (4.6149)	grad_norm 2.6520 (3.1332)	mem 8929MB
[2022-04-05 05:16:22 large] (main.py 226): INFO Train: [12/300][1900/2502]	eta 0:06:06 lr 0.000319	time 0.7168 (0.6085)	loss 5.2371 (4.6118)	grad_norm 3.4572 (3.1394)	mem 8929MB
[2022-04-05 05:17:23 large] (main.py 226): INFO Train: [12/300][2000/2502]	eta 0:05:05 lr 0.000320	time 0.6051 (0.6084)	loss 5.6884 (4.6068)	grad_norm 2.8258 (3.1328)	mem 8929MB
[2022-04-05 05:18:24 large] (main.py 226): INFO Train: [12/300][2100/2502]	eta 0:04:04 lr 0.000321	time 0.6169 (0.6084)	loss 5.1406 (4.6087)	grad_norm 3.3635 (inf)	mem 8929MB
[2022-04-05 05:19:24 large] (main.py 226): INFO Train: [12/300][2200/2502]	eta 0:03:03 lr 0.000322	time 0.6408 (0.6082)	loss 4.7638 (4.6106)	grad_norm 3.2314 (inf)	mem 8929MB
[2022-04-05 05:20:25 large] (main.py 226): INFO Train: [12/300][2300/2502]	eta 0:02:02 lr 0.000323	time 0.5704 (0.6082)	loss 4.9215 (4.6117)	grad_norm 3.0394 (inf)	mem 8929MB
[2022-04-05 05:21:26 large] (main.py 226): INFO Train: [12/300][2400/2502]	eta 0:01:02 lr 0.000324	time 0.6158 (0.6081)	loss 4.6706 (4.6121)	grad_norm 3.2456 (inf)	mem 8929MB
[2022-04-05 05:22:26 large] (main.py 226): INFO Train: [12/300][2500/2502]	eta 0:00:01 lr 0.000325	time 0.6136 (0.6081)	loss 3.8280 (4.6075)	grad_norm 2.7991 (inf)	mem 8929MB
[2022-04-05 05:22:27 large] (main.py 233): INFO EPOCH 12 training takes 0:25:21
[2022-04-05 05:22:34 large] (main.py 273): INFO Test: [0/98]	Time 6.590 (6.590)	Loss 1.9887 (1.9887)	Acc@1 57.031 (57.031)	Acc@5 80.664 (80.664)	Mem 8929MB
[2022-04-05 05:22:59 large] (main.py 279): INFO  * Acc@1 57.386 Acc@5 81.406
[2022-04-05 05:22:59 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 57.4%
[2022-04-05 05:22:59 large] (utils.py 57): INFO output/large/default/ckpt_epoch_12.pth saving......
[2022-04-05 05:23:00 large] (utils.py 59): INFO output/large/default/ckpt_epoch_12.pth saved !!!
[2022-04-05 05:23:00 large] (main.py 148): INFO Max accuracy: 57.39%
[2022-04-05 05:23:08 large] (main.py 226): INFO Train: [13/300][0/2502]	eta 5:19:44 lr 0.000325	time 7.6677 (7.6677)	loss 4.6520 (4.6520)	grad_norm 3.2434 (3.2434)	mem 8929MB
[2022-04-05 05:23:58 large] (main.py 226): INFO Train: [13/300][100/2502]	eta 0:22:40 lr 0.000326	time 0.5009 (0.5666)	loss 5.0853 (4.5146)	grad_norm 3.1248 (3.2651)	mem 8929MB
[2022-04-05 05:24:51 large] (main.py 226): INFO Train: [13/300][200/2502]	eta 0:21:12 lr 0.000327	time 0.5377 (0.5529)	loss 4.9419 (4.5315)	grad_norm 2.4445 (3.0575)	mem 8929MB
[2022-04-05 05:25:53 large] (main.py 226): INFO Train: [13/300][300/2502]	eta 0:21:05 lr 0.000328	time 0.6033 (0.5746)	loss 5.2687 (4.5503)	grad_norm 2.1788 (3.0993)	mem 8929MB
[2022-04-05 05:26:54 large] (main.py 226): INFO Train: [13/300][400/2502]	eta 0:20:24 lr 0.000329	time 0.5034 (0.5827)	loss 4.8659 (4.5466)	grad_norm 2.2636 (3.1095)	mem 8929MB
[2022-04-05 05:27:56 large] (main.py 226): INFO Train: [13/300][500/2502]	eta 0:19:41 lr 0.000330	time 0.6112 (0.5900)	loss 5.0445 (4.5416)	grad_norm 3.7061 (3.1298)	mem 8929MB
[2022-04-05 05:28:57 large] (main.py 226): INFO Train: [13/300][600/2502]	eta 0:18:48 lr 0.000331	time 0.6054 (0.5933)	loss 4.9669 (4.5545)	grad_norm 4.0068 (3.1265)	mem 8929MB
[2022-04-05 05:29:58 large] (main.py 226): INFO Train: [13/300][700/2502]	eta 0:17:53 lr 0.000332	time 0.6165 (0.5956)	loss 5.3277 (4.5406)	grad_norm 4.5075 (3.1004)	mem 8929MB
[2022-04-05 05:30:59 large] (main.py 226): INFO Train: [13/300][800/2502]	eta 0:16:56 lr 0.000333	time 0.5050 (0.5970)	loss 5.3458 (4.5519)	grad_norm 3.5411 (3.0907)	mem 8929MB
[2022-04-05 05:32:00 large] (main.py 226): INFO Train: [13/300][900/2502]	eta 0:15:59 lr 0.000334	time 0.5840 (0.5989)	loss 5.0614 (4.5430)	grad_norm 3.4919 (3.0722)	mem 8929MB
[2022-04-05 05:33:00 large] (main.py 226): INFO Train: [13/300][1000/2502]	eta 0:15:00 lr 0.000335	time 0.6616 (0.5995)	loss 5.0335 (4.5489)	grad_norm 3.1066 (3.0907)	mem 8929MB
[2022-04-05 05:34:02 large] (main.py 226): INFO Train: [13/300][1100/2502]	eta 0:14:01 lr 0.000336	time 0.6169 (0.6006)	loss 4.7553 (4.5553)	grad_norm 2.8718 (3.0896)	mem 8929MB
[2022-04-05 05:35:01 large] (main.py 226): INFO Train: [13/300][1200/2502]	eta 0:13:01 lr 0.000337	time 0.5541 (0.6001)	loss 5.0053 (4.5409)	grad_norm 3.6772 (3.0927)	mem 8929MB
[2022-04-05 05:36:02 large] (main.py 226): INFO Train: [13/300][1300/2502]	eta 0:12:02 lr 0.000338	time 0.5866 (0.6008)	loss 5.0415 (4.5410)	grad_norm 3.1015 (3.0907)	mem 8929MB
[2022-04-05 05:37:02 large] (main.py 226): INFO Train: [13/300][1400/2502]	eta 0:11:02 lr 0.000339	time 0.6911 (0.6010)	loss 5.3506 (4.5421)	grad_norm 2.4727 (3.0921)	mem 8929MB
[2022-04-05 05:38:04 large] (main.py 226): INFO Train: [13/300][1500/2502]	eta 0:10:03 lr 0.000340	time 0.5783 (0.6019)	loss 5.1936 (4.5370)	grad_norm 2.5024 (3.0925)	mem 8929MB
[2022-04-05 05:39:04 large] (main.py 226): INFO Train: [13/300][1600/2502]	eta 0:09:03 lr 0.000341	time 0.5840 (0.6021)	loss 5.1651 (4.5338)	grad_norm 2.5699 (3.0839)	mem 8929MB
[2022-04-05 05:40:06 large] (main.py 226): INFO Train: [13/300][1700/2502]	eta 0:08:03 lr 0.000342	time 0.6341 (0.6029)	loss 3.0351 (4.5259)	grad_norm 3.3756 (inf)	mem 8929MB
[2022-04-05 05:41:07 large] (main.py 226): INFO Train: [13/300][1800/2502]	eta 0:07:03 lr 0.000343	time 0.5976 (0.6031)	loss 4.9677 (4.5294)	grad_norm 2.5308 (inf)	mem 8929MB
[2022-04-05 05:42:07 large] (main.py 226): INFO Train: [13/300][1900/2502]	eta 0:06:03 lr 0.000344	time 0.6471 (0.6034)	loss 4.3798 (4.5289)	grad_norm 2.3614 (inf)	mem 8929MB
[2022-04-05 05:43:08 large] (main.py 226): INFO Train: [13/300][2000/2502]	eta 0:05:02 lr 0.000345	time 0.6247 (0.6033)	loss 4.5732 (4.5300)	grad_norm 5.4113 (inf)	mem 8929MB
[2022-04-05 05:44:08 large] (main.py 226): INFO Train: [13/300][2100/2502]	eta 0:04:02 lr 0.000346	time 0.6491 (0.6033)	loss 3.5147 (4.5253)	grad_norm 2.6339 (inf)	mem 8929MB
[2022-04-05 05:45:09 large] (main.py 226): INFO Train: [13/300][2200/2502]	eta 0:03:02 lr 0.000347	time 0.5747 (0.6036)	loss 4.8647 (4.5284)	grad_norm 3.0913 (inf)	mem 8929MB
[2022-04-05 05:46:09 large] (main.py 226): INFO Train: [13/300][2300/2502]	eta 0:02:01 lr 0.000348	time 0.4929 (0.6034)	loss 4.2341 (4.5290)	grad_norm 2.5294 (inf)	mem 8929MB
[2022-04-05 05:47:09 large] (main.py 226): INFO Train: [13/300][2400/2502]	eta 0:01:01 lr 0.000349	time 0.6294 (0.6035)	loss 5.3985 (4.5306)	grad_norm 4.0175 (inf)	mem 8929MB
[2022-04-05 05:48:10 large] (main.py 226): INFO Train: [13/300][2500/2502]	eta 0:00:01 lr 0.000350	time 0.6049 (0.6037)	loss 4.9474 (4.5299)	grad_norm 2.5482 (inf)	mem 8929MB
[2022-04-05 05:48:11 large] (main.py 233): INFO EPOCH 13 training takes 0:25:10
[2022-04-05 05:48:17 large] (main.py 273): INFO Test: [0/98]	Time 5.986 (5.986)	Loss 1.9779 (1.9779)	Acc@1 58.789 (58.789)	Acc@5 83.008 (83.008)	Mem 8929MB
[2022-04-05 05:48:43 large] (main.py 279): INFO  * Acc@1 58.284 Acc@5 81.930
[2022-04-05 05:48:43 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 58.3%
[2022-04-05 05:48:43 large] (utils.py 57): INFO output/large/default/ckpt_epoch_13.pth saving......
[2022-04-05 05:48:44 large] (utils.py 59): INFO output/large/default/ckpt_epoch_13.pth saved !!!
[2022-04-05 05:48:44 large] (main.py 148): INFO Max accuracy: 58.28%
[2022-04-05 05:48:52 large] (main.py 226): INFO Train: [14/300][0/2502]	eta 5:14:20 lr 0.000350	time 7.5380 (7.5380)	loss 4.9040 (4.9040)	grad_norm 2.2000 (2.2000)	mem 8929MB
[2022-04-05 05:49:43 large] (main.py 226): INFO Train: [14/300][100/2502]	eta 0:23:23 lr 0.000351	time 0.5132 (0.5845)	loss 5.0846 (4.5210)	grad_norm 3.3152 (2.9025)	mem 8929MB
[2022-04-05 05:50:44 large] (main.py 226): INFO Train: [14/300][200/2502]	eta 0:22:50 lr 0.000352	time 0.4976 (0.5953)	loss 4.0732 (4.5763)	grad_norm 2.5576 (2.8446)	mem 8929MB
[2022-04-05 05:51:46 large] (main.py 226): INFO Train: [14/300][300/2502]	eta 0:22:09 lr 0.000353	time 0.5943 (0.6036)	loss 3.7074 (4.5383)	grad_norm 3.5466 (2.9076)	mem 8929MB
[2022-04-05 05:52:47 large] (main.py 226): INFO Train: [14/300][400/2502]	eta 0:21:15 lr 0.000354	time 0.6369 (0.6067)	loss 4.1711 (4.4966)	grad_norm 2.2728 (2.9054)	mem 8929MB
[2022-04-05 05:53:49 large] (main.py 226): INFO Train: [14/300][500/2502]	eta 0:20:18 lr 0.000355	time 0.5196 (0.6086)	loss 4.3408 (4.5033)	grad_norm 2.5221 (2.9496)	mem 8929MB
[2022-04-05 05:54:51 large] (main.py 226): INFO Train: [14/300][600/2502]	eta 0:19:20 lr 0.000356	time 0.5650 (0.6100)	loss 4.7194 (4.5227)	grad_norm 4.2525 (2.9436)	mem 8929MB
[2022-04-05 05:55:52 large] (main.py 226): INFO Train: [14/300][700/2502]	eta 0:18:20 lr 0.000357	time 0.5213 (0.6107)	loss 4.3085 (4.5006)	grad_norm 3.6241 (2.9545)	mem 8929MB
[2022-04-05 05:56:54 large] (main.py 226): INFO Train: [14/300][800/2502]	eta 0:17:21 lr 0.000358	time 0.6322 (0.6117)	loss 4.4431 (4.4915)	grad_norm 3.2202 (2.9568)	mem 8929MB
[2022-04-05 05:57:54 large] (main.py 226): INFO Train: [14/300][900/2502]	eta 0:16:18 lr 0.000359	time 0.6080 (0.6106)	loss 5.0994 (4.4800)	grad_norm 2.5090 (2.9477)	mem 8929MB
[2022-04-05 05:58:55 large] (main.py 226): INFO Train: [14/300][1000/2502]	eta 0:15:16 lr 0.000360	time 0.6210 (0.6102)	loss 4.2549 (4.4731)	grad_norm 2.3442 (2.9468)	mem 8929MB
[2022-04-05 05:59:57 large] (main.py 226): INFO Train: [14/300][1100/2502]	eta 0:14:16 lr 0.000361	time 0.6498 (0.6110)	loss 4.7563 (4.4669)	grad_norm 3.6767 (2.9361)	mem 8929MB
[2022-04-05 06:00:57 large] (main.py 226): INFO Train: [14/300][1200/2502]	eta 0:13:15 lr 0.000362	time 0.4791 (0.6107)	loss 4.6610 (4.4676)	grad_norm 2.4550 (2.9242)	mem 8929MB
[2022-04-05 06:01:59 large] (main.py 226): INFO Train: [14/300][1300/2502]	eta 0:12:14 lr 0.000363	time 0.6489 (0.6112)	loss 3.9094 (4.4703)	grad_norm 3.2642 (2.9357)	mem 8929MB
[2022-04-05 06:03:01 large] (main.py 226): INFO Train: [14/300][1400/2502]	eta 0:11:13 lr 0.000364	time 1.3030 (0.6116)	loss 5.1270 (4.4656)	grad_norm 2.9247 (inf)	mem 8929MB
[2022-04-05 06:04:01 large] (main.py 226): INFO Train: [14/300][1500/2502]	eta 0:10:12 lr 0.000365	time 0.6997 (0.6108)	loss 4.3929 (4.4684)	grad_norm 2.3957 (inf)	mem 8929MB
[2022-04-05 06:05:01 large] (main.py 226): INFO Train: [14/300][1600/2502]	eta 0:09:10 lr 0.000366	time 0.5944 (0.6101)	loss 4.5752 (4.4662)	grad_norm 2.5384 (inf)	mem 8929MB
[2022-04-05 06:06:02 large] (main.py 226): INFO Train: [14/300][1700/2502]	eta 0:08:09 lr 0.000367	time 0.5233 (0.6105)	loss 4.2738 (4.4639)	grad_norm 2.9009 (inf)	mem 8929MB
[2022-04-05 06:07:03 large] (main.py 226): INFO Train: [14/300][1800/2502]	eta 0:07:08 lr 0.000368	time 0.6056 (0.6104)	loss 4.2315 (4.4618)	grad_norm 2.3028 (inf)	mem 8929MB
[2022-04-05 06:08:04 large] (main.py 226): INFO Train: [14/300][1900/2502]	eta 0:06:07 lr 0.000369	time 0.6194 (0.6102)	loss 5.3286 (4.4621)	grad_norm 2.1593 (inf)	mem 8929MB
[2022-04-05 06:09:05 large] (main.py 226): INFO Train: [14/300][2000/2502]	eta 0:05:06 lr 0.000370	time 0.6409 (0.6102)	loss 3.6298 (4.4660)	grad_norm 3.0722 (inf)	mem 8929MB
[2022-04-05 06:10:06 large] (main.py 226): INFO Train: [14/300][2100/2502]	eta 0:04:05 lr 0.000371	time 0.5540 (0.6103)	loss 4.8074 (4.4652)	grad_norm 2.6748 (inf)	mem 8929MB
[2022-04-05 06:11:07 large] (main.py 226): INFO Train: [14/300][2200/2502]	eta 0:03:04 lr 0.000372	time 0.5932 (0.6103)	loss 3.9897 (4.4648)	grad_norm 4.5101 (inf)	mem 8929MB
[2022-04-05 06:12:09 large] (main.py 226): INFO Train: [14/300][2300/2502]	eta 0:02:03 lr 0.000373	time 0.6225 (0.6106)	loss 4.7381 (4.4677)	grad_norm 2.5337 (inf)	mem 8929MB
[2022-04-05 06:13:09 large] (main.py 226): INFO Train: [14/300][2400/2502]	eta 0:01:02 lr 0.000374	time 0.5404 (0.6101)	loss 3.7162 (4.4681)	grad_norm 2.8389 (inf)	mem 8929MB
[2022-04-05 06:14:10 large] (main.py 226): INFO Train: [14/300][2500/2502]	eta 0:00:01 lr 0.000375	time 0.6197 (0.6102)	loss 4.3564 (4.4641)	grad_norm 2.7332 (inf)	mem 8929MB
[2022-04-05 06:14:11 large] (main.py 233): INFO EPOCH 14 training takes 0:25:27
[2022-04-05 06:14:18 large] (main.py 273): INFO Test: [0/98]	Time 6.854 (6.854)	Loss 1.9821 (1.9821)	Acc@1 56.250 (56.250)	Acc@5 83.008 (83.008)	Mem 8929MB
[2022-04-05 06:14:44 large] (main.py 279): INFO  * Acc@1 58.980 Acc@5 82.826
[2022-04-05 06:14:44 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 59.0%
[2022-04-05 06:14:44 large] (utils.py 57): INFO output/large/default/ckpt_epoch_14.pth saving......
[2022-04-05 06:14:45 large] (utils.py 59): INFO output/large/default/ckpt_epoch_14.pth saved !!!
[2022-04-05 06:14:45 large] (main.py 148): INFO Max accuracy: 58.98%
[2022-04-05 06:14:52 large] (main.py 226): INFO Train: [15/300][0/2502]	eta 4:56:24 lr 0.000375	time 7.1080 (7.1080)	loss 5.0641 (5.0641)	grad_norm 2.5616 (2.5616)	mem 8929MB
[2022-04-05 06:15:42 large] (main.py 226): INFO Train: [15/300][100/2502]	eta 0:22:32 lr 0.000376	time 0.4790 (0.5630)	loss 3.2140 (4.4309)	grad_norm 2.2612 (2.9521)	mem 8929MB
[2022-04-05 06:16:42 large] (main.py 226): INFO Train: [15/300][200/2502]	eta 0:22:21 lr 0.000377	time 0.7331 (0.5826)	loss 5.1547 (4.4840)	grad_norm 2.3248 (2.8759)	mem 8929MB
[2022-04-05 06:17:44 large] (main.py 226): INFO Train: [15/300][300/2502]	eta 0:21:50 lr 0.000378	time 0.6423 (0.5951)	loss 4.1932 (4.4348)	grad_norm 2.6040 (2.8680)	mem 8929MB
[2022-04-05 06:18:46 large] (main.py 226): INFO Train: [15/300][400/2502]	eta 0:21:07 lr 0.000379	time 0.6513 (0.6030)	loss 4.9776 (4.4389)	grad_norm 2.5043 (2.8635)	mem 8929MB
[2022-04-05 06:19:49 large] (main.py 226): INFO Train: [15/300][500/2502]	eta 0:20:15 lr 0.000380	time 0.5790 (0.6072)	loss 2.9972 (4.4227)	grad_norm 3.3584 (2.8684)	mem 8929MB
[2022-04-05 06:20:50 large] (main.py 226): INFO Train: [15/300][600/2502]	eta 0:19:16 lr 0.000381	time 0.5633 (0.6081)	loss 3.4441 (4.4286)	grad_norm 2.9615 (2.8790)	mem 8929MB
[2022-04-05 06:21:51 large] (main.py 226): INFO Train: [15/300][700/2502]	eta 0:18:14 lr 0.000382	time 0.6800 (0.6076)	loss 3.8267 (4.4344)	grad_norm 2.4608 (2.8630)	mem 8929MB
[2022-04-05 06:22:52 large] (main.py 226): INFO Train: [15/300][800/2502]	eta 0:17:14 lr 0.000383	time 0.6454 (0.6078)	loss 4.8751 (4.4360)	grad_norm 2.8007 (2.8582)	mem 8929MB
[2022-04-05 06:23:52 large] (main.py 226): INFO Train: [15/300][900/2502]	eta 0:16:12 lr 0.000384	time 0.6308 (0.6072)	loss 3.8169 (4.4323)	grad_norm 2.7317 (2.8517)	mem 8929MB
[2022-04-05 06:24:52 large] (main.py 226): INFO Train: [15/300][1000/2502]	eta 0:15:11 lr 0.000385	time 0.6709 (0.6069)	loss 5.0572 (4.4344)	grad_norm 2.6844 (2.8531)	mem 8929MB
[2022-04-05 06:25:54 large] (main.py 226): INFO Train: [15/300][1100/2502]	eta 0:14:12 lr 0.000386	time 0.6673 (0.6078)	loss 4.2747 (4.4237)	grad_norm 2.4074 (inf)	mem 8929MB
[2022-04-05 06:26:55 large] (main.py 226): INFO Train: [15/300][1200/2502]	eta 0:13:11 lr 0.000387	time 0.6223 (0.6081)	loss 4.8230 (4.4214)	grad_norm 2.9782 (inf)	mem 8929MB
[2022-04-05 06:27:56 large] (main.py 226): INFO Train: [15/300][1300/2502]	eta 0:12:10 lr 0.000388	time 0.6197 (0.6081)	loss 4.2224 (4.4177)	grad_norm 2.2058 (inf)	mem 8929MB
[2022-04-05 06:28:57 large] (main.py 226): INFO Train: [15/300][1400/2502]	eta 0:11:10 lr 0.000389	time 0.6204 (0.6082)	loss 4.7094 (4.4216)	grad_norm 2.7455 (inf)	mem 8929MB
[2022-04-05 06:29:58 large] (main.py 226): INFO Train: [15/300][1500/2502]	eta 0:10:09 lr 0.000390	time 0.6219 (0.6086)	loss 5.1143 (4.4209)	grad_norm 2.6340 (inf)	mem 8929MB
[2022-04-05 06:30:58 large] (main.py 226): INFO Train: [15/300][1600/2502]	eta 0:09:08 lr 0.000391	time 0.6285 (0.6082)	loss 4.0643 (4.4271)	grad_norm 2.1397 (inf)	mem 8929MB
[2022-04-05 06:31:59 large] (main.py 226): INFO Train: [15/300][1700/2502]	eta 0:08:07 lr 0.000392	time 0.6093 (0.6079)	loss 4.5806 (4.4284)	grad_norm 2.6928 (inf)	mem 8929MB
[2022-04-05 06:32:59 large] (main.py 226): INFO Train: [15/300][1800/2502]	eta 0:07:06 lr 0.000393	time 0.5736 (0.6077)	loss 3.4292 (4.4243)	grad_norm 2.3568 (inf)	mem 8929MB
[2022-04-05 06:34:01 large] (main.py 226): INFO Train: [15/300][1900/2502]	eta 0:06:06 lr 0.000394	time 0.5845 (0.6081)	loss 4.7217 (4.4267)	grad_norm 3.0351 (inf)	mem 8929MB
[2022-04-05 06:35:01 large] (main.py 226): INFO Train: [15/300][2000/2502]	eta 0:05:05 lr 0.000395	time 0.5230 (0.6078)	loss 5.0955 (4.4305)	grad_norm 2.3162 (inf)	mem 8929MB
[2022-04-05 06:36:02 large] (main.py 226): INFO Train: [15/300][2100/2502]	eta 0:04:04 lr 0.000396	time 0.5059 (0.6077)	loss 5.4136 (4.4333)	grad_norm 3.0396 (inf)	mem 8929MB
[2022-04-05 06:37:02 large] (main.py 226): INFO Train: [15/300][2200/2502]	eta 0:03:03 lr 0.000397	time 0.6041 (0.6077)	loss 3.2508 (4.4346)	grad_norm 2.2469 (inf)	mem 8929MB
[2022-04-05 06:38:02 large] (main.py 226): INFO Train: [15/300][2300/2502]	eta 0:02:02 lr 0.000398	time 0.6025 (0.6074)	loss 4.5906 (4.4337)	grad_norm 2.8514 (inf)	mem 8929MB
[2022-04-05 06:39:03 large] (main.py 226): INFO Train: [15/300][2400/2502]	eta 0:01:01 lr 0.000399	time 0.6714 (0.6073)	loss 3.7514 (4.4308)	grad_norm 2.4445 (inf)	mem 8929MB
[2022-04-05 06:40:04 large] (main.py 226): INFO Train: [15/300][2500/2502]	eta 0:00:01 lr 0.000400	time 0.6204 (0.6075)	loss 3.9850 (4.4313)	grad_norm 2.6736 (inf)	mem 8929MB
[2022-04-05 06:40:05 large] (main.py 233): INFO EPOCH 15 training takes 0:25:20
[2022-04-05 06:40:11 large] (main.py 273): INFO Test: [0/98]	Time 5.728 (5.728)	Loss 1.9696 (1.9696)	Acc@1 59.766 (59.766)	Acc@5 80.859 (80.859)	Mem 8929MB
[2022-04-05 06:40:38 large] (main.py 279): INFO  * Acc@1 60.096 Acc@5 83.466
[2022-04-05 06:40:38 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 60.1%
[2022-04-05 06:40:38 large] (utils.py 57): INFO output/large/default/ckpt_epoch_15.pth saving......
[2022-04-05 06:40:39 large] (utils.py 59): INFO output/large/default/ckpt_epoch_15.pth saved !!!
[2022-04-05 06:40:39 large] (main.py 148): INFO Max accuracy: 60.10%
[2022-04-05 06:40:46 large] (main.py 226): INFO Train: [16/300][0/2502]	eta 5:25:14 lr 0.000400	time 7.7996 (7.7996)	loss 3.9417 (3.9417)	grad_norm 3.2125 (3.2125)	mem 8929MB
[2022-04-05 06:41:43 large] (main.py 226): INFO Train: [16/300][100/2502]	eta 0:25:39 lr 0.000401	time 0.6360 (0.6409)	loss 4.4246 (4.3905)	grad_norm 2.3992 (2.8668)	mem 8929MB
[2022-04-05 06:42:45 large] (main.py 226): INFO Train: [16/300][200/2502]	eta 0:24:01 lr 0.000402	time 0.6007 (0.6262)	loss 4.2837 (4.4104)	grad_norm 2.3055 (2.8279)	mem 8929MB
[2022-04-05 06:43:46 large] (main.py 226): INFO Train: [16/300][300/2502]	eta 0:22:49 lr 0.000403	time 0.5202 (0.6218)	loss 4.5483 (4.4357)	grad_norm 4.1015 (2.8302)	mem 8929MB
[2022-04-05 06:44:47 large] (main.py 226): INFO Train: [16/300][400/2502]	eta 0:21:41 lr 0.000404	time 0.5183 (0.6192)	loss 3.8090 (4.4146)	grad_norm 2.6431 (2.8236)	mem 8929MB
[2022-04-05 06:45:48 large] (main.py 226): INFO Train: [16/300][500/2502]	eta 0:20:35 lr 0.000405	time 0.5298 (0.6173)	loss 4.5176 (4.4410)	grad_norm 2.9133 (2.8014)	mem 8929MB
[2022-04-05 06:46:49 large] (main.py 226): INFO Train: [16/300][600/2502]	eta 0:19:30 lr 0.000406	time 0.6553 (0.6155)	loss 3.3101 (4.4192)	grad_norm 3.0416 (2.8050)	mem 8929MB
[2022-04-05 06:47:49 large] (main.py 226): INFO Train: [16/300][700/2502]	eta 0:18:27 lr 0.000407	time 0.5158 (0.6143)	loss 4.0852 (4.4178)	grad_norm 2.4736 (inf)	mem 8929MB
[2022-04-05 06:48:49 large] (main.py 226): INFO Train: [16/300][800/2502]	eta 0:17:22 lr 0.000408	time 0.6197 (0.6127)	loss 4.5923 (4.4035)	grad_norm 3.3105 (inf)	mem 8929MB
[2022-04-05 06:49:50 large] (main.py 226): INFO Train: [16/300][900/2502]	eta 0:16:20 lr 0.000409	time 0.6676 (0.6118)	loss 4.5038 (4.3960)	grad_norm 2.8081 (inf)	mem 8929MB
[2022-04-05 06:50:51 large] (main.py 226): INFO Train: [16/300][1000/2502]	eta 0:15:18 lr 0.000410	time 0.5300 (0.6116)	loss 4.6020 (4.3984)	grad_norm 1.9879 (inf)	mem 8929MB
[2022-04-05 06:51:51 large] (main.py 226): INFO Train: [16/300][1100/2502]	eta 0:14:16 lr 0.000411	time 0.5133 (0.6110)	loss 4.6315 (4.4067)	grad_norm 2.6149 (inf)	mem 8929MB
[2022-04-05 06:52:52 large] (main.py 226): INFO Train: [16/300][1200/2502]	eta 0:13:14 lr 0.000412	time 0.5870 (0.6105)	loss 5.2107 (4.4086)	grad_norm 3.6906 (inf)	mem 8929MB
[2022-04-05 06:53:52 large] (main.py 226): INFO Train: [16/300][1300/2502]	eta 0:12:12 lr 0.000413	time 0.5394 (0.6098)	loss 3.5271 (4.4071)	grad_norm 3.4672 (inf)	mem 8929MB
[2022-04-05 06:54:53 large] (main.py 226): INFO Train: [16/300][1400/2502]	eta 0:11:11 lr 0.000414	time 0.6477 (0.6094)	loss 4.1766 (4.4042)	grad_norm 2.2624 (inf)	mem 8929MB
[2022-04-05 06:55:52 large] (main.py 226): INFO Train: [16/300][1500/2502]	eta 0:10:09 lr 0.000415	time 0.6341 (0.6083)	loss 4.3355 (4.3998)	grad_norm 2.6242 (inf)	mem 8929MB
[2022-04-05 06:56:52 large] (main.py 226): INFO Train: [16/300][1600/2502]	eta 0:09:08 lr 0.000416	time 0.5530 (0.6080)	loss 4.4387 (4.4005)	grad_norm 2.4655 (inf)	mem 8929MB
[2022-04-05 06:57:51 large] (main.py 226): INFO Train: [16/300][1700/2502]	eta 0:08:06 lr 0.000417	time 0.5320 (0.6070)	loss 3.5928 (4.3928)	grad_norm 2.4577 (inf)	mem 8929MB
[2022-04-05 06:58:52 large] (main.py 226): INFO Train: [16/300][1800/2502]	eta 0:07:06 lr 0.000418	time 0.6615 (0.6070)	loss 3.7980 (4.3888)	grad_norm 3.6241 (inf)	mem 8929MB
[2022-04-05 06:59:52 large] (main.py 226): INFO Train: [16/300][1900/2502]	eta 0:06:05 lr 0.000419	time 0.6221 (0.6068)	loss 3.8946 (4.3890)	grad_norm 3.9324 (inf)	mem 8929MB
[2022-04-05 07:00:53 large] (main.py 226): INFO Train: [16/300][2000/2502]	eta 0:05:04 lr 0.000420	time 0.7106 (0.6069)	loss 4.6027 (4.3930)	grad_norm 3.2982 (inf)	mem 8929MB
[2022-04-05 07:01:53 large] (main.py 226): INFO Train: [16/300][2100/2502]	eta 0:04:03 lr 0.000421	time 0.5971 (0.6065)	loss 5.2846 (4.3936)	grad_norm 3.1758 (inf)	mem 8929MB
[2022-04-05 07:02:54 large] (main.py 226): INFO Train: [16/300][2200/2502]	eta 0:03:03 lr 0.000422	time 0.5761 (0.6065)	loss 4.1788 (4.3938)	grad_norm 2.2934 (inf)	mem 8929MB
[2022-04-05 07:03:54 large] (main.py 226): INFO Train: [16/300][2300/2502]	eta 0:02:02 lr 0.000423	time 0.6733 (0.6063)	loss 4.6063 (4.3943)	grad_norm 2.3948 (inf)	mem 8929MB
[2022-04-05 07:04:53 large] (main.py 226): INFO Train: [16/300][2400/2502]	eta 0:01:01 lr 0.000424	time 0.5646 (0.6059)	loss 4.8409 (4.3935)	grad_norm 3.9706 (inf)	mem 8929MB
[2022-04-05 07:05:53 large] (main.py 226): INFO Train: [16/300][2500/2502]	eta 0:00:01 lr 0.000425	time 0.6137 (0.6055)	loss 4.3504 (4.3943)	grad_norm 3.4593 (inf)	mem 8929MB
[2022-04-05 07:05:54 large] (main.py 233): INFO EPOCH 16 training takes 0:25:15
[2022-04-05 07:06:01 large] (main.py 273): INFO Test: [0/98]	Time 6.346 (6.346)	Loss 1.7717 (1.7717)	Acc@1 61.719 (61.719)	Acc@5 84.375 (84.375)	Mem 8929MB
[2022-04-05 07:06:26 large] (main.py 279): INFO  * Acc@1 60.610 Acc@5 83.948
[2022-04-05 07:06:26 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 60.6%
[2022-04-05 07:06:26 large] (utils.py 57): INFO output/large/default/ckpt_epoch_16.pth saving......
[2022-04-05 07:06:27 large] (utils.py 59): INFO output/large/default/ckpt_epoch_16.pth saved !!!
[2022-04-05 07:06:27 large] (main.py 148): INFO Max accuracy: 60.61%
[2022-04-05 07:06:35 large] (main.py 226): INFO Train: [17/300][0/2502]	eta 5:37:48 lr 0.000425	time 8.1011 (8.1011)	loss 4.6909 (4.6909)	grad_norm 3.2374 (3.2374)	mem 8929MB
[2022-04-05 07:07:28 large] (main.py 226): INFO Train: [17/300][100/2502]	eta 0:24:15 lr 0.000426	time 0.6079 (0.6058)	loss 4.8545 (4.2735)	grad_norm 2.1074 (2.6680)	mem 8929MB
[2022-04-05 07:08:29 large] (main.py 226): INFO Train: [17/300][200/2502]	eta 0:23:12 lr 0.000427	time 0.6668 (0.6050)	loss 4.8358 (4.3266)	grad_norm 5.9783 (2.6778)	mem 8929MB
[2022-04-05 07:09:30 large] (main.py 226): INFO Train: [17/300][300/2502]	eta 0:22:13 lr 0.000428	time 0.6587 (0.6057)	loss 4.6056 (4.3378)	grad_norm 3.6368 (2.6810)	mem 8929MB
[2022-04-05 07:10:30 large] (main.py 226): INFO Train: [17/300][400/2502]	eta 0:21:14 lr 0.000429	time 0.5896 (0.6063)	loss 3.7457 (4.3333)	grad_norm 2.8347 (2.7276)	mem 8929MB
[2022-04-05 07:11:30 large] (main.py 226): INFO Train: [17/300][500/2502]	eta 0:20:10 lr 0.000430	time 0.5563 (0.6049)	loss 4.3919 (4.3245)	grad_norm 2.6015 (2.7415)	mem 8929MB
[2022-04-05 07:12:31 large] (main.py 226): INFO Train: [17/300][600/2502]	eta 0:19:11 lr 0.000431	time 0.6593 (0.6052)	loss 3.4482 (4.3386)	grad_norm 3.0597 (2.7121)	mem 8929MB
[2022-04-05 07:13:26 large] (main.py 226): INFO Train: [17/300][700/2502]	eta 0:17:55 lr 0.000432	time 0.5053 (0.5968)	loss 4.7287 (4.3521)	grad_norm 2.3011 (2.7066)	mem 8929MB
[2022-04-05 07:14:25 large] (main.py 226): INFO Train: [17/300][800/2502]	eta 0:16:54 lr 0.000433	time 0.6050 (0.5962)	loss 4.2861 (4.3634)	grad_norm 2.7759 (2.7111)	mem 8929MB
[2022-04-05 07:15:20 large] (main.py 226): INFO Train: [17/300][900/2502]	eta 0:15:46 lr 0.000434	time 0.4895 (0.5910)	loss 4.8047 (4.3735)	grad_norm 3.3291 (2.7087)	mem 8929MB
[2022-04-05 07:16:10 large] (main.py 226): INFO Train: [17/300][1000/2502]	eta 0:14:34 lr 0.000435	time 0.5997 (0.5825)	loss 4.8123 (4.3697)	grad_norm 2.2652 (2.7096)	mem 8929MB
[2022-04-05 07:17:09 large] (main.py 226): INFO Train: [17/300][1100/2502]	eta 0:13:37 lr 0.000436	time 0.7053 (0.5831)	loss 3.9179 (4.3656)	grad_norm 3.7784 (2.7106)	mem 8929MB
[2022-04-05 07:18:09 large] (main.py 226): INFO Train: [17/300][1200/2502]	eta 0:12:40 lr 0.000437	time 0.6174 (0.5843)	loss 5.5162 (4.3668)	grad_norm 2.0410 (2.7151)	mem 8929MB
[2022-04-05 07:19:09 large] (main.py 226): INFO Train: [17/300][1300/2502]	eta 0:11:43 lr 0.000438	time 0.6000 (0.5857)	loss 3.7390 (4.3654)	grad_norm 2.0556 (2.7042)	mem 8929MB
[2022-04-05 07:20:10 large] (main.py 226): INFO Train: [17/300][1400/2502]	eta 0:10:46 lr 0.000439	time 0.5939 (0.5870)	loss 4.5859 (4.3659)	grad_norm 2.7520 (2.7016)	mem 8929MB
[2022-04-05 07:21:10 large] (main.py 226): INFO Train: [17/300][1500/2502]	eta 0:09:49 lr 0.000440	time 1.3699 (0.5879)	loss 4.8936 (4.3656)	grad_norm 2.9665 (2.7018)	mem 8929MB
[2022-04-05 07:22:10 large] (main.py 226): INFO Train: [17/300][1600/2502]	eta 0:08:50 lr 0.000441	time 0.6570 (0.5886)	loss 4.6116 (4.3695)	grad_norm 2.3655 (2.6983)	mem 8929MB
[2022-04-05 07:23:08 large] (main.py 226): INFO Train: [17/300][1700/2502]	eta 0:07:51 lr 0.000442	time 0.5326 (0.5885)	loss 4.8512 (4.3743)	grad_norm 2.6394 (2.7029)	mem 8929MB
[2022-04-05 07:24:08 large] (main.py 226): INFO Train: [17/300][1800/2502]	eta 0:06:53 lr 0.000443	time 0.6865 (0.5889)	loss 4.1800 (4.3757)	grad_norm 2.3600 (2.7066)	mem 8929MB
[2022-04-05 07:25:07 large] (main.py 226): INFO Train: [17/300][1900/2502]	eta 0:05:54 lr 0.000444	time 0.5863 (0.5890)	loss 3.7982 (4.3754)	grad_norm 3.1584 (2.7028)	mem 8929MB
[2022-04-05 07:26:08 large] (main.py 226): INFO Train: [17/300][2000/2502]	eta 0:04:56 lr 0.000445	time 0.5809 (0.5899)	loss 4.6251 (4.3690)	grad_norm 2.7426 (2.7057)	mem 8929MB
[2022-04-05 07:27:08 large] (main.py 226): INFO Train: [17/300][2100/2502]	eta 0:03:57 lr 0.000446	time 0.6314 (0.5903)	loss 4.7331 (4.3687)	grad_norm 2.7794 (2.7012)	mem 8929MB
[2022-04-05 07:28:02 large] (main.py 226): INFO Train: [17/300][2200/2502]	eta 0:02:57 lr 0.000447	time 0.5332 (0.5882)	loss 4.1617 (4.3713)	grad_norm 2.6078 (2.6998)	mem 8929MB
[2022-04-05 07:29:02 large] (main.py 226): INFO Train: [17/300][2300/2502]	eta 0:01:58 lr 0.000448	time 0.6195 (0.5888)	loss 4.8663 (4.3704)	grad_norm 2.5117 (2.6944)	mem 8929MB
[2022-04-05 07:30:01 large] (main.py 226): INFO Train: [17/300][2400/2502]	eta 0:01:00 lr 0.000449	time 0.6980 (0.5887)	loss 4.7830 (4.3662)	grad_norm 3.8888 (2.6939)	mem 8929MB
[2022-04-05 07:30:58 large] (main.py 226): INFO Train: [17/300][2500/2502]	eta 0:00:01 lr 0.000450	time 0.5960 (0.5880)	loss 5.1745 (4.3683)	grad_norm 2.9618 (inf)	mem 8929MB
[2022-04-05 07:30:59 large] (main.py 233): INFO EPOCH 17 training takes 0:24:31
[2022-04-05 07:31:04 large] (main.py 273): INFO Test: [0/98]	Time 5.260 (5.260)	Loss 1.8358 (1.8358)	Acc@1 60.156 (60.156)	Acc@5 83.789 (83.789)	Mem 8929MB
[2022-04-05 07:31:31 large] (main.py 279): INFO  * Acc@1 61.524 Acc@5 84.666
[2022-04-05 07:31:31 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 61.5%
[2022-04-05 07:31:31 large] (utils.py 57): INFO output/large/default/ckpt_epoch_17.pth saving......
[2022-04-05 07:31:32 large] (utils.py 59): INFO output/large/default/ckpt_epoch_17.pth saved !!!
[2022-04-05 07:31:32 large] (main.py 148): INFO Max accuracy: 61.52%
[2022-04-05 07:31:40 large] (main.py 226): INFO Train: [18/300][0/2502]	eta 5:50:35 lr 0.000450	time 8.4073 (8.4073)	loss 4.8778 (4.8778)	grad_norm 2.4467 (2.4467)	mem 8929MB
[2022-04-05 07:32:33 large] (main.py 226): INFO Train: [18/300][100/2502]	eta 0:24:25 lr 0.000451	time 0.6759 (0.6103)	loss 4.6182 (4.3966)	grad_norm 2.9769 (2.7461)	mem 8929MB
[2022-04-05 07:33:33 large] (main.py 226): INFO Train: [18/300][200/2502]	eta 0:23:04 lr 0.000452	time 0.4871 (0.6015)	loss 4.9615 (4.3663)	grad_norm 2.2584 (2.6507)	mem 8929MB
[2022-04-05 07:34:33 large] (main.py 226): INFO Train: [18/300][300/2502]	eta 0:22:03 lr 0.000453	time 0.5990 (0.6010)	loss 4.8060 (4.3648)	grad_norm 2.2941 (2.6719)	mem 8929MB
[2022-04-05 07:35:33 large] (main.py 226): INFO Train: [18/300][400/2502]	eta 0:21:04 lr 0.000454	time 0.5415 (0.6015)	loss 4.8287 (4.3487)	grad_norm 2.8024 (2.6817)	mem 8929MB
[2022-04-05 07:36:34 large] (main.py 226): INFO Train: [18/300][500/2502]	eta 0:20:05 lr 0.000455	time 0.6509 (0.6024)	loss 3.9474 (4.3229)	grad_norm 2.7841 (2.6639)	mem 8929MB
[2022-04-05 07:37:34 large] (main.py 226): INFO Train: [18/300][600/2502]	eta 0:19:05 lr 0.000456	time 0.5621 (0.6021)	loss 4.7782 (4.3153)	grad_norm 2.3577 (2.6432)	mem 8929MB
[2022-04-05 07:38:33 large] (main.py 226): INFO Train: [18/300][700/2502]	eta 0:18:03 lr 0.000457	time 0.6166 (0.6015)	loss 4.3798 (4.3204)	grad_norm 2.9017 (2.6568)	mem 8929MB
[2022-04-05 07:39:33 large] (main.py 226): INFO Train: [18/300][800/2502]	eta 0:17:02 lr 0.000458	time 0.5262 (0.6010)	loss 3.5081 (4.3126)	grad_norm 3.0338 (2.6547)	mem 8929MB
[2022-04-05 07:40:32 large] (main.py 226): INFO Train: [18/300][900/2502]	eta 0:16:00 lr 0.000459	time 0.4468 (0.5996)	loss 3.9068 (4.3044)	grad_norm 3.1498 (2.6371)	mem 8929MB
[2022-04-05 07:41:23 large] (main.py 226): INFO Train: [18/300][1000/2502]	eta 0:14:46 lr 0.000460	time 0.6601 (0.5904)	loss 3.2484 (4.3105)	grad_norm 2.8243 (2.6355)	mem 8929MB
[2022-04-05 07:42:22 large] (main.py 226): INFO Train: [18/300][1100/2502]	eta 0:13:47 lr 0.000461	time 0.5247 (0.5905)	loss 4.3579 (4.3112)	grad_norm 2.2864 (2.6320)	mem 8929MB
[2022-04-05 07:43:22 large] (main.py 226): INFO Train: [18/300][1200/2502]	eta 0:12:50 lr 0.000462	time 0.6209 (0.5917)	loss 4.6394 (4.3215)	grad_norm 2.5821 (2.6433)	mem 8929MB
[2022-04-05 07:44:23 large] (main.py 226): INFO Train: [18/300][1300/2502]	eta 0:11:52 lr 0.000463	time 0.5519 (0.5926)	loss 4.4568 (4.3263)	grad_norm 2.0670 (2.6364)	mem 8929MB
[2022-04-05 07:45:23 large] (main.py 226): INFO Train: [18/300][1400/2502]	eta 0:10:53 lr 0.000464	time 0.5768 (0.5931)	loss 3.7003 (4.3259)	grad_norm 1.9674 (2.6337)	mem 8929MB
[2022-04-05 07:46:23 large] (main.py 226): INFO Train: [18/300][1500/2502]	eta 0:09:54 lr 0.000465	time 0.6223 (0.5935)	loss 4.7299 (4.3225)	grad_norm 3.7863 (2.6299)	mem 8929MB
[2022-04-05 07:47:22 large] (main.py 226): INFO Train: [18/300][1600/2502]	eta 0:08:55 lr 0.000466	time 0.5971 (0.5934)	loss 4.6037 (4.3216)	grad_norm 2.2041 (2.6257)	mem 8929MB
[2022-04-05 07:48:22 large] (main.py 226): INFO Train: [18/300][1700/2502]	eta 0:07:56 lr 0.000467	time 0.6328 (0.5937)	loss 4.9777 (4.3187)	grad_norm 3.8218 (2.6230)	mem 8929MB
[2022-04-05 07:49:22 large] (main.py 226): INFO Train: [18/300][1800/2502]	eta 0:06:57 lr 0.000468	time 0.6123 (0.5944)	loss 5.1563 (4.3237)	grad_norm 2.4347 (2.6224)	mem 8929MB
[2022-04-05 07:50:21 large] (main.py 226): INFO Train: [18/300][1900/2502]	eta 0:05:57 lr 0.000469	time 0.6550 (0.5942)	loss 4.8923 (4.3240)	grad_norm 2.5067 (2.6318)	mem 8929MB
[2022-04-05 07:51:20 large] (main.py 226): INFO Train: [18/300][2000/2502]	eta 0:04:58 lr 0.000470	time 0.5145 (0.5940)	loss 4.8158 (4.3311)	grad_norm 2.6749 (2.6323)	mem 8929MB
[2022-04-05 07:52:20 large] (main.py 226): INFO Train: [18/300][2100/2502]	eta 0:03:58 lr 0.000471	time 0.6049 (0.5939)	loss 4.6077 (4.3287)	grad_norm 2.7843 (2.6285)	mem 8929MB
[2022-04-05 07:53:19 large] (main.py 226): INFO Train: [18/300][2200/2502]	eta 0:02:59 lr 0.000472	time 0.5588 (0.5940)	loss 4.8959 (4.3303)	grad_norm 2.7956 (2.6317)	mem 8929MB
[2022-04-05 07:54:19 large] (main.py 226): INFO Train: [18/300][2300/2502]	eta 0:02:00 lr 0.000473	time 0.7024 (0.5943)	loss 4.6651 (4.3300)	grad_norm 1.9783 (2.6325)	mem 8929MB
[2022-04-05 07:55:19 large] (main.py 226): INFO Train: [18/300][2400/2502]	eta 0:01:00 lr 0.000474	time 0.6931 (0.5945)	loss 4.8666 (4.3337)	grad_norm 2.1813 (2.6264)	mem 8929MB
[2022-04-05 07:56:18 large] (main.py 226): INFO Train: [18/300][2500/2502]	eta 0:00:01 lr 0.000475	time 0.5131 (0.5943)	loss 4.9011 (4.3339)	grad_norm 2.0832 (2.6271)	mem 8929MB
[2022-04-05 07:56:19 large] (main.py 233): INFO EPOCH 18 training takes 0:24:47
[2022-04-05 07:56:26 large] (main.py 273): INFO Test: [0/98]	Time 6.320 (6.320)	Loss 1.7289 (1.7289)	Acc@1 62.695 (62.695)	Acc@5 84.375 (84.375)	Mem 8929MB
[2022-04-05 07:56:51 large] (main.py 279): INFO  * Acc@1 61.824 Acc@5 84.724
[2022-04-05 07:56:51 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 61.8%
[2022-04-05 07:56:51 large] (utils.py 57): INFO output/large/default/ckpt_epoch_18.pth saving......
[2022-04-05 07:56:52 large] (utils.py 59): INFO output/large/default/ckpt_epoch_18.pth saved !!!
[2022-04-05 07:56:52 large] (main.py 148): INFO Max accuracy: 61.82%
[2022-04-05 07:57:01 large] (main.py 226): INFO Train: [19/300][0/2502]	eta 5:46:43 lr 0.000475	time 8.3147 (8.3147)	loss 4.5536 (4.5536)	grad_norm 3.1860 (3.1860)	mem 8929MB
[2022-04-05 07:57:53 large] (main.py 226): INFO Train: [19/300][100/2502]	eta 0:24:02 lr 0.000476	time 0.6121 (0.6005)	loss 3.3257 (4.3013)	grad_norm 3.1127 (2.5874)	mem 8929MB
[2022-04-05 07:58:54 large] (main.py 226): INFO Train: [19/300][200/2502]	eta 0:23:09 lr 0.000477	time 0.6801 (0.6035)	loss 4.5571 (4.3270)	grad_norm 2.5540 (2.6296)	mem 8929MB
[2022-04-05 07:59:54 large] (main.py 226): INFO Train: [19/300][300/2502]	eta 0:22:11 lr 0.000478	time 0.5250 (0.6047)	loss 4.4866 (4.3567)	grad_norm 4.4083 (2.6178)	mem 8929MB
[2022-04-05 08:00:55 large] (main.py 226): INFO Train: [19/300][400/2502]	eta 0:21:10 lr 0.000479	time 0.5277 (0.6046)	loss 5.2789 (4.3583)	grad_norm 2.8434 (inf)	mem 8929MB
[2022-04-05 08:01:54 large] (main.py 226): INFO Train: [19/300][500/2502]	eta 0:20:06 lr 0.000480	time 0.5276 (0.6026)	loss 4.7170 (4.3576)	grad_norm 2.1733 (inf)	mem 8929MB
[2022-04-05 08:02:54 large] (main.py 226): INFO Train: [19/300][600/2502]	eta 0:19:05 lr 0.000481	time 0.6211 (0.6025)	loss 5.0460 (4.3374)	grad_norm 2.0345 (inf)	mem 8929MB
[2022-04-05 08:03:53 large] (main.py 226): INFO Train: [19/300][700/2502]	eta 0:18:02 lr 0.000482	time 0.6085 (0.6009)	loss 5.1401 (4.3415)	grad_norm 1.9483 (inf)	mem 8929MB
[2022-04-05 08:04:53 large] (main.py 226): INFO Train: [19/300][800/2502]	eta 0:17:00 lr 0.000483	time 0.6200 (0.5998)	loss 4.2642 (4.3327)	grad_norm 2.7695 (inf)	mem 8929MB
[2022-04-05 08:05:52 large] (main.py 226): INFO Train: [19/300][900/2502]	eta 0:16:00 lr 0.000484	time 0.5455 (0.5993)	loss 4.1494 (4.3398)	grad_norm 1.9919 (inf)	mem 8929MB
[2022-04-05 08:06:52 large] (main.py 226): INFO Train: [19/300][1000/2502]	eta 0:14:59 lr 0.000485	time 0.5810 (0.5988)	loss 5.2465 (4.3396)	grad_norm 3.2188 (inf)	mem 8929MB
[2022-04-05 08:07:51 large] (main.py 226): INFO Train: [19/300][1100/2502]	eta 0:13:58 lr 0.000486	time 0.4959 (0.5983)	loss 3.0850 (4.3327)	grad_norm 3.3817 (inf)	mem 8929MB
[2022-04-05 08:08:45 large] (main.py 226): INFO Train: [19/300][1200/2502]	eta 0:12:52 lr 0.000487	time 0.6086 (0.5933)	loss 3.6696 (4.3273)	grad_norm 2.6073 (inf)	mem 8929MB
[2022-04-05 08:09:43 large] (main.py 226): INFO Train: [19/300][1300/2502]	eta 0:11:51 lr 0.000488	time 0.5355 (0.5922)	loss 5.0859 (4.3256)	grad_norm 2.4010 (inf)	mem 8929MB
[2022-04-05 08:10:42 large] (main.py 226): INFO Train: [19/300][1400/2502]	eta 0:10:52 lr 0.000489	time 0.5913 (0.5925)	loss 4.8395 (4.3291)	grad_norm 4.1105 (inf)	mem 8929MB
[2022-04-05 08:11:42 large] (main.py 226): INFO Train: [19/300][1500/2502]	eta 0:09:53 lr 0.000490	time 0.6929 (0.5927)	loss 3.6310 (4.3299)	grad_norm 2.3509 (inf)	mem 8929MB
[2022-04-05 08:12:42 large] (main.py 226): INFO Train: [19/300][1600/2502]	eta 0:08:55 lr 0.000491	time 0.6118 (0.5936)	loss 4.7036 (4.3283)	grad_norm 2.4756 (inf)	mem 8929MB
[2022-04-05 08:13:42 large] (main.py 226): INFO Train: [19/300][1700/2502]	eta 0:07:56 lr 0.000492	time 0.6075 (0.5939)	loss 4.5717 (4.3302)	grad_norm 2.4518 (inf)	mem 8929MB
[2022-04-05 08:14:42 large] (main.py 226): INFO Train: [19/300][1800/2502]	eta 0:06:57 lr 0.000493	time 0.5327 (0.5942)	loss 4.1506 (4.3293)	grad_norm 3.1093 (inf)	mem 8929MB
[2022-04-05 08:15:43 large] (main.py 226): INFO Train: [19/300][1900/2502]	eta 0:05:58 lr 0.000494	time 0.5226 (0.5947)	loss 4.1429 (4.3351)	grad_norm 2.4366 (inf)	mem 8929MB
[2022-04-05 08:16:43 large] (main.py 226): INFO Train: [19/300][2000/2502]	eta 0:04:58 lr 0.000495	time 0.6216 (0.5950)	loss 3.2255 (4.3309)	grad_norm 2.0462 (inf)	mem 8929MB
[2022-04-05 08:17:42 large] (main.py 226): INFO Train: [19/300][2100/2502]	eta 0:03:59 lr 0.000496	time 0.6124 (0.5949)	loss 3.4599 (4.3260)	grad_norm 2.7511 (inf)	mem 8929MB
[2022-04-05 08:18:42 large] (main.py 226): INFO Train: [19/300][2200/2502]	eta 0:02:59 lr 0.000497	time 0.5259 (0.5952)	loss 5.1359 (4.3234)	grad_norm 2.4587 (inf)	mem 8929MB
[2022-04-05 08:19:41 large] (main.py 226): INFO Train: [19/300][2300/2502]	eta 0:02:00 lr 0.000498	time 0.5176 (0.5950)	loss 4.1928 (4.3224)	grad_norm 2.6559 (inf)	mem 8929MB
[2022-04-05 08:20:42 large] (main.py 226): INFO Train: [19/300][2400/2502]	eta 0:01:00 lr 0.000499	time 0.5977 (0.5956)	loss 5.2521 (4.3249)	grad_norm 2.6736 (inf)	mem 8931MB
[2022-04-05 08:21:42 large] (main.py 226): INFO Train: [19/300][2500/2502]	eta 0:00:01 lr 0.000500	time 0.5343 (0.5955)	loss 3.6537 (4.3228)	grad_norm 2.7502 (inf)	mem 8931MB
[2022-04-05 08:21:43 large] (main.py 233): INFO EPOCH 19 training takes 0:24:50
[2022-04-05 08:21:49 large] (main.py 273): INFO Test: [0/98]	Time 6.446 (6.446)	Loss 1.6752 (1.6752)	Acc@1 62.891 (62.891)	Acc@5 86.719 (86.719)	Mem 8931MB
[2022-04-05 08:22:16 large] (main.py 279): INFO  * Acc@1 62.588 Acc@5 85.246
[2022-04-05 08:22:16 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 62.6%
[2022-04-05 08:22:16 large] (utils.py 57): INFO output/large/default/ckpt_epoch_19.pth saving......
[2022-04-05 08:22:16 large] (utils.py 59): INFO output/large/default/ckpt_epoch_19.pth saved !!!
[2022-04-05 08:22:16 large] (main.py 148): INFO Max accuracy: 62.59%
[2022-04-05 08:22:24 large] (main.py 226): INFO Train: [20/300][0/2502]	eta 5:24:47 lr 0.000495	time 7.7889 (7.7889)	loss 3.2650 (3.2650)	grad_norm 3.1529 (3.1529)	mem 8931MB
[2022-04-05 08:23:21 large] (main.py 226): INFO Train: [20/300][100/2502]	eta 0:25:47 lr 0.000495	time 0.5479 (0.6444)	loss 4.5514 (4.2342)	grad_norm 1.9560 (2.4485)	mem 8931MB
[2022-04-05 08:24:22 large] (main.py 226): INFO Train: [20/300][200/2502]	eta 0:23:58 lr 0.000495	time 0.6432 (0.6247)	loss 4.2065 (4.2601)	grad_norm 2.1220 (2.4985)	mem 8931MB
[2022-04-05 08:25:23 large] (main.py 226): INFO Train: [20/300][300/2502]	eta 0:22:44 lr 0.000495	time 0.5715 (0.6198)	loss 4.4951 (4.2619)	grad_norm 2.7378 (2.5040)	mem 8931MB
[2022-04-05 08:26:24 large] (main.py 226): INFO Train: [20/300][400/2502]	eta 0:21:39 lr 0.000495	time 0.6927 (0.6182)	loss 5.2465 (4.3055)	grad_norm 4.5597 (2.5163)	mem 8931MB
[2022-04-05 08:27:25 large] (main.py 226): INFO Train: [20/300][500/2502]	eta 0:20:32 lr 0.000494	time 0.5526 (0.6154)	loss 5.1630 (4.3120)	grad_norm 2.9856 (2.5116)	mem 8931MB
[2022-04-05 08:28:25 large] (main.py 226): INFO Train: [20/300][600/2502]	eta 0:19:27 lr 0.000494	time 0.6982 (0.6138)	loss 4.4412 (4.3001)	grad_norm 3.8309 (2.4845)	mem 8931MB
[2022-04-05 08:29:26 large] (main.py 226): INFO Train: [20/300][700/2502]	eta 0:18:23 lr 0.000494	time 0.6887 (0.6122)	loss 4.2016 (4.3115)	grad_norm 2.2818 (2.5095)	mem 8931MB
[2022-04-05 08:30:24 large] (main.py 226): INFO Train: [20/300][800/2502]	eta 0:17:16 lr 0.000494	time 0.5810 (0.6088)	loss 3.5259 (4.2933)	grad_norm 1.7492 (2.5018)	mem 8931MB
[2022-04-05 08:31:24 large] (main.py 226): INFO Train: [20/300][900/2502]	eta 0:16:13 lr 0.000494	time 0.5369 (0.6077)	loss 4.5652 (4.3066)	grad_norm 2.0893 (2.4957)	mem 8931MB
[2022-04-05 08:32:24 large] (main.py 226): INFO Train: [20/300][1000/2502]	eta 0:15:11 lr 0.000494	time 0.6205 (0.6067)	loss 4.1508 (4.3044)	grad_norm 2.1301 (2.5089)	mem 8931MB
[2022-04-05 08:33:22 large] (main.py 226): INFO Train: [20/300][1100/2502]	eta 0:14:07 lr 0.000494	time 0.6101 (0.6047)	loss 4.3657 (4.2968)	grad_norm 2.3316 (2.4994)	mem 8931MB
[2022-04-05 08:34:21 large] (main.py 226): INFO Train: [20/300][1200/2502]	eta 0:13:05 lr 0.000494	time 0.6421 (0.6036)	loss 4.7193 (4.2846)	grad_norm 2.8009 (2.4955)	mem 8931MB
[2022-04-05 08:35:22 large] (main.py 226): INFO Train: [20/300][1300/2502]	eta 0:12:05 lr 0.000494	time 0.6762 (0.6039)	loss 4.1469 (4.2785)	grad_norm 2.6415 (2.4864)	mem 8931MB
[2022-04-05 08:36:22 large] (main.py 226): INFO Train: [20/300][1400/2502]	eta 0:11:04 lr 0.000494	time 0.6884 (0.6033)	loss 4.2488 (4.2836)	grad_norm 2.2721 (2.4856)	mem 8931MB
[2022-04-05 08:37:21 large] (main.py 226): INFO Train: [20/300][1500/2502]	eta 0:10:04 lr 0.000494	time 0.7600 (0.6030)	loss 3.8893 (4.2825)	grad_norm 2.7860 (2.4874)	mem 8931MB
[2022-04-05 08:38:21 large] (main.py 226): INFO Train: [20/300][1600/2502]	eta 0:09:03 lr 0.000494	time 0.5744 (0.6023)	loss 5.2214 (4.2842)	grad_norm 2.5784 (2.4868)	mem 8931MB
[2022-04-05 08:39:20 large] (main.py 226): INFO Train: [20/300][1700/2502]	eta 0:08:02 lr 0.000494	time 0.5653 (0.6017)	loss 4.7746 (4.2804)	grad_norm 2.2057 (2.4901)	mem 8931MB
[2022-04-05 08:40:20 large] (main.py 226): INFO Train: [20/300][1800/2502]	eta 0:07:02 lr 0.000494	time 0.6556 (0.6017)	loss 4.3603 (4.2757)	grad_norm 2.5115 (2.4957)	mem 8931MB
[2022-04-05 08:41:20 large] (main.py 226): INFO Train: [20/300][1900/2502]	eta 0:06:02 lr 0.000494	time 0.5850 (0.6016)	loss 4.4291 (4.2781)	grad_norm 2.8597 (2.5032)	mem 8931MB
[2022-04-05 08:42:21 large] (main.py 226): INFO Train: [20/300][2000/2502]	eta 0:05:02 lr 0.000494	time 0.6280 (0.6018)	loss 4.5800 (4.2762)	grad_norm 2.5483 (inf)	mem 8931MB
[2022-04-05 08:43:21 large] (main.py 226): INFO Train: [20/300][2100/2502]	eta 0:04:01 lr 0.000494	time 0.5804 (0.6019)	loss 4.3260 (4.2788)	grad_norm 2.5890 (inf)	mem 8931MB
[2022-04-05 08:44:21 large] (main.py 226): INFO Train: [20/300][2200/2502]	eta 0:03:01 lr 0.000494	time 0.5853 (0.6019)	loss 3.6184 (4.2810)	grad_norm 2.6554 (inf)	mem 8931MB
[2022-04-05 08:45:17 large] (main.py 226): INFO Train: [20/300][2300/2502]	eta 0:02:01 lr 0.000494	time 0.5020 (0.5999)	loss 4.3471 (4.2812)	grad_norm 2.6645 (inf)	mem 8931MB
[2022-04-05 08:46:14 large] (main.py 226): INFO Train: [20/300][2400/2502]	eta 0:01:01 lr 0.000494	time 0.5742 (0.5988)	loss 3.9228 (4.2809)	grad_norm 2.3687 (inf)	mem 8931MB
[2022-04-05 08:47:14 large] (main.py 226): INFO Train: [20/300][2500/2502]	eta 0:00:01 lr 0.000494	time 0.5747 (0.5988)	loss 4.6057 (4.2810)	grad_norm 2.7633 (inf)	mem 8931MB
[2022-04-05 08:47:15 large] (main.py 233): INFO EPOCH 20 training takes 0:24:58
[2022-04-05 08:47:21 large] (main.py 273): INFO Test: [0/98]	Time 5.865 (5.865)	Loss 1.7181 (1.7181)	Acc@1 64.258 (64.258)	Acc@5 84.180 (84.180)	Mem 8931MB
[2022-04-05 08:47:48 large] (main.py 279): INFO  * Acc@1 63.674 Acc@5 85.904
[2022-04-05 08:47:48 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 63.7%
[2022-04-05 08:47:48 large] (utils.py 57): INFO output/large/default/ckpt_epoch_20.pth saving......
[2022-04-05 08:47:48 large] (utils.py 59): INFO output/large/default/ckpt_epoch_20.pth saved !!!
[2022-04-05 08:47:48 large] (main.py 148): INFO Max accuracy: 63.67%
[2022-04-05 08:47:56 large] (main.py 226): INFO Train: [21/300][0/2502]	eta 5:17:23 lr 0.000494	time 7.6112 (7.6112)	loss 4.3373 (4.3373)	grad_norm 1.6493 (1.6493)	mem 8931MB
[2022-04-05 08:48:52 large] (main.py 226): INFO Train: [21/300][100/2502]	eta 0:25:19 lr 0.000494	time 0.6093 (0.6326)	loss 5.0460 (4.3234)	grad_norm 2.2641 (2.3236)	mem 8931MB
[2022-04-05 08:49:53 large] (main.py 226): INFO Train: [21/300][200/2502]	eta 0:23:41 lr 0.000494	time 0.6253 (0.6176)	loss 3.2514 (4.2358)	grad_norm 3.1107 (2.3854)	mem 8931MB
[2022-04-05 08:50:53 large] (main.py 226): INFO Train: [21/300][300/2502]	eta 0:22:33 lr 0.000494	time 0.7573 (0.6147)	loss 4.3303 (4.2112)	grad_norm 3.1098 (2.4342)	mem 8931MB
[2022-04-05 08:51:55 large] (main.py 226): INFO Train: [21/300][400/2502]	eta 0:21:30 lr 0.000494	time 0.5359 (0.6138)	loss 4.2475 (4.2092)	grad_norm 1.9279 (2.4384)	mem 8931MB
[2022-04-05 08:52:56 large] (main.py 226): INFO Train: [21/300][500/2502]	eta 0:20:29 lr 0.000494	time 0.6500 (0.6140)	loss 4.0779 (4.2104)	grad_norm 1.7160 (2.4242)	mem 8931MB
[2022-04-05 08:53:56 large] (main.py 226): INFO Train: [21/300][600/2502]	eta 0:19:23 lr 0.000494	time 0.5380 (0.6118)	loss 3.7897 (4.2114)	grad_norm 2.4147 (2.4519)	mem 8931MB
[2022-04-05 08:54:57 large] (main.py 226): INFO Train: [21/300][700/2502]	eta 0:18:20 lr 0.000494	time 0.6160 (0.6109)	loss 3.8907 (4.2013)	grad_norm 2.9701 (2.4519)	mem 8931MB
[2022-04-05 08:55:58 large] (main.py 226): INFO Train: [21/300][800/2502]	eta 0:17:19 lr 0.000494	time 0.7363 (0.6108)	loss 3.8757 (4.1959)	grad_norm 1.9672 (2.4514)	mem 8931MB
[2022-04-05 08:56:57 large] (main.py 226): INFO Train: [21/300][900/2502]	eta 0:16:15 lr 0.000494	time 0.6375 (0.6092)	loss 5.1120 (4.1935)	grad_norm 2.8715 (2.4520)	mem 8931MB
[2022-04-05 08:57:58 large] (main.py 226): INFO Train: [21/300][1000/2502]	eta 0:15:14 lr 0.000494	time 0.6143 (0.6090)	loss 3.3377 (4.1976)	grad_norm 1.9319 (2.4446)	mem 8931MB
[2022-04-05 08:58:59 large] (main.py 226): INFO Train: [21/300][1100/2502]	eta 0:14:13 lr 0.000494	time 0.6568 (0.6090)	loss 4.6388 (4.1989)	grad_norm 2.3527 (2.4524)	mem 8931MB
[2022-04-05 09:00:00 large] (main.py 226): INFO Train: [21/300][1200/2502]	eta 0:13:12 lr 0.000494	time 0.5370 (0.6089)	loss 4.7130 (4.2007)	grad_norm 2.4533 (2.4463)	mem 8931MB
[2022-04-05 09:01:01 large] (main.py 226): INFO Train: [21/300][1300/2502]	eta 0:12:12 lr 0.000494	time 0.6080 (0.6092)	loss 4.6107 (4.2027)	grad_norm 1.8902 (2.4485)	mem 8931MB
[2022-04-05 09:02:01 large] (main.py 226): INFO Train: [21/300][1400/2502]	eta 0:11:10 lr 0.000494	time 0.5954 (0.6086)	loss 4.6006 (4.2047)	grad_norm 1.7457 (2.4387)	mem 8931MB
[2022-04-05 09:03:03 large] (main.py 226): INFO Train: [21/300][1500/2502]	eta 0:10:10 lr 0.000494	time 0.5917 (0.6094)	loss 4.7241 (4.2019)	grad_norm 2.5231 (2.4498)	mem 8931MB
[2022-04-05 09:04:04 large] (main.py 226): INFO Train: [21/300][1600/2502]	eta 0:09:09 lr 0.000494	time 0.5152 (0.6091)	loss 3.8622 (4.2017)	grad_norm 1.7504 (2.4515)	mem 8931MB
[2022-04-05 09:05:03 large] (main.py 226): INFO Train: [21/300][1700/2502]	eta 0:08:08 lr 0.000494	time 0.5895 (0.6085)	loss 4.6215 (4.2036)	grad_norm 3.0470 (2.4558)	mem 8931MB
[2022-04-05 09:06:04 large] (main.py 226): INFO Train: [21/300][1800/2502]	eta 0:07:06 lr 0.000494	time 0.8118 (0.6081)	loss 3.5944 (4.2052)	grad_norm 3.4955 (2.4507)	mem 8931MB
[2022-04-05 09:07:06 large] (main.py 226): INFO Train: [21/300][1900/2502]	eta 0:06:06 lr 0.000494	time 0.5978 (0.6089)	loss 3.2674 (4.1989)	grad_norm 2.2954 (2.4490)	mem 8931MB
[2022-04-05 09:08:06 large] (main.py 226): INFO Train: [21/300][2000/2502]	eta 0:05:05 lr 0.000494	time 0.5006 (0.6085)	loss 4.3598 (4.1977)	grad_norm 2.3477 (2.4412)	mem 8931MB
[2022-04-05 09:09:06 large] (main.py 226): INFO Train: [21/300][2100/2502]	eta 0:04:04 lr 0.000494	time 0.5870 (0.6081)	loss 3.9039 (4.2034)	grad_norm 1.9511 (2.4396)	mem 8931MB
[2022-04-05 09:10:07 large] (main.py 226): INFO Train: [21/300][2200/2502]	eta 0:03:03 lr 0.000494	time 0.6190 (0.6081)	loss 4.5157 (4.1958)	grad_norm 2.2504 (inf)	mem 8931MB
[2022-04-05 09:11:08 large] (main.py 226): INFO Train: [21/300][2300/2502]	eta 0:02:02 lr 0.000494	time 0.5172 (0.6083)	loss 4.7975 (4.1943)	grad_norm 2.4756 (inf)	mem 8931MB
[2022-04-05 09:12:10 large] (main.py 226): INFO Train: [21/300][2400/2502]	eta 0:01:02 lr 0.000493	time 0.6068 (0.6086)	loss 4.1388 (4.1986)	grad_norm 2.4443 (inf)	mem 8931MB
[2022-04-05 09:13:09 large] (main.py 226): INFO Train: [21/300][2500/2502]	eta 0:00:01 lr 0.000493	time 0.6166 (0.6081)	loss 4.1527 (4.1959)	grad_norm 3.1111 (inf)	mem 8931MB
[2022-04-05 09:13:10 large] (main.py 233): INFO EPOCH 21 training takes 0:25:21
[2022-04-05 09:13:16 large] (main.py 273): INFO Test: [0/98]	Time 5.889 (5.889)	Loss 1.6035 (1.6035)	Acc@1 66.797 (66.797)	Acc@5 87.305 (87.305)	Mem 8931MB
[2022-04-05 09:13:42 large] (main.py 279): INFO  * Acc@1 64.896 Acc@5 86.610
[2022-04-05 09:13:42 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 64.9%
[2022-04-05 09:13:42 large] (utils.py 57): INFO output/large/default/ckpt_epoch_21.pth saving......
[2022-04-05 09:13:43 large] (utils.py 59): INFO output/large/default/ckpt_epoch_21.pth saved !!!
[2022-04-05 09:13:43 large] (main.py 148): INFO Max accuracy: 64.90%
[2022-04-05 09:13:51 large] (main.py 226): INFO Train: [22/300][0/2502]	eta 5:35:39 lr 0.000493	time 8.0493 (8.0493)	loss 3.9996 (3.9996)	grad_norm 1.8125 (1.8125)	mem 8931MB
[2022-04-05 09:14:46 large] (main.py 226): INFO Train: [22/300][100/2502]	eta 0:24:51 lr 0.000493	time 0.5616 (0.6210)	loss 4.0617 (4.2210)	grad_norm 5.5426 (2.3526)	mem 8931MB
[2022-04-05 09:15:48 large] (main.py 226): INFO Train: [22/300][200/2502]	eta 0:23:48 lr 0.000493	time 0.6379 (0.6207)	loss 3.1964 (4.1957)	grad_norm 2.1870 (2.3698)	mem 8931MB
[2022-04-05 09:16:49 large] (main.py 226): INFO Train: [22/300][300/2502]	eta 0:22:42 lr 0.000493	time 0.4715 (0.6189)	loss 4.5807 (4.1884)	grad_norm 2.1473 (2.3781)	mem 8931MB
[2022-04-05 09:17:51 large] (main.py 226): INFO Train: [22/300][400/2502]	eta 0:21:42 lr 0.000493	time 0.5827 (0.6196)	loss 4.0240 (4.1999)	grad_norm 2.3054 (2.3739)	mem 8931MB
[2022-04-05 09:18:53 large] (main.py 226): INFO Train: [22/300][500/2502]	eta 0:20:37 lr 0.000493	time 0.5966 (0.6182)	loss 3.3775 (4.1987)	grad_norm 3.1301 (2.3822)	mem 8931MB
[2022-04-05 09:19:52 large] (main.py 226): INFO Train: [22/300][600/2502]	eta 0:19:28 lr 0.000493	time 0.5759 (0.6144)	loss 4.4215 (4.2079)	grad_norm 2.3493 (2.4043)	mem 8931MB
[2022-04-05 09:20:53 large] (main.py 226): INFO Train: [22/300][700/2502]	eta 0:18:25 lr 0.000493	time 0.5909 (0.6135)	loss 2.8681 (4.1963)	grad_norm 2.8846 (2.4091)	mem 8931MB
[2022-04-05 09:21:54 large] (main.py 226): INFO Train: [22/300][800/2502]	eta 0:17:23 lr 0.000493	time 0.5582 (0.6132)	loss 3.9106 (4.1877)	grad_norm 2.1436 (2.4069)	mem 8931MB
[2022-04-05 09:22:55 large] (main.py 226): INFO Train: [22/300][900/2502]	eta 0:16:21 lr 0.000493	time 0.6469 (0.6127)	loss 3.9985 (4.1844)	grad_norm 2.4154 (2.4086)	mem 8931MB
[2022-04-05 09:23:57 large] (main.py 226): INFO Train: [22/300][1000/2502]	eta 0:15:21 lr 0.000493	time 0.5112 (0.6135)	loss 4.3874 (4.1910)	grad_norm 2.2874 (2.4105)	mem 8931MB
[2022-04-05 09:24:58 large] (main.py 226): INFO Train: [22/300][1100/2502]	eta 0:14:19 lr 0.000493	time 0.5621 (0.6129)	loss 4.5821 (4.1855)	grad_norm 2.0604 (2.4122)	mem 8931MB
[2022-04-05 09:25:59 large] (main.py 226): INFO Train: [22/300][1200/2502]	eta 0:13:17 lr 0.000493	time 0.6010 (0.6124)	loss 4.0534 (4.1851)	grad_norm 2.0465 (2.4136)	mem 8931MB
[2022-04-05 09:26:59 large] (main.py 226): INFO Train: [22/300][1300/2502]	eta 0:12:15 lr 0.000493	time 0.5512 (0.6116)	loss 3.3279 (4.1893)	grad_norm 3.6515 (2.4140)	mem 8931MB
[2022-04-05 09:27:59 large] (main.py 226): INFO Train: [22/300][1400/2502]	eta 0:11:13 lr 0.000493	time 0.8116 (0.6108)	loss 4.7747 (4.1943)	grad_norm 2.8385 (2.4122)	mem 8931MB
[2022-04-05 09:28:59 large] (main.py 226): INFO Train: [22/300][1500/2502]	eta 0:10:11 lr 0.000493	time 0.6496 (0.6104)	loss 4.3769 (4.1937)	grad_norm 1.9796 (2.4137)	mem 8931MB
[2022-04-05 09:29:59 large] (main.py 226): INFO Train: [22/300][1600/2502]	eta 0:09:09 lr 0.000493	time 0.6266 (0.6096)	loss 4.2696 (4.1939)	grad_norm 1.8037 (2.4064)	mem 8931MB
[2022-04-05 09:31:00 large] (main.py 226): INFO Train: [22/300][1700/2502]	eta 0:08:08 lr 0.000493	time 0.5500 (0.6096)	loss 4.0419 (4.1921)	grad_norm 1.9034 (2.4019)	mem 8931MB
[2022-04-05 09:32:00 large] (main.py 226): INFO Train: [22/300][1800/2502]	eta 0:07:07 lr 0.000493	time 0.6291 (0.6093)	loss 4.8365 (4.1927)	grad_norm 3.0465 (2.3997)	mem 8931MB
[2022-04-05 09:33:01 large] (main.py 226): INFO Train: [22/300][1900/2502]	eta 0:06:06 lr 0.000493	time 0.6196 (0.6089)	loss 4.5202 (4.1896)	grad_norm 2.7397 (inf)	mem 8931MB
[2022-04-05 09:34:02 large] (main.py 226): INFO Train: [22/300][2000/2502]	eta 0:05:05 lr 0.000493	time 0.5493 (0.6090)	loss 4.5205 (4.1853)	grad_norm 2.1853 (inf)	mem 8931MB
[2022-04-05 09:35:02 large] (main.py 226): INFO Train: [22/300][2100/2502]	eta 0:04:04 lr 0.000493	time 0.5121 (0.6089)	loss 4.2845 (4.1853)	grad_norm 2.9134 (inf)	mem 8931MB
[2022-04-05 09:36:03 large] (main.py 226): INFO Train: [22/300][2200/2502]	eta 0:03:03 lr 0.000493	time 0.6658 (0.6087)	loss 4.6708 (4.1801)	grad_norm 2.5741 (inf)	mem 8931MB
[2022-04-05 09:37:03 large] (main.py 226): INFO Train: [22/300][2300/2502]	eta 0:02:02 lr 0.000493	time 0.5616 (0.6086)	loss 4.0391 (4.1820)	grad_norm 2.1176 (inf)	mem 8931MB
[2022-04-05 09:38:03 large] (main.py 226): INFO Train: [22/300][2400/2502]	eta 0:01:02 lr 0.000493	time 0.7001 (0.6082)	loss 3.4828 (4.1798)	grad_norm 2.9259 (inf)	mem 8931MB
[2022-04-05 09:39:05 large] (main.py 226): INFO Train: [22/300][2500/2502]	eta 0:00:01 lr 0.000493	time 0.6128 (0.6085)	loss 2.8669 (4.1767)	grad_norm 2.9473 (inf)	mem 8931MB
[2022-04-05 09:39:06 large] (main.py 233): INFO EPOCH 22 training takes 0:25:23
[2022-04-05 09:39:13 large] (main.py 273): INFO Test: [0/98]	Time 6.691 (6.691)	Loss 1.6164 (1.6164)	Acc@1 63.477 (63.477)	Acc@5 86.133 (86.133)	Mem 8931MB
[2022-04-05 09:39:38 large] (main.py 279): INFO  * Acc@1 64.872 Acc@5 86.790
[2022-04-05 09:39:38 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 64.9%
[2022-04-05 09:39:38 large] (main.py 148): INFO Max accuracy: 64.90%
[2022-04-05 09:39:45 large] (main.py 226): INFO Train: [23/300][0/2502]	eta 4:36:50 lr 0.000493	time 6.6388 (6.6388)	loss 3.0094 (3.0094)	grad_norm 2.2506 (2.2506)	mem 8931MB
[2022-04-05 09:40:39 large] (main.py 226): INFO Train: [23/300][100/2502]	eta 0:23:49 lr 0.000493	time 0.5817 (0.5949)	loss 4.4461 (4.2153)	grad_norm 1.9251 (2.4362)	mem 8931MB
[2022-04-05 09:41:41 large] (main.py 226): INFO Train: [23/300][200/2502]	eta 0:23:23 lr 0.000493	time 0.7408 (0.6096)	loss 4.5160 (4.1568)	grad_norm 3.0486 (2.3881)	mem 8931MB
[2022-04-05 09:42:41 large] (main.py 226): INFO Train: [23/300][300/2502]	eta 0:22:16 lr 0.000493	time 0.6268 (0.6068)	loss 4.6369 (4.1495)	grad_norm 2.7985 (2.3861)	mem 8931MB
[2022-04-05 09:43:43 large] (main.py 226): INFO Train: [23/300][400/2502]	eta 0:21:20 lr 0.000493	time 0.5609 (0.6090)	loss 4.5991 (4.1271)	grad_norm 1.9009 (2.3844)	mem 8931MB
[2022-04-05 09:44:43 large] (main.py 226): INFO Train: [23/300][500/2502]	eta 0:20:18 lr 0.000493	time 0.5987 (0.6087)	loss 4.8170 (4.1426)	grad_norm 2.2039 (2.4185)	mem 8931MB
[2022-04-05 09:45:45 large] (main.py 226): INFO Train: [23/300][600/2502]	eta 0:19:19 lr 0.000493	time 0.6094 (0.6096)	loss 3.5386 (4.1485)	grad_norm 2.3457 (2.4304)	mem 8931MB
[2022-04-05 09:46:45 large] (main.py 226): INFO Train: [23/300][700/2502]	eta 0:18:15 lr 0.000493	time 0.6110 (0.6081)	loss 4.0205 (4.1379)	grad_norm 2.0153 (2.4302)	mem 8931MB
[2022-04-05 09:47:44 large] (main.py 226): INFO Train: [23/300][800/2502]	eta 0:17:12 lr 0.000493	time 0.7287 (0.6066)	loss 4.7667 (4.1411)	grad_norm 2.9221 (2.4254)	mem 8931MB
[2022-04-05 09:48:44 large] (main.py 226): INFO Train: [23/300][900/2502]	eta 0:16:09 lr 0.000493	time 0.6553 (0.6052)	loss 4.5926 (4.1354)	grad_norm 2.7880 (2.4252)	mem 8931MB
[2022-04-05 09:49:44 large] (main.py 226): INFO Train: [23/300][1000/2502]	eta 0:15:09 lr 0.000493	time 0.7126 (0.6052)	loss 3.2453 (4.1352)	grad_norm 1.9437 (2.4348)	mem 8931MB
[2022-04-05 09:50:45 large] (main.py 226): INFO Train: [23/300][1100/2502]	eta 0:14:09 lr 0.000493	time 0.6222 (0.6058)	loss 2.9062 (4.1203)	grad_norm 2.5757 (2.4399)	mem 8931MB
[2022-04-05 09:51:46 large] (main.py 226): INFO Train: [23/300][1200/2502]	eta 0:13:09 lr 0.000493	time 0.5888 (0.6061)	loss 4.4255 (4.1243)	grad_norm 1.9555 (2.4271)	mem 8931MB
[2022-04-05 09:52:47 large] (main.py 226): INFO Train: [23/300][1300/2502]	eta 0:12:08 lr 0.000493	time 0.6147 (0.6063)	loss 4.1015 (4.1261)	grad_norm 2.3353 (2.4275)	mem 8931MB
[2022-04-05 09:53:48 large] (main.py 226): INFO Train: [23/300][1400/2502]	eta 0:11:08 lr 0.000493	time 0.6392 (0.6063)	loss 3.6508 (4.1239)	grad_norm 2.2485 (2.4187)	mem 8931MB
[2022-04-05 09:54:49 large] (main.py 226): INFO Train: [23/300][1500/2502]	eta 0:10:07 lr 0.000492	time 0.6120 (0.6066)	loss 3.8333 (4.1282)	grad_norm 1.8421 (2.4139)	mem 8931MB
[2022-04-05 09:55:49 large] (main.py 226): INFO Train: [23/300][1600/2502]	eta 0:09:06 lr 0.000492	time 0.6228 (0.6063)	loss 3.5833 (4.1262)	grad_norm 2.0861 (2.4091)	mem 8931MB
[2022-04-05 09:56:49 large] (main.py 226): INFO Train: [23/300][1700/2502]	eta 0:08:05 lr 0.000492	time 0.6028 (0.6060)	loss 4.7492 (4.1291)	grad_norm 2.0435 (2.4093)	mem 8931MB
[2022-04-05 09:57:50 large] (main.py 226): INFO Train: [23/300][1800/2502]	eta 0:07:05 lr 0.000492	time 0.6891 (0.6061)	loss 4.9948 (4.1260)	grad_norm 1.7966 (2.4172)	mem 8931MB
[2022-04-05 09:58:51 large] (main.py 226): INFO Train: [23/300][1900/2502]	eta 0:06:05 lr 0.000492	time 0.6183 (0.6063)	loss 3.6769 (4.1315)	grad_norm 2.1813 (2.4089)	mem 8931MB
[2022-04-05 09:59:52 large] (main.py 226): INFO Train: [23/300][2000/2502]	eta 0:05:04 lr 0.000492	time 0.5993 (0.6063)	loss 3.8410 (4.1287)	grad_norm 2.1944 (2.4041)	mem 8931MB
[2022-04-05 10:00:52 large] (main.py 226): INFO Train: [23/300][2100/2502]	eta 0:04:03 lr 0.000492	time 0.6757 (0.6063)	loss 4.6699 (4.1315)	grad_norm 2.1090 (2.4019)	mem 8931MB
[2022-04-05 10:01:53 large] (main.py 226): INFO Train: [23/300][2200/2502]	eta 0:03:03 lr 0.000492	time 0.6136 (0.6062)	loss 4.8376 (4.1232)	grad_norm 2.0991 (inf)	mem 8931MB
[2022-04-05 10:02:53 large] (main.py 226): INFO Train: [23/300][2300/2502]	eta 0:02:02 lr 0.000492	time 0.6609 (0.6062)	loss 4.4286 (4.1216)	grad_norm 2.0235 (inf)	mem 8931MB
[2022-04-05 10:03:54 large] (main.py 226): INFO Train: [23/300][2400/2502]	eta 0:01:01 lr 0.000492	time 0.6324 (0.6063)	loss 4.9872 (4.1224)	grad_norm 2.1595 (inf)	mem 8931MB
[2022-04-05 10:04:54 large] (main.py 226): INFO Train: [23/300][2500/2502]	eta 0:00:01 lr 0.000492	time 0.5657 (0.6058)	loss 4.5430 (4.1246)	grad_norm 2.5481 (inf)	mem 8931MB
[2022-04-05 10:04:55 large] (main.py 233): INFO EPOCH 23 training takes 0:25:16
[2022-04-05 10:05:01 large] (main.py 273): INFO Test: [0/98]	Time 6.707 (6.707)	Loss 1.6131 (1.6131)	Acc@1 65.625 (65.625)	Acc@5 87.109 (87.109)	Mem 8931MB
[2022-04-05 10:05:27 large] (main.py 279): INFO  * Acc@1 66.238 Acc@5 87.616
[2022-04-05 10:05:27 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 66.2%
[2022-04-05 10:05:27 large] (utils.py 57): INFO output/large/default/ckpt_epoch_23.pth saving......
[2022-04-05 10:05:28 large] (utils.py 59): INFO output/large/default/ckpt_epoch_23.pth saved !!!
[2022-04-05 10:05:28 large] (main.py 148): INFO Max accuracy: 66.24%
[2022-04-05 10:05:35 large] (main.py 226): INFO Train: [24/300][0/2502]	eta 5:10:35 lr 0.000492	time 7.4484 (7.4484)	loss 4.3401 (4.3401)	grad_norm 2.6570 (2.6570)	mem 8931MB
[2022-04-05 10:06:28 large] (main.py 226): INFO Train: [24/300][100/2502]	eta 0:24:07 lr 0.000492	time 0.6414 (0.6026)	loss 3.4137 (4.1735)	grad_norm 3.0194 (2.4179)	mem 8931MB
[2022-04-05 10:07:28 large] (main.py 226): INFO Train: [24/300][200/2502]	eta 0:23:02 lr 0.000492	time 0.6412 (0.6005)	loss 4.3292 (4.1464)	grad_norm 2.7344 (2.4042)	mem 8931MB
[2022-04-05 10:08:30 large] (main.py 226): INFO Train: [24/300][300/2502]	eta 0:22:14 lr 0.000492	time 0.5693 (0.6062)	loss 4.4816 (4.1094)	grad_norm 2.6791 (2.4213)	mem 8931MB
[2022-04-05 10:09:31 large] (main.py 226): INFO Train: [24/300][400/2502]	eta 0:21:15 lr 0.000492	time 0.6119 (0.6070)	loss 4.2442 (4.1123)	grad_norm 4.0031 (2.4306)	mem 8931MB
[2022-04-05 10:10:32 large] (main.py 226): INFO Train: [24/300][500/2502]	eta 0:20:17 lr 0.000492	time 0.5139 (0.6082)	loss 4.4657 (4.1229)	grad_norm 1.9212 (2.4327)	mem 8931MB
[2022-04-05 10:11:34 large] (main.py 226): INFO Train: [24/300][600/2502]	eta 0:19:18 lr 0.000492	time 0.5998 (0.6092)	loss 4.1332 (4.1222)	grad_norm 2.4623 (2.4143)	mem 8931MB
[2022-04-05 10:12:35 large] (main.py 226): INFO Train: [24/300][700/2502]	eta 0:18:18 lr 0.000492	time 0.5329 (0.6095)	loss 3.9516 (4.1270)	grad_norm 2.0519 (2.4100)	mem 8931MB
[2022-04-05 10:13:36 large] (main.py 226): INFO Train: [24/300][800/2502]	eta 0:17:17 lr 0.000492	time 0.6395 (0.6095)	loss 4.1967 (4.1309)	grad_norm 3.6884 (2.4238)	mem 8931MB
[2022-04-05 10:14:36 large] (main.py 226): INFO Train: [24/300][900/2502]	eta 0:16:14 lr 0.000492	time 0.6057 (0.6085)	loss 4.4129 (4.1222)	grad_norm 1.7933 (2.4135)	mem 8931MB
[2022-04-05 10:15:36 large] (main.py 226): INFO Train: [24/300][1000/2502]	eta 0:15:13 lr 0.000492	time 0.4445 (0.6081)	loss 3.6274 (4.1263)	grad_norm 2.1579 (2.4171)	mem 8931MB
[2022-04-05 10:16:36 large] (main.py 226): INFO Train: [24/300][1100/2502]	eta 0:14:11 lr 0.000492	time 0.6953 (0.6074)	loss 4.2268 (4.1201)	grad_norm 2.3130 (2.4120)	mem 8931MB
[2022-04-05 10:17:36 large] (main.py 226): INFO Train: [24/300][1200/2502]	eta 0:13:10 lr 0.000492	time 0.5113 (0.6069)	loss 3.4880 (4.1156)	grad_norm 1.9571 (2.4163)	mem 8931MB
[2022-04-05 10:18:37 large] (main.py 226): INFO Train: [24/300][1300/2502]	eta 0:12:09 lr 0.000492	time 0.7312 (0.6065)	loss 3.9115 (4.1141)	grad_norm 2.1741 (2.4073)	mem 8931MB
[2022-04-05 10:19:37 large] (main.py 226): INFO Train: [24/300][1400/2502]	eta 0:11:08 lr 0.000492	time 0.7057 (0.6065)	loss 3.6604 (4.1079)	grad_norm 2.9015 (2.4073)	mem 8931MB
[2022-04-05 10:20:38 large] (main.py 226): INFO Train: [24/300][1500/2502]	eta 0:10:08 lr 0.000492	time 0.5567 (0.6068)	loss 3.1037 (4.1035)	grad_norm 2.1700 (2.4084)	mem 8931MB
[2022-04-05 10:21:40 large] (main.py 226): INFO Train: [24/300][1600/2502]	eta 0:09:07 lr 0.000492	time 0.6460 (0.6071)	loss 4.4089 (4.1004)	grad_norm 2.0355 (2.4082)	mem 8931MB
[2022-04-05 10:22:41 large] (main.py 226): INFO Train: [24/300][1700/2502]	eta 0:08:07 lr 0.000492	time 0.6933 (0.6074)	loss 4.7480 (4.1042)	grad_norm 2.3793 (2.4116)	mem 8931MB
[2022-04-05 10:23:41 large] (main.py 226): INFO Train: [24/300][1800/2502]	eta 0:07:06 lr 0.000492	time 0.5252 (0.6074)	loss 3.5219 (4.0989)	grad_norm 1.6400 (inf)	mem 8931MB
[2022-04-05 10:24:42 large] (main.py 226): INFO Train: [24/300][1900/2502]	eta 0:06:05 lr 0.000492	time 0.6221 (0.6073)	loss 4.7911 (4.1060)	grad_norm 2.2998 (inf)	mem 8931MB
[2022-04-05 10:25:43 large] (main.py 226): INFO Train: [24/300][2000/2502]	eta 0:05:04 lr 0.000492	time 0.5134 (0.6072)	loss 4.6548 (4.1047)	grad_norm 1.5022 (inf)	mem 8931MB
[2022-04-05 10:26:44 large] (main.py 226): INFO Train: [24/300][2100/2502]	eta 0:04:04 lr 0.000492	time 0.5869 (0.6076)	loss 4.8478 (4.0986)	grad_norm 1.9463 (inf)	mem 8931MB
[2022-04-05 10:27:45 large] (main.py 226): INFO Train: [24/300][2200/2502]	eta 0:03:03 lr 0.000492	time 0.5536 (0.6078)	loss 4.4224 (4.0986)	grad_norm 3.4137 (inf)	mem 8931MB
[2022-04-05 10:28:45 large] (main.py 226): INFO Train: [24/300][2300/2502]	eta 0:02:02 lr 0.000492	time 0.5164 (0.6075)	loss 4.3871 (4.0963)	grad_norm 2.1084 (inf)	mem 8931MB
[2022-04-05 10:29:46 large] (main.py 226): INFO Train: [24/300][2400/2502]	eta 0:01:01 lr 0.000492	time 0.6703 (0.6073)	loss 4.7798 (4.0949)	grad_norm 2.3464 (inf)	mem 8931MB
[2022-04-05 10:30:46 large] (main.py 226): INFO Train: [24/300][2500/2502]	eta 0:00:01 lr 0.000492	time 0.5709 (0.6070)	loss 3.6438 (4.0941)	grad_norm 3.0523 (inf)	mem 8931MB
[2022-04-05 10:30:47 large] (main.py 233): INFO EPOCH 24 training takes 0:25:19
[2022-04-05 10:30:53 large] (main.py 273): INFO Test: [0/98]	Time 5.802 (5.802)	Loss 1.5426 (1.5426)	Acc@1 64.062 (64.062)	Acc@5 89.062 (89.062)	Mem 8931MB
[2022-04-05 10:31:19 large] (main.py 279): INFO  * Acc@1 66.918 Acc@5 87.976
[2022-04-05 10:31:19 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 66.9%
[2022-04-05 10:31:19 large] (utils.py 57): INFO output/large/default/ckpt_epoch_24.pth saving......
[2022-04-05 10:31:20 large] (utils.py 59): INFO output/large/default/ckpt_epoch_24.pth saved !!!
[2022-04-05 10:31:20 large] (main.py 148): INFO Max accuracy: 66.92%
[2022-04-05 10:31:28 large] (main.py 226): INFO Train: [25/300][0/2502]	eta 5:38:11 lr 0.000492	time 8.1102 (8.1102)	loss 3.3834 (3.3834)	grad_norm 1.7553 (1.7553)	mem 8931MB
[2022-04-05 10:32:22 large] (main.py 226): INFO Train: [25/300][100/2502]	eta 0:24:44 lr 0.000492	time 0.7302 (0.6180)	loss 4.1322 (3.9890)	grad_norm 2.3592 (2.4373)	mem 8931MB
[2022-04-05 10:33:24 large] (main.py 226): INFO Train: [25/300][200/2502]	eta 0:23:36 lr 0.000492	time 0.5807 (0.6154)	loss 4.1225 (4.0696)	grad_norm 2.8812 (2.3782)	mem 8931MB
[2022-04-05 10:34:25 large] (main.py 226): INFO Train: [25/300][300/2502]	eta 0:22:36 lr 0.000491	time 0.6199 (0.6159)	loss 3.1098 (4.0549)	grad_norm 2.5058 (2.4034)	mem 8931MB
[2022-04-05 10:35:26 large] (main.py 226): INFO Train: [25/300][400/2502]	eta 0:21:27 lr 0.000491	time 0.6379 (0.6127)	loss 3.9197 (4.0911)	grad_norm 2.4897 (2.3774)	mem 8931MB
[2022-04-05 10:36:26 large] (main.py 226): INFO Train: [25/300][500/2502]	eta 0:20:23 lr 0.000491	time 0.6289 (0.6113)	loss 4.3221 (4.0939)	grad_norm 1.8329 (2.3664)	mem 8931MB
[2022-04-05 10:37:27 large] (main.py 226): INFO Train: [25/300][600/2502]	eta 0:19:23 lr 0.000491	time 0.6428 (0.6115)	loss 3.7044 (4.0958)	grad_norm 1.8229 (2.3738)	mem 8931MB
[2022-04-05 10:38:28 large] (main.py 226): INFO Train: [25/300][700/2502]	eta 0:18:21 lr 0.000491	time 0.5425 (0.6112)	loss 3.6216 (4.0865)	grad_norm 2.9739 (2.3720)	mem 8931MB
[2022-04-05 10:39:30 large] (main.py 226): INFO Train: [25/300][800/2502]	eta 0:17:21 lr 0.000491	time 0.6724 (0.6120)	loss 3.0223 (4.0956)	grad_norm 3.2659 (2.3580)	mem 8931MB
[2022-04-05 10:40:30 large] (main.py 226): INFO Train: [25/300][900/2502]	eta 0:16:18 lr 0.000491	time 0.5792 (0.6109)	loss 4.7189 (4.0977)	grad_norm 1.9970 (2.3516)	mem 8931MB
[2022-04-05 10:41:30 large] (main.py 226): INFO Train: [25/300][1000/2502]	eta 0:15:15 lr 0.000491	time 0.7043 (0.6094)	loss 3.4879 (4.0906)	grad_norm 2.2703 (2.3410)	mem 8931MB
[2022-04-05 10:42:31 large] (main.py 226): INFO Train: [25/300][1100/2502]	eta 0:14:14 lr 0.000491	time 0.5254 (0.6097)	loss 3.8447 (4.0853)	grad_norm 1.8601 (2.3403)	mem 8931MB
[2022-04-05 10:43:32 large] (main.py 226): INFO Train: [25/300][1200/2502]	eta 0:13:14 lr 0.000491	time 0.6153 (0.6098)	loss 3.8784 (4.0892)	grad_norm 2.0803 (2.3459)	mem 8931MB
[2022-04-05 10:44:34 large] (main.py 226): INFO Train: [25/300][1300/2502]	eta 0:12:13 lr 0.000491	time 1.2905 (0.6102)	loss 4.3595 (4.0918)	grad_norm 3.1497 (2.3377)	mem 8931MB
[2022-04-05 10:45:34 large] (main.py 226): INFO Train: [25/300][1400/2502]	eta 0:11:12 lr 0.000491	time 0.5963 (0.6100)	loss 3.2985 (4.0886)	grad_norm 2.4802 (inf)	mem 8931MB
[2022-04-05 10:46:35 large] (main.py 226): INFO Train: [25/300][1500/2502]	eta 0:10:11 lr 0.000491	time 0.6485 (0.6099)	loss 3.5362 (4.0895)	grad_norm 1.8363 (inf)	mem 8931MB
[2022-04-05 10:47:36 large] (main.py 226): INFO Train: [25/300][1600/2502]	eta 0:09:10 lr 0.000491	time 0.6933 (0.6100)	loss 4.4346 (4.0875)	grad_norm 2.0386 (inf)	mem 8931MB
[2022-04-05 10:48:37 large] (main.py 226): INFO Train: [25/300][1700/2502]	eta 0:08:09 lr 0.000491	time 0.4991 (0.6098)	loss 4.1062 (4.0852)	grad_norm 1.8734 (inf)	mem 8931MB
[2022-04-05 10:49:38 large] (main.py 226): INFO Train: [25/300][1800/2502]	eta 0:07:07 lr 0.000491	time 0.6362 (0.6095)	loss 4.7164 (4.0850)	grad_norm 2.7151 (inf)	mem 8931MB
[2022-04-05 10:50:38 large] (main.py 226): INFO Train: [25/300][1900/2502]	eta 0:06:06 lr 0.000491	time 0.6525 (0.6091)	loss 4.9830 (4.0828)	grad_norm 2.3945 (inf)	mem 8931MB
[2022-04-05 10:51:40 large] (main.py 226): INFO Train: [25/300][2000/2502]	eta 0:05:06 lr 0.000491	time 0.6774 (0.6096)	loss 3.7058 (4.0789)	grad_norm 1.9462 (inf)	mem 8931MB
[2022-04-05 10:52:41 large] (main.py 226): INFO Train: [25/300][2100/2502]	eta 0:04:05 lr 0.000491	time 0.6224 (0.6097)	loss 2.9444 (4.0807)	grad_norm 2.2851 (inf)	mem 8931MB
[2022-04-05 10:53:43 large] (main.py 226): INFO Train: [25/300][2200/2502]	eta 0:03:04 lr 0.000491	time 0.5390 (0.6101)	loss 4.4987 (4.0793)	grad_norm 1.8829 (inf)	mem 8931MB
[2022-04-05 10:54:44 large] (main.py 226): INFO Train: [25/300][2300/2502]	eta 0:02:03 lr 0.000491	time 0.5709 (0.6101)	loss 3.8983 (4.0735)	grad_norm 1.9538 (inf)	mem 8931MB
[2022-04-05 10:55:45 large] (main.py 226): INFO Train: [25/300][2400/2502]	eta 0:01:02 lr 0.000491	time 0.5129 (0.6100)	loss 4.0059 (4.0770)	grad_norm 4.0323 (inf)	mem 8931MB
[2022-04-05 10:56:46 large] (main.py 226): INFO Train: [25/300][2500/2502]	eta 0:00:01 lr 0.000491	time 0.6177 (0.6103)	loss 4.5215 (4.0751)	grad_norm 2.4965 (inf)	mem 8931MB
[2022-04-05 10:56:47 large] (main.py 233): INFO EPOCH 25 training takes 0:25:27
[2022-04-05 10:56:53 large] (main.py 273): INFO Test: [0/98]	Time 5.903 (5.903)	Loss 1.6350 (1.6350)	Acc@1 65.625 (65.625)	Acc@5 87.500 (87.500)	Mem 8931MB
[2022-04-05 10:57:20 large] (main.py 279): INFO  * Acc@1 66.732 Acc@5 87.938
[2022-04-05 10:57:20 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 66.7%
[2022-04-05 10:57:20 large] (main.py 148): INFO Max accuracy: 66.92%
[2022-04-05 10:57:27 large] (main.py 226): INFO Train: [26/300][0/2502]	eta 5:00:29 lr 0.000491	time 7.2061 (7.2061)	loss 3.5970 (3.5970)	grad_norm 2.2132 (2.2132)	mem 8931MB
[2022-04-05 10:58:25 large] (main.py 226): INFO Train: [26/300][100/2502]	eta 0:25:56 lr 0.000491	time 0.6312 (0.6478)	loss 4.6408 (4.0581)	grad_norm 2.1394 (2.4544)	mem 8931MB
[2022-04-05 10:59:27 large] (main.py 226): INFO Train: [26/300][200/2502]	eta 0:24:14 lr 0.000491	time 0.7617 (0.6320)	loss 4.3461 (4.1085)	grad_norm 1.7424 (2.4007)	mem 8931MB
[2022-04-05 11:00:28 large] (main.py 226): INFO Train: [26/300][300/2502]	eta 0:22:56 lr 0.000491	time 0.6063 (0.6249)	loss 4.3445 (4.0703)	grad_norm 1.9332 (2.3713)	mem 8931MB
[2022-04-05 11:01:30 large] (main.py 226): INFO Train: [26/300][400/2502]	eta 0:21:52 lr 0.000491	time 0.6790 (0.6243)	loss 4.3750 (4.0837)	grad_norm 2.1490 (2.3704)	mem 8931MB
[2022-04-05 11:02:32 large] (main.py 226): INFO Train: [26/300][500/2502]	eta 0:20:45 lr 0.000491	time 0.7167 (0.6223)	loss 4.9724 (4.0992)	grad_norm 1.9698 (2.3743)	mem 8931MB
[2022-04-05 11:03:33 large] (main.py 226): INFO Train: [26/300][600/2502]	eta 0:19:40 lr 0.000491	time 0.5366 (0.6204)	loss 4.0673 (4.0799)	grad_norm 2.5020 (2.3855)	mem 8931MB
[2022-04-05 11:04:34 large] (main.py 226): INFO Train: [26/300][700/2502]	eta 0:18:35 lr 0.000491	time 0.5354 (0.6192)	loss 4.0747 (4.0653)	grad_norm 2.0894 (2.3693)	mem 8931MB
[2022-04-05 11:05:35 large] (main.py 226): INFO Train: [26/300][800/2502]	eta 0:17:31 lr 0.000491	time 0.5796 (0.6179)	loss 5.0360 (4.0594)	grad_norm 1.9560 (2.3619)	mem 8931MB
[2022-04-05 11:06:36 large] (main.py 226): INFO Train: [26/300][900/2502]	eta 0:16:29 lr 0.000491	time 0.6479 (0.6175)	loss 4.3274 (4.0622)	grad_norm 1.9949 (2.3555)	mem 8931MB
[2022-04-05 11:07:38 large] (main.py 226): INFO Train: [26/300][1000/2502]	eta 0:15:27 lr 0.000491	time 0.6331 (0.6172)	loss 4.2118 (4.0606)	grad_norm 2.1936 (2.3505)	mem 8931MB
[2022-04-05 11:08:39 large] (main.py 226): INFO Train: [26/300][1100/2502]	eta 0:14:24 lr 0.000491	time 0.6591 (0.6168)	loss 4.2894 (4.0643)	grad_norm 2.7064 (2.3499)	mem 8931MB
[2022-04-05 11:09:40 large] (main.py 226): INFO Train: [26/300][1200/2502]	eta 0:13:22 lr 0.000491	time 0.5361 (0.6162)	loss 3.5974 (4.0669)	grad_norm 1.6020 (2.3553)	mem 8931MB
[2022-04-05 11:10:41 large] (main.py 226): INFO Train: [26/300][1300/2502]	eta 0:12:20 lr 0.000491	time 0.6042 (0.6157)	loss 3.0282 (4.0585)	grad_norm 2.9781 (2.3547)	mem 8931MB
[2022-04-05 11:11:41 large] (main.py 226): INFO Train: [26/300][1400/2502]	eta 0:11:17 lr 0.000490	time 0.5854 (0.6149)	loss 4.9835 (4.0591)	grad_norm 3.2568 (2.3600)	mem 8931MB
[2022-04-05 11:12:42 large] (main.py 226): INFO Train: [26/300][1500/2502]	eta 0:10:15 lr 0.000490	time 0.6467 (0.6143)	loss 4.1259 (4.0567)	grad_norm 2.1825 (2.3598)	mem 8931MB
[2022-04-05 11:13:43 large] (main.py 226): INFO Train: [26/300][1600/2502]	eta 0:09:13 lr 0.000490	time 0.6036 (0.6140)	loss 4.1770 (4.0527)	grad_norm 2.3059 (2.3524)	mem 8931MB
[2022-04-05 11:14:44 large] (main.py 226): INFO Train: [26/300][1700/2502]	eta 0:08:12 lr 0.000490	time 0.5957 (0.6141)	loss 3.9938 (4.0553)	grad_norm 2.0008 (inf)	mem 8931MB
[2022-04-05 11:15:45 large] (main.py 226): INFO Train: [26/300][1800/2502]	eta 0:07:10 lr 0.000490	time 0.6956 (0.6139)	loss 4.5429 (4.0605)	grad_norm 2.6756 (inf)	mem 8931MB
[2022-04-05 11:16:47 large] (main.py 226): INFO Train: [26/300][1900/2502]	eta 0:06:09 lr 0.000490	time 0.5957 (0.6138)	loss 3.2226 (4.0591)	grad_norm 2.0110 (inf)	mem 8931MB
[2022-04-05 11:17:48 large] (main.py 226): INFO Train: [26/300][2000/2502]	eta 0:05:08 lr 0.000490	time 0.6304 (0.6138)	loss 2.8513 (4.0551)	grad_norm 2.0073 (inf)	mem 8931MB
[2022-04-05 11:18:49 large] (main.py 226): INFO Train: [26/300][2100/2502]	eta 0:04:06 lr 0.000490	time 0.5406 (0.6134)	loss 3.1130 (4.0504)	grad_norm 3.3281 (inf)	mem 8931MB
[2022-04-05 11:19:49 large] (main.py 226): INFO Train: [26/300][2200/2502]	eta 0:03:05 lr 0.000490	time 0.5306 (0.6130)	loss 3.0620 (4.0485)	grad_norm 2.8710 (inf)	mem 8931MB
[2022-04-05 11:20:51 large] (main.py 226): INFO Train: [26/300][2300/2502]	eta 0:02:03 lr 0.000490	time 0.6286 (0.6131)	loss 3.4885 (4.0452)	grad_norm 1.8604 (inf)	mem 8931MB
[2022-04-05 11:21:52 large] (main.py 226): INFO Train: [26/300][2400/2502]	eta 0:01:02 lr 0.000490	time 0.6097 (0.6133)	loss 3.3234 (4.0442)	grad_norm 2.0507 (inf)	mem 8931MB
[2022-04-05 11:22:52 large] (main.py 226): INFO Train: [26/300][2500/2502]	eta 0:00:01 lr 0.000490	time 0.6092 (0.6128)	loss 2.8428 (4.0402)	grad_norm 2.0858 (inf)	mem 8931MB
[2022-04-05 11:22:53 large] (main.py 233): INFO EPOCH 26 training takes 0:25:33
[2022-04-05 11:23:00 large] (main.py 273): INFO Test: [0/98]	Time 6.306 (6.306)	Loss 1.4956 (1.4956)	Acc@1 65.820 (65.820)	Acc@5 88.477 (88.477)	Mem 8931MB
[2022-04-05 11:23:26 large] (main.py 279): INFO  * Acc@1 67.408 Acc@5 88.352
[2022-04-05 11:23:26 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 67.4%
[2022-04-05 11:23:26 large] (utils.py 57): INFO output/large/default/ckpt_epoch_26.pth saving......
[2022-04-05 11:23:27 large] (utils.py 59): INFO output/large/default/ckpt_epoch_26.pth saved !!!
[2022-04-05 11:23:27 large] (main.py 148): INFO Max accuracy: 67.41%
[2022-04-05 11:23:35 large] (main.py 226): INFO Train: [27/300][0/2502]	eta 5:38:35 lr 0.000490	time 8.1195 (8.1195)	loss 2.8133 (2.8133)	grad_norm 2.0068 (2.0068)	mem 8931MB
[2022-04-05 11:24:29 large] (main.py 226): INFO Train: [27/300][100/2502]	eta 0:24:46 lr 0.000490	time 0.5137 (0.6189)	loss 4.3784 (4.0479)	grad_norm 1.8164 (2.2969)	mem 8931MB
[2022-04-05 11:25:31 large] (main.py 226): INFO Train: [27/300][200/2502]	eta 0:23:46 lr 0.000490	time 0.5031 (0.6196)	loss 4.3562 (4.0413)	grad_norm 2.0388 (2.3336)	mem 8931MB
[2022-04-05 11:26:33 large] (main.py 226): INFO Train: [27/300][300/2502]	eta 0:22:45 lr 0.000490	time 0.6965 (0.6203)	loss 3.7636 (4.0223)	grad_norm 2.0051 (2.3377)	mem 8931MB
[2022-04-05 11:27:35 large] (main.py 226): INFO Train: [27/300][400/2502]	eta 0:21:40 lr 0.000490	time 0.6016 (0.6189)	loss 4.1705 (4.0159)	grad_norm 2.2532 (2.3321)	mem 8931MB
[2022-04-05 11:28:36 large] (main.py 226): INFO Train: [27/300][500/2502]	eta 0:20:35 lr 0.000490	time 0.6125 (0.6171)	loss 2.4131 (4.0095)	grad_norm 2.2137 (2.3400)	mem 8931MB
[2022-04-05 11:29:37 large] (main.py 226): INFO Train: [27/300][600/2502]	eta 0:19:32 lr 0.000490	time 0.5410 (0.6164)	loss 4.0138 (4.0129)	grad_norm 2.1477 (2.3356)	mem 8931MB
[2022-04-05 11:30:38 large] (main.py 226): INFO Train: [27/300][700/2502]	eta 0:18:29 lr 0.000490	time 0.6466 (0.6159)	loss 4.3772 (4.0327)	grad_norm 2.0244 (2.3347)	mem 8931MB
[2022-04-05 11:31:40 large] (main.py 226): INFO Train: [27/300][800/2502]	eta 0:17:27 lr 0.000490	time 0.5915 (0.6154)	loss 4.6143 (4.0441)	grad_norm 2.0111 (2.3286)	mem 8931MB
[2022-04-05 11:32:41 large] (main.py 226): INFO Train: [27/300][900/2502]	eta 0:16:25 lr 0.000490	time 0.5349 (0.6154)	loss 4.3987 (4.0564)	grad_norm 3.7905 (2.3272)	mem 8931MB
[2022-04-05 11:33:43 large] (main.py 226): INFO Train: [27/300][1000/2502]	eta 0:15:25 lr 0.000490	time 0.5840 (0.6160)	loss 4.1948 (4.0546)	grad_norm 2.4081 (2.3219)	mem 8931MB
[2022-04-05 11:34:45 large] (main.py 226): INFO Train: [27/300][1100/2502]	eta 0:14:23 lr 0.000490	time 0.6155 (0.6159)	loss 4.7874 (4.0552)	grad_norm 3.3766 (2.3209)	mem 8931MB
[2022-04-05 11:35:45 large] (main.py 226): INFO Train: [27/300][1200/2502]	eta 0:13:20 lr 0.000490	time 0.6965 (0.6150)	loss 4.5891 (4.0519)	grad_norm 1.9487 (2.3302)	mem 8931MB
[2022-04-05 11:36:47 large] (main.py 226): INFO Train: [27/300][1300/2502]	eta 0:12:19 lr 0.000490	time 0.6091 (0.6149)	loss 4.2418 (4.0463)	grad_norm 2.0514 (2.3315)	mem 8931MB
[2022-04-05 11:37:48 large] (main.py 226): INFO Train: [27/300][1400/2502]	eta 0:11:17 lr 0.000490	time 0.6432 (0.6147)	loss 4.2517 (4.0463)	grad_norm 2.9820 (2.3295)	mem 8931MB
[2022-04-05 11:38:50 large] (main.py 226): INFO Train: [27/300][1500/2502]	eta 0:10:16 lr 0.000490	time 0.6148 (0.6150)	loss 4.5322 (4.0485)	grad_norm 1.8949 (2.3334)	mem 8931MB
[2022-04-05 11:39:51 large] (main.py 226): INFO Train: [27/300][1600/2502]	eta 0:09:14 lr 0.000490	time 0.6049 (0.6151)	loss 4.3425 (4.0435)	grad_norm 2.0724 (inf)	mem 8931MB
[2022-04-05 11:40:53 large] (main.py 226): INFO Train: [27/300][1700/2502]	eta 0:08:13 lr 0.000490	time 0.5792 (0.6150)	loss 3.9931 (4.0385)	grad_norm 1.7677 (inf)	mem 8931MB
[2022-04-05 11:41:54 large] (main.py 226): INFO Train: [27/300][1800/2502]	eta 0:07:11 lr 0.000490	time 0.5792 (0.6147)	loss 4.4607 (4.0390)	grad_norm 2.1378 (inf)	mem 8931MB
[2022-04-05 11:42:55 large] (main.py 226): INFO Train: [27/300][1900/2502]	eta 0:06:10 lr 0.000490	time 0.5007 (0.6148)	loss 2.8763 (4.0404)	grad_norm 1.8644 (inf)	mem 8931MB
[2022-04-05 11:43:57 large] (main.py 226): INFO Train: [27/300][2000/2502]	eta 0:05:08 lr 0.000490	time 0.5217 (0.6149)	loss 2.8612 (4.0371)	grad_norm 2.4514 (inf)	mem 8931MB
[2022-04-05 11:44:59 large] (main.py 226): INFO Train: [27/300][2100/2502]	eta 0:04:07 lr 0.000490	time 0.6244 (0.6152)	loss 4.7299 (4.0290)	grad_norm 2.4521 (inf)	mem 8931MB
[2022-04-05 11:46:01 large] (main.py 226): INFO Train: [27/300][2200/2502]	eta 0:03:05 lr 0.000490	time 0.6829 (0.6154)	loss 3.1782 (4.0309)	grad_norm 2.3909 (inf)	mem 8931MB
[2022-04-05 11:47:03 large] (main.py 226): INFO Train: [27/300][2300/2502]	eta 0:02:04 lr 0.000489	time 0.6218 (0.6157)	loss 4.9563 (4.0305)	grad_norm 4.4232 (inf)	mem 8931MB
[2022-04-05 11:48:05 large] (main.py 226): INFO Train: [27/300][2400/2502]	eta 0:01:02 lr 0.000489	time 0.6251 (0.6156)	loss 3.6867 (4.0281)	grad_norm 2.6570 (inf)	mem 8931MB
[2022-04-05 11:49:06 large] (main.py 226): INFO Train: [27/300][2500/2502]	eta 0:00:01 lr 0.000489	time 0.5799 (0.6154)	loss 4.4024 (4.0230)	grad_norm 2.9058 (inf)	mem 8931MB
[2022-04-05 11:49:07 large] (main.py 233): INFO EPOCH 27 training takes 0:25:40
[2022-04-05 11:49:13 large] (main.py 273): INFO Test: [0/98]	Time 6.702 (6.702)	Loss 1.5001 (1.5001)	Acc@1 66.602 (66.602)	Acc@5 88.281 (88.281)	Mem 8931MB
[2022-04-05 11:49:38 large] (main.py 279): INFO  * Acc@1 67.580 Acc@5 88.416
[2022-04-05 11:49:38 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 67.6%
[2022-04-05 11:49:38 large] (utils.py 57): INFO output/large/default/ckpt_epoch_27.pth saving......
[2022-04-05 11:49:39 large] (utils.py 59): INFO output/large/default/ckpt_epoch_27.pth saved !!!
[2022-04-05 11:49:39 large] (main.py 148): INFO Max accuracy: 67.58%
[2022-04-05 11:49:47 large] (main.py 226): INFO Train: [28/300][0/2502]	eta 5:13:32 lr 0.000489	time 7.5191 (7.5191)	loss 3.7734 (3.7734)	grad_norm 2.4688 (2.4688)	mem 8931MB
[2022-04-05 11:50:40 large] (main.py 226): INFO Train: [28/300][100/2502]	eta 0:24:10 lr 0.000489	time 1.2252 (0.6038)	loss 3.1250 (3.9382)	grad_norm 2.4994 (2.4118)	mem 8931MB
[2022-04-05 11:51:43 large] (main.py 226): INFO Train: [28/300][200/2502]	eta 0:23:32 lr 0.000489	time 0.5203 (0.6134)	loss 3.0575 (3.9556)	grad_norm 1.9215 (2.4285)	mem 8931MB
[2022-04-05 11:52:45 large] (main.py 226): INFO Train: [28/300][300/2502]	eta 0:22:42 lr 0.000489	time 0.5894 (0.6188)	loss 4.3605 (3.9913)	grad_norm 1.8077 (2.3657)	mem 8931MB
[2022-04-05 11:53:47 large] (main.py 226): INFO Train: [28/300][400/2502]	eta 0:21:39 lr 0.000489	time 0.6001 (0.6184)	loss 4.5868 (4.0210)	grad_norm 2.5864 (2.3368)	mem 8931MB
[2022-04-05 11:54:50 large] (main.py 226): INFO Train: [28/300][500/2502]	eta 0:20:42 lr 0.000489	time 0.5997 (0.6208)	loss 4.3424 (4.0191)	grad_norm 1.9308 (2.3382)	mem 8931MB
[2022-04-05 11:55:51 large] (main.py 226): INFO Train: [28/300][600/2502]	eta 0:19:37 lr 0.000489	time 0.6370 (0.6191)	loss 4.0275 (4.0173)	grad_norm 2.5380 (2.3362)	mem 8931MB
[2022-04-05 11:56:53 large] (main.py 226): INFO Train: [28/300][700/2502]	eta 0:18:35 lr 0.000489	time 0.5663 (0.6189)	loss 3.1462 (4.0225)	grad_norm 2.4035 (2.3452)	mem 8931MB
[2022-04-05 11:57:54 large] (main.py 226): INFO Train: [28/300][800/2502]	eta 0:17:32 lr 0.000489	time 0.6273 (0.6182)	loss 4.2482 (4.0143)	grad_norm 1.9623 (2.3491)	mem 8931MB
[2022-04-05 11:58:56 large] (main.py 226): INFO Train: [28/300][900/2502]	eta 0:16:30 lr 0.000489	time 0.6458 (0.6180)	loss 4.0791 (4.0168)	grad_norm 2.8475 (2.3522)	mem 8931MB
[2022-04-05 11:59:58 large] (main.py 226): INFO Train: [28/300][1000/2502]	eta 0:15:28 lr 0.000489	time 0.6076 (0.6180)	loss 4.6711 (4.0256)	grad_norm 3.5902 (2.3497)	mem 8931MB
[2022-04-05 12:01:00 large] (main.py 226): INFO Train: [28/300][1100/2502]	eta 0:14:26 lr 0.000489	time 0.5575 (0.6180)	loss 3.2056 (4.0155)	grad_norm 2.2618 (2.3507)	mem 8931MB
[2022-04-05 12:02:02 large] (main.py 226): INFO Train: [28/300][1200/2502]	eta 0:13:25 lr 0.000489	time 0.5937 (0.6184)	loss 3.3121 (4.0125)	grad_norm 2.1651 (2.3466)	mem 8931MB
[2022-04-05 12:03:04 large] (main.py 226): INFO Train: [28/300][1300/2502]	eta 0:12:23 lr 0.000489	time 0.6188 (0.6185)	loss 4.9921 (4.0057)	grad_norm 2.0586 (2.3450)	mem 8931MB
[2022-04-05 12:04:05 large] (main.py 226): INFO Train: [28/300][1400/2502]	eta 0:11:21 lr 0.000489	time 0.6232 (0.6183)	loss 3.1177 (4.0071)	grad_norm 2.7036 (2.3397)	mem 8931MB
[2022-04-05 12:05:07 large] (main.py 226): INFO Train: [28/300][1500/2502]	eta 0:10:19 lr 0.000489	time 0.6724 (0.6183)	loss 3.7460 (4.0002)	grad_norm 1.7356 (2.3441)	mem 8931MB
[2022-04-05 12:06:10 large] (main.py 226): INFO Train: [28/300][1600/2502]	eta 0:09:18 lr 0.000489	time 0.6766 (0.6187)	loss 3.8175 (3.9997)	grad_norm 3.2067 (2.3479)	mem 8931MB
[2022-04-05 12:07:12 large] (main.py 226): INFO Train: [28/300][1700/2502]	eta 0:08:16 lr 0.000489	time 0.5744 (0.6186)	loss 4.2171 (4.0045)	grad_norm 2.5309 (2.3481)	mem 8931MB
[2022-04-05 12:08:06 large] (main.py 226): INFO Train: [28/300][1800/2502]	eta 0:07:11 lr 0.000489	time 0.5916 (0.6148)	loss 4.4161 (4.0016)	grad_norm 2.3269 (2.3519)	mem 8931MB
[2022-04-05 12:09:08 large] (main.py 226): INFO Train: [28/300][1900/2502]	eta 0:06:10 lr 0.000489	time 0.5008 (0.6147)	loss 4.2290 (3.9982)	grad_norm 1.8600 (2.3476)	mem 8931MB
[2022-04-05 12:10:09 large] (main.py 226): INFO Train: [28/300][2000/2502]	eta 0:05:08 lr 0.000489	time 0.6607 (0.6144)	loss 3.0913 (3.9996)	grad_norm 2.5439 (2.3516)	mem 8931MB
[2022-04-05 12:11:10 large] (main.py 226): INFO Train: [28/300][2100/2502]	eta 0:04:07 lr 0.000489	time 0.6132 (0.6146)	loss 3.3562 (3.9992)	grad_norm 2.4795 (2.3507)	mem 8931MB
[2022-04-05 12:12:13 large] (main.py 226): INFO Train: [28/300][2200/2502]	eta 0:03:05 lr 0.000489	time 0.6368 (0.6152)	loss 4.2477 (3.9970)	grad_norm 1.9821 (2.3458)	mem 8931MB
[2022-04-05 12:13:14 large] (main.py 226): INFO Train: [28/300][2300/2502]	eta 0:02:04 lr 0.000489	time 0.8306 (0.6148)	loss 3.4313 (3.9982)	grad_norm 2.1731 (2.3461)	mem 8931MB
[2022-04-05 12:14:17 large] (main.py 226): INFO Train: [28/300][2400/2502]	eta 0:01:02 lr 0.000489	time 0.5920 (0.6153)	loss 4.5139 (3.9962)	grad_norm 1.8902 (2.3465)	mem 8931MB
[2022-04-05 12:15:18 large] (main.py 226): INFO Train: [28/300][2500/2502]	eta 0:00:01 lr 0.000489	time 0.6232 (0.6152)	loss 3.7893 (3.9922)	grad_norm 2.7285 (2.3418)	mem 8931MB
[2022-04-05 12:15:19 large] (main.py 233): INFO EPOCH 28 training takes 0:25:39
[2022-04-05 12:15:25 large] (main.py 273): INFO Test: [0/98]	Time 5.824 (5.824)	Loss 1.5735 (1.5735)	Acc@1 68.555 (68.555)	Acc@5 88.281 (88.281)	Mem 8931MB
[2022-04-05 12:15:51 large] (main.py 279): INFO  * Acc@1 67.692 Acc@5 88.704
[2022-04-05 12:15:51 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 67.7%
[2022-04-05 12:15:51 large] (utils.py 57): INFO output/large/default/ckpt_epoch_28.pth saving......
[2022-04-05 12:15:52 large] (utils.py 59): INFO output/large/default/ckpt_epoch_28.pth saved !!!
[2022-04-05 12:15:52 large] (main.py 148): INFO Max accuracy: 67.69%
[2022-04-05 12:15:59 large] (main.py 226): INFO Train: [29/300][0/2502]	eta 5:01:02 lr 0.000489	time 7.2193 (7.2193)	loss 4.2374 (4.2374)	grad_norm 2.8937 (2.8937)	mem 8931MB
[2022-04-05 12:16:57 large] (main.py 226): INFO Train: [29/300][100/2502]	eta 0:25:57 lr 0.000489	time 0.6565 (0.6483)	loss 5.0379 (3.9249)	grad_norm 1.7915 (2.2900)	mem 8931MB
[2022-04-05 12:17:59 large] (main.py 226): INFO Train: [29/300][200/2502]	eta 0:24:14 lr 0.000489	time 0.6220 (0.6319)	loss 3.4547 (3.9541)	grad_norm 2.0505 (2.3331)	mem 8931MB
[2022-04-05 12:19:02 large] (main.py 226): INFO Train: [29/300][300/2502]	eta 0:23:10 lr 0.000489	time 0.4851 (0.6313)	loss 4.4303 (3.9625)	grad_norm 2.0434 (2.3798)	mem 8931MB
[2022-04-05 12:20:04 large] (main.py 226): INFO Train: [29/300][400/2502]	eta 0:22:00 lr 0.000489	time 0.6439 (0.6282)	loss 3.8998 (3.9777)	grad_norm 2.6183 (2.3814)	mem 8931MB
[2022-04-05 12:21:06 large] (main.py 226): INFO Train: [29/300][500/2502]	eta 0:20:53 lr 0.000489	time 0.6764 (0.6263)	loss 2.7654 (3.9896)	grad_norm 2.0574 (2.3852)	mem 8931MB
[2022-04-05 12:22:07 large] (main.py 226): INFO Train: [29/300][600/2502]	eta 0:19:47 lr 0.000488	time 0.6229 (0.6245)	loss 4.2637 (4.0040)	grad_norm 2.3110 (inf)	mem 8931MB
[2022-04-05 12:23:09 large] (main.py 226): INFO Train: [29/300][700/2502]	eta 0:18:42 lr 0.000488	time 0.6820 (0.6228)	loss 4.2805 (4.0071)	grad_norm 1.7062 (inf)	mem 8931MB
[2022-04-05 12:24:10 large] (main.py 226): INFO Train: [29/300][800/2502]	eta 0:17:38 lr 0.000488	time 0.5939 (0.6221)	loss 2.6047 (4.0044)	grad_norm 3.0167 (inf)	mem 8931MB
[2022-04-05 12:25:12 large] (main.py 226): INFO Train: [29/300][900/2502]	eta 0:16:35 lr 0.000488	time 0.6505 (0.6217)	loss 3.6901 (4.0025)	grad_norm 2.1467 (inf)	mem 8931MB
[2022-04-05 12:26:15 large] (main.py 226): INFO Train: [29/300][1000/2502]	eta 0:15:34 lr 0.000488	time 0.6770 (0.6221)	loss 3.6768 (3.9974)	grad_norm 2.1118 (inf)	mem 8931MB
[2022-04-05 12:27:17 large] (main.py 226): INFO Train: [29/300][1100/2502]	eta 0:14:32 lr 0.000488	time 0.7097 (0.6220)	loss 4.1574 (3.9935)	grad_norm 1.7832 (inf)	mem 8931MB
[2022-04-05 12:28:19 large] (main.py 226): INFO Train: [29/300][1200/2502]	eta 0:13:29 lr 0.000488	time 0.5783 (0.6218)	loss 4.2864 (3.9877)	grad_norm 2.3273 (inf)	mem 8931MB
[2022-04-05 12:29:21 large] (main.py 226): INFO Train: [29/300][1300/2502]	eta 0:12:27 lr 0.000488	time 0.5795 (0.6219)	loss 4.3571 (3.9895)	grad_norm 2.2418 (inf)	mem 8931MB
[2022-04-05 12:30:23 large] (main.py 226): INFO Train: [29/300][1400/2502]	eta 0:11:25 lr 0.000488	time 0.6410 (0.6220)	loss 4.3811 (3.9813)	grad_norm 3.0497 (inf)	mem 8931MB
[2022-04-05 12:31:26 large] (main.py 226): INFO Train: [29/300][1500/2502]	eta 0:10:23 lr 0.000488	time 0.6041 (0.6221)	loss 4.0450 (3.9836)	grad_norm 2.5145 (inf)	mem 8931MB
[2022-04-05 12:32:27 large] (main.py 226): INFO Train: [29/300][1600/2502]	eta 0:09:20 lr 0.000488	time 0.5346 (0.6216)	loss 4.2353 (3.9872)	grad_norm 3.1363 (inf)	mem 8931MB
[2022-04-05 12:33:30 large] (main.py 226): INFO Train: [29/300][1700/2502]	eta 0:08:19 lr 0.000488	time 0.6420 (0.6222)	loss 3.6232 (3.9792)	grad_norm 2.5479 (inf)	mem 8931MB
[2022-04-05 12:34:33 large] (main.py 226): INFO Train: [29/300][1800/2502]	eta 0:07:16 lr 0.000488	time 0.6433 (0.6223)	loss 3.6700 (3.9850)	grad_norm 2.2168 (inf)	mem 8931MB
[2022-04-05 12:35:35 large] (main.py 226): INFO Train: [29/300][1900/2502]	eta 0:06:14 lr 0.000488	time 0.6325 (0.6223)	loss 3.7903 (3.9823)	grad_norm 2.6358 (inf)	mem 8931MB
[2022-04-05 12:36:37 large] (main.py 226): INFO Train: [29/300][2000/2502]	eta 0:05:12 lr 0.000488	time 0.6465 (0.6224)	loss 4.4768 (3.9815)	grad_norm 1.8687 (inf)	mem 8931MB
[2022-04-05 12:37:40 large] (main.py 226): INFO Train: [29/300][2100/2502]	eta 0:04:10 lr 0.000488	time 0.5337 (0.6226)	loss 4.3659 (3.9846)	grad_norm 3.2444 (inf)	mem 8931MB
[2022-04-05 12:38:42 large] (main.py 226): INFO Train: [29/300][2200/2502]	eta 0:03:08 lr 0.000488	time 0.5759 (0.6226)	loss 4.5920 (3.9892)	grad_norm 1.6855 (inf)	mem 8931MB
[2022-04-05 12:39:45 large] (main.py 226): INFO Train: [29/300][2300/2502]	eta 0:02:05 lr 0.000488	time 0.7091 (0.6226)	loss 4.5825 (3.9899)	grad_norm 1.9388 (inf)	mem 8931MB
[2022-04-05 12:40:47 large] (main.py 226): INFO Train: [29/300][2400/2502]	eta 0:01:03 lr 0.000488	time 0.6113 (0.6227)	loss 4.2770 (3.9902)	grad_norm 2.1863 (inf)	mem 8931MB
[2022-04-05 12:41:49 large] (main.py 226): INFO Train: [29/300][2500/2502]	eta 0:00:01 lr 0.000488	time 0.5830 (0.6225)	loss 4.4494 (3.9868)	grad_norm 1.7993 (inf)	mem 8931MB
[2022-04-05 12:41:50 large] (main.py 233): INFO EPOCH 29 training takes 0:25:57
[2022-04-05 12:41:56 large] (main.py 273): INFO Test: [0/98]	Time 5.993 (5.993)	Loss 1.4698 (1.4698)	Acc@1 68.750 (68.750)	Acc@5 89.453 (89.453)	Mem 8931MB
[2022-04-05 12:42:22 large] (main.py 279): INFO  * Acc@1 68.532 Acc@5 88.912
[2022-04-05 12:42:22 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 68.5%
[2022-04-05 12:42:22 large] (utils.py 57): INFO output/large/default/ckpt_epoch_29.pth saving......
[2022-04-05 12:42:23 large] (utils.py 59): INFO output/large/default/ckpt_epoch_29.pth saved !!!
[2022-04-05 12:42:23 large] (main.py 148): INFO Max accuracy: 68.53%
[2022-04-05 12:42:31 large] (main.py 226): INFO Train: [30/300][0/2502]	eta 5:17:24 lr 0.000488	time 7.6117 (7.6117)	loss 3.8846 (3.8846)	grad_norm 2.4750 (2.4750)	mem 8931MB
[2022-04-05 12:43:22 large] (main.py 226): INFO Train: [30/300][100/2502]	eta 0:23:13 lr 0.000488	time 0.5944 (0.5802)	loss 4.6293 (3.9163)	grad_norm 2.9132 (2.3299)	mem 8931MB
[2022-04-05 12:44:25 large] (main.py 226): INFO Train: [30/300][200/2502]	eta 0:23:10 lr 0.000488	time 0.6503 (0.6041)	loss 3.9915 (3.9599)	grad_norm 1.9649 (2.3208)	mem 8931MB
[2022-04-05 12:45:28 large] (main.py 226): INFO Train: [30/300][300/2502]	eta 0:22:34 lr 0.000488	time 0.6837 (0.6149)	loss 5.0017 (3.9619)	grad_norm 2.9252 (2.3609)	mem 8931MB
[2022-04-05 12:46:33 large] (main.py 226): INFO Train: [30/300][400/2502]	eta 0:21:47 lr 0.000488	time 0.5847 (0.6220)	loss 4.4701 (3.9690)	grad_norm 2.0695 (2.3603)	mem 8931MB
[2022-04-05 12:47:36 large] (main.py 226): INFO Train: [30/300][500/2502]	eta 0:20:50 lr 0.000488	time 0.6247 (0.6245)	loss 4.0979 (3.9648)	grad_norm 2.6695 (2.3502)	mem 8931MB
[2022-04-05 12:48:40 large] (main.py 226): INFO Train: [30/300][600/2502]	eta 0:19:51 lr 0.000488	time 0.7762 (0.6264)	loss 4.2536 (3.9871)	grad_norm 2.1850 (2.3532)	mem 8931MB
[2022-04-05 12:49:44 large] (main.py 226): INFO Train: [30/300][700/2502]	eta 0:18:52 lr 0.000488	time 1.2924 (0.6284)	loss 4.0983 (3.9942)	grad_norm 2.7499 (2.3596)	mem 8931MB
[2022-04-05 12:50:47 large] (main.py 226): INFO Train: [30/300][800/2502]	eta 0:17:50 lr 0.000488	time 0.6596 (0.6289)	loss 3.0815 (3.9846)	grad_norm 2.1001 (2.3607)	mem 8931MB
[2022-04-05 12:51:49 large] (main.py 226): INFO Train: [30/300][900/2502]	eta 0:16:45 lr 0.000488	time 0.6071 (0.6279)	loss 2.7342 (3.9769)	grad_norm 2.6357 (2.3588)	mem 8931MB
[2022-04-05 12:52:51 large] (main.py 226): INFO Train: [30/300][1000/2502]	eta 0:15:41 lr 0.000488	time 0.6905 (0.6271)	loss 3.1055 (3.9671)	grad_norm 2.0289 (2.3530)	mem 8931MB
[2022-04-05 12:53:53 large] (main.py 226): INFO Train: [30/300][1100/2502]	eta 0:14:38 lr 0.000488	time 0.6358 (0.6268)	loss 2.7443 (3.9715)	grad_norm 3.0362 (inf)	mem 8931MB
[2022-04-05 12:54:56 large] (main.py 226): INFO Train: [30/300][1200/2502]	eta 0:13:36 lr 0.000487	time 0.6527 (0.6273)	loss 4.3792 (3.9717)	grad_norm 1.7161 (inf)	mem 8931MB
[2022-04-05 12:55:59 large] (main.py 226): INFO Train: [30/300][1300/2502]	eta 0:12:33 lr 0.000487	time 0.5095 (0.6270)	loss 4.5542 (3.9659)	grad_norm 2.0830 (inf)	mem 8931MB
[2022-04-05 12:57:01 large] (main.py 226): INFO Train: [30/300][1400/2502]	eta 0:11:30 lr 0.000487	time 0.5815 (0.6264)	loss 3.7369 (3.9623)	grad_norm 1.8934 (inf)	mem 8931MB
[2022-04-05 12:58:03 large] (main.py 226): INFO Train: [30/300][1500/2502]	eta 0:10:27 lr 0.000487	time 0.6824 (0.6262)	loss 4.0259 (3.9618)	grad_norm 2.0759 (inf)	mem 8931MB
[2022-04-05 12:59:05 large] (main.py 226): INFO Train: [30/300][1600/2502]	eta 0:09:24 lr 0.000487	time 0.6273 (0.6257)	loss 4.9336 (3.9631)	grad_norm 3.0996 (inf)	mem 8931MB
[2022-04-05 13:00:08 large] (main.py 226): INFO Train: [30/300][1700/2502]	eta 0:08:22 lr 0.000487	time 0.6398 (0.6260)	loss 4.2175 (3.9634)	grad_norm 1.6821 (inf)	mem 8931MB
[2022-04-05 13:01:09 large] (main.py 226): INFO Train: [30/300][1800/2502]	eta 0:07:19 lr 0.000487	time 0.6053 (0.6254)	loss 4.2541 (3.9662)	grad_norm 2.0859 (inf)	mem 8931MB
[2022-04-05 13:02:12 large] (main.py 226): INFO Train: [30/300][1900/2502]	eta 0:06:16 lr 0.000487	time 0.6610 (0.6253)	loss 3.5105 (3.9675)	grad_norm 2.3901 (inf)	mem 8931MB
[2022-04-05 13:03:14 large] (main.py 226): INFO Train: [30/300][2000/2502]	eta 0:05:13 lr 0.000487	time 0.6333 (0.6251)	loss 4.1063 (3.9636)	grad_norm 2.4004 (inf)	mem 8931MB
[2022-04-05 13:04:16 large] (main.py 226): INFO Train: [30/300][2100/2502]	eta 0:04:11 lr 0.000487	time 0.6707 (0.6251)	loss 4.7674 (3.9662)	grad_norm 2.4824 (inf)	mem 8931MB
[2022-04-05 13:05:19 large] (main.py 226): INFO Train: [30/300][2200/2502]	eta 0:03:08 lr 0.000487	time 0.6132 (0.6252)	loss 4.2172 (3.9708)	grad_norm 3.1639 (inf)	mem 8931MB
[2022-04-05 13:06:20 large] (main.py 226): INFO Train: [30/300][2300/2502]	eta 0:02:06 lr 0.000487	time 0.7358 (0.6246)	loss 4.2099 (3.9734)	grad_norm 2.1731 (inf)	mem 8931MB
[2022-04-05 13:07:22 large] (main.py 226): INFO Train: [30/300][2400/2502]	eta 0:01:03 lr 0.000487	time 0.6444 (0.6243)	loss 4.4123 (3.9733)	grad_norm 4.1207 (inf)	mem 8931MB
[2022-04-05 13:08:25 large] (main.py 226): INFO Train: [30/300][2500/2502]	eta 0:00:01 lr 0.000487	time 0.5939 (0.6247)	loss 3.8170 (3.9709)	grad_norm 2.5157 (inf)	mem 8931MB
[2022-04-05 13:08:26 large] (main.py 233): INFO EPOCH 30 training takes 0:26:03
[2022-04-05 13:08:33 large] (main.py 273): INFO Test: [0/98]	Time 6.411 (6.411)	Loss 1.4412 (1.4412)	Acc@1 70.508 (70.508)	Acc@5 89.453 (89.453)	Mem 8931MB
[2022-04-05 13:08:59 large] (main.py 279): INFO  * Acc@1 68.610 Acc@5 88.988
[2022-04-05 13:08:59 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 68.6%
[2022-04-05 13:08:59 large] (utils.py 57): INFO output/large/default/ckpt_epoch_30.pth saving......
[2022-04-05 13:09:00 large] (utils.py 59): INFO output/large/default/ckpt_epoch_30.pth saved !!!
[2022-04-05 13:09:00 large] (main.py 148): INFO Max accuracy: 68.61%
[2022-04-05 13:09:08 large] (main.py 226): INFO Train: [31/300][0/2502]	eta 5:46:44 lr 0.000487	time 8.3152 (8.3152)	loss 4.0502 (4.0502)	grad_norm 1.9941 (1.9941)	mem 8931MB
[2022-04-05 13:10:03 large] (main.py 226): INFO Train: [31/300][100/2502]	eta 0:25:14 lr 0.000487	time 0.7122 (0.6305)	loss 4.3745 (3.8964)	grad_norm 2.1655 (2.3103)	mem 8931MB
[2022-04-05 13:11:06 large] (main.py 226): INFO Train: [31/300][200/2502]	eta 0:24:13 lr 0.000487	time 0.6296 (0.6314)	loss 4.3420 (3.8634)	grad_norm 2.8719 (2.3744)	mem 8931MB
[2022-04-05 13:12:10 large] (main.py 226): INFO Train: [31/300][300/2502]	eta 0:23:12 lr 0.000487	time 0.6091 (0.6323)	loss 3.8995 (3.8957)	grad_norm 2.2795 (2.3565)	mem 8931MB
[2022-04-05 13:13:13 large] (main.py 226): INFO Train: [31/300][400/2502]	eta 0:22:09 lr 0.000487	time 0.7253 (0.6324)	loss 4.2889 (3.9169)	grad_norm 2.1061 (2.3382)	mem 8931MB
[2022-04-05 13:14:16 large] (main.py 226): INFO Train: [31/300][500/2502]	eta 0:21:06 lr 0.000487	time 0.6610 (0.6324)	loss 3.9295 (3.9153)	grad_norm 2.0438 (2.3500)	mem 8931MB
[2022-04-05 13:15:18 large] (main.py 226): INFO Train: [31/300][600/2502]	eta 0:19:57 lr 0.000487	time 0.5989 (0.6294)	loss 3.7148 (3.9255)	grad_norm 2.0238 (2.3466)	mem 8931MB
[2022-04-05 13:16:20 large] (main.py 226): INFO Train: [31/300][700/2502]	eta 0:18:52 lr 0.000487	time 0.5875 (0.6285)	loss 4.4115 (3.9301)	grad_norm 2.1634 (inf)	mem 8931MB
[2022-04-05 13:17:23 large] (main.py 226): INFO Train: [31/300][800/2502]	eta 0:17:49 lr 0.000487	time 0.6894 (0.6283)	loss 2.9531 (3.9274)	grad_norm 2.2096 (inf)	mem 8931MB
[2022-04-05 13:18:26 large] (main.py 226): INFO Train: [31/300][900/2502]	eta 0:16:46 lr 0.000487	time 0.6306 (0.6283)	loss 3.3304 (3.9200)	grad_norm 2.0945 (inf)	mem 8931MB
[2022-04-05 13:19:29 large] (main.py 226): INFO Train: [31/300][1000/2502]	eta 0:15:44 lr 0.000487	time 0.6457 (0.6285)	loss 3.9172 (3.9208)	grad_norm 2.2185 (inf)	mem 8931MB
[2022-04-05 13:20:32 large] (main.py 226): INFO Train: [31/300][1100/2502]	eta 0:14:41 lr 0.000487	time 0.7232 (0.6287)	loss 4.3246 (3.9289)	grad_norm 2.7320 (inf)	mem 8931MB
[2022-04-05 13:21:34 large] (main.py 226): INFO Train: [31/300][1200/2502]	eta 0:13:38 lr 0.000487	time 0.6330 (0.6284)	loss 4.5397 (3.9320)	grad_norm 2.0182 (inf)	mem 8931MB
[2022-04-05 13:22:38 large] (main.py 226): INFO Train: [31/300][1300/2502]	eta 0:12:35 lr 0.000487	time 0.6392 (0.6287)	loss 3.4844 (3.9282)	grad_norm 4.7319 (inf)	mem 8931MB
[2022-04-05 13:23:40 large] (main.py 226): INFO Train: [31/300][1400/2502]	eta 0:11:32 lr 0.000487	time 0.6288 (0.6282)	loss 3.3618 (3.9285)	grad_norm 2.2199 (inf)	mem 8931MB
[2022-04-05 13:24:42 large] (main.py 226): INFO Train: [31/300][1500/2502]	eta 0:10:29 lr 0.000487	time 0.6421 (0.6282)	loss 3.6672 (3.9289)	grad_norm 3.2827 (inf)	mem 8931MB
[2022-04-05 13:25:45 large] (main.py 226): INFO Train: [31/300][1600/2502]	eta 0:09:26 lr 0.000487	time 0.6055 (0.6281)	loss 4.1526 (3.9253)	grad_norm 3.7656 (inf)	mem 8931MB
[2022-04-05 13:26:46 large] (main.py 226): INFO Train: [31/300][1700/2502]	eta 0:08:23 lr 0.000487	time 0.6047 (0.6272)	loss 4.3595 (3.9362)	grad_norm 1.9100 (inf)	mem 8931MB
[2022-04-05 13:27:45 large] (main.py 226): INFO Train: [31/300][1800/2502]	eta 0:07:18 lr 0.000486	time 0.5055 (0.6247)	loss 4.3485 (3.9383)	grad_norm 2.8097 (inf)	mem 8931MB
[2022-04-05 13:28:43 large] (main.py 226): INFO Train: [31/300][1900/2502]	eta 0:06:14 lr 0.000486	time 0.5931 (0.6225)	loss 4.3191 (3.9414)	grad_norm 1.8988 (inf)	mem 8931MB
[2022-04-05 13:29:46 large] (main.py 226): INFO Train: [31/300][2000/2502]	eta 0:05:12 lr 0.000486	time 0.6118 (0.6227)	loss 4.6681 (3.9393)	grad_norm 1.8529 (inf)	mem 8931MB
[2022-04-05 13:30:47 large] (main.py 226): INFO Train: [31/300][2100/2502]	eta 0:04:10 lr 0.000486	time 0.6385 (0.6225)	loss 4.2970 (3.9362)	grad_norm 1.6872 (inf)	mem 8931MB
[2022-04-05 13:31:46 large] (main.py 226): INFO Train: [31/300][2200/2502]	eta 0:03:07 lr 0.000486	time 0.4846 (0.6210)	loss 4.1478 (3.9347)	grad_norm 2.1741 (inf)	mem 8931MB
[2022-04-05 13:32:45 large] (main.py 226): INFO Train: [31/300][2300/2502]	eta 0:02:05 lr 0.000486	time 0.6692 (0.6193)	loss 4.4714 (3.9334)	grad_norm 2.2591 (inf)	mem 8931MB
[2022-04-05 13:33:47 large] (main.py 226): INFO Train: [31/300][2400/2502]	eta 0:01:03 lr 0.000486	time 0.6134 (0.6195)	loss 3.8289 (3.9323)	grad_norm 2.6409 (inf)	mem 8931MB
[2022-04-05 13:34:50 large] (main.py 226): INFO Train: [31/300][2500/2502]	eta 0:00:01 lr 0.000486	time 0.5728 (0.6199)	loss 3.9864 (3.9322)	grad_norm 2.5859 (inf)	mem 8931MB
[2022-04-05 13:34:51 large] (main.py 233): INFO EPOCH 31 training takes 0:25:51
[2022-04-05 13:34:57 large] (main.py 273): INFO Test: [0/98]	Time 5.968 (5.968)	Loss 1.3399 (1.3399)	Acc@1 70.117 (70.117)	Acc@5 90.039 (90.039)	Mem 8931MB
[2022-04-05 13:35:23 large] (main.py 279): INFO  * Acc@1 69.138 Acc@5 89.196
[2022-04-05 13:35:23 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 69.1%
[2022-04-05 13:35:23 large] (utils.py 57): INFO output/large/default/ckpt_epoch_31.pth saving......
[2022-04-05 13:35:24 large] (utils.py 59): INFO output/large/default/ckpt_epoch_31.pth saved !!!
[2022-04-05 13:35:24 large] (main.py 148): INFO Max accuracy: 69.14%
[2022-04-05 13:35:32 large] (main.py 226): INFO Train: [32/300][0/2502]	eta 5:22:31 lr 0.000486	time 7.7346 (7.7346)	loss 3.9425 (3.9425)	grad_norm 4.0204 (4.0204)	mem 8931MB
[2022-04-05 13:36:27 large] (main.py 226): INFO Train: [32/300][100/2502]	eta 0:25:08 lr 0.000486	time 0.6540 (0.6282)	loss 3.9526 (3.9010)	grad_norm 2.0250 (2.3441)	mem 8931MB
[2022-04-05 13:37:31 large] (main.py 226): INFO Train: [32/300][200/2502]	eta 0:24:17 lr 0.000486	time 0.6103 (0.6332)	loss 3.4705 (3.9062)	grad_norm 1.9032 (2.3782)	mem 8931MB
[2022-04-05 13:38:23 large] (main.py 226): INFO Train: [32/300][300/2502]	eta 0:21:54 lr 0.000486	time 0.5647 (0.5968)	loss 3.2150 (3.9116)	grad_norm 1.6520 (2.3705)	mem 8931MB
[2022-04-05 13:39:25 large] (main.py 226): INFO Train: [32/300][400/2502]	eta 0:21:06 lr 0.000486	time 0.6167 (0.6025)	loss 3.6179 (3.9058)	grad_norm 2.6055 (inf)	mem 8931MB
[2022-04-05 13:40:29 large] (main.py 226): INFO Train: [32/300][500/2502]	eta 0:20:18 lr 0.000486	time 0.7062 (0.6085)	loss 3.3534 (3.9065)	grad_norm 2.0925 (inf)	mem 8931MB
[2022-04-05 13:41:31 large] (main.py 226): INFO Train: [32/300][600/2502]	eta 0:19:23 lr 0.000486	time 0.5055 (0.6116)	loss 4.7748 (3.9156)	grad_norm 2.0164 (inf)	mem 8931MB
[2022-04-05 13:42:34 large] (main.py 226): INFO Train: [32/300][700/2502]	eta 0:18:26 lr 0.000486	time 0.5897 (0.6142)	loss 3.7018 (3.9122)	grad_norm 3.5433 (inf)	mem 8931MB
[2022-04-05 13:43:38 large] (main.py 226): INFO Train: [32/300][800/2502]	eta 0:17:30 lr 0.000486	time 0.5790 (0.6173)	loss 4.7440 (3.9160)	grad_norm 2.0885 (inf)	mem 8931MB
[2022-04-05 13:44:41 large] (main.py 226): INFO Train: [32/300][900/2502]	eta 0:16:30 lr 0.000486	time 0.6831 (0.6182)	loss 4.1834 (3.9282)	grad_norm 2.0335 (inf)	mem 8931MB
[2022-04-05 13:45:43 large] (main.py 226): INFO Train: [32/300][1000/2502]	eta 0:15:29 lr 0.000486	time 0.6597 (0.6189)	loss 4.0124 (3.9334)	grad_norm 2.6022 (inf)	mem 8931MB
[2022-04-05 13:46:45 large] (main.py 226): INFO Train: [32/300][1100/2502]	eta 0:14:27 lr 0.000486	time 0.6831 (0.6189)	loss 3.7469 (3.9310)	grad_norm 1.8615 (inf)	mem 8931MB
[2022-04-05 13:47:48 large] (main.py 226): INFO Train: [32/300][1200/2502]	eta 0:13:26 lr 0.000486	time 0.5003 (0.6197)	loss 4.0834 (3.9285)	grad_norm 1.7253 (inf)	mem 8931MB
[2022-04-05 13:48:51 large] (main.py 226): INFO Train: [32/300][1300/2502]	eta 0:12:25 lr 0.000486	time 0.6535 (0.6203)	loss 4.3018 (3.9250)	grad_norm 2.4071 (inf)	mem 8931MB
[2022-04-05 13:49:54 large] (main.py 226): INFO Train: [32/300][1400/2502]	eta 0:11:24 lr 0.000486	time 0.6019 (0.6209)	loss 4.1399 (3.9225)	grad_norm 2.2991 (inf)	mem 8931MB
[2022-04-05 13:50:56 large] (main.py 226): INFO Train: [32/300][1500/2502]	eta 0:10:22 lr 0.000486	time 0.4803 (0.6213)	loss 3.9193 (3.9162)	grad_norm 2.6630 (inf)	mem 8931MB
[2022-04-05 13:51:58 large] (main.py 226): INFO Train: [32/300][1600/2502]	eta 0:09:20 lr 0.000486	time 0.6675 (0.6213)	loss 3.9194 (3.9172)	grad_norm 2.9837 (inf)	mem 8931MB
[2022-04-05 13:53:01 large] (main.py 226): INFO Train: [32/300][1700/2502]	eta 0:08:18 lr 0.000486	time 0.6447 (0.6218)	loss 4.7114 (3.9141)	grad_norm 1.8736 (inf)	mem 8931MB
[2022-04-05 13:54:04 large] (main.py 226): INFO Train: [32/300][1800/2502]	eta 0:07:16 lr 0.000486	time 0.6083 (0.6218)	loss 3.9737 (3.9174)	grad_norm 1.7308 (inf)	mem 8931MB
[2022-04-05 13:55:06 large] (main.py 226): INFO Train: [32/300][1900/2502]	eta 0:06:14 lr 0.000486	time 0.5559 (0.6219)	loss 3.4405 (3.9184)	grad_norm 2.8558 (inf)	mem 8931MB
[2022-04-05 13:56:09 large] (main.py 226): INFO Train: [32/300][2000/2502]	eta 0:05:12 lr 0.000486	time 0.6713 (0.6224)	loss 4.2343 (3.9262)	grad_norm 2.0120 (inf)	mem 8931MB
[2022-04-05 13:57:12 large] (main.py 226): INFO Train: [32/300][2100/2502]	eta 0:04:10 lr 0.000486	time 0.6132 (0.6227)	loss 4.3383 (3.9274)	grad_norm 1.9469 (inf)	mem 8931MB
[2022-04-05 13:58:16 large] (main.py 226): INFO Train: [32/300][2200/2502]	eta 0:03:08 lr 0.000485	time 0.6815 (0.6233)	loss 4.2904 (3.9257)	grad_norm 2.0394 (inf)	mem 8931MB
[2022-04-05 13:59:19 large] (main.py 226): INFO Train: [32/300][2300/2502]	eta 0:02:05 lr 0.000485	time 0.6189 (0.6237)	loss 4.2283 (3.9244)	grad_norm 2.0042 (inf)	mem 8931MB
[2022-04-05 14:00:21 large] (main.py 226): INFO Train: [32/300][2400/2502]	eta 0:01:03 lr 0.000485	time 0.6258 (0.6237)	loss 4.2509 (3.9263)	grad_norm 2.2942 (inf)	mem 8931MB
[2022-04-05 14:01:23 large] (main.py 226): INFO Train: [32/300][2500/2502]	eta 0:00:01 lr 0.000485	time 0.5788 (0.6234)	loss 3.8678 (3.9286)	grad_norm 1.9505 (inf)	mem 8931MB
[2022-04-05 14:01:24 large] (main.py 233): INFO EPOCH 32 training takes 0:26:00
[2022-04-05 14:01:30 large] (main.py 273): INFO Test: [0/98]	Time 6.252 (6.252)	Loss 1.4213 (1.4213)	Acc@1 69.922 (69.922)	Acc@5 89.648 (89.648)	Mem 8931MB
[2022-04-05 14:01:56 large] (main.py 279): INFO  * Acc@1 69.220 Acc@5 89.428
[2022-04-05 14:01:56 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 69.2%
[2022-04-05 14:01:56 large] (utils.py 57): INFO output/large/default/ckpt_epoch_32.pth saving......
[2022-04-05 14:01:57 large] (utils.py 59): INFO output/large/default/ckpt_epoch_32.pth saved !!!
[2022-04-05 14:01:57 large] (main.py 148): INFO Max accuracy: 69.22%
[2022-04-05 14:02:05 large] (main.py 226): INFO Train: [33/300][0/2502]	eta 5:28:24 lr 0.000485	time 7.8756 (7.8756)	loss 3.0922 (3.0922)	grad_norm 2.0577 (2.0577)	mem 8931MB
[2022-04-05 14:02:57 large] (main.py 226): INFO Train: [33/300][100/2502]	eta 0:24:02 lr 0.000485	time 0.5852 (0.6004)	loss 3.5719 (3.9172)	grad_norm 2.4920 (2.4296)	mem 8931MB
[2022-04-05 14:04:01 large] (main.py 226): INFO Train: [33/300][200/2502]	eta 0:23:37 lr 0.000485	time 0.6431 (0.6158)	loss 3.3775 (3.9368)	grad_norm 2.4320 (2.3698)	mem 8931MB
[2022-04-05 14:05:04 large] (main.py 226): INFO Train: [33/300][300/2502]	eta 0:22:46 lr 0.000485	time 0.6305 (0.6207)	loss 3.9460 (3.9258)	grad_norm 2.2718 (2.3358)	mem 8931MB
[2022-04-05 14:06:08 large] (main.py 226): INFO Train: [33/300][400/2502]	eta 0:21:55 lr 0.000485	time 0.6146 (0.6260)	loss 4.1562 (3.9230)	grad_norm 2.0166 (2.3572)	mem 8931MB
[2022-04-05 14:07:11 large] (main.py 226): INFO Train: [33/300][500/2502]	eta 0:20:55 lr 0.000485	time 0.7779 (0.6269)	loss 4.0069 (3.9007)	grad_norm 2.0098 (2.3634)	mem 8931MB
[2022-04-05 14:08:14 large] (main.py 226): INFO Train: [33/300][600/2502]	eta 0:19:54 lr 0.000485	time 0.6710 (0.6279)	loss 3.8405 (3.9115)	grad_norm 1.8514 (2.3529)	mem 8931MB
[2022-04-05 14:09:17 large] (main.py 226): INFO Train: [33/300][700/2502]	eta 0:18:51 lr 0.000485	time 0.6320 (0.6279)	loss 2.9969 (3.9184)	grad_norm 2.2675 (2.3349)	mem 8931MB
[2022-04-05 14:10:20 large] (main.py 226): INFO Train: [33/300][800/2502]	eta 0:17:48 lr 0.000485	time 0.6205 (0.6280)	loss 3.9309 (3.9128)	grad_norm 2.0491 (2.3359)	mem 8931MB
[2022-04-05 14:11:23 large] (main.py 226): INFO Train: [33/300][900/2502]	eta 0:16:46 lr 0.000485	time 0.6708 (0.6285)	loss 3.1744 (3.9102)	grad_norm 2.2667 (2.3287)	mem 8931MB
[2022-04-05 14:12:25 large] (main.py 226): INFO Train: [33/300][1000/2502]	eta 0:15:42 lr 0.000485	time 0.6088 (0.6273)	loss 3.1059 (3.9123)	grad_norm 2.3317 (2.3440)	mem 8931MB
[2022-04-05 14:13:26 large] (main.py 226): INFO Train: [33/300][1100/2502]	eta 0:14:37 lr 0.000485	time 0.6321 (0.6261)	loss 4.3859 (3.9181)	grad_norm 1.8254 (2.3389)	mem 8931MB
[2022-04-05 14:14:28 large] (main.py 226): INFO Train: [33/300][1200/2502]	eta 0:13:34 lr 0.000485	time 0.5989 (0.6255)	loss 4.1574 (3.9185)	grad_norm 2.2432 (2.3387)	mem 8931MB
[2022-04-05 14:15:30 large] (main.py 226): INFO Train: [33/300][1300/2502]	eta 0:12:31 lr 0.000485	time 0.6715 (0.6251)	loss 2.9581 (3.9169)	grad_norm 2.2681 (2.3380)	mem 8931MB
[2022-04-05 14:16:32 large] (main.py 226): INFO Train: [33/300][1400/2502]	eta 0:11:28 lr 0.000485	time 0.5746 (0.6245)	loss 4.2839 (3.9153)	grad_norm 2.3185 (2.3337)	mem 8931MB
[2022-04-05 14:17:33 large] (main.py 226): INFO Train: [33/300][1500/2502]	eta 0:10:25 lr 0.000485	time 0.6781 (0.6238)	loss 4.1293 (3.9154)	grad_norm 2.0897 (2.3268)	mem 8931MB
[2022-04-05 14:18:36 large] (main.py 226): INFO Train: [33/300][1600/2502]	eta 0:09:23 lr 0.000485	time 0.5537 (0.6242)	loss 4.3291 (3.9190)	grad_norm 2.0315 (2.3307)	mem 8931MB
[2022-04-05 14:19:40 large] (main.py 226): INFO Train: [33/300][1700/2502]	eta 0:08:21 lr 0.000485	time 0.6060 (0.6248)	loss 4.1759 (3.9200)	grad_norm 1.7941 (2.3351)	mem 8931MB
[2022-04-05 14:20:42 large] (main.py 226): INFO Train: [33/300][1800/2502]	eta 0:07:18 lr 0.000485	time 0.7187 (0.6248)	loss 4.5717 (3.9223)	grad_norm 1.8341 (2.3334)	mem 8931MB
[2022-04-05 14:21:44 large] (main.py 226): INFO Train: [33/300][1900/2502]	eta 0:06:15 lr 0.000485	time 0.6840 (0.6245)	loss 4.4230 (3.9204)	grad_norm 2.2183 (2.3293)	mem 8931MB
[2022-04-05 14:22:47 large] (main.py 226): INFO Train: [33/300][2000/2502]	eta 0:05:13 lr 0.000485	time 0.6841 (0.6248)	loss 4.0646 (3.9182)	grad_norm 3.6898 (nan)	mem 8931MB
[2022-04-05 14:23:50 large] (main.py 226): INFO Train: [33/300][2100/2502]	eta 0:04:11 lr 0.000485	time 0.6106 (0.6250)	loss 4.2346 (3.9203)	grad_norm 2.0053 (nan)	mem 8931MB
[2022-04-05 14:24:54 large] (main.py 226): INFO Train: [33/300][2200/2502]	eta 0:03:08 lr 0.000485	time 0.6617 (0.6255)	loss 4.2854 (3.9235)	grad_norm 1.8647 (nan)	mem 8931MB
[2022-04-05 14:25:56 large] (main.py 226): INFO Train: [33/300][2300/2502]	eta 0:02:06 lr 0.000485	time 0.6847 (0.6254)	loss 2.8326 (3.9262)	grad_norm 1.9407 (nan)	mem 8931MB
[2022-04-05 14:26:57 large] (main.py 226): INFO Train: [33/300][2400/2502]	eta 0:01:03 lr 0.000485	time 0.6331 (0.6246)	loss 4.7780 (3.9276)	grad_norm 2.6570 (nan)	mem 8931MB
[2022-04-05 14:27:59 large] (main.py 226): INFO Train: [33/300][2500/2502]	eta 0:00:01 lr 0.000484	time 0.6604 (0.6247)	loss 3.9192 (3.9237)	grad_norm 2.3958 (nan)	mem 8931MB
[2022-04-05 14:28:00 large] (main.py 233): INFO EPOCH 33 training takes 0:26:03
[2022-04-05 14:28:07 large] (main.py 273): INFO Test: [0/98]	Time 6.775 (6.775)	Loss 1.4048 (1.4048)	Acc@1 70.508 (70.508)	Acc@5 88.086 (88.086)	Mem 8931MB
[2022-04-05 14:28:32 large] (main.py 279): INFO  * Acc@1 69.590 Acc@5 89.596
[2022-04-05 14:28:32 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 69.6%
[2022-04-05 14:28:32 large] (utils.py 57): INFO output/large/default/ckpt_epoch_33.pth saving......
[2022-04-05 14:28:33 large] (utils.py 59): INFO output/large/default/ckpt_epoch_33.pth saved !!!
[2022-04-05 14:28:33 large] (main.py 148): INFO Max accuracy: 69.59%
[2022-04-05 14:28:42 large] (main.py 226): INFO Train: [34/300][0/2502]	eta 5:47:40 lr 0.000484	time 8.3376 (8.3376)	loss 4.8354 (4.8354)	grad_norm 3.8440 (3.8440)	mem 8931MB
[2022-04-05 14:29:37 large] (main.py 226): INFO Train: [34/300][100/2502]	eta 0:25:10 lr 0.000484	time 0.6296 (0.6287)	loss 2.7478 (3.8997)	grad_norm 2.4139 (2.3722)	mem 8931MB
[2022-04-05 14:30:40 large] (main.py 226): INFO Train: [34/300][200/2502]	eta 0:24:11 lr 0.000484	time 0.6389 (0.6305)	loss 2.5924 (3.8925)	grad_norm 2.8806 (2.4183)	mem 8931MB
[2022-04-05 14:31:44 large] (main.py 226): INFO Train: [34/300][300/2502]	eta 0:23:13 lr 0.000484	time 0.6122 (0.6327)	loss 4.5158 (3.8869)	grad_norm 2.2977 (2.3894)	mem 8931MB
[2022-04-05 14:32:47 large] (main.py 226): INFO Train: [34/300][400/2502]	eta 0:22:09 lr 0.000484	time 0.5925 (0.6327)	loss 4.3625 (3.8951)	grad_norm 2.4375 (2.3538)	mem 8931MB
[2022-04-05 14:33:51 large] (main.py 226): INFO Train: [34/300][500/2502]	eta 0:21:09 lr 0.000484	time 0.6222 (0.6342)	loss 4.1906 (3.8967)	grad_norm 1.7529 (2.3557)	mem 8931MB
[2022-04-05 14:34:55 large] (main.py 226): INFO Train: [34/300][600/2502]	eta 0:20:07 lr 0.000484	time 0.6489 (0.6346)	loss 3.3486 (3.8970)	grad_norm 1.7762 (2.3640)	mem 8931MB
[2022-04-05 14:35:58 large] (main.py 226): INFO Train: [34/300][700/2502]	eta 0:19:03 lr 0.000484	time 0.6644 (0.6346)	loss 4.2784 (3.9068)	grad_norm 2.4423 (2.3480)	mem 8931MB
[2022-04-05 14:37:02 large] (main.py 226): INFO Train: [34/300][800/2502]	eta 0:18:00 lr 0.000484	time 0.7673 (0.6349)	loss 2.7853 (3.9084)	grad_norm 2.1585 (2.3631)	mem 8931MB
[2022-04-05 14:38:04 large] (main.py 226): INFO Train: [34/300][900/2502]	eta 0:16:54 lr 0.000484	time 0.6415 (0.6335)	loss 3.5881 (3.8998)	grad_norm 2.2191 (2.3437)	mem 8931MB
[2022-04-05 14:39:07 large] (main.py 226): INFO Train: [34/300][1000/2502]	eta 0:15:51 lr 0.000484	time 0.6169 (0.6335)	loss 4.5702 (3.8928)	grad_norm 1.9982 (2.3452)	mem 8931MB
[2022-04-05 14:40:10 large] (main.py 226): INFO Train: [34/300][1100/2502]	eta 0:14:47 lr 0.000484	time 0.6584 (0.6331)	loss 2.9532 (3.8881)	grad_norm 2.4359 (2.3508)	mem 8931MB
[2022-04-05 14:41:14 large] (main.py 226): INFO Train: [34/300][1200/2502]	eta 0:13:44 lr 0.000484	time 0.7258 (0.6335)	loss 3.0956 (3.8850)	grad_norm 3.1188 (2.3434)	mem 8931MB
[2022-04-05 14:42:16 large] (main.py 226): INFO Train: [34/300][1300/2502]	eta 0:12:40 lr 0.000484	time 0.6629 (0.6324)	loss 3.3877 (3.8867)	grad_norm 3.1432 (2.3418)	mem 8931MB
[2022-04-05 14:43:20 large] (main.py 226): INFO Train: [34/300][1400/2502]	eta 0:11:37 lr 0.000484	time 0.7156 (0.6328)	loss 2.6995 (3.8890)	grad_norm 2.1581 (2.3505)	mem 8931MB
[2022-04-05 14:44:21 large] (main.py 226): INFO Train: [34/300][1500/2502]	eta 0:10:32 lr 0.000484	time 0.6188 (0.6317)	loss 3.9318 (3.8818)	grad_norm 2.3895 (2.3537)	mem 8931MB
[2022-04-05 14:45:23 large] (main.py 226): INFO Train: [34/300][1600/2502]	eta 0:09:28 lr 0.000484	time 0.6767 (0.6308)	loss 4.7796 (3.8823)	grad_norm 2.6471 (2.3528)	mem 8931MB
[2022-04-05 14:46:25 large] (main.py 226): INFO Train: [34/300][1700/2502]	eta 0:08:25 lr 0.000484	time 0.6047 (0.6303)	loss 3.7156 (3.8795)	grad_norm 1.8514 (inf)	mem 8931MB
[2022-04-05 14:47:28 large] (main.py 226): INFO Train: [34/300][1800/2502]	eta 0:07:22 lr 0.000484	time 0.6143 (0.6302)	loss 3.7317 (3.8778)	grad_norm 2.0038 (inf)	mem 8931MB
[2022-04-05 14:48:31 large] (main.py 226): INFO Train: [34/300][1900/2502]	eta 0:06:19 lr 0.000484	time 0.5770 (0.6303)	loss 3.3605 (3.8809)	grad_norm 2.1388 (inf)	mem 8931MB
[2022-04-05 14:49:35 large] (main.py 226): INFO Train: [34/300][2000/2502]	eta 0:05:16 lr 0.000484	time 0.6611 (0.6306)	loss 3.7557 (3.8800)	grad_norm 3.0095 (inf)	mem 8931MB
[2022-04-05 14:50:38 large] (main.py 226): INFO Train: [34/300][2100/2502]	eta 0:04:13 lr 0.000484	time 0.6673 (0.6307)	loss 2.9081 (3.8779)	grad_norm 2.0899 (inf)	mem 8931MB
[2022-04-05 14:51:42 large] (main.py 226): INFO Train: [34/300][2200/2502]	eta 0:03:10 lr 0.000484	time 0.6222 (0.6311)	loss 3.5397 (3.8830)	grad_norm 1.7452 (inf)	mem 8931MB
[2022-04-05 14:52:46 large] (main.py 226): INFO Train: [34/300][2300/2502]	eta 0:02:07 lr 0.000484	time 0.6676 (0.6312)	loss 3.1849 (3.8856)	grad_norm 1.8476 (inf)	mem 8931MB
[2022-04-05 14:53:49 large] (main.py 226): INFO Train: [34/300][2400/2502]	eta 0:01:04 lr 0.000484	time 0.5888 (0.6315)	loss 3.1314 (3.8850)	grad_norm 1.6958 (inf)	mem 8931MB
[2022-04-05 14:54:51 large] (main.py 226): INFO Train: [34/300][2500/2502]	eta 0:00:01 lr 0.000484	time 0.5123 (0.6308)	loss 3.0111 (3.8848)	grad_norm 2.6304 (inf)	mem 8931MB
[2022-04-05 14:54:52 large] (main.py 233): INFO EPOCH 34 training takes 0:26:18
[2022-04-05 14:54:58 large] (main.py 273): INFO Test: [0/98]	Time 5.909 (5.909)	Loss 1.4294 (1.4294)	Acc@1 69.336 (69.336)	Acc@5 89.844 (89.844)	Mem 8931MB
[2022-04-05 14:55:24 large] (main.py 279): INFO  * Acc@1 69.712 Acc@5 89.778
[2022-04-05 14:55:24 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 69.7%
[2022-04-05 14:55:24 large] (utils.py 57): INFO output/large/default/ckpt_epoch_34.pth saving......
[2022-04-05 14:55:25 large] (utils.py 59): INFO output/large/default/ckpt_epoch_34.pth saved !!!
[2022-04-05 14:55:25 large] (main.py 148): INFO Max accuracy: 69.71%
[2022-04-05 14:55:33 large] (main.py 226): INFO Train: [35/300][0/2502]	eta 5:36:37 lr 0.000484	time 8.0727 (8.0727)	loss 4.1772 (4.1772)	grad_norm 2.2312 (2.2312)	mem 8931MB
[2022-04-05 14:56:29 large] (main.py 226): INFO Train: [35/300][100/2502]	eta 0:25:11 lr 0.000484	time 0.6819 (0.6292)	loss 3.5937 (3.8407)	grad_norm 1.5554 (2.3336)	mem 8931MB
[2022-04-05 14:57:31 large] (main.py 226): INFO Train: [35/300][200/2502]	eta 0:24:02 lr 0.000483	time 0.6012 (0.6265)	loss 3.2113 (3.8495)	grad_norm 3.4628 (2.3535)	mem 8931MB
[2022-04-05 14:58:33 large] (main.py 226): INFO Train: [35/300][300/2502]	eta 0:22:55 lr 0.000483	time 0.5618 (0.6247)	loss 4.4109 (3.8474)	grad_norm 2.3993 (2.3705)	mem 8931MB
[2022-04-05 14:59:38 large] (main.py 226): INFO Train: [35/300][400/2502]	eta 0:22:03 lr 0.000483	time 0.6441 (0.6296)	loss 4.2428 (3.8544)	grad_norm 2.1519 (2.3746)	mem 8931MB
[2022-04-05 15:00:41 large] (main.py 226): INFO Train: [35/300][500/2502]	eta 0:21:03 lr 0.000483	time 0.6930 (0.6311)	loss 3.6306 (3.8554)	grad_norm 2.9974 (2.3722)	mem 8931MB
[2022-04-05 15:01:44 large] (main.py 226): INFO Train: [35/300][600/2502]	eta 0:20:00 lr 0.000483	time 0.5639 (0.6311)	loss 4.1816 (3.8448)	grad_norm 1.8941 (2.3674)	mem 8931MB
[2022-04-05 15:02:46 large] (main.py 226): INFO Train: [35/300][700/2502]	eta 0:18:53 lr 0.000483	time 0.5709 (0.6292)	loss 3.7781 (3.8490)	grad_norm 2.0100 (2.3826)	mem 8931MB
[2022-04-05 15:03:49 large] (main.py 226): INFO Train: [35/300][800/2502]	eta 0:17:50 lr 0.000483	time 0.6420 (0.6290)	loss 4.3857 (3.8503)	grad_norm 2.0777 (2.3715)	mem 8931MB
[2022-04-05 15:04:51 large] (main.py 226): INFO Train: [35/300][900/2502]	eta 0:16:45 lr 0.000483	time 0.6054 (0.6276)	loss 4.7123 (3.8625)	grad_norm 2.0921 (2.3738)	mem 8931MB
[2022-04-05 15:05:53 large] (main.py 226): INFO Train: [35/300][1000/2502]	eta 0:15:41 lr 0.000483	time 0.6715 (0.6269)	loss 4.7442 (3.8650)	grad_norm 2.3560 (2.3633)	mem 8931MB
[2022-04-05 15:06:54 large] (main.py 226): INFO Train: [35/300][1100/2502]	eta 0:14:37 lr 0.000483	time 0.6166 (0.6258)	loss 4.5561 (3.8758)	grad_norm 2.8632 (2.3617)	mem 8931MB
[2022-04-05 15:07:57 large] (main.py 226): INFO Train: [35/300][1200/2502]	eta 0:13:35 lr 0.000483	time 0.6081 (0.6264)	loss 3.8913 (3.8758)	grad_norm 2.2983 (2.3670)	mem 8931MB
[2022-04-05 15:09:01 large] (main.py 226): INFO Train: [35/300][1300/2502]	eta 0:12:33 lr 0.000483	time 0.6195 (0.6272)	loss 4.3770 (3.8725)	grad_norm 2.6588 (2.3659)	mem 8931MB
[2022-04-05 15:10:05 large] (main.py 226): INFO Train: [35/300][1400/2502]	eta 0:11:31 lr 0.000483	time 0.6593 (0.6279)	loss 3.5786 (3.8736)	grad_norm 1.9270 (2.3750)	mem 8931MB
[2022-04-05 15:11:07 large] (main.py 226): INFO Train: [35/300][1500/2502]	eta 0:10:28 lr 0.000483	time 0.6622 (0.6274)	loss 2.7104 (3.8686)	grad_norm 2.3151 (2.3705)	mem 8931MB
[2022-04-05 15:12:09 large] (main.py 226): INFO Train: [35/300][1600/2502]	eta 0:09:25 lr 0.000483	time 0.5640 (0.6269)	loss 3.7758 (3.8638)	grad_norm 2.5082 (inf)	mem 8931MB
[2022-04-05 15:13:13 large] (main.py 226): INFO Train: [35/300][1700/2502]	eta 0:08:23 lr 0.000483	time 0.6512 (0.6276)	loss 2.5776 (3.8611)	grad_norm 2.5538 (inf)	mem 8931MB
[2022-04-05 15:14:16 large] (main.py 226): INFO Train: [35/300][1800/2502]	eta 0:07:20 lr 0.000483	time 0.6814 (0.6281)	loss 3.0480 (3.8626)	grad_norm 2.5937 (inf)	mem 8931MB
[2022-04-05 15:15:20 large] (main.py 226): INFO Train: [35/300][1900/2502]	eta 0:06:18 lr 0.000483	time 0.5070 (0.6285)	loss 4.2982 (3.8646)	grad_norm 2.1614 (inf)	mem 8931MB
[2022-04-05 15:16:23 large] (main.py 226): INFO Train: [35/300][2000/2502]	eta 0:05:15 lr 0.000483	time 0.5834 (0.6285)	loss 3.5618 (3.8660)	grad_norm 2.1737 (inf)	mem 8931MB
[2022-04-05 15:17:26 large] (main.py 226): INFO Train: [35/300][2100/2502]	eta 0:04:12 lr 0.000483	time 0.6761 (0.6287)	loss 3.8153 (3.8716)	grad_norm 2.3275 (inf)	mem 8931MB
[2022-04-05 15:18:28 large] (main.py 226): INFO Train: [35/300][2200/2502]	eta 0:03:09 lr 0.000483	time 0.5682 (0.6285)	loss 4.1220 (3.8710)	grad_norm 1.8055 (inf)	mem 8931MB
[2022-04-05 15:19:31 large] (main.py 226): INFO Train: [35/300][2300/2502]	eta 0:02:06 lr 0.000483	time 0.5811 (0.6285)	loss 4.7889 (3.8709)	grad_norm 1.8500 (inf)	mem 8931MB
[2022-04-05 15:20:34 large] (main.py 226): INFO Train: [35/300][2400/2502]	eta 0:01:04 lr 0.000483	time 0.6109 (0.6286)	loss 4.7488 (3.8730)	grad_norm 2.0065 (inf)	mem 8931MB
[2022-04-05 15:21:37 large] (main.py 226): INFO Train: [35/300][2500/2502]	eta 0:00:01 lr 0.000483	time 0.6297 (0.6286)	loss 4.2240 (3.8693)	grad_norm 1.9477 (inf)	mem 8931MB
[2022-04-05 15:21:38 large] (main.py 233): INFO EPOCH 35 training takes 0:26:13
[2022-04-05 15:21:44 large] (main.py 273): INFO Test: [0/98]	Time 5.451 (5.451)	Loss 1.4978 (1.4978)	Acc@1 69.336 (69.336)	Acc@5 87.695 (87.695)	Mem 8931MB
[2022-04-05 15:22:11 large] (main.py 279): INFO  * Acc@1 70.172 Acc@5 89.966
[2022-04-05 15:22:11 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 70.2%
[2022-04-05 15:22:11 large] (utils.py 57): INFO output/large/default/ckpt_epoch_35.pth saving......
[2022-04-05 15:22:11 large] (utils.py 59): INFO output/large/default/ckpt_epoch_35.pth saved !!!
[2022-04-05 15:22:11 large] (main.py 148): INFO Max accuracy: 70.17%
[2022-04-05 15:22:19 large] (main.py 226): INFO Train: [36/300][0/2502]	eta 5:28:45 lr 0.000483	time 7.8840 (7.8840)	loss 3.6873 (3.6873)	grad_norm 2.8729 (2.8729)	mem 8931MB
[2022-04-05 15:23:09 large] (main.py 226): INFO Train: [36/300][100/2502]	eta 0:22:54 lr 0.000483	time 0.5872 (0.5721)	loss 2.9432 (3.8245)	grad_norm 1.8460 (2.4095)	mem 8931MB
[2022-04-05 15:24:12 large] (main.py 226): INFO Train: [36/300][200/2502]	eta 0:22:56 lr 0.000483	time 0.6088 (0.5981)	loss 4.7008 (3.8659)	grad_norm 2.6193 (2.3683)	mem 8931MB
[2022-04-05 15:25:18 large] (main.py 226): INFO Train: [36/300][300/2502]	eta 0:22:42 lr 0.000483	time 0.6463 (0.6186)	loss 4.2294 (3.8374)	grad_norm 2.4026 (2.3151)	mem 8931MB
[2022-04-05 15:26:21 large] (main.py 226): INFO Train: [36/300][400/2502]	eta 0:21:49 lr 0.000482	time 0.6407 (0.6232)	loss 4.6869 (3.8474)	grad_norm 1.9256 (2.3293)	mem 8931MB
[2022-04-05 15:27:26 large] (main.py 226): INFO Train: [36/300][500/2502]	eta 0:20:57 lr 0.000482	time 0.5995 (0.6281)	loss 2.9985 (3.8496)	grad_norm 1.8783 (2.3274)	mem 8931MB
[2022-04-05 15:28:30 large] (main.py 226): INFO Train: [36/300][600/2502]	eta 0:19:58 lr 0.000482	time 0.6770 (0.6302)	loss 3.8828 (3.8290)	grad_norm 1.8360 (2.3316)	mem 8931MB
[2022-04-05 15:29:34 large] (main.py 226): INFO Train: [36/300][700/2502]	eta 0:18:58 lr 0.000482	time 0.6703 (0.6317)	loss 4.6801 (3.8416)	grad_norm 2.2970 (2.3440)	mem 8931MB
[2022-04-05 15:30:38 large] (main.py 226): INFO Train: [36/300][800/2502]	eta 0:17:55 lr 0.000482	time 0.6293 (0.6320)	loss 4.3078 (3.8482)	grad_norm 3.6135 (2.3413)	mem 8931MB
[2022-04-05 15:31:39 large] (main.py 226): INFO Train: [36/300][900/2502]	eta 0:16:50 lr 0.000482	time 0.6539 (0.6305)	loss 4.1941 (3.8557)	grad_norm 2.5786 (2.3463)	mem 8931MB
[2022-04-05 15:32:42 large] (main.py 226): INFO Train: [36/300][1000/2502]	eta 0:15:46 lr 0.000482	time 0.7278 (0.6303)	loss 3.7869 (3.8508)	grad_norm 3.3203 (2.3392)	mem 8931MB
[2022-04-05 15:33:44 large] (main.py 226): INFO Train: [36/300][1100/2502]	eta 0:14:42 lr 0.000482	time 0.6344 (0.6294)	loss 4.6070 (3.8595)	grad_norm 1.9673 (2.3434)	mem 8931MB
[2022-04-05 15:34:48 large] (main.py 226): INFO Train: [36/300][1200/2502]	eta 0:13:39 lr 0.000482	time 0.5091 (0.6296)	loss 3.2658 (3.8547)	grad_norm 1.6596 (2.3467)	mem 8931MB
[2022-04-05 15:35:50 large] (main.py 226): INFO Train: [36/300][1300/2502]	eta 0:12:35 lr 0.000482	time 0.6397 (0.6289)	loss 4.7590 (3.8488)	grad_norm 2.3084 (2.3511)	mem 8931MB
[2022-04-05 15:36:52 large] (main.py 226): INFO Train: [36/300][1400/2502]	eta 0:11:32 lr 0.000482	time 0.6907 (0.6288)	loss 4.4682 (3.8492)	grad_norm 2.4284 (inf)	mem 8931MB
[2022-04-05 15:37:56 large] (main.py 226): INFO Train: [36/300][1500/2502]	eta 0:10:30 lr 0.000482	time 0.6446 (0.6292)	loss 4.5937 (3.8511)	grad_norm 1.7646 (inf)	mem 8931MB
[2022-04-05 15:38:59 large] (main.py 226): INFO Train: [36/300][1600/2502]	eta 0:09:27 lr 0.000482	time 0.6232 (0.6293)	loss 3.7679 (3.8507)	grad_norm 1.6807 (inf)	mem 8931MB
[2022-04-05 15:40:02 large] (main.py 226): INFO Train: [36/300][1700/2502]	eta 0:08:24 lr 0.000482	time 0.6299 (0.6295)	loss 3.3591 (3.8480)	grad_norm 3.6010 (inf)	mem 8931MB
[2022-04-05 15:41:04 large] (main.py 226): INFO Train: [36/300][1800/2502]	eta 0:07:21 lr 0.000482	time 0.5518 (0.6289)	loss 3.3359 (3.8434)	grad_norm 2.1828 (inf)	mem 8931MB
[2022-04-05 15:42:06 large] (main.py 226): INFO Train: [36/300][1900/2502]	eta 0:06:18 lr 0.000482	time 0.6154 (0.6286)	loss 3.1009 (3.8424)	grad_norm 1.8630 (inf)	mem 8931MB
[2022-04-05 15:43:11 large] (main.py 226): INFO Train: [36/300][2000/2502]	eta 0:05:16 lr 0.000482	time 0.6342 (0.6295)	loss 4.0569 (3.8429)	grad_norm 2.6779 (inf)	mem 8931MB
[2022-04-05 15:44:13 large] (main.py 226): INFO Train: [36/300][2100/2502]	eta 0:04:12 lr 0.000482	time 0.5249 (0.6291)	loss 4.2464 (3.8448)	grad_norm 2.1604 (inf)	mem 8931MB
[2022-04-05 15:45:17 large] (main.py 226): INFO Train: [36/300][2200/2502]	eta 0:03:10 lr 0.000482	time 0.6316 (0.6296)	loss 3.5495 (3.8473)	grad_norm 2.0542 (inf)	mem 8931MB
[2022-04-05 15:46:19 large] (main.py 226): INFO Train: [36/300][2300/2502]	eta 0:02:07 lr 0.000482	time 0.6821 (0.6292)	loss 2.6340 (3.8451)	grad_norm 2.4564 (inf)	mem 8931MB
[2022-04-05 15:47:22 large] (main.py 226): INFO Train: [36/300][2400/2502]	eta 0:01:04 lr 0.000482	time 0.6102 (0.6292)	loss 4.8370 (3.8447)	grad_norm 2.2550 (inf)	mem 8931MB
[2022-04-05 15:48:24 large] (main.py 226): INFO Train: [36/300][2500/2502]	eta 0:00:01 lr 0.000482	time 0.5865 (0.6290)	loss 2.9695 (3.8432)	grad_norm 2.6541 (inf)	mem 8931MB
[2022-04-05 15:48:25 large] (main.py 233): INFO EPOCH 36 training takes 0:26:14
[2022-04-05 15:48:31 large] (main.py 273): INFO Test: [0/98]	Time 5.968 (5.968)	Loss 1.3816 (1.3816)	Acc@1 72.070 (72.070)	Acc@5 88.281 (88.281)	Mem 8931MB
[2022-04-05 15:48:58 large] (main.py 279): INFO  * Acc@1 70.024 Acc@5 89.794
[2022-04-05 15:48:58 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 70.0%
[2022-04-05 15:48:58 large] (main.py 148): INFO Max accuracy: 70.17%
[2022-04-05 15:49:04 large] (main.py 226): INFO Train: [37/300][0/2502]	eta 4:34:53 lr 0.000482	time 6.5921 (6.5921)	loss 3.9715 (3.9715)	grad_norm 1.8582 (1.8582)	mem 8931MB
[2022-04-05 15:49:55 large] (main.py 226): INFO Train: [37/300][100/2502]	eta 0:22:51 lr 0.000482	time 0.5490 (0.5710)	loss 4.2351 (3.8324)	grad_norm 2.3188 (2.4780)	mem 8931MB
[2022-04-05 15:50:51 large] (main.py 226): INFO Train: [37/300][200/2502]	eta 0:21:38 lr 0.000482	time 0.4828 (0.5642)	loss 2.4436 (3.8533)	grad_norm 1.7225 (2.4089)	mem 8931MB
[2022-04-05 15:51:51 large] (main.py 226): INFO Train: [37/300][300/2502]	eta 0:21:10 lr 0.000482	time 0.6202 (0.5769)	loss 4.8365 (3.8075)	grad_norm 2.7352 (2.3871)	mem 8931MB
[2022-04-05 15:52:55 large] (main.py 226): INFO Train: [37/300][400/2502]	eta 0:20:43 lr 0.000481	time 0.6096 (0.5917)	loss 3.6338 (3.8364)	grad_norm 2.1802 (2.3876)	mem 8931MB
[2022-04-05 15:53:52 large] (main.py 226): INFO Train: [37/300][500/2502]	eta 0:19:34 lr 0.000481	time 0.6344 (0.5865)	loss 3.1312 (3.8395)	grad_norm 2.0934 (2.3933)	mem 8931MB
[2022-04-05 15:54:56 large] (main.py 226): INFO Train: [37/300][600/2502]	eta 0:18:54 lr 0.000481	time 0.6645 (0.5966)	loss 2.9126 (3.8496)	grad_norm 2.3107 (2.3812)	mem 8931MB
[2022-04-05 15:56:01 large] (main.py 226): INFO Train: [37/300][700/2502]	eta 0:18:08 lr 0.000481	time 0.6710 (0.6043)	loss 4.3991 (3.8420)	grad_norm 2.4677 (2.3779)	mem 8931MB
[2022-04-05 15:57:05 large] (main.py 226): INFO Train: [37/300][800/2502]	eta 0:17:16 lr 0.000481	time 0.6073 (0.6088)	loss 4.5201 (3.8419)	grad_norm 2.2552 (2.3689)	mem 8931MB
[2022-04-05 15:58:08 large] (main.py 226): INFO Train: [37/300][900/2502]	eta 0:16:18 lr 0.000481	time 0.6276 (0.6109)	loss 4.4561 (3.8450)	grad_norm 2.0237 (2.3776)	mem 8931MB
[2022-04-05 15:59:10 large] (main.py 226): INFO Train: [37/300][1000/2502]	eta 0:15:18 lr 0.000481	time 0.7640 (0.6115)	loss 4.1706 (3.8457)	grad_norm 2.7301 (inf)	mem 8931MB
[2022-04-05 16:00:14 large] (main.py 226): INFO Train: [37/300][1100/2502]	eta 0:14:20 lr 0.000481	time 0.7143 (0.6138)	loss 4.0692 (3.8504)	grad_norm 2.2127 (inf)	mem 8931MB
[2022-04-05 16:01:17 large] (main.py 226): INFO Train: [37/300][1200/2502]	eta 0:13:21 lr 0.000481	time 0.6206 (0.6155)	loss 3.3897 (3.8472)	grad_norm 2.5388 (inf)	mem 8931MB
[2022-04-05 16:02:20 large] (main.py 226): INFO Train: [37/300][1300/2502]	eta 0:12:21 lr 0.000481	time 0.5425 (0.6167)	loss 4.5771 (3.8548)	grad_norm 2.4387 (inf)	mem 8931MB
[2022-04-05 16:03:23 large] (main.py 226): INFO Train: [37/300][1400/2502]	eta 0:11:20 lr 0.000481	time 0.5970 (0.6179)	loss 3.5643 (3.8549)	grad_norm 3.0613 (inf)	mem 8931MB
[2022-04-05 16:04:26 large] (main.py 226): INFO Train: [37/300][1500/2502]	eta 0:10:19 lr 0.000481	time 0.6797 (0.6187)	loss 3.5662 (3.8574)	grad_norm 2.3994 (inf)	mem 8931MB
[2022-04-05 16:05:30 large] (main.py 226): INFO Train: [37/300][1600/2502]	eta 0:09:18 lr 0.000481	time 0.6535 (0.6197)	loss 3.4700 (3.8611)	grad_norm 2.2520 (inf)	mem 8931MB
[2022-04-05 16:06:33 large] (main.py 226): INFO Train: [37/300][1700/2502]	eta 0:08:17 lr 0.000481	time 0.6131 (0.6205)	loss 3.1178 (3.8584)	grad_norm 2.7555 (inf)	mem 8931MB
[2022-04-05 16:07:37 large] (main.py 226): INFO Train: [37/300][1800/2502]	eta 0:07:16 lr 0.000481	time 0.6717 (0.6217)	loss 2.7528 (3.8612)	grad_norm 2.6053 (inf)	mem 8931MB
[2022-04-05 16:08:42 large] (main.py 226): INFO Train: [37/300][1900/2502]	eta 0:06:14 lr 0.000481	time 0.6014 (0.6228)	loss 4.3704 (3.8658)	grad_norm 2.1426 (inf)	mem 8931MB
[2022-04-05 16:09:46 large] (main.py 226): INFO Train: [37/300][2000/2502]	eta 0:05:13 lr 0.000481	time 0.5617 (0.6236)	loss 4.4009 (3.8635)	grad_norm 3.2526 (inf)	mem 8931MB
[2022-04-05 16:10:49 large] (main.py 226): INFO Train: [37/300][2100/2502]	eta 0:04:10 lr 0.000481	time 0.5331 (0.6243)	loss 2.8535 (3.8650)	grad_norm 1.7850 (inf)	mem 8931MB
[2022-04-05 16:11:52 large] (main.py 226): INFO Train: [37/300][2200/2502]	eta 0:03:08 lr 0.000481	time 0.6096 (0.6244)	loss 4.2114 (3.8648)	grad_norm 2.7259 (inf)	mem 8931MB
[2022-04-05 16:12:56 large] (main.py 226): INFO Train: [37/300][2300/2502]	eta 0:02:06 lr 0.000481	time 0.5854 (0.6250)	loss 4.0218 (3.8690)	grad_norm 2.5207 (inf)	mem 8931MB
[2022-04-05 16:13:58 large] (main.py 226): INFO Train: [37/300][2400/2502]	eta 0:01:03 lr 0.000481	time 0.5871 (0.6249)	loss 3.0849 (3.8662)	grad_norm 2.1266 (inf)	mem 8931MB
[2022-04-05 16:15:01 large] (main.py 226): INFO Train: [37/300][2500/2502]	eta 0:00:01 lr 0.000481	time 0.6137 (0.6249)	loss 4.0873 (3.8652)	grad_norm 1.9044 (inf)	mem 8931MB
[2022-04-05 16:15:02 large] (main.py 233): INFO EPOCH 37 training takes 0:26:03
[2022-04-05 16:15:08 large] (main.py 273): INFO Test: [0/98]	Time 6.478 (6.478)	Loss 1.3496 (1.3496)	Acc@1 69.141 (69.141)	Acc@5 90.234 (90.234)	Mem 8931MB
[2022-04-05 16:15:34 large] (main.py 279): INFO  * Acc@1 70.344 Acc@5 90.152
[2022-04-05 16:15:34 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 70.3%
[2022-04-05 16:15:34 large] (utils.py 57): INFO output/large/default/ckpt_epoch_37.pth saving......
[2022-04-05 16:15:35 large] (utils.py 59): INFO output/large/default/ckpt_epoch_37.pth saved !!!
[2022-04-05 16:15:35 large] (main.py 148): INFO Max accuracy: 70.34%
[2022-04-05 16:15:44 large] (main.py 226): INFO Train: [38/300][0/2502]	eta 5:44:05 lr 0.000481	time 8.2514 (8.2514)	loss 4.2566 (4.2566)	grad_norm 2.7534 (2.7534)	mem 8931MB
[2022-04-05 16:16:43 large] (main.py 226): INFO Train: [38/300][100/2502]	eta 0:26:44 lr 0.000481	time 0.5785 (0.6678)	loss 3.7907 (3.9113)	grad_norm 1.7762 (2.3779)	mem 8931MB
[2022-04-05 16:17:48 large] (main.py 226): INFO Train: [38/300][200/2502]	eta 0:25:16 lr 0.000481	time 0.6546 (0.6589)	loss 2.7990 (3.9027)	grad_norm 2.0152 (2.3309)	mem 8931MB
[2022-04-05 16:18:53 large] (main.py 226): INFO Train: [38/300][300/2502]	eta 0:24:03 lr 0.000481	time 0.6167 (0.6556)	loss 3.4179 (3.8452)	grad_norm 2.4107 (2.3296)	mem 8931MB
[2022-04-05 16:19:50 large] (main.py 226): INFO Train: [38/300][400/2502]	eta 0:22:13 lr 0.000481	time 0.4854 (0.6345)	loss 2.7510 (3.8271)	grad_norm 2.5437 (2.3600)	mem 8931MB
[2022-04-05 16:20:49 large] (main.py 226): INFO Train: [38/300][500/2502]	eta 0:20:52 lr 0.000480	time 0.6721 (0.6257)	loss 3.1845 (3.8348)	grad_norm 2.1121 (2.3446)	mem 8931MB
[2022-04-05 16:21:55 large] (main.py 226): INFO Train: [38/300][600/2502]	eta 0:20:00 lr 0.000480	time 0.6368 (0.6310)	loss 4.0819 (3.8290)	grad_norm 2.1024 (2.3478)	mem 8931MB
[2022-04-05 16:23:00 large] (main.py 226): INFO Train: [38/300][700/2502]	eta 0:19:02 lr 0.000480	time 0.5316 (0.6339)	loss 4.5249 (3.8403)	grad_norm 2.2742 (inf)	mem 8931MB
[2022-04-05 16:24:05 large] (main.py 226): INFO Train: [38/300][800/2502]	eta 0:18:03 lr 0.000480	time 0.5479 (0.6363)	loss 4.2069 (3.8448)	grad_norm 2.0489 (inf)	mem 8931MB
[2022-04-05 16:25:10 large] (main.py 226): INFO Train: [38/300][900/2502]	eta 0:17:01 lr 0.000480	time 0.6402 (0.6378)	loss 4.1350 (3.8474)	grad_norm 2.0329 (inf)	mem 8931MB
[2022-04-05 16:26:14 large] (main.py 226): INFO Train: [38/300][1000/2502]	eta 0:15:57 lr 0.000480	time 0.7875 (0.6377)	loss 4.1135 (3.8400)	grad_norm 2.4146 (inf)	mem 8931MB
[2022-04-05 16:27:17 large] (main.py 226): INFO Train: [38/300][1100/2502]	eta 0:14:53 lr 0.000480	time 0.5997 (0.6376)	loss 3.5707 (3.8416)	grad_norm 1.5526 (inf)	mem 8931MB
[2022-04-05 16:28:21 large] (main.py 226): INFO Train: [38/300][1200/2502]	eta 0:13:50 lr 0.000480	time 0.5003 (0.6379)	loss 4.2509 (3.8346)	grad_norm 2.2460 (inf)	mem 8931MB
[2022-04-05 16:29:26 large] (main.py 226): INFO Train: [38/300][1300/2502]	eta 0:12:47 lr 0.000480	time 0.6989 (0.6385)	loss 3.1590 (3.8302)	grad_norm 2.8088 (inf)	mem 8931MB
[2022-04-05 16:30:31 large] (main.py 226): INFO Train: [38/300][1400/2502]	eta 0:11:44 lr 0.000480	time 0.6898 (0.6393)	loss 3.7861 (3.8377)	grad_norm 1.8464 (inf)	mem 8931MB
[2022-04-05 16:31:35 large] (main.py 226): INFO Train: [38/300][1500/2502]	eta 0:10:40 lr 0.000480	time 0.7203 (0.6395)	loss 4.1674 (3.8412)	grad_norm 2.1679 (inf)	mem 8931MB
[2022-04-05 16:32:40 large] (main.py 226): INFO Train: [38/300][1600/2502]	eta 0:09:37 lr 0.000480	time 0.6443 (0.6400)	loss 3.8633 (3.8467)	grad_norm 2.4938 (inf)	mem 8931MB
[2022-04-05 16:33:45 large] (main.py 226): INFO Train: [38/300][1700/2502]	eta 0:08:33 lr 0.000480	time 0.6668 (0.6405)	loss 4.7289 (3.8511)	grad_norm 2.7372 (inf)	mem 8931MB
[2022-04-05 16:34:50 large] (main.py 226): INFO Train: [38/300][1800/2502]	eta 0:07:30 lr 0.000480	time 0.7118 (0.6411)	loss 3.6922 (3.8514)	grad_norm 1.8014 (inf)	mem 8931MB
[2022-04-05 16:35:55 large] (main.py 226): INFO Train: [38/300][1900/2502]	eta 0:06:26 lr 0.000480	time 0.6504 (0.6414)	loss 3.6644 (3.8507)	grad_norm 2.1113 (inf)	mem 8931MB
[2022-04-05 16:36:58 large] (main.py 226): INFO Train: [38/300][2000/2502]	eta 0:05:21 lr 0.000480	time 0.6392 (0.6412)	loss 4.4082 (3.8506)	grad_norm 2.0808 (inf)	mem 8931MB
[2022-04-05 16:38:02 large] (main.py 226): INFO Train: [38/300][2100/2502]	eta 0:04:17 lr 0.000480	time 0.6891 (0.6412)	loss 4.7444 (3.8511)	grad_norm 2.6709 (inf)	mem 8931MB
[2022-04-05 16:39:05 large] (main.py 226): INFO Train: [38/300][2200/2502]	eta 0:03:13 lr 0.000480	time 0.6265 (0.6404)	loss 4.0199 (3.8498)	grad_norm 1.6799 (inf)	mem 8931MB
[2022-04-05 16:40:09 large] (main.py 226): INFO Train: [38/300][2300/2502]	eta 0:02:09 lr 0.000480	time 0.6355 (0.6403)	loss 4.2861 (3.8523)	grad_norm 1.7344 (inf)	mem 8931MB
[2022-04-05 16:41:13 large] (main.py 226): INFO Train: [38/300][2400/2502]	eta 0:01:05 lr 0.000480	time 0.6551 (0.6405)	loss 3.4464 (3.8518)	grad_norm 2.3969 (inf)	mem 8931MB
[2022-04-05 16:42:17 large] (main.py 226): INFO Train: [38/300][2500/2502]	eta 0:00:01 lr 0.000480	time 0.6131 (0.6404)	loss 3.0158 (3.8490)	grad_norm 3.1852 (inf)	mem 8931MB
[2022-04-05 16:42:18 large] (main.py 233): INFO EPOCH 38 training takes 0:26:42
[2022-04-05 16:42:23 large] (main.py 273): INFO Test: [0/98]	Time 5.344 (5.344)	Loss 1.5013 (1.5013)	Acc@1 66.602 (66.602)	Acc@5 89.453 (89.453)	Mem 8931MB
[2022-04-05 16:42:50 large] (main.py 279): INFO  * Acc@1 70.456 Acc@5 90.062
[2022-04-05 16:42:50 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 70.5%
[2022-04-05 16:42:50 large] (utils.py 57): INFO output/large/default/ckpt_epoch_38.pth saving......
[2022-04-05 16:42:51 large] (utils.py 59): INFO output/large/default/ckpt_epoch_38.pth saved !!!
[2022-04-05 16:42:51 large] (main.py 148): INFO Max accuracy: 70.46%
[2022-04-05 16:42:59 large] (main.py 226): INFO Train: [39/300][0/2502]	eta 5:30:17 lr 0.000480	time 7.9206 (7.9206)	loss 4.0571 (4.0571)	grad_norm 2.6125 (2.6125)	mem 8931MB
[2022-04-05 16:43:54 large] (main.py 226): INFO Train: [39/300][100/2502]	eta 0:25:05 lr 0.000480	time 0.6768 (0.6266)	loss 4.1555 (3.8598)	grad_norm 1.8740 (2.3418)	mem 8931MB
[2022-04-05 16:45:00 large] (main.py 226): INFO Train: [39/300][200/2502]	eta 0:24:42 lr 0.000480	time 0.5512 (0.6441)	loss 4.2666 (3.8027)	grad_norm 2.2394 (inf)	mem 8931MB
[2022-04-05 16:46:07 large] (main.py 226): INFO Train: [39/300][300/2502]	eta 0:23:56 lr 0.000480	time 0.6682 (0.6525)	loss 2.4872 (3.8026)	grad_norm 2.3680 (inf)	mem 8931MB
[2022-04-05 16:47:13 large] (main.py 226): INFO Train: [39/300][400/2502]	eta 0:22:57 lr 0.000479	time 0.6155 (0.6552)	loss 4.6953 (3.7979)	grad_norm 2.1398 (inf)	mem 8931MB
[2022-04-05 16:48:19 large] (main.py 226): INFO Train: [39/300][500/2502]	eta 0:21:50 lr 0.000479	time 0.7000 (0.6546)	loss 4.4112 (3.8089)	grad_norm 2.1460 (inf)	mem 8931MB
[2022-04-05 16:49:24 large] (main.py 226): INFO Train: [39/300][600/2502]	eta 0:20:43 lr 0.000479	time 0.6393 (0.6537)	loss 2.6638 (3.7966)	grad_norm 2.3335 (inf)	mem 8931MB
[2022-04-05 16:50:29 large] (main.py 226): INFO Train: [39/300][700/2502]	eta 0:19:38 lr 0.000479	time 0.5228 (0.6539)	loss 4.0831 (3.8007)	grad_norm 2.3729 (inf)	mem 8931MB
[2022-04-05 16:51:35 large] (main.py 226): INFO Train: [39/300][800/2502]	eta 0:18:33 lr 0.000479	time 0.7479 (0.6545)	loss 2.6294 (3.8141)	grad_norm 2.5601 (inf)	mem 8931MB
[2022-04-05 16:52:37 large] (main.py 226): INFO Train: [39/300][900/2502]	eta 0:17:23 lr 0.000479	time 0.7132 (0.6512)	loss 3.6323 (3.8203)	grad_norm 3.0438 (inf)	mem 8931MB
[2022-04-05 16:53:42 large] (main.py 226): INFO Train: [39/300][1000/2502]	eta 0:16:17 lr 0.000479	time 0.6483 (0.6507)	loss 3.0116 (3.8288)	grad_norm 2.0575 (inf)	mem 8931MB
[2022-04-05 16:54:48 large] (main.py 226): INFO Train: [39/300][1100/2502]	eta 0:15:13 lr 0.000479	time 0.6534 (0.6517)	loss 2.7100 (3.8296)	grad_norm 1.9543 (inf)	mem 8931MB
[2022-04-05 16:55:52 large] (main.py 226): INFO Train: [39/300][1200/2502]	eta 0:14:07 lr 0.000479	time 0.6199 (0.6509)	loss 4.7348 (3.8326)	grad_norm 2.3276 (inf)	mem 8931MB
[2022-04-05 16:56:56 large] (main.py 226): INFO Train: [39/300][1300/2502]	eta 0:13:01 lr 0.000479	time 0.6519 (0.6499)	loss 4.2336 (3.8346)	grad_norm 2.0836 (inf)	mem 8931MB
[2022-04-05 16:58:01 large] (main.py 226): INFO Train: [39/300][1400/2502]	eta 0:11:56 lr 0.000479	time 0.6681 (0.6498)	loss 3.4941 (3.8298)	grad_norm 2.0456 (inf)	mem 8931MB
[2022-04-05 16:59:06 large] (main.py 226): INFO Train: [39/300][1500/2502]	eta 0:10:50 lr 0.000479	time 0.6070 (0.6494)	loss 4.4946 (3.8286)	grad_norm 2.4884 (inf)	mem 8931MB
[2022-04-05 17:00:11 large] (main.py 226): INFO Train: [39/300][1600/2502]	eta 0:09:46 lr 0.000479	time 0.5974 (0.6498)	loss 4.5441 (3.8288)	grad_norm 2.2456 (inf)	mem 8931MB
[2022-04-05 17:01:16 large] (main.py 226): INFO Train: [39/300][1700/2502]	eta 0:08:41 lr 0.000479	time 0.6369 (0.6499)	loss 3.5279 (3.8338)	grad_norm 2.3137 (inf)	mem 8931MB
[2022-04-05 17:02:21 large] (main.py 226): INFO Train: [39/300][1800/2502]	eta 0:07:35 lr 0.000479	time 0.6650 (0.6496)	loss 4.1710 (3.8351)	grad_norm 2.1578 (inf)	mem 8931MB
[2022-04-05 17:03:26 large] (main.py 226): INFO Train: [39/300][1900/2502]	eta 0:06:31 lr 0.000479	time 0.6610 (0.6499)	loss 3.0239 (3.8415)	grad_norm 2.2355 (inf)	mem 8931MB
[2022-04-05 17:04:31 large] (main.py 226): INFO Train: [39/300][2000/2502]	eta 0:05:26 lr 0.000479	time 0.6180 (0.6500)	loss 3.5173 (3.8419)	grad_norm 2.3488 (inf)	mem 8931MB
[2022-04-05 17:05:34 large] (main.py 226): INFO Train: [39/300][2100/2502]	eta 0:04:20 lr 0.000479	time 0.6194 (0.6489)	loss 2.6894 (3.8416)	grad_norm 2.2553 (inf)	mem 8931MB
[2022-04-05 17:06:39 large] (main.py 226): INFO Train: [39/300][2200/2502]	eta 0:03:15 lr 0.000479	time 0.5667 (0.6489)	loss 4.0959 (3.8369)	grad_norm 2.2294 (inf)	mem 8931MB
[2022-04-05 17:07:42 large] (main.py 226): INFO Train: [39/300][2300/2502]	eta 0:02:10 lr 0.000479	time 0.5202 (0.6480)	loss 3.3512 (3.8374)	grad_norm 2.5902 (inf)	mem 8931MB
[2022-04-05 17:08:48 large] (main.py 226): INFO Train: [39/300][2400/2502]	eta 0:01:06 lr 0.000479	time 0.6516 (0.6484)	loss 4.3394 (3.8398)	grad_norm 2.8229 (inf)	mem 8931MB
[2022-04-05 17:09:52 large] (main.py 226): INFO Train: [39/300][2500/2502]	eta 0:00:01 lr 0.000479	time 0.7249 (0.6482)	loss 3.9103 (3.8371)	grad_norm 2.2664 (inf)	mem 8931MB
[2022-04-05 17:09:53 large] (main.py 233): INFO EPOCH 39 training takes 0:27:02
[2022-04-05 17:09:58 large] (main.py 273): INFO Test: [0/98]	Time 5.498 (5.498)	Loss 1.3715 (1.3715)	Acc@1 71.289 (71.289)	Acc@5 90.625 (90.625)	Mem 8931MB
[2022-04-05 17:10:25 large] (main.py 279): INFO  * Acc@1 70.834 Acc@5 90.620
[2022-04-05 17:10:25 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 70.8%
[2022-04-05 17:10:25 large] (utils.py 57): INFO output/large/default/ckpt_epoch_39.pth saving......
[2022-04-05 17:10:26 large] (utils.py 59): INFO output/large/default/ckpt_epoch_39.pth saved !!!
[2022-04-05 17:10:26 large] (main.py 148): INFO Max accuracy: 70.83%
[2022-04-05 17:10:34 large] (main.py 226): INFO Train: [40/300][0/2502]	eta 5:41:29 lr 0.000479	time 8.1894 (8.1894)	loss 3.1042 (3.1042)	grad_norm 2.1919 (2.1919)	mem 8931MB
[2022-04-05 17:11:30 large] (main.py 226): INFO Train: [40/300][100/2502]	eta 0:25:20 lr 0.000479	time 0.6581 (0.6328)	loss 4.2298 (3.8085)	grad_norm 1.7160 (2.4675)	mem 8931MB
[2022-04-05 17:12:36 large] (main.py 226): INFO Train: [40/300][200/2502]	eta 0:24:48 lr 0.000479	time 0.6431 (0.6466)	loss 4.3565 (3.8491)	grad_norm 2.3519 (2.4540)	mem 8931MB
[2022-04-05 17:13:42 large] (main.py 226): INFO Train: [40/300][300/2502]	eta 0:23:53 lr 0.000478	time 0.5323 (0.6511)	loss 2.9626 (3.8434)	grad_norm 2.3725 (2.4237)	mem 8931MB
[2022-04-05 17:14:47 large] (main.py 226): INFO Train: [40/300][400/2502]	eta 0:22:52 lr 0.000478	time 0.6495 (0.6529)	loss 3.5570 (3.8153)	grad_norm 2.2181 (2.4122)	mem 8931MB
[2022-04-05 17:15:54 large] (main.py 226): INFO Train: [40/300][500/2502]	eta 0:21:51 lr 0.000478	time 0.5913 (0.6549)	loss 3.8726 (3.8054)	grad_norm 1.8186 (2.3998)	mem 8931MB
[2022-04-05 17:16:59 large] (main.py 226): INFO Train: [40/300][600/2502]	eta 0:20:45 lr 0.000478	time 0.5899 (0.6549)	loss 3.2393 (3.8028)	grad_norm 2.0966 (2.4001)	mem 8931MB
[2022-04-05 17:18:05 large] (main.py 226): INFO Train: [40/300][700/2502]	eta 0:19:41 lr 0.000478	time 0.6788 (0.6554)	loss 3.1098 (3.8071)	grad_norm 2.5651 (2.3929)	mem 8931MB
[2022-04-05 17:19:11 large] (main.py 226): INFO Train: [40/300][800/2502]	eta 0:18:35 lr 0.000478	time 0.6865 (0.6553)	loss 4.1773 (3.8088)	grad_norm 2.5364 (2.3932)	mem 8931MB
[2022-04-05 17:20:15 large] (main.py 226): INFO Train: [40/300][900/2502]	eta 0:17:28 lr 0.000478	time 0.7180 (0.6542)	loss 3.8830 (3.7945)	grad_norm 1.9483 (2.3922)	mem 8931MB
[2022-04-05 17:21:19 large] (main.py 226): INFO Train: [40/300][1000/2502]	eta 0:16:19 lr 0.000478	time 0.5908 (0.6523)	loss 2.7392 (3.7946)	grad_norm 2.9197 (2.3932)	mem 8931MB
[2022-04-05 17:22:24 large] (main.py 226): INFO Train: [40/300][1100/2502]	eta 0:15:15 lr 0.000478	time 0.6531 (0.6527)	loss 2.9614 (3.7987)	grad_norm 2.0967 (2.3860)	mem 8931MB
[2022-04-05 17:23:30 large] (main.py 226): INFO Train: [40/300][1200/2502]	eta 0:14:10 lr 0.000478	time 0.6380 (0.6529)	loss 4.2445 (3.7966)	grad_norm 2.1283 (2.3887)	mem 8931MB
[2022-04-05 17:24:35 large] (main.py 226): INFO Train: [40/300][1300/2502]	eta 0:13:04 lr 0.000478	time 0.5970 (0.6529)	loss 2.5146 (3.8025)	grad_norm 1.9952 (2.3900)	mem 8931MB
[2022-04-05 17:25:42 large] (main.py 226): INFO Train: [40/300][1400/2502]	eta 0:12:00 lr 0.000478	time 0.6178 (0.6541)	loss 3.9609 (3.8045)	grad_norm 1.8229 (2.3882)	mem 8931MB
[2022-04-05 17:26:47 large] (main.py 226): INFO Train: [40/300][1500/2502]	eta 0:10:54 lr 0.000478	time 0.6179 (0.6537)	loss 2.7195 (3.8078)	grad_norm 3.0832 (2.3914)	mem 8931MB
[2022-04-05 17:27:52 large] (main.py 226): INFO Train: [40/300][1600/2502]	eta 0:09:49 lr 0.000478	time 0.5042 (0.6536)	loss 4.0397 (3.8068)	grad_norm 2.9028 (2.3918)	mem 8931MB
[2022-04-05 17:28:59 large] (main.py 226): INFO Train: [40/300][1700/2502]	eta 0:08:44 lr 0.000478	time 0.7934 (0.6543)	loss 4.0602 (3.8117)	grad_norm 2.2475 (2.3927)	mem 8931MB
[2022-04-05 17:30:04 large] (main.py 226): INFO Train: [40/300][1800/2502]	eta 0:07:39 lr 0.000478	time 0.6928 (0.6543)	loss 3.7680 (3.8096)	grad_norm 3.4958 (2.3894)	mem 8931MB
[2022-04-05 17:31:09 large] (main.py 226): INFO Train: [40/300][1900/2502]	eta 0:06:33 lr 0.000478	time 0.6295 (0.6539)	loss 3.8705 (3.8167)	grad_norm 2.2928 (2.3923)	mem 8931MB
[2022-04-05 17:32:14 large] (main.py 226): INFO Train: [40/300][2000/2502]	eta 0:05:28 lr 0.000478	time 0.6681 (0.6536)	loss 3.5576 (3.8168)	grad_norm 1.9748 (inf)	mem 8931MB
[2022-04-05 17:33:19 large] (main.py 226): INFO Train: [40/300][2100/2502]	eta 0:04:22 lr 0.000478	time 0.6941 (0.6535)	loss 3.0881 (3.8193)	grad_norm 2.1948 (inf)	mem 8931MB
[2022-04-05 17:34:23 large] (main.py 226): INFO Train: [40/300][2200/2502]	eta 0:03:17 lr 0.000478	time 0.6081 (0.6530)	loss 4.4681 (3.8171)	grad_norm 1.6907 (inf)	mem 8931MB
[2022-04-05 17:35:30 large] (main.py 226): INFO Train: [40/300][2300/2502]	eta 0:02:12 lr 0.000478	time 0.5731 (0.6536)	loss 4.0894 (3.8186)	grad_norm 1.8217 (inf)	mem 8931MB
[2022-04-05 17:36:34 large] (main.py 226): INFO Train: [40/300][2400/2502]	eta 0:01:06 lr 0.000478	time 0.6463 (0.6533)	loss 4.0464 (3.8134)	grad_norm 3.2603 (inf)	mem 8931MB
[2022-04-05 17:37:38 large] (main.py 226): INFO Train: [40/300][2500/2502]	eta 0:00:01 lr 0.000478	time 0.6132 (0.6529)	loss 4.5431 (3.8169)	grad_norm 2.1059 (inf)	mem 8931MB
[2022-04-05 17:37:39 large] (main.py 233): INFO EPOCH 40 training takes 0:27:13
[2022-04-05 17:37:46 large] (main.py 273): INFO Test: [0/98]	Time 6.021 (6.021)	Loss 1.3004 (1.3004)	Acc@1 70.508 (70.508)	Acc@5 90.234 (90.234)	Mem 8931MB
[2022-04-05 17:38:11 large] (main.py 279): INFO  * Acc@1 71.282 Acc@5 90.470
[2022-04-05 17:38:11 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 71.3%
[2022-04-05 17:38:11 large] (utils.py 57): INFO output/large/default/ckpt_epoch_40.pth saving......
[2022-04-05 17:38:12 large] (utils.py 59): INFO output/large/default/ckpt_epoch_40.pth saved !!!
[2022-04-05 17:38:12 large] (main.py 148): INFO Max accuracy: 71.28%
[2022-04-05 17:38:20 large] (main.py 226): INFO Train: [41/300][0/2502]	eta 5:32:13 lr 0.000478	time 7.9668 (7.9668)	loss 2.5326 (2.5326)	grad_norm 2.1111 (2.1111)	mem 8931MB
[2022-04-05 17:39:16 large] (main.py 226): INFO Train: [41/300][100/2502]	eta 0:25:25 lr 0.000477	time 0.6361 (0.6349)	loss 4.0867 (3.8050)	grad_norm 1.8013 (2.4484)	mem 8931MB
[2022-04-05 17:40:24 large] (main.py 226): INFO Train: [41/300][200/2502]	eta 0:25:09 lr 0.000477	time 0.6665 (0.6559)	loss 2.7428 (3.8412)	grad_norm 2.8684 (2.3823)	mem 8931MB
[2022-04-05 17:41:31 large] (main.py 226): INFO Train: [41/300][300/2502]	eta 0:24:11 lr 0.000477	time 0.6453 (0.6591)	loss 3.7747 (3.8424)	grad_norm 2.0174 (2.4150)	mem 8931MB
[2022-04-05 17:42:37 large] (main.py 226): INFO Train: [41/300][400/2502]	eta 0:23:08 lr 0.000477	time 0.7433 (0.6605)	loss 3.0187 (3.8368)	grad_norm 2.1098 (2.3812)	mem 8931MB
[2022-04-05 17:43:43 large] (main.py 226): INFO Train: [41/300][500/2502]	eta 0:22:02 lr 0.000477	time 0.6388 (0.6605)	loss 4.1742 (3.8194)	grad_norm 2.3355 (2.3886)	mem 8931MB
[2022-04-05 17:44:49 large] (main.py 226): INFO Train: [41/300][600/2502]	eta 0:20:54 lr 0.000477	time 0.6327 (0.6596)	loss 4.5174 (3.8107)	grad_norm 1.9550 (2.3988)	mem 8931MB
[2022-04-05 17:45:55 large] (main.py 226): INFO Train: [41/300][700/2502]	eta 0:19:48 lr 0.000477	time 0.6031 (0.6595)	loss 4.5144 (3.8210)	grad_norm 3.2866 (2.3884)	mem 8931MB
[2022-04-05 17:46:58 large] (main.py 226): INFO Train: [41/300][800/2502]	eta 0:18:38 lr 0.000477	time 0.5060 (0.6570)	loss 3.1737 (3.8159)	grad_norm 2.0166 (2.3837)	mem 8931MB
[2022-04-05 17:48:05 large] (main.py 226): INFO Train: [41/300][900/2502]	eta 0:17:33 lr 0.000477	time 0.6717 (0.6577)	loss 3.9033 (3.8181)	grad_norm 2.5341 (2.3862)	mem 8931MB
[2022-04-05 17:49:09 large] (main.py 226): INFO Train: [41/300][1000/2502]	eta 0:16:25 lr 0.000477	time 0.6709 (0.6559)	loss 3.4170 (3.8184)	grad_norm 2.5119 (2.3971)	mem 8931MB
[2022-04-05 17:50:15 large] (main.py 226): INFO Train: [41/300][1100/2502]	eta 0:15:20 lr 0.000477	time 0.6077 (0.6565)	loss 4.3568 (3.8151)	grad_norm 2.1387 (2.3983)	mem 8931MB
[2022-04-05 17:51:21 large] (main.py 226): INFO Train: [41/300][1200/2502]	eta 0:14:14 lr 0.000477	time 1.3358 (0.6564)	loss 4.5899 (3.8063)	grad_norm 2.6980 (2.4054)	mem 8931MB
[2022-04-05 17:52:26 large] (main.py 226): INFO Train: [41/300][1300/2502]	eta 0:13:08 lr 0.000477	time 0.4885 (0.6563)	loss 4.2808 (3.8077)	grad_norm 2.5957 (2.4172)	mem 8931MB
[2022-04-05 17:53:29 large] (main.py 226): INFO Train: [41/300][1400/2502]	eta 0:12:01 lr 0.000477	time 0.6118 (0.6547)	loss 3.4013 (3.8133)	grad_norm 2.0700 (2.4173)	mem 8931MB
[2022-04-05 17:54:20 large] (main.py 226): INFO Train: [41/300][1500/2502]	eta 0:10:46 lr 0.000477	time 0.5367 (0.6449)	loss 3.5209 (3.8145)	grad_norm 2.7239 (2.4260)	mem 8931MB
[2022-04-05 17:55:25 large] (main.py 226): INFO Train: [41/300][1600/2502]	eta 0:09:42 lr 0.000477	time 0.6674 (0.6453)	loss 3.5274 (3.8107)	grad_norm 2.2306 (inf)	mem 8931MB
[2022-04-05 17:56:31 large] (main.py 226): INFO Train: [41/300][1700/2502]	eta 0:08:38 lr 0.000477	time 0.7366 (0.6463)	loss 4.0392 (3.8085)	grad_norm 1.7688 (inf)	mem 8931MB
[2022-04-05 17:57:38 large] (main.py 226): INFO Train: [41/300][1800/2502]	eta 0:07:34 lr 0.000477	time 0.7138 (0.6472)	loss 3.6963 (3.8061)	grad_norm 2.0083 (inf)	mem 8931MB
[2022-04-05 17:58:44 large] (main.py 226): INFO Train: [41/300][1900/2502]	eta 0:06:29 lr 0.000477	time 0.6170 (0.6478)	loss 4.6125 (3.8078)	grad_norm 2.4675 (inf)	mem 8931MB
[2022-04-05 17:59:50 large] (main.py 226): INFO Train: [41/300][2000/2502]	eta 0:05:25 lr 0.000477	time 0.5842 (0.6486)	loss 4.1649 (3.8070)	grad_norm 2.5376 (inf)	mem 8931MB
[2022-04-05 18:00:56 large] (main.py 226): INFO Train: [41/300][2100/2502]	eta 0:04:20 lr 0.000477	time 0.6435 (0.6491)	loss 3.5817 (3.8031)	grad_norm 1.7048 (inf)	mem 8931MB
[2022-04-05 18:02:03 large] (main.py 226): INFO Train: [41/300][2200/2502]	eta 0:03:16 lr 0.000477	time 0.6936 (0.6500)	loss 4.5634 (3.8058)	grad_norm 2.2841 (inf)	mem 8931MB
[2022-04-05 18:03:09 large] (main.py 226): INFO Train: [41/300][2300/2502]	eta 0:02:11 lr 0.000477	time 0.6562 (0.6505)	loss 4.3244 (3.8026)	grad_norm 2.2757 (inf)	mem 8931MB
[2022-04-05 18:04:15 large] (main.py 226): INFO Train: [41/300][2400/2502]	eta 0:01:06 lr 0.000476	time 0.7142 (0.6510)	loss 4.0497 (3.8046)	grad_norm 2.0929 (inf)	mem 8931MB
[2022-04-05 18:05:20 large] (main.py 226): INFO Train: [41/300][2500/2502]	eta 0:00:01 lr 0.000476	time 0.5272 (0.6509)	loss 3.8713 (3.8043)	grad_norm 2.9540 (inf)	mem 8931MB
[2022-04-05 18:05:21 large] (main.py 233): INFO EPOCH 41 training takes 0:27:08
[2022-04-05 18:05:27 large] (main.py 273): INFO Test: [0/98]	Time 6.232 (6.232)	Loss 1.4158 (1.4158)	Acc@1 68.555 (68.555)	Acc@5 88.672 (88.672)	Mem 8931MB
[2022-04-05 18:05:53 large] (main.py 279): INFO  * Acc@1 71.348 Acc@5 90.662
[2022-04-05 18:05:53 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 71.3%
[2022-04-05 18:05:53 large] (utils.py 57): INFO output/large/default/ckpt_epoch_41.pth saving......
[2022-04-05 18:05:54 large] (utils.py 59): INFO output/large/default/ckpt_epoch_41.pth saved !!!
[2022-04-05 18:05:54 large] (main.py 148): INFO Max accuracy: 71.35%
[2022-04-05 18:06:02 large] (main.py 226): INFO Train: [42/300][0/2502]	eta 5:27:25 lr 0.000476	time 7.8519 (7.8519)	loss 3.4934 (3.4934)	grad_norm 2.3956 (2.3956)	mem 8931MB
[2022-04-05 18:06:58 large] (main.py 226): INFO Train: [42/300][100/2502]	eta 0:25:17 lr 0.000476	time 0.6354 (0.6318)	loss 2.6898 (3.8040)	grad_norm 2.4587 (2.3759)	mem 8931MB
[2022-04-05 18:08:05 large] (main.py 226): INFO Train: [42/300][200/2502]	eta 0:24:58 lr 0.000476	time 0.6182 (0.6508)	loss 4.1732 (3.8032)	grad_norm 2.7124 (2.4163)	mem 8931MB
[2022-04-05 18:09:13 large] (main.py 226): INFO Train: [42/300][300/2502]	eta 0:24:11 lr 0.000476	time 0.6057 (0.6592)	loss 2.5533 (3.7756)	grad_norm 2.2072 (2.4168)	mem 8931MB
[2022-04-05 18:10:19 large] (main.py 226): INFO Train: [42/300][400/2502]	eta 0:23:05 lr 0.000476	time 0.6157 (0.6593)	loss 2.5425 (3.7930)	grad_norm 2.5192 (2.4195)	mem 8931MB
[2022-04-05 18:11:24 large] (main.py 226): INFO Train: [42/300][500/2502]	eta 0:21:59 lr 0.000476	time 0.7384 (0.6589)	loss 3.9360 (3.8045)	grad_norm 1.8597 (2.4447)	mem 8931MB
[2022-04-05 18:12:31 large] (main.py 226): INFO Train: [42/300][600/2502]	eta 0:20:55 lr 0.000476	time 0.6931 (0.6599)	loss 4.2530 (3.7935)	grad_norm 2.2814 (2.4622)	mem 8931MB
[2022-04-05 18:13:37 large] (main.py 226): INFO Train: [42/300][700/2502]	eta 0:19:50 lr 0.000476	time 0.6925 (0.6606)	loss 3.1579 (3.8032)	grad_norm 2.0956 (2.4403)	mem 8931MB
[2022-04-05 18:14:43 large] (main.py 226): INFO Train: [42/300][800/2502]	eta 0:18:43 lr 0.000476	time 0.6535 (0.6600)	loss 4.3285 (3.8047)	grad_norm 2.1089 (2.4192)	mem 8931MB
[2022-04-05 18:15:48 large] (main.py 226): INFO Train: [42/300][900/2502]	eta 0:17:35 lr 0.000476	time 0.6765 (0.6591)	loss 4.1740 (3.8064)	grad_norm 1.8004 (2.4120)	mem 8931MB
[2022-04-05 18:16:53 large] (main.py 226): INFO Train: [42/300][1000/2502]	eta 0:16:28 lr 0.000476	time 0.6719 (0.6584)	loss 2.9715 (3.8059)	grad_norm 2.6280 (2.4108)	mem 8931MB
[2022-04-05 18:17:58 large] (main.py 226): INFO Train: [42/300][1100/2502]	eta 0:15:21 lr 0.000476	time 0.6394 (0.6574)	loss 2.9966 (3.8039)	grad_norm 1.9233 (2.4065)	mem 8931MB
[2022-04-05 18:19:03 large] (main.py 226): INFO Train: [42/300][1200/2502]	eta 0:14:14 lr 0.000476	time 0.6314 (0.6565)	loss 4.4779 (3.8044)	grad_norm 2.1823 (2.4038)	mem 8931MB
[2022-04-05 18:20:07 large] (main.py 226): INFO Train: [42/300][1300/2502]	eta 0:13:08 lr 0.000476	time 0.7287 (0.6557)	loss 3.8320 (3.8058)	grad_norm 2.1404 (2.4049)	mem 8931MB
[2022-04-05 18:21:11 large] (main.py 226): INFO Train: [42/300][1400/2502]	eta 0:12:01 lr 0.000476	time 0.6149 (0.6543)	loss 4.5041 (3.8037)	grad_norm 2.8720 (2.4064)	mem 8931MB
[2022-04-05 18:22:14 large] (main.py 226): INFO Train: [42/300][1500/2502]	eta 0:10:54 lr 0.000476	time 0.6628 (0.6528)	loss 3.0466 (3.7999)	grad_norm 2.1831 (inf)	mem 8931MB
[2022-04-05 18:23:18 large] (main.py 226): INFO Train: [42/300][1600/2502]	eta 0:09:48 lr 0.000476	time 0.7114 (0.6520)	loss 2.5079 (3.8039)	grad_norm 2.4828 (inf)	mem 8931MB
[2022-04-05 18:24:22 large] (main.py 226): INFO Train: [42/300][1700/2502]	eta 0:08:42 lr 0.000476	time 0.5869 (0.6511)	loss 3.6899 (3.8039)	grad_norm 2.2000 (inf)	mem 8931MB
[2022-04-05 18:25:26 large] (main.py 226): INFO Train: [42/300][1800/2502]	eta 0:07:36 lr 0.000476	time 0.6699 (0.6506)	loss 3.9289 (3.8008)	grad_norm 2.3826 (inf)	mem 8931MB
[2022-04-05 18:26:29 large] (main.py 226): INFO Train: [42/300][1900/2502]	eta 0:06:31 lr 0.000476	time 0.6864 (0.6496)	loss 2.9206 (3.8031)	grad_norm 2.0828 (inf)	mem 8931MB
[2022-04-05 18:27:33 large] (main.py 226): INFO Train: [42/300][2000/2502]	eta 0:05:25 lr 0.000476	time 0.6865 (0.6488)	loss 3.9150 (3.8023)	grad_norm 2.1335 (inf)	mem 8931MB
[2022-04-05 18:28:37 large] (main.py 226): INFO Train: [42/300][2100/2502]	eta 0:04:20 lr 0.000476	time 0.6075 (0.6487)	loss 2.9204 (3.7973)	grad_norm 2.6277 (inf)	mem 8931MB
[2022-04-05 18:29:41 large] (main.py 226): INFO Train: [42/300][2200/2502]	eta 0:03:15 lr 0.000475	time 0.5725 (0.6484)	loss 3.2575 (3.7979)	grad_norm 1.8481 (inf)	mem 8931MB
[2022-04-05 18:30:46 large] (main.py 226): INFO Train: [42/300][2300/2502]	eta 0:02:10 lr 0.000475	time 0.6405 (0.6484)	loss 2.2681 (3.7969)	grad_norm 2.4080 (inf)	mem 8931MB
[2022-04-05 18:31:51 large] (main.py 226): INFO Train: [42/300][2400/2502]	eta 0:01:06 lr 0.000475	time 0.6179 (0.6483)	loss 4.2964 (3.7999)	grad_norm 2.5460 (inf)	mem 8931MB
[2022-04-05 18:32:54 large] (main.py 226): INFO Train: [42/300][2500/2502]	eta 0:00:01 lr 0.000475	time 0.5628 (0.6477)	loss 4.0833 (3.8006)	grad_norm 2.3220 (inf)	mem 8931MB
[2022-04-05 18:32:55 large] (main.py 233): INFO EPOCH 42 training takes 0:27:01
[2022-04-05 18:33:02 large] (main.py 273): INFO Test: [0/98]	Time 6.593 (6.593)	Loss 1.3999 (1.3999)	Acc@1 68.164 (68.164)	Acc@5 89.453 (89.453)	Mem 8931MB
[2022-04-05 18:33:27 large] (main.py 279): INFO  * Acc@1 71.200 Acc@5 90.678
[2022-04-05 18:33:27 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 71.2%
[2022-04-05 18:33:27 large] (main.py 148): INFO Max accuracy: 71.35%
[2022-04-05 18:33:35 large] (main.py 226): INFO Train: [43/300][0/2502]	eta 5:09:23 lr 0.000475	time 7.4194 (7.4194)	loss 4.0837 (4.0837)	grad_norm 2.4251 (2.4251)	mem 8931MB
[2022-04-05 18:34:26 large] (main.py 226): INFO Train: [43/300][100/2502]	eta 0:23:09 lr 0.000475	time 0.5312 (0.5783)	loss 4.7163 (3.8447)	grad_norm 3.2752 (2.4544)	mem 8931MB
[2022-04-05 18:35:28 large] (main.py 226): INFO Train: [43/300][200/2502]	eta 0:23:01 lr 0.000475	time 0.6428 (0.6002)	loss 3.8331 (3.8130)	grad_norm 2.7631 (2.4456)	mem 8931MB
[2022-04-05 18:36:34 large] (main.py 226): INFO Train: [43/300][300/2502]	eta 0:22:46 lr 0.000475	time 0.6534 (0.6205)	loss 4.2358 (3.8569)	grad_norm 1.7951 (2.4141)	mem 8931MB
[2022-04-05 18:37:40 large] (main.py 226): INFO Train: [43/300][400/2502]	eta 0:22:05 lr 0.000475	time 0.7307 (0.6308)	loss 4.2012 (3.8321)	grad_norm 2.1179 (2.4131)	mem 8931MB
[2022-04-05 18:38:45 large] (main.py 226): INFO Train: [43/300][500/2502]	eta 0:21:11 lr 0.000475	time 0.6363 (0.6350)	loss 3.8103 (3.8137)	grad_norm 2.2514 (2.4033)	mem 8931MB
[2022-04-05 18:39:50 large] (main.py 226): INFO Train: [43/300][600/2502]	eta 0:20:12 lr 0.000475	time 0.6712 (0.6375)	loss 4.6794 (3.8123)	grad_norm 2.1420 (2.4042)	mem 8931MB
[2022-04-05 18:40:56 large] (main.py 226): INFO Train: [43/300][700/2502]	eta 0:19:12 lr 0.000475	time 0.5899 (0.6394)	loss 3.1952 (3.8180)	grad_norm 2.4383 (2.3978)	mem 8931MB
[2022-04-05 18:41:59 large] (main.py 226): INFO Train: [43/300][800/2502]	eta 0:18:08 lr 0.000475	time 0.6179 (0.6394)	loss 4.5096 (3.8150)	grad_norm 2.3516 (2.3991)	mem 8931MB
[2022-04-05 18:43:04 large] (main.py 226): INFO Train: [43/300][900/2502]	eta 0:17:05 lr 0.000475	time 0.6990 (0.6403)	loss 4.3827 (3.8158)	grad_norm 2.2075 (2.4144)	mem 8931MB
[2022-04-05 18:44:07 large] (main.py 226): INFO Train: [43/300][1000/2502]	eta 0:16:00 lr 0.000475	time 0.6112 (0.6392)	loss 4.0567 (3.8058)	grad_norm 1.9014 (2.4115)	mem 8931MB
[2022-04-05 18:45:10 large] (main.py 226): INFO Train: [43/300][1100/2502]	eta 0:14:54 lr 0.000475	time 0.5740 (0.6381)	loss 3.6978 (3.8002)	grad_norm 2.4382 (2.4091)	mem 8931MB
[2022-04-05 18:46:13 large] (main.py 226): INFO Train: [43/300][1200/2502]	eta 0:13:50 lr 0.000475	time 0.6535 (0.6377)	loss 4.2259 (3.7972)	grad_norm 2.2836 (2.4094)	mem 8931MB
[2022-04-05 18:47:17 large] (main.py 226): INFO Train: [43/300][1300/2502]	eta 0:12:46 lr 0.000475	time 0.6299 (0.6377)	loss 3.6248 (3.7963)	grad_norm 2.4813 (2.4171)	mem 8931MB
[2022-04-05 18:48:21 large] (main.py 226): INFO Train: [43/300][1400/2502]	eta 0:11:43 lr 0.000475	time 0.6119 (0.6381)	loss 2.9859 (3.7923)	grad_norm 2.0616 (2.4112)	mem 8931MB
[2022-04-05 18:49:25 large] (main.py 226): INFO Train: [43/300][1500/2502]	eta 0:10:39 lr 0.000475	time 0.6278 (0.6382)	loss 3.9868 (3.7900)	grad_norm 1.7807 (2.4095)	mem 8931MB
[2022-04-05 18:50:29 large] (main.py 226): INFO Train: [43/300][1600/2502]	eta 0:09:35 lr 0.000475	time 0.7137 (0.6382)	loss 3.7411 (3.7889)	grad_norm 2.0502 (2.4037)	mem 8931MB
[2022-04-05 18:51:33 large] (main.py 226): INFO Train: [43/300][1700/2502]	eta 0:08:31 lr 0.000475	time 0.5980 (0.6383)	loss 4.3162 (3.7867)	grad_norm 1.8596 (2.4056)	mem 8931MB
[2022-04-05 18:52:37 large] (main.py 226): INFO Train: [43/300][1800/2502]	eta 0:07:28 lr 0.000475	time 0.6293 (0.6383)	loss 3.0970 (3.7876)	grad_norm 2.0912 (2.4013)	mem 8931MB
[2022-04-05 18:53:40 large] (main.py 226): INFO Train: [43/300][1900/2502]	eta 0:06:23 lr 0.000474	time 0.6004 (0.6379)	loss 4.0634 (3.7915)	grad_norm 2.0482 (2.3971)	mem 8931MB
[2022-04-05 18:54:44 large] (main.py 226): INFO Train: [43/300][2000/2502]	eta 0:05:20 lr 0.000474	time 0.6030 (0.6380)	loss 3.8499 (3.7905)	grad_norm 1.8049 (2.3977)	mem 8931MB
[2022-04-05 18:55:48 large] (main.py 226): INFO Train: [43/300][2100/2502]	eta 0:04:16 lr 0.000474	time 0.5913 (0.6383)	loss 3.9279 (3.7864)	grad_norm 3.8702 (2.3970)	mem 8931MB
[2022-04-05 18:56:52 large] (main.py 226): INFO Train: [43/300][2200/2502]	eta 0:03:12 lr 0.000474	time 0.6535 (0.6380)	loss 3.4703 (3.7843)	grad_norm 3.0176 (2.3969)	mem 8931MB
[2022-04-05 18:57:56 large] (main.py 226): INFO Train: [43/300][2300/2502]	eta 0:02:08 lr 0.000474	time 0.6332 (0.6381)	loss 4.2139 (3.7871)	grad_norm 3.3448 (2.3958)	mem 8931MB
[2022-04-05 18:58:59 large] (main.py 226): INFO Train: [43/300][2400/2502]	eta 0:01:05 lr 0.000474	time 0.5817 (0.6379)	loss 4.7232 (3.7891)	grad_norm 2.6981 (2.4060)	mem 8931MB
[2022-04-05 19:00:02 large] (main.py 226): INFO Train: [43/300][2500/2502]	eta 0:00:01 lr 0.000474	time 0.6264 (0.6377)	loss 3.8007 (3.7882)	grad_norm 1.8622 (2.4087)	mem 8931MB
[2022-04-05 19:00:03 large] (main.py 233): INFO EPOCH 43 training takes 0:26:35
[2022-04-05 19:00:09 large] (main.py 273): INFO Test: [0/98]	Time 6.224 (6.224)	Loss 1.4094 (1.4094)	Acc@1 70.898 (70.898)	Acc@5 89.453 (89.453)	Mem 8931MB
[2022-04-05 19:00:35 large] (main.py 279): INFO  * Acc@1 71.428 Acc@5 90.768
[2022-04-05 19:00:35 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 71.4%
[2022-04-05 19:00:35 large] (utils.py 57): INFO output/large/default/ckpt_epoch_43.pth saving......
[2022-04-05 19:00:37 large] (utils.py 59): INFO output/large/default/ckpt_epoch_43.pth saved !!!
[2022-04-05 19:00:37 large] (main.py 148): INFO Max accuracy: 71.43%
[2022-04-05 19:00:44 large] (main.py 226): INFO Train: [44/300][0/2502]	eta 4:56:56 lr 0.000474	time 7.1209 (7.1209)	loss 4.0631 (4.0631)	grad_norm 2.8061 (2.8061)	mem 8931MB
[2022-04-05 19:01:36 large] (main.py 226): INFO Train: [44/300][100/2502]	eta 0:23:39 lr 0.000474	time 0.6346 (0.5911)	loss 4.1525 (3.7468)	grad_norm 1.9796 (inf)	mem 8931MB
[2022-04-05 19:02:42 large] (main.py 226): INFO Train: [44/300][200/2502]	eta 0:23:52 lr 0.000474	time 0.7477 (0.6221)	loss 4.6139 (3.7492)	grad_norm 2.7725 (inf)	mem 8931MB
[2022-04-05 19:03:46 large] (main.py 226): INFO Train: [44/300][300/2502]	eta 0:23:07 lr 0.000474	time 0.6367 (0.6301)	loss 4.3202 (3.7426)	grad_norm 2.3707 (inf)	mem 8931MB
[2022-04-05 19:04:52 large] (main.py 226): INFO Train: [44/300][400/2502]	eta 0:22:19 lr 0.000474	time 0.5311 (0.6374)	loss 3.7917 (3.7347)	grad_norm 2.0234 (inf)	mem 8931MB
[2022-04-05 19:05:57 large] (main.py 226): INFO Train: [44/300][500/2502]	eta 0:21:20 lr 0.000474	time 0.6290 (0.6397)	loss 2.8131 (3.7566)	grad_norm 2.9601 (inf)	mem 8931MB
[2022-04-05 19:07:02 large] (main.py 226): INFO Train: [44/300][600/2502]	eta 0:20:20 lr 0.000474	time 0.6613 (0.6418)	loss 3.9590 (3.7571)	grad_norm 2.0214 (inf)	mem 8931MB
[2022-04-05 19:08:06 large] (main.py 226): INFO Train: [44/300][700/2502]	eta 0:19:16 lr 0.000474	time 0.6735 (0.6415)	loss 4.6378 (3.7547)	grad_norm 2.3155 (inf)	mem 8931MB
[2022-04-05 19:09:12 large] (main.py 226): INFO Train: [44/300][800/2502]	eta 0:18:14 lr 0.000474	time 0.6096 (0.6432)	loss 2.7471 (3.7543)	grad_norm 2.7713 (inf)	mem 8931MB
[2022-04-05 19:10:16 large] (main.py 226): INFO Train: [44/300][900/2502]	eta 0:17:10 lr 0.000474	time 0.6056 (0.6434)	loss 3.1494 (3.7629)	grad_norm 1.8251 (inf)	mem 8931MB
[2022-04-05 19:11:22 large] (main.py 226): INFO Train: [44/300][1000/2502]	eta 0:16:07 lr 0.000474	time 0.6443 (0.6442)	loss 4.1285 (3.7786)	grad_norm 2.2493 (inf)	mem 8931MB
[2022-04-05 19:12:26 large] (main.py 226): INFO Train: [44/300][1100/2502]	eta 0:15:03 lr 0.000474	time 0.5925 (0.6446)	loss 3.1664 (3.7858)	grad_norm 1.8523 (inf)	mem 8931MB
[2022-04-05 19:13:33 large] (main.py 226): INFO Train: [44/300][1200/2502]	eta 0:14:01 lr 0.000474	time 0.6659 (0.6462)	loss 4.2571 (3.7853)	grad_norm 2.6508 (inf)	mem 8931MB
[2022-04-05 19:14:36 large] (main.py 226): INFO Train: [44/300][1300/2502]	eta 0:12:55 lr 0.000474	time 0.7373 (0.6451)	loss 3.3076 (3.7791)	grad_norm 2.6864 (inf)	mem 8931MB
[2022-04-05 19:15:42 large] (main.py 226): INFO Train: [44/300][1400/2502]	eta 0:11:51 lr 0.000474	time 0.7404 (0.6458)	loss 4.0951 (3.7747)	grad_norm 2.1274 (inf)	mem 8931MB
[2022-04-05 19:16:47 large] (main.py 226): INFO Train: [44/300][1500/2502]	eta 0:10:47 lr 0.000473	time 0.6652 (0.6461)	loss 3.1833 (3.7789)	grad_norm 2.6155 (inf)	mem 8931MB
[2022-04-05 19:17:53 large] (main.py 226): INFO Train: [44/300][1600/2502]	eta 0:09:43 lr 0.000473	time 0.6154 (0.6470)	loss 4.0517 (3.7812)	grad_norm 2.1680 (inf)	mem 8931MB
[2022-04-05 19:18:58 large] (main.py 226): INFO Train: [44/300][1700/2502]	eta 0:08:39 lr 0.000473	time 0.6190 (0.6474)	loss 3.1767 (3.7752)	grad_norm 2.2548 (inf)	mem 8931MB
[2022-04-05 19:20:04 large] (main.py 226): INFO Train: [44/300][1800/2502]	eta 0:07:34 lr 0.000473	time 0.6641 (0.6480)	loss 3.5319 (3.7742)	grad_norm 2.0341 (inf)	mem 8931MB
[2022-04-05 19:21:09 large] (main.py 226): INFO Train: [44/300][1900/2502]	eta 0:06:30 lr 0.000473	time 0.6152 (0.6481)	loss 4.5210 (3.7739)	grad_norm 2.9409 (inf)	mem 8931MB
[2022-04-05 19:22:13 large] (main.py 226): INFO Train: [44/300][2000/2502]	eta 0:05:25 lr 0.000473	time 0.6104 (0.6480)	loss 3.6678 (3.7776)	grad_norm 1.8254 (inf)	mem 8931MB
[2022-04-05 19:23:19 large] (main.py 226): INFO Train: [44/300][2100/2502]	eta 0:04:20 lr 0.000473	time 0.6250 (0.6483)	loss 4.1741 (3.7820)	grad_norm 2.5291 (inf)	mem 8931MB
[2022-04-05 19:24:24 large] (main.py 226): INFO Train: [44/300][2200/2502]	eta 0:03:15 lr 0.000473	time 1.2140 (0.6485)	loss 4.1754 (3.7860)	grad_norm 2.1144 (inf)	mem 8931MB
[2022-04-05 19:25:29 large] (main.py 226): INFO Train: [44/300][2300/2502]	eta 0:02:11 lr 0.000473	time 0.5141 (0.6486)	loss 4.0906 (3.7830)	grad_norm 1.7861 (inf)	mem 8931MB
[2022-04-05 19:26:35 large] (main.py 226): INFO Train: [44/300][2400/2502]	eta 0:01:06 lr 0.000473	time 0.7365 (0.6491)	loss 2.8473 (3.7809)	grad_norm 2.2206 (inf)	mem 8931MB
[2022-04-05 19:27:39 large] (main.py 226): INFO Train: [44/300][2500/2502]	eta 0:00:01 lr 0.000473	time 0.5325 (0.6487)	loss 3.1492 (3.7786)	grad_norm 3.0385 (inf)	mem 8931MB
[2022-04-05 19:27:40 large] (main.py 233): INFO EPOCH 44 training takes 0:27:03
[2022-04-05 19:27:47 large] (main.py 273): INFO Test: [0/98]	Time 6.752 (6.752)	Loss 1.4412 (1.4412)	Acc@1 71.680 (71.680)	Acc@5 87.891 (87.891)	Mem 8931MB
[2022-04-05 19:28:13 large] (main.py 279): INFO  * Acc@1 71.372 Acc@5 90.670
[2022-04-05 19:28:13 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 71.4%
[2022-04-05 19:28:13 large] (main.py 148): INFO Max accuracy: 71.43%
[2022-04-05 19:28:20 large] (main.py 226): INFO Train: [45/300][0/2502]	eta 4:59:16 lr 0.000473	time 7.1769 (7.1769)	loss 4.3195 (4.3195)	grad_norm 2.1087 (2.1087)	mem 8931MB
[2022-04-05 19:29:18 large] (main.py 226): INFO Train: [45/300][100/2502]	eta 0:25:50 lr 0.000473	time 0.6697 (0.6455)	loss 4.7374 (3.8146)	grad_norm 2.0934 (2.3912)	mem 8931MB
[2022-04-05 19:30:23 large] (main.py 226): INFO Train: [45/300][200/2502]	eta 0:24:51 lr 0.000473	time 0.6151 (0.6480)	loss 3.9481 (3.7426)	grad_norm 2.3221 (2.4250)	mem 8931MB
[2022-04-05 19:31:29 large] (main.py 226): INFO Train: [45/300][300/2502]	eta 0:23:53 lr 0.000473	time 0.6568 (0.6511)	loss 4.0234 (3.7662)	grad_norm 2.1969 (2.4083)	mem 8931MB
[2022-04-05 19:32:33 large] (main.py 226): INFO Train: [45/300][400/2502]	eta 0:22:47 lr 0.000473	time 0.7098 (0.6505)	loss 2.8821 (3.7740)	grad_norm 2.2313 (2.4304)	mem 8931MB
[2022-04-05 19:33:38 large] (main.py 226): INFO Train: [45/300][500/2502]	eta 0:21:41 lr 0.000473	time 0.6528 (0.6503)	loss 3.9369 (3.7748)	grad_norm 2.1296 (2.3995)	mem 8931MB
[2022-04-05 19:34:44 large] (main.py 226): INFO Train: [45/300][600/2502]	eta 0:20:39 lr 0.000473	time 0.7113 (0.6516)	loss 3.6974 (3.7619)	grad_norm 1.8583 (2.4264)	mem 8931MB
[2022-04-05 19:35:48 large] (main.py 226): INFO Train: [45/300][700/2502]	eta 0:19:30 lr 0.000473	time 0.6368 (0.6493)	loss 3.9140 (3.7630)	grad_norm 2.5891 (2.4353)	mem 8931MB
[2022-04-05 19:36:51 large] (main.py 226): INFO Train: [45/300][800/2502]	eta 0:18:21 lr 0.000473	time 0.6566 (0.6472)	loss 4.5970 (3.7614)	grad_norm 2.1386 (2.4260)	mem 8931MB
[2022-04-05 19:37:57 large] (main.py 226): INFO Train: [45/300][900/2502]	eta 0:17:18 lr 0.000473	time 0.6160 (0.6482)	loss 3.5469 (3.7638)	grad_norm 2.8319 (2.4169)	mem 8931MB
[2022-04-05 19:38:59 large] (main.py 226): INFO Train: [45/300][1000/2502]	eta 0:16:09 lr 0.000473	time 0.5999 (0.6455)	loss 3.6989 (3.7638)	grad_norm 2.7852 (2.4174)	mem 8931MB
[2022-04-05 19:40:03 large] (main.py 226): INFO Train: [45/300][1100/2502]	eta 0:15:04 lr 0.000473	time 0.5148 (0.6452)	loss 3.7330 (3.7648)	grad_norm 2.4155 (2.4093)	mem 8931MB
[2022-04-05 19:41:07 large] (main.py 226): INFO Train: [45/300][1200/2502]	eta 0:13:59 lr 0.000472	time 0.6327 (0.6449)	loss 2.9557 (3.7585)	grad_norm 2.6367 (2.4031)	mem 8931MB
[2022-04-05 19:42:11 large] (main.py 226): INFO Train: [45/300][1300/2502]	eta 0:12:55 lr 0.000472	time 0.5823 (0.6448)	loss 3.8963 (3.7611)	grad_norm 2.7173 (2.4078)	mem 8931MB
[2022-04-05 19:43:15 large] (main.py 226): INFO Train: [45/300][1400/2502]	eta 0:11:50 lr 0.000472	time 0.6978 (0.6443)	loss 3.2289 (3.7640)	grad_norm 3.5174 (2.4047)	mem 8931MB
[2022-04-05 19:44:19 large] (main.py 226): INFO Train: [45/300][1500/2502]	eta 0:10:45 lr 0.000472	time 0.4988 (0.6439)	loss 3.5175 (3.7660)	grad_norm 2.1372 (2.4092)	mem 8931MB
[2022-04-05 19:45:23 large] (main.py 226): INFO Train: [45/300][1600/2502]	eta 0:09:40 lr 0.000472	time 0.6680 (0.6438)	loss 4.0373 (3.7681)	grad_norm 2.3198 (2.4072)	mem 8931MB
[2022-04-05 19:46:28 large] (main.py 226): INFO Train: [45/300][1700/2502]	eta 0:08:36 lr 0.000472	time 0.5489 (0.6442)	loss 2.6076 (3.7697)	grad_norm 2.3685 (2.4071)	mem 8931MB
[2022-04-05 19:47:33 large] (main.py 226): INFO Train: [45/300][1800/2502]	eta 0:07:32 lr 0.000472	time 0.6469 (0.6442)	loss 3.6170 (3.7762)	grad_norm 2.6702 (2.4080)	mem 8931MB
[2022-04-05 19:48:38 large] (main.py 226): INFO Train: [45/300][1900/2502]	eta 0:06:28 lr 0.000472	time 0.5732 (0.6448)	loss 3.0719 (3.7789)	grad_norm 2.1342 (2.4061)	mem 8931MB
[2022-04-05 19:49:42 large] (main.py 226): INFO Train: [45/300][2000/2502]	eta 0:05:23 lr 0.000472	time 0.6972 (0.6446)	loss 3.9134 (3.7820)	grad_norm 2.2444 (inf)	mem 8931MB
[2022-04-05 19:50:46 large] (main.py 226): INFO Train: [45/300][2100/2502]	eta 0:04:19 lr 0.000472	time 0.4987 (0.6444)	loss 4.0064 (3.7860)	grad_norm 2.9914 (inf)	mem 8931MB
[2022-04-05 19:51:52 large] (main.py 226): INFO Train: [45/300][2200/2502]	eta 0:03:14 lr 0.000472	time 0.6620 (0.6448)	loss 4.4087 (3.7867)	grad_norm 2.7185 (inf)	mem 8931MB
[2022-04-05 19:52:56 large] (main.py 226): INFO Train: [45/300][2300/2502]	eta 0:02:10 lr 0.000472	time 0.6285 (0.6446)	loss 4.3440 (3.7870)	grad_norm 2.3792 (inf)	mem 8931MB
[2022-04-05 19:54:01 large] (main.py 226): INFO Train: [45/300][2400/2502]	eta 0:01:05 lr 0.000472	time 0.6628 (0.6448)	loss 4.0622 (3.7870)	grad_norm 1.9048 (inf)	mem 8931MB
[2022-04-05 19:55:05 large] (main.py 226): INFO Train: [45/300][2500/2502]	eta 0:00:01 lr 0.000472	time 0.5690 (0.6446)	loss 3.4321 (3.7841)	grad_norm 2.1660 (inf)	mem 8931MB
[2022-04-05 19:55:06 large] (main.py 233): INFO EPOCH 45 training takes 0:26:53
[2022-04-05 19:55:13 large] (main.py 273): INFO Test: [0/98]	Time 7.051 (7.051)	Loss 1.3020 (1.3020)	Acc@1 70.703 (70.703)	Acc@5 90.625 (90.625)	Mem 8931MB
[2022-04-05 19:55:38 large] (main.py 279): INFO  * Acc@1 71.944 Acc@5 90.928
[2022-04-05 19:55:38 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 71.9%
[2022-04-05 19:55:38 large] (utils.py 57): INFO output/large/default/ckpt_epoch_45.pth saving......
[2022-04-05 19:55:39 large] (utils.py 59): INFO output/large/default/ckpt_epoch_45.pth saved !!!
[2022-04-05 19:55:39 large] (main.py 148): INFO Max accuracy: 71.94%
[2022-04-05 19:55:47 large] (main.py 226): INFO Train: [46/300][0/2502]	eta 5:24:51 lr 0.000472	time 7.7904 (7.7904)	loss 3.6836 (3.6836)	grad_norm 2.2267 (2.2267)	mem 8931MB
[2022-04-05 19:56:37 large] (main.py 226): INFO Train: [46/300][100/2502]	eta 0:22:49 lr 0.000472	time 0.5501 (0.5700)	loss 3.9661 (3.6725)	grad_norm 2.9705 (2.3494)	mem 8931MB
[2022-04-05 19:57:40 large] (main.py 226): INFO Train: [46/300][200/2502]	eta 0:23:01 lr 0.000472	time 0.5665 (0.6000)	loss 3.0563 (3.7484)	grad_norm 2.7263 (2.3597)	mem 8931MB
[2022-04-05 19:58:44 large] (main.py 226): INFO Train: [46/300][300/2502]	eta 0:22:34 lr 0.000472	time 0.6291 (0.6150)	loss 3.3251 (3.7621)	grad_norm 2.4477 (2.3903)	mem 8931MB
[2022-04-05 19:59:50 large] (main.py 226): INFO Train: [46/300][400/2502]	eta 0:21:56 lr 0.000472	time 0.6799 (0.6264)	loss 3.6380 (3.7735)	grad_norm 2.1728 (2.3865)	mem 8931MB
[2022-04-05 20:00:56 large] (main.py 226): INFO Train: [46/300][500/2502]	eta 0:21:04 lr 0.000472	time 0.6248 (0.6318)	loss 2.8033 (3.7868)	grad_norm 2.2363 (2.3860)	mem 8931MB
[2022-04-05 20:02:01 large] (main.py 226): INFO Train: [46/300][600/2502]	eta 0:20:07 lr 0.000472	time 0.7539 (0.6347)	loss 4.5905 (3.7852)	grad_norm 1.9599 (2.3895)	mem 8931MB
[2022-04-05 20:03:05 large] (main.py 226): INFO Train: [46/300][700/2502]	eta 0:19:06 lr 0.000471	time 0.6603 (0.6362)	loss 3.7453 (3.7835)	grad_norm 4.0452 (2.3988)	mem 8931MB
[2022-04-05 20:04:10 large] (main.py 226): INFO Train: [46/300][800/2502]	eta 0:18:05 lr 0.000471	time 0.6515 (0.6380)	loss 4.1801 (3.7807)	grad_norm 2.6888 (2.4034)	mem 8931MB
[2022-04-05 20:05:16 large] (main.py 226): INFO Train: [46/300][900/2502]	eta 0:17:05 lr 0.000471	time 0.6321 (0.6402)	loss 4.3464 (3.7783)	grad_norm 2.2593 (2.4083)	mem 8931MB
[2022-04-05 20:06:16 large] (main.py 226): INFO Train: [46/300][1000/2502]	eta 0:15:55 lr 0.000471	time 0.5423 (0.6359)	loss 4.4634 (3.7713)	grad_norm 2.1688 (2.4056)	mem 8931MB
[2022-04-05 20:07:12 large] (main.py 226): INFO Train: [46/300][1100/2502]	eta 0:14:41 lr 0.000471	time 0.6335 (0.6289)	loss 4.0643 (3.7684)	grad_norm 4.2805 (2.4127)	mem 8931MB
[2022-04-05 20:08:17 large] (main.py 226): INFO Train: [46/300][1200/2502]	eta 0:13:41 lr 0.000471	time 0.6687 (0.6309)	loss 3.3137 (3.7681)	grad_norm 1.9262 (2.4106)	mem 8931MB
[2022-04-05 20:09:22 large] (main.py 226): INFO Train: [46/300][1300/2502]	eta 0:12:39 lr 0.000471	time 0.6380 (0.6322)	loss 3.2664 (3.7703)	grad_norm 2.0748 (2.4140)	mem 8931MB
[2022-04-05 20:10:27 large] (main.py 226): INFO Train: [46/300][1400/2502]	eta 0:11:38 lr 0.000471	time 0.6069 (0.6336)	loss 3.1623 (3.7793)	grad_norm 3.2817 (2.4198)	mem 8931MB
[2022-04-05 20:11:32 large] (main.py 226): INFO Train: [46/300][1500/2502]	eta 0:10:35 lr 0.000471	time 0.6683 (0.6346)	loss 3.9749 (3.7786)	grad_norm 1.7165 (2.4285)	mem 8931MB
[2022-04-05 20:12:36 large] (main.py 226): INFO Train: [46/300][1600/2502]	eta 0:09:33 lr 0.000471	time 0.6258 (0.6353)	loss 4.5419 (3.7838)	grad_norm 2.4932 (2.4264)	mem 8931MB
[2022-04-05 20:13:41 large] (main.py 226): INFO Train: [46/300][1700/2502]	eta 0:08:30 lr 0.000471	time 0.6701 (0.6359)	loss 4.6752 (3.7844)	grad_norm 2.1145 (2.4216)	mem 8931MB
[2022-04-05 20:14:47 large] (main.py 226): INFO Train: [46/300][1800/2502]	eta 0:07:27 lr 0.000471	time 0.7109 (0.6371)	loss 4.0147 (3.7827)	grad_norm 2.7746 (2.4294)	mem 8931MB
[2022-04-05 20:15:52 large] (main.py 226): INFO Train: [46/300][1900/2502]	eta 0:06:23 lr 0.000471	time 0.6713 (0.6378)	loss 4.0260 (3.7845)	grad_norm 3.0285 (2.4343)	mem 8931MB
[2022-04-05 20:16:56 large] (main.py 226): INFO Train: [46/300][2000/2502]	eta 0:05:20 lr 0.000471	time 0.6723 (0.6383)	loss 4.4850 (3.7879)	grad_norm 2.7980 (2.4288)	mem 8931MB
[2022-04-05 20:18:01 large] (main.py 226): INFO Train: [46/300][2100/2502]	eta 0:04:16 lr 0.000471	time 0.6701 (0.6385)	loss 4.0869 (3.7889)	grad_norm 2.6253 (2.4319)	mem 8931MB
[2022-04-05 20:19:05 large] (main.py 226): INFO Train: [46/300][2200/2502]	eta 0:03:12 lr 0.000471	time 0.5658 (0.6389)	loss 3.6199 (3.7892)	grad_norm 1.8900 (2.4308)	mem 8931MB
[2022-04-05 20:20:10 large] (main.py 226): INFO Train: [46/300][2300/2502]	eta 0:02:09 lr 0.000471	time 0.6146 (0.6390)	loss 2.7780 (3.7871)	grad_norm 2.1919 (2.4293)	mem 8931MB
[2022-04-05 20:21:15 large] (main.py 226): INFO Train: [46/300][2400/2502]	eta 0:01:05 lr 0.000471	time 0.5777 (0.6395)	loss 3.1004 (3.7876)	grad_norm 2.8647 (2.4258)	mem 8931MB
[2022-04-05 20:22:18 large] (main.py 226): INFO Train: [46/300][2500/2502]	eta 0:00:01 lr 0.000471	time 0.5927 (0.6394)	loss 2.6660 (3.7892)	grad_norm 2.6965 (2.4285)	mem 8931MB
[2022-04-05 20:22:19 large] (main.py 233): INFO EPOCH 46 training takes 0:26:40
[2022-04-05 20:22:26 large] (main.py 273): INFO Test: [0/98]	Time 6.092 (6.092)	Loss 1.3525 (1.3525)	Acc@1 70.898 (70.898)	Acc@5 90.820 (90.820)	Mem 8931MB
[2022-04-05 20:22:51 large] (main.py 279): INFO  * Acc@1 71.508 Acc@5 90.896
[2022-04-05 20:22:51 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 71.5%
[2022-04-05 20:22:51 large] (main.py 148): INFO Max accuracy: 71.94%
[2022-04-05 20:22:58 large] (main.py 226): INFO Train: [47/300][0/2502]	eta 4:58:56 lr 0.000471	time 7.1688 (7.1688)	loss 3.4412 (3.4412)	grad_norm inf (inf)	mem 8931MB
[2022-04-05 20:23:58 large] (main.py 226): INFO Train: [47/300][100/2502]	eta 0:26:23 lr 0.000471	time 0.6490 (0.6594)	loss 4.6505 (3.7341)	grad_norm 2.8821 (inf)	mem 8931MB
[2022-04-05 20:25:04 large] (main.py 226): INFO Train: [47/300][200/2502]	eta 0:25:18 lr 0.000471	time 0.7495 (0.6596)	loss 2.6975 (3.7552)	grad_norm 2.6022 (inf)	mem 8931MB
[2022-04-05 20:26:09 large] (main.py 226): INFO Train: [47/300][300/2502]	eta 0:24:07 lr 0.000470	time 0.6681 (0.6571)	loss 3.4700 (3.7549)	grad_norm 2.0735 (inf)	mem 8931MB
[2022-04-05 20:27:14 large] (main.py 226): INFO Train: [47/300][400/2502]	eta 0:22:55 lr 0.000470	time 0.6458 (0.6545)	loss 3.7663 (3.7907)	grad_norm 2.6208 (inf)	mem 8931MB
[2022-04-05 20:28:18 large] (main.py 226): INFO Train: [47/300][500/2502]	eta 0:21:44 lr 0.000470	time 0.6462 (0.6518)	loss 3.9102 (3.7609)	grad_norm 2.8702 (inf)	mem 8931MB
[2022-04-05 20:29:22 large] (main.py 226): INFO Train: [47/300][600/2502]	eta 0:20:37 lr 0.000470	time 0.6322 (0.6507)	loss 2.8010 (3.7561)	grad_norm 2.1521 (inf)	mem 8931MB
[2022-04-05 20:30:26 large] (main.py 226): INFO Train: [47/300][700/2502]	eta 0:19:29 lr 0.000470	time 0.6531 (0.6490)	loss 3.3543 (3.7696)	grad_norm 2.2936 (inf)	mem 8931MB
[2022-04-05 20:31:31 large] (main.py 226): INFO Train: [47/300][800/2502]	eta 0:18:23 lr 0.000470	time 0.6936 (0.6484)	loss 3.9041 (3.7782)	grad_norm 2.5129 (inf)	mem 8931MB
[2022-04-05 20:32:34 large] (main.py 226): INFO Train: [47/300][900/2502]	eta 0:17:15 lr 0.000470	time 0.5185 (0.6466)	loss 4.3331 (3.7736)	grad_norm 2.6104 (inf)	mem 8931MB
[2022-04-05 20:33:37 large] (main.py 226): INFO Train: [47/300][1000/2502]	eta 0:16:09 lr 0.000470	time 0.5835 (0.6455)	loss 4.3853 (3.7679)	grad_norm 2.1485 (inf)	mem 8931MB
[2022-04-05 20:34:41 large] (main.py 226): INFO Train: [47/300][1100/2502]	eta 0:15:03 lr 0.000470	time 0.6042 (0.6447)	loss 3.5432 (3.7655)	grad_norm 2.0048 (inf)	mem 8931MB
[2022-04-05 20:35:45 large] (main.py 226): INFO Train: [47/300][1200/2502]	eta 0:13:58 lr 0.000470	time 0.6254 (0.6441)	loss 3.2244 (3.7612)	grad_norm 2.2749 (inf)	mem 8931MB
[2022-04-05 20:36:48 large] (main.py 226): INFO Train: [47/300][1300/2502]	eta 0:12:52 lr 0.000470	time 0.5823 (0.6431)	loss 3.6483 (3.7570)	grad_norm 2.2765 (inf)	mem 8931MB
[2022-04-05 20:37:52 large] (main.py 226): INFO Train: [47/300][1400/2502]	eta 0:11:48 lr 0.000470	time 0.6189 (0.6426)	loss 4.2169 (3.7627)	grad_norm 1.7216 (inf)	mem 8931MB
[2022-04-05 20:38:55 large] (main.py 226): INFO Train: [47/300][1500/2502]	eta 0:10:43 lr 0.000470	time 0.5949 (0.6420)	loss 3.6527 (3.7650)	grad_norm 2.9958 (inf)	mem 8931MB
[2022-04-05 20:39:58 large] (main.py 226): INFO Train: [47/300][1600/2502]	eta 0:09:38 lr 0.000470	time 0.6131 (0.6415)	loss 3.3540 (3.7718)	grad_norm 2.1608 (inf)	mem 8931MB
[2022-04-05 20:41:03 large] (main.py 226): INFO Train: [47/300][1700/2502]	eta 0:08:34 lr 0.000470	time 0.5113 (0.6416)	loss 2.7262 (3.7688)	grad_norm 2.2927 (inf)	mem 8931MB
[2022-04-05 20:42:06 large] (main.py 226): INFO Train: [47/300][1800/2502]	eta 0:07:30 lr 0.000470	time 0.7134 (0.6413)	loss 4.5692 (3.7717)	grad_norm 1.9280 (inf)	mem 8931MB
[2022-04-05 20:43:11 large] (main.py 226): INFO Train: [47/300][1900/2502]	eta 0:06:26 lr 0.000470	time 0.7317 (0.6417)	loss 2.8749 (3.7687)	grad_norm 1.9432 (inf)	mem 8931MB
[2022-04-05 20:44:15 large] (main.py 226): INFO Train: [47/300][2000/2502]	eta 0:05:21 lr 0.000470	time 0.6299 (0.6414)	loss 2.7328 (3.7648)	grad_norm 2.7586 (inf)	mem 8931MB
[2022-04-05 20:45:18 large] (main.py 226): INFO Train: [47/300][2100/2502]	eta 0:04:17 lr 0.000470	time 0.6452 (0.6411)	loss 4.1701 (3.7660)	grad_norm 2.5786 (inf)	mem 8931MB
[2022-04-05 20:46:22 large] (main.py 226): INFO Train: [47/300][2200/2502]	eta 0:03:13 lr 0.000470	time 0.6454 (0.6411)	loss 4.0491 (3.7685)	grad_norm 2.3041 (inf)	mem 8931MB
[2022-04-05 20:47:26 large] (main.py 226): INFO Train: [47/300][2300/2502]	eta 0:02:09 lr 0.000469	time 0.5923 (0.6409)	loss 3.3973 (3.7656)	grad_norm 2.4977 (inf)	mem 8931MB
[2022-04-05 20:48:30 large] (main.py 226): INFO Train: [47/300][2400/2502]	eta 0:01:05 lr 0.000469	time 0.6024 (0.6410)	loss 3.5430 (3.7649)	grad_norm 2.2470 (inf)	mem 8931MB
[2022-04-05 20:49:33 large] (main.py 226): INFO Train: [47/300][2500/2502]	eta 0:00:01 lr 0.000469	time 0.6464 (0.6404)	loss 3.9046 (3.7641)	grad_norm 2.2525 (inf)	mem 8931MB
[2022-04-05 20:49:34 large] (main.py 233): INFO EPOCH 47 training takes 0:26:42
[2022-04-05 20:49:40 large] (main.py 273): INFO Test: [0/98]	Time 5.674 (5.674)	Loss 1.3471 (1.3471)	Acc@1 71.484 (71.484)	Acc@5 90.625 (90.625)	Mem 8931MB
[2022-04-05 20:50:07 large] (main.py 279): INFO  * Acc@1 71.972 Acc@5 90.934
[2022-04-05 20:50:07 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.0%
[2022-04-05 20:50:07 large] (utils.py 57): INFO output/large/default/ckpt_epoch_47.pth saving......
[2022-04-05 20:50:08 large] (utils.py 59): INFO output/large/default/ckpt_epoch_47.pth saved !!!
[2022-04-05 20:50:08 large] (main.py 148): INFO Max accuracy: 71.97%
[2022-04-05 20:50:15 large] (main.py 226): INFO Train: [48/300][0/2502]	eta 5:01:02 lr 0.000469	time 7.2192 (7.2192)	loss 4.5881 (4.5881)	grad_norm 2.4371 (2.4371)	mem 8931MB
[2022-04-05 20:51:07 large] (main.py 226): INFO Train: [48/300][100/2502]	eta 0:23:26 lr 0.000469	time 0.5839 (0.5857)	loss 4.4412 (3.6219)	grad_norm 2.7924 (2.4869)	mem 8931MB
[2022-04-05 20:52:11 large] (main.py 226): INFO Train: [48/300][200/2502]	eta 0:23:26 lr 0.000469	time 0.6182 (0.6112)	loss 2.7304 (3.7260)	grad_norm 2.2064 (2.5246)	mem 8931MB
[2022-04-05 20:53:15 large] (main.py 226): INFO Train: [48/300][300/2502]	eta 0:22:52 lr 0.000469	time 1.5159 (0.6232)	loss 2.7725 (3.7322)	grad_norm 2.2931 (2.5080)	mem 8931MB
[2022-04-05 20:54:19 large] (main.py 226): INFO Train: [48/300][400/2502]	eta 0:21:58 lr 0.000469	time 0.6760 (0.6272)	loss 2.6016 (3.7411)	grad_norm 2.0410 (2.4976)	mem 8931MB
[2022-04-05 20:55:23 large] (main.py 226): INFO Train: [48/300][500/2502]	eta 0:21:01 lr 0.000469	time 0.6691 (0.6299)	loss 3.1570 (3.7307)	grad_norm 2.7252 (2.5308)	mem 8931MB
[2022-04-05 20:56:27 large] (main.py 226): INFO Train: [48/300][600/2502]	eta 0:20:01 lr 0.000469	time 0.6082 (0.6316)	loss 3.9414 (3.7557)	grad_norm 2.4198 (2.5098)	mem 8931MB
[2022-04-05 20:57:31 large] (main.py 226): INFO Train: [48/300][700/2502]	eta 0:18:59 lr 0.000469	time 0.7010 (0.6324)	loss 4.5289 (3.7599)	grad_norm 1.9018 (2.4976)	mem 8931MB
[2022-04-05 20:58:34 large] (main.py 226): INFO Train: [48/300][800/2502]	eta 0:17:56 lr 0.000469	time 0.6430 (0.6326)	loss 4.2353 (3.7679)	grad_norm 2.7595 (2.4840)	mem 8931MB
[2022-04-05 20:59:38 large] (main.py 226): INFO Train: [48/300][900/2502]	eta 0:16:53 lr 0.000469	time 0.5203 (0.6327)	loss 4.7920 (3.7720)	grad_norm 2.5608 (2.4875)	mem 8931MB
[2022-04-05 21:00:41 large] (main.py 226): INFO Train: [48/300][1000/2502]	eta 0:15:50 lr 0.000469	time 0.6624 (0.6328)	loss 3.6765 (3.7671)	grad_norm 2.6604 (nan)	mem 8931MB
[2022-04-05 21:01:45 large] (main.py 226): INFO Train: [48/300][1100/2502]	eta 0:14:47 lr 0.000469	time 0.6042 (0.6332)	loss 3.3130 (3.7692)	grad_norm 2.5698 (nan)	mem 8931MB
[2022-04-05 21:02:49 large] (main.py 226): INFO Train: [48/300][1200/2502]	eta 0:13:45 lr 0.000469	time 0.6415 (0.6338)	loss 4.2873 (3.7703)	grad_norm 2.0650 (nan)	mem 8931MB
[2022-04-05 21:03:52 large] (main.py 226): INFO Train: [48/300][1300/2502]	eta 0:12:41 lr 0.000469	time 0.6445 (0.6338)	loss 4.4994 (3.7705)	grad_norm 2.2086 (nan)	mem 8931MB
[2022-04-05 21:04:55 large] (main.py 226): INFO Train: [48/300][1400/2502]	eta 0:11:38 lr 0.000469	time 0.6378 (0.6335)	loss 4.2368 (3.7753)	grad_norm 2.5489 (nan)	mem 8931MB
[2022-04-05 21:05:58 large] (main.py 226): INFO Train: [48/300][1500/2502]	eta 0:10:34 lr 0.000469	time 0.6371 (0.6333)	loss 4.4099 (3.7797)	grad_norm 2.8978 (nan)	mem 8931MB
[2022-04-05 21:07:01 large] (main.py 226): INFO Train: [48/300][1600/2502]	eta 0:09:31 lr 0.000469	time 0.6495 (0.6331)	loss 4.1195 (3.7828)	grad_norm 2.5255 (nan)	mem 8931MB
[2022-04-05 21:08:05 large] (main.py 226): INFO Train: [48/300][1700/2502]	eta 0:08:27 lr 0.000469	time 0.6161 (0.6333)	loss 3.7498 (3.7812)	grad_norm 2.6896 (nan)	mem 8931MB
[2022-04-05 21:09:08 large] (main.py 226): INFO Train: [48/300][1800/2502]	eta 0:07:24 lr 0.000468	time 0.7216 (0.6330)	loss 3.8389 (3.7779)	grad_norm 2.4345 (nan)	mem 8931MB
[2022-04-05 21:10:11 large] (main.py 226): INFO Train: [48/300][1900/2502]	eta 0:06:20 lr 0.000468	time 0.6168 (0.6328)	loss 3.6706 (3.7802)	grad_norm 4.0669 (nan)	mem 8931MB
[2022-04-05 21:11:14 large] (main.py 226): INFO Train: [48/300][2000/2502]	eta 0:05:17 lr 0.000468	time 0.7392 (0.6328)	loss 3.6112 (3.7746)	grad_norm 2.2750 (nan)	mem 8931MB
[2022-04-05 21:12:16 large] (main.py 226): INFO Train: [48/300][2100/2502]	eta 0:04:14 lr 0.000468	time 0.6120 (0.6324)	loss 3.9969 (3.7771)	grad_norm 2.7196 (nan)	mem 8931MB
[2022-04-05 21:13:20 large] (main.py 226): INFO Train: [48/300][2200/2502]	eta 0:03:10 lr 0.000468	time 0.6081 (0.6324)	loss 4.2489 (3.7748)	grad_norm 2.7581 (nan)	mem 8931MB
[2022-04-05 21:14:22 large] (main.py 226): INFO Train: [48/300][2300/2502]	eta 0:02:07 lr 0.000468	time 0.7203 (0.6322)	loss 3.1039 (3.7713)	grad_norm 2.1586 (nan)	mem 8931MB
[2022-04-05 21:15:26 large] (main.py 226): INFO Train: [48/300][2400/2502]	eta 0:01:04 lr 0.000468	time 0.6120 (0.6322)	loss 3.5810 (3.7681)	grad_norm 1.9589 (nan)	mem 8931MB
[2022-04-05 21:16:28 large] (main.py 226): INFO Train: [48/300][2500/2502]	eta 0:00:01 lr 0.000468	time 0.6173 (0.6320)	loss 4.2730 (3.7669)	grad_norm 2.2788 (nan)	mem 8931MB
[2022-04-05 21:16:29 large] (main.py 233): INFO EPOCH 48 training takes 0:26:21
[2022-04-05 21:16:36 large] (main.py 273): INFO Test: [0/98]	Time 6.462 (6.462)	Loss 1.2526 (1.2526)	Acc@1 73.047 (73.047)	Acc@5 92.578 (92.578)	Mem 8931MB
[2022-04-05 21:17:02 large] (main.py 279): INFO  * Acc@1 71.804 Acc@5 91.182
[2022-04-05 21:17:02 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 71.8%
[2022-04-05 21:17:02 large] (main.py 148): INFO Max accuracy: 71.97%
[2022-04-05 21:17:09 large] (main.py 226): INFO Train: [49/300][0/2502]	eta 4:57:56 lr 0.000468	time 7.1450 (7.1450)	loss 4.3702 (4.3702)	grad_norm 2.3215 (2.3215)	mem 8931MB
[2022-04-05 21:18:03 large] (main.py 226): INFO Train: [49/300][100/2502]	eta 0:24:29 lr 0.000468	time 0.7121 (0.6117)	loss 4.1042 (3.7560)	grad_norm 2.0007 (2.3669)	mem 8931MB
[2022-04-05 21:19:09 large] (main.py 226): INFO Train: [49/300][200/2502]	eta 0:24:18 lr 0.000468	time 0.5374 (0.6335)	loss 4.7894 (3.7498)	grad_norm 2.4388 (2.3790)	mem 8931MB
[2022-04-05 21:20:12 large] (main.py 226): INFO Train: [49/300][300/2502]	eta 0:23:16 lr 0.000468	time 0.6423 (0.6340)	loss 4.2249 (3.7639)	grad_norm 2.3659 (2.3756)	mem 8931MB
[2022-04-05 21:21:17 large] (main.py 226): INFO Train: [49/300][400/2502]	eta 0:22:18 lr 0.000468	time 0.5287 (0.6367)	loss 3.2947 (3.7535)	grad_norm 2.8165 (2.3999)	mem 8931MB
[2022-04-05 21:22:21 large] (main.py 226): INFO Train: [49/300][500/2502]	eta 0:21:17 lr 0.000468	time 0.6255 (0.6383)	loss 3.5558 (3.7440)	grad_norm 3.0925 (2.4138)	mem 8931MB
[2022-04-05 21:23:25 large] (main.py 226): INFO Train: [49/300][600/2502]	eta 0:20:14 lr 0.000468	time 0.5955 (0.6385)	loss 4.0154 (3.7385)	grad_norm 2.6066 (2.4167)	mem 8931MB
[2022-04-05 21:24:29 large] (main.py 226): INFO Train: [49/300][700/2502]	eta 0:19:09 lr 0.000468	time 0.5603 (0.6382)	loss 3.1719 (3.7342)	grad_norm 3.0434 (2.4367)	mem 8931MB
[2022-04-05 21:25:32 large] (main.py 226): INFO Train: [49/300][800/2502]	eta 0:18:04 lr 0.000468	time 0.6400 (0.6371)	loss 3.1756 (3.7346)	grad_norm 2.1135 (2.4388)	mem 8931MB
[2022-04-05 21:26:35 large] (main.py 226): INFO Train: [49/300][900/2502]	eta 0:16:59 lr 0.000468	time 0.5714 (0.6365)	loss 3.3774 (3.7287)	grad_norm 2.5693 (2.4444)	mem 8931MB
[2022-04-05 21:27:38 large] (main.py 226): INFO Train: [49/300][1000/2502]	eta 0:15:55 lr 0.000468	time 0.6084 (0.6360)	loss 4.0930 (3.7385)	grad_norm 3.1869 (2.4438)	mem 8931MB
[2022-04-05 21:28:42 large] (main.py 226): INFO Train: [49/300][1100/2502]	eta 0:14:51 lr 0.000468	time 0.6067 (0.6361)	loss 3.9661 (3.7419)	grad_norm 2.2693 (2.4433)	mem 8931MB
[2022-04-05 21:29:46 large] (main.py 226): INFO Train: [49/300][1200/2502]	eta 0:13:48 lr 0.000468	time 0.6815 (0.6366)	loss 2.7075 (3.7426)	grad_norm 3.6836 (2.4471)	mem 8931MB
[2022-04-05 21:30:48 large] (main.py 226): INFO Train: [49/300][1300/2502]	eta 0:12:43 lr 0.000467	time 0.6593 (0.6354)	loss 4.0067 (3.7428)	grad_norm 2.0776 (2.4437)	mem 8931MB
[2022-04-05 21:31:51 large] (main.py 226): INFO Train: [49/300][1400/2502]	eta 0:11:39 lr 0.000467	time 0.7196 (0.6351)	loss 4.0221 (3.7312)	grad_norm 2.0710 (2.4425)	mem 8931MB
[2022-04-05 21:32:54 large] (main.py 226): INFO Train: [49/300][1500/2502]	eta 0:10:35 lr 0.000467	time 0.6236 (0.6345)	loss 3.6934 (3.7338)	grad_norm 2.5444 (2.4466)	mem 8931MB
[2022-04-05 21:33:57 large] (main.py 226): INFO Train: [49/300][1600/2502]	eta 0:09:31 lr 0.000467	time 0.6432 (0.6341)	loss 4.0548 (3.7360)	grad_norm 2.3073 (2.4544)	mem 8931MB
[2022-04-05 21:35:00 large] (main.py 226): INFO Train: [49/300][1700/2502]	eta 0:08:28 lr 0.000467	time 0.5850 (0.6338)	loss 3.8524 (3.7398)	grad_norm 1.9538 (2.4485)	mem 8931MB
[2022-04-05 21:36:02 large] (main.py 226): INFO Train: [49/300][1800/2502]	eta 0:07:24 lr 0.000467	time 0.6177 (0.6331)	loss 3.5836 (3.7355)	grad_norm 2.0590 (2.4508)	mem 8931MB
[2022-04-05 21:37:04 large] (main.py 226): INFO Train: [49/300][1900/2502]	eta 0:06:20 lr 0.000467	time 0.6455 (0.6327)	loss 3.3112 (3.7362)	grad_norm 2.3774 (2.4624)	mem 8931MB
[2022-04-05 21:38:07 large] (main.py 226): INFO Train: [49/300][2000/2502]	eta 0:05:17 lr 0.000467	time 0.5985 (0.6326)	loss 4.3378 (3.7358)	grad_norm 3.4729 (2.4604)	mem 8931MB
[2022-04-05 21:39:11 large] (main.py 226): INFO Train: [49/300][2100/2502]	eta 0:04:14 lr 0.000467	time 0.6413 (0.6326)	loss 3.5801 (3.7390)	grad_norm 2.7852 (2.4587)	mem 8931MB
[2022-04-05 21:40:12 large] (main.py 226): INFO Train: [49/300][2200/2502]	eta 0:03:10 lr 0.000467	time 0.6195 (0.6317)	loss 4.4797 (3.7414)	grad_norm 2.8136 (2.4599)	mem 8931MB
[2022-04-05 21:41:10 large] (main.py 226): INFO Train: [49/300][2300/2502]	eta 0:02:07 lr 0.000467	time 0.6765 (0.6294)	loss 3.9750 (3.7428)	grad_norm 2.6443 (2.4592)	mem 8931MB
[2022-04-05 21:42:13 large] (main.py 226): INFO Train: [49/300][2400/2502]	eta 0:01:04 lr 0.000467	time 0.5649 (0.6294)	loss 3.0899 (3.7439)	grad_norm 2.0298 (2.4640)	mem 8931MB
[2022-04-05 21:43:16 large] (main.py 226): INFO Train: [49/300][2500/2502]	eta 0:00:01 lr 0.000467	time 0.6125 (0.6296)	loss 2.5399 (3.7490)	grad_norm 2.2006 (2.4622)	mem 8931MB
[2022-04-05 21:43:17 large] (main.py 233): INFO EPOCH 49 training takes 0:26:15
[2022-04-05 21:43:24 large] (main.py 273): INFO Test: [0/98]	Time 6.717 (6.717)	Loss 1.2540 (1.2540)	Acc@1 73.242 (73.242)	Acc@5 92.578 (92.578)	Mem 8931MB
[2022-04-05 21:43:49 large] (main.py 279): INFO  * Acc@1 72.156 Acc@5 91.186
[2022-04-05 21:43:49 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.2%
[2022-04-05 21:43:49 large] (utils.py 57): INFO output/large/default/ckpt_epoch_49.pth saving......
[2022-04-05 21:43:50 large] (utils.py 59): INFO output/large/default/ckpt_epoch_49.pth saved !!!
[2022-04-05 21:43:50 large] (main.py 148): INFO Max accuracy: 72.16%
[2022-04-05 21:43:57 large] (main.py 226): INFO Train: [50/300][0/2502]	eta 5:01:39 lr 0.000467	time 7.2341 (7.2341)	loss 3.2750 (3.2750)	grad_norm 2.6938 (2.6938)	mem 8931MB
[2022-04-05 21:44:50 large] (main.py 226): INFO Train: [50/300][100/2502]	eta 0:23:37 lr 0.000467	time 0.5977 (0.5901)	loss 3.2505 (3.7692)	grad_norm 2.4893 (inf)	mem 8931MB
[2022-04-05 21:45:54 large] (main.py 226): INFO Train: [50/300][200/2502]	eta 0:23:35 lr 0.000467	time 0.6435 (0.6150)	loss 3.2855 (3.6949)	grad_norm 1.6411 (inf)	mem 8931MB
[2022-04-05 21:46:58 large] (main.py 226): INFO Train: [50/300][300/2502]	eta 0:22:56 lr 0.000467	time 0.6252 (0.6249)	loss 3.3592 (3.7065)	grad_norm 1.9703 (inf)	mem 8931MB
[2022-04-05 21:48:03 large] (main.py 226): INFO Train: [50/300][400/2502]	eta 0:22:03 lr 0.000467	time 0.6436 (0.6298)	loss 3.6450 (3.7224)	grad_norm 2.4072 (inf)	mem 8931MB
[2022-04-05 21:49:07 large] (main.py 226): INFO Train: [50/300][500/2502]	eta 0:21:07 lr 0.000467	time 0.6139 (0.6331)	loss 3.7771 (3.7332)	grad_norm 2.2333 (inf)	mem 8931MB
[2022-04-05 21:50:12 large] (main.py 226): INFO Train: [50/300][600/2502]	eta 0:20:09 lr 0.000467	time 0.6411 (0.6357)	loss 3.4959 (3.7461)	grad_norm 1.9203 (inf)	mem 8931MB
[2022-04-05 21:51:16 large] (main.py 226): INFO Train: [50/300][700/2502]	eta 0:19:07 lr 0.000466	time 0.6275 (0.6365)	loss 4.4161 (3.7488)	grad_norm 2.4665 (inf)	mem 8931MB
[2022-04-05 21:52:19 large] (main.py 226): INFO Train: [50/300][800/2502]	eta 0:18:01 lr 0.000466	time 0.6370 (0.6356)	loss 3.7926 (3.7377)	grad_norm 2.0173 (inf)	mem 8931MB
[2022-04-05 21:53:22 large] (main.py 226): INFO Train: [50/300][900/2502]	eta 0:16:57 lr 0.000466	time 0.6206 (0.6349)	loss 4.2182 (3.7336)	grad_norm 2.3075 (inf)	mem 8931MB
[2022-04-05 21:54:26 large] (main.py 226): INFO Train: [50/300][1000/2502]	eta 0:15:53 lr 0.000466	time 0.6530 (0.6350)	loss 3.7272 (3.7292)	grad_norm 1.8601 (inf)	mem 8931MB
[2022-04-05 21:55:29 large] (main.py 226): INFO Train: [50/300][1100/2502]	eta 0:14:50 lr 0.000466	time 0.6635 (0.6351)	loss 3.1889 (3.7333)	grad_norm 2.4778 (inf)	mem 8931MB
[2022-04-05 21:56:34 large] (main.py 226): INFO Train: [50/300][1200/2502]	eta 0:13:47 lr 0.000466	time 0.6549 (0.6356)	loss 3.1335 (3.7334)	grad_norm 2.2681 (inf)	mem 8931MB
[2022-04-05 21:57:37 large] (main.py 226): INFO Train: [50/300][1300/2502]	eta 0:12:43 lr 0.000466	time 0.6274 (0.6355)	loss 4.4806 (3.7298)	grad_norm 2.6356 (inf)	mem 8931MB
[2022-04-05 21:58:39 large] (main.py 226): INFO Train: [50/300][1400/2502]	eta 0:11:39 lr 0.000466	time 0.5764 (0.6347)	loss 3.2987 (3.7388)	grad_norm 3.1087 (inf)	mem 8931MB
[2022-04-05 21:59:42 large] (main.py 226): INFO Train: [50/300][1500/2502]	eta 0:10:35 lr 0.000466	time 0.6576 (0.6344)	loss 4.1110 (3.7374)	grad_norm 2.0290 (inf)	mem 8931MB
[2022-04-05 22:00:46 large] (main.py 226): INFO Train: [50/300][1600/2502]	eta 0:09:32 lr 0.000466	time 0.7082 (0.6344)	loss 4.1344 (3.7387)	grad_norm 2.2638 (inf)	mem 8931MB
[2022-04-05 22:01:49 large] (main.py 226): INFO Train: [50/300][1700/2502]	eta 0:08:28 lr 0.000466	time 0.5763 (0.6341)	loss 3.4310 (3.7389)	grad_norm 2.2092 (inf)	mem 8931MB
[2022-04-05 22:02:47 large] (main.py 226): INFO Train: [50/300][1800/2502]	eta 0:07:22 lr 0.000466	time 0.5177 (0.6310)	loss 3.4354 (3.7390)	grad_norm 1.9504 (inf)	mem 8931MB
[2022-04-05 22:03:41 large] (main.py 226): INFO Train: [50/300][1900/2502]	eta 0:06:17 lr 0.000466	time 0.7561 (0.6267)	loss 3.5790 (3.7375)	grad_norm 2.1377 (inf)	mem 8931MB
[2022-04-05 22:04:45 large] (main.py 226): INFO Train: [50/300][2000/2502]	eta 0:05:14 lr 0.000466	time 0.6860 (0.6271)	loss 3.7043 (3.7383)	grad_norm 2.3961 (inf)	mem 8931MB
[2022-04-05 22:05:47 large] (main.py 226): INFO Train: [50/300][2100/2502]	eta 0:04:12 lr 0.000466	time 0.5810 (0.6270)	loss 3.5160 (3.7405)	grad_norm 2.4063 (inf)	mem 8931MB
[2022-04-05 22:06:50 large] (main.py 226): INFO Train: [50/300][2200/2502]	eta 0:03:09 lr 0.000466	time 0.7044 (0.6270)	loss 4.1248 (3.7415)	grad_norm 2.7734 (inf)	mem 8931MB
[2022-04-05 22:07:54 large] (main.py 226): INFO Train: [50/300][2300/2502]	eta 0:02:06 lr 0.000466	time 0.5948 (0.6273)	loss 3.4787 (3.7415)	grad_norm 3.4678 (inf)	mem 8931MB
[2022-04-05 22:08:57 large] (main.py 226): INFO Train: [50/300][2400/2502]	eta 0:01:04 lr 0.000466	time 0.5656 (0.6277)	loss 3.8445 (3.7411)	grad_norm 2.1228 (inf)	mem 8931MB
[2022-04-05 22:10:00 large] (main.py 226): INFO Train: [50/300][2500/2502]	eta 0:00:01 lr 0.000466	time 0.6079 (0.6279)	loss 3.2401 (3.7434)	grad_norm 2.0198 (inf)	mem 8931MB
[2022-04-05 22:10:02 large] (main.py 233): INFO EPOCH 50 training takes 0:26:11
[2022-04-05 22:10:07 large] (main.py 273): INFO Test: [0/98]	Time 5.833 (5.833)	Loss 1.1499 (1.1499)	Acc@1 74.219 (74.219)	Acc@5 92.188 (92.188)	Mem 8931MB
[2022-04-05 22:10:34 large] (main.py 279): INFO  * Acc@1 71.868 Acc@5 90.948
[2022-04-05 22:10:34 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 71.9%
[2022-04-05 22:10:34 large] (main.py 148): INFO Max accuracy: 72.16%
[2022-04-05 22:10:40 large] (main.py 226): INFO Train: [51/300][0/2502]	eta 4:19:06 lr 0.000466	time 6.2138 (6.2138)	loss 3.8948 (3.8948)	grad_norm 2.7337 (2.7337)	mem 8931MB
[2022-04-05 22:11:33 large] (main.py 226): INFO Train: [51/300][100/2502]	eta 0:23:36 lr 0.000465	time 0.5709 (0.5895)	loss 4.4469 (3.6722)	grad_norm 1.9295 (2.4901)	mem 8931MB
[2022-04-05 22:12:37 large] (main.py 226): INFO Train: [51/300][200/2502]	eta 0:23:30 lr 0.000465	time 0.6557 (0.6128)	loss 4.0804 (3.6648)	grad_norm 2.2972 (2.4845)	mem 8931MB
[2022-04-05 22:13:41 large] (main.py 226): INFO Train: [51/300][300/2502]	eta 0:22:52 lr 0.000465	time 0.6582 (0.6232)	loss 3.8361 (3.7214)	grad_norm 2.1427 (2.4642)	mem 8931MB
[2022-04-05 22:14:47 large] (main.py 226): INFO Train: [51/300][400/2502]	eta 0:22:05 lr 0.000465	time 0.6813 (0.6306)	loss 3.7610 (3.7372)	grad_norm 1.6079 (2.4587)	mem 8931MB
[2022-04-05 22:15:50 large] (main.py 226): INFO Train: [51/300][500/2502]	eta 0:21:05 lr 0.000465	time 0.6684 (0.6322)	loss 3.3271 (3.7305)	grad_norm 2.4954 (2.4495)	mem 8931MB
[2022-04-05 22:16:54 large] (main.py 226): INFO Train: [51/300][600/2502]	eta 0:20:03 lr 0.000465	time 0.7461 (0.6329)	loss 3.4864 (3.7232)	grad_norm 2.2984 (2.4505)	mem 8931MB
[2022-04-05 22:17:58 large] (main.py 226): INFO Train: [51/300][700/2502]	eta 0:19:00 lr 0.000465	time 0.7187 (0.6330)	loss 4.4467 (3.7204)	grad_norm 2.3360 (2.4529)	mem 8931MB
[2022-04-05 22:19:01 large] (main.py 226): INFO Train: [51/300][800/2502]	eta 0:17:57 lr 0.000465	time 0.5216 (0.6334)	loss 4.2230 (3.7289)	grad_norm 2.0674 (2.4515)	mem 8931MB
[2022-04-05 22:20:05 large] (main.py 226): INFO Train: [51/300][900/2502]	eta 0:16:54 lr 0.000465	time 0.5886 (0.6335)	loss 4.5543 (3.7338)	grad_norm 2.2634 (2.4522)	mem 8931MB
[2022-04-05 22:21:08 large] (main.py 226): INFO Train: [51/300][1000/2502]	eta 0:15:51 lr 0.000465	time 0.6201 (0.6334)	loss 4.1762 (3.7364)	grad_norm 1.9127 (2.4485)	mem 8931MB
[2022-04-05 22:22:11 large] (main.py 226): INFO Train: [51/300][1100/2502]	eta 0:14:47 lr 0.000465	time 0.6035 (0.6333)	loss 4.6702 (3.7347)	grad_norm 2.6155 (2.4549)	mem 8931MB
[2022-04-05 22:23:14 large] (main.py 226): INFO Train: [51/300][1200/2502]	eta 0:13:44 lr 0.000465	time 0.6769 (0.6332)	loss 3.2639 (3.7298)	grad_norm 3.3735 (2.4562)	mem 8931MB
[2022-04-05 22:24:17 large] (main.py 226): INFO Train: [51/300][1300/2502]	eta 0:12:40 lr 0.000465	time 0.6376 (0.6328)	loss 3.2317 (3.7234)	grad_norm 1.9938 (2.4617)	mem 8931MB
[2022-04-05 22:25:21 large] (main.py 226): INFO Train: [51/300][1400/2502]	eta 0:11:37 lr 0.000465	time 0.6278 (0.6332)	loss 2.5752 (3.7255)	grad_norm 2.5689 (2.4632)	mem 8931MB
[2022-04-05 22:26:24 large] (main.py 226): INFO Train: [51/300][1500/2502]	eta 0:10:34 lr 0.000465	time 0.5978 (0.6332)	loss 4.2658 (3.7266)	grad_norm 2.5171 (2.4622)	mem 8931MB
[2022-04-05 22:27:27 large] (main.py 226): INFO Train: [51/300][1600/2502]	eta 0:09:31 lr 0.000465	time 0.5935 (0.6331)	loss 3.0699 (3.7200)	grad_norm 2.3528 (2.4684)	mem 8931MB
[2022-04-05 22:28:31 large] (main.py 226): INFO Train: [51/300][1700/2502]	eta 0:08:27 lr 0.000465	time 0.6852 (0.6330)	loss 2.7785 (3.7229)	grad_norm 2.3903 (2.4670)	mem 8931MB
[2022-04-05 22:29:35 large] (main.py 226): INFO Train: [51/300][1800/2502]	eta 0:07:24 lr 0.000465	time 0.7128 (0.6334)	loss 3.0589 (3.7186)	grad_norm 2.4892 (2.4720)	mem 8931MB
[2022-04-05 22:30:38 large] (main.py 226): INFO Train: [51/300][1900/2502]	eta 0:06:21 lr 0.000465	time 0.5019 (0.6333)	loss 4.3296 (3.7242)	grad_norm 3.5539 (2.4768)	mem 8931MB
[2022-04-05 22:31:41 large] (main.py 226): INFO Train: [51/300][2000/2502]	eta 0:05:17 lr 0.000464	time 0.5910 (0.6332)	loss 4.1488 (3.7264)	grad_norm 2.2821 (2.4725)	mem 8931MB
[2022-04-05 22:32:44 large] (main.py 226): INFO Train: [51/300][2100/2502]	eta 0:04:14 lr 0.000464	time 0.6653 (0.6332)	loss 4.1406 (3.7237)	grad_norm 2.5114 (2.4671)	mem 8931MB
[2022-04-05 22:33:46 large] (main.py 226): INFO Train: [51/300][2200/2502]	eta 0:03:11 lr 0.000464	time 0.6941 (0.6326)	loss 4.4546 (3.7257)	grad_norm 2.7459 (2.4677)	mem 8931MB
[2022-04-05 22:34:49 large] (main.py 226): INFO Train: [51/300][2300/2502]	eta 0:02:07 lr 0.000464	time 0.5765 (0.6323)	loss 3.6804 (3.7276)	grad_norm 2.2541 (inf)	mem 8931MB
[2022-04-05 22:35:51 large] (main.py 226): INFO Train: [51/300][2400/2502]	eta 0:01:04 lr 0.000464	time 0.6224 (0.6320)	loss 4.2853 (3.7298)	grad_norm 2.0785 (inf)	mem 8931MB
[2022-04-05 22:36:53 large] (main.py 226): INFO Train: [51/300][2500/2502]	eta 0:00:01 lr 0.000464	time 0.5912 (0.6316)	loss 4.1189 (3.7317)	grad_norm 2.4106 (inf)	mem 8931MB
[2022-04-05 22:36:54 large] (main.py 233): INFO EPOCH 51 training takes 0:26:20
[2022-04-05 22:37:00 large] (main.py 273): INFO Test: [0/98]	Time 5.942 (5.942)	Loss 1.3223 (1.3223)	Acc@1 72.461 (72.461)	Acc@5 91.211 (91.211)	Mem 8931MB
[2022-04-05 22:37:27 large] (main.py 279): INFO  * Acc@1 72.162 Acc@5 91.194
[2022-04-05 22:37:27 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.2%
[2022-04-05 22:37:27 large] (utils.py 57): INFO output/large/default/ckpt_epoch_51.pth saving......
[2022-04-05 22:37:27 large] (utils.py 59): INFO output/large/default/ckpt_epoch_51.pth saved !!!
[2022-04-05 22:37:27 large] (main.py 148): INFO Max accuracy: 72.16%
[2022-04-05 22:37:35 large] (main.py 226): INFO Train: [52/300][0/2502]	eta 5:26:20 lr 0.000464	time 7.8261 (7.8261)	loss 3.5784 (3.5784)	grad_norm 3.0124 (3.0124)	mem 8931MB
[2022-04-05 22:38:31 large] (main.py 226): INFO Train: [52/300][100/2502]	eta 0:25:18 lr 0.000464	time 0.7759 (0.6320)	loss 4.0173 (3.6839)	grad_norm 2.3931 (2.4762)	mem 8931MB
[2022-04-05 22:39:34 large] (main.py 226): INFO Train: [52/300][200/2502]	eta 0:24:12 lr 0.000464	time 0.5252 (0.6311)	loss 3.3378 (3.7289)	grad_norm 2.5126 (2.4569)	mem 8931MB
[2022-04-05 22:40:38 large] (main.py 226): INFO Train: [52/300][300/2502]	eta 0:23:10 lr 0.000464	time 0.5949 (0.6314)	loss 4.0897 (3.7341)	grad_norm 3.5822 (2.4515)	mem 8931MB
[2022-04-05 22:41:41 large] (main.py 226): INFO Train: [52/300][400/2502]	eta 0:22:10 lr 0.000464	time 0.7150 (0.6330)	loss 3.4630 (3.7242)	grad_norm 2.2179 (2.4333)	mem 8931MB
[2022-04-05 22:42:45 large] (main.py 226): INFO Train: [52/300][500/2502]	eta 0:21:10 lr 0.000464	time 0.5961 (0.6344)	loss 4.1155 (3.7155)	grad_norm 2.0714 (2.4289)	mem 8931MB
[2022-04-05 22:43:48 large] (main.py 226): INFO Train: [52/300][600/2502]	eta 0:20:05 lr 0.000464	time 0.6516 (0.6338)	loss 3.8944 (3.7145)	grad_norm 2.6628 (2.4512)	mem 8931MB
[2022-04-05 22:44:52 large] (main.py 226): INFO Train: [52/300][700/2502]	eta 0:19:03 lr 0.000464	time 0.6404 (0.6345)	loss 4.1551 (3.7137)	grad_norm 2.3817 (2.4557)	mem 8931MB
[2022-04-05 22:45:55 large] (main.py 226): INFO Train: [52/300][800/2502]	eta 0:17:59 lr 0.000464	time 0.6283 (0.6341)	loss 4.5465 (3.7167)	grad_norm 2.2077 (2.4568)	mem 8931MB
[2022-04-05 22:46:59 large] (main.py 226): INFO Train: [52/300][900/2502]	eta 0:16:55 lr 0.000464	time 0.6004 (0.6339)	loss 3.9260 (3.7133)	grad_norm 1.9219 (2.4645)	mem 8931MB
[2022-04-05 22:48:02 large] (main.py 226): INFO Train: [52/300][1000/2502]	eta 0:15:52 lr 0.000464	time 0.6489 (0.6340)	loss 3.9740 (3.7099)	grad_norm 2.5776 (2.4640)	mem 8931MB
[2022-04-05 22:49:04 large] (main.py 226): INFO Train: [52/300][1100/2502]	eta 0:14:46 lr 0.000464	time 0.6324 (0.6326)	loss 4.3117 (3.7126)	grad_norm 2.5821 (2.4629)	mem 8931MB
[2022-04-05 22:50:07 large] (main.py 226): INFO Train: [52/300][1200/2502]	eta 0:13:43 lr 0.000464	time 0.7250 (0.6323)	loss 2.7239 (3.7153)	grad_norm 2.6332 (2.4685)	mem 8931MB
[2022-04-05 22:51:10 large] (main.py 226): INFO Train: [52/300][1300/2502]	eta 0:12:39 lr 0.000464	time 0.6441 (0.6319)	loss 3.2460 (3.7189)	grad_norm 2.0075 (2.4647)	mem 8931MB
[2022-04-05 22:52:09 large] (main.py 226): INFO Train: [52/300][1400/2502]	eta 0:11:33 lr 0.000463	time 0.4885 (0.6289)	loss 2.8065 (3.7139)	grad_norm 2.7541 (2.4671)	mem 8931MB
[2022-04-05 22:53:07 large] (main.py 226): INFO Train: [52/300][1500/2502]	eta 0:10:27 lr 0.000463	time 0.6067 (0.6262)	loss 3.4529 (3.7132)	grad_norm 2.5333 (2.4651)	mem 8931MB
[2022-04-05 22:54:10 large] (main.py 226): INFO Train: [52/300][1600/2502]	eta 0:09:24 lr 0.000463	time 0.7174 (0.6260)	loss 4.5478 (3.7111)	grad_norm 2.9866 (2.4657)	mem 8931MB
[2022-04-05 22:55:13 large] (main.py 226): INFO Train: [52/300][1700/2502]	eta 0:08:22 lr 0.000463	time 0.6409 (0.6262)	loss 3.9460 (3.7109)	grad_norm 1.6967 (2.4597)	mem 8931MB
[2022-04-05 22:56:15 large] (main.py 226): INFO Train: [52/300][1800/2502]	eta 0:07:19 lr 0.000463	time 0.6019 (0.6262)	loss 2.6974 (3.7106)	grad_norm 2.0834 (2.4630)	mem 8931MB
[2022-04-05 22:57:16 large] (main.py 226): INFO Train: [52/300][1900/2502]	eta 0:06:16 lr 0.000463	time 0.6232 (0.6254)	loss 4.0084 (3.7083)	grad_norm 2.2970 (2.4636)	mem 8931MB
[2022-04-05 22:58:17 large] (main.py 226): INFO Train: [52/300][2000/2502]	eta 0:05:13 lr 0.000463	time 0.5383 (0.6246)	loss 3.7134 (3.7139)	grad_norm 1.9151 (2.4637)	mem 8931MB
[2022-04-05 22:59:19 large] (main.py 226): INFO Train: [52/300][2100/2502]	eta 0:04:10 lr 0.000463	time 0.6051 (0.6243)	loss 2.6790 (3.7137)	grad_norm 2.5597 (2.4685)	mem 8931MB
[2022-04-05 23:00:22 large] (main.py 226): INFO Train: [52/300][2200/2502]	eta 0:03:08 lr 0.000463	time 0.7891 (0.6245)	loss 3.7199 (3.7161)	grad_norm 2.4132 (2.4696)	mem 8931MB
[2022-04-05 23:01:20 large] (main.py 226): INFO Train: [52/300][2300/2502]	eta 0:02:05 lr 0.000463	time 0.5341 (0.6227)	loss 3.8907 (3.7154)	grad_norm 1.9899 (2.4725)	mem 8931MB
[2022-04-05 23:02:21 large] (main.py 226): INFO Train: [52/300][2400/2502]	eta 0:01:03 lr 0.000463	time 0.6164 (0.6221)	loss 4.6229 (3.7188)	grad_norm 2.8387 (nan)	mem 8931MB
[2022-04-05 23:03:24 large] (main.py 226): INFO Train: [52/300][2500/2502]	eta 0:00:01 lr 0.000463	time 0.6157 (0.6225)	loss 3.1003 (3.7204)	grad_norm 3.0477 (nan)	mem 8931MB
[2022-04-05 23:03:25 large] (main.py 233): INFO EPOCH 52 training takes 0:25:57
[2022-04-05 23:03:31 large] (main.py 273): INFO Test: [0/98]	Time 5.959 (5.959)	Loss 1.2639 (1.2639)	Acc@1 74.023 (74.023)	Acc@5 92.969 (92.969)	Mem 8931MB
[2022-04-05 23:03:57 large] (main.py 279): INFO  * Acc@1 72.466 Acc@5 91.334
[2022-04-05 23:03:57 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.5%
[2022-04-05 23:03:57 large] (utils.py 57): INFO output/large/default/ckpt_epoch_52.pth saving......
[2022-04-05 23:03:58 large] (utils.py 59): INFO output/large/default/ckpt_epoch_52.pth saved !!!
[2022-04-05 23:03:58 large] (main.py 148): INFO Max accuracy: 72.47%
[2022-04-05 23:04:06 large] (main.py 226): INFO Train: [53/300][0/2502]	eta 5:45:26 lr 0.000463	time 8.2839 (8.2839)	loss 3.7450 (3.7450)	grad_norm 3.3733 (3.3733)	mem 8931MB
[2022-04-05 23:05:02 large] (main.py 226): INFO Train: [53/300][100/2502]	eta 0:25:15 lr 0.000463	time 0.6184 (0.6311)	loss 3.5272 (3.6535)	grad_norm 1.7859 (2.5133)	mem 8931MB
[2022-04-05 23:06:05 large] (main.py 226): INFO Train: [53/300][200/2502]	eta 0:24:20 lr 0.000463	time 0.6805 (0.6343)	loss 4.1654 (3.6331)	grad_norm 2.0947 (2.4627)	mem 8931MB
[2022-04-05 23:07:10 large] (main.py 226): INFO Train: [53/300][300/2502]	eta 0:23:21 lr 0.000463	time 0.4981 (0.6363)	loss 3.5770 (3.6977)	grad_norm 3.1874 (2.4574)	mem 8931MB
[2022-04-05 23:08:07 large] (main.py 226): INFO Train: [53/300][400/2502]	eta 0:21:47 lr 0.000463	time 0.5327 (0.6218)	loss 3.2884 (3.7194)	grad_norm 2.0669 (2.4648)	mem 8931MB
[2022-04-05 23:09:09 large] (main.py 226): INFO Train: [53/300][500/2502]	eta 0:20:42 lr 0.000463	time 0.6201 (0.6204)	loss 4.1462 (3.7345)	grad_norm 2.4500 (2.4678)	mem 8931MB
[2022-04-05 23:10:13 large] (main.py 226): INFO Train: [53/300][600/2502]	eta 0:19:45 lr 0.000463	time 0.6129 (0.6232)	loss 3.5193 (3.7300)	grad_norm 4.1334 (2.4789)	mem 8931MB
[2022-04-05 23:11:16 large] (main.py 226): INFO Train: [53/300][700/2502]	eta 0:18:46 lr 0.000462	time 0.6225 (0.6252)	loss 2.7900 (3.7398)	grad_norm 3.3692 (2.4990)	mem 8931MB
[2022-04-05 23:12:19 large] (main.py 226): INFO Train: [53/300][800/2502]	eta 0:17:45 lr 0.000462	time 0.6774 (0.6259)	loss 3.9384 (3.7413)	grad_norm 1.8075 (2.5008)	mem 8931MB
[2022-04-05 23:13:22 large] (main.py 226): INFO Train: [53/300][900/2502]	eta 0:16:43 lr 0.000462	time 0.8268 (0.6263)	loss 3.7293 (3.7421)	grad_norm 2.8667 (2.4960)	mem 8931MB
[2022-04-05 23:14:26 large] (main.py 226): INFO Train: [53/300][1000/2502]	eta 0:15:41 lr 0.000462	time 0.6320 (0.6270)	loss 4.0457 (3.7425)	grad_norm 1.6994 (2.5054)	mem 8931MB
[2022-04-05 23:15:27 large] (main.py 226): INFO Train: [53/300][1100/2502]	eta 0:14:37 lr 0.000462	time 0.6850 (0.6260)	loss 3.9634 (3.7396)	grad_norm 2.2212 (2.5042)	mem 8931MB
[2022-04-05 23:16:30 large] (main.py 226): INFO Train: [53/300][1200/2502]	eta 0:13:34 lr 0.000462	time 0.6026 (0.6259)	loss 2.8679 (3.7295)	grad_norm 2.1643 (2.5111)	mem 8931MB
[2022-04-05 23:17:32 large] (main.py 226): INFO Train: [53/300][1300/2502]	eta 0:12:32 lr 0.000462	time 0.5397 (0.6257)	loss 4.8173 (3.7289)	grad_norm 2.6187 (2.5051)	mem 8931MB
[2022-04-05 23:18:35 large] (main.py 226): INFO Train: [53/300][1400/2502]	eta 0:11:29 lr 0.000462	time 0.6266 (0.6258)	loss 3.9638 (3.7247)	grad_norm 2.1159 (2.5013)	mem 8931MB
[2022-04-05 23:19:37 large] (main.py 226): INFO Train: [53/300][1500/2502]	eta 0:10:26 lr 0.000462	time 0.6831 (0.6257)	loss 4.4597 (3.7246)	grad_norm 2.9078 (2.4995)	mem 8931MB
[2022-04-05 23:20:40 large] (main.py 226): INFO Train: [53/300][1600/2502]	eta 0:09:24 lr 0.000462	time 0.6431 (0.6260)	loss 3.8528 (3.7295)	grad_norm 3.5993 (2.5032)	mem 8931MB
[2022-04-05 23:21:44 large] (main.py 226): INFO Train: [53/300][1700/2502]	eta 0:08:22 lr 0.000462	time 0.6154 (0.6266)	loss 3.0810 (3.7272)	grad_norm 2.0763 (2.5009)	mem 8931MB
[2022-04-05 23:22:47 large] (main.py 226): INFO Train: [53/300][1800/2502]	eta 0:07:19 lr 0.000462	time 0.6581 (0.6267)	loss 4.1425 (3.7251)	grad_norm 2.3852 (2.4933)	mem 8931MB
[2022-04-05 23:23:49 large] (main.py 226): INFO Train: [53/300][1900/2502]	eta 0:06:17 lr 0.000462	time 0.6036 (0.6265)	loss 3.8398 (3.7269)	grad_norm 2.5515 (2.4937)	mem 8931MB
[2022-04-05 23:24:52 large] (main.py 226): INFO Train: [53/300][2000/2502]	eta 0:05:14 lr 0.000462	time 0.6880 (0.6269)	loss 2.8571 (3.7200)	grad_norm 2.8524 (2.4970)	mem 8931MB
[2022-04-05 23:25:55 large] (main.py 226): INFO Train: [53/300][2100/2502]	eta 0:04:11 lr 0.000462	time 0.6156 (0.6267)	loss 4.1780 (3.7219)	grad_norm 1.9683 (inf)	mem 8931MB
[2022-04-05 23:26:57 large] (main.py 226): INFO Train: [53/300][2200/2502]	eta 0:03:09 lr 0.000462	time 0.6396 (0.6263)	loss 4.2820 (3.7235)	grad_norm 2.6022 (inf)	mem 8931MB
[2022-04-05 23:27:59 large] (main.py 226): INFO Train: [53/300][2300/2502]	eta 0:02:06 lr 0.000462	time 0.6431 (0.6263)	loss 3.4293 (3.7244)	grad_norm 1.8844 (inf)	mem 8931MB
[2022-04-05 23:29:02 large] (main.py 226): INFO Train: [53/300][2400/2502]	eta 0:01:03 lr 0.000462	time 0.5794 (0.6262)	loss 4.7928 (3.7250)	grad_norm 2.7234 (inf)	mem 8931MB
[2022-04-05 23:30:04 large] (main.py 226): INFO Train: [53/300][2500/2502]	eta 0:00:01 lr 0.000461	time 0.7252 (0.6260)	loss 3.2913 (3.7227)	grad_norm 2.7300 (inf)	mem 8931MB
[2022-04-05 23:30:05 large] (main.py 233): INFO EPOCH 53 training takes 0:26:06
[2022-04-05 23:30:11 large] (main.py 273): INFO Test: [0/98]	Time 5.789 (5.789)	Loss 1.2933 (1.2933)	Acc@1 70.703 (70.703)	Acc@5 91.602 (91.602)	Mem 8931MB
[2022-04-05 23:30:37 large] (main.py 279): INFO  * Acc@1 72.378 Acc@5 91.334
[2022-04-05 23:30:37 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.4%
[2022-04-05 23:30:37 large] (main.py 148): INFO Max accuracy: 72.47%
[2022-04-05 23:30:44 large] (main.py 226): INFO Train: [54/300][0/2502]	eta 5:00:37 lr 0.000461	time 7.2091 (7.2091)	loss 3.8739 (3.8739)	grad_norm 1.9276 (1.9276)	mem 8931MB
[2022-04-05 23:31:40 large] (main.py 226): INFO Train: [54/300][100/2502]	eta 0:25:00 lr 0.000461	time 0.5744 (0.6247)	loss 4.1139 (3.7373)	grad_norm 2.2535 (2.4447)	mem 8931MB
[2022-04-05 23:32:43 large] (main.py 226): INFO Train: [54/300][200/2502]	eta 0:23:59 lr 0.000461	time 0.6443 (0.6253)	loss 4.3590 (3.7425)	grad_norm 2.4762 (2.4688)	mem 8931MB
[2022-04-05 23:33:46 large] (main.py 226): INFO Train: [54/300][300/2502]	eta 0:23:01 lr 0.000461	time 0.6752 (0.6274)	loss 4.1907 (3.7502)	grad_norm 2.2581 (2.5105)	mem 8931MB
[2022-04-05 23:34:49 large] (main.py 226): INFO Train: [54/300][400/2502]	eta 0:22:01 lr 0.000461	time 0.6078 (0.6288)	loss 4.2139 (3.7217)	grad_norm 1.9771 (2.4940)	mem 8931MB
[2022-04-05 23:35:52 large] (main.py 226): INFO Train: [54/300][500/2502]	eta 0:20:59 lr 0.000461	time 0.6677 (0.6290)	loss 2.9151 (3.7299)	grad_norm 2.2262 (2.5013)	mem 8931MB
[2022-04-05 23:36:55 large] (main.py 226): INFO Train: [54/300][600/2502]	eta 0:19:57 lr 0.000461	time 0.4956 (0.6298)	loss 2.9141 (3.7418)	grad_norm 2.3280 (2.5083)	mem 8931MB
[2022-04-05 23:37:57 large] (main.py 226): INFO Train: [54/300][700/2502]	eta 0:18:51 lr 0.000461	time 0.7009 (0.6281)	loss 3.0620 (3.7432)	grad_norm 2.4414 (2.4906)	mem 8931MB
[2022-04-05 23:39:00 large] (main.py 226): INFO Train: [54/300][800/2502]	eta 0:17:49 lr 0.000461	time 0.5572 (0.6286)	loss 3.9612 (3.7430)	grad_norm 2.0267 (2.4896)	mem 8931MB
[2022-04-05 23:40:04 large] (main.py 226): INFO Train: [54/300][900/2502]	eta 0:16:47 lr 0.000461	time 0.6361 (0.6290)	loss 2.9647 (3.7480)	grad_norm 2.3264 (2.4987)	mem 8931MB
[2022-04-05 23:41:06 large] (main.py 226): INFO Train: [54/300][1000/2502]	eta 0:15:43 lr 0.000461	time 0.5423 (0.6284)	loss 4.0301 (3.7527)	grad_norm 2.7140 (2.4994)	mem 8931MB
[2022-04-05 23:42:09 large] (main.py 226): INFO Train: [54/300][1100/2502]	eta 0:14:41 lr 0.000461	time 0.5702 (0.6285)	loss 3.2295 (3.7470)	grad_norm 2.2841 (2.4946)	mem 8931MB
[2022-04-05 23:43:11 large] (main.py 226): INFO Train: [54/300][1200/2502]	eta 0:13:37 lr 0.000461	time 0.7469 (0.6279)	loss 3.2573 (3.7519)	grad_norm 3.5550 (2.4979)	mem 8931MB
[2022-04-05 23:44:13 large] (main.py 226): INFO Train: [54/300][1300/2502]	eta 0:12:34 lr 0.000461	time 0.6262 (0.6274)	loss 4.2981 (3.7493)	grad_norm 3.1220 (2.5032)	mem 8931MB
[2022-04-05 23:45:15 large] (main.py 226): INFO Train: [54/300][1400/2502]	eta 0:11:30 lr 0.000461	time 0.6902 (0.6268)	loss 2.7308 (3.7414)	grad_norm 2.2123 (2.4966)	mem 8931MB
[2022-04-05 23:46:17 large] (main.py 226): INFO Train: [54/300][1500/2502]	eta 0:10:27 lr 0.000461	time 0.6093 (0.6264)	loss 3.9277 (3.7430)	grad_norm 3.9903 (2.4948)	mem 8931MB
[2022-04-05 23:47:19 large] (main.py 226): INFO Train: [54/300][1600/2502]	eta 0:09:24 lr 0.000461	time 0.6136 (0.6258)	loss 2.4765 (3.7353)	grad_norm 2.1244 (2.4968)	mem 8931MB
[2022-04-05 23:48:21 large] (main.py 226): INFO Train: [54/300][1700/2502]	eta 0:08:21 lr 0.000461	time 0.6014 (0.6255)	loss 2.8465 (3.7357)	grad_norm 2.3300 (2.4987)	mem 8931MB
[2022-04-05 23:49:24 large] (main.py 226): INFO Train: [54/300][1800/2502]	eta 0:07:19 lr 0.000460	time 0.6110 (0.6256)	loss 4.4098 (3.7355)	grad_norm 2.3693 (2.5013)	mem 8931MB
[2022-04-05 23:50:27 large] (main.py 226): INFO Train: [54/300][1900/2502]	eta 0:06:16 lr 0.000460	time 0.5912 (0.6260)	loss 4.4931 (3.7380)	grad_norm 2.5365 (2.5063)	mem 8931MB
[2022-04-05 23:51:30 large] (main.py 226): INFO Train: [54/300][2000/2502]	eta 0:05:14 lr 0.000460	time 0.6554 (0.6262)	loss 3.7666 (3.7395)	grad_norm 2.1381 (2.5056)	mem 8931MB
[2022-04-05 23:52:32 large] (main.py 226): INFO Train: [54/300][2100/2502]	eta 0:04:11 lr 0.000460	time 0.6224 (0.6261)	loss 3.9075 (3.7345)	grad_norm 1.9435 (2.5003)	mem 8931MB
[2022-04-05 23:53:35 large] (main.py 226): INFO Train: [54/300][2200/2502]	eta 0:03:09 lr 0.000460	time 0.6404 (0.6261)	loss 3.7751 (3.7345)	grad_norm 2.6621 (2.5025)	mem 8931MB
[2022-04-05 23:54:38 large] (main.py 226): INFO Train: [54/300][2300/2502]	eta 0:02:06 lr 0.000460	time 0.6466 (0.6262)	loss 2.9250 (3.7313)	grad_norm 2.4515 (inf)	mem 8931MB
[2022-04-05 23:55:41 large] (main.py 226): INFO Train: [54/300][2400/2502]	eta 0:01:03 lr 0.000460	time 0.5661 (0.6263)	loss 3.2857 (3.7329)	grad_norm 3.0565 (inf)	mem 8931MB
[2022-04-05 23:56:43 large] (main.py 226): INFO Train: [54/300][2500/2502]	eta 0:00:01 lr 0.000460	time 0.6163 (0.6263)	loss 3.8163 (3.7316)	grad_norm 2.7815 (inf)	mem 8931MB
[2022-04-05 23:56:44 large] (main.py 233): INFO EPOCH 54 training takes 0:26:07
[2022-04-05 23:56:51 large] (main.py 273): INFO Test: [0/98]	Time 6.262 (6.262)	Loss 1.2867 (1.2867)	Acc@1 72.070 (72.070)	Acc@5 90.430 (90.430)	Mem 8931MB
[2022-04-05 23:57:16 large] (main.py 279): INFO  * Acc@1 72.630 Acc@5 91.428
[2022-04-05 23:57:16 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.6%
[2022-04-05 23:57:16 large] (utils.py 57): INFO output/large/default/ckpt_epoch_54.pth saving......
[2022-04-05 23:57:17 large] (utils.py 59): INFO output/large/default/ckpt_epoch_54.pth saved !!!
[2022-04-05 23:57:17 large] (main.py 148): INFO Max accuracy: 72.63%
[2022-04-05 23:57:24 large] (main.py 226): INFO Train: [55/300][0/2502]	eta 4:49:44 lr 0.000460	time 6.9483 (6.9483)	loss 4.2595 (4.2595)	grad_norm 2.3302 (2.3302)	mem 8931MB
[2022-04-05 23:58:16 large] (main.py 226): INFO Train: [55/300][100/2502]	eta 0:23:27 lr 0.000460	time 0.6756 (0.5860)	loss 3.5492 (3.6882)	grad_norm 2.4581 (2.5486)	mem 8931MB
[2022-04-05 23:59:21 large] (main.py 226): INFO Train: [55/300][200/2502]	eta 0:23:35 lr 0.000460	time 0.6113 (0.6149)	loss 3.7258 (3.7269)	grad_norm 2.1818 (2.5742)	mem 8931MB
[2022-04-06 00:00:25 large] (main.py 226): INFO Train: [55/300][300/2502]	eta 0:22:55 lr 0.000460	time 0.6625 (0.6247)	loss 2.5669 (3.7066)	grad_norm 2.1321 (2.5404)	mem 8931MB
[2022-04-06 00:01:29 large] (main.py 226): INFO Train: [55/300][400/2502]	eta 0:22:02 lr 0.000460	time 0.5712 (0.6293)	loss 3.6102 (3.7007)	grad_norm 2.6838 (2.5024)	mem 8931MB
[2022-04-06 00:02:32 large] (main.py 226): INFO Train: [55/300][500/2502]	eta 0:20:56 lr 0.000460	time 0.7533 (0.6278)	loss 4.3642 (3.7098)	grad_norm 2.7936 (2.5070)	mem 8931MB
[2022-04-06 00:03:35 large] (main.py 226): INFO Train: [55/300][600/2502]	eta 0:19:57 lr 0.000460	time 0.6276 (0.6296)	loss 4.3611 (3.7078)	grad_norm 2.4966 (2.5010)	mem 8931MB
[2022-04-06 00:04:38 large] (main.py 226): INFO Train: [55/300][700/2502]	eta 0:18:54 lr 0.000460	time 0.5944 (0.6294)	loss 3.7758 (3.7040)	grad_norm 3.0542 (2.5174)	mem 8931MB
[2022-04-06 00:05:41 large] (main.py 226): INFO Train: [55/300][800/2502]	eta 0:17:49 lr 0.000460	time 0.6183 (0.6285)	loss 2.8916 (3.6938)	grad_norm 3.0220 (2.5155)	mem 8931MB
[2022-04-06 00:06:43 large] (main.py 226): INFO Train: [55/300][900/2502]	eta 0:16:46 lr 0.000460	time 0.5592 (0.6282)	loss 4.1466 (3.6922)	grad_norm 2.2380 (2.5204)	mem 8931MB
[2022-04-06 00:07:45 large] (main.py 226): INFO Train: [55/300][1000/2502]	eta 0:15:42 lr 0.000460	time 0.5896 (0.6277)	loss 3.9067 (3.6862)	grad_norm 2.6664 (2.5093)	mem 8931MB
[2022-04-06 00:08:47 large] (main.py 226): INFO Train: [55/300][1100/2502]	eta 0:14:38 lr 0.000459	time 0.5101 (0.6269)	loss 4.5384 (3.6772)	grad_norm 2.5905 (2.5061)	mem 8931MB
[2022-04-06 00:09:49 large] (main.py 226): INFO Train: [55/300][1200/2502]	eta 0:13:35 lr 0.000459	time 0.5504 (0.6264)	loss 3.8713 (3.6789)	grad_norm 1.8320 (2.5086)	mem 8931MB
[2022-04-06 00:10:50 large] (main.py 226): INFO Train: [55/300][1300/2502]	eta 0:12:31 lr 0.000459	time 0.6406 (0.6251)	loss 4.1662 (3.6796)	grad_norm 2.2034 (2.5073)	mem 8931MB
[2022-04-06 00:11:52 large] (main.py 226): INFO Train: [55/300][1400/2502]	eta 0:11:28 lr 0.000459	time 0.5011 (0.6247)	loss 4.3575 (3.6805)	grad_norm 2.9133 (2.5120)	mem 8931MB
[2022-04-06 00:12:54 large] (main.py 226): INFO Train: [55/300][1500/2502]	eta 0:10:25 lr 0.000459	time 0.7390 (0.6243)	loss 3.9560 (3.6849)	grad_norm 2.0284 (2.5139)	mem 8931MB
[2022-04-06 00:13:56 large] (main.py 226): INFO Train: [55/300][1600/2502]	eta 0:09:22 lr 0.000459	time 0.5788 (0.6237)	loss 4.2213 (3.6851)	grad_norm 2.1078 (2.5162)	mem 8931MB
[2022-04-06 00:14:56 large] (main.py 226): INFO Train: [55/300][1700/2502]	eta 0:08:19 lr 0.000459	time 0.6567 (0.6228)	loss 2.5853 (3.6892)	grad_norm 2.9526 (2.5193)	mem 8931MB
[2022-04-06 00:15:59 large] (main.py 226): INFO Train: [55/300][1800/2502]	eta 0:07:17 lr 0.000459	time 0.6258 (0.6232)	loss 4.4737 (3.6916)	grad_norm 2.5950 (2.5095)	mem 8931MB
[2022-04-06 00:17:02 large] (main.py 226): INFO Train: [55/300][1900/2502]	eta 0:06:15 lr 0.000459	time 0.6470 (0.6231)	loss 4.0633 (3.6948)	grad_norm 2.7685 (2.5062)	mem 8931MB
[2022-04-06 00:18:04 large] (main.py 226): INFO Train: [55/300][2000/2502]	eta 0:05:12 lr 0.000459	time 0.6315 (0.6231)	loss 4.8182 (3.6957)	grad_norm 2.9690 (inf)	mem 8931MB
[2022-04-06 00:19:06 large] (main.py 226): INFO Train: [55/300][2100/2502]	eta 0:04:10 lr 0.000459	time 0.6983 (0.6232)	loss 4.1039 (3.6978)	grad_norm 2.0275 (inf)	mem 8931MB
[2022-04-06 00:20:09 large] (main.py 226): INFO Train: [55/300][2200/2502]	eta 0:03:08 lr 0.000459	time 0.5921 (0.6234)	loss 3.6029 (3.6980)	grad_norm 2.7816 (inf)	mem 8931MB
[2022-04-06 00:21:12 large] (main.py 226): INFO Train: [55/300][2300/2502]	eta 0:02:05 lr 0.000459	time 0.7694 (0.6235)	loss 3.9450 (3.7035)	grad_norm 3.1451 (inf)	mem 8931MB
[2022-04-06 00:22:13 large] (main.py 226): INFO Train: [55/300][2400/2502]	eta 0:01:03 lr 0.000459	time 0.6218 (0.6231)	loss 2.9912 (3.6999)	grad_norm 2.2749 (inf)	mem 8931MB
[2022-04-06 00:23:15 large] (main.py 226): INFO Train: [55/300][2500/2502]	eta 0:00:01 lr 0.000459	time 0.5903 (0.6227)	loss 4.0709 (3.7018)	grad_norm 1.9632 (inf)	mem 8931MB
[2022-04-06 00:23:16 large] (main.py 233): INFO EPOCH 55 training takes 0:25:58
[2022-04-06 00:23:21 large] (main.py 273): INFO Test: [0/98]	Time 5.640 (5.640)	Loss 1.4092 (1.4092)	Acc@1 70.508 (70.508)	Acc@5 89.648 (89.648)	Mem 8931MB
[2022-04-06 00:23:48 large] (main.py 279): INFO  * Acc@1 72.760 Acc@5 91.588
[2022-04-06 00:23:48 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.8%
[2022-04-06 00:23:48 large] (utils.py 57): INFO output/large/default/ckpt_epoch_55.pth saving......
[2022-04-06 00:23:49 large] (utils.py 59): INFO output/large/default/ckpt_epoch_55.pth saved !!!
[2022-04-06 00:23:49 large] (main.py 148): INFO Max accuracy: 72.76%
[2022-04-06 00:23:57 large] (main.py 226): INFO Train: [56/300][0/2502]	eta 5:39:30 lr 0.000459	time 8.1418 (8.1418)	loss 4.3001 (4.3001)	grad_norm 2.0826 (2.0826)	mem 8931MB
[2022-04-06 00:24:48 large] (main.py 226): INFO Train: [56/300][100/2502]	eta 0:23:28 lr 0.000459	time 0.6417 (0.5865)	loss 4.1160 (3.6692)	grad_norm 2.6427 (2.4788)	mem 8931MB
[2022-04-06 00:25:50 large] (main.py 226): INFO Train: [56/300][200/2502]	eta 0:23:09 lr 0.000459	time 0.7180 (0.6035)	loss 4.0690 (3.6700)	grad_norm 2.2265 (2.4786)	mem 8931MB
[2022-04-06 00:26:52 large] (main.py 226): INFO Train: [56/300][300/2502]	eta 0:22:20 lr 0.000458	time 0.6124 (0.6086)	loss 4.0048 (3.6670)	grad_norm 3.4242 (2.4740)	mem 8931MB
[2022-04-06 00:27:54 large] (main.py 226): INFO Train: [56/300][400/2502]	eta 0:21:28 lr 0.000458	time 0.5908 (0.6130)	loss 3.7617 (3.6967)	grad_norm 2.3393 (2.4761)	mem 8931MB
[2022-04-06 00:28:57 large] (main.py 226): INFO Train: [56/300][500/2502]	eta 0:20:32 lr 0.000458	time 0.6530 (0.6158)	loss 3.6292 (3.6940)	grad_norm 2.8701 (2.4771)	mem 8931MB
[2022-04-06 00:29:59 large] (main.py 226): INFO Train: [56/300][600/2502]	eta 0:19:32 lr 0.000458	time 0.5333 (0.6164)	loss 4.2306 (3.6935)	grad_norm 2.5130 (2.4857)	mem 8931MB
[2022-04-06 00:31:01 large] (main.py 226): INFO Train: [56/300][700/2502]	eta 0:18:32 lr 0.000458	time 0.5453 (0.6172)	loss 3.4387 (3.6904)	grad_norm 2.8996 (2.4921)	mem 8931MB
[2022-04-06 00:32:02 large] (main.py 226): INFO Train: [56/300][800/2502]	eta 0:17:28 lr 0.000458	time 0.6728 (0.6158)	loss 3.2538 (3.6896)	grad_norm 2.6118 (2.5101)	mem 8931MB
[2022-04-06 00:33:04 large] (main.py 226): INFO Train: [56/300][900/2502]	eta 0:16:26 lr 0.000458	time 0.5947 (0.6158)	loss 3.2082 (3.6878)	grad_norm 2.4084 (2.5046)	mem 8931MB
[2022-04-06 00:34:06 large] (main.py 226): INFO Train: [56/300][1000/2502]	eta 0:15:25 lr 0.000458	time 0.6270 (0.6164)	loss 4.5069 (3.6916)	grad_norm 1.9986 (2.5090)	mem 8931MB
[2022-04-06 00:35:08 large] (main.py 226): INFO Train: [56/300][1100/2502]	eta 0:14:24 lr 0.000458	time 0.7046 (0.6168)	loss 3.4504 (3.6821)	grad_norm 2.0484 (2.5075)	mem 8931MB
[2022-04-06 00:36:10 large] (main.py 226): INFO Train: [56/300][1200/2502]	eta 0:13:23 lr 0.000458	time 0.5243 (0.6170)	loss 4.0364 (3.6741)	grad_norm 2.0150 (2.5126)	mem 8931MB
[2022-04-06 00:37:11 large] (main.py 226): INFO Train: [56/300][1300/2502]	eta 0:12:21 lr 0.000458	time 0.6290 (0.6170)	loss 3.7553 (3.6714)	grad_norm 3.7197 (2.5180)	mem 8931MB
[2022-04-06 00:38:13 large] (main.py 226): INFO Train: [56/300][1400/2502]	eta 0:11:19 lr 0.000458	time 0.5963 (0.6167)	loss 4.6029 (3.6760)	grad_norm 2.7005 (2.5189)	mem 8931MB
[2022-04-06 00:39:15 large] (main.py 226): INFO Train: [56/300][1500/2502]	eta 0:10:18 lr 0.000458	time 0.6201 (0.6172)	loss 3.2407 (3.6762)	grad_norm 2.4914 (2.5258)	mem 8931MB
[2022-04-06 00:40:17 large] (main.py 226): INFO Train: [56/300][1600/2502]	eta 0:09:16 lr 0.000458	time 0.6125 (0.6171)	loss 4.6277 (3.6825)	grad_norm 2.3599 (inf)	mem 8931MB
[2022-04-06 00:41:18 large] (main.py 226): INFO Train: [56/300][1700/2502]	eta 0:08:14 lr 0.000458	time 0.8059 (0.6170)	loss 3.6564 (3.6856)	grad_norm 2.3338 (inf)	mem 8931MB
[2022-04-06 00:42:20 large] (main.py 226): INFO Train: [56/300][1800/2502]	eta 0:07:13 lr 0.000458	time 0.5977 (0.6172)	loss 3.2562 (3.6871)	grad_norm 2.3887 (inf)	mem 8931MB
[2022-04-06 00:43:22 large] (main.py 226): INFO Train: [56/300][1900/2502]	eta 0:06:11 lr 0.000458	time 0.7084 (0.6173)	loss 3.6674 (3.6847)	grad_norm 2.6758 (inf)	mem 8931MB
[2022-04-06 00:44:25 large] (main.py 226): INFO Train: [56/300][2000/2502]	eta 0:05:10 lr 0.000457	time 0.5769 (0.6177)	loss 2.7924 (3.6845)	grad_norm 2.4173 (inf)	mem 8931MB
[2022-04-06 00:45:27 large] (main.py 226): INFO Train: [56/300][2100/2502]	eta 0:04:08 lr 0.000457	time 0.6276 (0.6182)	loss 3.7159 (3.6866)	grad_norm 2.7841 (inf)	mem 8931MB
[2022-04-06 00:46:28 large] (main.py 226): INFO Train: [56/300][2200/2502]	eta 0:03:06 lr 0.000457	time 0.6134 (0.6177)	loss 2.5041 (3.6877)	grad_norm 3.1684 (inf)	mem 8931MB
[2022-04-06 00:47:31 large] (main.py 226): INFO Train: [56/300][2300/2502]	eta 0:02:04 lr 0.000457	time 0.6456 (0.6180)	loss 4.3544 (3.6854)	grad_norm 2.6397 (inf)	mem 8931MB
[2022-04-06 00:48:33 large] (main.py 226): INFO Train: [56/300][2400/2502]	eta 0:01:03 lr 0.000457	time 0.5991 (0.6182)	loss 3.7584 (3.6877)	grad_norm 2.6158 (inf)	mem 8931MB
[2022-04-06 00:49:35 large] (main.py 226): INFO Train: [56/300][2500/2502]	eta 0:00:01 lr 0.000457	time 0.6236 (0.6182)	loss 3.6786 (3.6894)	grad_norm 3.3538 (inf)	mem 8931MB
[2022-04-06 00:49:36 large] (main.py 233): INFO EPOCH 56 training takes 0:25:47
[2022-04-06 00:49:42 large] (main.py 273): INFO Test: [0/98]	Time 6.686 (6.686)	Loss 1.2493 (1.2493)	Acc@1 72.070 (72.070)	Acc@5 90.820 (90.820)	Mem 8931MB
[2022-04-06 00:50:08 large] (main.py 279): INFO  * Acc@1 72.908 Acc@5 91.496
[2022-04-06 00:50:08 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.9%
[2022-04-06 00:50:08 large] (utils.py 57): INFO output/large/default/ckpt_epoch_56.pth saving......
[2022-04-06 00:50:09 large] (utils.py 59): INFO output/large/default/ckpt_epoch_56.pth saved !!!
[2022-04-06 00:50:09 large] (main.py 148): INFO Max accuracy: 72.91%
[2022-04-06 00:50:17 large] (main.py 226): INFO Train: [57/300][0/2502]	eta 5:58:28 lr 0.000457	time 8.5965 (8.5965)	loss 4.0020 (4.0020)	grad_norm 2.0048 (2.0048)	mem 8931MB
[2022-04-06 00:51:09 large] (main.py 226): INFO Train: [57/300][100/2502]	eta 0:23:49 lr 0.000457	time 0.6008 (0.5951)	loss 4.5015 (3.6311)	grad_norm 2.4666 (2.6032)	mem 8931MB
[2022-04-06 00:52:12 large] (main.py 226): INFO Train: [57/300][200/2502]	eta 0:23:29 lr 0.000457	time 0.6206 (0.6124)	loss 4.5020 (3.6829)	grad_norm 2.0542 (2.5790)	mem 8931MB
[2022-04-06 00:53:15 large] (main.py 226): INFO Train: [57/300][300/2502]	eta 0:22:42 lr 0.000457	time 0.6569 (0.6188)	loss 3.6567 (3.6793)	grad_norm 2.2476 (2.5589)	mem 8931MB
[2022-04-06 00:54:17 large] (main.py 226): INFO Train: [57/300][400/2502]	eta 0:21:43 lr 0.000457	time 0.5884 (0.6203)	loss 3.7667 (3.6836)	grad_norm 2.4683 (2.5055)	mem 8931MB
[2022-04-06 00:55:19 large] (main.py 226): INFO Train: [57/300][500/2502]	eta 0:20:41 lr 0.000457	time 0.6663 (0.6202)	loss 2.4801 (3.6643)	grad_norm 2.4772 (2.4907)	mem 8931MB
[2022-04-06 00:56:22 large] (main.py 226): INFO Train: [57/300][600/2502]	eta 0:19:42 lr 0.000457	time 0.5872 (0.6219)	loss 3.9957 (3.6492)	grad_norm 2.6489 (2.4889)	mem 8931MB
[2022-04-06 00:57:25 large] (main.py 226): INFO Train: [57/300][700/2502]	eta 0:18:40 lr 0.000457	time 0.6643 (0.6219)	loss 2.7334 (3.6676)	grad_norm 2.4617 (2.4989)	mem 8931MB
[2022-04-06 00:58:27 large] (main.py 226): INFO Train: [57/300][800/2502]	eta 0:17:38 lr 0.000457	time 0.6776 (0.6216)	loss 4.6237 (3.6725)	grad_norm 3.0811 (2.4935)	mem 8931MB
[2022-04-06 00:59:29 large] (main.py 226): INFO Train: [57/300][900/2502]	eta 0:16:36 lr 0.000457	time 0.5617 (0.6222)	loss 3.8050 (3.6799)	grad_norm 2.4471 (2.4905)	mem 8931MB
[2022-04-06 01:00:31 large] (main.py 226): INFO Train: [57/300][1000/2502]	eta 0:15:33 lr 0.000457	time 0.6061 (0.6216)	loss 3.4218 (3.6764)	grad_norm 3.3004 (2.4993)	mem 8931MB
[2022-04-06 01:01:34 large] (main.py 226): INFO Train: [57/300][1100/2502]	eta 0:14:32 lr 0.000457	time 0.5891 (0.6225)	loss 3.9195 (3.6713)	grad_norm 5.1390 (2.5107)	mem 8931MB
[2022-04-06 01:02:34 large] (main.py 226): INFO Train: [57/300][1200/2502]	eta 0:13:28 lr 0.000457	time 0.5036 (0.6208)	loss 4.0110 (3.6739)	grad_norm 1.9223 (2.5045)	mem 8931MB
[2022-04-06 01:03:35 large] (main.py 226): INFO Train: [57/300][1300/2502]	eta 0:12:25 lr 0.000456	time 0.6864 (0.6200)	loss 4.2002 (3.6689)	grad_norm 2.5540 (2.4958)	mem 8931MB
[2022-04-06 01:04:36 large] (main.py 226): INFO Train: [57/300][1400/2502]	eta 0:11:22 lr 0.000456	time 0.5979 (0.6191)	loss 3.3896 (3.6700)	grad_norm 2.1219 (2.4984)	mem 8931MB
[2022-04-06 01:05:37 large] (main.py 226): INFO Train: [57/300][1500/2502]	eta 0:10:19 lr 0.000456	time 0.6872 (0.6183)	loss 3.7090 (3.6737)	grad_norm 3.3158 (inf)	mem 8931MB
[2022-04-06 01:06:40 large] (main.py 226): INFO Train: [57/300][1600/2502]	eta 0:09:18 lr 0.000456	time 0.6819 (0.6189)	loss 3.0602 (3.6766)	grad_norm 3.2363 (inf)	mem 8931MB
[2022-04-06 01:07:39 large] (main.py 226): INFO Train: [57/300][1700/2502]	eta 0:08:15 lr 0.000456	time 0.5245 (0.6174)	loss 4.0880 (3.6756)	grad_norm 2.3866 (inf)	mem 8931MB
[2022-04-06 01:08:32 large] (main.py 226): INFO Train: [57/300][1800/2502]	eta 0:07:09 lr 0.000456	time 0.5948 (0.6124)	loss 4.1727 (3.6743)	grad_norm 2.6782 (inf)	mem 8931MB
[2022-04-06 01:09:34 large] (main.py 226): INFO Train: [57/300][1900/2502]	eta 0:06:09 lr 0.000456	time 0.6448 (0.6132)	loss 3.3523 (3.6716)	grad_norm 2.6269 (inf)	mem 8931MB
[2022-04-06 01:10:38 large] (main.py 226): INFO Train: [57/300][2000/2502]	eta 0:05:08 lr 0.000456	time 0.6221 (0.6141)	loss 4.2349 (3.6782)	grad_norm 2.4078 (inf)	mem 8931MB
[2022-04-06 01:11:39 large] (main.py 226): INFO Train: [57/300][2100/2502]	eta 0:04:06 lr 0.000456	time 0.6484 (0.6142)	loss 2.7987 (3.6762)	grad_norm 2.6977 (inf)	mem 8931MB
[2022-04-06 01:12:41 large] (main.py 226): INFO Train: [57/300][2200/2502]	eta 0:03:05 lr 0.000456	time 0.6178 (0.6144)	loss 3.3247 (3.6743)	grad_norm 2.3803 (inf)	mem 8931MB
[2022-04-06 01:13:43 large] (main.py 226): INFO Train: [57/300][2300/2502]	eta 0:02:04 lr 0.000456	time 0.5332 (0.6146)	loss 3.7121 (3.6734)	grad_norm 2.4409 (inf)	mem 8931MB
[2022-04-06 01:14:45 large] (main.py 226): INFO Train: [57/300][2400/2502]	eta 0:01:02 lr 0.000456	time 0.7190 (0.6149)	loss 2.4156 (3.6728)	grad_norm 1.8803 (inf)	mem 8931MB
[2022-04-06 01:15:47 large] (main.py 226): INFO Train: [57/300][2500/2502]	eta 0:00:01 lr 0.000456	time 0.6202 (0.6151)	loss 3.8907 (3.6705)	grad_norm 2.2453 (inf)	mem 8931MB
[2022-04-06 01:15:48 large] (main.py 233): INFO EPOCH 57 training takes 0:25:39
[2022-04-06 01:15:55 large] (main.py 273): INFO Test: [0/98]	Time 6.909 (6.909)	Loss 1.2482 (1.2482)	Acc@1 71.875 (71.875)	Acc@5 91.406 (91.406)	Mem 8931MB
[2022-04-06 01:16:20 large] (main.py 279): INFO  * Acc@1 72.758 Acc@5 91.454
[2022-04-06 01:16:20 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.8%
[2022-04-06 01:16:20 large] (main.py 148): INFO Max accuracy: 72.91%
[2022-04-06 01:16:27 large] (main.py 226): INFO Train: [58/300][0/2502]	eta 4:59:11 lr 0.000456	time 7.1747 (7.1747)	loss 3.7026 (3.7026)	grad_norm 2.8483 (2.8483)	mem 8931MB
[2022-04-06 01:17:20 large] (main.py 226): INFO Train: [58/300][100/2502]	eta 0:23:34 lr 0.000456	time 0.6283 (0.5889)	loss 4.2379 (3.7085)	grad_norm 2.1394 (nan)	mem 8931MB
[2022-04-06 01:18:22 large] (main.py 226): INFO Train: [58/300][200/2502]	eta 0:23:09 lr 0.000456	time 0.7019 (0.6037)	loss 3.3072 (3.6921)	grad_norm 3.6199 (nan)	mem 8931MB
[2022-04-06 01:19:25 large] (main.py 226): INFO Train: [58/300][300/2502]	eta 0:22:28 lr 0.000456	time 0.5887 (0.6126)	loss 3.7426 (3.6687)	grad_norm 2.0581 (nan)	mem 8931MB
[2022-04-06 01:20:27 large] (main.py 226): INFO Train: [58/300][400/2502]	eta 0:21:33 lr 0.000455	time 0.7398 (0.6154)	loss 2.7794 (3.6786)	grad_norm 2.1315 (nan)	mem 8931MB
[2022-04-06 01:21:28 large] (main.py 226): INFO Train: [58/300][500/2502]	eta 0:20:28 lr 0.000455	time 0.6309 (0.6136)	loss 3.6730 (3.6856)	grad_norm 2.7276 (nan)	mem 8931MB
[2022-04-06 01:22:29 large] (main.py 226): INFO Train: [58/300][600/2502]	eta 0:19:26 lr 0.000455	time 0.6272 (0.6130)	loss 3.7437 (3.6875)	grad_norm 2.5212 (nan)	mem 8931MB
[2022-04-06 01:23:32 large] (main.py 226): INFO Train: [58/300][700/2502]	eta 0:18:29 lr 0.000455	time 0.6150 (0.6155)	loss 3.1854 (3.6850)	grad_norm 1.9912 (nan)	mem 8931MB
[2022-04-06 01:24:34 large] (main.py 226): INFO Train: [58/300][800/2502]	eta 0:17:28 lr 0.000455	time 0.6128 (0.6159)	loss 4.3124 (3.6854)	grad_norm 2.2146 (nan)	mem 8931MB
[2022-04-06 01:25:36 large] (main.py 226): INFO Train: [58/300][900/2502]	eta 0:16:27 lr 0.000455	time 0.6348 (0.6164)	loss 4.0669 (3.6890)	grad_norm 2.8332 (nan)	mem 8931MB
[2022-04-06 01:26:38 large] (main.py 226): INFO Train: [58/300][1000/2502]	eta 0:15:27 lr 0.000455	time 0.5664 (0.6172)	loss 3.6070 (3.6909)	grad_norm 2.7361 (nan)	mem 8931MB
[2022-04-06 01:27:41 large] (main.py 226): INFO Train: [58/300][1100/2502]	eta 0:14:26 lr 0.000455	time 0.6120 (0.6182)	loss 3.9325 (3.6950)	grad_norm 1.8771 (nan)	mem 8931MB
[2022-04-06 01:28:43 large] (main.py 226): INFO Train: [58/300][1200/2502]	eta 0:13:24 lr 0.000455	time 0.6268 (0.6180)	loss 3.6493 (3.6896)	grad_norm 2.0202 (nan)	mem 8931MB
[2022-04-06 01:29:45 large] (main.py 226): INFO Train: [58/300][1300/2502]	eta 0:12:23 lr 0.000455	time 0.6135 (0.6184)	loss 3.9472 (3.6955)	grad_norm 2.3414 (nan)	mem 8931MB
[2022-04-06 01:30:46 large] (main.py 226): INFO Train: [58/300][1400/2502]	eta 0:11:21 lr 0.000455	time 0.7010 (0.6182)	loss 2.5777 (3.6943)	grad_norm 2.2764 (nan)	mem 8931MB
[2022-04-06 01:31:48 large] (main.py 226): INFO Train: [58/300][1500/2502]	eta 0:10:19 lr 0.000455	time 0.5395 (0.6183)	loss 4.3876 (3.6953)	grad_norm 2.2057 (nan)	mem 8931MB
[2022-04-06 01:32:51 large] (main.py 226): INFO Train: [58/300][1600/2502]	eta 0:09:17 lr 0.000455	time 0.6271 (0.6186)	loss 2.7282 (3.6923)	grad_norm 4.1160 (nan)	mem 8931MB
[2022-04-06 01:33:51 large] (main.py 226): INFO Train: [58/300][1700/2502]	eta 0:08:15 lr 0.000455	time 0.5117 (0.6180)	loss 3.6260 (3.6940)	grad_norm 2.6230 (nan)	mem 8931MB
[2022-04-06 01:34:53 large] (main.py 226): INFO Train: [58/300][1800/2502]	eta 0:07:13 lr 0.000455	time 0.5911 (0.6181)	loss 2.9415 (3.6968)	grad_norm 2.2092 (nan)	mem 8931MB
[2022-04-06 01:35:55 large] (main.py 226): INFO Train: [58/300][1900/2502]	eta 0:06:12 lr 0.000455	time 0.5988 (0.6181)	loss 3.8991 (3.6970)	grad_norm 2.6485 (nan)	mem 8931MB
[2022-04-06 01:36:58 large] (main.py 226): INFO Train: [58/300][2000/2502]	eta 0:05:10 lr 0.000455	time 0.5541 (0.6187)	loss 3.6241 (3.6912)	grad_norm 2.1220 (nan)	mem 8931MB
[2022-04-06 01:38:01 large] (main.py 226): INFO Train: [58/300][2100/2502]	eta 0:04:08 lr 0.000454	time 0.5746 (0.6190)	loss 3.3858 (3.6936)	grad_norm 2.3838 (nan)	mem 8931MB
[2022-04-06 01:39:03 large] (main.py 226): INFO Train: [58/300][2200/2502]	eta 0:03:06 lr 0.000454	time 0.6408 (0.6189)	loss 4.0390 (3.6915)	grad_norm 2.4000 (nan)	mem 8931MB
[2022-04-06 01:40:05 large] (main.py 226): INFO Train: [58/300][2300/2502]	eta 0:02:05 lr 0.000454	time 0.6050 (0.6190)	loss 3.6263 (3.6942)	grad_norm 2.2157 (nan)	mem 8931MB
[2022-04-06 01:41:07 large] (main.py 226): INFO Train: [58/300][2400/2502]	eta 0:01:03 lr 0.000454	time 0.6233 (0.6191)	loss 3.7468 (3.6946)	grad_norm 3.1868 (nan)	mem 8931MB
[2022-04-06 01:42:07 large] (main.py 226): INFO Train: [58/300][2500/2502]	eta 0:00:01 lr 0.000454	time 0.5813 (0.6186)	loss 4.1170 (3.6977)	grad_norm 2.2396 (nan)	mem 8931MB
[2022-04-06 01:42:08 large] (main.py 233): INFO EPOCH 58 training takes 0:25:48
[2022-04-06 01:42:15 large] (main.py 273): INFO Test: [0/98]	Time 6.528 (6.528)	Loss 1.2593 (1.2593)	Acc@1 74.023 (74.023)	Acc@5 92.969 (92.969)	Mem 8931MB
[2022-04-06 01:42:41 large] (main.py 279): INFO  * Acc@1 73.028 Acc@5 91.596
[2022-04-06 01:42:41 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 73.0%
[2022-04-06 01:42:41 large] (utils.py 57): INFO output/large/default/ckpt_epoch_58.pth saving......
[2022-04-06 01:42:42 large] (utils.py 59): INFO output/large/default/ckpt_epoch_58.pth saved !!!
[2022-04-06 01:42:42 large] (main.py 148): INFO Max accuracy: 73.03%
[2022-04-06 01:42:49 large] (main.py 226): INFO Train: [59/300][0/2502]	eta 5:25:44 lr 0.000454	time 7.8116 (7.8116)	loss 2.7648 (2.7648)	grad_norm 2.2161 (2.2161)	mem 8931MB
[2022-04-06 01:43:38 large] (main.py 226): INFO Train: [59/300][100/2502]	eta 0:22:22 lr 0.000454	time 0.4813 (0.5590)	loss 4.0377 (3.7071)	grad_norm 2.0219 (2.6559)	mem 8931MB
[2022-04-06 01:44:29 large] (main.py 226): INFO Train: [59/300][200/2502]	eta 0:20:31 lr 0.000454	time 0.7384 (0.5352)	loss 2.6732 (3.7170)	grad_norm 3.9752 (2.6082)	mem 8931MB
[2022-04-06 01:45:32 large] (main.py 226): INFO Train: [59/300][300/2502]	eta 0:20:44 lr 0.000454	time 0.5110 (0.5653)	loss 3.6777 (3.6665)	grad_norm 2.5590 (2.5524)	mem 8931MB
[2022-04-06 01:46:35 large] (main.py 226): INFO Train: [59/300][400/2502]	eta 0:20:20 lr 0.000454	time 0.5210 (0.5807)	loss 3.1667 (3.6747)	grad_norm 2.2320 (2.5345)	mem 8931MB
[2022-04-06 01:47:38 large] (main.py 226): INFO Train: [59/300][500/2502]	eta 0:19:44 lr 0.000454	time 0.5396 (0.5917)	loss 3.4542 (3.6741)	grad_norm 3.1705 (2.5115)	mem 8931MB
[2022-04-06 01:48:41 large] (main.py 226): INFO Train: [59/300][600/2502]	eta 0:18:55 lr 0.000454	time 0.6994 (0.5972)	loss 4.4437 (3.6816)	grad_norm 2.4130 (2.5318)	mem 8931MB
[2022-04-06 01:49:43 large] (main.py 226): INFO Train: [59/300][700/2502]	eta 0:18:02 lr 0.000454	time 0.6209 (0.6009)	loss 3.6526 (3.6795)	grad_norm 2.3801 (2.5314)	mem 8931MB
[2022-04-06 01:50:45 large] (main.py 226): INFO Train: [59/300][800/2502]	eta 0:17:07 lr 0.000454	time 0.6335 (0.6037)	loss 4.0781 (3.6837)	grad_norm 2.5100 (2.5267)	mem 8931MB
[2022-04-06 01:51:47 large] (main.py 226): INFO Train: [59/300][900/2502]	eta 0:16:10 lr 0.000454	time 0.6911 (0.6058)	loss 4.2927 (3.6770)	grad_norm 2.4096 (2.5259)	mem 8931MB
[2022-04-06 01:52:51 large] (main.py 226): INFO Train: [59/300][1000/2502]	eta 0:15:13 lr 0.000454	time 0.5829 (0.6085)	loss 4.2208 (3.6771)	grad_norm 2.6076 (2.5261)	mem 8931MB
[2022-04-06 01:53:51 large] (main.py 226): INFO Train: [59/300][1100/2502]	eta 0:14:12 lr 0.000454	time 0.5892 (0.6083)	loss 3.1086 (3.6771)	grad_norm 2.6355 (2.5230)	mem 8931MB
[2022-04-06 01:54:55 large] (main.py 226): INFO Train: [59/300][1200/2502]	eta 0:13:14 lr 0.000454	time 0.4892 (0.6103)	loss 4.2545 (3.6818)	grad_norm 1.7771 (2.5344)	mem 8931MB
[2022-04-06 01:55:56 large] (main.py 226): INFO Train: [59/300][1300/2502]	eta 0:12:14 lr 0.000453	time 0.6312 (0.6109)	loss 2.4913 (3.6809)	grad_norm 2.4225 (2.5306)	mem 8931MB
[2022-04-06 01:56:58 large] (main.py 226): INFO Train: [59/300][1400/2502]	eta 0:11:13 lr 0.000453	time 0.6225 (0.6114)	loss 3.4398 (3.6741)	grad_norm 1.8642 (2.5315)	mem 8931MB
[2022-04-06 01:58:00 large] (main.py 226): INFO Train: [59/300][1500/2502]	eta 0:10:13 lr 0.000453	time 0.6033 (0.6121)	loss 4.1080 (3.6760)	grad_norm 3.4934 (2.5255)	mem 8931MB
[2022-04-06 01:59:02 large] (main.py 226): INFO Train: [59/300][1600/2502]	eta 0:09:12 lr 0.000453	time 0.6828 (0.6124)	loss 2.8719 (3.6718)	grad_norm 2.3375 (2.5305)	mem 8931MB
[2022-04-06 02:00:04 large] (main.py 226): INFO Train: [59/300][1700/2502]	eta 0:08:11 lr 0.000453	time 0.6359 (0.6127)	loss 4.1372 (3.6694)	grad_norm 2.4333 (2.5234)	mem 8931MB
[2022-04-06 02:01:06 large] (main.py 226): INFO Train: [59/300][1800/2502]	eta 0:07:10 lr 0.000453	time 0.5908 (0.6132)	loss 4.2611 (3.6752)	grad_norm 1.9801 (inf)	mem 8931MB
[2022-04-06 02:02:07 large] (main.py 226): INFO Train: [59/300][1900/2502]	eta 0:06:09 lr 0.000453	time 0.5826 (0.6132)	loss 3.7817 (3.6783)	grad_norm 3.2707 (inf)	mem 8931MB
[2022-04-06 02:03:10 large] (main.py 226): INFO Train: [59/300][2000/2502]	eta 0:05:08 lr 0.000453	time 0.6795 (0.6137)	loss 3.4478 (3.6765)	grad_norm 2.3268 (inf)	mem 8931MB
[2022-04-06 02:04:12 large] (main.py 226): INFO Train: [59/300][2100/2502]	eta 0:04:06 lr 0.000453	time 0.5702 (0.6140)	loss 3.9952 (3.6766)	grad_norm 2.4317 (inf)	mem 8931MB
[2022-04-06 02:05:14 large] (main.py 226): INFO Train: [59/300][2200/2502]	eta 0:03:05 lr 0.000453	time 0.7254 (0.6146)	loss 4.1079 (3.6782)	grad_norm 1.9226 (inf)	mem 8931MB
[2022-04-06 02:06:16 large] (main.py 226): INFO Train: [59/300][2300/2502]	eta 0:02:04 lr 0.000453	time 0.6540 (0.6147)	loss 4.1437 (3.6810)	grad_norm 2.0219 (inf)	mem 8931MB
[2022-04-06 02:07:18 large] (main.py 226): INFO Train: [59/300][2400/2502]	eta 0:01:02 lr 0.000453	time 0.5741 (0.6150)	loss 3.8356 (3.6846)	grad_norm 2.1618 (inf)	mem 8931MB
[2022-04-06 02:08:19 large] (main.py 226): INFO Train: [59/300][2500/2502]	eta 0:00:01 lr 0.000453	time 0.6163 (0.6146)	loss 3.0326 (3.6849)	grad_norm 2.0333 (inf)	mem 8931MB
[2022-04-06 02:08:20 large] (main.py 233): INFO EPOCH 59 training takes 0:25:38
[2022-04-06 02:08:26 large] (main.py 273): INFO Test: [0/98]	Time 6.436 (6.436)	Loss 1.3419 (1.3419)	Acc@1 72.461 (72.461)	Acc@5 90.820 (90.820)	Mem 8931MB
[2022-04-06 02:08:52 large] (main.py 279): INFO  * Acc@1 72.970 Acc@5 91.570
[2022-04-06 02:08:52 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 73.0%
[2022-04-06 02:08:52 large] (main.py 148): INFO Max accuracy: 73.03%
[2022-04-06 02:08:59 large] (main.py 226): INFO Train: [60/300][0/2502]	eta 4:45:13 lr 0.000453	time 6.8399 (6.8399)	loss 3.2199 (3.2199)	grad_norm 2.7910 (2.7910)	mem 8931MB
[2022-04-06 02:09:49 large] (main.py 226): INFO Train: [60/300][100/2502]	eta 0:22:28 lr 0.000453	time 0.4802 (0.5615)	loss 3.9980 (3.6485)	grad_norm 2.5705 (2.4678)	mem 8931MB
[2022-04-06 02:10:42 large] (main.py 226): INFO Train: [60/300][200/2502]	eta 0:20:55 lr 0.000453	time 0.6245 (0.5455)	loss 3.8267 (3.6604)	grad_norm 3.3269 (2.4926)	mem 8931MB
[2022-04-06 02:11:45 large] (main.py 226): INFO Train: [60/300][300/2502]	eta 0:21:02 lr 0.000453	time 0.5733 (0.5734)	loss 2.4779 (3.6827)	grad_norm 2.8309 (2.4935)	mem 8931MB
[2022-04-06 02:12:48 large] (main.py 226): INFO Train: [60/300][400/2502]	eta 0:20:37 lr 0.000452	time 0.6555 (0.5887)	loss 2.5392 (3.6971)	grad_norm 2.0442 (2.4923)	mem 8931MB
[2022-04-06 02:13:52 large] (main.py 226): INFO Train: [60/300][500/2502]	eta 0:19:57 lr 0.000452	time 0.6825 (0.5979)	loss 3.4643 (3.6962)	grad_norm 2.5293 (2.5148)	mem 8931MB
[2022-04-06 02:14:54 large] (main.py 226): INFO Train: [60/300][600/2502]	eta 0:19:05 lr 0.000452	time 0.5248 (0.6023)	loss 3.9629 (3.7002)	grad_norm 2.6990 (2.5208)	mem 8931MB
[2022-04-06 02:15:57 large] (main.py 226): INFO Train: [60/300][700/2502]	eta 0:18:10 lr 0.000452	time 0.6140 (0.6053)	loss 2.8159 (3.7014)	grad_norm 2.5774 (2.5199)	mem 8931MB
[2022-04-06 02:17:00 large] (main.py 226): INFO Train: [60/300][800/2502]	eta 0:17:16 lr 0.000452	time 0.6180 (0.6089)	loss 3.1368 (3.6933)	grad_norm 3.4688 (2.5128)	mem 8931MB
[2022-04-06 02:18:02 large] (main.py 226): INFO Train: [60/300][900/2502]	eta 0:16:17 lr 0.000452	time 0.6313 (0.6100)	loss 3.3954 (3.6985)	grad_norm 2.2567 (2.5071)	mem 8931MB
[2022-04-06 02:19:03 large] (main.py 226): INFO Train: [60/300][1000/2502]	eta 0:15:16 lr 0.000452	time 0.5015 (0.6102)	loss 3.1090 (3.7035)	grad_norm 3.0850 (2.4947)	mem 8931MB
[2022-04-06 02:20:04 large] (main.py 226): INFO Train: [60/300][1100/2502]	eta 0:14:15 lr 0.000452	time 0.6128 (0.6105)	loss 4.1181 (3.7008)	grad_norm 3.5496 (2.5003)	mem 8931MB
[2022-04-06 02:21:06 large] (main.py 226): INFO Train: [60/300][1200/2502]	eta 0:13:15 lr 0.000452	time 0.6539 (0.6110)	loss 4.4183 (3.6987)	grad_norm 3.1113 (2.5050)	mem 8931MB
[2022-04-06 02:22:08 large] (main.py 226): INFO Train: [60/300][1300/2502]	eta 0:12:15 lr 0.000452	time 0.6366 (0.6116)	loss 4.3123 (3.7062)	grad_norm 3.4680 (2.5087)	mem 8931MB
[2022-04-06 02:23:10 large] (main.py 226): INFO Train: [60/300][1400/2502]	eta 0:11:14 lr 0.000452	time 0.6545 (0.6120)	loss 4.3020 (3.6962)	grad_norm 2.9262 (2.5137)	mem 8931MB
[2022-04-06 02:24:12 large] (main.py 226): INFO Train: [60/300][1500/2502]	eta 0:10:13 lr 0.000452	time 0.5876 (0.6127)	loss 2.8988 (3.6929)	grad_norm 2.2665 (inf)	mem 8931MB
[2022-04-06 02:25:14 large] (main.py 226): INFO Train: [60/300][1600/2502]	eta 0:09:13 lr 0.000452	time 0.6543 (0.6133)	loss 4.1552 (3.6916)	grad_norm 2.3785 (inf)	mem 8931MB
[2022-04-06 02:26:16 large] (main.py 226): INFO Train: [60/300][1700/2502]	eta 0:08:11 lr 0.000452	time 0.6690 (0.6134)	loss 4.3465 (3.6958)	grad_norm 2.3275 (inf)	mem 8931MB
[2022-04-06 02:27:17 large] (main.py 226): INFO Train: [60/300][1800/2502]	eta 0:07:10 lr 0.000452	time 0.6010 (0.6136)	loss 3.8990 (3.6956)	grad_norm 2.1174 (inf)	mem 8931MB
[2022-04-06 02:28:20 large] (main.py 226): INFO Train: [60/300][1900/2502]	eta 0:06:09 lr 0.000452	time 0.6079 (0.6141)	loss 4.1831 (3.6955)	grad_norm 2.0825 (inf)	mem 8931MB
[2022-04-06 02:29:22 large] (main.py 226): INFO Train: [60/300][2000/2502]	eta 0:05:08 lr 0.000452	time 0.5983 (0.6145)	loss 4.0818 (3.6961)	grad_norm 2.5066 (inf)	mem 8931MB
[2022-04-06 02:30:24 large] (main.py 226): INFO Train: [60/300][2100/2502]	eta 0:04:07 lr 0.000451	time 0.7244 (0.6149)	loss 3.9073 (3.6934)	grad_norm 2.3578 (inf)	mem 8931MB
[2022-04-06 02:31:26 large] (main.py 226): INFO Train: [60/300][2200/2502]	eta 0:03:05 lr 0.000451	time 0.6387 (0.6149)	loss 2.5282 (3.6931)	grad_norm 2.0531 (inf)	mem 8931MB
[2022-04-06 02:32:27 large] (main.py 226): INFO Train: [60/300][2300/2502]	eta 0:02:04 lr 0.000451	time 0.5224 (0.6151)	loss 2.5620 (3.6945)	grad_norm 1.9440 (inf)	mem 8931MB
[2022-04-06 02:33:30 large] (main.py 226): INFO Train: [60/300][2400/2502]	eta 0:01:02 lr 0.000451	time 0.7829 (0.6155)	loss 4.1886 (3.6893)	grad_norm 2.0581 (inf)	mem 8931MB
[2022-04-06 02:34:32 large] (main.py 226): INFO Train: [60/300][2500/2502]	eta 0:00:01 lr 0.000451	time 0.6006 (0.6155)	loss 3.9457 (3.6919)	grad_norm 2.2873 (inf)	mem 8931MB
[2022-04-06 02:34:33 large] (main.py 233): INFO EPOCH 60 training takes 0:25:40
[2022-04-06 02:34:39 large] (main.py 273): INFO Test: [0/98]	Time 5.922 (5.922)	Loss 1.2737 (1.2737)	Acc@1 73.242 (73.242)	Acc@5 91.406 (91.406)	Mem 8931MB
[2022-04-06 02:35:05 large] (main.py 279): INFO  * Acc@1 72.752 Acc@5 91.542
[2022-04-06 02:35:05 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.8%
[2022-04-06 02:35:05 large] (main.py 148): INFO Max accuracy: 73.03%
[2022-04-06 02:35:12 large] (main.py 226): INFO Train: [61/300][0/2502]	eta 4:33:06 lr 0.000451	time 6.5495 (6.5495)	loss 3.8654 (3.8654)	grad_norm 4.0076 (4.0076)	mem 8931MB
[2022-04-06 02:36:08 large] (main.py 226): INFO Train: [61/300][100/2502]	eta 0:24:46 lr 0.000451	time 0.6579 (0.6189)	loss 2.5231 (3.5742)	grad_norm 2.4636 (2.5396)	mem 8931MB
[2022-04-06 02:37:10 large] (main.py 226): INFO Train: [61/300][200/2502]	eta 0:23:54 lr 0.000451	time 0.6219 (0.6229)	loss 3.5351 (3.5983)	grad_norm 2.3128 (2.5131)	mem 8931MB
[2022-04-06 02:38:14 large] (main.py 226): INFO Train: [61/300][300/2502]	eta 0:22:59 lr 0.000451	time 0.5709 (0.6266)	loss 3.5482 (3.6180)	grad_norm 2.3877 (2.5089)	mem 8931MB
[2022-04-06 02:39:16 large] (main.py 226): INFO Train: [61/300][400/2502]	eta 0:21:52 lr 0.000451	time 0.6177 (0.6244)	loss 3.8379 (3.6135)	grad_norm 2.8821 (2.5134)	mem 8931MB
[2022-04-06 02:40:14 large] (main.py 226): INFO Train: [61/300][500/2502]	eta 0:20:32 lr 0.000451	time 0.5282 (0.6154)	loss 4.0140 (3.6208)	grad_norm 2.5595 (2.5101)	mem 8931MB
[2022-04-06 02:41:15 large] (main.py 226): INFO Train: [61/300][600/2502]	eta 0:19:29 lr 0.000451	time 0.6282 (0.6147)	loss 2.9743 (3.6210)	grad_norm 2.3850 (2.5186)	mem 8931MB
[2022-04-06 02:42:17 large] (main.py 226): INFO Train: [61/300][700/2502]	eta 0:18:30 lr 0.000451	time 0.6607 (0.6161)	loss 3.7836 (3.6451)	grad_norm 2.2205 (2.5361)	mem 8931MB
[2022-04-06 02:43:19 large] (main.py 226): INFO Train: [61/300][800/2502]	eta 0:17:29 lr 0.000451	time 0.6739 (0.6167)	loss 3.6328 (3.6583)	grad_norm 1.9815 (2.5346)	mem 8931MB
[2022-04-06 02:44:22 large] (main.py 226): INFO Train: [61/300][900/2502]	eta 0:16:30 lr 0.000451	time 0.5082 (0.6181)	loss 3.8259 (3.6659)	grad_norm 2.6134 (2.5289)	mem 8931MB
[2022-04-06 02:45:25 large] (main.py 226): INFO Train: [61/300][1000/2502]	eta 0:15:30 lr 0.000451	time 0.6204 (0.6192)	loss 3.9580 (3.6618)	grad_norm 2.5727 (2.5268)	mem 8931MB
[2022-04-06 02:46:26 large] (main.py 226): INFO Train: [61/300][1100/2502]	eta 0:14:26 lr 0.000451	time 0.5955 (0.6181)	loss 3.7001 (3.6587)	grad_norm 2.3027 (2.5296)	mem 8931MB
[2022-04-06 02:47:28 large] (main.py 226): INFO Train: [61/300][1200/2502]	eta 0:13:25 lr 0.000450	time 0.5287 (0.6183)	loss 4.2474 (3.6602)	grad_norm 3.4044 (2.5233)	mem 8931MB
[2022-04-06 02:48:30 large] (main.py 226): INFO Train: [61/300][1300/2502]	eta 0:12:23 lr 0.000450	time 0.5970 (0.6183)	loss 3.8198 (3.6600)	grad_norm 2.2126 (2.5269)	mem 8931MB
[2022-04-06 02:49:31 large] (main.py 226): INFO Train: [61/300][1400/2502]	eta 0:11:21 lr 0.000450	time 0.6339 (0.6182)	loss 3.9157 (3.6604)	grad_norm 2.6091 (inf)	mem 8931MB
[2022-04-06 02:50:33 large] (main.py 226): INFO Train: [61/300][1500/2502]	eta 0:10:19 lr 0.000450	time 0.6054 (0.6182)	loss 4.0431 (3.6641)	grad_norm 2.2719 (inf)	mem 8931MB
[2022-04-06 02:51:34 large] (main.py 226): INFO Train: [61/300][1600/2502]	eta 0:09:17 lr 0.000450	time 0.6528 (0.6177)	loss 2.5543 (3.6656)	grad_norm 2.3782 (inf)	mem 8931MB
[2022-04-06 02:52:36 large] (main.py 226): INFO Train: [61/300][1700/2502]	eta 0:08:15 lr 0.000450	time 0.6034 (0.6178)	loss 3.5477 (3.6647)	grad_norm 4.0188 (inf)	mem 8931MB
[2022-04-06 02:53:39 large] (main.py 226): INFO Train: [61/300][1800/2502]	eta 0:07:13 lr 0.000450	time 0.6251 (0.6182)	loss 4.0381 (3.6661)	grad_norm 2.2062 (inf)	mem 8931MB
[2022-04-06 02:54:41 large] (main.py 226): INFO Train: [61/300][1900/2502]	eta 0:06:12 lr 0.000450	time 0.5709 (0.6184)	loss 3.6887 (3.6724)	grad_norm 2.4130 (inf)	mem 8931MB
[2022-04-06 02:55:41 large] (main.py 226): INFO Train: [61/300][2000/2502]	eta 0:05:10 lr 0.000450	time 0.7010 (0.6178)	loss 4.1258 (3.6713)	grad_norm 2.7211 (inf)	mem 8931MB
[2022-04-06 02:56:43 large] (main.py 226): INFO Train: [61/300][2100/2502]	eta 0:04:08 lr 0.000450	time 1.4772 (0.6178)	loss 3.5878 (3.6726)	grad_norm 3.1955 (inf)	mem 8931MB
[2022-04-06 02:57:44 large] (main.py 226): INFO Train: [61/300][2200/2502]	eta 0:03:06 lr 0.000450	time 0.6333 (0.6172)	loss 4.3201 (3.6713)	grad_norm 2.9457 (inf)	mem 8931MB
[2022-04-06 02:58:45 large] (main.py 226): INFO Train: [61/300][2300/2502]	eta 0:02:04 lr 0.000450	time 0.5811 (0.6171)	loss 3.9635 (3.6741)	grad_norm 2.1617 (inf)	mem 8931MB
[2022-04-06 02:59:46 large] (main.py 226): INFO Train: [61/300][2400/2502]	eta 0:01:02 lr 0.000450	time 0.5157 (0.6169)	loss 3.0902 (3.6746)	grad_norm 2.4005 (inf)	mem 8931MB
[2022-04-06 03:00:48 large] (main.py 226): INFO Train: [61/300][2500/2502]	eta 0:00:01 lr 0.000450	time 0.6006 (0.6167)	loss 2.4122 (3.6735)	grad_norm 2.5621 (inf)	mem 8931MB
[2022-04-06 03:00:49 large] (main.py 233): INFO EPOCH 61 training takes 0:25:43
[2022-04-06 03:00:55 large] (main.py 273): INFO Test: [0/98]	Time 6.347 (6.347)	Loss 1.1932 (1.1932)	Acc@1 74.414 (74.414)	Acc@5 94.141 (94.141)	Mem 8931MB
[2022-04-06 03:01:21 large] (main.py 279): INFO  * Acc@1 73.106 Acc@5 91.674
[2022-04-06 03:01:21 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 73.1%
[2022-04-06 03:01:21 large] (utils.py 57): INFO output/large/default/ckpt_epoch_61.pth saving......
[2022-04-06 03:01:22 large] (utils.py 59): INFO output/large/default/ckpt_epoch_61.pth saved !!!
[2022-04-06 03:01:22 large] (main.py 148): INFO Max accuracy: 73.11%
[2022-04-06 03:01:29 large] (main.py 226): INFO Train: [62/300][0/2502]	eta 5:11:16 lr 0.000450	time 7.4646 (7.4646)	loss 3.8441 (3.8441)	grad_norm 3.1372 (3.1372)	mem 8931MB
[2022-04-06 03:02:22 large] (main.py 226): INFO Train: [62/300][100/2502]	eta 0:23:48 lr 0.000450	time 0.5599 (0.5947)	loss 4.1740 (3.5986)	grad_norm 2.5722 (2.5024)	mem 8931MB
[2022-04-06 03:03:23 large] (main.py 226): INFO Train: [62/300][200/2502]	eta 0:23:11 lr 0.000450	time 0.5791 (0.6045)	loss 4.5451 (3.6398)	grad_norm 3.0097 (2.5257)	mem 8931MB
[2022-04-06 03:04:27 large] (main.py 226): INFO Train: [62/300][300/2502]	eta 0:22:32 lr 0.000449	time 0.6852 (0.6142)	loss 3.1533 (3.6616)	grad_norm 2.4321 (2.5296)	mem 8931MB
[2022-04-06 03:05:28 large] (main.py 226): INFO Train: [62/300][400/2502]	eta 0:21:31 lr 0.000449	time 0.6128 (0.6144)	loss 3.8876 (3.6843)	grad_norm 2.0587 (2.5549)	mem 8931MB
[2022-04-06 03:06:30 large] (main.py 226): INFO Train: [62/300][500/2502]	eta 0:20:32 lr 0.000449	time 0.5641 (0.6154)	loss 3.4881 (3.6911)	grad_norm 2.0626 (2.5333)	mem 8931MB
[2022-04-06 03:07:32 large] (main.py 226): INFO Train: [62/300][600/2502]	eta 0:19:32 lr 0.000449	time 0.6674 (0.6162)	loss 3.8369 (3.6902)	grad_norm 2.3541 (2.5357)	mem 8931MB
[2022-04-06 03:08:34 large] (main.py 226): INFO Train: [62/300][700/2502]	eta 0:18:30 lr 0.000449	time 0.6536 (0.6163)	loss 3.9295 (3.6866)	grad_norm 1.8870 (2.5354)	mem 8931MB
[2022-04-06 03:09:35 large] (main.py 226): INFO Train: [62/300][800/2502]	eta 0:17:27 lr 0.000449	time 0.6507 (0.6154)	loss 4.3452 (3.6932)	grad_norm 2.1113 (2.5398)	mem 8931MB
[2022-04-06 03:10:36 large] (main.py 226): INFO Train: [62/300][900/2502]	eta 0:16:25 lr 0.000449	time 0.5883 (0.6150)	loss 3.9963 (3.6873)	grad_norm 2.5333 (2.5428)	mem 8931MB
[2022-04-06 03:11:37 large] (main.py 226): INFO Train: [62/300][1000/2502]	eta 0:15:23 lr 0.000449	time 0.5918 (0.6146)	loss 3.9373 (3.6877)	grad_norm 2.4277 (2.5434)	mem 8931MB
[2022-04-06 03:12:39 large] (main.py 226): INFO Train: [62/300][1100/2502]	eta 0:14:21 lr 0.000449	time 0.6599 (0.6146)	loss 3.6635 (3.6899)	grad_norm 2.3790 (2.5374)	mem 8931MB
[2022-04-06 03:13:39 large] (main.py 226): INFO Train: [62/300][1200/2502]	eta 0:13:19 lr 0.000449	time 0.6210 (0.6137)	loss 3.1090 (3.6929)	grad_norm 2.0236 (2.5440)	mem 8931MB
[2022-04-06 03:14:40 large] (main.py 226): INFO Train: [62/300][1300/2502]	eta 0:12:16 lr 0.000449	time 0.5225 (0.6131)	loss 3.7720 (3.6879)	grad_norm 2.8307 (2.5327)	mem 8931MB
[2022-04-06 03:15:34 large] (main.py 226): INFO Train: [62/300][1400/2502]	eta 0:11:10 lr 0.000449	time 0.5220 (0.6084)	loss 4.2564 (3.6929)	grad_norm 1.9702 (inf)	mem 8931MB
[2022-04-06 03:16:35 large] (main.py 226): INFO Train: [62/300][1500/2502]	eta 0:10:09 lr 0.000449	time 0.6537 (0.6083)	loss 4.2874 (3.6915)	grad_norm 2.6868 (inf)	mem 8931MB
[2022-04-06 03:17:37 large] (main.py 226): INFO Train: [62/300][1600/2502]	eta 0:09:09 lr 0.000449	time 0.6022 (0.6089)	loss 4.6193 (3.6945)	grad_norm 2.4251 (inf)	mem 8931MB
[2022-04-06 03:18:38 large] (main.py 226): INFO Train: [62/300][1700/2502]	eta 0:08:08 lr 0.000449	time 0.6946 (0.6091)	loss 4.5522 (3.6899)	grad_norm 2.2755 (inf)	mem 8931MB
[2022-04-06 03:19:40 large] (main.py 226): INFO Train: [62/300][1800/2502]	eta 0:07:07 lr 0.000449	time 0.5772 (0.6096)	loss 4.0058 (3.6861)	grad_norm 2.3811 (inf)	mem 8931MB
[2022-04-06 03:20:41 large] (main.py 226): INFO Train: [62/300][1900/2502]	eta 0:06:07 lr 0.000448	time 0.5995 (0.6097)	loss 2.8901 (3.6829)	grad_norm 2.0631 (inf)	mem 8931MB
[2022-04-06 03:21:43 large] (main.py 226): INFO Train: [62/300][2000/2502]	eta 0:05:06 lr 0.000448	time 0.5901 (0.6102)	loss 2.6967 (3.6813)	grad_norm 3.0853 (inf)	mem 8931MB
[2022-04-06 03:22:44 large] (main.py 226): INFO Train: [62/300][2100/2502]	eta 0:04:05 lr 0.000448	time 0.5792 (0.6103)	loss 4.4470 (3.6786)	grad_norm 2.4185 (inf)	mem 8931MB
[2022-04-06 03:23:45 large] (main.py 226): INFO Train: [62/300][2200/2502]	eta 0:03:04 lr 0.000448	time 0.5431 (0.6104)	loss 4.1817 (3.6809)	grad_norm 2.6299 (inf)	mem 8931MB
[2022-04-06 03:24:48 large] (main.py 226): INFO Train: [62/300][2300/2502]	eta 0:02:03 lr 0.000448	time 0.7008 (0.6109)	loss 4.1575 (3.6804)	grad_norm 2.1676 (inf)	mem 8931MB
[2022-04-06 03:25:48 large] (main.py 226): INFO Train: [62/300][2400/2502]	eta 0:01:02 lr 0.000448	time 0.6207 (0.6107)	loss 3.6516 (3.6816)	grad_norm 3.4039 (inf)	mem 8931MB
[2022-04-06 03:26:49 large] (main.py 226): INFO Train: [62/300][2500/2502]	eta 0:00:01 lr 0.000448	time 0.5967 (0.6107)	loss 3.9253 (3.6855)	grad_norm 2.1053 (inf)	mem 8931MB
[2022-04-06 03:26:50 large] (main.py 233): INFO EPOCH 62 training takes 0:25:28
[2022-04-06 03:26:57 large] (main.py 273): INFO Test: [0/98]	Time 6.643 (6.643)	Loss 1.2329 (1.2329)	Acc@1 73.242 (73.242)	Acc@5 91.797 (91.797)	Mem 8931MB
[2022-04-06 03:27:23 large] (main.py 279): INFO  * Acc@1 73.212 Acc@5 91.766
[2022-04-06 03:27:23 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 73.2%
[2022-04-06 03:27:23 large] (utils.py 57): INFO output/large/default/ckpt_epoch_62.pth saving......
[2022-04-06 03:27:24 large] (utils.py 59): INFO output/large/default/ckpt_epoch_62.pth saved !!!
[2022-04-06 03:27:24 large] (main.py 148): INFO Max accuracy: 73.21%
[2022-04-06 03:27:31 large] (main.py 226): INFO Train: [63/300][0/2502]	eta 5:14:00 lr 0.000448	time 7.5302 (7.5302)	loss 4.1815 (4.1815)	grad_norm 2.6538 (2.6538)	mem 8931MB
[2022-04-06 03:28:26 large] (main.py 226): INFO Train: [63/300][100/2502]	eta 0:24:36 lr 0.000448	time 0.5875 (0.6147)	loss 4.0924 (3.6904)	grad_norm 2.6524 (2.5649)	mem 8931MB
[2022-04-06 03:29:27 large] (main.py 226): INFO Train: [63/300][200/2502]	eta 0:23:32 lr 0.000448	time 0.5341 (0.6135)	loss 4.2906 (3.6751)	grad_norm 2.1632 (2.5225)	mem 8931MB
[2022-04-06 03:30:30 large] (main.py 226): INFO Train: [63/300][300/2502]	eta 0:22:42 lr 0.000448	time 0.6261 (0.6187)	loss 2.7345 (3.6928)	grad_norm 2.6940 (2.5329)	mem 8931MB
[2022-04-06 03:31:32 large] (main.py 226): INFO Train: [63/300][400/2502]	eta 0:21:40 lr 0.000448	time 0.6231 (0.6188)	loss 3.6554 (3.6836)	grad_norm 1.7540 (2.5331)	mem 8931MB
[2022-04-06 03:32:33 large] (main.py 226): INFO Train: [63/300][500/2502]	eta 0:20:36 lr 0.000448	time 0.6821 (0.6174)	loss 3.1538 (3.6739)	grad_norm 2.0044 (2.5555)	mem 8931MB
[2022-04-06 03:33:34 large] (main.py 226): INFO Train: [63/300][600/2502]	eta 0:19:32 lr 0.000448	time 0.6314 (0.6165)	loss 3.2216 (3.6741)	grad_norm 3.1730 (2.5565)	mem 8931MB
[2022-04-06 03:34:36 large] (main.py 226): INFO Train: [63/300][700/2502]	eta 0:18:30 lr 0.000448	time 0.5844 (0.6162)	loss 3.8027 (3.6798)	grad_norm 2.0529 (2.5578)	mem 8931MB
[2022-04-06 03:35:37 large] (main.py 226): INFO Train: [63/300][800/2502]	eta 0:17:27 lr 0.000448	time 0.6184 (0.6157)	loss 3.9452 (3.6707)	grad_norm 2.7042 (2.5595)	mem 8931MB
[2022-04-06 03:36:38 large] (main.py 226): INFO Train: [63/300][900/2502]	eta 0:16:26 lr 0.000447	time 0.5943 (0.6157)	loss 3.9283 (3.6744)	grad_norm 2.2084 (nan)	mem 8931MB
[2022-04-06 03:37:34 large] (main.py 226): INFO Train: [63/300][1000/2502]	eta 0:15:15 lr 0.000447	time 0.5520 (0.6096)	loss 4.1948 (3.6688)	grad_norm 2.5872 (nan)	mem 8931MB
[2022-04-06 03:38:35 large] (main.py 226): INFO Train: [63/300][1100/2502]	eta 0:14:14 lr 0.000447	time 0.6099 (0.6094)	loss 2.9733 (3.6683)	grad_norm 2.4479 (nan)	mem 8931MB
[2022-04-06 03:39:36 large] (main.py 226): INFO Train: [63/300][1200/2502]	eta 0:13:14 lr 0.000447	time 0.6119 (0.6098)	loss 4.0627 (3.6643)	grad_norm 2.3088 (nan)	mem 8931MB
[2022-04-06 03:40:37 large] (main.py 226): INFO Train: [63/300][1300/2502]	eta 0:12:13 lr 0.000447	time 0.5343 (0.6099)	loss 4.0047 (3.6710)	grad_norm 4.0459 (nan)	mem 8931MB
[2022-04-06 03:41:38 large] (main.py 226): INFO Train: [63/300][1400/2502]	eta 0:11:12 lr 0.000447	time 0.5984 (0.6099)	loss 4.3343 (3.6664)	grad_norm 2.4878 (nan)	mem 8931MB
[2022-04-06 03:42:38 large] (main.py 226): INFO Train: [63/300][1500/2502]	eta 0:10:10 lr 0.000447	time 0.6126 (0.6091)	loss 3.9593 (3.6724)	grad_norm 2.8814 (nan)	mem 8931MB
[2022-04-06 03:43:38 large] (main.py 226): INFO Train: [63/300][1600/2502]	eta 0:09:09 lr 0.000447	time 0.5337 (0.6088)	loss 3.6677 (3.6693)	grad_norm 2.7760 (nan)	mem 8931MB
[2022-04-06 03:44:39 large] (main.py 226): INFO Train: [63/300][1700/2502]	eta 0:08:08 lr 0.000447	time 0.5933 (0.6089)	loss 4.5681 (3.6691)	grad_norm 2.9906 (nan)	mem 8931MB
[2022-04-06 03:45:41 large] (main.py 226): INFO Train: [63/300][1800/2502]	eta 0:07:07 lr 0.000447	time 0.5758 (0.6092)	loss 3.8088 (3.6648)	grad_norm 2.1700 (nan)	mem 8931MB
[2022-04-06 03:46:43 large] (main.py 226): INFO Train: [63/300][1900/2502]	eta 0:06:07 lr 0.000447	time 0.4845 (0.6097)	loss 3.9436 (3.6669)	grad_norm 2.1815 (nan)	mem 8931MB
[2022-04-06 03:47:44 large] (main.py 226): INFO Train: [63/300][2000/2502]	eta 0:05:06 lr 0.000447	time 0.6009 (0.6100)	loss 4.0585 (3.6696)	grad_norm 3.7223 (nan)	mem 8931MB
[2022-04-06 03:48:45 large] (main.py 226): INFO Train: [63/300][2100/2502]	eta 0:04:05 lr 0.000447	time 0.6656 (0.6099)	loss 2.8579 (3.6644)	grad_norm 2.8368 (nan)	mem 8931MB
[2022-04-06 03:49:46 large] (main.py 226): INFO Train: [63/300][2200/2502]	eta 0:03:04 lr 0.000447	time 0.5131 (0.6101)	loss 4.0468 (3.6630)	grad_norm 2.4399 (nan)	mem 8931MB
[2022-04-06 03:50:46 large] (main.py 226): INFO Train: [63/300][2300/2502]	eta 0:02:03 lr 0.000447	time 0.6936 (0.6095)	loss 3.5025 (3.6634)	grad_norm 2.8913 (nan)	mem 8931MB
[2022-04-06 03:51:47 large] (main.py 226): INFO Train: [63/300][2400/2502]	eta 0:01:02 lr 0.000447	time 0.6502 (0.6095)	loss 2.7578 (3.6607)	grad_norm 1.8603 (nan)	mem 8931MB
[2022-04-06 03:52:49 large] (main.py 226): INFO Train: [63/300][2500/2502]	eta 0:00:01 lr 0.000446	time 0.6141 (0.6097)	loss 3.4059 (3.6611)	grad_norm 3.0264 (nan)	mem 8931MB
[2022-04-06 03:52:50 large] (main.py 233): INFO EPOCH 63 training takes 0:25:25
[2022-04-06 03:52:55 large] (main.py 273): INFO Test: [0/98]	Time 5.763 (5.763)	Loss 1.1950 (1.1950)	Acc@1 76.758 (76.758)	Acc@5 91.992 (91.992)	Mem 8931MB
[2022-04-06 03:53:22 large] (main.py 279): INFO  * Acc@1 73.394 Acc@5 91.602
[2022-04-06 03:53:22 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 73.4%
[2022-04-06 03:53:22 large] (utils.py 57): INFO output/large/default/ckpt_epoch_63.pth saving......
[2022-04-06 03:53:22 large] (utils.py 59): INFO output/large/default/ckpt_epoch_63.pth saved !!!
[2022-04-06 03:53:22 large] (main.py 148): INFO Max accuracy: 73.39%
[2022-04-06 03:53:31 large] (main.py 226): INFO Train: [64/300][0/2502]	eta 5:40:02 lr 0.000446	time 8.1544 (8.1544)	loss 3.6447 (3.6447)	grad_norm 2.2536 (2.2536)	mem 8931MB
[2022-04-06 03:54:22 large] (main.py 226): INFO Train: [64/300][100/2502]	eta 0:23:25 lr 0.000446	time 0.5301 (0.5850)	loss 4.3357 (3.6963)	grad_norm 2.2315 (2.5277)	mem 8931MB
[2022-04-06 03:55:23 large] (main.py 226): INFO Train: [64/300][200/2502]	eta 0:23:05 lr 0.000446	time 0.5879 (0.6018)	loss 4.3287 (3.6923)	grad_norm 1.9335 (2.5813)	mem 8931MB
[2022-04-06 03:56:26 large] (main.py 226): INFO Train: [64/300][300/2502]	eta 0:22:19 lr 0.000446	time 0.5291 (0.6084)	loss 3.6539 (3.6627)	grad_norm 2.8744 (2.5785)	mem 8931MB
[2022-04-06 03:57:28 large] (main.py 226): INFO Train: [64/300][400/2502]	eta 0:21:27 lr 0.000446	time 0.6028 (0.6127)	loss 3.9194 (3.6700)	grad_norm 2.5264 (2.5648)	mem 8931MB
[2022-04-06 03:58:30 large] (main.py 226): INFO Train: [64/300][500/2502]	eta 0:20:30 lr 0.000446	time 0.6873 (0.6147)	loss 4.1411 (3.6687)	grad_norm 2.8156 (2.5584)	mem 8931MB
[2022-04-06 03:59:33 large] (main.py 226): INFO Train: [64/300][600/2502]	eta 0:19:31 lr 0.000446	time 0.6411 (0.6161)	loss 3.1008 (3.6627)	grad_norm 2.0597 (2.5564)	mem 8931MB
[2022-04-06 04:00:35 large] (main.py 226): INFO Train: [64/300][700/2502]	eta 0:18:32 lr 0.000446	time 0.5484 (0.6172)	loss 3.7460 (3.6617)	grad_norm 2.6005 (2.5586)	mem 8931MB
[2022-04-06 04:01:36 large] (main.py 226): INFO Train: [64/300][800/2502]	eta 0:17:29 lr 0.000446	time 0.7231 (0.6166)	loss 3.3020 (3.6580)	grad_norm 2.1204 (2.5498)	mem 8931MB
[2022-04-06 04:02:37 large] (main.py 226): INFO Train: [64/300][900/2502]	eta 0:16:26 lr 0.000446	time 0.5861 (0.6157)	loss 3.9369 (3.6529)	grad_norm 1.9508 (2.5498)	mem 8931MB
[2022-04-06 04:03:38 large] (main.py 226): INFO Train: [64/300][1000/2502]	eta 0:15:23 lr 0.000446	time 0.5662 (0.6151)	loss 3.9512 (3.6594)	grad_norm 1.9465 (2.5597)	mem 8931MB
[2022-04-06 04:04:40 large] (main.py 226): INFO Train: [64/300][1100/2502]	eta 0:14:22 lr 0.000446	time 0.5938 (0.6150)	loss 3.9276 (3.6599)	grad_norm 2.2438 (2.5564)	mem 8931MB
[2022-04-06 04:05:41 large] (main.py 226): INFO Train: [64/300][1200/2502]	eta 0:13:20 lr 0.000446	time 0.4828 (0.6146)	loss 3.7321 (3.6595)	grad_norm 3.5502 (2.5529)	mem 8931MB
[2022-04-06 04:06:42 large] (main.py 226): INFO Train: [64/300][1300/2502]	eta 0:12:18 lr 0.000446	time 0.6491 (0.6147)	loss 2.1977 (3.6582)	grad_norm 2.0313 (2.5615)	mem 8931MB
[2022-04-06 04:07:42 large] (main.py 226): INFO Train: [64/300][1400/2502]	eta 0:11:16 lr 0.000446	time 0.6549 (0.6138)	loss 3.3636 (3.6559)	grad_norm 2.5835 (2.5534)	mem 8931MB
[2022-04-06 04:08:40 large] (main.py 226): INFO Train: [64/300][1500/2502]	eta 0:10:12 lr 0.000445	time 0.4702 (0.6113)	loss 3.9493 (3.6588)	grad_norm 2.0443 (2.5582)	mem 8931MB
[2022-04-06 04:09:38 large] (main.py 226): INFO Train: [64/300][1600/2502]	eta 0:09:09 lr 0.000445	time 0.6109 (0.6091)	loss 4.1498 (3.6618)	grad_norm 2.9759 (2.5619)	mem 8931MB
[2022-04-06 04:10:39 large] (main.py 226): INFO Train: [64/300][1700/2502]	eta 0:08:08 lr 0.000445	time 0.6123 (0.6094)	loss 3.7838 (3.6648)	grad_norm 2.6110 (2.5639)	mem 8931MB
[2022-04-06 04:11:39 large] (main.py 226): INFO Train: [64/300][1800/2502]	eta 0:07:07 lr 0.000445	time 0.5890 (0.6091)	loss 3.8891 (3.6637)	grad_norm 2.0610 (2.5567)	mem 8931MB
[2022-04-06 04:12:40 large] (main.py 226): INFO Train: [64/300][1900/2502]	eta 0:06:06 lr 0.000445	time 0.6428 (0.6089)	loss 2.6090 (3.6659)	grad_norm 2.5859 (2.5550)	mem 8931MB
[2022-04-06 04:13:40 large] (main.py 226): INFO Train: [64/300][2000/2502]	eta 0:05:05 lr 0.000445	time 0.6065 (0.6086)	loss 3.7136 (3.6622)	grad_norm 3.0454 (2.5580)	mem 8931MB
[2022-04-06 04:14:41 large] (main.py 226): INFO Train: [64/300][2100/2502]	eta 0:04:04 lr 0.000445	time 0.5564 (0.6088)	loss 2.8939 (3.6646)	grad_norm 2.4023 (2.5553)	mem 8931MB
[2022-04-06 04:15:42 large] (main.py 226): INFO Train: [64/300][2200/2502]	eta 0:03:03 lr 0.000445	time 0.4881 (0.6088)	loss 4.4335 (3.6702)	grad_norm 1.9987 (2.5551)	mem 8931MB
[2022-04-06 04:16:43 large] (main.py 226): INFO Train: [64/300][2300/2502]	eta 0:02:02 lr 0.000445	time 0.5755 (0.6088)	loss 3.4548 (3.6736)	grad_norm 2.1214 (2.5553)	mem 8931MB
[2022-04-06 04:17:44 large] (main.py 226): INFO Train: [64/300][2400/2502]	eta 0:01:02 lr 0.000445	time 0.6185 (0.6089)	loss 3.4553 (3.6714)	grad_norm 3.3400 (2.5536)	mem 8931MB
[2022-04-06 04:18:45 large] (main.py 226): INFO Train: [64/300][2500/2502]	eta 0:00:01 lr 0.000445	time 0.5745 (0.6088)	loss 4.2016 (3.6729)	grad_norm 2.4754 (2.5538)	mem 8931MB
[2022-04-06 04:18:46 large] (main.py 233): INFO EPOCH 64 training takes 0:25:23
[2022-04-06 04:18:51 large] (main.py 273): INFO Test: [0/98]	Time 5.325 (5.325)	Loss 1.3079 (1.3079)	Acc@1 71.094 (71.094)	Acc@5 90.430 (90.430)	Mem 8931MB
[2022-04-06 04:19:18 large] (main.py 279): INFO  * Acc@1 73.418 Acc@5 91.912
[2022-04-06 04:19:18 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 73.4%
[2022-04-06 04:19:18 large] (utils.py 57): INFO output/large/default/ckpt_epoch_64.pth saving......
[2022-04-06 04:19:19 large] (utils.py 59): INFO output/large/default/ckpt_epoch_64.pth saved !!!
[2022-04-06 04:19:19 large] (main.py 148): INFO Max accuracy: 73.42%
[2022-04-06 04:19:27 large] (main.py 226): INFO Train: [65/300][0/2502]	eta 5:46:18 lr 0.000445	time 8.3046 (8.3046)	loss 4.0275 (4.0275)	grad_norm 2.1604 (2.1604)	mem 8931MB
[2022-04-06 04:20:16 large] (main.py 226): INFO Train: [65/300][100/2502]	eta 0:22:38 lr 0.000445	time 0.4810 (0.5657)	loss 2.9274 (3.6953)	grad_norm 2.1430 (2.6248)	mem 8931MB
[2022-04-06 04:21:14 large] (main.py 226): INFO Train: [65/300][200/2502]	eta 0:21:52 lr 0.000445	time 0.7611 (0.5702)	loss 4.1419 (3.7156)	grad_norm 2.8333 (2.5625)	mem 8931MB
[2022-04-06 04:22:16 large] (main.py 226): INFO Train: [65/300][300/2502]	eta 0:21:31 lr 0.000445	time 0.6332 (0.5864)	loss 4.4241 (3.7177)	grad_norm 3.0266 (2.5707)	mem 8931MB
[2022-04-06 04:23:18 large] (main.py 226): INFO Train: [65/300][400/2502]	eta 0:20:50 lr 0.000445	time 0.6559 (0.5950)	loss 3.9297 (3.6982)	grad_norm 2.8081 (2.5646)	mem 8931MB
[2022-04-06 04:24:20 large] (main.py 226): INFO Train: [65/300][500/2502]	eta 0:20:00 lr 0.000445	time 0.5661 (0.5996)	loss 4.3973 (3.6990)	grad_norm 2.6118 (2.5740)	mem 8931MB
[2022-04-06 04:25:21 large] (main.py 226): INFO Train: [65/300][600/2502]	eta 0:19:06 lr 0.000444	time 0.5460 (0.6026)	loss 3.6014 (3.7031)	grad_norm 2.2018 (2.5694)	mem 8931MB
[2022-04-06 04:26:22 large] (main.py 226): INFO Train: [65/300][700/2502]	eta 0:18:07 lr 0.000444	time 0.5999 (0.6032)	loss 3.8464 (3.6915)	grad_norm 2.9395 (2.5760)	mem 8931MB
[2022-04-06 04:27:23 large] (main.py 226): INFO Train: [65/300][800/2502]	eta 0:17:07 lr 0.000444	time 0.5510 (0.6037)	loss 4.3948 (3.6950)	grad_norm 2.2981 (2.5708)	mem 8931MB
[2022-04-06 04:28:24 large] (main.py 226): INFO Train: [65/300][900/2502]	eta 0:16:09 lr 0.000444	time 0.6720 (0.6051)	loss 3.9296 (3.6961)	grad_norm 2.1580 (2.5739)	mem 8931MB
[2022-04-06 04:29:24 large] (main.py 226): INFO Train: [65/300][1000/2502]	eta 0:15:07 lr 0.000444	time 0.6274 (0.6042)	loss 3.7336 (3.7038)	grad_norm 2.4071 (2.5672)	mem 8931MB
[2022-04-06 04:30:25 large] (main.py 226): INFO Train: [65/300][1100/2502]	eta 0:14:07 lr 0.000444	time 0.6184 (0.6047)	loss 3.8663 (3.6982)	grad_norm 1.8710 (2.5627)	mem 8931MB
[2022-04-06 04:31:26 large] (main.py 226): INFO Train: [65/300][1200/2502]	eta 0:13:07 lr 0.000444	time 0.6511 (0.6051)	loss 4.5952 (3.6992)	grad_norm 1.9772 (2.5668)	mem 8931MB
[2022-04-06 04:32:27 large] (main.py 226): INFO Train: [65/300][1300/2502]	eta 0:12:07 lr 0.000444	time 0.5358 (0.6055)	loss 4.3909 (3.7025)	grad_norm 2.6214 (nan)	mem 8931MB
[2022-04-06 04:33:28 large] (main.py 226): INFO Train: [65/300][1400/2502]	eta 0:11:07 lr 0.000444	time 0.5798 (0.6057)	loss 3.9761 (3.6983)	grad_norm 3.0416 (nan)	mem 8931MB
[2022-04-06 04:34:28 large] (main.py 226): INFO Train: [65/300][1500/2502]	eta 0:10:06 lr 0.000444	time 0.5607 (0.6055)	loss 3.5967 (3.6917)	grad_norm 2.2319 (nan)	mem 8931MB
[2022-04-06 04:35:30 large] (main.py 226): INFO Train: [65/300][1600/2502]	eta 0:09:06 lr 0.000444	time 1.4494 (0.6062)	loss 2.8055 (3.6905)	grad_norm 2.0010 (nan)	mem 8931MB
[2022-04-06 04:36:30 large] (main.py 226): INFO Train: [65/300][1700/2502]	eta 0:08:05 lr 0.000444	time 0.6509 (0.6058)	loss 3.2630 (3.6854)	grad_norm 2.5156 (nan)	mem 8931MB
[2022-04-06 04:37:31 large] (main.py 226): INFO Train: [65/300][1800/2502]	eta 0:07:05 lr 0.000444	time 0.6258 (0.6065)	loss 3.1350 (3.6807)	grad_norm 2.2502 (nan)	mem 8931MB
[2022-04-06 04:38:32 large] (main.py 226): INFO Train: [65/300][1900/2502]	eta 0:06:05 lr 0.000444	time 0.6313 (0.6067)	loss 4.4751 (3.6807)	grad_norm 2.6161 (nan)	mem 8931MB
[2022-04-06 04:39:33 large] (main.py 226): INFO Train: [65/300][2000/2502]	eta 0:05:04 lr 0.000444	time 0.5880 (0.6068)	loss 4.0560 (3.6817)	grad_norm 2.7557 (nan)	mem 8931MB
[2022-04-06 04:40:34 large] (main.py 226): INFO Train: [65/300][2100/2502]	eta 0:04:03 lr 0.000443	time 0.5642 (0.6068)	loss 3.6155 (3.6802)	grad_norm 2.1914 (nan)	mem 8931MB
[2022-04-06 04:41:35 large] (main.py 226): INFO Train: [65/300][2200/2502]	eta 0:03:03 lr 0.000443	time 0.5669 (0.6070)	loss 3.4842 (3.6768)	grad_norm 2.2373 (nan)	mem 8931MB
[2022-04-06 04:42:35 large] (main.py 226): INFO Train: [65/300][2300/2502]	eta 0:02:02 lr 0.000443	time 0.6514 (0.6068)	loss 4.4993 (3.6771)	grad_norm 2.3485 (nan)	mem 8931MB
[2022-04-06 04:43:35 large] (main.py 226): INFO Train: [65/300][2400/2502]	eta 0:01:01 lr 0.000443	time 0.6704 (0.6065)	loss 2.8660 (3.6776)	grad_norm 2.0552 (nan)	mem 8931MB
[2022-04-06 04:44:36 large] (main.py 226): INFO Train: [65/300][2500/2502]	eta 0:00:01 lr 0.000443	time 0.6032 (0.6065)	loss 4.5377 (3.6808)	grad_norm 3.4224 (nan)	mem 8931MB
[2022-04-06 04:44:37 large] (main.py 233): INFO EPOCH 65 training takes 0:25:17
[2022-04-06 04:44:43 large] (main.py 273): INFO Test: [0/98]	Time 6.168 (6.168)	Loss 1.3447 (1.3447)	Acc@1 71.484 (71.484)	Acc@5 89.844 (89.844)	Mem 8931MB
[2022-04-06 04:45:09 large] (main.py 279): INFO  * Acc@1 72.734 Acc@5 91.662
[2022-04-06 04:45:09 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.7%
[2022-04-06 04:45:09 large] (main.py 148): INFO Max accuracy: 73.42%
[2022-04-06 04:45:15 large] (main.py 226): INFO Train: [66/300][0/2502]	eta 4:26:46 lr 0.000443	time 6.3976 (6.3976)	loss 4.2289 (4.2289)	grad_norm 3.1438 (3.1438)	mem 8931MB
[2022-04-06 04:46:06 large] (main.py 226): INFO Train: [66/300][100/2502]	eta 0:22:33 lr 0.000443	time 0.5034 (0.5633)	loss 2.8076 (3.5521)	grad_norm 2.2655 (2.5908)	mem 8931MB
[2022-04-06 04:47:04 large] (main.py 226): INFO Train: [66/300][200/2502]	eta 0:21:57 lr 0.000443	time 0.5919 (0.5725)	loss 2.7640 (3.6054)	grad_norm 2.2495 (2.5889)	mem 8931MB
[2022-04-06 04:48:06 large] (main.py 226): INFO Train: [66/300][300/2502]	eta 0:21:31 lr 0.000443	time 0.6085 (0.5866)	loss 3.2499 (3.6169)	grad_norm 2.3392 (2.6102)	mem 8931MB
[2022-04-06 04:49:07 large] (main.py 226): INFO Train: [66/300][400/2502]	eta 0:20:48 lr 0.000443	time 0.5948 (0.5940)	loss 4.4988 (3.6455)	grad_norm 2.4269 (2.6082)	mem 8931MB
[2022-04-06 04:50:08 large] (main.py 226): INFO Train: [66/300][500/2502]	eta 0:19:55 lr 0.000443	time 0.5899 (0.5970)	loss 3.7415 (3.6456)	grad_norm 2.3449 (2.6278)	mem 8931MB
[2022-04-06 04:51:09 large] (main.py 226): INFO Train: [66/300][600/2502]	eta 0:18:59 lr 0.000443	time 0.6114 (0.5993)	loss 3.8628 (3.6660)	grad_norm 3.7594 (inf)	mem 8931MB
[2022-04-06 04:52:11 large] (main.py 226): INFO Train: [66/300][700/2502]	eta 0:18:04 lr 0.000443	time 0.5942 (0.6020)	loss 4.0459 (3.6532)	grad_norm 2.1476 (inf)	mem 8931MB
[2022-04-06 04:53:13 large] (main.py 226): INFO Train: [66/300][800/2502]	eta 0:17:08 lr 0.000443	time 0.4769 (0.6042)	loss 2.6381 (3.6523)	grad_norm 3.3124 (inf)	mem 8931MB
[2022-04-06 04:54:14 large] (main.py 226): INFO Train: [66/300][900/2502]	eta 0:16:08 lr 0.000443	time 0.5936 (0.6048)	loss 3.4519 (3.6479)	grad_norm 2.4161 (inf)	mem 8931MB
[2022-04-06 04:55:15 large] (main.py 226): INFO Train: [66/300][1000/2502]	eta 0:15:09 lr 0.000443	time 0.5920 (0.6058)	loss 3.7576 (3.6529)	grad_norm 2.4834 (inf)	mem 8931MB
[2022-04-06 04:56:15 large] (main.py 226): INFO Train: [66/300][1100/2502]	eta 0:14:07 lr 0.000442	time 0.4773 (0.6048)	loss 2.8348 (3.6529)	grad_norm 2.1120 (inf)	mem 8931MB
[2022-04-06 04:57:10 large] (main.py 226): INFO Train: [66/300][1200/2502]	eta 0:13:01 lr 0.000442	time 0.5590 (0.6004)	loss 3.3087 (3.6583)	grad_norm 2.5506 (inf)	mem 8931MB
[2022-04-06 04:58:11 large] (main.py 226): INFO Train: [66/300][1300/2502]	eta 0:12:02 lr 0.000442	time 0.6001 (0.6010)	loss 3.4197 (3.6521)	grad_norm 2.7642 (inf)	mem 8931MB
[2022-04-06 04:59:12 large] (main.py 226): INFO Train: [66/300][1400/2502]	eta 0:11:03 lr 0.000442	time 0.6921 (0.6021)	loss 3.7897 (3.6551)	grad_norm 2.8567 (inf)	mem 8931MB
[2022-04-06 05:00:13 large] (main.py 226): INFO Train: [66/300][1500/2502]	eta 0:10:03 lr 0.000442	time 0.5961 (0.6022)	loss 4.1560 (3.6615)	grad_norm 3.0405 (inf)	mem 8931MB
[2022-04-06 05:01:13 large] (main.py 226): INFO Train: [66/300][1600/2502]	eta 0:09:03 lr 0.000442	time 0.6714 (0.6023)	loss 4.3369 (3.6601)	grad_norm 2.4426 (inf)	mem 8931MB
[2022-04-06 05:02:13 large] (main.py 226): INFO Train: [66/300][1700/2502]	eta 0:08:02 lr 0.000442	time 0.5363 (0.6022)	loss 4.2291 (3.6585)	grad_norm 3.8559 (inf)	mem 8931MB
[2022-04-06 05:03:14 large] (main.py 226): INFO Train: [66/300][1800/2502]	eta 0:07:02 lr 0.000442	time 0.5203 (0.6025)	loss 3.7485 (3.6624)	grad_norm 2.6689 (inf)	mem 8931MB
[2022-04-06 05:04:14 large] (main.py 226): INFO Train: [66/300][1900/2502]	eta 0:06:02 lr 0.000442	time 0.7305 (0.6023)	loss 3.2254 (3.6597)	grad_norm 2.3617 (inf)	mem 8931MB
[2022-04-06 05:05:14 large] (main.py 226): INFO Train: [66/300][2000/2502]	eta 0:05:02 lr 0.000442	time 0.5700 (0.6023)	loss 3.4017 (3.6580)	grad_norm 3.1290 (inf)	mem 8931MB
[2022-04-06 05:06:15 large] (main.py 226): INFO Train: [66/300][2100/2502]	eta 0:04:02 lr 0.000442	time 0.5674 (0.6025)	loss 3.9912 (3.6582)	grad_norm 2.7249 (inf)	mem 8931MB
[2022-04-06 05:07:15 large] (main.py 226): INFO Train: [66/300][2200/2502]	eta 0:03:01 lr 0.000442	time 0.5872 (0.6025)	loss 4.1796 (3.6554)	grad_norm 2.6982 (inf)	mem 8931MB
[2022-04-06 05:08:16 large] (main.py 226): INFO Train: [66/300][2300/2502]	eta 0:02:01 lr 0.000442	time 0.6392 (0.6029)	loss 3.2251 (3.6552)	grad_norm 2.4312 (inf)	mem 8931MB
[2022-04-06 05:09:17 large] (main.py 226): INFO Train: [66/300][2400/2502]	eta 0:01:01 lr 0.000442	time 0.5482 (0.6030)	loss 3.9211 (3.6574)	grad_norm 2.6671 (inf)	mem 8931MB
[2022-04-06 05:10:17 large] (main.py 226): INFO Train: [66/300][2500/2502]	eta 0:00:01 lr 0.000442	time 0.5028 (0.6030)	loss 4.1257 (3.6592)	grad_norm 2.2723 (inf)	mem 8931MB
[2022-04-06 05:10:18 large] (main.py 233): INFO EPOCH 66 training takes 0:25:09
[2022-04-06 05:10:24 large] (main.py 273): INFO Test: [0/98]	Time 6.100 (6.100)	Loss 1.3025 (1.3025)	Acc@1 70.508 (70.508)	Acc@5 92.773 (92.773)	Mem 8931MB
[2022-04-06 05:10:50 large] (main.py 279): INFO  * Acc@1 73.464 Acc@5 91.890
[2022-04-06 05:10:50 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 73.5%
[2022-04-06 05:10:50 large] (utils.py 57): INFO output/large/default/ckpt_epoch_66.pth saving......
[2022-04-06 05:10:51 large] (utils.py 59): INFO output/large/default/ckpt_epoch_66.pth saved !!!
[2022-04-06 05:10:51 large] (main.py 148): INFO Max accuracy: 73.46%
[2022-04-06 05:10:58 large] (main.py 226): INFO Train: [67/300][0/2502]	eta 5:08:11 lr 0.000442	time 7.3908 (7.3908)	loss 3.6448 (3.6448)	grad_norm 2.2044 (2.2044)	mem 8931MB
[2022-04-06 05:11:52 large] (main.py 226): INFO Train: [67/300][100/2502]	eta 0:24:05 lr 0.000441	time 0.6386 (0.6018)	loss 2.7022 (3.6121)	grad_norm 2.4209 (2.5701)	mem 8931MB
[2022-04-06 05:12:52 large] (main.py 226): INFO Train: [67/300][200/2502]	eta 0:23:11 lr 0.000441	time 0.5864 (0.6045)	loss 4.0495 (3.5878)	grad_norm 2.3103 (2.6016)	mem 8931MB
[2022-04-06 05:13:53 large] (main.py 226): INFO Train: [67/300][300/2502]	eta 0:22:14 lr 0.000441	time 0.6109 (0.6063)	loss 4.0313 (3.6360)	grad_norm 2.8031 (2.6243)	mem 8931MB
[2022-04-06 05:14:54 large] (main.py 226): INFO Train: [67/300][400/2502]	eta 0:21:14 lr 0.000441	time 0.5668 (0.6063)	loss 4.3518 (3.6417)	grad_norm 3.8106 (2.6313)	mem 8931MB
[2022-04-06 05:15:56 large] (main.py 226): INFO Train: [67/300][500/2502]	eta 0:20:20 lr 0.000441	time 0.6241 (0.6094)	loss 4.1021 (3.6188)	grad_norm 1.8646 (2.6053)	mem 8931MB
[2022-04-06 05:16:57 large] (main.py 226): INFO Train: [67/300][600/2502]	eta 0:19:18 lr 0.000441	time 0.6125 (0.6090)	loss 3.1470 (3.6329)	grad_norm 2.2635 (2.6075)	mem 8931MB
[2022-04-06 05:17:57 large] (main.py 226): INFO Train: [67/300][700/2502]	eta 0:18:16 lr 0.000441	time 0.6722 (0.6086)	loss 2.7378 (3.6409)	grad_norm 2.8611 (2.6124)	mem 8931MB
[2022-04-06 05:18:57 large] (main.py 226): INFO Train: [67/300][800/2502]	eta 0:17:12 lr 0.000441	time 0.5809 (0.6065)	loss 2.8141 (3.6483)	grad_norm 2.1191 (2.6084)	mem 8931MB
[2022-04-06 05:19:57 large] (main.py 226): INFO Train: [67/300][900/2502]	eta 0:16:11 lr 0.000441	time 0.5428 (0.6067)	loss 4.0850 (3.6481)	grad_norm 2.3858 (2.5962)	mem 8931MB
[2022-04-06 05:20:58 large] (main.py 226): INFO Train: [67/300][1000/2502]	eta 0:15:11 lr 0.000441	time 0.5248 (0.6070)	loss 4.3533 (3.6437)	grad_norm 2.0715 (2.5891)	mem 8931MB
[2022-04-06 05:21:59 large] (main.py 226): INFO Train: [67/300][1100/2502]	eta 0:14:11 lr 0.000441	time 0.7338 (0.6071)	loss 3.8634 (3.6445)	grad_norm 2.4531 (2.5861)	mem 8931MB
[2022-04-06 05:23:01 large] (main.py 226): INFO Train: [67/300][1200/2502]	eta 0:13:11 lr 0.000441	time 0.5725 (0.6079)	loss 3.5615 (3.6465)	grad_norm 2.9720 (2.5883)	mem 8931MB
[2022-04-06 05:24:01 large] (main.py 226): INFO Train: [67/300][1300/2502]	eta 0:12:10 lr 0.000441	time 0.6025 (0.6074)	loss 3.6933 (3.6484)	grad_norm 2.1374 (2.5916)	mem 8931MB
[2022-04-06 05:25:01 large] (main.py 226): INFO Train: [67/300][1400/2502]	eta 0:11:08 lr 0.000441	time 0.4857 (0.6066)	loss 4.4706 (3.6564)	grad_norm 2.2413 (2.5865)	mem 8931MB
[2022-04-06 05:25:56 large] (main.py 226): INFO Train: [67/300][1500/2502]	eta 0:10:03 lr 0.000441	time 0.5271 (0.6028)	loss 4.1079 (3.6635)	grad_norm 2.4406 (nan)	mem 8931MB
[2022-04-06 05:26:54 large] (main.py 226): INFO Train: [67/300][1600/2502]	eta 0:09:02 lr 0.000440	time 0.5879 (0.6016)	loss 4.1847 (3.6617)	grad_norm 2.4054 (nan)	mem 8931MB
[2022-04-06 05:27:55 large] (main.py 226): INFO Train: [67/300][1700/2502]	eta 0:08:02 lr 0.000440	time 0.6197 (0.6022)	loss 3.0023 (3.6659)	grad_norm 2.6769 (nan)	mem 8931MB
[2022-04-06 05:28:55 large] (main.py 226): INFO Train: [67/300][1800/2502]	eta 0:07:02 lr 0.000440	time 0.4807 (0.6021)	loss 3.8709 (3.6707)	grad_norm 2.5989 (nan)	mem 8931MB
[2022-04-06 05:29:50 large] (main.py 226): INFO Train: [67/300][1900/2502]	eta 0:06:00 lr 0.000440	time 0.6374 (0.5995)	loss 4.0600 (3.6717)	grad_norm 2.1758 (nan)	mem 8931MB
[2022-04-06 05:30:51 large] (main.py 226): INFO Train: [67/300][2000/2502]	eta 0:05:01 lr 0.000440	time 0.5070 (0.5997)	loss 4.0751 (3.6737)	grad_norm 2.8388 (nan)	mem 8931MB
[2022-04-06 05:31:52 large] (main.py 226): INFO Train: [67/300][2100/2502]	eta 0:04:01 lr 0.000440	time 0.6358 (0.6004)	loss 4.5167 (3.6751)	grad_norm 3.3378 (nan)	mem 8931MB
[2022-04-06 05:32:53 large] (main.py 226): INFO Train: [67/300][2200/2502]	eta 0:03:01 lr 0.000440	time 0.6830 (0.6008)	loss 3.4321 (3.6734)	grad_norm 1.9872 (nan)	mem 8931MB
[2022-04-06 05:33:54 large] (main.py 226): INFO Train: [67/300][2300/2502]	eta 0:02:01 lr 0.000440	time 0.6828 (0.6012)	loss 3.9043 (3.6710)	grad_norm 2.8070 (nan)	mem 8931MB
[2022-04-06 05:34:55 large] (main.py 226): INFO Train: [67/300][2400/2502]	eta 0:01:01 lr 0.000440	time 0.6102 (0.6016)	loss 2.7257 (3.6706)	grad_norm 2.2606 (nan)	mem 8931MB
[2022-04-06 05:35:56 large] (main.py 226): INFO Train: [67/300][2500/2502]	eta 0:00:01 lr 0.000440	time 0.5596 (0.6017)	loss 3.8761 (3.6708)	grad_norm 2.4676 (nan)	mem 8931MB
[2022-04-06 05:35:57 large] (main.py 233): INFO EPOCH 67 training takes 0:25:05
[2022-04-06 05:36:03 large] (main.py 273): INFO Test: [0/98]	Time 6.454 (6.454)	Loss 1.2604 (1.2604)	Acc@1 75.586 (75.586)	Acc@5 90.820 (90.820)	Mem 8931MB
[2022-04-06 05:36:29 large] (main.py 279): INFO  * Acc@1 73.292 Acc@5 91.822
[2022-04-06 05:36:29 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 73.3%
[2022-04-06 05:36:29 large] (main.py 148): INFO Max accuracy: 73.46%
[2022-04-06 05:36:37 large] (main.py 226): INFO Train: [68/300][0/2502]	eta 5:10:13 lr 0.000440	time 7.4395 (7.4395)	loss 3.5542 (3.5542)	grad_norm 1.9909 (1.9909)	mem 8931MB
[2022-04-06 05:37:27 large] (main.py 226): INFO Train: [68/300][100/2502]	eta 0:23:03 lr 0.000440	time 0.5669 (0.5762)	loss 4.1979 (3.5996)	grad_norm 2.2921 (2.5992)	mem 8931MB
[2022-04-06 05:38:17 large] (main.py 226): INFO Train: [68/300][200/2502]	eta 0:20:37 lr 0.000440	time 0.5356 (0.5374)	loss 3.9973 (3.7044)	grad_norm 2.1114 (2.5993)	mem 8931MB
[2022-04-06 05:39:18 large] (main.py 226): INFO Train: [68/300][300/2502]	eta 0:20:35 lr 0.000440	time 0.6190 (0.5610)	loss 3.7227 (3.6837)	grad_norm 2.6237 (2.5926)	mem 8931MB
[2022-04-06 05:40:21 large] (main.py 226): INFO Train: [68/300][400/2502]	eta 0:20:14 lr 0.000440	time 0.6503 (0.5776)	loss 2.7524 (3.6769)	grad_norm 3.7453 (2.5933)	mem 8931MB
[2022-04-06 05:41:22 large] (main.py 226): INFO Train: [68/300][500/2502]	eta 0:19:30 lr 0.000440	time 0.6451 (0.5848)	loss 4.6069 (3.6738)	grad_norm 3.1846 (2.6445)	mem 8931MB
[2022-04-06 05:42:24 large] (main.py 226): INFO Train: [68/300][600/2502]	eta 0:18:42 lr 0.000439	time 0.5902 (0.5901)	loss 3.9352 (3.6768)	grad_norm 2.3544 (2.6294)	mem 8931MB
[2022-04-06 05:43:24 large] (main.py 226): INFO Train: [68/300][700/2502]	eta 0:17:47 lr 0.000439	time 0.5374 (0.5925)	loss 4.7085 (3.6772)	grad_norm 3.1170 (2.6169)	mem 8931MB
[2022-04-06 05:44:26 large] (main.py 226): INFO Train: [68/300][800/2502]	eta 0:16:52 lr 0.000439	time 0.4966 (0.5951)	loss 3.9654 (3.6756)	grad_norm 2.3503 (2.6219)	mem 8931MB
[2022-04-06 05:45:28 large] (main.py 226): INFO Train: [68/300][900/2502]	eta 0:15:57 lr 0.000439	time 0.6174 (0.5979)	loss 4.1869 (3.6700)	grad_norm 2.1592 (2.6299)	mem 8931MB
[2022-04-06 05:46:24 large] (main.py 226): INFO Train: [68/300][1000/2502]	eta 0:14:52 lr 0.000439	time 0.4876 (0.5945)	loss 3.8725 (3.6594)	grad_norm 2.5253 (2.6230)	mem 8931MB
[2022-04-06 05:47:21 large] (main.py 226): INFO Train: [68/300][1100/2502]	eta 0:13:50 lr 0.000439	time 0.6635 (0.5925)	loss 3.9731 (3.6584)	grad_norm 2.5859 (2.6239)	mem 8931MB
[2022-04-06 05:48:22 large] (main.py 226): INFO Train: [68/300][1200/2502]	eta 0:12:52 lr 0.000439	time 0.5203 (0.5934)	loss 3.9786 (3.6625)	grad_norm 2.4631 (2.6176)	mem 8931MB
[2022-04-06 05:49:22 large] (main.py 226): INFO Train: [68/300][1300/2502]	eta 0:11:53 lr 0.000439	time 0.6188 (0.5940)	loss 3.9532 (3.6647)	grad_norm 2.8419 (2.6191)	mem 8931MB
[2022-04-06 05:50:22 large] (main.py 226): INFO Train: [68/300][1400/2502]	eta 0:10:55 lr 0.000439	time 0.5816 (0.5946)	loss 4.2119 (3.6643)	grad_norm 3.3541 (2.6128)	mem 8931MB
[2022-04-06 05:51:22 large] (main.py 226): INFO Train: [68/300][1500/2502]	eta 0:09:55 lr 0.000439	time 0.5937 (0.5948)	loss 3.1731 (3.6638)	grad_norm 2.4426 (2.6078)	mem 8931MB
[2022-04-06 05:52:23 large] (main.py 226): INFO Train: [68/300][1600/2502]	eta 0:08:57 lr 0.000439	time 0.6171 (0.5955)	loss 4.6914 (3.6626)	grad_norm 2.9292 (2.6104)	mem 8931MB
[2022-04-06 05:53:24 large] (main.py 226): INFO Train: [68/300][1700/2502]	eta 0:07:58 lr 0.000439	time 0.5653 (0.5964)	loss 3.9547 (3.6601)	grad_norm 2.3861 (2.6143)	mem 8931MB
[2022-04-06 05:54:25 large] (main.py 226): INFO Train: [68/300][1800/2502]	eta 0:06:59 lr 0.000439	time 0.5927 (0.5976)	loss 4.5731 (3.6559)	grad_norm 3.4911 (2.6127)	mem 8931MB
[2022-04-06 05:55:26 large] (main.py 226): INFO Train: [68/300][1900/2502]	eta 0:06:00 lr 0.000439	time 0.6189 (0.5982)	loss 3.6753 (3.6579)	grad_norm 2.2616 (2.6152)	mem 8931MB
[2022-04-06 05:56:27 large] (main.py 226): INFO Train: [68/300][2000/2502]	eta 0:05:00 lr 0.000438	time 0.5043 (0.5988)	loss 2.9592 (3.6541)	grad_norm 1.8969 (2.6123)	mem 8931MB
[2022-04-06 05:57:28 large] (main.py 226): INFO Train: [68/300][2100/2502]	eta 0:04:00 lr 0.000438	time 0.6306 (0.5992)	loss 3.7840 (3.6511)	grad_norm 1.8669 (2.6122)	mem 8931MB
[2022-04-06 05:58:29 large] (main.py 226): INFO Train: [68/300][2200/2502]	eta 0:03:01 lr 0.000438	time 0.6518 (0.5997)	loss 2.2761 (3.6539)	grad_norm 2.6384 (2.6125)	mem 8931MB
[2022-04-06 05:59:29 large] (main.py 226): INFO Train: [68/300][2300/2502]	eta 0:02:01 lr 0.000438	time 0.6262 (0.5999)	loss 4.3905 (3.6575)	grad_norm 3.4037 (2.6169)	mem 8931MB
[2022-04-06 06:00:29 large] (main.py 226): INFO Train: [68/300][2400/2502]	eta 0:01:01 lr 0.000438	time 0.6153 (0.5999)	loss 4.1810 (3.6592)	grad_norm 3.2500 (2.6145)	mem 8931MB
[2022-04-06 06:01:29 large] (main.py 226): INFO Train: [68/300][2500/2502]	eta 0:00:01 lr 0.000438	time 0.5790 (0.5997)	loss 4.0850 (3.6580)	grad_norm 2.6035 (2.6116)	mem 8931MB
[2022-04-06 06:01:30 large] (main.py 233): INFO EPOCH 68 training takes 0:25:00
[2022-04-06 06:01:36 large] (main.py 273): INFO Test: [0/98]	Time 5.786 (5.786)	Loss 1.2492 (1.2492)	Acc@1 71.680 (71.680)	Acc@5 91.211 (91.211)	Mem 8931MB
[2022-04-06 06:02:02 large] (main.py 279): INFO  * Acc@1 73.534 Acc@5 91.930
[2022-04-06 06:02:02 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 73.5%
[2022-04-06 06:02:02 large] (utils.py 57): INFO output/large/default/ckpt_epoch_68.pth saving......
[2022-04-06 06:02:03 large] (utils.py 59): INFO output/large/default/ckpt_epoch_68.pth saved !!!
[2022-04-06 06:02:03 large] (main.py 148): INFO Max accuracy: 73.53%
[2022-04-06 06:02:10 large] (main.py 226): INFO Train: [69/300][0/2502]	eta 5:04:32 lr 0.000438	time 7.3032 (7.3032)	loss 3.9241 (3.9241)	grad_norm 2.1609 (2.1609)	mem 8931MB
[2022-04-06 06:03:04 large] (main.py 226): INFO Train: [69/300][100/2502]	eta 0:24:16 lr 0.000438	time 0.5133 (0.6065)	loss 3.0488 (3.6519)	grad_norm 2.8885 (2.4954)	mem 8931MB
[2022-04-06 06:04:06 large] (main.py 226): INFO Train: [69/300][200/2502]	eta 0:23:33 lr 0.000438	time 0.6582 (0.6140)	loss 4.0766 (3.6872)	grad_norm 3.1102 (2.6195)	mem 8931MB
[2022-04-06 06:05:07 large] (main.py 226): INFO Train: [69/300][300/2502]	eta 0:22:29 lr 0.000438	time 0.5584 (0.6128)	loss 3.0643 (3.6740)	grad_norm 2.2978 (2.6164)	mem 8931MB
[2022-04-06 06:06:09 large] (main.py 226): INFO Train: [69/300][400/2502]	eta 0:21:31 lr 0.000438	time 0.4952 (0.6142)	loss 2.8960 (3.6251)	grad_norm 2.1362 (2.5857)	mem 8931MB
[2022-04-06 06:07:11 large] (main.py 226): INFO Train: [69/300][500/2502]	eta 0:20:31 lr 0.000438	time 0.6486 (0.6151)	loss 4.1968 (3.6198)	grad_norm 3.1820 (2.6021)	mem 8931MB
[2022-04-06 06:08:13 large] (main.py 226): INFO Train: [69/300][600/2502]	eta 0:19:31 lr 0.000438	time 0.5963 (0.6159)	loss 3.5573 (3.6020)	grad_norm 2.4766 (2.6058)	mem 8931MB
[2022-04-06 06:09:15 large] (main.py 226): INFO Train: [69/300][700/2502]	eta 0:18:30 lr 0.000438	time 0.4959 (0.6160)	loss 3.1037 (3.6142)	grad_norm 2.4669 (inf)	mem 8931MB
[2022-04-06 06:10:16 large] (main.py 226): INFO Train: [69/300][800/2502]	eta 0:17:28 lr 0.000438	time 0.6655 (0.6159)	loss 3.0628 (3.6152)	grad_norm 2.2406 (inf)	mem 8931MB
[2022-04-06 06:11:17 large] (main.py 226): INFO Train: [69/300][900/2502]	eta 0:16:25 lr 0.000438	time 0.5924 (0.6152)	loss 2.8048 (3.6292)	grad_norm 3.5201 (inf)	mem 8931MB
[2022-04-06 06:12:18 large] (main.py 226): INFO Train: [69/300][1000/2502]	eta 0:15:23 lr 0.000437	time 0.6560 (0.6150)	loss 4.1918 (3.6370)	grad_norm 2.5661 (inf)	mem 8931MB
[2022-04-06 06:13:19 large] (main.py 226): INFO Train: [69/300][1100/2502]	eta 0:14:21 lr 0.000437	time 0.5452 (0.6143)	loss 4.0776 (3.6405)	grad_norm 2.1081 (inf)	mem 8931MB
[2022-04-06 06:14:21 large] (main.py 226): INFO Train: [69/300][1200/2502]	eta 0:13:20 lr 0.000437	time 0.5833 (0.6147)	loss 4.0185 (3.6378)	grad_norm 2.1065 (inf)	mem 8931MB
[2022-04-06 06:15:22 large] (main.py 226): INFO Train: [69/300][1300/2502]	eta 0:12:18 lr 0.000437	time 0.5973 (0.6146)	loss 3.4250 (3.6394)	grad_norm 2.9382 (inf)	mem 8931MB
[2022-04-06 06:16:23 large] (main.py 226): INFO Train: [69/300][1400/2502]	eta 0:11:16 lr 0.000437	time 0.5919 (0.6142)	loss 3.4086 (3.6423)	grad_norm 2.0333 (inf)	mem 8931MB
[2022-04-06 06:17:25 large] (main.py 226): INFO Train: [69/300][1500/2502]	eta 0:10:15 lr 0.000437	time 0.7948 (0.6144)	loss 4.1698 (3.6440)	grad_norm 2.4675 (inf)	mem 8931MB
[2022-04-06 06:18:25 large] (main.py 226): INFO Train: [69/300][1600/2502]	eta 0:09:13 lr 0.000437	time 0.6109 (0.6137)	loss 3.4584 (3.6405)	grad_norm 2.1810 (inf)	mem 8931MB
[2022-04-06 06:19:25 large] (main.py 226): INFO Train: [69/300][1700/2502]	eta 0:08:11 lr 0.000437	time 0.5026 (0.6128)	loss 4.2558 (3.6446)	grad_norm 2.7149 (inf)	mem 8931MB
[2022-04-06 06:20:26 large] (main.py 226): INFO Train: [69/300][1800/2502]	eta 0:07:09 lr 0.000437	time 0.6353 (0.6125)	loss 3.2492 (3.6451)	grad_norm 2.8614 (inf)	mem 8931MB
[2022-04-06 06:21:27 large] (main.py 226): INFO Train: [69/300][1900/2502]	eta 0:06:08 lr 0.000437	time 0.5914 (0.6126)	loss 4.0068 (3.6477)	grad_norm 2.0596 (inf)	mem 8931MB
[2022-04-06 06:22:29 large] (main.py 226): INFO Train: [69/300][2000/2502]	eta 0:05:07 lr 0.000437	time 0.5868 (0.6126)	loss 4.0770 (3.6451)	grad_norm 2.1771 (inf)	mem 8931MB
[2022-04-06 06:23:30 large] (main.py 226): INFO Train: [69/300][2100/2502]	eta 0:04:06 lr 0.000437	time 0.5565 (0.6126)	loss 3.8130 (3.6407)	grad_norm 2.8790 (inf)	mem 8931MB
[2022-04-06 06:24:32 large] (main.py 226): INFO Train: [69/300][2200/2502]	eta 0:03:05 lr 0.000437	time 0.6225 (0.6128)	loss 2.5389 (3.6414)	grad_norm 2.2182 (inf)	mem 8931MB
[2022-04-06 06:25:32 large] (main.py 226): INFO Train: [69/300][2300/2502]	eta 0:02:03 lr 0.000437	time 0.5952 (0.6126)	loss 2.9005 (3.6392)	grad_norm 2.5815 (inf)	mem 8931MB
[2022-04-06 06:26:33 large] (main.py 226): INFO Train: [69/300][2400/2502]	eta 0:01:02 lr 0.000436	time 0.5996 (0.6124)	loss 4.4878 (3.6401)	grad_norm 2.5999 (inf)	mem 8931MB
[2022-04-06 06:27:33 large] (main.py 226): INFO Train: [69/300][2500/2502]	eta 0:00:01 lr 0.000436	time 0.5508 (0.6117)	loss 3.9694 (3.6425)	grad_norm 2.6978 (inf)	mem 8931MB
[2022-04-06 06:27:34 large] (main.py 233): INFO EPOCH 69 training takes 0:25:30
[2022-04-06 06:27:40 large] (main.py 273): INFO Test: [0/98]	Time 5.891 (5.891)	Loss 1.1959 (1.1959)	Acc@1 75.586 (75.586)	Acc@5 91.992 (91.992)	Mem 8931MB
[2022-04-06 06:28:06 large] (main.py 279): INFO  * Acc@1 73.568 Acc@5 91.894
[2022-04-06 06:28:06 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 73.6%
[2022-04-06 06:28:06 large] (utils.py 57): INFO output/large/default/ckpt_epoch_69.pth saving......
[2022-04-06 06:28:06 large] (utils.py 59): INFO output/large/default/ckpt_epoch_69.pth saved !!!
[2022-04-06 06:28:06 large] (main.py 148): INFO Max accuracy: 73.57%
[2022-04-06 06:28:15 large] (main.py 226): INFO Train: [70/300][0/2502]	eta 5:40:22 lr 0.000436	time 8.1624 (8.1624)	loss 4.2907 (4.2907)	grad_norm 2.7333 (2.7333)	mem 8931MB
[2022-04-06 06:29:09 large] (main.py 226): INFO Train: [70/300][100/2502]	eta 0:24:43 lr 0.000436	time 0.5221 (0.6175)	loss 2.7416 (3.6242)	grad_norm 3.0356 (2.5824)	mem 8931MB
[2022-04-06 06:30:11 large] (main.py 226): INFO Train: [70/300][200/2502]	eta 0:23:52 lr 0.000436	time 0.6626 (0.6223)	loss 3.9470 (3.6122)	grad_norm 2.4694 (2.6013)	mem 8931MB
[2022-04-06 06:31:13 large] (main.py 226): INFO Train: [70/300][300/2502]	eta 0:22:46 lr 0.000436	time 0.6515 (0.6206)	loss 3.7637 (3.6156)	grad_norm 2.6862 (inf)	mem 8931MB
[2022-04-06 06:32:15 large] (main.py 226): INFO Train: [70/300][400/2502]	eta 0:21:43 lr 0.000436	time 0.5906 (0.6201)	loss 3.5467 (3.6252)	grad_norm 2.1748 (inf)	mem 8931MB
[2022-04-06 06:33:17 large] (main.py 226): INFO Train: [70/300][500/2502]	eta 0:20:42 lr 0.000436	time 0.6181 (0.6206)	loss 3.6520 (3.6339)	grad_norm 3.3833 (inf)	mem 8931MB
[2022-04-06 06:34:19 large] (main.py 226): INFO Train: [70/300][600/2502]	eta 0:19:38 lr 0.000436	time 0.6315 (0.6196)	loss 2.5856 (3.6363)	grad_norm 2.3725 (inf)	mem 8931MB
[2022-04-06 06:35:19 large] (main.py 226): INFO Train: [70/300][700/2502]	eta 0:18:32 lr 0.000436	time 0.7013 (0.6174)	loss 3.4695 (3.6423)	grad_norm 3.1334 (inf)	mem 8931MB
[2022-04-06 06:36:21 large] (main.py 226): INFO Train: [70/300][800/2502]	eta 0:17:30 lr 0.000436	time 0.6789 (0.6172)	loss 4.1330 (3.6325)	grad_norm 2.7250 (inf)	mem 8931MB
[2022-04-06 06:37:22 large] (main.py 226): INFO Train: [70/300][900/2502]	eta 0:16:28 lr 0.000436	time 0.5439 (0.6169)	loss 3.3552 (3.6426)	grad_norm 3.1868 (inf)	mem 8931MB
[2022-04-06 06:38:23 large] (main.py 226): INFO Train: [70/300][1000/2502]	eta 0:15:24 lr 0.000436	time 0.5759 (0.6158)	loss 3.2393 (3.6361)	grad_norm 2.7824 (inf)	mem 8931MB
[2022-04-06 06:39:23 large] (main.py 226): INFO Train: [70/300][1100/2502]	eta 0:14:22 lr 0.000436	time 0.6225 (0.6149)	loss 4.1269 (3.6388)	grad_norm 2.6327 (inf)	mem 8931MB
[2022-04-06 06:40:24 large] (main.py 226): INFO Train: [70/300][1200/2502]	eta 0:13:20 lr 0.000436	time 0.6132 (0.6145)	loss 4.0774 (3.6440)	grad_norm 2.2702 (inf)	mem 8931MB
[2022-04-06 06:41:26 large] (main.py 226): INFO Train: [70/300][1300/2502]	eta 0:12:18 lr 0.000436	time 0.6621 (0.6143)	loss 3.7907 (3.6489)	grad_norm 3.6983 (inf)	mem 8931MB
[2022-04-06 06:42:26 large] (main.py 226): INFO Train: [70/300][1400/2502]	eta 0:11:16 lr 0.000435	time 0.6468 (0.6135)	loss 3.8232 (3.6405)	grad_norm 2.6501 (inf)	mem 8931MB
[2022-04-06 06:43:26 large] (main.py 226): INFO Train: [70/300][1500/2502]	eta 0:10:14 lr 0.000435	time 0.6353 (0.6129)	loss 4.1134 (3.6361)	grad_norm 1.9600 (inf)	mem 8931MB
[2022-04-06 06:44:27 large] (main.py 226): INFO Train: [70/300][1600/2502]	eta 0:09:12 lr 0.000435	time 0.5614 (0.6125)	loss 4.2812 (3.6312)	grad_norm 2.2449 (inf)	mem 8931MB
[2022-04-06 06:45:27 large] (main.py 226): INFO Train: [70/300][1700/2502]	eta 0:08:10 lr 0.000435	time 0.6619 (0.6116)	loss 3.3447 (3.6305)	grad_norm 2.9032 (inf)	mem 8931MB
[2022-04-06 06:46:28 large] (main.py 226): INFO Train: [70/300][1800/2502]	eta 0:07:09 lr 0.000435	time 0.5118 (0.6117)	loss 3.3379 (3.6312)	grad_norm 2.3337 (inf)	mem 8931MB
[2022-04-06 06:47:28 large] (main.py 226): INFO Train: [70/300][1900/2502]	eta 0:06:07 lr 0.000435	time 0.5836 (0.6113)	loss 3.8604 (3.6345)	grad_norm 2.6286 (inf)	mem 8931MB
[2022-04-06 06:48:30 large] (main.py 226): INFO Train: [70/300][2000/2502]	eta 0:05:06 lr 0.000435	time 0.6233 (0.6114)	loss 3.7784 (3.6357)	grad_norm 3.5270 (inf)	mem 8931MB
[2022-04-06 06:49:31 large] (main.py 226): INFO Train: [70/300][2100/2502]	eta 0:04:05 lr 0.000435	time 0.5006 (0.6112)	loss 4.4225 (3.6371)	grad_norm 2.9290 (inf)	mem 8931MB
[2022-04-06 06:50:30 large] (main.py 226): INFO Train: [70/300][2200/2502]	eta 0:03:04 lr 0.000435	time 0.6052 (0.6106)	loss 3.3818 (3.6382)	grad_norm 2.3053 (inf)	mem 8931MB
[2022-04-06 06:51:31 large] (main.py 226): INFO Train: [70/300][2300/2502]	eta 0:02:03 lr 0.000435	time 0.5209 (0.6102)	loss 4.3152 (3.6444)	grad_norm 2.2619 (nan)	mem 8931MB
[2022-04-06 06:52:31 large] (main.py 226): INFO Train: [70/300][2400/2502]	eta 0:01:02 lr 0.000435	time 0.6649 (0.6099)	loss 3.5689 (3.6506)	grad_norm 2.7456 (nan)	mem 8931MB
[2022-04-06 06:53:31 large] (main.py 226): INFO Train: [70/300][2500/2502]	eta 0:00:01 lr 0.000435	time 0.5425 (0.6097)	loss 3.8103 (3.6516)	grad_norm 2.9582 (nan)	mem 8931MB
[2022-04-06 06:53:32 large] (main.py 233): INFO EPOCH 70 training takes 0:25:25
[2022-04-06 06:53:38 large] (main.py 273): INFO Test: [0/98]	Time 5.953 (5.953)	Loss 1.2553 (1.2553)	Acc@1 72.461 (72.461)	Acc@5 91.016 (91.016)	Mem 8931MB
[2022-04-06 06:54:05 large] (main.py 279): INFO  * Acc@1 73.476 Acc@5 92.022
[2022-04-06 06:54:05 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 73.5%
[2022-04-06 06:54:05 large] (main.py 148): INFO Max accuracy: 73.57%
[2022-04-06 06:54:11 large] (main.py 226): INFO Train: [71/300][0/2502]	eta 4:31:22 lr 0.000435	time 6.5077 (6.5077)	loss 2.4846 (2.4846)	grad_norm 2.5734 (2.5734)	mem 8931MB
[2022-04-06 06:55:04 large] (main.py 226): INFO Train: [71/300][100/2502]	eta 0:23:33 lr 0.000435	time 0.7143 (0.5884)	loss 3.6746 (3.5897)	grad_norm 2.4991 (2.6022)	mem 8931MB
[2022-04-06 06:56:05 large] (main.py 226): INFO Train: [71/300][200/2502]	eta 0:23:02 lr 0.000435	time 0.7399 (0.6005)	loss 4.1688 (3.5788)	grad_norm 2.8152 (2.6379)	mem 8931MB
[2022-04-06 06:57:07 large] (main.py 226): INFO Train: [71/300][300/2502]	eta 0:22:12 lr 0.000434	time 0.5914 (0.6051)	loss 3.5513 (3.6075)	grad_norm 4.7387 (2.6829)	mem 8931MB
[2022-04-06 06:58:09 large] (main.py 226): INFO Train: [71/300][400/2502]	eta 0:21:19 lr 0.000434	time 0.6669 (0.6088)	loss 4.0588 (3.5958)	grad_norm 2.3388 (2.6825)	mem 8931MB
[2022-04-06 06:59:08 large] (main.py 226): INFO Train: [71/300][500/2502]	eta 0:20:12 lr 0.000434	time 0.6111 (0.6055)	loss 3.2450 (3.6002)	grad_norm 2.6763 (2.6942)	mem 8931MB
[2022-04-06 07:00:08 large] (main.py 226): INFO Train: [71/300][600/2502]	eta 0:19:10 lr 0.000434	time 0.6392 (0.6047)	loss 4.1576 (3.5914)	grad_norm 2.4478 (2.6874)	mem 8931MB
[2022-04-06 07:01:08 large] (main.py 226): INFO Train: [71/300][700/2502]	eta 0:18:09 lr 0.000434	time 0.6738 (0.6048)	loss 3.4972 (3.5944)	grad_norm 2.1365 (2.6834)	mem 8931MB
[2022-04-06 07:02:09 large] (main.py 226): INFO Train: [71/300][800/2502]	eta 0:17:08 lr 0.000434	time 0.6089 (0.6044)	loss 4.0926 (3.5971)	grad_norm 2.4358 (2.6696)	mem 8931MB
[2022-04-06 07:03:09 large] (main.py 226): INFO Train: [71/300][900/2502]	eta 0:16:07 lr 0.000434	time 0.6337 (0.6041)	loss 3.7388 (3.6150)	grad_norm 2.7444 (2.6640)	mem 8931MB
[2022-04-06 07:04:09 large] (main.py 226): INFO Train: [71/300][1000/2502]	eta 0:15:07 lr 0.000434	time 0.5647 (0.6044)	loss 3.6255 (3.6233)	grad_norm 3.2925 (2.6627)	mem 8931MB
[2022-04-06 07:05:09 large] (main.py 226): INFO Train: [71/300][1100/2502]	eta 0:14:06 lr 0.000434	time 0.6421 (0.6035)	loss 4.0557 (3.6219)	grad_norm 2.2901 (2.6586)	mem 8931MB
[2022-04-06 07:06:09 large] (main.py 226): INFO Train: [71/300][1200/2502]	eta 0:13:05 lr 0.000434	time 0.5040 (0.6035)	loss 2.4159 (3.6204)	grad_norm 2.0075 (2.6501)	mem 8931MB
[2022-04-06 07:07:09 large] (main.py 226): INFO Train: [71/300][1300/2502]	eta 0:12:04 lr 0.000434	time 0.5462 (0.6029)	loss 3.5845 (3.6234)	grad_norm 2.5180 (2.6489)	mem 8931MB
[2022-04-06 07:08:10 large] (main.py 226): INFO Train: [71/300][1400/2502]	eta 0:11:04 lr 0.000434	time 0.6043 (0.6033)	loss 2.7291 (3.6257)	grad_norm 2.7801 (2.6517)	mem 8931MB
[2022-04-06 07:09:11 large] (main.py 226): INFO Train: [71/300][1500/2502]	eta 0:10:04 lr 0.000434	time 0.4930 (0.6036)	loss 3.3800 (3.6309)	grad_norm 4.3406 (2.6529)	mem 8931MB
[2022-04-06 07:10:10 large] (main.py 226): INFO Train: [71/300][1600/2502]	eta 0:09:03 lr 0.000434	time 0.5006 (0.6028)	loss 3.0450 (3.6279)	grad_norm 2.5051 (2.6524)	mem 8931MB
[2022-04-06 07:11:09 large] (main.py 226): INFO Train: [71/300][1700/2502]	eta 0:08:03 lr 0.000433	time 0.5867 (0.6024)	loss 3.2658 (3.6217)	grad_norm 2.3137 (2.6501)	mem 8931MB
[2022-04-06 07:12:08 large] (main.py 226): INFO Train: [71/300][1800/2502]	eta 0:07:02 lr 0.000433	time 0.5353 (0.6019)	loss 3.7104 (3.6219)	grad_norm 2.1412 (2.6498)	mem 8931MB
[2022-04-06 07:13:08 large] (main.py 226): INFO Train: [71/300][1900/2502]	eta 0:06:02 lr 0.000433	time 0.6075 (0.6015)	loss 2.9125 (3.6189)	grad_norm 2.4868 (2.6474)	mem 8931MB
[2022-04-06 07:14:08 large] (main.py 226): INFO Train: [71/300][2000/2502]	eta 0:05:01 lr 0.000433	time 0.5892 (0.6013)	loss 2.4396 (3.6168)	grad_norm 2.4184 (2.6429)	mem 8931MB
[2022-04-06 07:15:08 large] (main.py 226): INFO Train: [71/300][2100/2502]	eta 0:04:01 lr 0.000433	time 0.5574 (0.6012)	loss 3.4866 (3.6160)	grad_norm 3.0977 (2.6422)	mem 8931MB
[2022-04-06 07:16:08 large] (main.py 226): INFO Train: [71/300][2200/2502]	eta 0:03:01 lr 0.000433	time 0.5952 (0.6011)	loss 3.9073 (3.6160)	grad_norm 3.6487 (2.6418)	mem 8931MB
[2022-04-06 07:17:07 large] (main.py 226): INFO Train: [71/300][2300/2502]	eta 0:02:01 lr 0.000433	time 0.6218 (0.6007)	loss 2.7020 (3.6101)	grad_norm 2.8791 (2.6437)	mem 8931MB
[2022-04-06 07:18:07 large] (main.py 226): INFO Train: [71/300][2400/2502]	eta 0:01:01 lr 0.000433	time 0.5945 (0.6007)	loss 3.2749 (3.6126)	grad_norm 3.5866 (2.6415)	mem 8931MB
[2022-04-06 07:19:07 large] (main.py 226): INFO Train: [71/300][2500/2502]	eta 0:00:01 lr 0.000433	time 0.5669 (0.6007)	loss 4.3812 (3.6163)	grad_norm 3.1289 (2.6422)	mem 8931MB
[2022-04-06 07:19:08 large] (main.py 233): INFO EPOCH 71 training takes 0:25:03
[2022-04-06 07:19:14 large] (main.py 273): INFO Test: [0/98]	Time 5.637 (5.637)	Loss 1.2497 (1.2497)	Acc@1 74.219 (74.219)	Acc@5 91.797 (91.797)	Mem 8931MB
[2022-04-06 07:19:40 large] (main.py 279): INFO  * Acc@1 73.580 Acc@5 91.950
[2022-04-06 07:19:40 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 73.6%
[2022-04-06 07:19:40 large] (utils.py 57): INFO output/large/default/ckpt_epoch_71.pth saving......
[2022-04-06 07:19:41 large] (utils.py 59): INFO output/large/default/ckpt_epoch_71.pth saved !!!
[2022-04-06 07:19:41 large] (main.py 148): INFO Max accuracy: 73.58%
[2022-04-06 07:19:48 large] (main.py 226): INFO Train: [72/300][0/2502]	eta 5:15:43 lr 0.000433	time 7.5714 (7.5714)	loss 3.8883 (3.8883)	grad_norm 3.0372 (3.0372)	mem 8931MB
[2022-04-06 07:20:43 large] (main.py 226): INFO Train: [72/300][100/2502]	eta 0:24:29 lr 0.000433	time 0.6237 (0.6116)	loss 4.1832 (3.6123)	grad_norm 3.6054 (2.6162)	mem 8931MB
[2022-04-06 07:21:44 large] (main.py 226): INFO Train: [72/300][200/2502]	eta 0:23:25 lr 0.000433	time 0.5541 (0.6106)	loss 3.4662 (3.5681)	grad_norm 2.9921 (2.6253)	mem 8931MB
[2022-04-06 07:22:45 large] (main.py 226): INFO Train: [72/300][300/2502]	eta 0:22:23 lr 0.000433	time 0.6058 (0.6103)	loss 4.0859 (3.5850)	grad_norm 2.4386 (2.6207)	mem 8931MB
[2022-04-06 07:23:45 large] (main.py 226): INFO Train: [72/300][400/2502]	eta 0:21:17 lr 0.000433	time 0.6252 (0.6078)	loss 4.1461 (3.6040)	grad_norm 2.4318 (2.6361)	mem 8931MB
[2022-04-06 07:24:44 large] (main.py 226): INFO Train: [72/300][500/2502]	eta 0:20:13 lr 0.000433	time 0.6638 (0.6061)	loss 3.2963 (3.5999)	grad_norm 2.7341 (2.6420)	mem 8931MB
[2022-04-06 07:25:44 large] (main.py 226): INFO Train: [72/300][600/2502]	eta 0:19:09 lr 0.000432	time 0.5205 (0.6046)	loss 3.3006 (3.6147)	grad_norm 3.0703 (2.6357)	mem 8931MB
[2022-04-06 07:26:44 large] (main.py 226): INFO Train: [72/300][700/2502]	eta 0:18:07 lr 0.000432	time 0.5911 (0.6037)	loss 3.9354 (3.6044)	grad_norm 2.7803 (2.6264)	mem 8931MB
[2022-04-06 07:27:44 large] (main.py 226): INFO Train: [72/300][800/2502]	eta 0:17:06 lr 0.000432	time 0.5994 (0.6031)	loss 3.9680 (3.6048)	grad_norm 2.5198 (2.6225)	mem 8931MB
[2022-04-06 07:28:43 large] (main.py 226): INFO Train: [72/300][900/2502]	eta 0:16:04 lr 0.000432	time 0.5731 (0.6023)	loss 4.0580 (3.6018)	grad_norm 2.9397 (2.6097)	mem 8931MB
[2022-04-06 07:29:43 large] (main.py 226): INFO Train: [72/300][1000/2502]	eta 0:15:02 lr 0.000432	time 0.5911 (0.6012)	loss 3.6983 (3.6016)	grad_norm 2.7610 (2.6190)	mem 8931MB
[2022-04-06 07:30:42 large] (main.py 226): INFO Train: [72/300][1100/2502]	eta 0:14:01 lr 0.000432	time 0.5521 (0.6001)	loss 3.5275 (3.6064)	grad_norm 2.1782 (2.6138)	mem 8931MB
[2022-04-06 07:31:40 large] (main.py 226): INFO Train: [72/300][1200/2502]	eta 0:12:59 lr 0.000432	time 0.5516 (0.5990)	loss 4.3772 (3.6096)	grad_norm 3.2904 (2.6230)	mem 8931MB
[2022-04-06 07:32:38 large] (main.py 226): INFO Train: [72/300][1300/2502]	eta 0:11:58 lr 0.000432	time 0.4659 (0.5975)	loss 2.5255 (3.6077)	grad_norm nan (nan)	mem 8931MB
[2022-04-06 07:33:37 large] (main.py 226): INFO Train: [72/300][1400/2502]	eta 0:10:57 lr 0.000432	time 0.5335 (0.5966)	loss 3.6073 (3.6138)	grad_norm 4.3590 (nan)	mem 8931MB
[2022-04-06 07:34:36 large] (main.py 226): INFO Train: [72/300][1500/2502]	eta 0:09:57 lr 0.000432	time 0.5964 (0.5962)	loss 3.6850 (3.6177)	grad_norm 2.9653 (nan)	mem 8931MB
[2022-04-06 07:35:36 large] (main.py 226): INFO Train: [72/300][1600/2502]	eta 0:08:58 lr 0.000432	time 0.6268 (0.5966)	loss 3.2670 (3.6193)	grad_norm 2.6307 (nan)	mem 8931MB
[2022-04-06 07:36:36 large] (main.py 226): INFO Train: [72/300][1700/2502]	eta 0:07:58 lr 0.000432	time 0.4892 (0.5969)	loss 4.0945 (3.6215)	grad_norm 2.2845 (nan)	mem 8931MB
[2022-04-06 07:37:35 large] (main.py 226): INFO Train: [72/300][1800/2502]	eta 0:06:58 lr 0.000432	time 0.5814 (0.5965)	loss 4.1960 (3.6239)	grad_norm 2.4973 (nan)	mem 8931MB
[2022-04-06 07:38:34 large] (main.py 226): INFO Train: [72/300][1900/2502]	eta 0:05:58 lr 0.000432	time 0.4996 (0.5962)	loss 3.6867 (3.6232)	grad_norm 3.5932 (nan)	mem 8931MB
[2022-04-06 07:39:34 large] (main.py 226): INFO Train: [72/300][2000/2502]	eta 0:04:59 lr 0.000431	time 0.5827 (0.5963)	loss 3.8596 (3.6217)	grad_norm 2.3307 (nan)	mem 8931MB
[2022-04-06 07:40:30 large] (main.py 226): INFO Train: [72/300][2100/2502]	eta 0:03:59 lr 0.000431	time 0.5613 (0.5948)	loss 3.5619 (3.6233)	grad_norm 1.8971 (nan)	mem 8931MB
[2022-04-06 07:41:28 large] (main.py 226): INFO Train: [72/300][2200/2502]	eta 0:02:59 lr 0.000431	time 0.5640 (0.5939)	loss 3.9915 (3.6217)	grad_norm 3.5814 (nan)	mem 8931MB
[2022-04-06 07:42:28 large] (main.py 226): INFO Train: [72/300][2300/2502]	eta 0:02:00 lr 0.000431	time 0.5905 (0.5943)	loss 3.4570 (3.6192)	grad_norm 2.7341 (nan)	mem 8931MB
[2022-04-06 07:43:28 large] (main.py 226): INFO Train: [72/300][2400/2502]	eta 0:01:00 lr 0.000431	time 0.5936 (0.5946)	loss 3.9728 (3.6187)	grad_norm 2.0510 (nan)	mem 8931MB
[2022-04-06 07:44:26 large] (main.py 226): INFO Train: [72/300][2500/2502]	eta 0:00:01 lr 0.000431	time 0.5680 (0.5939)	loss 2.3179 (3.6222)	grad_norm 2.4577 (nan)	mem 8931MB
[2022-04-06 07:44:27 large] (main.py 233): INFO EPOCH 72 training takes 0:24:46
[2022-04-06 07:44:34 large] (main.py 273): INFO Test: [0/98]	Time 6.647 (6.647)	Loss 1.1583 (1.1583)	Acc@1 72.852 (72.852)	Acc@5 94.336 (94.336)	Mem 8931MB
[2022-04-06 07:44:59 large] (main.py 279): INFO  * Acc@1 73.402 Acc@5 91.880
[2022-04-06 07:44:59 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 73.4%
[2022-04-06 07:44:59 large] (main.py 148): INFO Max accuracy: 73.58%
[2022-04-06 07:45:06 large] (main.py 226): INFO Train: [73/300][0/2502]	eta 5:04:44 lr 0.000431	time 7.3079 (7.3079)	loss 4.2096 (4.2096)	grad_norm 2.1415 (2.1415)	mem 8931MB
[2022-04-06 07:46:00 large] (main.py 226): INFO Train: [73/300][100/2502]	eta 0:24:18 lr 0.000431	time 0.5735 (0.6074)	loss 2.3167 (3.5398)	grad_norm 2.7630 (2.5598)	mem 8931MB
[2022-04-06 07:47:02 large] (main.py 226): INFO Train: [73/300][200/2502]	eta 0:23:23 lr 0.000431	time 0.5456 (0.6095)	loss 2.5327 (3.5504)	grad_norm 2.9126 (2.5552)	mem 8931MB
[2022-04-06 07:48:02 large] (main.py 226): INFO Train: [73/300][300/2502]	eta 0:22:19 lr 0.000431	time 0.6115 (0.6085)	loss 2.9293 (3.5677)	grad_norm 2.6430 (2.5991)	mem 8931MB
[2022-04-06 07:49:03 large] (main.py 226): INFO Train: [73/300][400/2502]	eta 0:21:18 lr 0.000431	time 0.6756 (0.6083)	loss 4.4849 (3.5709)	grad_norm 3.2920 (2.6214)	mem 8931MB
[2022-04-06 07:50:04 large] (main.py 226): INFO Train: [73/300][500/2502]	eta 0:20:17 lr 0.000431	time 0.6127 (0.6080)	loss 2.5982 (3.5852)	grad_norm 3.8742 (2.6349)	mem 8931MB
[2022-04-06 07:51:03 large] (main.py 226): INFO Train: [73/300][600/2502]	eta 0:19:10 lr 0.000431	time 0.6600 (0.6049)	loss 4.3039 (3.5938)	grad_norm 2.5221 (2.6327)	mem 8931MB
[2022-04-06 07:52:04 large] (main.py 226): INFO Train: [73/300][700/2502]	eta 0:18:11 lr 0.000431	time 0.5290 (0.6055)	loss 2.4648 (3.5977)	grad_norm 3.1154 (2.6303)	mem 8931MB
[2022-04-06 07:53:04 large] (main.py 226): INFO Train: [73/300][800/2502]	eta 0:17:10 lr 0.000431	time 0.5825 (0.6056)	loss 3.7490 (3.5958)	grad_norm 4.2363 (2.6345)	mem 8931MB
[2022-04-06 07:54:05 large] (main.py 226): INFO Train: [73/300][900/2502]	eta 0:16:10 lr 0.000430	time 0.5823 (0.6056)	loss 3.0498 (3.6002)	grad_norm 3.3691 (2.6368)	mem 8931MB
[2022-04-06 07:55:06 large] (main.py 226): INFO Train: [73/300][1000/2502]	eta 0:15:09 lr 0.000430	time 0.6338 (0.6058)	loss 3.8672 (3.6023)	grad_norm 2.5966 (2.6401)	mem 8931MB
[2022-04-06 07:56:05 large] (main.py 226): INFO Train: [73/300][1100/2502]	eta 0:14:08 lr 0.000430	time 0.4953 (0.6050)	loss 2.4705 (3.6027)	grad_norm 2.0633 (2.6438)	mem 8931MB
[2022-04-06 07:56:59 large] (main.py 226): INFO Train: [73/300][1200/2502]	eta 0:13:00 lr 0.000430	time 0.5315 (0.5993)	loss 4.0862 (3.6046)	grad_norm 2.8174 (2.6505)	mem 8931MB
[2022-04-06 07:57:58 large] (main.py 226): INFO Train: [73/300][1300/2502]	eta 0:11:59 lr 0.000430	time 0.6734 (0.5988)	loss 3.9453 (3.6032)	grad_norm 2.4291 (2.6451)	mem 8931MB
[2022-04-06 07:58:59 large] (main.py 226): INFO Train: [73/300][1400/2502]	eta 0:11:00 lr 0.000430	time 0.6513 (0.5993)	loss 3.8411 (3.6016)	grad_norm 1.9896 (2.6463)	mem 8931MB
[2022-04-06 08:00:00 large] (main.py 226): INFO Train: [73/300][1500/2502]	eta 0:10:01 lr 0.000430	time 0.6793 (0.6003)	loss 3.8298 (3.6054)	grad_norm 2.3853 (2.6509)	mem 8931MB
[2022-04-06 08:01:02 large] (main.py 226): INFO Train: [73/300][1600/2502]	eta 0:09:02 lr 0.000430	time 0.5645 (0.6011)	loss 4.2660 (3.6016)	grad_norm 2.6513 (2.6474)	mem 8931MB
[2022-04-06 08:02:01 large] (main.py 226): INFO Train: [73/300][1700/2502]	eta 0:08:01 lr 0.000430	time 0.5838 (0.6008)	loss 3.2635 (3.6050)	grad_norm 2.8396 (2.6551)	mem 8931MB
[2022-04-06 08:03:01 large] (main.py 226): INFO Train: [73/300][1800/2502]	eta 0:07:01 lr 0.000430	time 0.6015 (0.6009)	loss 4.0186 (3.6044)	grad_norm 2.1477 (2.6448)	mem 8931MB
[2022-04-06 08:04:02 large] (main.py 226): INFO Train: [73/300][1900/2502]	eta 0:06:01 lr 0.000430	time 0.5813 (0.6010)	loss 4.3034 (3.6079)	grad_norm 2.9989 (2.6493)	mem 8931MB
[2022-04-06 08:05:02 large] (main.py 226): INFO Train: [73/300][2000/2502]	eta 0:05:01 lr 0.000430	time 0.5570 (0.6012)	loss 3.8785 (3.6093)	grad_norm 2.3593 (2.6498)	mem 8931MB
[2022-04-06 08:06:01 large] (main.py 226): INFO Train: [73/300][2100/2502]	eta 0:04:01 lr 0.000430	time 0.5177 (0.6007)	loss 3.9234 (3.6129)	grad_norm 2.3519 (2.6510)	mem 8931MB
[2022-04-06 08:06:59 large] (main.py 226): INFO Train: [73/300][2200/2502]	eta 0:03:01 lr 0.000430	time 0.6558 (0.5998)	loss 3.7923 (3.6124)	grad_norm 2.4273 (2.6552)	mem 8931MB
[2022-04-06 08:07:58 large] (main.py 226): INFO Train: [73/300][2300/2502]	eta 0:02:01 lr 0.000429	time 0.6228 (0.5992)	loss 2.9899 (3.6132)	grad_norm 3.2539 (2.6565)	mem 8931MB
[2022-04-06 08:08:58 large] (main.py 226): INFO Train: [73/300][2400/2502]	eta 0:01:01 lr 0.000429	time 0.5267 (0.5994)	loss 4.2230 (3.6096)	grad_norm 3.4870 (2.6546)	mem 8931MB
[2022-04-06 08:09:59 large] (main.py 226): INFO Train: [73/300][2500/2502]	eta 0:00:01 lr 0.000429	time 0.6120 (0.5997)	loss 4.4117 (3.6110)	grad_norm 2.6284 (2.6541)	mem 8931MB
[2022-04-06 08:10:00 large] (main.py 233): INFO EPOCH 73 training takes 0:25:00
[2022-04-06 08:10:07 large] (main.py 273): INFO Test: [0/98]	Time 6.622 (6.622)	Loss 1.2940 (1.2940)	Acc@1 71.875 (71.875)	Acc@5 91.797 (91.797)	Mem 8931MB
[2022-04-06 08:10:32 large] (main.py 279): INFO  * Acc@1 73.554 Acc@5 92.000
[2022-04-06 08:10:32 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 73.6%
[2022-04-06 08:10:32 large] (main.py 148): INFO Max accuracy: 73.58%
[2022-04-06 08:10:39 large] (main.py 226): INFO Train: [74/300][0/2502]	eta 4:58:41 lr 0.000429	time 7.1628 (7.1628)	loss 3.9251 (3.9251)	grad_norm 2.3647 (2.3647)	mem 8931MB
[2022-04-06 08:11:34 large] (main.py 226): INFO Train: [74/300][100/2502]	eta 0:24:24 lr 0.000429	time 0.5147 (0.6097)	loss 2.4843 (3.6362)	grad_norm 2.2333 (2.5613)	mem 8931MB
[2022-04-06 08:12:35 large] (main.py 226): INFO Train: [74/300][200/2502]	eta 0:23:22 lr 0.000429	time 0.4935 (0.6091)	loss 4.1658 (3.5772)	grad_norm 2.4825 (2.5908)	mem 8931MB
[2022-04-06 08:13:35 large] (main.py 226): INFO Train: [74/300][300/2502]	eta 0:22:14 lr 0.000429	time 0.5352 (0.6061)	loss 4.0188 (3.5827)	grad_norm 2.8348 (2.6017)	mem 8931MB
[2022-04-06 08:14:35 large] (main.py 226): INFO Train: [74/300][400/2502]	eta 0:21:15 lr 0.000429	time 0.6171 (0.6066)	loss 4.3100 (3.6084)	grad_norm 2.8629 (2.6165)	mem 8931MB
[2022-04-06 08:15:36 large] (main.py 226): INFO Train: [74/300][500/2502]	eta 0:20:13 lr 0.000429	time 0.6667 (0.6060)	loss 3.6587 (3.6053)	grad_norm 2.4240 (2.6633)	mem 8931MB
[2022-04-06 08:16:35 large] (main.py 226): INFO Train: [74/300][600/2502]	eta 0:19:09 lr 0.000429	time 0.5978 (0.6043)	loss 4.4108 (3.6211)	grad_norm 3.3966 (2.6613)	mem 8931MB
[2022-04-06 08:17:35 large] (main.py 226): INFO Train: [74/300][700/2502]	eta 0:18:05 lr 0.000429	time 0.5845 (0.6024)	loss 4.0118 (3.6198)	grad_norm 2.4406 (2.6504)	mem 8931MB
[2022-04-06 08:18:34 large] (main.py 226): INFO Train: [74/300][800/2502]	eta 0:17:03 lr 0.000429	time 0.6433 (0.6015)	loss 4.0605 (3.6132)	grad_norm 3.1233 (inf)	mem 8931MB
[2022-04-06 08:19:33 large] (main.py 226): INFO Train: [74/300][900/2502]	eta 0:16:01 lr 0.000429	time 0.5890 (0.6004)	loss 3.0770 (3.6184)	grad_norm 2.3873 (inf)	mem 8931MB
[2022-04-06 08:20:32 large] (main.py 226): INFO Train: [74/300][1000/2502]	eta 0:15:00 lr 0.000429	time 0.6009 (0.5996)	loss 2.5797 (3.6276)	grad_norm 2.5736 (inf)	mem 8931MB
[2022-04-06 08:21:33 large] (main.py 226): INFO Train: [74/300][1100/2502]	eta 0:14:01 lr 0.000429	time 0.6186 (0.6000)	loss 3.9337 (3.6271)	grad_norm 2.7540 (inf)	mem 8931MB
[2022-04-06 08:22:32 large] (main.py 226): INFO Train: [74/300][1200/2502]	eta 0:13:00 lr 0.000428	time 0.6243 (0.5994)	loss 3.9545 (3.6278)	grad_norm 2.5468 (inf)	mem 8931MB
[2022-04-06 08:23:33 large] (main.py 226): INFO Train: [74/300][1300/2502]	eta 0:12:01 lr 0.000428	time 0.6304 (0.6002)	loss 4.4271 (3.6235)	grad_norm 2.3679 (inf)	mem 8931MB
[2022-04-06 08:24:33 large] (main.py 226): INFO Train: [74/300][1400/2502]	eta 0:11:01 lr 0.000428	time 0.5448 (0.6002)	loss 3.8266 (3.6255)	grad_norm 2.7476 (inf)	mem 8931MB
[2022-04-06 08:25:34 large] (main.py 226): INFO Train: [74/300][1500/2502]	eta 0:10:02 lr 0.000428	time 0.6095 (0.6010)	loss 3.8077 (3.6298)	grad_norm 4.0181 (inf)	mem 8931MB
[2022-04-06 08:26:29 large] (main.py 226): INFO Train: [74/300][1600/2502]	eta 0:08:59 lr 0.000428	time 0.6122 (0.5978)	loss 3.0006 (3.6302)	grad_norm 2.5041 (inf)	mem 8931MB
[2022-04-06 08:27:30 large] (main.py 226): INFO Train: [74/300][1700/2502]	eta 0:07:59 lr 0.000428	time 0.6057 (0.5984)	loss 3.9939 (3.6330)	grad_norm 3.6133 (inf)	mem 8931MB
[2022-04-06 08:28:31 large] (main.py 226): INFO Train: [74/300][1800/2502]	eta 0:07:00 lr 0.000428	time 0.5991 (0.5990)	loss 3.1666 (3.6316)	grad_norm 2.5385 (inf)	mem 8931MB
[2022-04-06 08:29:31 large] (main.py 226): INFO Train: [74/300][1900/2502]	eta 0:06:00 lr 0.000428	time 0.5284 (0.5990)	loss 4.0872 (3.6309)	grad_norm 2.4435 (inf)	mem 8931MB
[2022-04-06 08:30:32 large] (main.py 226): INFO Train: [74/300][2000/2502]	eta 0:05:00 lr 0.000428	time 0.6080 (0.5994)	loss 4.4154 (3.6260)	grad_norm 2.5045 (inf)	mem 8931MB
[2022-04-06 08:31:32 large] (main.py 226): INFO Train: [74/300][2100/2502]	eta 0:04:00 lr 0.000428	time 0.6502 (0.5994)	loss 4.0894 (3.6211)	grad_norm 2.1317 (inf)	mem 8931MB
[2022-04-06 08:32:31 large] (main.py 226): INFO Train: [74/300][2200/2502]	eta 0:03:00 lr 0.000428	time 0.6373 (0.5993)	loss 4.0752 (3.6201)	grad_norm 3.3243 (inf)	mem 8931MB
[2022-04-06 08:33:31 large] (main.py 226): INFO Train: [74/300][2300/2502]	eta 0:02:01 lr 0.000428	time 0.6029 (0.5994)	loss 3.3017 (3.6194)	grad_norm 2.6323 (inf)	mem 8931MB
[2022-04-06 08:34:31 large] (main.py 226): INFO Train: [74/300][2400/2502]	eta 0:01:01 lr 0.000428	time 0.5804 (0.5992)	loss 3.1612 (3.6208)	grad_norm 2.4678 (inf)	mem 8931MB
[2022-04-06 08:35:27 large] (main.py 226): INFO Train: [74/300][2500/2502]	eta 0:00:01 lr 0.000428	time 0.4942 (0.5978)	loss 3.3304 (3.6175)	grad_norm 2.5619 (inf)	mem 8931MB
[2022-04-06 08:35:28 large] (main.py 233): INFO EPOCH 74 training takes 0:24:56
[2022-04-06 08:35:35 large] (main.py 273): INFO Test: [0/98]	Time 6.224 (6.224)	Loss 1.1645 (1.1645)	Acc@1 72.656 (72.656)	Acc@5 92.383 (92.383)	Mem 8931MB
[2022-04-06 08:36:00 large] (main.py 279): INFO  * Acc@1 73.838 Acc@5 91.940
[2022-04-06 08:36:00 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 73.8%
[2022-04-06 08:36:00 large] (utils.py 57): INFO output/large/default/ckpt_epoch_74.pth saving......
[2022-04-06 08:36:01 large] (utils.py 59): INFO output/large/default/ckpt_epoch_74.pth saved !!!
[2022-04-06 08:36:01 large] (main.py 148): INFO Max accuracy: 73.84%
[2022-04-06 08:36:09 large] (main.py 226): INFO Train: [75/300][0/2502]	eta 5:44:19 lr 0.000428	time 8.2573 (8.2573)	loss 4.0652 (4.0652)	grad_norm 2.1336 (2.1336)	mem 8931MB
[2022-04-06 08:36:58 large] (main.py 226): INFO Train: [75/300][100/2502]	eta 0:22:36 lr 0.000427	time 0.5084 (0.5649)	loss 2.8328 (3.6416)	grad_norm 2.5328 (2.6200)	mem 8931MB
[2022-04-06 08:37:59 large] (main.py 226): INFO Train: [75/300][200/2502]	eta 0:22:25 lr 0.000427	time 0.6344 (0.5847)	loss 3.0743 (3.6078)	grad_norm 2.5717 (2.6418)	mem 8931MB
[2022-04-06 08:39:01 large] (main.py 226): INFO Train: [75/300][300/2502]	eta 0:21:58 lr 0.000427	time 0.6490 (0.5987)	loss 3.7858 (3.5954)	grad_norm 2.6378 (nan)	mem 8931MB
[2022-04-06 08:40:04 large] (main.py 226): INFO Train: [75/300][400/2502]	eta 0:21:15 lr 0.000427	time 0.5861 (0.6066)	loss 2.8364 (3.5771)	grad_norm 3.2647 (nan)	mem 8931MB
[2022-04-06 08:41:06 large] (main.py 226): INFO Train: [75/300][500/2502]	eta 0:20:18 lr 0.000427	time 0.5352 (0.6087)	loss 4.1551 (3.5548)	grad_norm 2.8784 (nan)	mem 8931MB
[2022-04-06 08:42:07 large] (main.py 226): INFO Train: [75/300][600/2502]	eta 0:19:19 lr 0.000427	time 0.6378 (0.6096)	loss 2.4671 (3.5622)	grad_norm 2.7312 (nan)	mem 8931MB
[2022-04-06 08:43:07 large] (main.py 226): INFO Train: [75/300][700/2502]	eta 0:18:14 lr 0.000427	time 0.6186 (0.6072)	loss 3.0365 (3.5743)	grad_norm 2.3992 (nan)	mem 8931MB
[2022-04-06 08:44:08 large] (main.py 226): INFO Train: [75/300][800/2502]	eta 0:17:13 lr 0.000427	time 0.5772 (0.6075)	loss 2.8988 (3.5782)	grad_norm 2.2208 (nan)	mem 8931MB
[2022-04-06 08:45:08 large] (main.py 226): INFO Train: [75/300][900/2502]	eta 0:16:12 lr 0.000427	time 0.6299 (0.6073)	loss 3.7444 (3.5833)	grad_norm 2.5754 (nan)	mem 8931MB
[2022-04-06 08:46:09 large] (main.py 226): INFO Train: [75/300][1000/2502]	eta 0:15:11 lr 0.000427	time 0.5802 (0.6071)	loss 3.6441 (3.5848)	grad_norm 2.5662 (nan)	mem 8931MB
[2022-04-06 08:47:09 large] (main.py 226): INFO Train: [75/300][1100/2502]	eta 0:14:10 lr 0.000427	time 0.7055 (0.6065)	loss 3.7774 (3.5913)	grad_norm 2.3721 (nan)	mem 8931MB
[2022-04-06 08:48:09 large] (main.py 226): INFO Train: [75/300][1200/2502]	eta 0:13:09 lr 0.000427	time 0.6578 (0.6064)	loss 3.7693 (3.5869)	grad_norm 1.7761 (nan)	mem 8931MB
[2022-04-06 08:49:09 large] (main.py 226): INFO Train: [75/300][1300/2502]	eta 0:12:08 lr 0.000427	time 0.6875 (0.6059)	loss 4.1120 (3.5875)	grad_norm 2.7682 (nan)	mem 8931MB
[2022-04-06 08:50:09 large] (main.py 226): INFO Train: [75/300][1400/2502]	eta 0:11:06 lr 0.000426	time 0.5992 (0.6051)	loss 3.1845 (3.5950)	grad_norm 2.7072 (nan)	mem 8931MB
[2022-04-06 08:51:10 large] (main.py 226): INFO Train: [75/300][1500/2502]	eta 0:10:06 lr 0.000426	time 0.6333 (0.6054)	loss 4.0922 (3.5974)	grad_norm 2.6597 (nan)	mem 8931MB
[2022-04-06 08:52:11 large] (main.py 226): INFO Train: [75/300][1600/2502]	eta 0:09:06 lr 0.000426	time 0.6160 (0.6059)	loss 3.8541 (3.5972)	grad_norm 2.7433 (nan)	mem 8931MB
[2022-04-06 08:53:11 large] (main.py 226): INFO Train: [75/300][1700/2502]	eta 0:08:05 lr 0.000426	time 0.5331 (0.6056)	loss 3.9882 (3.6013)	grad_norm 1.9140 (nan)	mem 8931MB
[2022-04-06 08:54:13 large] (main.py 226): INFO Train: [75/300][1800/2502]	eta 0:07:05 lr 0.000426	time 0.5217 (0.6062)	loss 4.1730 (3.6039)	grad_norm 2.9127 (nan)	mem 8931MB
[2022-04-06 08:55:15 large] (main.py 226): INFO Train: [75/300][1900/2502]	eta 0:06:05 lr 0.000426	time 0.5808 (0.6067)	loss 4.5490 (3.6055)	grad_norm 2.5474 (nan)	mem 8931MB
[2022-04-06 08:56:15 large] (main.py 226): INFO Train: [75/300][2000/2502]	eta 0:05:04 lr 0.000426	time 0.5215 (0.6067)	loss 2.7869 (3.6055)	grad_norm 2.3676 (nan)	mem 8931MB
[2022-04-06 08:57:17 large] (main.py 226): INFO Train: [75/300][2100/2502]	eta 0:04:04 lr 0.000426	time 0.6391 (0.6072)	loss 3.1956 (3.6103)	grad_norm 3.3282 (nan)	mem 8931MB
[2022-04-06 08:58:18 large] (main.py 226): INFO Train: [75/300][2200/2502]	eta 0:03:03 lr 0.000426	time 0.7275 (0.6075)	loss 3.8740 (3.6131)	grad_norm 2.8755 (nan)	mem 8931MB
[2022-04-06 08:59:19 large] (main.py 226): INFO Train: [75/300][2300/2502]	eta 0:02:02 lr 0.000426	time 0.5935 (0.6077)	loss 3.5141 (3.6175)	grad_norm 2.7519 (nan)	mem 8931MB
[2022-04-06 09:00:20 large] (main.py 226): INFO Train: [75/300][2400/2502]	eta 0:01:01 lr 0.000426	time 0.6536 (0.6077)	loss 2.7292 (3.6178)	grad_norm 2.7038 (nan)	mem 8931MB
[2022-04-06 09:01:20 large] (main.py 226): INFO Train: [75/300][2500/2502]	eta 0:00:01 lr 0.000426	time 0.5475 (0.6072)	loss 3.7368 (3.6216)	grad_norm 2.3342 (nan)	mem 8931MB
[2022-04-06 09:01:21 large] (main.py 233): INFO EPOCH 75 training takes 0:25:19
[2022-04-06 09:01:28 large] (main.py 273): INFO Test: [0/98]	Time 6.715 (6.715)	Loss 1.2719 (1.2719)	Acc@1 74.023 (74.023)	Acc@5 91.406 (91.406)	Mem 8931MB
[2022-04-06 09:01:53 large] (main.py 279): INFO  * Acc@1 73.964 Acc@5 92.090
[2022-04-06 09:01:53 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 74.0%
[2022-04-06 09:01:53 large] (utils.py 57): INFO output/large/default/ckpt_epoch_75.pth saving......
[2022-04-06 09:01:54 large] (utils.py 59): INFO output/large/default/ckpt_epoch_75.pth saved !!!
[2022-04-06 09:01:54 large] (main.py 148): INFO Max accuracy: 73.96%
[2022-04-06 09:02:01 large] (main.py 226): INFO Train: [76/300][0/2502]	eta 5:09:57 lr 0.000426	time 7.4330 (7.4330)	loss 4.3052 (4.3052)	grad_norm 2.6812 (2.6812)	mem 8931MB
[2022-04-06 09:02:59 large] (main.py 226): INFO Train: [76/300][100/2502]	eta 0:25:39 lr 0.000426	time 0.6176 (0.6408)	loss 4.1104 (3.6116)	grad_norm 2.2243 (2.7648)	mem 8931MB
[2022-04-06 09:04:00 large] (main.py 226): INFO Train: [76/300][200/2502]	eta 0:24:05 lr 0.000426	time 0.6207 (0.6278)	loss 2.5317 (3.6186)	grad_norm 1.9699 (2.6906)	mem 8931MB
[2022-04-06 09:05:01 large] (main.py 226): INFO Train: [76/300][300/2502]	eta 0:22:51 lr 0.000425	time 0.6619 (0.6227)	loss 2.7606 (3.6323)	grad_norm 3.2810 (nan)	mem 8931MB
[2022-04-06 09:06:02 large] (main.py 226): INFO Train: [76/300][400/2502]	eta 0:21:42 lr 0.000425	time 0.6039 (0.6194)	loss 3.7336 (3.6183)	grad_norm 2.6384 (nan)	mem 8931MB
[2022-04-06 09:07:02 large] (main.py 226): INFO Train: [76/300][500/2502]	eta 0:20:32 lr 0.000425	time 0.6169 (0.6155)	loss 3.9927 (3.6112)	grad_norm 4.5106 (nan)	mem 8931MB
[2022-04-06 09:08:03 large] (main.py 226): INFO Train: [76/300][600/2502]	eta 0:19:29 lr 0.000425	time 0.6291 (0.6148)	loss 3.6992 (3.5937)	grad_norm 2.3109 (nan)	mem 8931MB
[2022-04-06 09:09:04 large] (main.py 226): INFO Train: [76/300][700/2502]	eta 0:18:24 lr 0.000425	time 0.5874 (0.6130)	loss 3.1330 (3.5988)	grad_norm 2.3290 (nan)	mem 8931MB
[2022-04-06 09:10:04 large] (main.py 226): INFO Train: [76/300][800/2502]	eta 0:17:21 lr 0.000425	time 0.5602 (0.6116)	loss 4.1465 (3.5926)	grad_norm 2.8618 (nan)	mem 8931MB
[2022-04-06 09:11:05 large] (main.py 226): INFO Train: [76/300][900/2502]	eta 0:16:20 lr 0.000425	time 0.5575 (0.6120)	loss 3.5855 (3.6063)	grad_norm 2.3167 (nan)	mem 8931MB
[2022-04-06 09:12:06 large] (main.py 226): INFO Train: [76/300][1000/2502]	eta 0:15:18 lr 0.000425	time 0.5905 (0.6116)	loss 3.7117 (3.6075)	grad_norm 2.4498 (nan)	mem 8931MB
[2022-04-06 09:13:08 large] (main.py 226): INFO Train: [76/300][1100/2502]	eta 0:14:18 lr 0.000425	time 0.5530 (0.6121)	loss 4.2108 (3.6045)	grad_norm 2.3793 (nan)	mem 8931MB
[2022-04-06 09:14:08 large] (main.py 226): INFO Train: [76/300][1200/2502]	eta 0:13:15 lr 0.000425	time 0.6497 (0.6110)	loss 4.1872 (3.6116)	grad_norm 2.3856 (nan)	mem 8931MB
[2022-04-06 09:15:08 large] (main.py 226): INFO Train: [76/300][1300/2502]	eta 0:12:14 lr 0.000425	time 0.6086 (0.6108)	loss 4.3130 (3.6037)	grad_norm 2.6667 (nan)	mem 8931MB
[2022-04-06 09:16:09 large] (main.py 226): INFO Train: [76/300][1400/2502]	eta 0:11:12 lr 0.000425	time 0.6745 (0.6104)	loss 3.7865 (3.6021)	grad_norm 2.7114 (nan)	mem 8931MB
[2022-04-06 09:17:10 large] (main.py 226): INFO Train: [76/300][1500/2502]	eta 0:10:11 lr 0.000425	time 0.6395 (0.6102)	loss 3.8153 (3.6018)	grad_norm 2.7546 (nan)	mem 8931MB
[2022-04-06 09:18:11 large] (main.py 226): INFO Train: [76/300][1600/2502]	eta 0:09:10 lr 0.000424	time 0.5576 (0.6104)	loss 2.5449 (3.6013)	grad_norm 2.7384 (nan)	mem 8931MB
[2022-04-06 09:19:11 large] (main.py 226): INFO Train: [76/300][1700/2502]	eta 0:08:09 lr 0.000424	time 0.6008 (0.6099)	loss 2.8727 (3.6029)	grad_norm 2.3163 (nan)	mem 8931MB
[2022-04-06 09:20:12 large] (main.py 226): INFO Train: [76/300][1800/2502]	eta 0:07:08 lr 0.000424	time 0.5886 (0.6097)	loss 4.6129 (3.6020)	grad_norm 2.1185 (nan)	mem 8931MB
[2022-04-06 09:21:13 large] (main.py 226): INFO Train: [76/300][1900/2502]	eta 0:06:06 lr 0.000424	time 0.6270 (0.6096)	loss 4.2736 (3.6052)	grad_norm 2.8405 (nan)	mem 8931MB
[2022-04-06 09:22:13 large] (main.py 226): INFO Train: [76/300][2000/2502]	eta 0:05:05 lr 0.000424	time 0.6255 (0.6094)	loss 4.1424 (3.6050)	grad_norm 3.3939 (nan)	mem 8931MB
[2022-04-06 09:23:14 large] (main.py 226): INFO Train: [76/300][2100/2502]	eta 0:04:05 lr 0.000424	time 0.4957 (0.6095)	loss 3.1317 (3.6051)	grad_norm 2.9456 (nan)	mem 8931MB
[2022-04-06 09:24:15 large] (main.py 226): INFO Train: [76/300][2200/2502]	eta 0:03:03 lr 0.000424	time 0.5608 (0.6092)	loss 3.1025 (3.6040)	grad_norm 2.3889 (nan)	mem 8931MB
[2022-04-06 09:25:16 large] (main.py 226): INFO Train: [76/300][2300/2502]	eta 0:02:03 lr 0.000424	time 0.5750 (0.6095)	loss 3.6084 (3.6045)	grad_norm 3.0545 (nan)	mem 8931MB
[2022-04-06 09:26:16 large] (main.py 226): INFO Train: [76/300][2400/2502]	eta 0:01:02 lr 0.000424	time 0.6070 (0.6092)	loss 4.2140 (3.6031)	grad_norm 2.3273 (nan)	mem 8931MB
[2022-04-06 09:27:17 large] (main.py 226): INFO Train: [76/300][2500/2502]	eta 0:00:01 lr 0.000424	time 0.5345 (0.6089)	loss 4.2907 (3.6007)	grad_norm 2.9054 (nan)	mem 8931MB
[2022-04-06 09:27:18 large] (main.py 233): INFO EPOCH 76 training takes 0:25:23
[2022-04-06 09:27:24 large] (main.py 273): INFO Test: [0/98]	Time 6.517 (6.517)	Loss 1.2564 (1.2564)	Acc@1 71.484 (71.484)	Acc@5 92.969 (92.969)	Mem 8931MB
[2022-04-06 09:27:50 large] (main.py 279): INFO  * Acc@1 74.084 Acc@5 92.218
[2022-04-06 09:27:50 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 74.1%
[2022-04-06 09:27:50 large] (utils.py 57): INFO output/large/default/ckpt_epoch_76.pth saving......
[2022-04-06 09:27:51 large] (utils.py 59): INFO output/large/default/ckpt_epoch_76.pth saved !!!
[2022-04-06 09:27:51 large] (main.py 148): INFO Max accuracy: 74.08%
[2022-04-06 09:27:59 large] (main.py 226): INFO Train: [77/300][0/2502]	eta 5:29:07 lr 0.000424	time 7.8928 (7.8928)	loss 3.1127 (3.1127)	grad_norm 2.6151 (2.6151)	mem 8931MB
[2022-04-06 09:28:54 large] (main.py 226): INFO Train: [77/300][100/2502]	eta 0:25:02 lr 0.000424	time 0.6002 (0.6256)	loss 4.4595 (3.5129)	grad_norm 3.2314 (2.7399)	mem 8931MB
[2022-04-06 09:29:57 large] (main.py 226): INFO Train: [77/300][200/2502]	eta 0:24:07 lr 0.000424	time 0.6194 (0.6290)	loss 4.0114 (3.5865)	grad_norm 2.5481 (2.7058)	mem 8931MB
[2022-04-06 09:30:57 large] (main.py 226): INFO Train: [77/300][300/2502]	eta 0:22:45 lr 0.000424	time 0.6933 (0.6202)	loss 3.4327 (3.5713)	grad_norm 3.1514 (2.6825)	mem 8931MB
[2022-04-06 09:31:59 large] (main.py 226): INFO Train: [77/300][400/2502]	eta 0:21:42 lr 0.000424	time 0.6056 (0.6196)	loss 3.8764 (3.5682)	grad_norm 2.6373 (2.6924)	mem 8931MB
[2022-04-06 09:33:01 large] (main.py 226): INFO Train: [77/300][500/2502]	eta 0:20:41 lr 0.000423	time 0.6721 (0.6203)	loss 3.5945 (3.5584)	grad_norm 2.3459 (2.7074)	mem 8931MB
[2022-04-06 09:34:03 large] (main.py 226): INFO Train: [77/300][600/2502]	eta 0:19:38 lr 0.000423	time 0.6205 (0.6198)	loss 2.8836 (3.5680)	grad_norm 2.9462 (2.6849)	mem 8931MB
[2022-04-06 09:35:05 large] (main.py 226): INFO Train: [77/300][700/2502]	eta 0:18:36 lr 0.000423	time 0.5786 (0.6193)	loss 4.0808 (3.5800)	grad_norm 3.1610 (2.6977)	mem 8931MB
[2022-04-06 09:36:07 large] (main.py 226): INFO Train: [77/300][800/2502]	eta 0:17:34 lr 0.000423	time 0.5725 (0.6196)	loss 4.6355 (3.5826)	grad_norm 2.4506 (2.6987)	mem 8931MB
[2022-04-06 09:37:08 large] (main.py 226): INFO Train: [77/300][900/2502]	eta 0:16:30 lr 0.000423	time 0.6136 (0.6186)	loss 3.2414 (3.5750)	grad_norm 2.5089 (2.6862)	mem 8931MB
[2022-04-06 09:38:09 large] (main.py 226): INFO Train: [77/300][1000/2502]	eta 0:15:28 lr 0.000423	time 0.6408 (0.6179)	loss 4.2894 (3.5702)	grad_norm 2.7914 (2.6806)	mem 8931MB
[2022-04-06 09:39:11 large] (main.py 226): INFO Train: [77/300][1100/2502]	eta 0:14:26 lr 0.000423	time 0.5766 (0.6181)	loss 3.9259 (3.5725)	grad_norm 2.3660 (2.6890)	mem 8931MB
[2022-04-06 09:40:12 large] (main.py 226): INFO Train: [77/300][1200/2502]	eta 0:13:24 lr 0.000423	time 0.5407 (0.6176)	loss 3.2100 (3.5787)	grad_norm 2.6000 (2.6892)	mem 8931MB
[2022-04-06 09:41:06 large] (main.py 226): INFO Train: [77/300][1300/2502]	eta 0:12:14 lr 0.000423	time 0.6547 (0.6114)	loss 4.0395 (3.5814)	grad_norm 2.9569 (2.6945)	mem 8931MB
[2022-04-06 09:42:07 large] (main.py 226): INFO Train: [77/300][1400/2502]	eta 0:11:13 lr 0.000423	time 0.6031 (0.6114)	loss 3.9404 (3.5780)	grad_norm 2.7806 (2.6960)	mem 8931MB
[2022-04-06 09:43:08 large] (main.py 226): INFO Train: [77/300][1500/2502]	eta 0:10:12 lr 0.000423	time 0.6137 (0.6110)	loss 3.5598 (3.5777)	grad_norm 2.4098 (2.6972)	mem 8931MB
[2022-04-06 09:44:09 large] (main.py 226): INFO Train: [77/300][1600/2502]	eta 0:09:11 lr 0.000423	time 0.5949 (0.6113)	loss 3.4801 (3.5836)	grad_norm 2.5497 (2.6976)	mem 8931MB
[2022-04-06 09:45:11 large] (main.py 226): INFO Train: [77/300][1700/2502]	eta 0:08:10 lr 0.000423	time 0.4895 (0.6115)	loss 3.6339 (3.5799)	grad_norm 2.8455 (2.7029)	mem 8931MB
[2022-04-06 09:46:13 large] (main.py 226): INFO Train: [77/300][1800/2502]	eta 0:07:09 lr 0.000422	time 0.6331 (0.6121)	loss 2.8378 (3.5792)	grad_norm 2.7023 (2.7060)	mem 8931MB
[2022-04-06 09:47:15 large] (main.py 226): INFO Train: [77/300][1900/2502]	eta 0:06:08 lr 0.000422	time 0.5813 (0.6122)	loss 4.1695 (3.5809)	grad_norm 2.5471 (2.6999)	mem 8931MB
[2022-04-06 09:48:14 large] (main.py 226): INFO Train: [77/300][2000/2502]	eta 0:05:06 lr 0.000422	time 0.5653 (0.6115)	loss 3.4244 (3.5865)	grad_norm 2.6404 (2.7001)	mem 8931MB
[2022-04-06 09:49:15 large] (main.py 226): INFO Train: [77/300][2100/2502]	eta 0:04:05 lr 0.000422	time 0.6060 (0.6115)	loss 3.5212 (3.5888)	grad_norm 2.2159 (2.7000)	mem 8931MB
[2022-04-06 09:50:16 large] (main.py 226): INFO Train: [77/300][2200/2502]	eta 0:03:04 lr 0.000422	time 0.5766 (0.6114)	loss 4.2669 (3.5919)	grad_norm 2.2204 (2.7005)	mem 8931MB
[2022-04-06 09:51:17 large] (main.py 226): INFO Train: [77/300][2300/2502]	eta 0:02:03 lr 0.000422	time 0.5293 (0.6112)	loss 3.8672 (3.5958)	grad_norm 2.4746 (nan)	mem 8931MB
[2022-04-06 09:52:19 large] (main.py 226): INFO Train: [77/300][2400/2502]	eta 0:01:02 lr 0.000422	time 0.7168 (0.6117)	loss 2.4383 (3.5938)	grad_norm 1.8747 (nan)	mem 8931MB
[2022-04-06 09:53:21 large] (main.py 226): INFO Train: [77/300][2500/2502]	eta 0:00:01 lr 0.000422	time 0.5922 (0.6118)	loss 4.5314 (3.5914)	grad_norm 2.4127 (nan)	mem 8931MB
[2022-04-06 09:53:22 large] (main.py 233): INFO EPOCH 77 training takes 0:25:31
[2022-04-06 09:53:28 large] (main.py 273): INFO Test: [0/98]	Time 6.405 (6.405)	Loss 1.1254 (1.1254)	Acc@1 76.758 (76.758)	Acc@5 93.945 (93.945)	Mem 8931MB
[2022-04-06 09:53:55 large] (main.py 279): INFO  * Acc@1 73.874 Acc@5 92.184
[2022-04-06 09:53:55 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 73.9%
[2022-04-06 09:53:55 large] (main.py 148): INFO Max accuracy: 74.08%
[2022-04-06 09:54:02 large] (main.py 226): INFO Train: [78/300][0/2502]	eta 5:03:46 lr 0.000422	time 7.2848 (7.2848)	loss 4.2939 (4.2939)	grad_norm 2.5518 (2.5518)	mem 8931MB
[2022-04-06 09:55:00 large] (main.py 226): INFO Train: [78/300][100/2502]	eta 0:25:47 lr 0.000422	time 0.6596 (0.6442)	loss 4.2732 (3.6371)	grad_norm 2.4296 (nan)	mem 8931MB
[2022-04-06 09:56:02 large] (main.py 226): INFO Train: [78/300][200/2502]	eta 0:24:10 lr 0.000422	time 0.5138 (0.6301)	loss 4.1078 (3.6121)	grad_norm 2.6425 (nan)	mem 8931MB
[2022-04-06 09:57:02 large] (main.py 226): INFO Train: [78/300][300/2502]	eta 0:22:52 lr 0.000422	time 0.7191 (0.6232)	loss 4.0049 (3.5936)	grad_norm 2.7546 (nan)	mem 8931MB
[2022-04-06 09:58:04 large] (main.py 226): INFO Train: [78/300][400/2502]	eta 0:21:47 lr 0.000422	time 0.5829 (0.6219)	loss 3.8500 (3.5794)	grad_norm 3.2511 (nan)	mem 8931MB
[2022-04-06 09:59:06 large] (main.py 226): INFO Train: [78/300][500/2502]	eta 0:20:42 lr 0.000422	time 0.7101 (0.6206)	loss 3.6635 (3.5924)	grad_norm 2.3141 (nan)	mem 8931MB
[2022-04-06 10:00:07 large] (main.py 226): INFO Train: [78/300][600/2502]	eta 0:19:37 lr 0.000421	time 0.5451 (0.6191)	loss 3.9615 (3.5937)	grad_norm 2.3814 (nan)	mem 8931MB
[2022-04-06 10:01:09 large] (main.py 226): INFO Train: [78/300][700/2502]	eta 0:18:34 lr 0.000421	time 0.6207 (0.6186)	loss 3.8978 (3.5948)	grad_norm 2.9332 (nan)	mem 8931MB
[2022-04-06 10:02:11 large] (main.py 226): INFO Train: [78/300][800/2502]	eta 0:17:34 lr 0.000421	time 0.6843 (0.6198)	loss 3.9367 (3.5957)	grad_norm 2.7551 (nan)	mem 8931MB
[2022-04-06 10:03:12 large] (main.py 226): INFO Train: [78/300][900/2502]	eta 0:16:30 lr 0.000421	time 0.6058 (0.6183)	loss 4.1667 (3.6054)	grad_norm 3.5811 (nan)	mem 8931MB
[2022-04-06 10:04:14 large] (main.py 226): INFO Train: [78/300][1000/2502]	eta 0:15:29 lr 0.000421	time 0.6689 (0.6188)	loss 4.0931 (3.6071)	grad_norm 2.9450 (nan)	mem 8931MB
[2022-04-06 10:05:17 large] (main.py 226): INFO Train: [78/300][1100/2502]	eta 0:14:28 lr 0.000421	time 0.6989 (0.6197)	loss 3.4446 (3.6086)	grad_norm 3.4605 (nan)	mem 8931MB
[2022-04-06 10:06:18 large] (main.py 226): INFO Train: [78/300][1200/2502]	eta 0:13:25 lr 0.000421	time 0.6168 (0.6189)	loss 2.5103 (3.6051)	grad_norm 3.1023 (nan)	mem 8931MB
[2022-04-06 10:07:21 large] (main.py 226): INFO Train: [78/300][1300/2502]	eta 0:12:24 lr 0.000421	time 0.6424 (0.6193)	loss 4.6457 (3.6125)	grad_norm 2.6591 (nan)	mem 8931MB
[2022-04-06 10:08:22 large] (main.py 226): INFO Train: [78/300][1400/2502]	eta 0:11:22 lr 0.000421	time 0.6269 (0.6192)	loss 3.5481 (3.6091)	grad_norm 3.2796 (nan)	mem 8931MB
[2022-04-06 10:09:24 large] (main.py 226): INFO Train: [78/300][1500/2502]	eta 0:10:20 lr 0.000421	time 0.6062 (0.6190)	loss 3.5475 (3.6135)	grad_norm 2.3383 (nan)	mem 8931MB
[2022-04-06 10:10:26 large] (main.py 226): INFO Train: [78/300][1600/2502]	eta 0:09:18 lr 0.000421	time 0.6442 (0.6192)	loss 3.8757 (3.6099)	grad_norm 3.3589 (nan)	mem 8931MB
[2022-04-06 10:11:28 large] (main.py 226): INFO Train: [78/300][1700/2502]	eta 0:08:16 lr 0.000421	time 0.6409 (0.6190)	loss 2.6599 (3.6062)	grad_norm 3.2157 (nan)	mem 8931MB
[2022-04-06 10:12:31 large] (main.py 226): INFO Train: [78/300][1800/2502]	eta 0:07:14 lr 0.000421	time 0.5957 (0.6195)	loss 4.1595 (3.6047)	grad_norm 2.4539 (nan)	mem 8931MB
[2022-04-06 10:13:32 large] (main.py 226): INFO Train: [78/300][1900/2502]	eta 0:06:12 lr 0.000420	time 0.7330 (0.6190)	loss 3.4985 (3.6073)	grad_norm 2.0337 (nan)	mem 8931MB
[2022-04-06 10:14:33 large] (main.py 226): INFO Train: [78/300][2000/2502]	eta 0:05:10 lr 0.000420	time 0.5782 (0.6187)	loss 4.1436 (3.6067)	grad_norm 2.3443 (nan)	mem 8931MB
[2022-04-06 10:15:34 large] (main.py 226): INFO Train: [78/300][2100/2502]	eta 0:04:08 lr 0.000420	time 0.6215 (0.6185)	loss 3.6825 (3.6062)	grad_norm 2.4448 (nan)	mem 8931MB
[2022-04-06 10:16:36 large] (main.py 226): INFO Train: [78/300][2200/2502]	eta 0:03:06 lr 0.000420	time 0.5786 (0.6184)	loss 2.6005 (3.6069)	grad_norm 2.2706 (nan)	mem 8931MB
[2022-04-06 10:17:38 large] (main.py 226): INFO Train: [78/300][2300/2502]	eta 0:02:04 lr 0.000420	time 0.7802 (0.6187)	loss 4.2833 (3.6058)	grad_norm 2.8611 (nan)	mem 8931MB
[2022-04-06 10:18:40 large] (main.py 226): INFO Train: [78/300][2400/2502]	eta 0:01:03 lr 0.000420	time 0.5042 (0.6185)	loss 3.9150 (3.6041)	grad_norm 3.2928 (nan)	mem 8931MB
[2022-04-06 10:19:40 large] (main.py 226): INFO Train: [78/300][2500/2502]	eta 0:00:01 lr 0.000420	time 0.6014 (0.6179)	loss 3.6472 (3.6017)	grad_norm 2.4685 (nan)	mem 8931MB
[2022-04-06 10:19:41 large] (main.py 233): INFO EPOCH 78 training takes 0:25:46
[2022-04-06 10:19:48 large] (main.py 273): INFO Test: [0/98]	Time 6.628 (6.628)	Loss 1.3688 (1.3688)	Acc@1 70.508 (70.508)	Acc@5 90.039 (90.039)	Mem 8931MB
[2022-04-06 10:20:14 large] (main.py 279): INFO  * Acc@1 73.920 Acc@5 92.076
[2022-04-06 10:20:14 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 73.9%
[2022-04-06 10:20:14 large] (main.py 148): INFO Max accuracy: 74.08%
[2022-04-06 10:20:20 large] (main.py 226): INFO Train: [79/300][0/2502]	eta 4:39:01 lr 0.000420	time 6.6912 (6.6912)	loss 2.8723 (2.8723)	grad_norm 2.4866 (2.4866)	mem 8931MB
[2022-04-06 10:21:11 large] (main.py 226): INFO Train: [79/300][100/2502]	eta 0:22:46 lr 0.000420	time 0.5431 (0.5691)	loss 4.2389 (3.6802)	grad_norm 2.3606 (2.6592)	mem 8931MB
[2022-04-06 10:22:12 large] (main.py 226): INFO Train: [79/300][200/2502]	eta 0:22:33 lr 0.000420	time 0.6318 (0.5882)	loss 3.3694 (3.6345)	grad_norm 2.7234 (2.6920)	mem 8931MB
[2022-04-06 10:23:14 large] (main.py 226): INFO Train: [79/300][300/2502]	eta 0:22:03 lr 0.000420	time 0.6780 (0.6011)	loss 3.9216 (3.5994)	grad_norm 2.1354 (2.7034)	mem 8931MB
[2022-04-06 10:24:17 large] (main.py 226): INFO Train: [79/300][400/2502]	eta 0:21:18 lr 0.000420	time 0.5475 (0.6083)	loss 3.2836 (3.6043)	grad_norm 2.7352 (2.7164)	mem 8931MB
[2022-04-06 10:25:20 large] (main.py 226): INFO Train: [79/300][500/2502]	eta 0:20:25 lr 0.000420	time 0.5802 (0.6122)	loss 3.8224 (3.5981)	grad_norm 2.1532 (2.7169)	mem 8931MB
[2022-04-06 10:26:23 large] (main.py 226): INFO Train: [79/300][600/2502]	eta 0:19:27 lr 0.000420	time 0.6258 (0.6139)	loss 4.1419 (3.6093)	grad_norm 1.9689 (2.7109)	mem 8931MB
[2022-04-06 10:27:25 large] (main.py 226): INFO Train: [79/300][700/2502]	eta 0:18:29 lr 0.000419	time 0.6328 (0.6156)	loss 3.1563 (3.6186)	grad_norm 3.8007 (2.7102)	mem 8931MB
[2022-04-06 10:28:28 large] (main.py 226): INFO Train: [79/300][800/2502]	eta 0:17:30 lr 0.000419	time 0.5580 (0.6171)	loss 2.5494 (3.6119)	grad_norm 2.3278 (2.7156)	mem 8931MB
[2022-04-06 10:29:31 large] (main.py 226): INFO Train: [79/300][900/2502]	eta 0:16:30 lr 0.000419	time 0.6978 (0.6182)	loss 4.3358 (3.6175)	grad_norm 2.6157 (2.7139)	mem 8931MB
[2022-04-06 10:30:33 large] (main.py 226): INFO Train: [79/300][1000/2502]	eta 0:15:28 lr 0.000419	time 0.5082 (0.6183)	loss 3.9423 (3.6177)	grad_norm 2.2683 (2.7089)	mem 8931MB
[2022-04-06 10:31:35 large] (main.py 226): INFO Train: [79/300][1100/2502]	eta 0:14:28 lr 0.000419	time 0.5045 (0.6193)	loss 4.1710 (3.6191)	grad_norm 2.7666 (2.7110)	mem 8931MB
[2022-04-06 10:32:37 large] (main.py 226): INFO Train: [79/300][1200/2502]	eta 0:13:26 lr 0.000419	time 0.6120 (0.6193)	loss 3.8657 (3.6158)	grad_norm 2.9053 (2.7016)	mem 8931MB
[2022-04-06 10:33:40 large] (main.py 226): INFO Train: [79/300][1300/2502]	eta 0:12:24 lr 0.000419	time 0.6586 (0.6195)	loss 3.4388 (3.6149)	grad_norm 2.2163 (2.6983)	mem 8931MB
[2022-04-06 10:34:42 large] (main.py 226): INFO Train: [79/300][1400/2502]	eta 0:11:23 lr 0.000419	time 0.6131 (0.6200)	loss 3.6499 (3.6089)	grad_norm 2.4508 (2.7044)	mem 8931MB
[2022-04-06 10:35:44 large] (main.py 226): INFO Train: [79/300][1500/2502]	eta 0:10:21 lr 0.000419	time 0.6154 (0.6201)	loss 2.9003 (3.6111)	grad_norm 3.7428 (2.7114)	mem 8931MB
[2022-04-06 10:36:46 large] (main.py 226): INFO Train: [79/300][1600/2502]	eta 0:09:19 lr 0.000419	time 0.6847 (0.6201)	loss 3.7475 (3.6132)	grad_norm 2.3851 (inf)	mem 8931MB
[2022-04-06 10:37:41 large] (main.py 226): INFO Train: [79/300][1700/2502]	eta 0:08:14 lr 0.000419	time 0.7578 (0.6160)	loss 4.2813 (3.6060)	grad_norm 2.7171 (inf)	mem 8931MB
[2022-04-06 10:38:44 large] (main.py 226): INFO Train: [79/300][1800/2502]	eta 0:07:12 lr 0.000419	time 0.4918 (0.6163)	loss 4.1570 (3.6022)	grad_norm 3.2690 (inf)	mem 8931MB
[2022-04-06 10:39:46 large] (main.py 226): INFO Train: [79/300][1900/2502]	eta 0:06:11 lr 0.000419	time 0.6129 (0.6168)	loss 4.1410 (3.6010)	grad_norm 2.6756 (inf)	mem 8931MB
[2022-04-06 10:40:48 large] (main.py 226): INFO Train: [79/300][2000/2502]	eta 0:05:09 lr 0.000418	time 0.6577 (0.6170)	loss 3.8950 (3.6028)	grad_norm 2.0641 (inf)	mem 8931MB
[2022-04-06 10:41:51 large] (main.py 226): INFO Train: [79/300][2100/2502]	eta 0:04:08 lr 0.000418	time 0.7132 (0.6174)	loss 3.8234 (3.6005)	grad_norm 2.5476 (inf)	mem 8931MB
[2022-04-06 10:42:53 large] (main.py 226): INFO Train: [79/300][2200/2502]	eta 0:03:06 lr 0.000418	time 0.6827 (0.6174)	loss 2.9560 (3.6006)	grad_norm 3.0350 (inf)	mem 8931MB
[2022-04-06 10:43:55 large] (main.py 226): INFO Train: [79/300][2300/2502]	eta 0:02:04 lr 0.000418	time 0.6192 (0.6177)	loss 4.1692 (3.6008)	grad_norm 2.7510 (inf)	mem 8931MB
[2022-04-06 10:44:57 large] (main.py 226): INFO Train: [79/300][2400/2502]	eta 0:01:03 lr 0.000418	time 0.6427 (0.6179)	loss 3.4975 (3.6031)	grad_norm 3.4580 (inf)	mem 8931MB
[2022-04-06 10:45:59 large] (main.py 226): INFO Train: [79/300][2500/2502]	eta 0:00:01 lr 0.000418	time 0.5808 (0.6180)	loss 2.8380 (3.6006)	grad_norm 2.8074 (inf)	mem 8931MB
[2022-04-06 10:46:00 large] (main.py 233): INFO EPOCH 79 training takes 0:25:46
[2022-04-06 10:46:06 large] (main.py 273): INFO Test: [0/98]	Time 5.426 (5.426)	Loss 1.1923 (1.1923)	Acc@1 72.461 (72.461)	Acc@5 92.578 (92.578)	Mem 8931MB
[2022-04-06 10:46:32 large] (main.py 279): INFO  * Acc@1 74.384 Acc@5 92.308
[2022-04-06 10:46:32 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 74.4%
[2022-04-06 10:46:32 large] (utils.py 57): INFO output/large/default/ckpt_epoch_79.pth saving......
[2022-04-06 10:46:33 large] (utils.py 59): INFO output/large/default/ckpt_epoch_79.pth saved !!!
[2022-04-06 10:46:33 large] (main.py 148): INFO Max accuracy: 74.38%
[2022-04-06 10:46:41 large] (main.py 226): INFO Train: [80/300][0/2502]	eta 5:29:52 lr 0.000418	time 7.9106 (7.9106)	loss 4.4075 (4.4075)	grad_norm 2.6093 (2.6093)	mem 8931MB
[2022-04-06 10:47:35 large] (main.py 226): INFO Train: [80/300][100/2502]	eta 0:24:13 lr 0.000418	time 0.6823 (0.6050)	loss 4.1776 (3.6129)	grad_norm 2.6073 (2.7666)	mem 8931MB
[2022-04-06 10:48:37 large] (main.py 226): INFO Train: [80/300][200/2502]	eta 0:23:34 lr 0.000418	time 0.6461 (0.6143)	loss 4.1050 (3.5878)	grad_norm 2.1002 (2.6688)	mem 8931MB
[2022-04-06 10:49:40 large] (main.py 226): INFO Train: [80/300][300/2502]	eta 0:22:45 lr 0.000418	time 0.6311 (0.6199)	loss 2.6584 (3.5744)	grad_norm 2.0610 (2.7020)	mem 8931MB
[2022-04-06 10:50:43 large] (main.py 226): INFO Train: [80/300][400/2502]	eta 0:21:46 lr 0.000418	time 0.4924 (0.6214)	loss 4.3826 (3.5735)	grad_norm 2.5053 (2.6863)	mem 8931MB
[2022-04-06 10:51:46 large] (main.py 226): INFO Train: [80/300][500/2502]	eta 0:20:47 lr 0.000418	time 0.5421 (0.6229)	loss 2.6170 (3.5594)	grad_norm 2.3807 (2.6931)	mem 8931MB
[2022-04-06 10:52:48 large] (main.py 226): INFO Train: [80/300][600/2502]	eta 0:19:46 lr 0.000418	time 0.6248 (0.6236)	loss 4.4616 (3.5601)	grad_norm 2.6560 (2.6888)	mem 8931MB
[2022-04-06 10:53:51 large] (main.py 226): INFO Train: [80/300][700/2502]	eta 0:18:45 lr 0.000418	time 0.6565 (0.6245)	loss 2.6925 (3.5571)	grad_norm 2.6592 (2.7054)	mem 8931MB
[2022-04-06 10:54:54 large] (main.py 226): INFO Train: [80/300][800/2502]	eta 0:17:42 lr 0.000417	time 0.6217 (0.6244)	loss 3.8246 (3.5514)	grad_norm 2.4333 (2.7157)	mem 8931MB
[2022-04-06 10:55:55 large] (main.py 226): INFO Train: [80/300][900/2502]	eta 0:16:37 lr 0.000417	time 0.6317 (0.6227)	loss 3.9420 (3.5555)	grad_norm 2.4261 (2.7198)	mem 8931MB
[2022-04-06 10:56:57 large] (main.py 226): INFO Train: [80/300][1000/2502]	eta 0:15:35 lr 0.000417	time 0.6632 (0.6226)	loss 4.4085 (3.5599)	grad_norm 2.3920 (2.7359)	mem 8931MB
[2022-04-06 10:58:00 large] (main.py 226): INFO Train: [80/300][1100/2502]	eta 0:14:34 lr 0.000417	time 0.6618 (0.6235)	loss 3.9368 (3.5495)	grad_norm 2.5239 (2.7347)	mem 8931MB
[2022-04-06 10:59:04 large] (main.py 226): INFO Train: [80/300][1200/2502]	eta 0:13:33 lr 0.000417	time 0.6182 (0.6246)	loss 3.7372 (3.5519)	grad_norm 3.0308 (2.7261)	mem 8931MB
[2022-04-06 11:00:07 large] (main.py 226): INFO Train: [80/300][1300/2502]	eta 0:12:31 lr 0.000417	time 0.6245 (0.6251)	loss 3.1737 (3.5437)	grad_norm 2.5995 (nan)	mem 8931MB
[2022-04-06 11:01:10 large] (main.py 226): INFO Train: [80/300][1400/2502]	eta 0:11:29 lr 0.000417	time 0.7352 (0.6254)	loss 3.4459 (3.5409)	grad_norm 2.5860 (nan)	mem 8931MB
[2022-04-06 11:02:14 large] (main.py 226): INFO Train: [80/300][1500/2502]	eta 0:10:27 lr 0.000417	time 0.5692 (0.6263)	loss 3.4722 (3.5471)	grad_norm 2.8970 (nan)	mem 8931MB
[2022-04-06 11:03:17 large] (main.py 226): INFO Train: [80/300][1600/2502]	eta 0:09:25 lr 0.000417	time 0.7717 (0.6266)	loss 4.2401 (3.5495)	grad_norm 2.2088 (nan)	mem 8931MB
[2022-04-06 11:04:20 large] (main.py 226): INFO Train: [80/300][1700/2502]	eta 0:08:22 lr 0.000417	time 0.6473 (0.6271)	loss 3.7461 (3.5570)	grad_norm 2.6595 (nan)	mem 8931MB
[2022-04-06 11:05:23 large] (main.py 226): INFO Train: [80/300][1800/2502]	eta 0:07:20 lr 0.000417	time 0.6366 (0.6273)	loss 3.8772 (3.5573)	grad_norm 2.8598 (nan)	mem 8931MB
[2022-04-06 11:06:26 large] (main.py 226): INFO Train: [80/300][1900/2502]	eta 0:06:17 lr 0.000417	time 0.6277 (0.6273)	loss 3.8214 (3.5596)	grad_norm 2.5989 (nan)	mem 8931MB
[2022-04-06 11:07:28 large] (main.py 226): INFO Train: [80/300][2000/2502]	eta 0:05:14 lr 0.000417	time 0.6939 (0.6271)	loss 3.0993 (3.5637)	grad_norm 3.0945 (nan)	mem 8931MB
[2022-04-06 11:08:31 large] (main.py 226): INFO Train: [80/300][2100/2502]	eta 0:04:12 lr 0.000416	time 0.6905 (0.6270)	loss 4.3459 (3.5656)	grad_norm 2.1953 (nan)	mem 8931MB
[2022-04-06 11:09:34 large] (main.py 226): INFO Train: [80/300][2200/2502]	eta 0:03:09 lr 0.000416	time 0.5706 (0.6271)	loss 3.1646 (3.5688)	grad_norm 2.7318 (nan)	mem 8931MB
[2022-04-06 11:10:36 large] (main.py 226): INFO Train: [80/300][2300/2502]	eta 0:02:06 lr 0.000416	time 0.6318 (0.6269)	loss 3.6338 (3.5726)	grad_norm 2.7467 (nan)	mem 8931MB
[2022-04-06 11:11:38 large] (main.py 226): INFO Train: [80/300][2400/2502]	eta 0:01:03 lr 0.000416	time 0.4767 (0.6267)	loss 4.1139 (3.5741)	grad_norm 2.5008 (nan)	mem 8931MB
[2022-04-06 11:12:41 large] (main.py 226): INFO Train: [80/300][2500/2502]	eta 0:00:01 lr 0.000416	time 0.6278 (0.6266)	loss 4.2279 (3.5738)	grad_norm 2.7440 (nan)	mem 8931MB
[2022-04-06 11:12:42 large] (main.py 233): INFO EPOCH 80 training takes 0:26:08
[2022-04-06 11:12:48 large] (main.py 273): INFO Test: [0/98]	Time 5.888 (5.888)	Loss 1.2771 (1.2771)	Acc@1 71.289 (71.289)	Acc@5 91.992 (91.992)	Mem 8931MB
[2022-04-06 11:13:14 large] (main.py 279): INFO  * Acc@1 74.452 Acc@5 92.360
[2022-04-06 11:13:14 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 74.5%
[2022-04-06 11:13:14 large] (utils.py 57): INFO output/large/default/ckpt_epoch_80.pth saving......
[2022-04-06 11:13:14 large] (utils.py 59): INFO output/large/default/ckpt_epoch_80.pth saved !!!
[2022-04-06 11:13:14 large] (main.py 148): INFO Max accuracy: 74.45%
[2022-04-06 11:13:22 large] (main.py 226): INFO Train: [81/300][0/2502]	eta 5:18:10 lr 0.000416	time 7.6300 (7.6300)	loss 3.1311 (3.1311)	grad_norm 2.6013 (2.6013)	mem 8931MB
[2022-04-06 11:14:18 large] (main.py 226): INFO Train: [81/300][100/2502]	eta 0:25:14 lr 0.000416	time 0.6263 (0.6303)	loss 3.1090 (3.5157)	grad_norm 4.0385 (2.7500)	mem 8931MB
[2022-04-06 11:15:22 large] (main.py 226): INFO Train: [81/300][200/2502]	eta 0:24:21 lr 0.000416	time 0.7030 (0.6347)	loss 3.4910 (3.5455)	grad_norm 2.4677 (2.7475)	mem 8931MB
[2022-04-06 11:16:26 large] (main.py 226): INFO Train: [81/300][300/2502]	eta 0:23:17 lr 0.000416	time 0.6161 (0.6347)	loss 3.5012 (3.5282)	grad_norm 2.5957 (2.7440)	mem 8931MB
[2022-04-06 11:17:29 large] (main.py 226): INFO Train: [81/300][400/2502]	eta 0:22:14 lr 0.000416	time 0.6433 (0.6347)	loss 3.2665 (3.5467)	grad_norm 2.3009 (2.7571)	mem 8931MB
[2022-04-06 11:18:32 large] (main.py 226): INFO Train: [81/300][500/2502]	eta 0:21:09 lr 0.000416	time 0.7029 (0.6342)	loss 4.0121 (3.5555)	grad_norm 2.1891 (2.7379)	mem 8931MB
[2022-04-06 11:19:36 large] (main.py 226): INFO Train: [81/300][600/2502]	eta 0:20:06 lr 0.000416	time 0.7476 (0.6341)	loss 2.9960 (3.5682)	grad_norm 4.2418 (2.7359)	mem 8931MB
[2022-04-06 11:20:38 large] (main.py 226): INFO Train: [81/300][700/2502]	eta 0:18:58 lr 0.000416	time 0.6128 (0.6320)	loss 4.0454 (3.5796)	grad_norm 2.6393 (nan)	mem 8931MB
[2022-04-06 11:21:40 large] (main.py 226): INFO Train: [81/300][800/2502]	eta 0:17:54 lr 0.000416	time 0.6070 (0.6313)	loss 3.7885 (3.5853)	grad_norm 2.5231 (nan)	mem 8931MB
[2022-04-06 11:22:43 large] (main.py 226): INFO Train: [81/300][900/2502]	eta 0:16:51 lr 0.000415	time 0.6037 (0.6314)	loss 3.8075 (3.5822)	grad_norm 2.9054 (nan)	mem 8931MB
[2022-04-06 11:23:46 large] (main.py 226): INFO Train: [81/300][1000/2502]	eta 0:15:48 lr 0.000415	time 0.6321 (0.6313)	loss 2.6806 (3.5802)	grad_norm 2.3429 (nan)	mem 8931MB
[2022-04-06 11:24:49 large] (main.py 226): INFO Train: [81/300][1100/2502]	eta 0:14:44 lr 0.000415	time 0.6251 (0.6308)	loss 4.4495 (3.5849)	grad_norm 3.0416 (nan)	mem 8931MB
[2022-04-06 11:25:52 large] (main.py 226): INFO Train: [81/300][1200/2502]	eta 0:13:40 lr 0.000415	time 0.6868 (0.6305)	loss 4.0360 (3.5958)	grad_norm 2.2141 (nan)	mem 8931MB
[2022-04-06 11:26:55 large] (main.py 226): INFO Train: [81/300][1300/2502]	eta 0:12:38 lr 0.000415	time 0.6578 (0.6309)	loss 3.9236 (3.5958)	grad_norm 2.3595 (nan)	mem 8931MB
[2022-04-06 11:27:58 large] (main.py 226): INFO Train: [81/300][1400/2502]	eta 0:11:34 lr 0.000415	time 0.5092 (0.6304)	loss 3.0255 (3.5965)	grad_norm 2.3190 (nan)	mem 8931MB
[2022-04-06 11:29:00 large] (main.py 226): INFO Train: [81/300][1500/2502]	eta 0:10:31 lr 0.000415	time 0.6177 (0.6299)	loss 4.2867 (3.5984)	grad_norm 2.1306 (nan)	mem 8931MB
[2022-04-06 11:30:03 large] (main.py 226): INFO Train: [81/300][1600/2502]	eta 0:09:28 lr 0.000415	time 0.6092 (0.6301)	loss 2.6165 (3.5955)	grad_norm 3.2392 (nan)	mem 8931MB
[2022-04-06 11:31:06 large] (main.py 226): INFO Train: [81/300][1700/2502]	eta 0:08:25 lr 0.000415	time 0.6019 (0.6300)	loss 4.3429 (3.5966)	grad_norm 2.2048 (nan)	mem 8931MB
[2022-04-06 11:32:09 large] (main.py 226): INFO Train: [81/300][1800/2502]	eta 0:07:22 lr 0.000415	time 0.8111 (0.6301)	loss 4.1963 (3.5979)	grad_norm 2.4452 (nan)	mem 8931MB
[2022-04-06 11:33:13 large] (main.py 226): INFO Train: [81/300][1900/2502]	eta 0:06:19 lr 0.000415	time 0.5903 (0.6302)	loss 4.4614 (3.5987)	grad_norm 2.5728 (nan)	mem 8931MB
[2022-04-06 11:34:16 large] (main.py 226): INFO Train: [81/300][2000/2502]	eta 0:05:16 lr 0.000415	time 0.6185 (0.6303)	loss 4.3694 (3.5973)	grad_norm 3.6598 (nan)	mem 8931MB
[2022-04-06 11:35:19 large] (main.py 226): INFO Train: [81/300][2100/2502]	eta 0:04:13 lr 0.000415	time 0.5111 (0.6304)	loss 3.7624 (3.5981)	grad_norm 3.3161 (nan)	mem 8931MB
[2022-04-06 11:36:23 large] (main.py 226): INFO Train: [81/300][2200/2502]	eta 0:03:10 lr 0.000414	time 0.5838 (0.6306)	loss 2.4446 (3.5996)	grad_norm 2.7902 (nan)	mem 8931MB
[2022-04-06 11:37:21 large] (main.py 226): INFO Train: [81/300][2300/2502]	eta 0:02:07 lr 0.000414	time 0.5085 (0.6288)	loss 3.7840 (3.5986)	grad_norm 2.1447 (nan)	mem 8931MB
[2022-04-06 11:38:22 large] (main.py 226): INFO Train: [81/300][2400/2502]	eta 0:01:04 lr 0.000414	time 0.6624 (0.6279)	loss 3.3823 (3.5979)	grad_norm 2.5537 (nan)	mem 8931MB
[2022-04-06 11:39:25 large] (main.py 226): INFO Train: [81/300][2500/2502]	eta 0:00:01 lr 0.000414	time 0.6078 (0.6280)	loss 4.2018 (3.5966)	grad_norm 2.1399 (nan)	mem 8931MB
[2022-04-06 11:39:26 large] (main.py 233): INFO EPOCH 81 training takes 0:26:11
[2022-04-06 11:39:33 large] (main.py 273): INFO Test: [0/98]	Time 6.526 (6.526)	Loss 1.3652 (1.3652)	Acc@1 70.898 (70.898)	Acc@5 90.234 (90.234)	Mem 8931MB
[2022-04-06 11:39:58 large] (main.py 279): INFO  * Acc@1 74.130 Acc@5 92.312
[2022-04-06 11:39:58 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 74.1%
[2022-04-06 11:39:58 large] (main.py 148): INFO Max accuracy: 74.45%
[2022-04-06 11:40:05 large] (main.py 226): INFO Train: [82/300][0/2502]	eta 4:42:55 lr 0.000414	time 6.7849 (6.7849)	loss 3.9606 (3.9606)	grad_norm 2.2264 (2.2264)	mem 8931MB
[2022-04-06 11:40:58 large] (main.py 226): INFO Train: [82/300][100/2502]	eta 0:23:48 lr 0.000414	time 0.6933 (0.5947)	loss 2.8101 (3.7010)	grad_norm 2.8812 (2.7491)	mem 8931MB
[2022-04-06 11:42:02 large] (main.py 226): INFO Train: [82/300][200/2502]	eta 0:23:43 lr 0.000414	time 0.6991 (0.6183)	loss 3.4683 (3.6645)	grad_norm 2.7655 (2.7507)	mem 8931MB
[2022-04-06 11:43:07 large] (main.py 226): INFO Train: [82/300][300/2502]	eta 0:22:59 lr 0.000414	time 0.6333 (0.6265)	loss 2.8738 (3.6192)	grad_norm 2.1034 (2.7282)	mem 8931MB
[2022-04-06 11:44:11 large] (main.py 226): INFO Train: [82/300][400/2502]	eta 0:22:02 lr 0.000414	time 0.6067 (0.6292)	loss 3.9296 (3.6104)	grad_norm 2.1864 (2.7510)	mem 8931MB
[2022-04-06 11:45:14 large] (main.py 226): INFO Train: [82/300][500/2502]	eta 0:21:01 lr 0.000414	time 0.6057 (0.6303)	loss 3.3968 (3.6033)	grad_norm 4.6230 (2.7376)	mem 8931MB
[2022-04-06 11:46:18 large] (main.py 226): INFO Train: [82/300][600/2502]	eta 0:20:02 lr 0.000414	time 0.6302 (0.6322)	loss 4.3178 (3.6003)	grad_norm 2.7093 (2.7379)	mem 8931MB
[2022-04-06 11:47:22 large] (main.py 226): INFO Train: [82/300][700/2502]	eta 0:18:59 lr 0.000414	time 0.5724 (0.6325)	loss 3.9694 (3.5990)	grad_norm 2.3014 (2.7098)	mem 8931MB
[2022-04-06 11:48:24 large] (main.py 226): INFO Train: [82/300][800/2502]	eta 0:17:55 lr 0.000414	time 0.5878 (0.6320)	loss 3.4402 (3.6049)	grad_norm 2.6143 (2.7262)	mem 8931MB
[2022-04-06 11:49:26 large] (main.py 226): INFO Train: [82/300][900/2502]	eta 0:16:50 lr 0.000414	time 0.5890 (0.6305)	loss 3.5971 (3.6115)	grad_norm 2.6984 (2.7349)	mem 8931MB
[2022-04-06 11:50:29 large] (main.py 226): INFO Train: [82/300][1000/2502]	eta 0:15:46 lr 0.000413	time 0.5621 (0.6299)	loss 2.5271 (3.6034)	grad_norm 2.8328 (2.7361)	mem 8931MB
[2022-04-06 11:51:32 large] (main.py 226): INFO Train: [82/300][1100/2502]	eta 0:14:43 lr 0.000413	time 0.5282 (0.6301)	loss 3.8468 (3.6011)	grad_norm 2.5771 (2.7416)	mem 8931MB
[2022-04-06 11:52:35 large] (main.py 226): INFO Train: [82/300][1200/2502]	eta 0:13:40 lr 0.000413	time 0.6546 (0.6304)	loss 3.0631 (3.6048)	grad_norm 3.1089 (2.7533)	mem 8931MB
[2022-04-06 11:53:38 large] (main.py 226): INFO Train: [82/300][1300/2502]	eta 0:12:36 lr 0.000413	time 0.6729 (0.6298)	loss 3.9177 (3.6128)	grad_norm 2.1648 (2.7500)	mem 8931MB
[2022-04-06 11:54:41 large] (main.py 226): INFO Train: [82/300][1400/2502]	eta 0:11:34 lr 0.000413	time 0.6116 (0.6301)	loss 2.8210 (3.6109)	grad_norm 2.6016 (2.7560)	mem 8931MB
[2022-04-06 11:55:42 large] (main.py 226): INFO Train: [82/300][1500/2502]	eta 0:10:30 lr 0.000413	time 0.6115 (0.6289)	loss 2.4936 (3.6146)	grad_norm 2.8697 (2.7609)	mem 8931MB
[2022-04-06 11:56:44 large] (main.py 226): INFO Train: [82/300][1600/2502]	eta 0:09:26 lr 0.000413	time 0.6549 (0.6285)	loss 3.5806 (3.6156)	grad_norm 2.2931 (2.7618)	mem 8931MB
[2022-04-06 11:57:49 large] (main.py 226): INFO Train: [82/300][1700/2502]	eta 0:08:24 lr 0.000413	time 0.6344 (0.6294)	loss 4.0366 (3.6176)	grad_norm 2.2313 (2.7593)	mem 8931MB
[2022-04-06 11:58:52 large] (main.py 226): INFO Train: [82/300][1800/2502]	eta 0:07:21 lr 0.000413	time 0.6358 (0.6294)	loss 3.9678 (3.6161)	grad_norm 2.8480 (2.7567)	mem 8931MB
[2022-04-06 11:59:55 large] (main.py 226): INFO Train: [82/300][1900/2502]	eta 0:06:19 lr 0.000413	time 0.6330 (0.6296)	loss 3.9417 (3.6182)	grad_norm 1.9837 (2.7566)	mem 8931MB
[2022-04-06 12:00:58 large] (main.py 226): INFO Train: [82/300][2000/2502]	eta 0:05:16 lr 0.000413	time 0.6623 (0.6296)	loss 4.0150 (3.6222)	grad_norm 2.4876 (2.7574)	mem 8931MB
[2022-04-06 12:02:01 large] (main.py 226): INFO Train: [82/300][2100/2502]	eta 0:04:13 lr 0.000413	time 0.6170 (0.6294)	loss 3.6253 (3.6204)	grad_norm 2.4748 (2.7555)	mem 8931MB
[2022-04-06 12:03:04 large] (main.py 226): INFO Train: [82/300][2200/2502]	eta 0:03:10 lr 0.000412	time 0.6116 (0.6295)	loss 3.9215 (3.6154)	grad_norm 1.9920 (2.7548)	mem 8931MB
[2022-04-06 12:04:07 large] (main.py 226): INFO Train: [82/300][2300/2502]	eta 0:02:07 lr 0.000412	time 0.5446 (0.6296)	loss 2.4733 (3.6148)	grad_norm 3.0006 (inf)	mem 8931MB
[2022-04-06 12:05:10 large] (main.py 226): INFO Train: [82/300][2400/2502]	eta 0:01:04 lr 0.000412	time 0.6483 (0.6295)	loss 4.2575 (3.6120)	grad_norm 4.2065 (inf)	mem 8931MB
[2022-04-06 12:06:12 large] (main.py 226): INFO Train: [82/300][2500/2502]	eta 0:00:01 lr 0.000412	time 0.5720 (0.6293)	loss 2.6285 (3.6111)	grad_norm 2.5749 (inf)	mem 8931MB
[2022-04-06 12:06:13 large] (main.py 233): INFO EPOCH 82 training takes 0:26:14
[2022-04-06 12:06:20 large] (main.py 273): INFO Test: [0/98]	Time 6.643 (6.643)	Loss 1.0425 (1.0425)	Acc@1 77.734 (77.734)	Acc@5 94.141 (94.141)	Mem 8931MB
[2022-04-06 12:06:46 large] (main.py 279): INFO  * Acc@1 74.324 Acc@5 92.280
[2022-04-06 12:06:46 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 74.3%
[2022-04-06 12:06:46 large] (main.py 148): INFO Max accuracy: 74.45%
[2022-04-06 12:06:54 large] (main.py 226): INFO Train: [83/300][0/2502]	eta 5:32:27 lr 0.000412	time 7.9728 (7.9728)	loss 4.0731 (4.0731)	grad_norm 2.8489 (2.8489)	mem 8931MB
[2022-04-06 12:07:48 large] (main.py 226): INFO Train: [83/300][100/2502]	eta 0:24:50 lr 0.000412	time 0.6401 (0.6206)	loss 3.8093 (3.5961)	grad_norm 2.6864 (2.8091)	mem 8931MB
[2022-04-06 12:08:52 large] (main.py 226): INFO Train: [83/300][200/2502]	eta 0:24:08 lr 0.000412	time 0.6844 (0.6293)	loss 3.8756 (3.5562)	grad_norm 2.3826 (2.7971)	mem 8931MB
[2022-04-06 12:09:56 large] (main.py 226): INFO Train: [83/300][300/2502]	eta 0:23:09 lr 0.000412	time 0.6097 (0.6311)	loss 4.0205 (3.5563)	grad_norm 3.1412 (2.8113)	mem 8931MB
[2022-04-06 12:11:00 large] (main.py 226): INFO Train: [83/300][400/2502]	eta 0:22:11 lr 0.000412	time 0.6107 (0.6334)	loss 3.2536 (3.5592)	grad_norm 2.3966 (2.7795)	mem 8931MB
[2022-04-06 12:12:03 large] (main.py 226): INFO Train: [83/300][500/2502]	eta 0:21:08 lr 0.000412	time 0.5151 (0.6338)	loss 3.6611 (3.5591)	grad_norm 2.9532 (2.7614)	mem 8931MB
[2022-04-06 12:13:07 large] (main.py 226): INFO Train: [83/300][600/2502]	eta 0:20:05 lr 0.000412	time 0.5886 (0.6338)	loss 3.3038 (3.5584)	grad_norm 3.1014 (2.7787)	mem 8931MB
[2022-04-06 12:14:11 large] (main.py 226): INFO Train: [83/300][700/2502]	eta 0:19:03 lr 0.000412	time 0.6032 (0.6348)	loss 4.1353 (3.5661)	grad_norm 3.0826 (2.7805)	mem 8931MB
[2022-04-06 12:15:14 large] (main.py 226): INFO Train: [83/300][800/2502]	eta 0:17:59 lr 0.000412	time 0.8143 (0.6342)	loss 2.8470 (3.5649)	grad_norm 2.9021 (2.7765)	mem 8931MB
[2022-04-06 12:16:16 large] (main.py 226): INFO Train: [83/300][900/2502]	eta 0:16:54 lr 0.000412	time 0.6448 (0.6335)	loss 3.8305 (3.5597)	grad_norm 3.6802 (2.7745)	mem 8931MB
[2022-04-06 12:17:20 large] (main.py 226): INFO Train: [83/300][1000/2502]	eta 0:15:51 lr 0.000411	time 0.6103 (0.6336)	loss 3.9168 (3.5655)	grad_norm 2.6247 (2.7768)	mem 8931MB
[2022-04-06 12:18:23 large] (main.py 226): INFO Train: [83/300][1100/2502]	eta 0:14:47 lr 0.000411	time 0.6266 (0.6334)	loss 4.1315 (3.5641)	grad_norm 2.7795 (2.7600)	mem 8931MB
[2022-04-06 12:19:26 large] (main.py 226): INFO Train: [83/300][1200/2502]	eta 0:13:44 lr 0.000411	time 0.7002 (0.6332)	loss 4.0581 (3.5732)	grad_norm 2.1864 (2.7558)	mem 8931MB
[2022-04-06 12:20:29 large] (main.py 226): INFO Train: [83/300][1300/2502]	eta 0:12:41 lr 0.000411	time 0.6682 (0.6332)	loss 4.0643 (3.5776)	grad_norm 3.4758 (2.7518)	mem 8931MB
[2022-04-06 12:21:33 large] (main.py 226): INFO Train: [83/300][1400/2502]	eta 0:11:38 lr 0.000411	time 0.6554 (0.6334)	loss 2.8815 (3.5801)	grad_norm 2.3380 (2.7508)	mem 8931MB
[2022-04-06 12:22:36 large] (main.py 226): INFO Train: [83/300][1500/2502]	eta 0:10:34 lr 0.000411	time 0.6461 (0.6331)	loss 2.6489 (3.5907)	grad_norm 2.3430 (2.7468)	mem 8931MB
[2022-04-06 12:23:39 large] (main.py 226): INFO Train: [83/300][1600/2502]	eta 0:09:30 lr 0.000411	time 0.6729 (0.6327)	loss 4.0526 (3.5883)	grad_norm 2.8451 (2.7412)	mem 8931MB
[2022-04-06 12:24:41 large] (main.py 226): INFO Train: [83/300][1700/2502]	eta 0:08:26 lr 0.000411	time 0.6800 (0.6319)	loss 3.0944 (3.5889)	grad_norm 2.4393 (2.7477)	mem 8931MB
[2022-04-06 12:25:44 large] (main.py 226): INFO Train: [83/300][1800/2502]	eta 0:07:23 lr 0.000411	time 0.6703 (0.6323)	loss 2.7711 (3.5910)	grad_norm 2.2417 (2.7458)	mem 8931MB
[2022-04-06 12:26:48 large] (main.py 226): INFO Train: [83/300][1900/2502]	eta 0:06:20 lr 0.000411	time 0.7101 (0.6324)	loss 3.1934 (3.5931)	grad_norm 2.8445 (2.7416)	mem 8931MB
[2022-04-06 12:27:51 large] (main.py 226): INFO Train: [83/300][2000/2502]	eta 0:05:17 lr 0.000411	time 0.5494 (0.6322)	loss 3.8311 (3.5922)	grad_norm 2.9270 (2.7388)	mem 8931MB
[2022-04-06 12:28:54 large] (main.py 226): INFO Train: [83/300][2100/2502]	eta 0:04:14 lr 0.000411	time 0.7055 (0.6323)	loss 3.8340 (3.5943)	grad_norm 3.1182 (2.7403)	mem 8931MB
[2022-04-06 12:29:57 large] (main.py 226): INFO Train: [83/300][2200/2502]	eta 0:03:10 lr 0.000411	time 0.5908 (0.6322)	loss 3.3406 (3.5928)	grad_norm 2.1669 (2.7383)	mem 8931MB
[2022-04-06 12:30:59 large] (main.py 226): INFO Train: [83/300][2300/2502]	eta 0:02:07 lr 0.000410	time 0.6375 (0.6317)	loss 4.0921 (3.5927)	grad_norm 2.9221 (2.7409)	mem 8931MB
[2022-04-06 12:32:02 large] (main.py 226): INFO Train: [83/300][2400/2502]	eta 0:01:04 lr 0.000410	time 0.4712 (0.6316)	loss 3.8377 (3.5938)	grad_norm 2.9627 (2.7398)	mem 8931MB
[2022-04-06 12:33:06 large] (main.py 226): INFO Train: [83/300][2500/2502]	eta 0:00:01 lr 0.000410	time 0.6655 (0.6318)	loss 2.5939 (3.5910)	grad_norm 2.0338 (2.7339)	mem 8931MB
[2022-04-06 12:33:07 large] (main.py 233): INFO EPOCH 83 training takes 0:26:21
[2022-04-06 12:33:13 large] (main.py 273): INFO Test: [0/98]	Time 6.555 (6.555)	Loss 1.3126 (1.3126)	Acc@1 72.852 (72.852)	Acc@5 91.602 (91.602)	Mem 8931MB
[2022-04-06 12:33:39 large] (main.py 279): INFO  * Acc@1 74.500 Acc@5 92.414
[2022-04-06 12:33:39 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 74.5%
[2022-04-06 12:33:39 large] (utils.py 57): INFO output/large/default/ckpt_epoch_83.pth saving......
[2022-04-06 12:33:40 large] (utils.py 59): INFO output/large/default/ckpt_epoch_83.pth saved !!!
[2022-04-06 12:33:40 large] (main.py 148): INFO Max accuracy: 74.50%
[2022-04-06 12:33:47 large] (main.py 226): INFO Train: [84/300][0/2502]	eta 5:02:16 lr 0.000410	time 7.2490 (7.2490)	loss 4.1509 (4.1509)	grad_norm 3.6632 (3.6632)	mem 8931MB
[2022-04-06 12:34:44 large] (main.py 226): INFO Train: [84/300][100/2502]	eta 0:25:21 lr 0.000410	time 0.6669 (0.6335)	loss 3.9573 (3.6169)	grad_norm 2.5543 (2.7965)	mem 8931MB
[2022-04-06 12:35:47 large] (main.py 226): INFO Train: [84/300][200/2502]	eta 0:24:20 lr 0.000410	time 0.5931 (0.6345)	loss 3.0282 (3.5572)	grad_norm 2.1361 (inf)	mem 8931MB
[2022-04-06 12:36:51 large] (main.py 226): INFO Train: [84/300][300/2502]	eta 0:23:17 lr 0.000410	time 0.6104 (0.6349)	loss 2.9658 (3.5458)	grad_norm 2.1886 (inf)	mem 8931MB
[2022-04-06 12:37:55 large] (main.py 226): INFO Train: [84/300][400/2502]	eta 0:22:16 lr 0.000410	time 0.6570 (0.6357)	loss 4.1503 (3.5628)	grad_norm 2.9890 (inf)	mem 8931MB
[2022-04-06 12:38:58 large] (main.py 226): INFO Train: [84/300][500/2502]	eta 0:21:09 lr 0.000410	time 0.5649 (0.6342)	loss 3.3707 (3.5565)	grad_norm 2.7549 (inf)	mem 8931MB
[2022-04-06 12:40:00 large] (main.py 226): INFO Train: [84/300][600/2502]	eta 0:20:02 lr 0.000410	time 0.6662 (0.6322)	loss 3.9409 (3.5501)	grad_norm 2.4920 (inf)	mem 8931MB
[2022-04-06 12:41:03 large] (main.py 226): INFO Train: [84/300][700/2502]	eta 0:18:58 lr 0.000410	time 0.6561 (0.6319)	loss 3.0730 (3.5453)	grad_norm 3.8649 (inf)	mem 8931MB
[2022-04-06 12:42:06 large] (main.py 226): INFO Train: [84/300][800/2502]	eta 0:17:55 lr 0.000410	time 0.6080 (0.6319)	loss 2.7452 (3.5518)	grad_norm 2.4002 (inf)	mem 8931MB
[2022-04-06 12:43:10 large] (main.py 226): INFO Train: [84/300][900/2502]	eta 0:16:52 lr 0.000410	time 0.5826 (0.6323)	loss 3.6756 (3.5702)	grad_norm 3.6815 (inf)	mem 8931MB
[2022-04-06 12:44:12 large] (main.py 226): INFO Train: [84/300][1000/2502]	eta 0:15:49 lr 0.000409	time 0.6729 (0.6318)	loss 2.3723 (3.5702)	grad_norm 2.6775 (inf)	mem 8931MB
[2022-04-06 12:45:16 large] (main.py 226): INFO Train: [84/300][1100/2502]	eta 0:14:45 lr 0.000409	time 0.5740 (0.6319)	loss 3.1851 (3.5722)	grad_norm 3.1497 (nan)	mem 8931MB
[2022-04-06 12:46:17 large] (main.py 226): INFO Train: [84/300][1200/2502]	eta 0:13:40 lr 0.000409	time 0.5660 (0.6305)	loss 3.7326 (3.5566)	grad_norm 2.3164 (nan)	mem 8931MB
[2022-04-06 12:47:20 large] (main.py 226): INFO Train: [84/300][1300/2502]	eta 0:12:37 lr 0.000409	time 0.6428 (0.6304)	loss 3.8156 (3.5536)	grad_norm 2.6354 (nan)	mem 8931MB
[2022-04-06 12:48:23 large] (main.py 226): INFO Train: [84/300][1400/2502]	eta 0:11:34 lr 0.000409	time 0.6860 (0.6301)	loss 3.8171 (3.5582)	grad_norm 3.5362 (nan)	mem 8931MB
[2022-04-06 12:49:26 large] (main.py 226): INFO Train: [84/300][1500/2502]	eta 0:10:31 lr 0.000409	time 0.5984 (0.6300)	loss 3.4440 (3.5601)	grad_norm 3.0745 (nan)	mem 8931MB
[2022-04-06 12:50:29 large] (main.py 226): INFO Train: [84/300][1600/2502]	eta 0:09:28 lr 0.000409	time 0.6986 (0.6303)	loss 2.6458 (3.5601)	grad_norm 3.4831 (nan)	mem 8931MB
[2022-04-06 12:51:32 large] (main.py 226): INFO Train: [84/300][1700/2502]	eta 0:08:25 lr 0.000409	time 0.6840 (0.6303)	loss 2.9751 (3.5667)	grad_norm 2.5832 (nan)	mem 8931MB
[2022-04-06 12:52:34 large] (main.py 226): INFO Train: [84/300][1800/2502]	eta 0:07:22 lr 0.000409	time 0.6109 (0.6299)	loss 2.9645 (3.5707)	grad_norm 2.6806 (nan)	mem 8931MB
[2022-04-06 12:53:38 large] (main.py 226): INFO Train: [84/300][1900/2502]	eta 0:06:19 lr 0.000409	time 0.5984 (0.6304)	loss 4.2318 (3.5739)	grad_norm 2.2813 (nan)	mem 8931MB
[2022-04-06 12:54:41 large] (main.py 226): INFO Train: [84/300][2000/2502]	eta 0:05:16 lr 0.000409	time 0.5708 (0.6303)	loss 3.5254 (3.5740)	grad_norm 2.8353 (nan)	mem 8931MB
[2022-04-06 12:55:44 large] (main.py 226): INFO Train: [84/300][2100/2502]	eta 0:04:13 lr 0.000409	time 0.7226 (0.6302)	loss 3.5678 (3.5734)	grad_norm 2.1020 (nan)	mem 8931MB
[2022-04-06 12:56:47 large] (main.py 226): INFO Train: [84/300][2200/2502]	eta 0:03:10 lr 0.000408	time 0.7008 (0.6303)	loss 3.7062 (3.5714)	grad_norm 2.2917 (nan)	mem 8931MB
[2022-04-06 12:57:51 large] (main.py 226): INFO Train: [84/300][2300/2502]	eta 0:02:07 lr 0.000408	time 0.6555 (0.6305)	loss 3.6139 (3.5769)	grad_norm 2.8930 (nan)	mem 8931MB
[2022-04-06 12:58:54 large] (main.py 226): INFO Train: [84/300][2400/2502]	eta 0:01:04 lr 0.000408	time 0.6308 (0.6307)	loss 3.5278 (3.5783)	grad_norm 3.0750 (nan)	mem 8931MB
[2022-04-06 12:59:58 large] (main.py 226): INFO Train: [84/300][2500/2502]	eta 0:00:01 lr 0.000408	time 0.5766 (0.6308)	loss 3.4507 (3.5778)	grad_norm 2.9881 (nan)	mem 8931MB
[2022-04-06 12:59:58 large] (main.py 233): INFO EPOCH 84 training takes 0:26:18
[2022-04-06 13:00:05 large] (main.py 273): INFO Test: [0/98]	Time 6.398 (6.398)	Loss 1.1907 (1.1907)	Acc@1 75.195 (75.195)	Acc@5 92.969 (92.969)	Mem 8931MB
[2022-04-06 13:00:31 large] (main.py 279): INFO  * Acc@1 74.186 Acc@5 92.172
[2022-04-06 13:00:31 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 74.2%
[2022-04-06 13:00:31 large] (main.py 148): INFO Max accuracy: 74.50%
[2022-04-06 13:00:38 large] (main.py 226): INFO Train: [85/300][0/2502]	eta 5:17:56 lr 0.000408	time 7.6247 (7.6247)	loss 2.6996 (2.6996)	grad_norm 3.2405 (3.2405)	mem 8931MB
[2022-04-06 13:01:36 large] (main.py 226): INFO Train: [85/300][100/2502]	eta 0:25:51 lr 0.000408	time 0.6062 (0.6459)	loss 3.8666 (3.5656)	grad_norm 1.8318 (2.6754)	mem 8931MB
[2022-04-06 13:02:42 large] (main.py 226): INFO Train: [85/300][200/2502]	eta 0:25:00 lr 0.000408	time 0.4589 (0.6519)	loss 2.9637 (3.5880)	grad_norm 2.4981 (2.7392)	mem 8931MB
[2022-04-06 13:03:46 large] (main.py 226): INFO Train: [85/300][300/2502]	eta 0:23:48 lr 0.000408	time 0.6117 (0.6486)	loss 3.7057 (3.5756)	grad_norm 2.7204 (2.7294)	mem 8931MB
[2022-04-06 13:04:48 large] (main.py 226): INFO Train: [85/300][400/2502]	eta 0:22:29 lr 0.000408	time 0.6710 (0.6419)	loss 4.3550 (3.5703)	grad_norm 2.4218 (2.7690)	mem 8931MB
[2022-04-06 13:05:51 large] (main.py 226): INFO Train: [85/300][500/2502]	eta 0:21:21 lr 0.000408	time 0.6200 (0.6399)	loss 3.8272 (3.5700)	grad_norm 2.4555 (2.7740)	mem 8931MB
[2022-04-06 13:06:56 large] (main.py 226): INFO Train: [85/300][600/2502]	eta 0:20:18 lr 0.000408	time 0.6528 (0.6405)	loss 3.4454 (3.5676)	grad_norm 3.1733 (2.7850)	mem 8931MB
[2022-04-06 13:08:00 large] (main.py 226): INFO Train: [85/300][700/2502]	eta 0:19:14 lr 0.000408	time 0.6261 (0.6405)	loss 3.7242 (3.5692)	grad_norm 2.4000 (2.7915)	mem 8931MB
[2022-04-06 13:09:03 large] (main.py 226): INFO Train: [85/300][800/2502]	eta 0:18:08 lr 0.000408	time 0.6243 (0.6398)	loss 3.8396 (3.5689)	grad_norm 2.7826 (2.7895)	mem 8931MB
[2022-04-06 13:10:07 large] (main.py 226): INFO Train: [85/300][900/2502]	eta 0:17:05 lr 0.000408	time 0.6081 (0.6400)	loss 2.6740 (3.5783)	grad_norm 2.5421 (2.8002)	mem 8931MB
[2022-04-06 13:11:11 large] (main.py 226): INFO Train: [85/300][1000/2502]	eta 0:16:01 lr 0.000407	time 0.5457 (0.6401)	loss 4.2487 (3.5755)	grad_norm 2.4438 (2.7952)	mem 8931MB
[2022-04-06 13:12:15 large] (main.py 226): INFO Train: [85/300][1100/2502]	eta 0:14:56 lr 0.000407	time 0.7075 (0.6398)	loss 4.2665 (3.5695)	grad_norm 2.2853 (2.7855)	mem 8931MB
[2022-04-06 13:13:19 large] (main.py 226): INFO Train: [85/300][1200/2502]	eta 0:13:52 lr 0.000407	time 0.5968 (0.6393)	loss 4.1336 (3.5739)	grad_norm 2.6094 (2.7770)	mem 8931MB
[2022-04-06 13:14:22 large] (main.py 226): INFO Train: [85/300][1300/2502]	eta 0:12:48 lr 0.000407	time 0.6524 (0.6393)	loss 4.2053 (3.5707)	grad_norm 3.2444 (2.7787)	mem 8931MB
[2022-04-06 13:15:26 large] (main.py 226): INFO Train: [85/300][1400/2502]	eta 0:11:44 lr 0.000407	time 0.6171 (0.6389)	loss 3.5086 (3.5722)	grad_norm 1.9860 (2.7699)	mem 8931MB
[2022-04-06 13:16:29 large] (main.py 226): INFO Train: [85/300][1500/2502]	eta 0:10:39 lr 0.000407	time 0.6381 (0.6385)	loss 4.0044 (3.5719)	grad_norm 3.6881 (2.7664)	mem 8931MB
[2022-04-06 13:17:32 large] (main.py 226): INFO Train: [85/300][1600/2502]	eta 0:09:35 lr 0.000407	time 0.7086 (0.6382)	loss 3.7599 (3.5681)	grad_norm 2.3924 (nan)	mem 8931MB
[2022-04-06 13:18:37 large] (main.py 226): INFO Train: [85/300][1700/2502]	eta 0:08:32 lr 0.000407	time 0.6528 (0.6385)	loss 3.0055 (3.5690)	grad_norm 2.7079 (nan)	mem 8931MB
[2022-04-06 13:19:40 large] (main.py 226): INFO Train: [85/300][1800/2502]	eta 0:07:27 lr 0.000407	time 0.6205 (0.6380)	loss 3.9696 (3.5729)	grad_norm 2.6566 (nan)	mem 8931MB
[2022-04-06 13:20:43 large] (main.py 226): INFO Train: [85/300][1900/2502]	eta 0:06:24 lr 0.000407	time 0.6098 (0.6379)	loss 2.5987 (3.5724)	grad_norm 2.2622 (nan)	mem 8931MB
[2022-04-06 13:21:46 large] (main.py 226): INFO Train: [85/300][2000/2502]	eta 0:05:20 lr 0.000407	time 0.6044 (0.6375)	loss 3.8884 (3.5776)	grad_norm 3.7454 (nan)	mem 8931MB
[2022-04-06 13:22:50 large] (main.py 226): INFO Train: [85/300][2100/2502]	eta 0:04:16 lr 0.000407	time 0.6215 (0.6375)	loss 4.3379 (3.5787)	grad_norm 2.7461 (nan)	mem 8931MB
[2022-04-06 13:23:54 large] (main.py 226): INFO Train: [85/300][2200/2502]	eta 0:03:12 lr 0.000406	time 0.7051 (0.6375)	loss 3.3665 (3.5797)	grad_norm 2.5367 (nan)	mem 8931MB
[2022-04-06 13:24:58 large] (main.py 226): INFO Train: [85/300][2300/2502]	eta 0:02:08 lr 0.000406	time 0.6461 (0.6375)	loss 2.5163 (3.5786)	grad_norm 3.0897 (nan)	mem 8931MB
[2022-04-06 13:26:02 large] (main.py 226): INFO Train: [85/300][2400/2502]	eta 0:01:05 lr 0.000406	time 0.5984 (0.6379)	loss 3.7936 (3.5793)	grad_norm 2.2003 (nan)	mem 8931MB
[2022-04-06 13:27:05 large] (main.py 226): INFO Train: [85/300][2500/2502]	eta 0:00:01 lr 0.000406	time 0.5382 (0.6376)	loss 3.9703 (3.5797)	grad_norm 2.3876 (nan)	mem 8931MB
[2022-04-06 13:27:07 large] (main.py 233): INFO EPOCH 85 training takes 0:26:35
[2022-04-06 13:27:13 large] (main.py 273): INFO Test: [0/98]	Time 5.994 (5.994)	Loss 1.0696 (1.0696)	Acc@1 77.148 (77.148)	Acc@5 93.359 (93.359)	Mem 8931MB
[2022-04-06 13:27:39 large] (main.py 279): INFO  * Acc@1 74.572 Acc@5 92.578
[2022-04-06 13:27:39 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 74.6%
[2022-04-06 13:27:39 large] (utils.py 57): INFO output/large/default/ckpt_epoch_85.pth saving......
[2022-04-06 13:27:40 large] (utils.py 59): INFO output/large/default/ckpt_epoch_85.pth saved !!!
[2022-04-06 13:27:40 large] (main.py 148): INFO Max accuracy: 74.57%
[2022-04-06 13:27:48 large] (main.py 226): INFO Train: [86/300][0/2502]	eta 5:30:32 lr 0.000406	time 7.9269 (7.9269)	loss 2.5867 (2.5867)	grad_norm 2.5664 (2.5664)	mem 8931MB
[2022-04-06 13:28:42 large] (main.py 226): INFO Train: [86/300][100/2502]	eta 0:24:37 lr 0.000406	time 0.6682 (0.6151)	loss 3.5705 (3.5128)	grad_norm 2.1274 (2.7312)	mem 8931MB
[2022-04-06 13:29:46 large] (main.py 226): INFO Train: [86/300][200/2502]	eta 0:24:09 lr 0.000406	time 0.7283 (0.6297)	loss 3.4701 (3.4915)	grad_norm 2.7826 (2.7045)	mem 8931MB
[2022-04-06 13:30:51 large] (main.py 226): INFO Train: [86/300][300/2502]	eta 0:23:19 lr 0.000406	time 0.5856 (0.6356)	loss 4.1268 (3.5039)	grad_norm 3.0126 (2.7121)	mem 8931MB
[2022-04-06 13:31:56 large] (main.py 226): INFO Train: [86/300][400/2502]	eta 0:22:21 lr 0.000406	time 0.5939 (0.6381)	loss 4.2157 (3.5045)	grad_norm 3.2022 (2.7427)	mem 8931MB
[2022-04-06 13:33:01 large] (main.py 226): INFO Train: [86/300][500/2502]	eta 0:21:23 lr 0.000406	time 0.6815 (0.6411)	loss 3.8900 (3.5198)	grad_norm 2.2481 (2.7492)	mem 8931MB
[2022-04-06 13:34:05 large] (main.py 226): INFO Train: [86/300][600/2502]	eta 0:20:20 lr 0.000406	time 0.6553 (0.6414)	loss 3.6203 (3.5312)	grad_norm 3.1623 (2.7437)	mem 8931MB
[2022-04-06 13:35:09 large] (main.py 226): INFO Train: [86/300][700/2502]	eta 0:19:15 lr 0.000406	time 0.6402 (0.6411)	loss 4.2551 (3.5353)	grad_norm 2.8714 (2.7713)	mem 8931MB
[2022-04-06 13:36:13 large] (main.py 226): INFO Train: [86/300][800/2502]	eta 0:18:10 lr 0.000406	time 0.6330 (0.6405)	loss 4.0082 (3.5481)	grad_norm 2.8042 (2.7678)	mem 8931MB
[2022-04-06 13:37:15 large] (main.py 226): INFO Train: [86/300][900/2502]	eta 0:17:02 lr 0.000406	time 0.4793 (0.6380)	loss 4.1565 (3.5496)	grad_norm 3.2885 (2.7741)	mem 8931MB
[2022-04-06 13:38:13 large] (main.py 226): INFO Train: [86/300][1000/2502]	eta 0:15:50 lr 0.000405	time 0.5934 (0.6327)	loss 3.6257 (3.5563)	grad_norm 2.3382 (2.7848)	mem 8931MB
[2022-04-06 13:39:17 large] (main.py 226): INFO Train: [86/300][1100/2502]	eta 0:14:47 lr 0.000405	time 0.7137 (0.6329)	loss 3.7131 (3.5575)	grad_norm 2.5748 (2.7849)	mem 8931MB
[2022-04-06 13:40:21 large] (main.py 226): INFO Train: [86/300][1200/2502]	eta 0:13:44 lr 0.000405	time 0.6317 (0.6334)	loss 4.3455 (3.5567)	grad_norm 3.1419 (nan)	mem 8931MB
[2022-04-06 13:41:25 large] (main.py 226): INFO Train: [86/300][1300/2502]	eta 0:12:41 lr 0.000405	time 0.6324 (0.6339)	loss 2.3275 (3.5568)	grad_norm 2.5774 (nan)	mem 8931MB
[2022-04-06 13:42:28 large] (main.py 226): INFO Train: [86/300][1400/2502]	eta 0:11:38 lr 0.000405	time 0.6243 (0.6341)	loss 3.6826 (3.5580)	grad_norm 2.2909 (nan)	mem 8931MB
[2022-04-06 13:43:32 large] (main.py 226): INFO Train: [86/300][1500/2502]	eta 0:10:35 lr 0.000405	time 0.6487 (0.6344)	loss 4.1523 (3.5655)	grad_norm 2.4446 (nan)	mem 8931MB
[2022-04-06 13:44:36 large] (main.py 226): INFO Train: [86/300][1600/2502]	eta 0:09:32 lr 0.000405	time 0.5940 (0.6349)	loss 3.4854 (3.5663)	grad_norm 2.4204 (nan)	mem 8931MB
[2022-04-06 13:45:39 large] (main.py 226): INFO Train: [86/300][1700/2502]	eta 0:08:29 lr 0.000405	time 0.7409 (0.6347)	loss 3.8983 (3.5635)	grad_norm 2.7979 (nan)	mem 8931MB
[2022-04-06 13:46:39 large] (main.py 226): INFO Train: [86/300][1800/2502]	eta 0:07:24 lr 0.000405	time 0.5066 (0.6327)	loss 3.7603 (3.5628)	grad_norm 3.5386 (nan)	mem 8931MB
[2022-04-06 13:47:38 large] (main.py 226): INFO Train: [86/300][1900/2502]	eta 0:06:19 lr 0.000405	time 0.6042 (0.6305)	loss 4.5292 (3.5685)	grad_norm 2.7246 (nan)	mem 8931MB
[2022-04-06 13:48:42 large] (main.py 226): INFO Train: [86/300][2000/2502]	eta 0:05:16 lr 0.000405	time 0.6336 (0.6308)	loss 3.0539 (3.5672)	grad_norm 2.5790 (nan)	mem 8931MB
[2022-04-06 13:49:46 large] (main.py 226): INFO Train: [86/300][2100/2502]	eta 0:04:13 lr 0.000405	time 0.6117 (0.6310)	loss 3.8877 (3.5726)	grad_norm 2.7705 (nan)	mem 8931MB
[2022-04-06 13:50:49 large] (main.py 226): INFO Train: [86/300][2200/2502]	eta 0:03:10 lr 0.000404	time 0.5160 (0.6312)	loss 3.5280 (3.5772)	grad_norm 2.2611 (nan)	mem 8931MB
[2022-04-06 13:51:53 large] (main.py 226): INFO Train: [86/300][2300/2502]	eta 0:02:07 lr 0.000404	time 0.5860 (0.6314)	loss 3.4205 (3.5789)	grad_norm 2.0919 (nan)	mem 8931MB
[2022-04-06 13:52:57 large] (main.py 226): INFO Train: [86/300][2400/2502]	eta 0:01:04 lr 0.000404	time 0.5977 (0.6318)	loss 3.7697 (3.5747)	grad_norm 2.6963 (nan)	mem 8931MB
[2022-04-06 13:54:00 large] (main.py 226): INFO Train: [86/300][2500/2502]	eta 0:00:01 lr 0.000404	time 0.6122 (0.6319)	loss 4.0667 (3.5766)	grad_norm 3.6662 (nan)	mem 8931MB
[2022-04-06 13:54:01 large] (main.py 233): INFO EPOCH 86 training takes 0:26:21
[2022-04-06 13:54:08 large] (main.py 273): INFO Test: [0/98]	Time 6.525 (6.525)	Loss 1.1706 (1.1706)	Acc@1 75.000 (75.000)	Acc@5 91.992 (91.992)	Mem 8931MB
[2022-04-06 13:54:34 large] (main.py 279): INFO  * Acc@1 74.442 Acc@5 92.520
[2022-04-06 13:54:34 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 74.4%
[2022-04-06 13:54:34 large] (main.py 148): INFO Max accuracy: 74.57%
[2022-04-06 13:54:41 large] (main.py 226): INFO Train: [87/300][0/2502]	eta 4:43:42 lr 0.000404	time 6.8035 (6.8035)	loss 3.0596 (3.0596)	grad_norm 2.4511 (2.4511)	mem 8931MB
[2022-04-06 13:55:37 large] (main.py 226): INFO Train: [87/300][100/2502]	eta 0:24:51 lr 0.000404	time 0.6246 (0.6210)	loss 3.0399 (3.5300)	grad_norm 3.7507 (2.7154)	mem 8931MB
[2022-04-06 13:56:42 large] (main.py 226): INFO Train: [87/300][200/2502]	eta 0:24:28 lr 0.000404	time 0.6081 (0.6379)	loss 3.9093 (3.5550)	grad_norm 2.2539 (2.7585)	mem 8931MB
[2022-04-06 13:57:47 large] (main.py 226): INFO Train: [87/300][300/2502]	eta 0:23:32 lr 0.000404	time 0.6524 (0.6414)	loss 2.5378 (3.5565)	grad_norm 3.1727 (2.7657)	mem 8931MB
[2022-04-06 13:58:52 large] (main.py 226): INFO Train: [87/300][400/2502]	eta 0:22:32 lr 0.000404	time 0.7147 (0.6434)	loss 4.0868 (3.5795)	grad_norm 3.1198 (2.7576)	mem 8931MB
[2022-04-06 13:59:57 large] (main.py 226): INFO Train: [87/300][500/2502]	eta 0:21:30 lr 0.000404	time 0.6590 (0.6446)	loss 3.3007 (3.5889)	grad_norm 2.6217 (2.7645)	mem 8931MB
[2022-04-06 14:01:01 large] (main.py 226): INFO Train: [87/300][600/2502]	eta 0:20:23 lr 0.000404	time 0.6344 (0.6434)	loss 3.9731 (3.5804)	grad_norm 2.6889 (2.7760)	mem 8931MB
[2022-04-06 14:02:04 large] (main.py 226): INFO Train: [87/300][700/2502]	eta 0:19:16 lr 0.000404	time 0.6094 (0.6419)	loss 2.5540 (3.5674)	grad_norm 4.4043 (2.7864)	mem 8931MB
[2022-04-06 14:03:08 large] (main.py 226): INFO Train: [87/300][800/2502]	eta 0:18:11 lr 0.000404	time 0.7071 (0.6416)	loss 3.1682 (3.5633)	grad_norm 3.9369 (2.7945)	mem 8931MB
[2022-04-06 14:04:12 large] (main.py 226): INFO Train: [87/300][900/2502]	eta 0:17:08 lr 0.000403	time 0.6681 (0.6419)	loss 4.1845 (3.5675)	grad_norm 2.8322 (2.7951)	mem 8931MB
[2022-04-06 14:05:17 large] (main.py 226): INFO Train: [87/300][1000/2502]	eta 0:16:04 lr 0.000403	time 0.6024 (0.6422)	loss 3.2686 (3.5633)	grad_norm 2.6754 (2.7920)	mem 8931MB
[2022-04-06 14:06:19 large] (main.py 226): INFO Train: [87/300][1100/2502]	eta 0:14:58 lr 0.000403	time 0.6351 (0.6407)	loss 2.5682 (3.5641)	grad_norm 2.9095 (2.7923)	mem 8931MB
[2022-04-06 14:07:24 large] (main.py 226): INFO Train: [87/300][1200/2502]	eta 0:13:54 lr 0.000403	time 0.6124 (0.6408)	loss 3.4203 (3.5674)	grad_norm 2.6375 (2.8028)	mem 8931MB
[2022-04-06 14:08:28 large] (main.py 226): INFO Train: [87/300][1300/2502]	eta 0:12:50 lr 0.000403	time 0.6683 (0.6409)	loss 2.8323 (3.5693)	grad_norm 2.5051 (2.7963)	mem 8931MB
[2022-04-06 14:09:32 large] (main.py 226): INFO Train: [87/300][1400/2502]	eta 0:11:46 lr 0.000403	time 0.6438 (0.6412)	loss 3.1011 (3.5736)	grad_norm 3.2991 (nan)	mem 8931MB
[2022-04-06 14:10:37 large] (main.py 226): INFO Train: [87/300][1500/2502]	eta 0:10:42 lr 0.000403	time 0.5676 (0.6415)	loss 3.7104 (3.5708)	grad_norm 2.7917 (nan)	mem 8931MB
[2022-04-06 14:11:41 large] (main.py 226): INFO Train: [87/300][1600/2502]	eta 0:09:38 lr 0.000403	time 0.5629 (0.6414)	loss 3.8644 (3.5719)	grad_norm 2.6976 (nan)	mem 8931MB
[2022-04-06 14:12:45 large] (main.py 226): INFO Train: [87/300][1700/2502]	eta 0:08:34 lr 0.000403	time 0.5693 (0.6411)	loss 3.3231 (3.5702)	grad_norm 2.4570 (nan)	mem 8931MB
[2022-04-06 14:13:48 large] (main.py 226): INFO Train: [87/300][1800/2502]	eta 0:07:29 lr 0.000403	time 0.6929 (0.6406)	loss 2.8833 (3.5730)	grad_norm 2.1259 (nan)	mem 8931MB
[2022-04-06 14:14:52 large] (main.py 226): INFO Train: [87/300][1900/2502]	eta 0:06:25 lr 0.000403	time 0.6084 (0.6406)	loss 2.9812 (3.5728)	grad_norm 2.2561 (nan)	mem 8931MB
[2022-04-06 14:15:56 large] (main.py 226): INFO Train: [87/300][2000/2502]	eta 0:05:21 lr 0.000403	time 0.6828 (0.6408)	loss 3.8444 (3.5696)	grad_norm 2.4232 (nan)	mem 8931MB
[2022-04-06 14:17:00 large] (main.py 226): INFO Train: [87/300][2100/2502]	eta 0:04:17 lr 0.000402	time 0.7771 (0.6405)	loss 3.9999 (3.5685)	grad_norm 2.5767 (nan)	mem 8931MB
[2022-04-06 14:18:06 large] (main.py 226): INFO Train: [87/300][2200/2502]	eta 0:03:13 lr 0.000402	time 0.8111 (0.6414)	loss 4.4201 (3.5688)	grad_norm 3.3725 (nan)	mem 8931MB
[2022-04-06 14:19:10 large] (main.py 226): INFO Train: [87/300][2300/2502]	eta 0:02:09 lr 0.000402	time 0.6738 (0.6415)	loss 3.7853 (3.5665)	grad_norm 2.9280 (nan)	mem 8931MB
[2022-04-06 14:20:15 large] (main.py 226): INFO Train: [87/300][2400/2502]	eta 0:01:05 lr 0.000402	time 0.6420 (0.6416)	loss 2.5856 (3.5670)	grad_norm 1.9744 (nan)	mem 8931MB
[2022-04-06 14:21:19 large] (main.py 226): INFO Train: [87/300][2500/2502]	eta 0:00:01 lr 0.000402	time 0.6244 (0.6417)	loss 3.8722 (3.5643)	grad_norm 2.2094 (nan)	mem 8931MB
[2022-04-06 14:21:20 large] (main.py 233): INFO EPOCH 87 training takes 0:26:45
[2022-04-06 14:21:26 large] (main.py 273): INFO Test: [0/98]	Time 5.650 (5.650)	Loss 1.2653 (1.2653)	Acc@1 73.242 (73.242)	Acc@5 91.211 (91.211)	Mem 8931MB
[2022-04-06 14:21:52 large] (main.py 279): INFO  * Acc@1 74.372 Acc@5 92.434
[2022-04-06 14:21:52 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 74.4%
[2022-04-06 14:21:52 large] (main.py 148): INFO Max accuracy: 74.57%
[2022-04-06 14:21:59 large] (main.py 226): INFO Train: [88/300][0/2502]	eta 5:01:32 lr 0.000402	time 7.2312 (7.2312)	loss 3.8566 (3.8566)	grad_norm 2.9198 (2.9198)	mem 8931MB
[2022-04-06 14:22:52 large] (main.py 226): INFO Train: [88/300][100/2502]	eta 0:23:50 lr 0.000402	time 0.5813 (0.5957)	loss 4.1736 (3.5881)	grad_norm 2.3901 (2.8338)	mem 8931MB
[2022-04-06 14:23:58 large] (main.py 226): INFO Train: [88/300][200/2502]	eta 0:23:59 lr 0.000402	time 0.6072 (0.6254)	loss 4.3172 (3.5354)	grad_norm 3.1802 (2.7872)	mem 8931MB
[2022-04-06 14:25:04 large] (main.py 226): INFO Train: [88/300][300/2502]	eta 0:23:23 lr 0.000402	time 0.6407 (0.6375)	loss 3.5090 (3.5508)	grad_norm 2.5534 (2.7835)	mem 8931MB
[2022-04-06 14:26:10 large] (main.py 226): INFO Train: [88/300][400/2502]	eta 0:22:29 lr 0.000402	time 0.6480 (0.6419)	loss 3.1811 (3.5844)	grad_norm 2.5833 (2.8020)	mem 8931MB
[2022-04-06 14:27:15 large] (main.py 226): INFO Train: [88/300][500/2502]	eta 0:21:29 lr 0.000402	time 0.6212 (0.6442)	loss 3.4938 (3.5975)	grad_norm 2.5468 (2.7828)	mem 8931MB
[2022-04-06 14:28:19 large] (main.py 226): INFO Train: [88/300][600/2502]	eta 0:20:23 lr 0.000402	time 0.8021 (0.6435)	loss 3.2198 (3.5847)	grad_norm 2.7938 (2.7723)	mem 8931MB
[2022-04-06 14:29:24 large] (main.py 226): INFO Train: [88/300][700/2502]	eta 0:19:20 lr 0.000402	time 0.6034 (0.6441)	loss 2.5059 (3.5742)	grad_norm 2.2415 (2.7825)	mem 8931MB
[2022-04-06 14:30:28 large] (main.py 226): INFO Train: [88/300][800/2502]	eta 0:18:16 lr 0.000401	time 0.6677 (0.6441)	loss 2.5008 (3.5743)	grad_norm 3.2112 (2.7785)	mem 8931MB
[2022-04-06 14:31:33 large] (main.py 226): INFO Train: [88/300][900/2502]	eta 0:17:12 lr 0.000401	time 0.7396 (0.6444)	loss 3.3933 (3.5648)	grad_norm 2.9988 (2.7775)	mem 8931MB
[2022-04-06 14:32:36 large] (main.py 226): INFO Train: [88/300][1000/2502]	eta 0:16:06 lr 0.000401	time 0.6798 (0.6435)	loss 3.6618 (3.5663)	grad_norm 3.9660 (2.7787)	mem 8931MB
[2022-04-06 14:33:41 large] (main.py 226): INFO Train: [88/300][1100/2502]	eta 0:15:03 lr 0.000401	time 0.6268 (0.6441)	loss 3.6860 (3.5656)	grad_norm 3.3131 (2.7789)	mem 8931MB
[2022-04-06 14:34:46 large] (main.py 226): INFO Train: [88/300][1200/2502]	eta 0:13:59 lr 0.000401	time 0.6127 (0.6448)	loss 2.6686 (3.5624)	grad_norm 3.2503 (2.7808)	mem 8931MB
[2022-04-06 14:35:51 large] (main.py 226): INFO Train: [88/300][1300/2502]	eta 0:12:54 lr 0.000401	time 0.6835 (0.6444)	loss 3.0907 (3.5608)	grad_norm 2.3993 (2.7807)	mem 8931MB
[2022-04-06 14:36:54 large] (main.py 226): INFO Train: [88/300][1400/2502]	eta 0:11:49 lr 0.000401	time 0.6931 (0.6440)	loss 3.9850 (3.5611)	grad_norm 2.0087 (2.7765)	mem 8931MB
[2022-04-06 14:37:59 large] (main.py 226): INFO Train: [88/300][1500/2502]	eta 0:10:45 lr 0.000401	time 0.6630 (0.6440)	loss 2.9371 (3.5705)	grad_norm 2.1629 (2.7782)	mem 8931MB
[2022-04-06 14:39:05 large] (main.py 226): INFO Train: [88/300][1600/2502]	eta 0:09:41 lr 0.000401	time 0.6909 (0.6451)	loss 2.9527 (3.5629)	grad_norm 2.1429 (2.7797)	mem 8931MB
[2022-04-06 14:40:10 large] (main.py 226): INFO Train: [88/300][1700/2502]	eta 0:08:37 lr 0.000401	time 0.5979 (0.6453)	loss 3.6757 (3.5630)	grad_norm 2.7147 (2.7774)	mem 8931MB
[2022-04-06 14:41:15 large] (main.py 226): INFO Train: [88/300][1800/2502]	eta 0:07:33 lr 0.000401	time 0.7098 (0.6457)	loss 3.9002 (3.5654)	grad_norm 2.3797 (2.7751)	mem 8931MB
[2022-04-06 14:42:19 large] (main.py 226): INFO Train: [88/300][1900/2502]	eta 0:06:28 lr 0.000401	time 0.6144 (0.6454)	loss 4.0951 (3.5706)	grad_norm 3.7369 (2.7695)	mem 8931MB
[2022-04-06 14:43:23 large] (main.py 226): INFO Train: [88/300][2000/2502]	eta 0:05:23 lr 0.000400	time 0.6039 (0.6452)	loss 3.7870 (3.5709)	grad_norm 3.2655 (2.7760)	mem 8931MB
[2022-04-06 14:44:28 large] (main.py 226): INFO Train: [88/300][2100/2502]	eta 0:04:19 lr 0.000400	time 1.2687 (0.6456)	loss 2.5910 (3.5688)	grad_norm 2.9090 (inf)	mem 8931MB
[2022-04-06 14:45:32 large] (main.py 226): INFO Train: [88/300][2200/2502]	eta 0:03:14 lr 0.000400	time 0.7017 (0.6453)	loss 3.5537 (3.5696)	grad_norm 2.2997 (inf)	mem 8931MB
[2022-04-06 14:46:38 large] (main.py 226): INFO Train: [88/300][2300/2502]	eta 0:02:10 lr 0.000400	time 0.7072 (0.6457)	loss 3.7544 (3.5679)	grad_norm 2.3676 (inf)	mem 8931MB
[2022-04-06 14:47:43 large] (main.py 226): INFO Train: [88/300][2400/2502]	eta 0:01:05 lr 0.000400	time 0.7595 (0.6458)	loss 2.5232 (3.5663)	grad_norm 2.2462 (inf)	mem 8931MB
[2022-04-06 14:48:47 large] (main.py 226): INFO Train: [88/300][2500/2502]	eta 0:00:01 lr 0.000400	time 0.5501 (0.6456)	loss 3.6244 (3.5652)	grad_norm 2.3947 (inf)	mem 8931MB
[2022-04-06 14:48:48 large] (main.py 233): INFO EPOCH 88 training takes 0:26:55
[2022-04-06 14:48:55 large] (main.py 273): INFO Test: [0/98]	Time 6.669 (6.669)	Loss 1.1562 (1.1562)	Acc@1 74.609 (74.609)	Acc@5 92.969 (92.969)	Mem 8931MB
[2022-04-06 14:49:21 large] (main.py 279): INFO  * Acc@1 74.798 Acc@5 92.572
[2022-04-06 14:49:21 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 74.8%
[2022-04-06 14:49:21 large] (utils.py 57): INFO output/large/default/ckpt_epoch_88.pth saving......
[2022-04-06 14:49:22 large] (utils.py 59): INFO output/large/default/ckpt_epoch_88.pth saved !!!
[2022-04-06 14:49:22 large] (main.py 148): INFO Max accuracy: 74.80%
[2022-04-06 14:49:30 large] (main.py 226): INFO Train: [89/300][0/2502]	eta 5:32:57 lr 0.000400	time 7.9846 (7.9846)	loss 2.6138 (2.6138)	grad_norm 2.6430 (2.6430)	mem 8931MB
[2022-04-06 14:50:30 large] (main.py 226): INFO Train: [89/300][100/2502]	eta 0:27:03 lr 0.000400	time 0.7120 (0.6757)	loss 4.4868 (3.5718)	grad_norm 3.6920 (2.8226)	mem 8931MB
[2022-04-06 14:51:35 large] (main.py 226): INFO Train: [89/300][200/2502]	eta 0:25:21 lr 0.000400	time 0.6240 (0.6609)	loss 3.7558 (3.6001)	grad_norm 2.9910 (2.7626)	mem 8931MB
[2022-04-06 14:52:41 large] (main.py 226): INFO Train: [89/300][300/2502]	eta 0:24:16 lr 0.000400	time 0.6114 (0.6617)	loss 3.9904 (3.5764)	grad_norm 3.9074 (2.7869)	mem 8931MB
[2022-04-06 14:53:47 large] (main.py 226): INFO Train: [89/300][400/2502]	eta 0:23:08 lr 0.000400	time 0.6063 (0.6604)	loss 3.1447 (3.5682)	grad_norm 2.7687 (2.8237)	mem 8931MB
[2022-04-06 14:54:52 large] (main.py 226): INFO Train: [89/300][500/2502]	eta 0:21:58 lr 0.000400	time 0.6987 (0.6587)	loss 2.6591 (3.5673)	grad_norm 2.7677 (2.8118)	mem 8931MB
[2022-04-06 14:55:55 large] (main.py 226): INFO Train: [89/300][600/2502]	eta 0:20:42 lr 0.000400	time 0.6078 (0.6534)	loss 3.7857 (3.5503)	grad_norm 2.5776 (2.8180)	mem 8931MB
[2022-04-06 14:56:58 large] (main.py 226): INFO Train: [89/300][700/2502]	eta 0:19:33 lr 0.000399	time 0.6313 (0.6512)	loss 3.3579 (3.5560)	grad_norm 2.6525 (2.8074)	mem 8931MB
[2022-04-06 14:58:03 large] (main.py 226): INFO Train: [89/300][800/2502]	eta 0:18:27 lr 0.000399	time 0.6734 (0.6505)	loss 3.1180 (3.5723)	grad_norm 2.5752 (2.8272)	mem 8931MB
[2022-04-06 14:59:08 large] (main.py 226): INFO Train: [89/300][900/2502]	eta 0:17:22 lr 0.000399	time 0.5582 (0.6508)	loss 3.8703 (3.5800)	grad_norm 2.0422 (2.8077)	mem 8931MB
[2022-04-06 15:00:12 large] (main.py 226): INFO Train: [89/300][1000/2502]	eta 0:16:16 lr 0.000399	time 0.6608 (0.6498)	loss 2.6334 (3.5690)	grad_norm 2.4290 (2.8044)	mem 8931MB
[2022-04-06 15:01:17 large] (main.py 226): INFO Train: [89/300][1100/2502]	eta 0:15:10 lr 0.000399	time 0.6508 (0.6496)	loss 3.7110 (3.5754)	grad_norm 2.3404 (2.8057)	mem 8931MB
[2022-04-06 15:02:21 large] (main.py 226): INFO Train: [89/300][1200/2502]	eta 0:14:04 lr 0.000399	time 0.5236 (0.6488)	loss 4.2247 (3.5723)	grad_norm 3.6256 (2.8028)	mem 8931MB
[2022-04-06 15:03:27 large] (main.py 226): INFO Train: [89/300][1300/2502]	eta 0:13:01 lr 0.000399	time 0.6776 (0.6499)	loss 3.7740 (3.5738)	grad_norm 2.8550 (2.8098)	mem 8931MB
[2022-04-06 15:04:31 large] (main.py 226): INFO Train: [89/300][1400/2502]	eta 0:11:55 lr 0.000399	time 0.6328 (0.6491)	loss 3.7994 (3.5747)	grad_norm 3.0080 (2.8094)	mem 8931MB
[2022-04-06 15:05:36 large] (main.py 226): INFO Train: [89/300][1500/2502]	eta 0:10:50 lr 0.000399	time 0.6325 (0.6490)	loss 4.3957 (3.5726)	grad_norm 2.9059 (2.8112)	mem 8931MB
[2022-04-06 15:06:40 large] (main.py 226): INFO Train: [89/300][1600/2502]	eta 0:09:45 lr 0.000399	time 0.7375 (0.6487)	loss 2.8207 (3.5700)	grad_norm 2.7289 (2.8128)	mem 8931MB
[2022-04-06 15:07:45 large] (main.py 226): INFO Train: [89/300][1700/2502]	eta 0:08:40 lr 0.000399	time 0.6821 (0.6485)	loss 2.2227 (3.5697)	grad_norm 2.8838 (2.8038)	mem 8931MB
[2022-04-06 15:08:50 large] (main.py 226): INFO Train: [89/300][1800/2502]	eta 0:07:35 lr 0.000399	time 0.6463 (0.6488)	loss 2.9577 (3.5695)	grad_norm 2.5334 (2.8044)	mem 8931MB
[2022-04-06 15:09:57 large] (main.py 226): INFO Train: [89/300][1900/2502]	eta 0:06:31 lr 0.000398	time 0.7456 (0.6496)	loss 3.2187 (3.5733)	grad_norm 2.4592 (2.8070)	mem 8931MB
[2022-04-06 15:11:02 large] (main.py 226): INFO Train: [89/300][2000/2502]	eta 0:05:26 lr 0.000398	time 0.6531 (0.6498)	loss 4.1370 (3.5710)	grad_norm 2.7016 (2.8082)	mem 8931MB
[2022-04-06 15:12:07 large] (main.py 226): INFO Train: [89/300][2100/2502]	eta 0:04:21 lr 0.000398	time 0.6208 (0.6499)	loss 2.6370 (3.5690)	grad_norm 2.9960 (2.8085)	mem 8931MB
[2022-04-06 15:13:13 large] (main.py 226): INFO Train: [89/300][2200/2502]	eta 0:03:16 lr 0.000398	time 0.7037 (0.6502)	loss 3.6154 (3.5662)	grad_norm 2.4744 (2.8092)	mem 8931MB
[2022-04-06 15:14:19 large] (main.py 226): INFO Train: [89/300][2300/2502]	eta 0:02:11 lr 0.000398	time 0.7193 (0.6507)	loss 2.4690 (3.5652)	grad_norm 2.3607 (2.8108)	mem 8931MB
[2022-04-06 15:15:24 large] (main.py 226): INFO Train: [89/300][2400/2502]	eta 0:01:06 lr 0.000398	time 0.6561 (0.6507)	loss 3.8726 (3.5651)	grad_norm 2.7884 (nan)	mem 8931MB
[2022-04-06 15:16:29 large] (main.py 226): INFO Train: [89/300][2500/2502]	eta 0:00:01 lr 0.000398	time 0.6175 (0.6506)	loss 2.7748 (3.5630)	grad_norm 2.3963 (nan)	mem 8931MB
[2022-04-06 15:16:30 large] (main.py 233): INFO EPOCH 89 training takes 0:27:08
[2022-04-06 15:16:36 large] (main.py 273): INFO Test: [0/98]	Time 6.265 (6.265)	Loss 1.2507 (1.2507)	Acc@1 73.828 (73.828)	Acc@5 92.969 (92.969)	Mem 8931MB
[2022-04-06 15:17:02 large] (main.py 279): INFO  * Acc@1 74.688 Acc@5 92.548
[2022-04-06 15:17:02 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 74.7%
[2022-04-06 15:17:02 large] (main.py 148): INFO Max accuracy: 74.80%
[2022-04-06 15:17:09 large] (main.py 226): INFO Train: [90/300][0/2502]	eta 4:40:00 lr 0.000398	time 6.7150 (6.7150)	loss 3.8150 (3.8150)	grad_norm 2.4310 (2.4310)	mem 8931MB
[2022-04-06 15:18:08 large] (main.py 226): INFO Train: [90/300][100/2502]	eta 0:25:54 lr 0.000398	time 0.6616 (0.6472)	loss 2.9236 (3.5670)	grad_norm 2.9567 (2.8031)	mem 8931MB
[2022-04-06 15:19:14 large] (main.py 226): INFO Train: [90/300][200/2502]	eta 0:25:03 lr 0.000398	time 0.6782 (0.6532)	loss 3.0763 (3.5212)	grad_norm 3.3390 (2.8476)	mem 8931MB
[2022-04-06 15:20:20 large] (main.py 226): INFO Train: [90/300][300/2502]	eta 0:24:07 lr 0.000398	time 0.6022 (0.6572)	loss 3.9042 (3.5187)	grad_norm 2.7536 (2.8395)	mem 8931MB
[2022-04-06 15:21:26 large] (main.py 226): INFO Train: [90/300][400/2502]	eta 0:23:00 lr 0.000398	time 0.6937 (0.6567)	loss 3.7430 (3.5324)	grad_norm 2.1533 (2.8374)	mem 8931MB
[2022-04-06 15:22:32 large] (main.py 226): INFO Train: [90/300][500/2502]	eta 0:21:56 lr 0.000398	time 0.7588 (0.6575)	loss 2.5332 (3.5275)	grad_norm 3.4711 (2.8330)	mem 8931MB
[2022-04-06 15:23:38 large] (main.py 226): INFO Train: [90/300][600/2502]	eta 0:20:52 lr 0.000397	time 0.6937 (0.6585)	loss 3.3761 (3.5403)	grad_norm 2.9179 (2.8322)	mem 8931MB
[2022-04-06 15:24:42 large] (main.py 226): INFO Train: [90/300][700/2502]	eta 0:19:40 lr 0.000397	time 0.6345 (0.6554)	loss 3.6611 (3.5488)	grad_norm 2.5454 (2.8500)	mem 8931MB
[2022-04-06 15:25:47 large] (main.py 226): INFO Train: [90/300][800/2502]	eta 0:18:34 lr 0.000397	time 0.6836 (0.6546)	loss 3.1435 (3.5507)	grad_norm 2.8670 (2.8500)	mem 8931MB
[2022-04-06 15:26:53 large] (main.py 226): INFO Train: [90/300][900/2502]	eta 0:17:29 lr 0.000397	time 0.6955 (0.6552)	loss 4.0652 (3.5569)	grad_norm 2.8713 (2.8420)	mem 8931MB
[2022-04-06 15:27:58 large] (main.py 226): INFO Train: [90/300][1000/2502]	eta 0:16:23 lr 0.000397	time 0.5148 (0.6549)	loss 3.6315 (3.5498)	grad_norm 2.3527 (2.8392)	mem 8931MB
[2022-04-06 15:29:04 large] (main.py 226): INFO Train: [90/300][1100/2502]	eta 0:15:19 lr 0.000397	time 0.5909 (0.6558)	loss 3.9597 (3.5528)	grad_norm 2.5555 (2.8245)	mem 8931MB
[2022-04-06 15:30:09 large] (main.py 226): INFO Train: [90/300][1200/2502]	eta 0:14:12 lr 0.000397	time 0.6493 (0.6551)	loss 4.4980 (3.5532)	grad_norm 3.3960 (2.8370)	mem 8931MB
[2022-04-06 15:31:14 large] (main.py 226): INFO Train: [90/300][1300/2502]	eta 0:13:07 lr 0.000397	time 0.6039 (0.6550)	loss 3.7253 (3.5667)	grad_norm 3.2157 (2.8487)	mem 8931MB
[2022-04-06 15:32:19 large] (main.py 226): INFO Train: [90/300][1400/2502]	eta 0:12:00 lr 0.000397	time 0.6149 (0.6542)	loss 4.1676 (3.5688)	grad_norm 2.7189 (2.8419)	mem 8931MB
[2022-04-06 15:33:24 large] (main.py 226): INFO Train: [90/300][1500/2502]	eta 0:10:55 lr 0.000397	time 0.6151 (0.6539)	loss 3.5801 (3.5734)	grad_norm 3.9756 (2.8433)	mem 8931MB
[2022-04-06 15:34:30 large] (main.py 226): INFO Train: [90/300][1600/2502]	eta 0:09:50 lr 0.000397	time 0.6725 (0.6543)	loss 3.4018 (3.5699)	grad_norm 2.8736 (2.8389)	mem 8931MB
[2022-04-06 15:35:35 large] (main.py 226): INFO Train: [90/300][1700/2502]	eta 0:08:44 lr 0.000397	time 0.5879 (0.6545)	loss 3.8336 (3.5708)	grad_norm 3.0997 (2.8357)	mem 8931MB
[2022-04-06 15:36:41 large] (main.py 226): INFO Train: [90/300][1800/2502]	eta 0:07:39 lr 0.000396	time 0.6764 (0.6544)	loss 2.6229 (3.5766)	grad_norm 2.5489 (2.8357)	mem 8931MB
[2022-04-06 15:37:47 large] (main.py 226): INFO Train: [90/300][1900/2502]	eta 0:06:34 lr 0.000396	time 0.6054 (0.6549)	loss 3.9193 (3.5735)	grad_norm 2.5939 (2.8335)	mem 8931MB
[2022-04-06 15:38:52 large] (main.py 226): INFO Train: [90/300][2000/2502]	eta 0:05:28 lr 0.000396	time 0.6865 (0.6545)	loss 3.9100 (3.5707)	grad_norm 2.0313 (2.8305)	mem 8931MB
[2022-04-06 15:39:58 large] (main.py 226): INFO Train: [90/300][2100/2502]	eta 0:04:23 lr 0.000396	time 0.6871 (0.6550)	loss 2.6315 (3.5694)	grad_norm 2.4510 (2.8279)	mem 8931MB
[2022-04-06 15:41:04 large] (main.py 226): INFO Train: [90/300][2200/2502]	eta 0:03:17 lr 0.000396	time 0.6298 (0.6552)	loss 3.7807 (3.5661)	grad_norm 2.3811 (2.8174)	mem 8931MB
[2022-04-06 15:42:09 large] (main.py 226): INFO Train: [90/300][2300/2502]	eta 0:02:12 lr 0.000396	time 0.6236 (0.6549)	loss 2.9191 (3.5657)	grad_norm 2.4014 (2.8194)	mem 8931MB
[2022-04-06 15:43:14 large] (main.py 226): INFO Train: [90/300][2400/2502]	eta 0:01:06 lr 0.000396	time 0.5002 (0.6546)	loss 3.5217 (3.5672)	grad_norm 2.3769 (2.8163)	mem 8931MB
[2022-04-06 15:44:19 large] (main.py 226): INFO Train: [90/300][2500/2502]	eta 0:00:01 lr 0.000396	time 0.6170 (0.6544)	loss 2.8976 (3.5667)	grad_norm 3.1645 (2.8182)	mem 8931MB
[2022-04-06 15:44:20 large] (main.py 233): INFO EPOCH 90 training takes 0:27:17
[2022-04-06 15:44:26 large] (main.py 273): INFO Test: [0/98]	Time 5.933 (5.933)	Loss 1.3571 (1.3571)	Acc@1 72.656 (72.656)	Acc@5 89.844 (89.844)	Mem 8931MB
[2022-04-06 15:44:52 large] (main.py 279): INFO  * Acc@1 74.488 Acc@5 92.440
[2022-04-06 15:44:52 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 74.5%
[2022-04-06 15:44:52 large] (main.py 148): INFO Max accuracy: 74.80%
[2022-04-06 15:44:59 large] (main.py 226): INFO Train: [91/300][0/2502]	eta 4:22:36 lr 0.000396	time 6.2976 (6.2976)	loss 2.8178 (2.8178)	grad_norm 2.2790 (2.2790)	mem 8931MB
[2022-04-06 15:45:57 large] (main.py 226): INFO Train: [91/300][100/2502]	eta 0:25:30 lr 0.000396	time 0.6069 (0.6374)	loss 3.7191 (3.5211)	grad_norm 2.6249 (2.8312)	mem 8931MB
[2022-04-06 15:47:02 large] (main.py 226): INFO Train: [91/300][200/2502]	eta 0:24:45 lr 0.000396	time 0.6240 (0.6453)	loss 3.5488 (3.5348)	grad_norm 3.3615 (2.8154)	mem 8931MB
[2022-04-06 15:48:08 large] (main.py 226): INFO Train: [91/300][300/2502]	eta 0:23:55 lr 0.000396	time 0.7715 (0.6520)	loss 4.4143 (3.5462)	grad_norm 3.0105 (2.8006)	mem 8931MB
[2022-04-06 15:49:14 large] (main.py 226): INFO Train: [91/300][400/2502]	eta 0:22:54 lr 0.000396	time 0.7127 (0.6539)	loss 4.1622 (3.5880)	grad_norm 2.9940 (2.7854)	mem 8931MB
[2022-04-06 15:50:20 large] (main.py 226): INFO Train: [91/300][500/2502]	eta 0:21:51 lr 0.000395	time 0.6514 (0.6550)	loss 3.7186 (3.5799)	grad_norm 4.1334 (2.7929)	mem 8931MB
[2022-04-06 15:51:26 large] (main.py 226): INFO Train: [91/300][600/2502]	eta 0:20:45 lr 0.000395	time 0.7763 (0.6548)	loss 3.6011 (3.5817)	grad_norm 2.8741 (2.7643)	mem 8931MB
[2022-04-06 15:52:31 large] (main.py 226): INFO Train: [91/300][700/2502]	eta 0:19:38 lr 0.000395	time 0.7267 (0.6539)	loss 3.4822 (3.5787)	grad_norm 2.9276 (2.7869)	mem 8931MB
[2022-04-06 15:53:35 large] (main.py 226): INFO Train: [91/300][800/2502]	eta 0:18:31 lr 0.000395	time 0.6489 (0.6528)	loss 2.6023 (3.5586)	grad_norm 2.3796 (2.8044)	mem 8931MB
[2022-04-06 15:54:39 large] (main.py 226): INFO Train: [91/300][900/2502]	eta 0:17:23 lr 0.000395	time 0.6627 (0.6517)	loss 3.7908 (3.5554)	grad_norm 2.9824 (2.8162)	mem 8931MB
[2022-04-06 15:55:43 large] (main.py 226): INFO Train: [91/300][1000/2502]	eta 0:16:17 lr 0.000395	time 0.6222 (0.6506)	loss 3.9499 (3.5605)	grad_norm 3.6186 (2.8070)	mem 8931MB
[2022-04-06 15:56:48 large] (main.py 226): INFO Train: [91/300][1100/2502]	eta 0:15:11 lr 0.000395	time 0.6640 (0.6501)	loss 3.5492 (3.5690)	grad_norm 3.3686 (2.8012)	mem 8931MB
[2022-04-06 15:57:54 large] (main.py 226): INFO Train: [91/300][1200/2502]	eta 0:14:07 lr 0.000395	time 0.6404 (0.6506)	loss 3.4438 (3.5669)	grad_norm 3.0739 (2.8041)	mem 8931MB
[2022-04-06 15:58:57 large] (main.py 226): INFO Train: [91/300][1300/2502]	eta 0:13:00 lr 0.000395	time 0.5196 (0.6492)	loss 3.2948 (3.5638)	grad_norm 2.4696 (2.8086)	mem 8931MB
[2022-04-06 16:00:01 large] (main.py 226): INFO Train: [91/300][1400/2502]	eta 0:11:54 lr 0.000395	time 0.6890 (0.6483)	loss 4.2716 (3.5699)	grad_norm 2.6567 (2.8156)	mem 8931MB
[2022-04-06 16:01:06 large] (main.py 226): INFO Train: [91/300][1500/2502]	eta 0:10:49 lr 0.000395	time 0.6462 (0.6486)	loss 4.3383 (3.5744)	grad_norm 4.2372 (nan)	mem 8931MB
[2022-04-06 16:02:12 large] (main.py 226): INFO Train: [91/300][1600/2502]	eta 0:09:45 lr 0.000395	time 0.6532 (0.6496)	loss 3.2515 (3.5731)	grad_norm 3.0794 (nan)	mem 8931MB
[2022-04-06 16:03:18 large] (main.py 226): INFO Train: [91/300][1700/2502]	eta 0:08:41 lr 0.000394	time 0.6834 (0.6498)	loss 3.2139 (3.5666)	grad_norm 2.5861 (nan)	mem 8931MB
[2022-04-06 16:04:23 large] (main.py 226): INFO Train: [91/300][1800/2502]	eta 0:07:36 lr 0.000394	time 0.6644 (0.6502)	loss 4.1881 (3.5654)	grad_norm 2.8357 (nan)	mem 8931MB
[2022-04-06 16:05:29 large] (main.py 226): INFO Train: [91/300][1900/2502]	eta 0:06:31 lr 0.000394	time 0.6340 (0.6507)	loss 4.0692 (3.5663)	grad_norm 2.9144 (nan)	mem 8931MB
[2022-04-06 16:06:35 large] (main.py 226): INFO Train: [91/300][2000/2502]	eta 0:05:26 lr 0.000394	time 0.5871 (0.6509)	loss 2.8216 (3.5705)	grad_norm 2.4736 (nan)	mem 8931MB
[2022-04-06 16:07:39 large] (main.py 226): INFO Train: [91/300][2100/2502]	eta 0:04:21 lr 0.000394	time 0.6329 (0.6504)	loss 3.2948 (3.5700)	grad_norm 2.9976 (nan)	mem 8931MB
[2022-04-06 16:08:43 large] (main.py 226): INFO Train: [91/300][2200/2502]	eta 0:03:16 lr 0.000394	time 0.6551 (0.6501)	loss 3.4770 (3.5663)	grad_norm 2.3018 (nan)	mem 8931MB
[2022-04-06 16:09:47 large] (main.py 226): INFO Train: [91/300][2300/2502]	eta 0:02:11 lr 0.000394	time 0.5845 (0.6496)	loss 3.8243 (3.5694)	grad_norm 2.4982 (nan)	mem 8931MB
[2022-04-06 16:10:52 large] (main.py 226): INFO Train: [91/300][2400/2502]	eta 0:01:06 lr 0.000394	time 0.7150 (0.6496)	loss 3.0161 (3.5623)	grad_norm 2.7478 (nan)	mem 8931MB
[2022-04-06 16:11:56 large] (main.py 226): INFO Train: [91/300][2500/2502]	eta 0:00:01 lr 0.000394	time 0.6041 (0.6493)	loss 3.4528 (3.5628)	grad_norm 2.6041 (nan)	mem 8931MB
[2022-04-06 16:11:57 large] (main.py 233): INFO EPOCH 91 training takes 0:27:05
[2022-04-06 16:12:03 large] (main.py 273): INFO Test: [0/98]	Time 6.107 (6.107)	Loss 1.0796 (1.0796)	Acc@1 76.367 (76.367)	Acc@5 93.945 (93.945)	Mem 8931MB
[2022-04-06 16:12:31 large] (main.py 279): INFO  * Acc@1 74.790 Acc@5 92.634
[2022-04-06 16:12:31 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 74.8%
[2022-04-06 16:12:31 large] (main.py 148): INFO Max accuracy: 74.80%
[2022-04-06 16:12:38 large] (main.py 226): INFO Train: [92/300][0/2502]	eta 5:00:00 lr 0.000394	time 7.1943 (7.1943)	loss 2.6840 (2.6840)	grad_norm 2.9062 (2.9062)	mem 8931MB
[2022-04-06 16:13:40 large] (main.py 226): INFO Train: [92/300][100/2502]	eta 0:27:28 lr 0.000394	time 0.6753 (0.6861)	loss 2.4344 (3.5169)	grad_norm 2.3810 (2.8350)	mem 8931MB
[2022-04-06 16:14:44 large] (main.py 226): INFO Train: [92/300][200/2502]	eta 0:25:33 lr 0.000394	time 0.6936 (0.6662)	loss 3.0141 (3.5319)	grad_norm 2.2703 (2.8697)	mem 8931MB
[2022-04-06 16:15:49 large] (main.py 226): INFO Train: [92/300][300/2502]	eta 0:24:14 lr 0.000393	time 0.5494 (0.6605)	loss 3.2733 (3.5645)	grad_norm 2.9632 (2.8459)	mem 8931MB
[2022-04-06 16:16:54 large] (main.py 226): INFO Train: [92/300][400/2502]	eta 0:23:03 lr 0.000393	time 0.6865 (0.6582)	loss 3.4037 (3.5832)	grad_norm 2.4863 (2.8532)	mem 8931MB
[2022-04-06 16:17:59 large] (main.py 226): INFO Train: [92/300][500/2502]	eta 0:21:53 lr 0.000393	time 0.5787 (0.6561)	loss 3.2755 (3.5805)	grad_norm 2.5220 (2.8229)	mem 8931MB
[2022-04-06 16:19:05 large] (main.py 226): INFO Train: [92/300][600/2502]	eta 0:20:47 lr 0.000393	time 0.5919 (0.6559)	loss 3.8696 (3.5897)	grad_norm 2.7823 (2.8265)	mem 8931MB
[2022-04-06 16:20:09 large] (main.py 226): INFO Train: [92/300][700/2502]	eta 0:19:39 lr 0.000393	time 0.7422 (0.6545)	loss 4.2989 (3.5873)	grad_norm 2.3504 (2.8372)	mem 8931MB
[2022-04-06 16:21:15 large] (main.py 226): INFO Train: [92/300][800/2502]	eta 0:18:34 lr 0.000393	time 0.6883 (0.6548)	loss 3.6791 (3.5788)	grad_norm 2.7015 (2.8368)	mem 8931MB
[2022-04-06 16:22:20 large] (main.py 226): INFO Train: [92/300][900/2502]	eta 0:17:28 lr 0.000393	time 0.6355 (0.6544)	loss 3.9522 (3.5752)	grad_norm 2.6212 (2.8279)	mem 8931MB
[2022-04-06 16:23:26 large] (main.py 226): INFO Train: [92/300][1000/2502]	eta 0:16:24 lr 0.000393	time 0.6882 (0.6553)	loss 2.5472 (3.5646)	grad_norm 2.4941 (2.8400)	mem 8931MB
[2022-04-06 16:24:31 large] (main.py 226): INFO Train: [92/300][1100/2502]	eta 0:15:17 lr 0.000393	time 0.7834 (0.6546)	loss 3.2112 (3.5647)	grad_norm 2.9726 (nan)	mem 8931MB
[2022-04-06 16:25:36 large] (main.py 226): INFO Train: [92/300][1200/2502]	eta 0:14:11 lr 0.000393	time 0.6691 (0.6540)	loss 3.3358 (3.5693)	grad_norm 2.1568 (nan)	mem 8931MB
[2022-04-06 16:26:41 large] (main.py 226): INFO Train: [92/300][1300/2502]	eta 0:13:05 lr 0.000393	time 0.7814 (0.6537)	loss 2.6068 (3.5656)	grad_norm 2.6403 (nan)	mem 8931MB
[2022-04-06 16:27:46 large] (main.py 226): INFO Train: [92/300][1400/2502]	eta 0:12:00 lr 0.000393	time 0.6386 (0.6537)	loss 4.3413 (3.5657)	grad_norm 3.0689 (nan)	mem 8931MB
[2022-04-06 16:28:52 large] (main.py 226): INFO Train: [92/300][1500/2502]	eta 0:10:54 lr 0.000392	time 0.6143 (0.6536)	loss 4.0361 (3.5664)	grad_norm 2.2602 (nan)	mem 8931MB
[2022-04-06 16:29:56 large] (main.py 226): INFO Train: [92/300][1600/2502]	eta 0:09:49 lr 0.000392	time 0.6561 (0.6531)	loss 4.1349 (3.5663)	grad_norm 2.3028 (nan)	mem 8931MB
[2022-04-06 16:31:01 large] (main.py 226): INFO Train: [92/300][1700/2502]	eta 0:08:43 lr 0.000392	time 0.6624 (0.6529)	loss 3.7957 (3.5661)	grad_norm 2.7643 (nan)	mem 8931MB
[2022-04-06 16:32:06 large] (main.py 226): INFO Train: [92/300][1800/2502]	eta 0:07:38 lr 0.000392	time 0.6413 (0.6528)	loss 4.2774 (3.5656)	grad_norm 2.5883 (nan)	mem 8931MB
[2022-04-06 16:33:10 large] (main.py 226): INFO Train: [92/300][1900/2502]	eta 0:06:32 lr 0.000392	time 0.5883 (0.6522)	loss 3.7442 (3.5659)	grad_norm 2.9084 (nan)	mem 8931MB
[2022-04-06 16:34:15 large] (main.py 226): INFO Train: [92/300][2000/2502]	eta 0:05:27 lr 0.000392	time 0.6598 (0.6521)	loss 2.5796 (3.5692)	grad_norm 3.5970 (nan)	mem 8931MB
[2022-04-06 16:35:21 large] (main.py 226): INFO Train: [92/300][2100/2502]	eta 0:04:22 lr 0.000392	time 0.5284 (0.6522)	loss 3.2584 (3.5744)	grad_norm 2.5628 (nan)	mem 8931MB
[2022-04-06 16:36:26 large] (main.py 226): INFO Train: [92/300][2200/2502]	eta 0:03:16 lr 0.000392	time 0.6438 (0.6521)	loss 2.8066 (3.5704)	grad_norm 3.5499 (nan)	mem 8931MB
[2022-04-06 16:37:31 large] (main.py 226): INFO Train: [92/300][2300/2502]	eta 0:02:11 lr 0.000392	time 0.7083 (0.6520)	loss 4.1293 (3.5717)	grad_norm 2.8463 (nan)	mem 8931MB
[2022-04-06 16:38:35 large] (main.py 226): INFO Train: [92/300][2400/2502]	eta 0:01:06 lr 0.000392	time 0.7255 (0.6516)	loss 3.8185 (3.5707)	grad_norm 2.8470 (nan)	mem 8931MB
[2022-04-06 16:39:39 large] (main.py 226): INFO Train: [92/300][2500/2502]	eta 0:00:01 lr 0.000392	time 0.6108 (0.6510)	loss 2.4402 (3.5738)	grad_norm 2.7541 (nan)	mem 8931MB
[2022-04-06 16:39:40 large] (main.py 233): INFO EPOCH 92 training takes 0:27:09
[2022-04-06 16:39:46 large] (main.py 273): INFO Test: [0/98]	Time 6.350 (6.350)	Loss 1.2524 (1.2524)	Acc@1 72.852 (72.852)	Acc@5 91.797 (91.797)	Mem 8931MB
[2022-04-06 16:40:12 large] (main.py 279): INFO  * Acc@1 74.768 Acc@5 92.532
[2022-04-06 16:40:12 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 74.8%
[2022-04-06 16:40:12 large] (main.py 148): INFO Max accuracy: 74.80%
[2022-04-06 16:40:19 large] (main.py 226): INFO Train: [93/300][0/2502]	eta 5:00:04 lr 0.000392	time 7.1959 (7.1959)	loss 2.7795 (2.7795)	grad_norm 2.9367 (2.9367)	mem 8931MB
[2022-04-06 16:41:14 large] (main.py 226): INFO Train: [93/300][100/2502]	eta 0:24:36 lr 0.000392	time 0.7121 (0.6145)	loss 2.3794 (3.5704)	grad_norm 2.8864 (2.9340)	mem 8931MB
[2022-04-06 16:42:20 large] (main.py 226): INFO Train: [93/300][200/2502]	eta 0:24:33 lr 0.000391	time 0.7081 (0.6399)	loss 3.4819 (3.5502)	grad_norm 3.4683 (2.8884)	mem 8931MB
[2022-04-06 16:43:26 large] (main.py 226): INFO Train: [93/300][300/2502]	eta 0:23:44 lr 0.000391	time 0.6689 (0.6468)	loss 3.8177 (3.5573)	grad_norm 2.5155 (2.8622)	mem 8931MB
[2022-04-06 16:44:33 large] (main.py 226): INFO Train: [93/300][400/2502]	eta 0:22:47 lr 0.000391	time 0.6538 (0.6506)	loss 3.7155 (3.5701)	grad_norm 2.8050 (2.8522)	mem 8931MB
[2022-04-06 16:45:38 large] (main.py 226): INFO Train: [93/300][500/2502]	eta 0:21:45 lr 0.000391	time 0.5445 (0.6522)	loss 2.8993 (3.5571)	grad_norm 2.1266 (2.8460)	mem 8931MB
[2022-04-06 16:46:43 large] (main.py 226): INFO Train: [93/300][600/2502]	eta 0:20:39 lr 0.000391	time 0.6083 (0.6515)	loss 3.6745 (3.5517)	grad_norm 3.0260 (2.8269)	mem 8931MB
[2022-04-06 16:47:48 large] (main.py 226): INFO Train: [93/300][700/2502]	eta 0:19:32 lr 0.000391	time 0.6315 (0.6507)	loss 4.0498 (3.5480)	grad_norm 2.7100 (2.8251)	mem 8931MB
[2022-04-06 16:48:52 large] (main.py 226): INFO Train: [93/300][800/2502]	eta 0:18:25 lr 0.000391	time 0.7727 (0.6496)	loss 4.4802 (3.5580)	grad_norm 3.0346 (2.8545)	mem 8931MB
[2022-04-06 16:49:57 large] (main.py 226): INFO Train: [93/300][900/2502]	eta 0:17:20 lr 0.000391	time 0.5616 (0.6497)	loss 3.8001 (3.5609)	grad_norm 2.6433 (2.8485)	mem 8931MB
[2022-04-06 16:51:02 large] (main.py 226): INFO Train: [93/300][1000/2502]	eta 0:16:16 lr 0.000391	time 0.5765 (0.6502)	loss 2.5575 (3.5505)	grad_norm 3.4141 (2.8429)	mem 8931MB
[2022-04-06 16:52:08 large] (main.py 226): INFO Train: [93/300][1100/2502]	eta 0:15:11 lr 0.000391	time 0.6169 (0.6503)	loss 3.9365 (3.5435)	grad_norm 3.9777 (2.8460)	mem 8931MB
[2022-04-06 16:53:11 large] (main.py 226): INFO Train: [93/300][1200/2502]	eta 0:14:05 lr 0.000391	time 0.6516 (0.6493)	loss 3.8255 (3.5344)	grad_norm 4.9473 (2.8492)	mem 8931MB
[2022-04-06 16:54:16 large] (main.py 226): INFO Train: [93/300][1300/2502]	eta 0:13:00 lr 0.000390	time 0.5956 (0.6493)	loss 3.7695 (3.5410)	grad_norm 3.1272 (2.8444)	mem 8931MB
[2022-04-06 16:55:22 large] (main.py 226): INFO Train: [93/300][1400/2502]	eta 0:11:55 lr 0.000390	time 0.5450 (0.6497)	loss 4.0718 (3.5403)	grad_norm 2.7676 (2.8448)	mem 8931MB
[2022-04-06 16:56:27 large] (main.py 226): INFO Train: [93/300][1500/2502]	eta 0:10:50 lr 0.000390	time 0.6856 (0.6495)	loss 4.2037 (3.5472)	grad_norm 3.3842 (2.8520)	mem 8931MB
[2022-04-06 16:57:32 large] (main.py 226): INFO Train: [93/300][1600/2502]	eta 0:09:46 lr 0.000390	time 0.6368 (0.6497)	loss 3.9150 (3.5455)	grad_norm 2.8772 (2.8495)	mem 8931MB
[2022-04-06 16:58:36 large] (main.py 226): INFO Train: [93/300][1700/2502]	eta 0:08:40 lr 0.000390	time 0.6365 (0.6495)	loss 3.3869 (3.5483)	grad_norm 2.9333 (nan)	mem 8931MB
[2022-04-06 16:59:42 large] (main.py 226): INFO Train: [93/300][1800/2502]	eta 0:07:36 lr 0.000390	time 0.7242 (0.6499)	loss 3.9566 (3.5483)	grad_norm 2.7501 (nan)	mem 8931MB
[2022-04-06 17:00:47 large] (main.py 226): INFO Train: [93/300][1900/2502]	eta 0:06:31 lr 0.000390	time 0.6342 (0.6497)	loss 3.5453 (3.5477)	grad_norm 3.1959 (nan)	mem 8931MB
[2022-04-06 17:01:52 large] (main.py 226): INFO Train: [93/300][2000/2502]	eta 0:05:26 lr 0.000390	time 0.7180 (0.6500)	loss 3.6653 (3.5454)	grad_norm 2.0570 (nan)	mem 8931MB
[2022-04-06 17:02:58 large] (main.py 226): INFO Train: [93/300][2100/2502]	eta 0:04:21 lr 0.000390	time 0.6087 (0.6504)	loss 3.9324 (3.5425)	grad_norm 2.4420 (nan)	mem 8931MB
[2022-04-06 17:04:03 large] (main.py 226): INFO Train: [93/300][2200/2502]	eta 0:03:16 lr 0.000390	time 0.6748 (0.6503)	loss 3.6890 (3.5384)	grad_norm 4.3340 (nan)	mem 8931MB
[2022-04-06 17:05:08 large] (main.py 226): INFO Train: [93/300][2300/2502]	eta 0:02:11 lr 0.000390	time 0.7402 (0.6502)	loss 3.9638 (3.5425)	grad_norm 2.6752 (nan)	mem 8931MB
[2022-04-06 17:06:10 large] (main.py 226): INFO Train: [93/300][2400/2502]	eta 0:01:06 lr 0.000390	time 0.7241 (0.6492)	loss 2.4375 (3.5435)	grad_norm 2.2219 (nan)	mem 8931MB
[2022-04-06 17:07:13 large] (main.py 226): INFO Train: [93/300][2500/2502]	eta 0:00:01 lr 0.000389	time 0.5921 (0.6484)	loss 4.2218 (3.5435)	grad_norm 2.9547 (nan)	mem 8931MB
[2022-04-06 17:07:15 large] (main.py 233): INFO EPOCH 93 training takes 0:27:03
[2022-04-06 17:07:21 large] (main.py 273): INFO Test: [0/98]	Time 6.173 (6.173)	Loss 1.3799 (1.3799)	Acc@1 72.266 (72.266)	Acc@5 90.430 (90.430)	Mem 8931MB
[2022-04-06 17:07:47 large] (main.py 279): INFO  * Acc@1 74.922 Acc@5 92.486
[2022-04-06 17:07:47 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 74.9%
[2022-04-06 17:07:47 large] (utils.py 57): INFO output/large/default/ckpt_epoch_93.pth saving......
[2022-04-06 17:07:48 large] (utils.py 59): INFO output/large/default/ckpt_epoch_93.pth saved !!!
[2022-04-06 17:07:48 large] (main.py 148): INFO Max accuracy: 74.92%
[2022-04-06 17:07:56 large] (main.py 226): INFO Train: [94/300][0/2502]	eta 5:15:22 lr 0.000389	time 7.5630 (7.5630)	loss 2.7779 (2.7779)	grad_norm 3.2651 (3.2651)	mem 8931MB
[2022-04-06 17:08:44 large] (main.py 226): INFO Train: [94/300][100/2502]	eta 0:22:09 lr 0.000389	time 0.4622 (0.5537)	loss 3.6361 (3.5241)	grad_norm 3.2501 (2.7620)	mem 8931MB
[2022-04-06 17:09:35 large] (main.py 226): INFO Train: [94/300][200/2502]	eta 0:20:26 lr 0.000389	time 0.5192 (0.5330)	loss 3.4236 (3.5693)	grad_norm 2.9205 (2.8425)	mem 8931MB
[2022-04-06 17:10:44 large] (main.py 226): INFO Train: [94/300][300/2502]	eta 0:21:23 lr 0.000389	time 0.6334 (0.5831)	loss 3.0850 (3.5541)	grad_norm 3.2072 (2.8496)	mem 8931MB
[2022-04-06 17:11:52 large] (main.py 226): INFO Train: [94/300][400/2502]	eta 0:21:16 lr 0.000389	time 0.6932 (0.6074)	loss 4.5468 (3.5726)	grad_norm 2.6617 (2.8736)	mem 8931MB
[2022-04-06 17:13:00 large] (main.py 226): INFO Train: [94/300][500/2502]	eta 0:20:45 lr 0.000389	time 0.7023 (0.6219)	loss 2.8968 (3.5603)	grad_norm 2.7377 (2.8511)	mem 8931MB
[2022-04-06 17:14:07 large] (main.py 226): INFO Train: [94/300][600/2502]	eta 0:19:59 lr 0.000389	time 0.6072 (0.6304)	loss 3.4876 (3.5453)	grad_norm 2.8839 (2.8561)	mem 8931MB
[2022-04-06 17:15:13 large] (main.py 226): INFO Train: [94/300][700/2502]	eta 0:19:03 lr 0.000389	time 0.7650 (0.6345)	loss 2.7475 (3.5504)	grad_norm 3.9273 (2.8611)	mem 8931MB
[2022-04-06 17:16:20 large] (main.py 226): INFO Train: [94/300][800/2502]	eta 0:18:07 lr 0.000389	time 0.4578 (0.6390)	loss 4.5128 (3.5560)	grad_norm 2.9916 (2.8618)	mem 8931MB
[2022-04-06 17:17:24 large] (main.py 226): INFO Train: [94/300][900/2502]	eta 0:17:04 lr 0.000389	time 0.6994 (0.6398)	loss 3.7952 (3.5523)	grad_norm 2.4994 (2.8607)	mem 8931MB
[2022-04-06 17:18:30 large] (main.py 226): INFO Train: [94/300][1000/2502]	eta 0:16:03 lr 0.000389	time 0.7581 (0.6415)	loss 2.8270 (3.5480)	grad_norm 3.1425 (2.8714)	mem 8931MB
[2022-04-06 17:19:36 large] (main.py 226): INFO Train: [94/300][1100/2502]	eta 0:15:00 lr 0.000389	time 0.6058 (0.6426)	loss 2.4120 (3.5408)	grad_norm 2.9584 (2.8768)	mem 8931MB
[2022-04-06 17:20:41 large] (main.py 226): INFO Train: [94/300][1200/2502]	eta 0:13:58 lr 0.000388	time 0.6566 (0.6436)	loss 3.9909 (3.5427)	grad_norm 3.0434 (2.8678)	mem 8931MB
[2022-04-06 17:21:47 large] (main.py 226): INFO Train: [94/300][1300/2502]	eta 0:12:55 lr 0.000388	time 0.6514 (0.6451)	loss 2.5882 (3.5426)	grad_norm 2.9744 (2.8655)	mem 8931MB
[2022-04-06 17:22:53 large] (main.py 226): INFO Train: [94/300][1400/2502]	eta 0:11:52 lr 0.000388	time 0.6560 (0.6461)	loss 3.7142 (3.5475)	grad_norm 2.7734 (2.8640)	mem 8931MB
[2022-04-06 17:23:59 large] (main.py 226): INFO Train: [94/300][1500/2502]	eta 0:10:48 lr 0.000388	time 0.7470 (0.6469)	loss 3.2698 (3.5525)	grad_norm 2.1741 (2.8577)	mem 8931MB
[2022-04-06 17:25:05 large] (main.py 226): INFO Train: [94/300][1600/2502]	eta 0:09:44 lr 0.000388	time 0.6677 (0.6477)	loss 3.4517 (3.5485)	grad_norm 3.0760 (2.8539)	mem 8931MB
[2022-04-06 17:26:11 large] (main.py 226): INFO Train: [94/300][1700/2502]	eta 0:08:40 lr 0.000388	time 0.6143 (0.6486)	loss 3.7741 (3.5421)	grad_norm 2.4919 (2.8522)	mem 8931MB
[2022-04-06 17:27:18 large] (main.py 226): INFO Train: [94/300][1800/2502]	eta 0:07:35 lr 0.000388	time 0.7661 (0.6494)	loss 3.6427 (3.5400)	grad_norm 2.2153 (2.8522)	mem 8931MB
[2022-04-06 17:28:24 large] (main.py 226): INFO Train: [94/300][1900/2502]	eta 0:06:31 lr 0.000388	time 0.6853 (0.6501)	loss 3.9551 (3.5353)	grad_norm 2.4890 (2.8525)	mem 8931MB
[2022-04-06 17:29:29 large] (main.py 226): INFO Train: [94/300][2000/2502]	eta 0:05:26 lr 0.000388	time 0.6838 (0.6502)	loss 3.5398 (3.5344)	grad_norm 3.3473 (2.8471)	mem 8931MB
[2022-04-06 17:30:34 large] (main.py 226): INFO Train: [94/300][2100/2502]	eta 0:04:21 lr 0.000388	time 0.6172 (0.6503)	loss 3.6776 (3.5366)	grad_norm 2.4528 (2.8520)	mem 8931MB
[2022-04-06 17:31:40 large] (main.py 226): INFO Train: [94/300][2200/2502]	eta 0:03:16 lr 0.000388	time 0.6259 (0.6507)	loss 3.4362 (3.5387)	grad_norm 2.9647 (2.8528)	mem 8931MB
[2022-04-06 17:32:46 large] (main.py 226): INFO Train: [94/300][2300/2502]	eta 0:02:11 lr 0.000387	time 0.6192 (0.6509)	loss 3.9052 (3.5364)	grad_norm 3.1252 (2.8470)	mem 8931MB
[2022-04-06 17:33:51 large] (main.py 226): INFO Train: [94/300][2400/2502]	eta 0:01:06 lr 0.000387	time 0.7229 (0.6511)	loss 3.8642 (3.5376)	grad_norm 2.5060 (2.8507)	mem 8931MB
[2022-04-06 17:34:56 large] (main.py 226): INFO Train: [94/300][2500/2502]	eta 0:00:01 lr 0.000387	time 0.6042 (0.6509)	loss 3.5058 (3.5409)	grad_norm 2.9355 (2.8546)	mem 8931MB
[2022-04-06 17:34:57 large] (main.py 233): INFO EPOCH 94 training takes 0:27:08
[2022-04-06 17:35:02 large] (main.py 273): INFO Test: [0/98]	Time 5.581 (5.581)	Loss 1.0648 (1.0648)	Acc@1 77.344 (77.344)	Acc@5 94.531 (94.531)	Mem 8931MB
[2022-04-06 17:35:29 large] (main.py 279): INFO  * Acc@1 74.784 Acc@5 92.614
[2022-04-06 17:35:29 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 74.8%
[2022-04-06 17:35:29 large] (main.py 148): INFO Max accuracy: 74.92%
[2022-04-06 17:35:36 large] (main.py 226): INFO Train: [95/300][0/2502]	eta 4:28:53 lr 0.000387	time 6.4482 (6.4482)	loss 3.3127 (3.3127)	grad_norm 4.7154 (4.7154)	mem 8931MB
[2022-04-06 17:36:33 large] (main.py 226): INFO Train: [95/300][100/2502]	eta 0:25:13 lr 0.000387	time 0.6579 (0.6302)	loss 3.9619 (3.4841)	grad_norm 2.6730 (2.9235)	mem 8931MB
[2022-04-06 17:37:41 large] (main.py 226): INFO Train: [95/300][200/2502]	eta 0:25:01 lr 0.000387	time 0.5881 (0.6521)	loss 2.6224 (3.5312)	grad_norm 3.1241 (2.8978)	mem 8931MB
[2022-04-06 17:38:48 large] (main.py 226): INFO Train: [95/300][300/2502]	eta 0:24:12 lr 0.000387	time 0.6608 (0.6598)	loss 3.7178 (3.5113)	grad_norm 3.4048 (2.8680)	mem 8931MB
[2022-04-06 17:39:54 large] (main.py 226): INFO Train: [95/300][400/2502]	eta 0:23:06 lr 0.000387	time 0.6917 (0.6598)	loss 3.3940 (3.5178)	grad_norm 2.8282 (2.8460)	mem 8931MB
[2022-04-06 17:41:01 large] (main.py 226): INFO Train: [95/300][500/2502]	eta 0:22:04 lr 0.000387	time 0.7354 (0.6614)	loss 3.9721 (3.5254)	grad_norm 3.1752 (2.8645)	mem 8931MB
[2022-04-06 17:42:07 large] (main.py 226): INFO Train: [95/300][600/2502]	eta 0:20:57 lr 0.000387	time 0.6692 (0.6610)	loss 3.4766 (3.5169)	grad_norm 3.6058 (2.8839)	mem 8931MB
[2022-04-06 17:43:13 large] (main.py 226): INFO Train: [95/300][700/2502]	eta 0:19:50 lr 0.000387	time 0.6433 (0.6607)	loss 3.8857 (3.5277)	grad_norm 2.5907 (inf)	mem 8931MB
[2022-04-06 17:44:19 large] (main.py 226): INFO Train: [95/300][800/2502]	eta 0:18:45 lr 0.000387	time 0.6780 (0.6611)	loss 3.4805 (3.5195)	grad_norm 2.9354 (inf)	mem 8931MB
[2022-04-06 17:45:25 large] (main.py 226): INFO Train: [95/300][900/2502]	eta 0:17:39 lr 0.000387	time 0.6630 (0.6612)	loss 2.1907 (3.5196)	grad_norm 2.5781 (inf)	mem 8931MB
[2022-04-06 17:46:29 large] (main.py 226): INFO Train: [95/300][1000/2502]	eta 0:16:30 lr 0.000386	time 0.6856 (0.6593)	loss 3.8087 (3.5225)	grad_norm 3.5970 (inf)	mem 8931MB
[2022-04-06 17:47:35 large] (main.py 226): INFO Train: [95/300][1100/2502]	eta 0:15:23 lr 0.000386	time 0.6481 (0.6588)	loss 4.2084 (3.5272)	grad_norm 2.7479 (inf)	mem 8931MB
[2022-04-06 17:48:39 large] (main.py 226): INFO Train: [95/300][1200/2502]	eta 0:14:16 lr 0.000386	time 0.6445 (0.6577)	loss 2.4833 (3.5232)	grad_norm 2.7797 (inf)	mem 8931MB
[2022-04-06 17:49:45 large] (main.py 226): INFO Train: [95/300][1300/2502]	eta 0:13:10 lr 0.000386	time 0.5939 (0.6574)	loss 3.2963 (3.5181)	grad_norm 2.8717 (inf)	mem 8931MB
[2022-04-06 17:50:48 large] (main.py 226): INFO Train: [95/300][1400/2502]	eta 0:12:02 lr 0.000386	time 0.5973 (0.6555)	loss 3.5682 (3.5190)	grad_norm 2.9277 (inf)	mem 8931MB
[2022-04-06 17:51:52 large] (main.py 226): INFO Train: [95/300][1500/2502]	eta 0:10:56 lr 0.000386	time 0.6463 (0.6549)	loss 3.0130 (3.5226)	grad_norm 2.2459 (inf)	mem 8931MB
[2022-04-06 17:52:58 large] (main.py 226): INFO Train: [95/300][1600/2502]	eta 0:09:50 lr 0.000386	time 0.7075 (0.6549)	loss 4.0990 (3.5347)	grad_norm 3.5179 (inf)	mem 8931MB
[2022-04-06 17:54:02 large] (main.py 226): INFO Train: [95/300][1700/2502]	eta 0:08:44 lr 0.000386	time 0.6421 (0.6540)	loss 2.6241 (3.5339)	grad_norm 3.7054 (inf)	mem 8931MB
[2022-04-06 17:55:08 large] (main.py 226): INFO Train: [95/300][1800/2502]	eta 0:07:39 lr 0.000386	time 0.6845 (0.6546)	loss 3.6992 (3.5383)	grad_norm 2.8795 (inf)	mem 8931MB
[2022-04-06 17:56:14 large] (main.py 226): INFO Train: [95/300][1900/2502]	eta 0:06:34 lr 0.000386	time 0.6262 (0.6546)	loss 2.4829 (3.5371)	grad_norm 2.4491 (inf)	mem 8931MB
[2022-04-06 17:57:19 large] (main.py 226): INFO Train: [95/300][2000/2502]	eta 0:05:28 lr 0.000386	time 0.6506 (0.6547)	loss 3.8344 (3.5400)	grad_norm 2.8061 (inf)	mem 8931MB
[2022-04-06 17:58:26 large] (main.py 226): INFO Train: [95/300][2100/2502]	eta 0:04:23 lr 0.000385	time 0.6565 (0.6553)	loss 4.1302 (3.5420)	grad_norm 3.3739 (inf)	mem 8931MB
[2022-04-06 17:59:34 large] (main.py 226): INFO Train: [95/300][2200/2502]	eta 0:03:18 lr 0.000385	time 0.6761 (0.6562)	loss 3.5215 (3.5351)	grad_norm 2.8738 (inf)	mem 8931MB
[2022-04-06 18:00:40 large] (main.py 226): INFO Train: [95/300][2300/2502]	eta 0:02:12 lr 0.000385	time 0.6305 (0.6563)	loss 3.6347 (3.5342)	grad_norm 2.5207 (inf)	mem 8931MB
[2022-04-06 18:01:45 large] (main.py 226): INFO Train: [95/300][2400/2502]	eta 0:01:06 lr 0.000385	time 0.6301 (0.6560)	loss 2.3432 (3.5365)	grad_norm 3.6341 (inf)	mem 8931MB
[2022-04-06 18:02:47 large] (main.py 226): INFO Train: [95/300][2500/2502]	eta 0:00:01 lr 0.000385	time 0.6090 (0.6547)	loss 3.6554 (3.5366)	grad_norm 2.7378 (inf)	mem 8931MB
[2022-04-06 18:02:48 large] (main.py 233): INFO EPOCH 95 training takes 0:27:18
[2022-04-06 18:02:54 large] (main.py 273): INFO Test: [0/98]	Time 6.520 (6.520)	Loss 1.1147 (1.1147)	Acc@1 78.320 (78.320)	Acc@5 93.750 (93.750)	Mem 8931MB
[2022-04-06 18:03:20 large] (main.py 279): INFO  * Acc@1 75.126 Acc@5 92.786
[2022-04-06 18:03:20 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 75.1%
[2022-04-06 18:03:20 large] (utils.py 57): INFO output/large/default/ckpt_epoch_95.pth saving......
[2022-04-06 18:03:21 large] (utils.py 59): INFO output/large/default/ckpt_epoch_95.pth saved !!!
[2022-04-06 18:03:21 large] (main.py 148): INFO Max accuracy: 75.13%
[2022-04-06 18:03:29 large] (main.py 226): INFO Train: [96/300][0/2502]	eta 5:16:47 lr 0.000385	time 7.5970 (7.5970)	loss 2.4268 (2.4268)	grad_norm 2.7691 (2.7691)	mem 8931MB
[2022-04-06 18:04:20 large] (main.py 226): INFO Train: [96/300][100/2502]	eta 0:23:21 lr 0.000385	time 0.7199 (0.5836)	loss 4.2941 (3.5760)	grad_norm 3.1786 (2.9183)	mem 8931MB
[2022-04-06 18:05:26 large] (main.py 226): INFO Train: [96/300][200/2502]	eta 0:23:44 lr 0.000385	time 0.7064 (0.6189)	loss 4.2336 (3.5438)	grad_norm 2.3334 (2.8875)	mem 8931MB
[2022-04-06 18:06:32 large] (main.py 226): INFO Train: [96/300][300/2502]	eta 0:23:13 lr 0.000385	time 0.4979 (0.6328)	loss 2.6227 (3.5359)	grad_norm 2.7812 (2.8868)	mem 8931MB
[2022-04-06 18:07:39 large] (main.py 226): INFO Train: [96/300][400/2502]	eta 0:22:30 lr 0.000385	time 0.7380 (0.6423)	loss 4.0104 (3.5405)	grad_norm 2.8142 (2.8773)	mem 8931MB
[2022-04-06 18:08:45 large] (main.py 226): INFO Train: [96/300][500/2502]	eta 0:21:32 lr 0.000385	time 0.5955 (0.6456)	loss 4.0419 (3.5334)	grad_norm 3.0832 (2.8893)	mem 8931MB
[2022-04-06 18:09:51 large] (main.py 226): INFO Train: [96/300][600/2502]	eta 0:20:35 lr 0.000385	time 0.6322 (0.6494)	loss 4.0499 (3.5284)	grad_norm 2.9734 (2.8882)	mem 8931MB
[2022-04-06 18:10:56 large] (main.py 226): INFO Train: [96/300][700/2502]	eta 0:19:30 lr 0.000385	time 0.6220 (0.6495)	loss 2.9748 (3.5256)	grad_norm 3.3022 (2.8955)	mem 8931MB
[2022-04-06 18:12:03 large] (main.py 226): INFO Train: [96/300][800/2502]	eta 0:18:28 lr 0.000384	time 0.6203 (0.6511)	loss 2.9388 (3.5309)	grad_norm 2.3665 (2.8886)	mem 8931MB
[2022-04-06 18:13:08 large] (main.py 226): INFO Train: [96/300][900/2502]	eta 0:17:23 lr 0.000384	time 0.5244 (0.6517)	loss 3.9609 (3.5471)	grad_norm 2.1656 (nan)	mem 8931MB
[2022-04-06 18:14:13 large] (main.py 226): INFO Train: [96/300][1000/2502]	eta 0:16:18 lr 0.000384	time 0.6277 (0.6515)	loss 3.5992 (3.5442)	grad_norm 3.1252 (nan)	mem 8931MB
[2022-04-06 18:15:18 large] (main.py 226): INFO Train: [96/300][1100/2502]	eta 0:15:13 lr 0.000384	time 0.6036 (0.6514)	loss 3.6011 (3.5411)	grad_norm 2.8569 (nan)	mem 8931MB
[2022-04-06 18:16:25 large] (main.py 226): INFO Train: [96/300][1200/2502]	eta 0:14:09 lr 0.000384	time 0.6878 (0.6528)	loss 2.9131 (3.5429)	grad_norm 2.9494 (nan)	mem 8931MB
[2022-04-06 18:17:30 large] (main.py 226): INFO Train: [96/300][1300/2502]	eta 0:13:04 lr 0.000384	time 0.6527 (0.6525)	loss 3.6307 (3.5470)	grad_norm 2.4570 (nan)	mem 8931MB
[2022-04-06 18:18:35 large] (main.py 226): INFO Train: [96/300][1400/2502]	eta 0:11:59 lr 0.000384	time 0.7001 (0.6526)	loss 3.5448 (3.5459)	grad_norm 2.8121 (nan)	mem 8931MB
[2022-04-06 18:19:42 large] (main.py 226): INFO Train: [96/300][1500/2502]	eta 0:10:54 lr 0.000384	time 0.6577 (0.6533)	loss 3.9060 (3.5462)	grad_norm 2.3397 (nan)	mem 8931MB
[2022-04-06 18:20:47 large] (main.py 226): INFO Train: [96/300][1600/2502]	eta 0:09:49 lr 0.000384	time 0.6669 (0.6531)	loss 2.8145 (3.5383)	grad_norm 2.8664 (nan)	mem 8931MB
[2022-04-06 18:21:51 large] (main.py 226): INFO Train: [96/300][1700/2502]	eta 0:08:43 lr 0.000384	time 0.5991 (0.6525)	loss 4.1210 (3.5361)	grad_norm 2.9086 (nan)	mem 8931MB
[2022-04-06 18:22:55 large] (main.py 226): INFO Train: [96/300][1800/2502]	eta 0:07:37 lr 0.000384	time 0.6079 (0.6519)	loss 4.0063 (3.5338)	grad_norm 3.9925 (nan)	mem 8931MB
[2022-04-06 18:24:00 large] (main.py 226): INFO Train: [96/300][1900/2502]	eta 0:06:32 lr 0.000383	time 0.6591 (0.6517)	loss 4.0512 (3.5327)	grad_norm 2.9174 (nan)	mem 8931MB
[2022-04-06 18:25:06 large] (main.py 226): INFO Train: [96/300][2000/2502]	eta 0:05:27 lr 0.000383	time 0.6099 (0.6522)	loss 4.0943 (3.5332)	grad_norm 2.4635 (nan)	mem 8931MB
[2022-04-06 18:26:12 large] (main.py 226): INFO Train: [96/300][2100/2502]	eta 0:04:22 lr 0.000383	time 1.5361 (0.6524)	loss 3.5148 (3.5337)	grad_norm 2.9808 (nan)	mem 8931MB
[2022-04-06 18:27:17 large] (main.py 226): INFO Train: [96/300][2200/2502]	eta 0:03:17 lr 0.000383	time 0.7127 (0.6524)	loss 2.1687 (3.5344)	grad_norm 2.7826 (nan)	mem 8931MB
[2022-04-06 18:28:23 large] (main.py 226): INFO Train: [96/300][2300/2502]	eta 0:02:11 lr 0.000383	time 0.6557 (0.6525)	loss 3.8809 (3.5355)	grad_norm 3.4744 (nan)	mem 8931MB
[2022-04-06 18:29:29 large] (main.py 226): INFO Train: [96/300][2400/2502]	eta 0:01:06 lr 0.000383	time 0.6457 (0.6529)	loss 2.6355 (3.5327)	grad_norm 3.1980 (nan)	mem 8931MB
[2022-04-06 18:30:35 large] (main.py 226): INFO Train: [96/300][2500/2502]	eta 0:00:01 lr 0.000383	time 0.7857 (0.6531)	loss 4.2240 (3.5334)	grad_norm 3.1182 (nan)	mem 8931MB
[2022-04-06 18:30:36 large] (main.py 233): INFO EPOCH 96 training takes 0:27:14
[2022-04-06 18:30:42 large] (main.py 273): INFO Test: [0/98]	Time 6.557 (6.557)	Loss 1.1327 (1.1327)	Acc@1 77.930 (77.930)	Acc@5 94.336 (94.336)	Mem 8931MB
[2022-04-06 18:31:08 large] (main.py 279): INFO  * Acc@1 74.974 Acc@5 92.774
[2022-04-06 18:31:08 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 75.0%
[2022-04-06 18:31:08 large] (main.py 148): INFO Max accuracy: 75.13%
[2022-04-06 18:31:16 large] (main.py 226): INFO Train: [97/300][0/2502]	eta 5:16:01 lr 0.000383	time 7.5785 (7.5785)	loss 3.2111 (3.2111)	grad_norm 2.7445 (2.7445)	mem 8931MB
[2022-04-06 18:32:12 large] (main.py 226): INFO Train: [97/300][100/2502]	eta 0:25:22 lr 0.000383	time 0.6789 (0.6340)	loss 3.9724 (3.5988)	grad_norm 3.0303 (2.8176)	mem 8931MB
[2022-04-06 18:33:19 large] (main.py 226): INFO Train: [97/300][200/2502]	eta 0:24:57 lr 0.000383	time 0.6830 (0.6505)	loss 3.7837 (3.5158)	grad_norm 2.5057 (2.9176)	mem 8931MB
[2022-04-06 18:34:26 large] (main.py 226): INFO Train: [97/300][300/2502]	eta 0:24:08 lr 0.000383	time 0.4750 (0.6580)	loss 3.5201 (3.5133)	grad_norm 3.3514 (2.9325)	mem 8931MB
[2022-04-06 18:35:32 large] (main.py 226): INFO Train: [97/300][400/2502]	eta 0:23:03 lr 0.000383	time 0.6540 (0.6584)	loss 3.8397 (3.5093)	grad_norm 2.4217 (2.9194)	mem 8931MB
[2022-04-06 18:36:38 large] (main.py 226): INFO Train: [97/300][500/2502]	eta 0:21:59 lr 0.000382	time 0.6336 (0.6590)	loss 3.3203 (3.5121)	grad_norm 2.3324 (2.9213)	mem 8931MB
[2022-04-06 18:37:44 large] (main.py 226): INFO Train: [97/300][600/2502]	eta 0:20:52 lr 0.000382	time 0.6480 (0.6585)	loss 3.6153 (3.5266)	grad_norm 2.3124 (2.9144)	mem 8931MB
[2022-04-06 18:38:49 large] (main.py 226): INFO Train: [97/300][700/2502]	eta 0:19:45 lr 0.000382	time 0.4871 (0.6580)	loss 3.5670 (3.5120)	grad_norm 2.1729 (2.9188)	mem 8931MB
[2022-04-06 18:39:55 large] (main.py 226): INFO Train: [97/300][800/2502]	eta 0:18:38 lr 0.000382	time 0.6692 (0.6572)	loss 4.2451 (3.5210)	grad_norm 2.3220 (2.9188)	mem 8931MB
[2022-04-06 18:41:00 large] (main.py 226): INFO Train: [97/300][900/2502]	eta 0:17:32 lr 0.000382	time 0.6422 (0.6568)	loss 3.6202 (3.5093)	grad_norm 2.9200 (2.9231)	mem 8931MB
[2022-04-06 18:42:04 large] (main.py 226): INFO Train: [97/300][1000/2502]	eta 0:16:24 lr 0.000382	time 0.7187 (0.6554)	loss 2.5068 (3.5162)	grad_norm 3.7199 (2.9204)	mem 8931MB
[2022-04-06 18:43:09 large] (main.py 226): INFO Train: [97/300][1100/2502]	eta 0:15:17 lr 0.000382	time 0.6198 (0.6548)	loss 3.4096 (3.5123)	grad_norm 2.3840 (2.9208)	mem 8931MB
[2022-04-06 18:44:14 large] (main.py 226): INFO Train: [97/300][1200/2502]	eta 0:14:12 lr 0.000382	time 0.6712 (0.6544)	loss 2.3010 (3.5133)	grad_norm 2.5384 (2.9222)	mem 8931MB
[2022-04-06 18:45:19 large] (main.py 226): INFO Train: [97/300][1300/2502]	eta 0:13:06 lr 0.000382	time 0.6014 (0.6540)	loss 3.0904 (3.5104)	grad_norm 3.3151 (2.9195)	mem 8931MB
[2022-04-06 18:46:23 large] (main.py 226): INFO Train: [97/300][1400/2502]	eta 0:11:59 lr 0.000382	time 0.6575 (0.6529)	loss 4.1647 (3.5146)	grad_norm 2.5790 (2.9154)	mem 8931MB
[2022-04-06 18:47:28 large] (main.py 226): INFO Train: [97/300][1500/2502]	eta 0:10:54 lr 0.000382	time 0.6076 (0.6527)	loss 3.4814 (3.5153)	grad_norm 3.4159 (2.9105)	mem 8931MB
[2022-04-06 18:48:33 large] (main.py 226): INFO Train: [97/300][1600/2502]	eta 0:09:48 lr 0.000382	time 0.6282 (0.6527)	loss 4.0966 (3.5178)	grad_norm 2.8169 (2.9147)	mem 8931MB
[2022-04-06 18:49:38 large] (main.py 226): INFO Train: [97/300][1700/2502]	eta 0:08:43 lr 0.000381	time 0.5676 (0.6524)	loss 2.7330 (3.5151)	grad_norm 3.2479 (2.9117)	mem 8931MB
[2022-04-06 18:50:43 large] (main.py 226): INFO Train: [97/300][1800/2502]	eta 0:07:38 lr 0.000381	time 0.7417 (0.6526)	loss 3.2085 (3.5183)	grad_norm 2.6449 (2.9086)	mem 8931MB
[2022-04-06 18:51:49 large] (main.py 226): INFO Train: [97/300][1900/2502]	eta 0:06:32 lr 0.000381	time 0.7121 (0.6527)	loss 3.8323 (3.5186)	grad_norm 2.2494 (2.9106)	mem 8931MB
[2022-04-06 18:52:54 large] (main.py 226): INFO Train: [97/300][2000/2502]	eta 0:05:27 lr 0.000381	time 0.7282 (0.6524)	loss 3.6328 (3.5246)	grad_norm 2.7575 (2.9030)	mem 8931MB
[2022-04-06 18:53:58 large] (main.py 226): INFO Train: [97/300][2100/2502]	eta 0:04:22 lr 0.000381	time 0.6237 (0.6521)	loss 3.6380 (3.5236)	grad_norm 2.9992 (2.9028)	mem 8931MB
[2022-04-06 18:55:02 large] (main.py 226): INFO Train: [97/300][2200/2502]	eta 0:03:16 lr 0.000381	time 0.6393 (0.6516)	loss 3.6202 (3.5233)	grad_norm 2.2060 (2.9066)	mem 8931MB
[2022-04-06 18:56:06 large] (main.py 226): INFO Train: [97/300][2300/2502]	eta 0:02:11 lr 0.000381	time 0.5710 (0.6511)	loss 3.9686 (3.5291)	grad_norm 2.7454 (nan)	mem 8931MB
[2022-04-06 18:57:12 large] (main.py 226): INFO Train: [97/300][2400/2502]	eta 0:01:06 lr 0.000381	time 0.6824 (0.6512)	loss 4.2704 (3.5271)	grad_norm 3.7839 (nan)	mem 8931MB
[2022-04-06 18:58:16 large] (main.py 226): INFO Train: [97/300][2500/2502]	eta 0:00:01 lr 0.000381	time 0.6101 (0.6509)	loss 2.7416 (3.5265)	grad_norm 3.1112 (nan)	mem 8931MB
[2022-04-06 18:58:17 large] (main.py 233): INFO EPOCH 97 training takes 0:27:09
[2022-04-06 18:58:23 large] (main.py 273): INFO Test: [0/98]	Time 6.064 (6.064)	Loss 1.1724 (1.1724)	Acc@1 76.758 (76.758)	Acc@5 91.406 (91.406)	Mem 8931MB
[2022-04-06 18:58:49 large] (main.py 279): INFO  * Acc@1 74.598 Acc@5 92.506
[2022-04-06 18:58:49 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 74.6%
[2022-04-06 18:58:49 large] (main.py 148): INFO Max accuracy: 75.13%
[2022-04-06 18:58:56 large] (main.py 226): INFO Train: [98/300][0/2502]	eta 4:42:33 lr 0.000381	time 6.7760 (6.7760)	loss 3.7250 (3.7250)	grad_norm 2.3595 (2.3595)	mem 8931MB
[2022-04-06 18:59:50 large] (main.py 226): INFO Train: [98/300][100/2502]	eta 0:23:51 lr 0.000381	time 0.6723 (0.5958)	loss 2.7686 (3.5138)	grad_norm 4.3408 (2.9921)	mem 8931MB
[2022-04-06 19:00:55 large] (main.py 226): INFO Train: [98/300][200/2502]	eta 0:23:54 lr 0.000381	time 0.6499 (0.6231)	loss 2.0922 (3.4805)	grad_norm 2.6873 (2.8818)	mem 8931MB
[2022-04-06 19:02:00 large] (main.py 226): INFO Train: [98/300][300/2502]	eta 0:23:14 lr 0.000380	time 0.6628 (0.6331)	loss 3.9910 (3.4506)	grad_norm 3.1218 (2.8819)	mem 8931MB
[2022-04-06 19:03:05 large] (main.py 226): INFO Train: [98/300][400/2502]	eta 0:22:19 lr 0.000380	time 0.8040 (0.6372)	loss 3.4880 (3.4607)	grad_norm 2.8859 (2.8871)	mem 8931MB
[2022-04-06 19:04:10 large] (main.py 226): INFO Train: [98/300][500/2502]	eta 0:21:20 lr 0.000380	time 0.6369 (0.6398)	loss 3.9112 (3.4822)	grad_norm 2.5190 (2.9002)	mem 8931MB
[2022-04-06 19:05:14 large] (main.py 226): INFO Train: [98/300][600/2502]	eta 0:20:17 lr 0.000380	time 0.6844 (0.6401)	loss 3.8017 (3.4960)	grad_norm 3.3693 (2.8899)	mem 8931MB
[2022-04-06 19:06:18 large] (main.py 226): INFO Train: [98/300][700/2502]	eta 0:19:13 lr 0.000380	time 0.6618 (0.6401)	loss 4.1483 (3.5159)	grad_norm 2.6852 (2.8997)	mem 8931MB
[2022-04-06 19:07:23 large] (main.py 226): INFO Train: [98/300][800/2502]	eta 0:18:10 lr 0.000380	time 0.6377 (0.6405)	loss 3.9073 (3.5131)	grad_norm 3.6669 (2.8955)	mem 8931MB
[2022-04-06 19:08:27 large] (main.py 226): INFO Train: [98/300][900/2502]	eta 0:17:06 lr 0.000380	time 0.5132 (0.6406)	loss 2.9474 (3.5078)	grad_norm 3.3465 (2.8942)	mem 8931MB
[2022-04-06 19:09:22 large] (main.py 226): INFO Train: [98/300][1000/2502]	eta 0:15:48 lr 0.000380	time 0.6175 (0.6318)	loss 3.2892 (3.5117)	grad_norm 3.0445 (2.8923)	mem 8931MB
[2022-04-06 19:10:25 large] (main.py 226): INFO Train: [98/300][1100/2502]	eta 0:14:45 lr 0.000380	time 0.5770 (0.6316)	loss 2.9684 (3.5201)	grad_norm 3.0038 (2.8874)	mem 8931MB
[2022-04-06 19:11:29 large] (main.py 226): INFO Train: [98/300][1200/2502]	eta 0:13:43 lr 0.000380	time 0.6742 (0.6322)	loss 3.8371 (3.5241)	grad_norm 3.4438 (2.8976)	mem 8931MB
[2022-04-06 19:12:33 large] (main.py 226): INFO Train: [98/300][1300/2502]	eta 0:12:40 lr 0.000380	time 0.6255 (0.6329)	loss 3.6822 (3.5209)	grad_norm 2.7097 (2.8941)	mem 8931MB
[2022-04-06 19:13:38 large] (main.py 226): INFO Train: [98/300][1400/2502]	eta 0:11:38 lr 0.000379	time 0.6521 (0.6341)	loss 4.3837 (3.5238)	grad_norm 3.3438 (2.8969)	mem 8931MB
[2022-04-06 19:14:42 large] (main.py 226): INFO Train: [98/300][1500/2502]	eta 0:10:36 lr 0.000379	time 0.7739 (0.6348)	loss 2.5277 (3.5251)	grad_norm 2.9456 (2.8933)	mem 8931MB
[2022-04-06 19:15:46 large] (main.py 226): INFO Train: [98/300][1600/2502]	eta 0:09:32 lr 0.000379	time 0.6115 (0.6348)	loss 3.4591 (3.5295)	grad_norm 2.9854 (2.8964)	mem 8931MB
[2022-04-06 19:16:50 large] (main.py 226): INFO Train: [98/300][1700/2502]	eta 0:08:29 lr 0.000379	time 1.2907 (0.6353)	loss 2.7871 (3.5263)	grad_norm 3.1866 (2.8915)	mem 8931MB
[2022-04-06 19:17:53 large] (main.py 226): INFO Train: [98/300][1800/2502]	eta 0:07:25 lr 0.000379	time 0.5136 (0.6351)	loss 2.2159 (3.5232)	grad_norm 2.6641 (2.8940)	mem 8931MB
[2022-04-06 19:18:58 large] (main.py 226): INFO Train: [98/300][1900/2502]	eta 0:06:22 lr 0.000379	time 0.6672 (0.6356)	loss 3.2526 (3.5251)	grad_norm 2.1639 (2.8958)	mem 8931MB
[2022-04-06 19:20:02 large] (main.py 226): INFO Train: [98/300][2000/2502]	eta 0:05:19 lr 0.000379	time 0.6932 (0.6359)	loss 3.9383 (3.5286)	grad_norm 3.3716 (2.8913)	mem 8931MB
[2022-04-06 19:21:07 large] (main.py 226): INFO Train: [98/300][2100/2502]	eta 0:04:15 lr 0.000379	time 0.5663 (0.6364)	loss 3.6057 (3.5267)	grad_norm 2.4664 (2.8986)	mem 8931MB
[2022-04-06 19:22:11 large] (main.py 226): INFO Train: [98/300][2200/2502]	eta 0:03:12 lr 0.000379	time 0.6649 (0.6368)	loss 4.1752 (3.5237)	grad_norm 3.0870 (2.9007)	mem 8931MB
[2022-04-06 19:23:15 large] (main.py 226): INFO Train: [98/300][2300/2502]	eta 0:02:08 lr 0.000379	time 0.6560 (0.6369)	loss 3.1547 (3.5261)	grad_norm 2.9191 (2.8979)	mem 8931MB
[2022-04-06 19:24:19 large] (main.py 226): INFO Train: [98/300][2400/2502]	eta 0:01:04 lr 0.000379	time 0.6283 (0.6369)	loss 3.7194 (3.5270)	grad_norm 2.7685 (2.8949)	mem 8931MB
[2022-04-06 19:25:22 large] (main.py 226): INFO Train: [98/300][2500/2502]	eta 0:00:01 lr 0.000378	time 0.6022 (0.6366)	loss 4.4888 (3.5297)	grad_norm 2.4319 (2.9027)	mem 8931MB
[2022-04-06 19:25:23 large] (main.py 233): INFO EPOCH 98 training takes 0:26:33
[2022-04-06 19:25:28 large] (main.py 273): INFO Test: [0/98]	Time 5.727 (5.727)	Loss 1.3138 (1.3138)	Acc@1 70.898 (70.898)	Acc@5 91.016 (91.016)	Mem 8931MB
[2022-04-06 19:25:55 large] (main.py 279): INFO  * Acc@1 75.236 Acc@5 92.904
[2022-04-06 19:25:55 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 75.2%
[2022-04-06 19:25:55 large] (utils.py 57): INFO output/large/default/ckpt_epoch_98.pth saving......
[2022-04-06 19:25:56 large] (utils.py 59): INFO output/large/default/ckpt_epoch_98.pth saved !!!
[2022-04-06 19:25:56 large] (main.py 148): INFO Max accuracy: 75.24%
[2022-04-06 19:26:04 large] (main.py 226): INFO Train: [99/300][0/2502]	eta 5:28:32 lr 0.000378	time 7.8786 (7.8786)	loss 3.3717 (3.3717)	grad_norm 3.1153 (3.1153)	mem 8931MB
[2022-04-06 19:27:00 large] (main.py 226): INFO Train: [99/300][100/2502]	eta 0:25:28 lr 0.000378	time 0.6422 (0.6365)	loss 3.6094 (3.6106)	grad_norm 2.2148 (2.9079)	mem 8931MB
[2022-04-06 19:28:06 large] (main.py 226): INFO Train: [99/300][200/2502]	eta 0:24:48 lr 0.000378	time 0.6636 (0.6467)	loss 4.3319 (3.5490)	grad_norm 3.0576 (2.9488)	mem 8931MB
[2022-04-06 19:29:10 large] (main.py 226): INFO Train: [99/300][300/2502]	eta 0:23:43 lr 0.000378	time 0.7238 (0.6463)	loss 3.5036 (3.5284)	grad_norm 3.3656 (2.9580)	mem 8931MB
[2022-04-06 19:30:15 large] (main.py 226): INFO Train: [99/300][400/2502]	eta 0:22:37 lr 0.000378	time 0.6793 (0.6459)	loss 3.4339 (3.5306)	grad_norm 2.3043 (2.9500)	mem 8931MB
[2022-04-06 19:31:19 large] (main.py 226): INFO Train: [99/300][500/2502]	eta 0:21:29 lr 0.000378	time 0.6966 (0.6443)	loss 3.7086 (3.5130)	grad_norm 2.9733 (2.9514)	mem 8931MB
[2022-04-06 19:32:23 large] (main.py 226): INFO Train: [99/300][600/2502]	eta 0:20:25 lr 0.000378	time 0.6255 (0.6444)	loss 3.4033 (3.5295)	grad_norm 2.6502 (2.9530)	mem 8931MB
[2022-04-06 19:33:27 large] (main.py 226): INFO Train: [99/300][700/2502]	eta 0:19:19 lr 0.000378	time 0.5939 (0.6432)	loss 3.0538 (3.5211)	grad_norm 2.8067 (2.9540)	mem 8931MB
[2022-04-06 19:34:30 large] (main.py 226): INFO Train: [99/300][800/2502]	eta 0:18:12 lr 0.000378	time 0.5862 (0.6417)	loss 2.8508 (3.5178)	grad_norm 2.9175 (2.9507)	mem 8931MB
[2022-04-06 19:35:35 large] (main.py 226): INFO Train: [99/300][900/2502]	eta 0:17:08 lr 0.000378	time 0.6640 (0.6422)	loss 3.0008 (3.5105)	grad_norm 2.9522 (2.9356)	mem 8931MB
[2022-04-06 19:36:38 large] (main.py 226): INFO Train: [99/300][1000/2502]	eta 0:16:02 lr 0.000378	time 0.6001 (0.6409)	loss 3.3559 (3.5107)	grad_norm 3.9424 (2.9347)	mem 8931MB
[2022-04-06 19:37:42 large] (main.py 226): INFO Train: [99/300][1100/2502]	eta 0:14:58 lr 0.000378	time 0.6327 (0.6412)	loss 3.6779 (3.5088)	grad_norm 2.1717 (2.9323)	mem 8931MB
[2022-04-06 19:38:46 large] (main.py 226): INFO Train: [99/300][1200/2502]	eta 0:13:54 lr 0.000377	time 0.6218 (0.6413)	loss 3.5310 (3.5173)	grad_norm 3.2108 (2.9341)	mem 8931MB
[2022-04-06 19:39:50 large] (main.py 226): INFO Train: [99/300][1300/2502]	eta 0:12:50 lr 0.000377	time 0.6178 (0.6411)	loss 3.8459 (3.5206)	grad_norm 2.4425 (inf)	mem 8931MB
[2022-04-06 19:40:55 large] (main.py 226): INFO Train: [99/300][1400/2502]	eta 0:11:47 lr 0.000377	time 0.7352 (0.6417)	loss 3.2779 (3.5203)	grad_norm 2.4998 (inf)	mem 8931MB
[2022-04-06 19:42:00 large] (main.py 226): INFO Train: [99/300][1500/2502]	eta 0:10:43 lr 0.000377	time 0.5930 (0.6423)	loss 2.6556 (3.5194)	grad_norm 3.9063 (inf)	mem 8931MB
[2022-04-06 19:43:05 large] (main.py 226): INFO Train: [99/300][1600/2502]	eta 0:09:39 lr 0.000377	time 0.6812 (0.6426)	loss 4.1537 (3.5195)	grad_norm 3.2957 (inf)	mem 8931MB
[2022-04-06 19:44:10 large] (main.py 226): INFO Train: [99/300][1700/2502]	eta 0:08:35 lr 0.000377	time 0.6296 (0.6433)	loss 2.3364 (3.5209)	grad_norm 3.1744 (inf)	mem 8931MB
[2022-04-06 19:45:13 large] (main.py 226): INFO Train: [99/300][1800/2502]	eta 0:07:31 lr 0.000377	time 0.6389 (0.6427)	loss 3.7557 (3.5150)	grad_norm 3.7138 (inf)	mem 8931MB
[2022-04-06 19:46:18 large] (main.py 226): INFO Train: [99/300][1900/2502]	eta 0:06:26 lr 0.000377	time 0.6446 (0.6427)	loss 2.7807 (3.5164)	grad_norm 2.9169 (nan)	mem 8931MB
[2022-04-06 19:47:24 large] (main.py 226): INFO Train: [99/300][2000/2502]	eta 0:05:23 lr 0.000377	time 0.6665 (0.6435)	loss 3.2131 (3.5189)	grad_norm 5.2845 (nan)	mem 8931MB
[2022-04-06 19:48:29 large] (main.py 226): INFO Train: [99/300][2100/2502]	eta 0:04:18 lr 0.000377	time 0.7219 (0.6442)	loss 3.6013 (3.5213)	grad_norm 2.9300 (nan)	mem 8931MB
[2022-04-06 19:49:35 large] (main.py 226): INFO Train: [99/300][2200/2502]	eta 0:03:14 lr 0.000377	time 0.5930 (0.6445)	loss 3.6202 (3.5229)	grad_norm 2.9354 (nan)	mem 8931MB
[2022-04-06 19:50:40 large] (main.py 226): INFO Train: [99/300][2300/2502]	eta 0:02:10 lr 0.000376	time 0.5128 (0.6449)	loss 3.4002 (3.5187)	grad_norm 2.3611 (nan)	mem 8931MB
[2022-04-06 19:51:47 large] (main.py 226): INFO Train: [99/300][2400/2502]	eta 0:01:05 lr 0.000376	time 0.6035 (0.6458)	loss 3.8397 (3.5153)	grad_norm 2.3709 (nan)	mem 8931MB
[2022-04-06 19:52:51 large] (main.py 226): INFO Train: [99/300][2500/2502]	eta 0:00:01 lr 0.000376	time 0.6080 (0.6459)	loss 3.1689 (3.5144)	grad_norm 3.8122 (nan)	mem 8931MB
[2022-04-06 19:52:52 large] (main.py 233): INFO EPOCH 99 training takes 0:26:56
[2022-04-06 19:52:59 large] (main.py 273): INFO Test: [0/98]	Time 6.882 (6.882)	Loss 1.1878 (1.1878)	Acc@1 73.633 (73.633)	Acc@5 92.383 (92.383)	Mem 8931MB
[2022-04-06 19:53:25 large] (main.py 279): INFO  * Acc@1 75.198 Acc@5 92.856
[2022-04-06 19:53:25 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 75.2%
[2022-04-06 19:53:25 large] (main.py 148): INFO Max accuracy: 75.24%
[2022-04-06 19:53:31 large] (main.py 226): INFO Train: [100/300][0/2502]	eta 4:36:24 lr 0.000376	time 6.6285 (6.6285)	loss 3.2584 (3.2584)	grad_norm 2.8565 (2.8565)	mem 8931MB
[2022-04-06 19:54:23 large] (main.py 226): INFO Train: [100/300][100/2502]	eta 0:23:18 lr 0.000376	time 0.5803 (0.5821)	loss 3.8096 (3.5050)	grad_norm 3.0327 (2.9712)	mem 8931MB
[2022-04-06 19:55:30 large] (main.py 226): INFO Train: [100/300][200/2502]	eta 0:23:53 lr 0.000376	time 0.6924 (0.6226)	loss 3.1674 (3.5018)	grad_norm 2.8350 (2.9509)	mem 8931MB
[2022-04-06 19:56:37 large] (main.py 226): INFO Train: [100/300][300/2502]	eta 0:23:31 lr 0.000376	time 0.6882 (0.6409)	loss 3.2705 (3.5006)	grad_norm 2.1399 (2.9220)	mem 8931MB
[2022-04-06 19:57:45 large] (main.py 226): INFO Train: [100/300][400/2502]	eta 0:22:45 lr 0.000376	time 0.7414 (0.6497)	loss 3.2215 (3.4969)	grad_norm 2.7940 (2.9325)	mem 8931MB
[2022-04-06 19:58:53 large] (main.py 226): INFO Train: [100/300][500/2502]	eta 0:21:51 lr 0.000376	time 0.7261 (0.6549)	loss 4.0013 (3.5005)	grad_norm 2.5764 (2.9405)	mem 8931MB
[2022-04-06 19:59:59 large] (main.py 226): INFO Train: [100/300][600/2502]	eta 0:20:48 lr 0.000376	time 0.5725 (0.6566)	loss 3.5290 (3.5051)	grad_norm 2.4001 (2.9309)	mem 8931MB
[2022-04-06 20:01:06 large] (main.py 226): INFO Train: [100/300][700/2502]	eta 0:19:45 lr 0.000376	time 0.6791 (0.6579)	loss 3.1781 (3.5134)	grad_norm 3.3634 (2.9295)	mem 8931MB
[2022-04-06 20:02:11 large] (main.py 226): INFO Train: [100/300][800/2502]	eta 0:18:39 lr 0.000376	time 0.6955 (0.6576)	loss 3.8032 (3.5185)	grad_norm 2.2741 (2.9194)	mem 8931MB
[2022-04-06 20:03:18 large] (main.py 226): INFO Train: [100/300][900/2502]	eta 0:17:35 lr 0.000375	time 0.7332 (0.6588)	loss 3.9809 (3.5168)	grad_norm 2.6348 (2.9208)	mem 8931MB
[2022-04-06 20:04:24 large] (main.py 226): INFO Train: [100/300][1000/2502]	eta 0:16:29 lr 0.000375	time 0.7214 (0.6590)	loss 2.8446 (3.5189)	grad_norm 2.6306 (2.9288)	mem 8931MB
[2022-04-06 20:05:30 large] (main.py 226): INFO Train: [100/300][1100/2502]	eta 0:15:24 lr 0.000375	time 0.6768 (0.6593)	loss 4.1540 (3.5170)	grad_norm 2.7414 (2.9432)	mem 8931MB
[2022-04-06 20:06:36 large] (main.py 226): INFO Train: [100/300][1200/2502]	eta 0:14:18 lr 0.000375	time 0.6117 (0.6594)	loss 3.6280 (3.5228)	grad_norm 3.1563 (2.9329)	mem 8931MB
[2022-04-06 20:07:43 large] (main.py 226): INFO Train: [100/300][1300/2502]	eta 0:13:13 lr 0.000375	time 0.6029 (0.6598)	loss 3.6677 (3.5275)	grad_norm 3.0561 (2.9340)	mem 8931MB
[2022-04-06 20:08:49 large] (main.py 226): INFO Train: [100/300][1400/2502]	eta 0:12:07 lr 0.000375	time 0.7479 (0.6597)	loss 4.4288 (3.5346)	grad_norm 2.9471 (2.9366)	mem 8931MB
[2022-04-06 20:09:55 large] (main.py 226): INFO Train: [100/300][1500/2502]	eta 0:11:01 lr 0.000375	time 0.6182 (0.6599)	loss 3.5679 (3.5383)	grad_norm 2.7801 (nan)	mem 8931MB
[2022-04-06 20:11:02 large] (main.py 226): INFO Train: [100/300][1600/2502]	eta 0:09:55 lr 0.000375	time 0.7102 (0.6607)	loss 3.9642 (3.5330)	grad_norm 3.0028 (nan)	mem 8931MB
[2022-04-06 20:12:08 large] (main.py 226): INFO Train: [100/300][1700/2502]	eta 0:08:49 lr 0.000375	time 0.6394 (0.6605)	loss 3.5637 (3.5390)	grad_norm 3.3533 (nan)	mem 8931MB
[2022-04-06 20:13:14 large] (main.py 226): INFO Train: [100/300][1800/2502]	eta 0:07:43 lr 0.000375	time 0.7397 (0.6607)	loss 3.9876 (3.5404)	grad_norm 3.0150 (nan)	mem 8931MB
[2022-04-06 20:14:21 large] (main.py 226): INFO Train: [100/300][1900/2502]	eta 0:06:37 lr 0.000375	time 0.6824 (0.6609)	loss 2.8309 (3.5363)	grad_norm 2.9568 (nan)	mem 8931MB
[2022-04-06 20:15:26 large] (main.py 226): INFO Train: [100/300][2000/2502]	eta 0:05:31 lr 0.000374	time 0.7068 (0.6606)	loss 3.9638 (3.5358)	grad_norm 2.8660 (nan)	mem 8931MB
[2022-04-06 20:16:33 large] (main.py 226): INFO Train: [100/300][2100/2502]	eta 0:04:25 lr 0.000374	time 0.8160 (0.6606)	loss 3.6025 (3.5383)	grad_norm 2.9107 (nan)	mem 8931MB
[2022-04-06 20:17:39 large] (main.py 226): INFO Train: [100/300][2200/2502]	eta 0:03:19 lr 0.000374	time 0.6754 (0.6608)	loss 3.3171 (3.5408)	grad_norm 2.4684 (nan)	mem 8931MB
[2022-04-06 20:18:45 large] (main.py 226): INFO Train: [100/300][2300/2502]	eta 0:02:13 lr 0.000374	time 0.6787 (0.6610)	loss 4.2216 (3.5374)	grad_norm 4.1819 (nan)	mem 8931MB
[2022-04-06 20:19:52 large] (main.py 226): INFO Train: [100/300][2400/2502]	eta 0:01:07 lr 0.000374	time 0.5694 (0.6610)	loss 3.6567 (3.5364)	grad_norm 2.3416 (nan)	mem 8931MB
[2022-04-06 20:20:56 large] (main.py 226): INFO Train: [100/300][2500/2502]	eta 0:00:01 lr 0.000374	time 0.5984 (0.6605)	loss 4.1784 (3.5367)	grad_norm 2.7006 (nan)	mem 8931MB
[2022-04-06 20:20:57 large] (main.py 233): INFO EPOCH 100 training takes 0:27:32
[2022-04-06 20:21:03 large] (main.py 273): INFO Test: [0/98]	Time 5.742 (5.742)	Loss 1.1657 (1.1657)	Acc@1 75.781 (75.781)	Acc@5 93.164 (93.164)	Mem 8931MB
[2022-04-06 20:21:30 large] (main.py 279): INFO  * Acc@1 75.132 Acc@5 92.742
[2022-04-06 20:21:30 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 75.1%
[2022-04-06 20:21:30 large] (main.py 148): INFO Max accuracy: 75.24%
[2022-04-06 20:21:37 large] (main.py 226): INFO Train: [101/300][0/2502]	eta 4:53:24 lr 0.000374	time 7.0362 (7.0362)	loss 4.0050 (4.0050)	grad_norm 2.3894 (2.3894)	mem 8931MB
[2022-04-06 20:22:33 large] (main.py 226): INFO Train: [101/300][100/2502]	eta 0:24:55 lr 0.000374	time 0.6952 (0.6226)	loss 4.1363 (3.6395)	grad_norm 2.8164 (2.9587)	mem 8931MB
[2022-04-06 20:23:41 large] (main.py 226): INFO Train: [101/300][200/2502]	eta 0:24:57 lr 0.000374	time 0.7018 (0.6505)	loss 3.8710 (3.5558)	grad_norm 2.6814 (2.9945)	mem 8931MB
[2022-04-06 20:24:48 large] (main.py 226): INFO Train: [101/300][300/2502]	eta 0:24:09 lr 0.000374	time 0.7473 (0.6582)	loss 3.8272 (3.5373)	grad_norm 2.9571 (2.9938)	mem 8931MB
[2022-04-06 20:25:55 large] (main.py 226): INFO Train: [101/300][400/2502]	eta 0:23:08 lr 0.000374	time 0.5985 (0.6607)	loss 4.1641 (3.5137)	grad_norm 2.8780 (2.9596)	mem 8931MB
[2022-04-06 20:27:03 large] (main.py 226): INFO Train: [101/300][500/2502]	eta 0:22:10 lr 0.000374	time 0.6076 (0.6646)	loss 3.9008 (3.5297)	grad_norm 2.8293 (2.9679)	mem 8931MB
[2022-04-06 20:28:09 large] (main.py 226): INFO Train: [101/300][600/2502]	eta 0:21:02 lr 0.000373	time 0.5431 (0.6635)	loss 3.9788 (3.5363)	grad_norm 3.6975 (2.9873)	mem 8931MB
[2022-04-06 20:29:14 large] (main.py 226): INFO Train: [101/300][700/2502]	eta 0:19:54 lr 0.000373	time 0.6662 (0.6629)	loss 3.7161 (3.5324)	grad_norm 2.8227 (2.9758)	mem 8931MB
[2022-04-06 20:30:21 large] (main.py 226): INFO Train: [101/300][800/2502]	eta 0:18:49 lr 0.000373	time 0.6937 (0.6635)	loss 4.2058 (3.5238)	grad_norm 2.7709 (2.9655)	mem 8931MB
[2022-04-06 20:31:28 large] (main.py 226): INFO Train: [101/300][900/2502]	eta 0:17:43 lr 0.000373	time 0.7605 (0.6636)	loss 3.5738 (3.5105)	grad_norm 3.2119 (2.9588)	mem 8931MB
[2022-04-06 20:32:34 large] (main.py 226): INFO Train: [101/300][1000/2502]	eta 0:16:36 lr 0.000373	time 0.6904 (0.6635)	loss 4.1077 (3.5068)	grad_norm 2.7229 (2.9594)	mem 8931MB
[2022-04-06 20:33:40 large] (main.py 226): INFO Train: [101/300][1100/2502]	eta 0:15:29 lr 0.000373	time 0.5171 (0.6633)	loss 3.6842 (3.5100)	grad_norm 2.5164 (2.9533)	mem 8931MB
[2022-04-06 20:34:46 large] (main.py 226): INFO Train: [101/300][1200/2502]	eta 0:14:22 lr 0.000373	time 0.6004 (0.6628)	loss 3.5373 (3.5139)	grad_norm 3.2305 (2.9530)	mem 8931MB
[2022-04-06 20:35:52 large] (main.py 226): INFO Train: [101/300][1300/2502]	eta 0:13:16 lr 0.000373	time 0.6475 (0.6629)	loss 3.7175 (3.5177)	grad_norm 2.3687 (2.9628)	mem 8931MB
[2022-04-06 20:37:00 large] (main.py 226): INFO Train: [101/300][1400/2502]	eta 0:12:11 lr 0.000373	time 0.6501 (0.6636)	loss 4.0146 (3.5215)	grad_norm 3.5522 (2.9654)	mem 8931MB
[2022-04-06 20:38:07 large] (main.py 226): INFO Train: [101/300][1500/2502]	eta 0:11:05 lr 0.000373	time 0.7320 (0.6641)	loss 2.5889 (3.5278)	grad_norm 3.4406 (2.9833)	mem 8931MB
[2022-04-06 20:39:13 large] (main.py 226): INFO Train: [101/300][1600/2502]	eta 0:09:59 lr 0.000373	time 0.8034 (0.6641)	loss 3.9271 (3.5221)	grad_norm 3.3764 (2.9862)	mem 8931MB
[2022-04-06 20:40:21 large] (main.py 226): INFO Train: [101/300][1700/2502]	eta 0:08:53 lr 0.000372	time 0.6717 (0.6647)	loss 3.7560 (3.5223)	grad_norm 3.1050 (2.9876)	mem 8931MB
[2022-04-06 20:41:26 large] (main.py 226): INFO Train: [101/300][1800/2502]	eta 0:07:46 lr 0.000372	time 0.5065 (0.6640)	loss 2.3821 (3.5200)	grad_norm 3.7803 (2.9831)	mem 8931MB
[2022-04-06 20:42:31 large] (main.py 226): INFO Train: [101/300][1900/2502]	eta 0:06:39 lr 0.000372	time 0.6463 (0.6634)	loss 3.5083 (3.5249)	grad_norm 3.0269 (2.9788)	mem 8931MB
[2022-04-06 20:43:38 large] (main.py 226): INFO Train: [101/300][2000/2502]	eta 0:05:33 lr 0.000372	time 0.6468 (0.6636)	loss 2.9372 (3.5288)	grad_norm 3.1460 (2.9763)	mem 8931MB
[2022-04-06 20:44:44 large] (main.py 226): INFO Train: [101/300][2100/2502]	eta 0:04:26 lr 0.000372	time 0.6905 (0.6635)	loss 4.1267 (3.5287)	grad_norm 2.9548 (2.9744)	mem 8931MB
[2022-04-06 20:45:51 large] (main.py 226): INFO Train: [101/300][2200/2502]	eta 0:03:20 lr 0.000372	time 0.5219 (0.6637)	loss 2.8685 (3.5338)	grad_norm 2.3838 (2.9716)	mem 8931MB
[2022-04-06 20:46:56 large] (main.py 226): INFO Train: [101/300][2300/2502]	eta 0:02:14 lr 0.000372	time 0.6367 (0.6634)	loss 4.3573 (3.5320)	grad_norm 3.4693 (2.9688)	mem 8931MB
[2022-04-06 20:48:03 large] (main.py 226): INFO Train: [101/300][2400/2502]	eta 0:01:07 lr 0.000372	time 0.6525 (0.6636)	loss 4.3489 (3.5336)	grad_norm 3.4101 (2.9718)	mem 8931MB
[2022-04-06 20:49:08 large] (main.py 226): INFO Train: [101/300][2500/2502]	eta 0:00:01 lr 0.000372	time 0.6503 (0.6632)	loss 4.1418 (3.5360)	grad_norm 2.7880 (2.9713)	mem 8931MB
[2022-04-06 20:49:09 large] (main.py 233): INFO EPOCH 101 training takes 0:27:39
[2022-04-06 20:49:16 large] (main.py 273): INFO Test: [0/98]	Time 6.331 (6.331)	Loss 1.2354 (1.2354)	Acc@1 76.172 (76.172)	Acc@5 91.406 (91.406)	Mem 8931MB
[2022-04-06 20:49:42 large] (main.py 279): INFO  * Acc@1 75.156 Acc@5 92.652
[2022-04-06 20:49:42 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 75.2%
[2022-04-06 20:49:42 large] (main.py 148): INFO Max accuracy: 75.24%
[2022-04-06 20:49:48 large] (main.py 226): INFO Train: [102/300][0/2502]	eta 4:31:55 lr 0.000372	time 6.5208 (6.5208)	loss 2.7143 (2.7143)	grad_norm 3.1846 (3.1846)	mem 8931MB
[2022-04-06 20:50:52 large] (main.py 226): INFO Train: [102/300][100/2502]	eta 0:27:45 lr 0.000372	time 0.7285 (0.6935)	loss 3.8275 (3.5665)	grad_norm 3.0158 (nan)	mem 8931MB
[2022-04-06 20:52:01 large] (main.py 226): INFO Train: [102/300][200/2502]	eta 0:26:30 lr 0.000372	time 0.7567 (0.6911)	loss 3.9932 (3.5413)	grad_norm 3.1603 (nan)	mem 8931MB
[2022-04-06 20:53:08 large] (main.py 226): INFO Train: [102/300][300/2502]	eta 0:25:04 lr 0.000371	time 0.7135 (0.6831)	loss 2.4002 (3.5477)	grad_norm 2.7061 (nan)	mem 8931MB
[2022-04-06 20:54:15 large] (main.py 226): INFO Train: [102/300][400/2502]	eta 0:23:51 lr 0.000371	time 0.6157 (0.6809)	loss 3.1920 (3.5611)	grad_norm 2.7766 (nan)	mem 8931MB
[2022-04-06 20:55:22 large] (main.py 226): INFO Train: [102/300][500/2502]	eta 0:22:36 lr 0.000371	time 0.5988 (0.6778)	loss 3.5019 (3.5500)	grad_norm 3.1307 (nan)	mem 8931MB
[2022-04-06 20:56:30 large] (main.py 226): INFO Train: [102/300][600/2502]	eta 0:21:31 lr 0.000371	time 0.6262 (0.6790)	loss 2.8114 (3.5605)	grad_norm 3.2155 (nan)	mem 8931MB
[2022-04-06 20:57:35 large] (main.py 226): INFO Train: [102/300][700/2502]	eta 0:20:17 lr 0.000371	time 0.6517 (0.6755)	loss 3.9644 (3.5560)	grad_norm 2.9496 (nan)	mem 8931MB
[2022-04-06 20:58:41 large] (main.py 226): INFO Train: [102/300][800/2502]	eta 0:19:04 lr 0.000371	time 0.6706 (0.6726)	loss 3.5073 (3.5583)	grad_norm 2.9968 (nan)	mem 8931MB
[2022-04-06 20:59:47 large] (main.py 226): INFO Train: [102/300][900/2502]	eta 0:17:55 lr 0.000371	time 0.7475 (0.6711)	loss 3.0186 (3.5522)	grad_norm 3.3023 (nan)	mem 8931MB
[2022-04-06 21:00:53 large] (main.py 226): INFO Train: [102/300][1000/2502]	eta 0:16:47 lr 0.000371	time 0.6704 (0.6706)	loss 3.0387 (3.5444)	grad_norm 3.3094 (nan)	mem 8931MB
[2022-04-06 21:01:58 large] (main.py 226): INFO Train: [102/300][1100/2502]	eta 0:15:37 lr 0.000371	time 0.6398 (0.6689)	loss 3.1682 (3.5532)	grad_norm 3.6448 (nan)	mem 8931MB
[2022-04-06 21:03:05 large] (main.py 226): INFO Train: [102/300][1200/2502]	eta 0:14:30 lr 0.000371	time 0.6142 (0.6683)	loss 3.1432 (3.5515)	grad_norm 3.8505 (nan)	mem 8931MB
[2022-04-06 21:04:11 large] (main.py 226): INFO Train: [102/300][1300/2502]	eta 0:13:22 lr 0.000371	time 0.6302 (0.6680)	loss 2.5252 (3.5521)	grad_norm 2.9772 (nan)	mem 8931MB
[2022-04-06 21:05:17 large] (main.py 226): INFO Train: [102/300][1400/2502]	eta 0:12:15 lr 0.000370	time 0.6180 (0.6676)	loss 2.5668 (3.5549)	grad_norm 2.8772 (nan)	mem 8931MB
[2022-04-06 21:06:23 large] (main.py 226): INFO Train: [102/300][1500/2502]	eta 0:11:08 lr 0.000370	time 0.6811 (0.6667)	loss 4.3828 (3.5457)	grad_norm 2.6277 (nan)	mem 8931MB
[2022-04-06 21:07:30 large] (main.py 226): INFO Train: [102/300][1600/2502]	eta 0:10:01 lr 0.000370	time 0.7286 (0.6669)	loss 3.0695 (3.5436)	grad_norm 3.2188 (nan)	mem 8931MB
[2022-04-06 21:08:35 large] (main.py 226): INFO Train: [102/300][1700/2502]	eta 0:08:54 lr 0.000370	time 0.6573 (0.6663)	loss 3.6969 (3.5460)	grad_norm 3.1048 (nan)	mem 8931MB
[2022-04-06 21:09:41 large] (main.py 226): INFO Train: [102/300][1800/2502]	eta 0:07:47 lr 0.000370	time 0.7672 (0.6658)	loss 2.8094 (3.5470)	grad_norm 3.2945 (nan)	mem 8931MB
[2022-04-06 21:10:49 large] (main.py 226): INFO Train: [102/300][1900/2502]	eta 0:06:41 lr 0.000370	time 0.5939 (0.6663)	loss 4.0226 (3.5448)	grad_norm 3.2573 (nan)	mem 8931MB
[2022-04-06 21:11:55 large] (main.py 226): INFO Train: [102/300][2000/2502]	eta 0:05:34 lr 0.000370	time 0.7885 (0.6664)	loss 2.6197 (3.5410)	grad_norm 4.2855 (nan)	mem 8931MB
[2022-04-06 21:13:01 large] (main.py 226): INFO Train: [102/300][2100/2502]	eta 0:04:27 lr 0.000370	time 0.6482 (0.6660)	loss 3.9544 (3.5407)	grad_norm 2.9603 (nan)	mem 8931MB
[2022-04-06 21:14:08 large] (main.py 226): INFO Train: [102/300][2200/2502]	eta 0:03:21 lr 0.000370	time 0.6788 (0.6659)	loss 4.4057 (3.5368)	grad_norm 4.3137 (nan)	mem 8931MB
[2022-04-06 21:15:14 large] (main.py 226): INFO Train: [102/300][2300/2502]	eta 0:02:14 lr 0.000370	time 0.6125 (0.6658)	loss 3.1999 (3.5358)	grad_norm 2.8429 (nan)	mem 8931MB
[2022-04-06 21:16:21 large] (main.py 226): INFO Train: [102/300][2400/2502]	eta 0:01:07 lr 0.000370	time 0.7531 (0.6660)	loss 2.6482 (3.5366)	grad_norm 2.6002 (nan)	mem 8931MB
[2022-04-06 21:17:27 large] (main.py 226): INFO Train: [102/300][2500/2502]	eta 0:00:01 lr 0.000369	time 0.6330 (0.6656)	loss 2.9992 (3.5364)	grad_norm 3.3045 (nan)	mem 8931MB
[2022-04-06 21:17:28 large] (main.py 233): INFO EPOCH 102 training takes 0:27:45
[2022-04-06 21:17:34 large] (main.py 273): INFO Test: [0/98]	Time 6.540 (6.540)	Loss 1.2327 (1.2327)	Acc@1 76.367 (76.367)	Acc@5 90.625 (90.625)	Mem 8931MB
[2022-04-06 21:18:00 large] (main.py 279): INFO  * Acc@1 75.188 Acc@5 92.800
[2022-04-06 21:18:00 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 75.2%
[2022-04-06 21:18:00 large] (main.py 148): INFO Max accuracy: 75.24%
[2022-04-06 21:18:07 large] (main.py 226): INFO Train: [103/300][0/2502]	eta 5:15:40 lr 0.000369	time 7.5701 (7.5701)	loss 3.8359 (3.8359)	grad_norm 2.5341 (2.5341)	mem 8931MB
[2022-04-06 21:19:05 large] (main.py 226): INFO Train: [103/300][100/2502]	eta 0:26:00 lr 0.000369	time 0.6343 (0.6495)	loss 2.7509 (3.4891)	grad_norm 3.0053 (3.0509)	mem 8931MB
[2022-04-06 21:20:13 large] (main.py 226): INFO Train: [103/300][200/2502]	eta 0:25:22 lr 0.000369	time 0.6820 (0.6612)	loss 4.0936 (3.5176)	grad_norm 3.0077 (2.9800)	mem 8931MB
[2022-04-06 21:21:21 large] (main.py 226): INFO Train: [103/300][300/2502]	eta 0:24:35 lr 0.000369	time 0.5742 (0.6703)	loss 2.3602 (3.5259)	grad_norm 2.8568 (3.0235)	mem 8931MB
[2022-04-06 21:22:28 large] (main.py 226): INFO Train: [103/300][400/2502]	eta 0:23:27 lr 0.000369	time 0.6826 (0.6694)	loss 3.8603 (3.5195)	grad_norm 2.9652 (2.9810)	mem 8931MB
[2022-04-06 21:23:35 large] (main.py 226): INFO Train: [103/300][500/2502]	eta 0:22:21 lr 0.000369	time 0.5785 (0.6701)	loss 2.3050 (3.4908)	grad_norm 3.3699 (2.9740)	mem 8931MB
[2022-04-06 21:24:41 large] (main.py 226): INFO Train: [103/300][600/2502]	eta 0:21:10 lr 0.000369	time 0.6235 (0.6680)	loss 3.7859 (3.4895)	grad_norm 2.6522 (2.9906)	mem 8931MB
[2022-04-06 21:25:48 large] (main.py 226): INFO Train: [103/300][700/2502]	eta 0:20:03 lr 0.000369	time 0.6758 (0.6676)	loss 3.6833 (3.4987)	grad_norm 2.6163 (nan)	mem 8931MB
[2022-04-06 21:26:55 large] (main.py 226): INFO Train: [103/300][800/2502]	eta 0:18:56 lr 0.000369	time 0.6124 (0.6678)	loss 3.6261 (3.4897)	grad_norm 3.7449 (nan)	mem 8931MB
[2022-04-06 21:28:01 large] (main.py 226): INFO Train: [103/300][900/2502]	eta 0:17:48 lr 0.000369	time 0.7391 (0.6670)	loss 3.4774 (3.5009)	grad_norm 3.2361 (nan)	mem 8931MB
[2022-04-06 21:29:07 large] (main.py 226): INFO Train: [103/300][1000/2502]	eta 0:16:41 lr 0.000369	time 0.6301 (0.6671)	loss 3.8323 (3.5000)	grad_norm 2.4200 (nan)	mem 8931MB
[2022-04-06 21:30:13 large] (main.py 226): INFO Train: [103/300][1100/2502]	eta 0:15:34 lr 0.000368	time 0.8033 (0.6663)	loss 3.8270 (3.5105)	grad_norm 2.8360 (nan)	mem 8931MB
[2022-04-06 21:31:21 large] (main.py 226): INFO Train: [103/300][1200/2502]	eta 0:14:28 lr 0.000368	time 0.6266 (0.6671)	loss 3.9025 (3.5128)	grad_norm 2.1674 (nan)	mem 8931MB
[2022-04-06 21:32:27 large] (main.py 226): INFO Train: [103/300][1300/2502]	eta 0:13:21 lr 0.000368	time 0.6691 (0.6668)	loss 3.1089 (3.5167)	grad_norm 3.2837 (nan)	mem 8931MB
[2022-04-06 21:33:33 large] (main.py 226): INFO Train: [103/300][1400/2502]	eta 0:12:13 lr 0.000368	time 0.6626 (0.6660)	loss 2.4507 (3.5115)	grad_norm 2.8164 (nan)	mem 8931MB
[2022-04-06 21:34:39 large] (main.py 226): INFO Train: [103/300][1500/2502]	eta 0:11:06 lr 0.000368	time 0.7165 (0.6656)	loss 2.9157 (3.5155)	grad_norm 2.6682 (nan)	mem 8931MB
[2022-04-06 21:35:44 large] (main.py 226): INFO Train: [103/300][1600/2502]	eta 0:09:59 lr 0.000368	time 0.7171 (0.6646)	loss 2.5507 (3.5143)	grad_norm 2.6710 (nan)	mem 8931MB
[2022-04-06 21:36:50 large] (main.py 226): INFO Train: [103/300][1700/2502]	eta 0:08:52 lr 0.000368	time 0.5991 (0.6645)	loss 4.1687 (3.5198)	grad_norm 2.8599 (nan)	mem 8931MB
[2022-04-06 21:37:56 large] (main.py 226): INFO Train: [103/300][1800/2502]	eta 0:07:46 lr 0.000368	time 1.5618 (0.6643)	loss 2.8103 (3.5177)	grad_norm 3.1839 (nan)	mem 8931MB
[2022-04-06 21:39:02 large] (main.py 226): INFO Train: [103/300][1900/2502]	eta 0:06:39 lr 0.000368	time 0.5122 (0.6638)	loss 4.0622 (3.5165)	grad_norm 2.7131 (nan)	mem 8931MB
[2022-04-06 21:40:08 large] (main.py 226): INFO Train: [103/300][2000/2502]	eta 0:05:33 lr 0.000368	time 0.5896 (0.6636)	loss 3.9446 (3.5124)	grad_norm 2.7740 (nan)	mem 8931MB
[2022-04-06 21:41:15 large] (main.py 226): INFO Train: [103/300][2100/2502]	eta 0:04:26 lr 0.000368	time 0.6813 (0.6640)	loss 3.8265 (3.5138)	grad_norm 3.6562 (nan)	mem 8931MB
[2022-04-06 21:42:21 large] (main.py 226): INFO Train: [103/300][2200/2502]	eta 0:03:20 lr 0.000367	time 0.5226 (0.6640)	loss 3.7707 (3.5132)	grad_norm 2.8372 (nan)	mem 8931MB
[2022-04-06 21:43:27 large] (main.py 226): INFO Train: [103/300][2300/2502]	eta 0:02:14 lr 0.000367	time 0.6542 (0.6637)	loss 3.8950 (3.5145)	grad_norm 2.6312 (nan)	mem 8931MB
[2022-04-06 21:44:32 large] (main.py 226): INFO Train: [103/300][2400/2502]	eta 0:01:07 lr 0.000367	time 0.7231 (0.6633)	loss 3.3654 (3.5143)	grad_norm 2.9110 (nan)	mem 8931MB
[2022-04-06 21:45:38 large] (main.py 226): INFO Train: [103/300][2500/2502]	eta 0:00:01 lr 0.000367	time 0.5380 (0.6629)	loss 3.7372 (3.5140)	grad_norm 2.3385 (nan)	mem 8931MB
[2022-04-06 21:45:39 large] (main.py 233): INFO EPOCH 103 training takes 0:27:38
[2022-04-06 21:45:45 large] (main.py 273): INFO Test: [0/98]	Time 6.020 (6.020)	Loss 1.1823 (1.1823)	Acc@1 75.195 (75.195)	Acc@5 92.969 (92.969)	Mem 8931MB
[2022-04-06 21:46:11 large] (main.py 279): INFO  * Acc@1 75.442 Acc@5 92.932
[2022-04-06 21:46:11 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 75.4%
[2022-04-06 21:46:11 large] (utils.py 57): INFO output/large/default/ckpt_epoch_103.pth saving......
[2022-04-06 21:46:12 large] (utils.py 59): INFO output/large/default/ckpt_epoch_103.pth saved !!!
[2022-04-06 21:46:12 large] (main.py 148): INFO Max accuracy: 75.44%
[2022-04-06 21:46:20 large] (main.py 226): INFO Train: [104/300][0/2502]	eta 5:25:07 lr 0.000367	time 7.7967 (7.7967)	loss 3.9856 (3.9856)	grad_norm 2.4990 (2.4990)	mem 8931MB
[2022-04-06 21:47:19 large] (main.py 226): INFO Train: [104/300][100/2502]	eta 0:26:32 lr 0.000367	time 0.7350 (0.6631)	loss 3.3271 (3.4871)	grad_norm 2.8486 (2.9256)	mem 8931MB
[2022-04-06 21:48:26 large] (main.py 226): INFO Train: [104/300][200/2502]	eta 0:25:35 lr 0.000367	time 0.6984 (0.6672)	loss 2.3895 (3.4792)	grad_norm 2.7608 (2.9234)	mem 8931MB
[2022-04-06 21:49:32 large] (main.py 226): INFO Train: [104/300][300/2502]	eta 0:24:24 lr 0.000367	time 0.7047 (0.6651)	loss 2.5734 (3.4623)	grad_norm 2.9504 (2.9328)	mem 8931MB
[2022-04-06 21:50:38 large] (main.py 226): INFO Train: [104/300][400/2502]	eta 0:23:13 lr 0.000367	time 0.6802 (0.6627)	loss 3.3111 (3.4656)	grad_norm 3.0385 (2.9446)	mem 8931MB
[2022-04-06 21:51:44 large] (main.py 226): INFO Train: [104/300][500/2502]	eta 0:22:09 lr 0.000367	time 0.7520 (0.6640)	loss 3.9016 (3.4781)	grad_norm 4.0974 (2.9663)	mem 8931MB
[2022-04-06 21:52:51 large] (main.py 226): INFO Train: [104/300][600/2502]	eta 0:21:03 lr 0.000367	time 0.6755 (0.6645)	loss 4.1931 (3.4850)	grad_norm 2.5680 (2.9594)	mem 8931MB
[2022-04-06 21:53:58 large] (main.py 226): INFO Train: [104/300][700/2502]	eta 0:19:58 lr 0.000367	time 0.6890 (0.6653)	loss 4.3297 (3.4878)	grad_norm 2.7806 (2.9560)	mem 8931MB
[2022-04-06 21:55:03 large] (main.py 226): INFO Train: [104/300][800/2502]	eta 0:18:49 lr 0.000366	time 0.6158 (0.6635)	loss 2.8401 (3.4839)	grad_norm 3.5411 (2.9675)	mem 8931MB
[2022-04-06 21:56:09 large] (main.py 226): INFO Train: [104/300][900/2502]	eta 0:17:42 lr 0.000366	time 0.6076 (0.6631)	loss 3.7989 (3.4795)	grad_norm 2.5310 (2.9596)	mem 8931MB
[2022-04-06 21:57:14 large] (main.py 226): INFO Train: [104/300][1000/2502]	eta 0:16:33 lr 0.000366	time 0.6442 (0.6614)	loss 3.9321 (3.4805)	grad_norm 2.6049 (2.9390)	mem 8931MB
[2022-04-06 21:58:19 large] (main.py 226): INFO Train: [104/300][1100/2502]	eta 0:15:26 lr 0.000366	time 0.6400 (0.6610)	loss 2.4727 (3.4819)	grad_norm 2.8321 (2.9413)	mem 8931MB
[2022-04-06 21:59:25 large] (main.py 226): INFO Train: [104/300][1200/2502]	eta 0:14:19 lr 0.000366	time 0.6457 (0.6602)	loss 3.7394 (3.4862)	grad_norm 2.1552 (2.9587)	mem 8931MB
[2022-04-06 22:00:31 large] (main.py 226): INFO Train: [104/300][1300/2502]	eta 0:13:13 lr 0.000366	time 0.6581 (0.6602)	loss 3.7829 (3.4904)	grad_norm 2.0188 (2.9548)	mem 8931MB
[2022-04-06 22:01:35 large] (main.py 226): INFO Train: [104/300][1400/2502]	eta 0:12:06 lr 0.000366	time 0.5880 (0.6593)	loss 2.9402 (3.4963)	grad_norm 2.7000 (2.9526)	mem 8931MB
[2022-04-06 22:02:42 large] (main.py 226): INFO Train: [104/300][1500/2502]	eta 0:11:00 lr 0.000366	time 0.6570 (0.6597)	loss 3.6960 (3.4945)	grad_norm 2.4244 (2.9543)	mem 8931MB
[2022-04-06 22:03:48 large] (main.py 226): INFO Train: [104/300][1600/2502]	eta 0:09:55 lr 0.000366	time 0.7311 (0.6599)	loss 3.9210 (3.4962)	grad_norm 2.8830 (2.9535)	mem 8931MB
[2022-04-06 22:04:54 large] (main.py 226): INFO Train: [104/300][1700/2502]	eta 0:08:48 lr 0.000366	time 0.6493 (0.6595)	loss 2.3758 (3.4964)	grad_norm 3.4257 (2.9562)	mem 8931MB
[2022-04-06 22:05:59 large] (main.py 226): INFO Train: [104/300][1800/2502]	eta 0:07:42 lr 0.000366	time 0.5661 (0.6591)	loss 2.4374 (3.4966)	grad_norm 4.5578 (2.9624)	mem 8931MB
[2022-04-06 22:07:05 large] (main.py 226): INFO Train: [104/300][1900/2502]	eta 0:06:36 lr 0.000365	time 0.6498 (0.6595)	loss 4.0589 (3.4968)	grad_norm 3.8825 (2.9637)	mem 8931MB
[2022-04-06 22:08:11 large] (main.py 226): INFO Train: [104/300][2000/2502]	eta 0:05:30 lr 0.000365	time 0.6945 (0.6593)	loss 3.2640 (3.4998)	grad_norm 2.4867 (2.9642)	mem 8931MB
[2022-04-06 22:09:17 large] (main.py 226): INFO Train: [104/300][2100/2502]	eta 0:04:24 lr 0.000365	time 0.8135 (0.6591)	loss 4.2289 (3.5007)	grad_norm 3.2089 (2.9647)	mem 8931MB
[2022-04-06 22:10:22 large] (main.py 226): INFO Train: [104/300][2200/2502]	eta 0:03:19 lr 0.000365	time 0.6459 (0.6591)	loss 4.0523 (3.5019)	grad_norm 2.7399 (2.9685)	mem 8931MB
[2022-04-06 22:11:28 large] (main.py 226): INFO Train: [104/300][2300/2502]	eta 0:02:13 lr 0.000365	time 0.6241 (0.6591)	loss 3.1574 (3.5072)	grad_norm 2.4674 (2.9708)	mem 8931MB
[2022-04-06 22:12:34 large] (main.py 226): INFO Train: [104/300][2400/2502]	eta 0:01:07 lr 0.000365	time 0.6155 (0.6590)	loss 3.9872 (3.5086)	grad_norm 3.1535 (2.9731)	mem 8931MB
[2022-04-06 22:13:39 large] (main.py 226): INFO Train: [104/300][2500/2502]	eta 0:00:01 lr 0.000365	time 0.5892 (0.6584)	loss 3.0086 (3.5076)	grad_norm 3.0348 (2.9768)	mem 8931MB
[2022-04-06 22:13:40 large] (main.py 233): INFO EPOCH 104 training takes 0:27:27
[2022-04-06 22:13:46 large] (main.py 273): INFO Test: [0/98]	Time 6.042 (6.042)	Loss 1.2180 (1.2180)	Acc@1 76.172 (76.172)	Acc@5 93.359 (93.359)	Mem 8931MB
[2022-04-06 22:14:12 large] (main.py 279): INFO  * Acc@1 75.480 Acc@5 92.860
[2022-04-06 22:14:12 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 75.5%
[2022-04-06 22:14:12 large] (utils.py 57): INFO output/large/default/ckpt_epoch_104.pth saving......
[2022-04-06 22:14:13 large] (utils.py 59): INFO output/large/default/ckpt_epoch_104.pth saved !!!
[2022-04-06 22:14:13 large] (main.py 148): INFO Max accuracy: 75.48%
[2022-04-06 22:14:21 large] (main.py 226): INFO Train: [105/300][0/2502]	eta 5:55:34 lr 0.000365	time 8.5271 (8.5271)	loss 4.1528 (4.1528)	grad_norm 2.5008 (2.5008)	mem 8931MB
[2022-04-06 22:15:18 large] (main.py 226): INFO Train: [105/300][100/2502]	eta 0:26:03 lr 0.000365	time 0.6875 (0.6511)	loss 2.6532 (3.4423)	grad_norm 2.5141 (2.9132)	mem 8931MB
[2022-04-06 22:16:25 large] (main.py 226): INFO Train: [105/300][200/2502]	eta 0:25:19 lr 0.000365	time 0.7282 (0.6601)	loss 3.5181 (3.4747)	grad_norm 4.2316 (2.9664)	mem 8931MB
[2022-04-06 22:17:31 large] (main.py 226): INFO Train: [105/300][300/2502]	eta 0:24:14 lr 0.000365	time 0.6826 (0.6604)	loss 4.3007 (3.4952)	grad_norm 3.2857 (2.9773)	mem 8931MB
[2022-04-06 22:18:37 large] (main.py 226): INFO Train: [105/300][400/2502]	eta 0:23:05 lr 0.000364	time 0.7073 (0.6594)	loss 3.6110 (3.5062)	grad_norm 3.0751 (2.9947)	mem 8931MB
[2022-04-06 22:19:42 large] (main.py 226): INFO Train: [105/300][500/2502]	eta 0:21:57 lr 0.000364	time 0.6117 (0.6581)	loss 4.0205 (3.4950)	grad_norm 2.9193 (3.0104)	mem 8931MB
[2022-04-06 22:20:47 large] (main.py 226): INFO Train: [105/300][600/2502]	eta 0:20:48 lr 0.000364	time 0.6912 (0.6564)	loss 3.9253 (3.5037)	grad_norm 3.7888 (3.0215)	mem 8931MB
[2022-04-06 22:21:52 large] (main.py 226): INFO Train: [105/300][700/2502]	eta 0:19:41 lr 0.000364	time 0.5507 (0.6554)	loss 3.9982 (3.5217)	grad_norm 3.2500 (3.0215)	mem 8931MB
[2022-04-06 22:22:56 large] (main.py 226): INFO Train: [105/300][800/2502]	eta 0:18:32 lr 0.000364	time 0.6327 (0.6536)	loss 2.7128 (3.5165)	grad_norm 2.2908 (3.0183)	mem 8931MB
[2022-04-06 22:24:01 large] (main.py 226): INFO Train: [105/300][900/2502]	eta 0:17:27 lr 0.000364	time 0.6454 (0.6536)	loss 3.7316 (3.5251)	grad_norm 2.6802 (3.0235)	mem 8931MB
[2022-04-06 22:25:06 large] (main.py 226): INFO Train: [105/300][1000/2502]	eta 0:16:20 lr 0.000364	time 0.6972 (0.6529)	loss 3.6988 (3.5198)	grad_norm 3.3402 (3.0277)	mem 8931MB
[2022-04-06 22:26:11 large] (main.py 226): INFO Train: [105/300][1100/2502]	eta 0:15:14 lr 0.000364	time 0.6085 (0.6524)	loss 3.5611 (3.5152)	grad_norm 3.5750 (3.0252)	mem 8931MB
[2022-04-06 22:27:15 large] (main.py 226): INFO Train: [105/300][1200/2502]	eta 0:14:08 lr 0.000364	time 0.6040 (0.6519)	loss 3.1161 (3.5148)	grad_norm 3.8339 (3.0291)	mem 8931MB
[2022-04-06 22:28:19 large] (main.py 226): INFO Train: [105/300][1300/2502]	eta 0:13:02 lr 0.000364	time 0.6437 (0.6510)	loss 3.7333 (3.5065)	grad_norm 2.9143 (nan)	mem 8931MB
[2022-04-06 22:29:23 large] (main.py 226): INFO Train: [105/300][1400/2502]	eta 0:11:56 lr 0.000364	time 0.5487 (0.6500)	loss 3.3735 (3.5042)	grad_norm 2.5596 (nan)	mem 8931MB
[2022-04-06 22:30:27 large] (main.py 226): INFO Train: [105/300][1500/2502]	eta 0:10:50 lr 0.000363	time 0.7452 (0.6491)	loss 2.8477 (3.5038)	grad_norm 2.5317 (nan)	mem 8931MB
[2022-04-06 22:31:31 large] (main.py 226): INFO Train: [105/300][1600/2502]	eta 0:09:44 lr 0.000363	time 0.6191 (0.6485)	loss 3.0656 (3.5052)	grad_norm 2.5064 (nan)	mem 8931MB
[2022-04-06 22:32:35 large] (main.py 226): INFO Train: [105/300][1700/2502]	eta 0:08:39 lr 0.000363	time 0.8487 (0.6482)	loss 4.1835 (3.5102)	grad_norm 2.6006 (nan)	mem 8931MB
[2022-04-06 22:33:40 large] (main.py 226): INFO Train: [105/300][1800/2502]	eta 0:07:34 lr 0.000363	time 0.6348 (0.6480)	loss 3.2157 (3.5098)	grad_norm 2.5715 (nan)	mem 8931MB
[2022-04-06 22:34:43 large] (main.py 226): INFO Train: [105/300][1900/2502]	eta 0:06:29 lr 0.000363	time 0.6598 (0.6475)	loss 3.6382 (3.5091)	grad_norm 3.2937 (nan)	mem 8931MB
[2022-04-06 22:35:48 large] (main.py 226): INFO Train: [105/300][2000/2502]	eta 0:05:24 lr 0.000363	time 0.6182 (0.6473)	loss 3.6021 (3.5104)	grad_norm 2.7471 (nan)	mem 8931MB
[2022-04-06 22:36:53 large] (main.py 226): INFO Train: [105/300][2100/2502]	eta 0:04:20 lr 0.000363	time 0.6629 (0.6473)	loss 2.5221 (3.5122)	grad_norm 2.8992 (nan)	mem 8931MB
[2022-04-06 22:37:57 large] (main.py 226): INFO Train: [105/300][2200/2502]	eta 0:03:15 lr 0.000363	time 0.6483 (0.6470)	loss 3.9772 (3.5116)	grad_norm 2.9904 (nan)	mem 8931MB
[2022-04-06 22:39:00 large] (main.py 226): INFO Train: [105/300][2300/2502]	eta 0:02:10 lr 0.000363	time 0.6256 (0.6466)	loss 4.3879 (3.5118)	grad_norm 3.3551 (nan)	mem 8931MB
[2022-04-06 22:40:05 large] (main.py 226): INFO Train: [105/300][2400/2502]	eta 0:01:05 lr 0.000363	time 0.6551 (0.6467)	loss 3.0651 (3.5092)	grad_norm 2.1250 (nan)	mem 8931MB
[2022-04-06 22:41:09 large] (main.py 226): INFO Train: [105/300][2500/2502]	eta 0:00:01 lr 0.000363	time 0.6129 (0.6464)	loss 4.1773 (3.5083)	grad_norm 3.3388 (nan)	mem 8931MB
[2022-04-06 22:41:10 large] (main.py 233): INFO EPOCH 105 training takes 0:26:57
[2022-04-06 22:41:16 large] (main.py 273): INFO Test: [0/98]	Time 5.808 (5.808)	Loss 1.1280 (1.1280)	Acc@1 75.000 (75.000)	Acc@5 92.969 (92.969)	Mem 8931MB
[2022-04-06 22:41:43 large] (main.py 279): INFO  * Acc@1 75.216 Acc@5 92.758
[2022-04-06 22:41:43 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 75.2%
[2022-04-06 22:41:43 large] (main.py 148): INFO Max accuracy: 75.48%
[2022-04-06 22:41:49 large] (main.py 226): INFO Train: [106/300][0/2502]	eta 4:36:21 lr 0.000363	time 6.6272 (6.6272)	loss 2.4050 (2.4050)	grad_norm 2.6881 (2.6881)	mem 8931MB
[2022-04-06 22:42:47 large] (main.py 226): INFO Train: [106/300][100/2502]	eta 0:25:24 lr 0.000362	time 0.6796 (0.6349)	loss 2.3314 (3.4380)	grad_norm 3.4009 (2.9096)	mem 8931MB
[2022-04-06 22:43:51 large] (main.py 226): INFO Train: [106/300][200/2502]	eta 0:24:32 lr 0.000362	time 0.6251 (0.6397)	loss 3.6758 (3.5053)	grad_norm 2.6574 (2.9594)	mem 8931MB
[2022-04-06 22:44:57 large] (main.py 226): INFO Train: [106/300][300/2502]	eta 0:23:37 lr 0.000362	time 0.6641 (0.6439)	loss 2.3939 (3.4558)	grad_norm 2.4468 (2.9451)	mem 8931MB
[2022-04-06 22:46:01 large] (main.py 226): INFO Train: [106/300][400/2502]	eta 0:22:35 lr 0.000362	time 0.7053 (0.6447)	loss 4.0862 (3.4396)	grad_norm 3.3922 (2.9372)	mem 8931MB
[2022-04-06 22:47:05 large] (main.py 226): INFO Train: [106/300][500/2502]	eta 0:21:28 lr 0.000362	time 0.6466 (0.6438)	loss 3.8680 (3.4335)	grad_norm 2.2562 (2.9681)	mem 8931MB
[2022-04-06 22:48:10 large] (main.py 226): INFO Train: [106/300][600/2502]	eta 0:20:24 lr 0.000362	time 0.6276 (0.6439)	loss 3.3192 (3.4496)	grad_norm 3.9450 (2.9747)	mem 8931MB
[2022-04-06 22:49:13 large] (main.py 226): INFO Train: [106/300][700/2502]	eta 0:19:18 lr 0.000362	time 0.6001 (0.6429)	loss 3.5856 (3.4568)	grad_norm 2.4336 (2.9782)	mem 8931MB
[2022-04-06 22:50:17 large] (main.py 226): INFO Train: [106/300][800/2502]	eta 0:18:12 lr 0.000362	time 0.7244 (0.6417)	loss 3.6354 (3.4648)	grad_norm 2.9948 (2.9640)	mem 8931MB
[2022-04-06 22:51:22 large] (main.py 226): INFO Train: [106/300][900/2502]	eta 0:17:08 lr 0.000362	time 0.5888 (0.6423)	loss 3.8715 (3.4672)	grad_norm 3.8291 (2.9619)	mem 8931MB
[2022-04-06 22:52:25 large] (main.py 226): INFO Train: [106/300][1000/2502]	eta 0:16:04 lr 0.000362	time 0.6119 (0.6419)	loss 4.0735 (3.4642)	grad_norm 2.8952 (2.9664)	mem 8931MB
[2022-04-06 22:53:29 large] (main.py 226): INFO Train: [106/300][1100/2502]	eta 0:14:59 lr 0.000362	time 0.6143 (0.6413)	loss 3.0542 (3.4596)	grad_norm 3.1855 (2.9821)	mem 8931MB
[2022-04-06 22:54:33 large] (main.py 226): INFO Train: [106/300][1200/2502]	eta 0:13:54 lr 0.000361	time 0.7471 (0.6409)	loss 3.2327 (3.4635)	grad_norm 3.2474 (nan)	mem 8931MB
[2022-04-06 22:55:37 large] (main.py 226): INFO Train: [106/300][1300/2502]	eta 0:12:50 lr 0.000361	time 0.6125 (0.6410)	loss 3.0679 (3.4617)	grad_norm 3.4766 (nan)	mem 8931MB
[2022-04-06 22:56:40 large] (main.py 226): INFO Train: [106/300][1400/2502]	eta 0:11:46 lr 0.000361	time 0.6006 (0.6407)	loss 3.9437 (3.4638)	grad_norm 2.9471 (nan)	mem 8931MB
[2022-04-06 22:57:45 large] (main.py 226): INFO Train: [106/300][1500/2502]	eta 0:10:42 lr 0.000361	time 0.6584 (0.6411)	loss 2.7172 (3.4671)	grad_norm 3.4826 (nan)	mem 8931MB
[2022-04-06 22:58:49 large] (main.py 226): INFO Train: [106/300][1600/2502]	eta 0:09:38 lr 0.000361	time 0.6300 (0.6411)	loss 3.6545 (3.4722)	grad_norm 3.1109 (nan)	mem 8931MB
[2022-04-06 22:59:53 large] (main.py 226): INFO Train: [106/300][1700/2502]	eta 0:08:33 lr 0.000361	time 0.8670 (0.6406)	loss 3.6597 (3.4754)	grad_norm 3.6872 (nan)	mem 8931MB
[2022-04-06 23:00:56 large] (main.py 226): INFO Train: [106/300][1800/2502]	eta 0:07:29 lr 0.000361	time 0.6294 (0.6405)	loss 2.7455 (3.4689)	grad_norm 2.8579 (nan)	mem 8931MB
[2022-04-06 23:02:01 large] (main.py 226): INFO Train: [106/300][1900/2502]	eta 0:06:25 lr 0.000361	time 0.6113 (0.6409)	loss 3.8243 (3.4747)	grad_norm 3.5953 (nan)	mem 8931MB
[2022-04-06 23:03:05 large] (main.py 226): INFO Train: [106/300][2000/2502]	eta 0:05:21 lr 0.000361	time 0.6725 (0.6410)	loss 3.8468 (3.4762)	grad_norm 2.4650 (nan)	mem 8931MB
[2022-04-06 23:04:10 large] (main.py 226): INFO Train: [106/300][2100/2502]	eta 0:04:17 lr 0.000361	time 0.6449 (0.6410)	loss 2.9332 (3.4789)	grad_norm 3.0519 (nan)	mem 8931MB
[2022-04-06 23:05:14 large] (main.py 226): INFO Train: [106/300][2200/2502]	eta 0:03:13 lr 0.000361	time 0.6469 (0.6411)	loss 3.8038 (3.4799)	grad_norm 3.1991 (nan)	mem 8931MB
[2022-04-06 23:06:17 large] (main.py 226): INFO Train: [106/300][2300/2502]	eta 0:02:09 lr 0.000360	time 0.6962 (0.6409)	loss 4.1811 (3.4801)	grad_norm 2.5521 (nan)	mem 8931MB
[2022-04-06 23:07:21 large] (main.py 226): INFO Train: [106/300][2400/2502]	eta 0:01:05 lr 0.000360	time 0.6168 (0.6406)	loss 3.6786 (3.4826)	grad_norm 4.4651 (nan)	mem 8931MB
[2022-04-06 23:08:23 large] (main.py 226): INFO Train: [106/300][2500/2502]	eta 0:00:01 lr 0.000360	time 0.5746 (0.6399)	loss 2.7341 (3.4870)	grad_norm 3.2244 (nan)	mem 8931MB
[2022-04-06 23:08:24 large] (main.py 233): INFO EPOCH 106 training takes 0:26:41
[2022-04-06 23:08:30 large] (main.py 273): INFO Test: [0/98]	Time 6.077 (6.077)	Loss 1.1451 (1.1451)	Acc@1 76.367 (76.367)	Acc@5 92.969 (92.969)	Mem 8931MB
[2022-04-06 23:08:57 large] (main.py 279): INFO  * Acc@1 75.378 Acc@5 92.810
[2022-04-06 23:08:57 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 75.4%
[2022-04-06 23:08:57 large] (main.py 148): INFO Max accuracy: 75.48%
[2022-04-06 23:09:03 large] (main.py 226): INFO Train: [107/300][0/2502]	eta 4:31:48 lr 0.000360	time 6.5184 (6.5184)	loss 4.0957 (4.0957)	grad_norm 3.1376 (3.1376)	mem 8931MB
[2022-04-06 23:10:01 large] (main.py 226): INFO Train: [107/300][100/2502]	eta 0:25:26 lr 0.000360	time 0.6606 (0.6357)	loss 4.0775 (3.5292)	grad_norm 3.9481 (2.9995)	mem 8931MB
[2022-04-06 23:11:06 large] (main.py 226): INFO Train: [107/300][200/2502]	eta 0:24:37 lr 0.000360	time 0.6806 (0.6419)	loss 3.7781 (3.5050)	grad_norm 3.9507 (3.0264)	mem 8931MB
[2022-04-06 23:12:11 large] (main.py 226): INFO Train: [107/300][300/2502]	eta 0:23:44 lr 0.000360	time 0.6136 (0.6468)	loss 3.5319 (3.5359)	grad_norm 2.5111 (3.0028)	mem 8931MB
[2022-04-06 23:13:16 large] (main.py 226): INFO Train: [107/300][400/2502]	eta 0:22:40 lr 0.000360	time 0.7023 (0.6473)	loss 4.2672 (3.5182)	grad_norm 3.2864 (3.0038)	mem 8931MB
[2022-04-06 23:14:21 large] (main.py 226): INFO Train: [107/300][500/2502]	eta 0:21:36 lr 0.000360	time 0.6202 (0.6478)	loss 3.2909 (3.5130)	grad_norm 3.0163 (2.9929)	mem 8931MB
[2022-04-06 23:15:26 large] (main.py 226): INFO Train: [107/300][600/2502]	eta 0:20:30 lr 0.000360	time 0.6519 (0.6471)	loss 3.5974 (3.5294)	grad_norm 3.5050 (2.9903)	mem 8931MB
[2022-04-06 23:16:29 large] (main.py 226): INFO Train: [107/300][700/2502]	eta 0:19:23 lr 0.000360	time 0.6260 (0.6458)	loss 4.3644 (3.5151)	grad_norm 2.8376 (2.9990)	mem 8931MB
[2022-04-06 23:17:33 large] (main.py 226): INFO Train: [107/300][800/2502]	eta 0:18:16 lr 0.000359	time 0.6292 (0.6442)	loss 3.2927 (3.5172)	grad_norm 3.0713 (2.9973)	mem 8931MB
[2022-04-06 23:18:35 large] (main.py 226): INFO Train: [107/300][900/2502]	eta 0:17:08 lr 0.000359	time 0.6250 (0.6418)	loss 4.3226 (3.5228)	grad_norm 2.5458 (2.9981)	mem 8931MB
[2022-04-06 23:19:39 large] (main.py 226): INFO Train: [107/300][1000/2502]	eta 0:16:02 lr 0.000359	time 0.5110 (0.6411)	loss 3.2306 (3.5239)	grad_norm 2.3345 (3.0044)	mem 8931MB
[2022-04-06 23:20:43 large] (main.py 226): INFO Train: [107/300][1100/2502]	eta 0:14:59 lr 0.000359	time 0.5606 (0.6416)	loss 2.5653 (3.5208)	grad_norm 3.3370 (3.0065)	mem 8931MB
[2022-04-06 23:21:46 large] (main.py 226): INFO Train: [107/300][1200/2502]	eta 0:13:54 lr 0.000359	time 0.6489 (0.6408)	loss 3.7779 (3.5203)	grad_norm 2.7771 (3.0093)	mem 8931MB
[2022-04-06 23:22:50 large] (main.py 226): INFO Train: [107/300][1300/2502]	eta 0:12:49 lr 0.000359	time 0.6075 (0.6405)	loss 4.0458 (3.5256)	grad_norm 3.0795 (3.0086)	mem 8931MB
[2022-04-06 23:23:53 large] (main.py 226): INFO Train: [107/300][1400/2502]	eta 0:11:44 lr 0.000359	time 0.6067 (0.6395)	loss 2.6702 (3.5212)	grad_norm 2.7546 (3.0032)	mem 8931MB
[2022-04-06 23:24:56 large] (main.py 226): INFO Train: [107/300][1500/2502]	eta 0:10:40 lr 0.000359	time 0.6372 (0.6393)	loss 3.7766 (3.5176)	grad_norm 3.6374 (3.0173)	mem 8931MB
[2022-04-06 23:26:00 large] (main.py 226): INFO Train: [107/300][1600/2502]	eta 0:09:36 lr 0.000359	time 0.5912 (0.6394)	loss 4.0829 (3.5192)	grad_norm 3.0590 (nan)	mem 8931MB
[2022-04-06 23:27:05 large] (main.py 226): INFO Train: [107/300][1700/2502]	eta 0:08:33 lr 0.000359	time 0.6667 (0.6397)	loss 3.7925 (3.5252)	grad_norm 2.7084 (nan)	mem 8931MB
[2022-04-06 23:28:07 large] (main.py 226): INFO Train: [107/300][1800/2502]	eta 0:07:28 lr 0.000359	time 0.5500 (0.6389)	loss 2.3509 (3.5234)	grad_norm 2.4180 (nan)	mem 8931MB
[2022-04-06 23:29:12 large] (main.py 226): INFO Train: [107/300][1900/2502]	eta 0:06:24 lr 0.000358	time 0.4988 (0.6391)	loss 3.1825 (3.5236)	grad_norm 2.7372 (nan)	mem 8931MB
[2022-04-06 23:30:16 large] (main.py 226): INFO Train: [107/300][2000/2502]	eta 0:05:20 lr 0.000358	time 0.6669 (0.6391)	loss 4.3970 (3.5246)	grad_norm 2.8219 (nan)	mem 8931MB
[2022-04-06 23:31:18 large] (main.py 226): INFO Train: [107/300][2100/2502]	eta 0:04:16 lr 0.000358	time 0.6317 (0.6386)	loss 3.2815 (3.5222)	grad_norm 3.3703 (nan)	mem 8931MB
[2022-04-06 23:32:22 large] (main.py 226): INFO Train: [107/300][2200/2502]	eta 0:03:12 lr 0.000358	time 0.6580 (0.6385)	loss 3.9547 (3.5231)	grad_norm 2.7267 (nan)	mem 8931MB
[2022-04-06 23:33:18 large] (main.py 226): INFO Train: [107/300][2300/2502]	eta 0:02:08 lr 0.000358	time 0.6436 (0.6352)	loss 3.8787 (3.5239)	grad_norm 3.3073 (nan)	mem 8931MB
[2022-04-06 23:34:23 large] (main.py 226): INFO Train: [107/300][2400/2502]	eta 0:01:04 lr 0.000358	time 0.6181 (0.6357)	loss 3.8291 (3.5211)	grad_norm 3.6009 (nan)	mem 8931MB
[2022-04-06 23:35:26 large] (main.py 226): INFO Train: [107/300][2500/2502]	eta 0:00:01 lr 0.000358	time 0.5562 (0.6353)	loss 2.4605 (3.5195)	grad_norm 3.0872 (nan)	mem 8931MB
[2022-04-06 23:35:27 large] (main.py 233): INFO EPOCH 107 training takes 0:26:29
[2022-04-06 23:35:32 large] (main.py 273): INFO Test: [0/98]	Time 5.811 (5.811)	Loss 1.2098 (1.2098)	Acc@1 75.391 (75.391)	Acc@5 91.992 (91.992)	Mem 8931MB
[2022-04-06 23:35:59 large] (main.py 279): INFO  * Acc@1 75.356 Acc@5 92.820
[2022-04-06 23:35:59 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 75.4%
[2022-04-06 23:35:59 large] (main.py 148): INFO Max accuracy: 75.48%
[2022-04-06 23:36:06 large] (main.py 226): INFO Train: [108/300][0/2502]	eta 4:56:29 lr 0.000358	time 7.1099 (7.1099)	loss 3.3675 (3.3675)	grad_norm 3.8428 (3.8428)	mem 8931MB
[2022-04-06 23:37:04 large] (main.py 226): INFO Train: [108/300][100/2502]	eta 0:25:47 lr 0.000358	time 0.6642 (0.6443)	loss 4.1108 (3.4952)	grad_norm 3.2724 (3.0476)	mem 8931MB
[2022-04-06 23:38:10 large] (main.py 226): INFO Train: [108/300][200/2502]	eta 0:24:50 lr 0.000358	time 0.6419 (0.6474)	loss 3.5026 (3.4648)	grad_norm 2.8299 (3.0441)	mem 8931MB
[2022-04-06 23:39:14 large] (main.py 226): INFO Train: [108/300][300/2502]	eta 0:23:45 lr 0.000358	time 0.6342 (0.6475)	loss 3.8745 (3.4677)	grad_norm 3.0716 (3.0193)	mem 8931MB
[2022-04-06 23:40:19 large] (main.py 226): INFO Train: [108/300][400/2502]	eta 0:22:41 lr 0.000358	time 0.7263 (0.6476)	loss 4.1780 (3.4796)	grad_norm 2.2263 (3.0601)	mem 8931MB
[2022-04-06 23:41:24 large] (main.py 226): INFO Train: [108/300][500/2502]	eta 0:21:36 lr 0.000357	time 0.6289 (0.6478)	loss 3.2140 (3.4804)	grad_norm 2.6007 (3.0281)	mem 8931MB
[2022-04-06 23:42:28 large] (main.py 226): INFO Train: [108/300][600/2502]	eta 0:20:30 lr 0.000357	time 0.6850 (0.6468)	loss 3.3667 (3.4539)	grad_norm 2.6785 (3.0298)	mem 8931MB
[2022-04-06 23:43:32 large] (main.py 226): INFO Train: [108/300][700/2502]	eta 0:19:23 lr 0.000357	time 0.6220 (0.6455)	loss 3.7106 (3.4585)	grad_norm 2.7853 (3.0245)	mem 8931MB
[2022-04-06 23:44:36 large] (main.py 226): INFO Train: [108/300][800/2502]	eta 0:18:16 lr 0.000357	time 0.5869 (0.6444)	loss 3.0438 (3.4598)	grad_norm 3.2043 (3.0258)	mem 8931MB
[2022-04-06 23:45:39 large] (main.py 226): INFO Train: [108/300][900/2502]	eta 0:17:10 lr 0.000357	time 0.5437 (0.6431)	loss 3.7576 (3.4647)	grad_norm 2.7198 (3.0324)	mem 8931MB
[2022-04-06 23:46:43 large] (main.py 226): INFO Train: [108/300][1000/2502]	eta 0:16:05 lr 0.000357	time 0.6984 (0.6429)	loss 3.0889 (3.4686)	grad_norm 3.2615 (3.0310)	mem 8931MB
[2022-04-06 23:47:45 large] (main.py 226): INFO Train: [108/300][1100/2502]	eta 0:14:58 lr 0.000357	time 0.5629 (0.6412)	loss 4.2709 (3.4841)	grad_norm 2.8680 (3.0496)	mem 8931MB
[2022-04-06 23:48:48 large] (main.py 226): INFO Train: [108/300][1200/2502]	eta 0:13:53 lr 0.000357	time 0.6555 (0.6398)	loss 3.9566 (3.4871)	grad_norm 3.1688 (3.0459)	mem 8931MB
[2022-04-06 23:49:50 large] (main.py 226): INFO Train: [108/300][1300/2502]	eta 0:12:47 lr 0.000357	time 0.7519 (0.6386)	loss 4.0053 (3.4860)	grad_norm 2.3997 (3.0521)	mem 8931MB
[2022-04-06 23:50:53 large] (main.py 226): INFO Train: [108/300][1400/2502]	eta 0:11:43 lr 0.000357	time 0.6035 (0.6380)	loss 4.0759 (3.4897)	grad_norm 3.3759 (3.0435)	mem 8931MB
[2022-04-06 23:51:57 large] (main.py 226): INFO Train: [108/300][1500/2502]	eta 0:10:39 lr 0.000356	time 0.6948 (0.6381)	loss 3.8380 (3.4900)	grad_norm 2.5290 (3.0389)	mem 8931MB
[2022-04-06 23:52:59 large] (main.py 226): INFO Train: [108/300][1600/2502]	eta 0:09:34 lr 0.000356	time 0.6187 (0.6366)	loss 4.2066 (3.4913)	grad_norm 2.4020 (nan)	mem 8931MB
[2022-04-06 23:54:01 large] (main.py 226): INFO Train: [108/300][1700/2502]	eta 0:08:30 lr 0.000356	time 0.6446 (0.6359)	loss 3.6200 (3.4911)	grad_norm 2.7862 (nan)	mem 8931MB
[2022-04-06 23:55:03 large] (main.py 226): INFO Train: [108/300][1800/2502]	eta 0:07:25 lr 0.000356	time 0.6604 (0.6353)	loss 3.7445 (3.4950)	grad_norm 3.5882 (nan)	mem 8931MB
[2022-04-06 23:56:06 large] (main.py 226): INFO Train: [108/300][1900/2502]	eta 0:06:22 lr 0.000356	time 0.6724 (0.6347)	loss 4.0310 (3.4997)	grad_norm 2.9494 (nan)	mem 8931MB
[2022-04-06 23:57:09 large] (main.py 226): INFO Train: [108/300][2000/2502]	eta 0:05:18 lr 0.000356	time 0.6301 (0.6346)	loss 3.6389 (3.4957)	grad_norm 2.6731 (nan)	mem 8931MB
[2022-04-06 23:58:13 large] (main.py 226): INFO Train: [108/300][2100/2502]	eta 0:04:15 lr 0.000356	time 0.5885 (0.6347)	loss 3.8933 (3.4931)	grad_norm 2.5260 (nan)	mem 8931MB
[2022-04-06 23:59:16 large] (main.py 226): INFO Train: [108/300][2200/2502]	eta 0:03:11 lr 0.000356	time 0.5540 (0.6345)	loss 3.6980 (3.4926)	grad_norm 2.7756 (nan)	mem 8931MB
[2022-04-07 00:00:19 large] (main.py 226): INFO Train: [108/300][2300/2502]	eta 0:02:08 lr 0.000356	time 0.6163 (0.6343)	loss 3.8515 (3.4901)	grad_norm 3.1881 (nan)	mem 8931MB
[2022-04-07 00:01:21 large] (main.py 226): INFO Train: [108/300][2400/2502]	eta 0:01:04 lr 0.000356	time 0.5139 (0.6339)	loss 3.2682 (3.4851)	grad_norm 3.0816 (nan)	mem 8931MB
[2022-04-07 00:02:24 large] (main.py 226): INFO Train: [108/300][2500/2502]	eta 0:00:01 lr 0.000356	time 0.6356 (0.6337)	loss 3.9499 (3.4864)	grad_norm 4.2880 (nan)	mem 8931MB
[2022-04-07 00:02:25 large] (main.py 233): INFO EPOCH 108 training takes 0:26:25
[2022-04-07 00:02:31 large] (main.py 273): INFO Test: [0/98]	Time 6.098 (6.098)	Loss 1.1700 (1.1700)	Acc@1 75.391 (75.391)	Acc@5 93.164 (93.164)	Mem 8931MB
[2022-04-07 00:02:57 large] (main.py 279): INFO  * Acc@1 75.400 Acc@5 92.852
[2022-04-07 00:02:57 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 75.4%
[2022-04-07 00:02:57 large] (main.py 148): INFO Max accuracy: 75.48%
[2022-04-07 00:03:04 large] (main.py 226): INFO Train: [109/300][0/2502]	eta 4:33:02 lr 0.000356	time 6.5476 (6.5476)	loss 3.5302 (3.5302)	grad_norm 2.6123 (2.6123)	mem 8931MB
[2022-04-07 00:03:57 large] (main.py 226): INFO Train: [109/300][100/2502]	eta 0:23:39 lr 0.000355	time 0.5381 (0.5908)	loss 2.1542 (3.4914)	grad_norm 3.0704 (3.1039)	mem 8931MB
[2022-04-07 00:04:59 large] (main.py 226): INFO Train: [109/300][200/2502]	eta 0:23:10 lr 0.000355	time 0.5035 (0.6041)	loss 3.6058 (3.4966)	grad_norm 4.3881 (3.0533)	mem 8931MB
[2022-04-07 00:06:04 large] (main.py 226): INFO Train: [109/300][300/2502]	eta 0:22:48 lr 0.000355	time 0.6724 (0.6214)	loss 3.7372 (3.4820)	grad_norm 3.5454 (3.0176)	mem 8931MB
[2022-04-07 00:07:10 large] (main.py 226): INFO Train: [109/300][400/2502]	eta 0:22:02 lr 0.000355	time 0.6684 (0.6292)	loss 3.8964 (3.4740)	grad_norm 2.7850 (3.0243)	mem 8931MB
[2022-04-07 00:08:14 large] (main.py 226): INFO Train: [109/300][500/2502]	eta 0:21:06 lr 0.000355	time 0.6166 (0.6327)	loss 3.1480 (3.4767)	grad_norm 2.4966 (3.0224)	mem 8931MB
[2022-04-07 00:09:17 large] (main.py 226): INFO Train: [109/300][600/2502]	eta 0:20:02 lr 0.000355	time 0.5769 (0.6324)	loss 4.0836 (3.4844)	grad_norm 2.4274 (3.0063)	mem 8931MB
[2022-04-07 00:10:22 large] (main.py 226): INFO Train: [109/300][700/2502]	eta 0:19:01 lr 0.000355	time 0.6005 (0.6335)	loss 4.2490 (3.4837)	grad_norm 2.9144 (3.0154)	mem 8931MB
[2022-04-07 00:11:25 large] (main.py 226): INFO Train: [109/300][800/2502]	eta 0:17:59 lr 0.000355	time 0.6330 (0.6343)	loss 3.6778 (3.4847)	grad_norm 2.3208 (3.0272)	mem 8931MB
[2022-04-07 00:12:30 large] (main.py 226): INFO Train: [109/300][900/2502]	eta 0:16:57 lr 0.000355	time 0.7690 (0.6353)	loss 3.6613 (3.4864)	grad_norm 2.9528 (3.0244)	mem 8931MB
[2022-04-07 00:13:34 large] (main.py 226): INFO Train: [109/300][1000/2502]	eta 0:15:55 lr 0.000355	time 0.6596 (0.6362)	loss 3.5247 (3.4860)	grad_norm 2.8558 (3.0255)	mem 8931MB
[2022-04-07 00:14:37 large] (main.py 226): INFO Train: [109/300][1100/2502]	eta 0:14:51 lr 0.000354	time 0.7020 (0.6357)	loss 2.6691 (3.4870)	grad_norm 3.8221 (3.0206)	mem 8931MB
[2022-04-07 00:15:40 large] (main.py 226): INFO Train: [109/300][1200/2502]	eta 0:13:46 lr 0.000354	time 0.6333 (0.6350)	loss 3.6446 (3.4893)	grad_norm 2.5145 (3.0115)	mem 8931MB
[2022-04-07 00:16:42 large] (main.py 226): INFO Train: [109/300][1300/2502]	eta 0:12:41 lr 0.000354	time 0.6442 (0.6339)	loss 3.8062 (3.4904)	grad_norm 2.4335 (3.0127)	mem 8931MB
[2022-04-07 00:17:45 large] (main.py 226): INFO Train: [109/300][1400/2502]	eta 0:11:38 lr 0.000354	time 0.5916 (0.6338)	loss 3.5594 (3.4919)	grad_norm 3.2340 (3.0100)	mem 8931MB
[2022-04-07 00:18:49 large] (main.py 226): INFO Train: [109/300][1500/2502]	eta 0:10:34 lr 0.000354	time 0.6173 (0.6337)	loss 3.5278 (3.4933)	grad_norm 2.8098 (3.0112)	mem 8931MB
[2022-04-07 00:19:51 large] (main.py 226): INFO Train: [109/300][1600/2502]	eta 0:09:30 lr 0.000354	time 0.6008 (0.6330)	loss 3.8536 (3.4912)	grad_norm 3.5551 (3.0076)	mem 8931MB
[2022-04-07 00:20:55 large] (main.py 226): INFO Train: [109/300][1700/2502]	eta 0:08:27 lr 0.000354	time 0.6791 (0.6334)	loss 4.1472 (3.4911)	grad_norm 2.6886 (3.0128)	mem 8931MB
[2022-04-07 00:21:58 large] (main.py 226): INFO Train: [109/300][1800/2502]	eta 0:07:24 lr 0.000354	time 0.6039 (0.6335)	loss 4.0527 (3.4883)	grad_norm 2.5949 (3.0180)	mem 8931MB
[2022-04-07 00:23:02 large] (main.py 226): INFO Train: [109/300][1900/2502]	eta 0:06:21 lr 0.000354	time 0.5933 (0.6335)	loss 2.4670 (3.4871)	grad_norm 3.0118 (3.0235)	mem 8931MB
[2022-04-07 00:24:04 large] (main.py 226): INFO Train: [109/300][2000/2502]	eta 0:05:17 lr 0.000354	time 0.5397 (0.6328)	loss 4.0741 (3.4903)	grad_norm 2.5348 (3.0247)	mem 8931MB
[2022-04-07 00:25:06 large] (main.py 226): INFO Train: [109/300][2100/2502]	eta 0:04:14 lr 0.000354	time 0.6442 (0.6322)	loss 3.6356 (3.4895)	grad_norm 3.3391 (3.0280)	mem 8931MB
[2022-04-07 00:26:08 large] (main.py 226): INFO Train: [109/300][2200/2502]	eta 0:03:10 lr 0.000353	time 0.6511 (0.6320)	loss 3.8070 (3.4934)	grad_norm 2.7095 (3.0315)	mem 8931MB
[2022-04-07 00:27:13 large] (main.py 226): INFO Train: [109/300][2300/2502]	eta 0:02:07 lr 0.000353	time 0.6213 (0.6325)	loss 2.6167 (3.4889)	grad_norm 2.2016 (3.0310)	mem 8931MB
[2022-04-07 00:28:17 large] (main.py 226): INFO Train: [109/300][2400/2502]	eta 0:01:04 lr 0.000353	time 0.6241 (0.6328)	loss 2.3557 (3.4890)	grad_norm 4.0551 (3.0312)	mem 8931MB
[2022-04-07 00:29:20 large] (main.py 226): INFO Train: [109/300][2500/2502]	eta 0:00:01 lr 0.000353	time 0.6164 (0.6328)	loss 4.2814 (3.4871)	grad_norm 2.3529 (3.0288)	mem 8931MB
[2022-04-07 00:29:21 large] (main.py 233): INFO EPOCH 109 training takes 0:26:23
[2022-04-07 00:29:27 large] (main.py 273): INFO Test: [0/98]	Time 6.092 (6.092)	Loss 1.0034 (1.0034)	Acc@1 78.711 (78.711)	Acc@5 94.141 (94.141)	Mem 8931MB
[2022-04-07 00:29:53 large] (main.py 279): INFO  * Acc@1 75.494 Acc@5 92.962
[2022-04-07 00:29:53 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 75.5%
[2022-04-07 00:29:53 large] (utils.py 57): INFO output/large/default/ckpt_epoch_109.pth saving......
[2022-04-07 00:29:54 large] (utils.py 59): INFO output/large/default/ckpt_epoch_109.pth saved !!!
[2022-04-07 00:29:54 large] (main.py 148): INFO Max accuracy: 75.49%
[2022-04-07 00:30:02 large] (main.py 226): INFO Train: [110/300][0/2502]	eta 5:54:33 lr 0.000353	time 8.5025 (8.5025)	loss 3.9027 (3.9027)	grad_norm 2.4439 (2.4439)	mem 8931MB
[2022-04-07 00:30:56 large] (main.py 226): INFO Train: [110/300][100/2502]	eta 0:24:47 lr 0.000353	time 0.6198 (0.6191)	loss 3.7403 (3.4751)	grad_norm 3.9326 (3.1040)	mem 8931MB
[2022-04-07 00:32:03 large] (main.py 226): INFO Train: [110/300][200/2502]	eta 0:24:35 lr 0.000353	time 0.5416 (0.6411)	loss 3.5349 (3.4987)	grad_norm 4.1697 (nan)	mem 8931MB
[2022-04-07 00:33:08 large] (main.py 226): INFO Train: [110/300][300/2502]	eta 0:23:37 lr 0.000353	time 0.6450 (0.6439)	loss 3.0943 (3.4984)	grad_norm 3.2652 (nan)	mem 8931MB
[2022-04-07 00:34:12 large] (main.py 226): INFO Train: [110/300][400/2502]	eta 0:22:35 lr 0.000353	time 0.6290 (0.6448)	loss 2.3482 (3.5004)	grad_norm 3.0713 (nan)	mem 8931MB
[2022-04-07 00:35:16 large] (main.py 226): INFO Train: [110/300][500/2502]	eta 0:21:27 lr 0.000353	time 0.6802 (0.6431)	loss 4.0398 (3.4897)	grad_norm 2.7402 (nan)	mem 8931MB
[2022-04-07 00:36:19 large] (main.py 226): INFO Train: [110/300][600/2502]	eta 0:20:19 lr 0.000353	time 0.5988 (0.6410)	loss 3.5416 (3.4803)	grad_norm 4.2650 (nan)	mem 8931MB
[2022-04-07 00:37:23 large] (main.py 226): INFO Train: [110/300][700/2502]	eta 0:19:15 lr 0.000353	time 0.6809 (0.6410)	loss 4.3269 (3.4936)	grad_norm 2.9386 (nan)	mem 8931MB
[2022-04-07 00:38:25 large] (main.py 226): INFO Train: [110/300][800/2502]	eta 0:18:07 lr 0.000352	time 0.7052 (0.6388)	loss 3.1023 (3.4938)	grad_norm 2.7716 (nan)	mem 8931MB
[2022-04-07 00:39:29 large] (main.py 226): INFO Train: [110/300][900/2502]	eta 0:17:03 lr 0.000352	time 0.6092 (0.6388)	loss 3.0234 (3.4942)	grad_norm 2.6274 (nan)	mem 8931MB
[2022-04-07 00:40:32 large] (main.py 226): INFO Train: [110/300][1000/2502]	eta 0:15:57 lr 0.000352	time 0.5420 (0.6375)	loss 2.6964 (3.4965)	grad_norm 2.8823 (nan)	mem 8931MB
[2022-04-07 00:41:34 large] (main.py 226): INFO Train: [110/300][1100/2502]	eta 0:14:51 lr 0.000352	time 0.6808 (0.6360)	loss 2.8253 (3.4891)	grad_norm 3.4568 (nan)	mem 8931MB
[2022-04-07 00:42:39 large] (main.py 226): INFO Train: [110/300][1200/2502]	eta 0:13:49 lr 0.000352	time 0.6001 (0.6371)	loss 3.7878 (3.4946)	grad_norm 3.0939 (nan)	mem 8931MB
[2022-04-07 00:43:42 large] (main.py 226): INFO Train: [110/300][1300/2502]	eta 0:12:45 lr 0.000352	time 0.5278 (0.6365)	loss 3.9453 (3.5009)	grad_norm 3.1428 (nan)	mem 8931MB
[2022-04-07 00:44:44 large] (main.py 226): INFO Train: [110/300][1400/2502]	eta 0:11:40 lr 0.000352	time 0.6701 (0.6354)	loss 3.7079 (3.4940)	grad_norm 2.6748 (nan)	mem 8931MB
[2022-04-07 00:45:47 large] (main.py 226): INFO Train: [110/300][1500/2502]	eta 0:10:36 lr 0.000352	time 0.6206 (0.6350)	loss 2.5634 (3.4980)	grad_norm 2.2711 (nan)	mem 8931MB
[2022-04-07 00:46:49 large] (main.py 226): INFO Train: [110/300][1600/2502]	eta 0:09:32 lr 0.000352	time 0.6116 (0.6343)	loss 3.3343 (3.4952)	grad_norm 2.8753 (nan)	mem 8931MB
[2022-04-07 00:47:53 large] (main.py 226): INFO Train: [110/300][1700/2502]	eta 0:08:28 lr 0.000352	time 0.6494 (0.6342)	loss 3.8030 (3.4912)	grad_norm 2.6018 (nan)	mem 8931MB
[2022-04-07 00:48:55 large] (main.py 226): INFO Train: [110/300][1800/2502]	eta 0:07:24 lr 0.000351	time 0.5986 (0.6335)	loss 3.1127 (3.4934)	grad_norm 3.2220 (nan)	mem 8931MB
[2022-04-07 00:49:56 large] (main.py 226): INFO Train: [110/300][1900/2502]	eta 0:06:20 lr 0.000351	time 0.6439 (0.6325)	loss 2.3246 (3.4972)	grad_norm 3.9907 (nan)	mem 8931MB
[2022-04-07 00:50:58 large] (main.py 226): INFO Train: [110/300][2000/2502]	eta 0:05:17 lr 0.000351	time 0.7073 (0.6320)	loss 2.7893 (3.4971)	grad_norm 3.1491 (nan)	mem 8931MB
[2022-04-07 00:52:02 large] (main.py 226): INFO Train: [110/300][2100/2502]	eta 0:04:14 lr 0.000351	time 0.6214 (0.6321)	loss 3.7855 (3.4921)	grad_norm 2.8978 (nan)	mem 8931MB
[2022-04-07 00:53:06 large] (main.py 226): INFO Train: [110/300][2200/2502]	eta 0:03:10 lr 0.000351	time 0.5568 (0.6324)	loss 3.6929 (3.4923)	grad_norm 2.8573 (nan)	mem 8931MB
[2022-04-07 00:54:09 large] (main.py 226): INFO Train: [110/300][2300/2502]	eta 0:02:07 lr 0.000351	time 0.6335 (0.6325)	loss 3.5690 (3.4935)	grad_norm 2.9093 (nan)	mem 8931MB
[2022-04-07 00:55:13 large] (main.py 226): INFO Train: [110/300][2400/2502]	eta 0:01:04 lr 0.000351	time 0.6678 (0.6328)	loss 3.3034 (3.4927)	grad_norm 2.8459 (nan)	mem 8931MB
[2022-04-07 00:56:17 large] (main.py 226): INFO Train: [110/300][2500/2502]	eta 0:00:01 lr 0.000351	time 0.6281 (0.6330)	loss 3.8487 (3.4925)	grad_norm 2.6722 (nan)	mem 8931MB
[2022-04-07 00:56:18 large] (main.py 233): INFO EPOCH 110 training takes 0:26:24
[2022-04-07 00:56:24 large] (main.py 273): INFO Test: [0/98]	Time 5.795 (5.795)	Loss 1.1224 (1.1224)	Acc@1 72.656 (72.656)	Acc@5 95.312 (95.312)	Mem 8931MB
[2022-04-07 00:56:50 large] (main.py 279): INFO  * Acc@1 75.362 Acc@5 92.798
[2022-04-07 00:56:50 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 75.4%
[2022-04-07 00:56:50 large] (main.py 148): INFO Max accuracy: 75.49%
[2022-04-07 00:56:58 large] (main.py 226): INFO Train: [111/300][0/2502]	eta 5:22:42 lr 0.000351	time 7.7387 (7.7387)	loss 4.1266 (4.1266)	grad_norm 4.0472 (4.0472)	mem 8931MB
[2022-04-07 00:57:54 large] (main.py 226): INFO Train: [111/300][100/2502]	eta 0:25:28 lr 0.000351	time 0.6034 (0.6364)	loss 3.7348 (3.3859)	grad_norm 2.6147 (3.1983)	mem 8931MB
[2022-04-07 00:58:57 large] (main.py 226): INFO Train: [111/300][200/2502]	eta 0:24:10 lr 0.000351	time 0.7032 (0.6301)	loss 4.1640 (3.3900)	grad_norm 3.3482 (3.1437)	mem 8931MB
[2022-04-07 00:59:59 large] (main.py 226): INFO Train: [111/300][300/2502]	eta 0:23:02 lr 0.000351	time 0.5185 (0.6277)	loss 2.8832 (3.4246)	grad_norm 3.7260 (3.1897)	mem 8931MB
[2022-04-07 01:01:02 large] (main.py 226): INFO Train: [111/300][400/2502]	eta 0:22:00 lr 0.000350	time 0.6965 (0.6282)	loss 3.6149 (3.4185)	grad_norm 2.6366 (3.1443)	mem 8931MB
[2022-04-07 01:02:04 large] (main.py 226): INFO Train: [111/300][500/2502]	eta 0:20:53 lr 0.000350	time 0.5861 (0.6261)	loss 2.2211 (3.4168)	grad_norm 3.2240 (3.1186)	mem 8931MB
[2022-04-07 01:03:06 large] (main.py 226): INFO Train: [111/300][600/2502]	eta 0:19:48 lr 0.000350	time 0.6855 (0.6250)	loss 3.9629 (3.4251)	grad_norm 3.7531 (3.1076)	mem 8931MB
[2022-04-07 01:04:07 large] (main.py 226): INFO Train: [111/300][700/2502]	eta 0:18:44 lr 0.000350	time 0.6094 (0.6238)	loss 3.6343 (3.4216)	grad_norm 2.9953 (3.1036)	mem 8931MB
[2022-04-07 01:05:08 large] (main.py 226): INFO Train: [111/300][800/2502]	eta 0:17:39 lr 0.000350	time 0.6802 (0.6225)	loss 4.1604 (3.4189)	grad_norm 4.4559 (3.0935)	mem 8931MB
[2022-04-07 01:06:12 large] (main.py 226): INFO Train: [111/300][900/2502]	eta 0:16:39 lr 0.000350	time 0.5756 (0.6238)	loss 2.2966 (3.4294)	grad_norm 3.1173 (3.0942)	mem 8931MB
[2022-04-07 01:07:15 large] (main.py 226): INFO Train: [111/300][1000/2502]	eta 0:15:37 lr 0.000350	time 0.7019 (0.6244)	loss 3.7446 (3.4375)	grad_norm 4.5462 (3.0999)	mem 8931MB
[2022-04-07 01:08:19 large] (main.py 226): INFO Train: [111/300][1100/2502]	eta 0:14:37 lr 0.000350	time 0.6810 (0.6258)	loss 3.1139 (3.4364)	grad_norm 2.9088 (3.1072)	mem 8931MB
[2022-04-07 01:09:20 large] (main.py 226): INFO Train: [111/300][1200/2502]	eta 0:13:33 lr 0.000350	time 0.5169 (0.6245)	loss 3.9285 (3.4390)	grad_norm 3.7215 (3.1103)	mem 8931MB
[2022-04-07 01:10:22 large] (main.py 226): INFO Train: [111/300][1300/2502]	eta 0:12:30 lr 0.000350	time 0.6706 (0.6241)	loss 3.4288 (3.4403)	grad_norm 3.3807 (3.1109)	mem 8931MB
[2022-04-07 01:11:24 large] (main.py 226): INFO Train: [111/300][1400/2502]	eta 0:11:27 lr 0.000349	time 0.6425 (0.6240)	loss 2.9426 (3.4428)	grad_norm 3.7486 (3.1085)	mem 8931MB
[2022-04-07 01:12:27 large] (main.py 226): INFO Train: [111/300][1500/2502]	eta 0:10:25 lr 0.000349	time 0.6411 (0.6242)	loss 3.3221 (3.4479)	grad_norm 2.6657 (3.1122)	mem 8931MB
[2022-04-07 01:13:29 large] (main.py 226): INFO Train: [111/300][1600/2502]	eta 0:09:23 lr 0.000349	time 0.6514 (0.6243)	loss 3.7959 (3.4510)	grad_norm 2.6513 (3.1104)	mem 8931MB
[2022-04-07 01:14:31 large] (main.py 226): INFO Train: [111/300][1700/2502]	eta 0:08:20 lr 0.000349	time 0.6511 (0.6240)	loss 3.5800 (3.4584)	grad_norm 2.5023 (3.1145)	mem 8931MB
[2022-04-07 01:15:33 large] (main.py 226): INFO Train: [111/300][1800/2502]	eta 0:07:17 lr 0.000349	time 0.5670 (0.6236)	loss 3.3360 (3.4603)	grad_norm 2.4476 (3.1041)	mem 8931MB
[2022-04-07 01:16:34 large] (main.py 226): INFO Train: [111/300][1900/2502]	eta 0:06:15 lr 0.000349	time 0.6430 (0.6230)	loss 4.4443 (3.4689)	grad_norm 4.3988 (3.0979)	mem 8931MB
[2022-04-07 01:17:36 large] (main.py 226): INFO Train: [111/300][2000/2502]	eta 0:05:12 lr 0.000349	time 0.6583 (0.6230)	loss 4.0546 (3.4700)	grad_norm 3.6502 (3.0956)	mem 8931MB
[2022-04-07 01:18:39 large] (main.py 226): INFO Train: [111/300][2100/2502]	eta 0:04:10 lr 0.000349	time 0.5905 (0.6230)	loss 3.2087 (3.4676)	grad_norm 3.0564 (3.0925)	mem 8931MB
[2022-04-07 01:19:43 large] (main.py 226): INFO Train: [111/300][2200/2502]	eta 0:03:08 lr 0.000349	time 0.6450 (0.6237)	loss 2.6154 (3.4663)	grad_norm 3.2297 (3.0935)	mem 8931MB
[2022-04-07 01:20:46 large] (main.py 226): INFO Train: [111/300][2300/2502]	eta 0:02:06 lr 0.000349	time 0.5023 (0.6240)	loss 2.9395 (3.4698)	grad_norm 2.8596 (3.0873)	mem 8931MB
[2022-04-07 01:21:48 large] (main.py 226): INFO Train: [111/300][2400/2502]	eta 0:01:03 lr 0.000349	time 0.5786 (0.6241)	loss 4.1945 (3.4696)	grad_norm 3.6810 (3.0908)	mem 8931MB
[2022-04-07 01:22:51 large] (main.py 226): INFO Train: [111/300][2500/2502]	eta 0:00:01 lr 0.000348	time 0.5039 (0.6241)	loss 3.8206 (3.4697)	grad_norm 3.4042 (3.0924)	mem 8931MB
[2022-04-07 01:22:52 large] (main.py 233): INFO EPOCH 111 training takes 0:26:01
[2022-04-07 01:22:58 large] (main.py 273): INFO Test: [0/98]	Time 5.840 (5.840)	Loss 1.2518 (1.2518)	Acc@1 72.070 (72.070)	Acc@5 91.992 (91.992)	Mem 8931MB
[2022-04-07 01:23:24 large] (main.py 279): INFO  * Acc@1 75.472 Acc@5 92.928
[2022-04-07 01:23:24 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 75.5%
[2022-04-07 01:23:24 large] (main.py 148): INFO Max accuracy: 75.49%
[2022-04-07 01:23:31 large] (main.py 226): INFO Train: [112/300][0/2502]	eta 4:52:28 lr 0.000348	time 7.0138 (7.0138)	loss 3.4419 (3.4419)	grad_norm 2.4766 (2.4766)	mem 8931MB
[2022-04-07 01:24:29 large] (main.py 226): INFO Train: [112/300][100/2502]	eta 0:25:53 lr 0.000348	time 0.6132 (0.6468)	loss 3.6958 (3.5687)	grad_norm 2.5632 (3.2170)	mem 8931MB
[2022-04-07 01:25:33 large] (main.py 226): INFO Train: [112/300][200/2502]	eta 0:24:44 lr 0.000348	time 0.5082 (0.6450)	loss 3.6486 (3.4534)	grad_norm 2.8912 (3.1875)	mem 8931MB
[2022-04-07 01:26:37 large] (main.py 226): INFO Train: [112/300][300/2502]	eta 0:23:36 lr 0.000348	time 0.6273 (0.6431)	loss 4.1513 (3.4720)	grad_norm 2.7871 (3.1436)	mem 8931MB
[2022-04-07 01:27:40 large] (main.py 226): INFO Train: [112/300][400/2502]	eta 0:22:23 lr 0.000348	time 0.5725 (0.6392)	loss 3.5660 (3.4837)	grad_norm 2.4991 (nan)	mem 8931MB
[2022-04-07 01:28:41 large] (main.py 226): INFO Train: [112/300][500/2502]	eta 0:21:06 lr 0.000348	time 0.5068 (0.6328)	loss 3.0737 (3.4918)	grad_norm 3.9058 (nan)	mem 8931MB
[2022-04-07 01:29:42 large] (main.py 226): INFO Train: [112/300][600/2502]	eta 0:19:57 lr 0.000348	time 0.6619 (0.6297)	loss 4.3280 (3.4940)	grad_norm 2.8984 (nan)	mem 8931MB
[2022-04-07 01:30:44 large] (main.py 226): INFO Train: [112/300][700/2502]	eta 0:18:51 lr 0.000348	time 0.6052 (0.6281)	loss 3.5496 (3.4922)	grad_norm 3.2773 (nan)	mem 8931MB
[2022-04-07 01:31:46 large] (main.py 226): INFO Train: [112/300][800/2502]	eta 0:17:47 lr 0.000348	time 0.6843 (0.6275)	loss 2.6331 (3.4794)	grad_norm 2.4311 (nan)	mem 8931MB
[2022-04-07 01:32:48 large] (main.py 226): INFO Train: [112/300][900/2502]	eta 0:16:42 lr 0.000348	time 0.6156 (0.6257)	loss 3.9988 (3.4897)	grad_norm 2.7190 (nan)	mem 8931MB
[2022-04-07 01:33:50 large] (main.py 226): INFO Train: [112/300][1000/2502]	eta 0:15:39 lr 0.000347	time 0.6248 (0.6252)	loss 3.6757 (3.4906)	grad_norm 2.7729 (nan)	mem 8931MB
[2022-04-07 01:34:51 large] (main.py 226): INFO Train: [112/300][1100/2502]	eta 0:14:35 lr 0.000347	time 0.6529 (0.6243)	loss 3.6499 (3.4878)	grad_norm 2.8871 (nan)	mem 8931MB
[2022-04-07 01:35:54 large] (main.py 226): INFO Train: [112/300][1200/2502]	eta 0:13:32 lr 0.000347	time 0.6118 (0.6243)	loss 4.0666 (3.4869)	grad_norm 2.5302 (nan)	mem 8931MB
[2022-04-07 01:36:56 large] (main.py 226): INFO Train: [112/300][1300/2502]	eta 0:12:30 lr 0.000347	time 0.6315 (0.6246)	loss 3.7852 (3.4746)	grad_norm 3.3296 (nan)	mem 8931MB
[2022-04-07 01:37:59 large] (main.py 226): INFO Train: [112/300][1400/2502]	eta 0:11:28 lr 0.000347	time 0.5663 (0.6246)	loss 3.2563 (3.4732)	grad_norm 3.2125 (nan)	mem 8931MB
[2022-04-07 01:39:01 large] (main.py 226): INFO Train: [112/300][1500/2502]	eta 0:10:25 lr 0.000347	time 0.6081 (0.6244)	loss 2.3943 (3.4722)	grad_norm 2.6792 (nan)	mem 8931MB
[2022-04-07 01:40:03 large] (main.py 226): INFO Train: [112/300][1600/2502]	eta 0:09:22 lr 0.000347	time 0.5648 (0.6241)	loss 3.5958 (3.4622)	grad_norm 2.6407 (nan)	mem 8931MB
[2022-04-07 01:41:05 large] (main.py 226): INFO Train: [112/300][1700/2502]	eta 0:08:20 lr 0.000347	time 0.5370 (0.6236)	loss 3.5957 (3.4630)	grad_norm 2.3101 (nan)	mem 8931MB
[2022-04-07 01:42:06 large] (main.py 226): INFO Train: [112/300][1800/2502]	eta 0:07:17 lr 0.000347	time 0.7335 (0.6233)	loss 3.4938 (3.4638)	grad_norm 3.1507 (nan)	mem 8931MB
[2022-04-07 01:43:07 large] (main.py 226): INFO Train: [112/300][1900/2502]	eta 0:06:14 lr 0.000347	time 0.6388 (0.6226)	loss 3.1468 (3.4632)	grad_norm 2.8557 (nan)	mem 8931MB
[2022-04-07 01:44:10 large] (main.py 226): INFO Train: [112/300][2000/2502]	eta 0:05:12 lr 0.000346	time 0.6817 (0.6226)	loss 3.7150 (3.4665)	grad_norm 2.0629 (nan)	mem 8931MB
[2022-04-07 01:45:12 large] (main.py 226): INFO Train: [112/300][2100/2502]	eta 0:04:10 lr 0.000346	time 0.6611 (0.6228)	loss 4.0596 (3.4684)	grad_norm 2.7213 (nan)	mem 8931MB
[2022-04-07 01:46:14 large] (main.py 226): INFO Train: [112/300][2200/2502]	eta 0:03:08 lr 0.000346	time 0.7001 (0.6227)	loss 3.9829 (3.4700)	grad_norm 3.2601 (nan)	mem 8931MB
[2022-04-07 01:47:17 large] (main.py 226): INFO Train: [112/300][2300/2502]	eta 0:02:05 lr 0.000346	time 0.6279 (0.6230)	loss 3.6918 (3.4713)	grad_norm 2.9397 (nan)	mem 8931MB
[2022-04-07 01:48:19 large] (main.py 226): INFO Train: [112/300][2400/2502]	eta 0:01:03 lr 0.000346	time 0.6624 (0.6227)	loss 3.4739 (3.4724)	grad_norm 2.7982 (nan)	mem 8931MB
[2022-04-07 01:49:20 large] (main.py 226): INFO Train: [112/300][2500/2502]	eta 0:00:01 lr 0.000346	time 0.6280 (0.6224)	loss 2.5597 (3.4733)	grad_norm 3.6205 (nan)	mem 8931MB
[2022-04-07 01:49:21 large] (main.py 233): INFO EPOCH 112 training takes 0:25:57
[2022-04-07 01:49:28 large] (main.py 273): INFO Test: [0/98]	Time 6.120 (6.120)	Loss 1.1397 (1.1397)	Acc@1 75.586 (75.586)	Acc@5 93.555 (93.555)	Mem 8931MB
[2022-04-07 01:49:53 large] (main.py 279): INFO  * Acc@1 75.456 Acc@5 93.138
[2022-04-07 01:49:53 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 75.5%
[2022-04-07 01:49:53 large] (main.py 148): INFO Max accuracy: 75.49%
[2022-04-07 01:50:00 large] (main.py 226): INFO Train: [113/300][0/2502]	eta 4:51:26 lr 0.000346	time 6.9891 (6.9891)	loss 3.9662 (3.9662)	grad_norm 3.1932 (3.1932)	mem 8931MB
[2022-04-07 01:50:56 large] (main.py 226): INFO Train: [113/300][100/2502]	eta 0:24:49 lr 0.000346	time 0.5631 (0.6202)	loss 2.7680 (3.4417)	grad_norm 3.4091 (nan)	mem 8931MB
[2022-04-07 01:51:58 large] (main.py 226): INFO Train: [113/300][200/2502]	eta 0:23:43 lr 0.000346	time 0.6102 (0.6183)	loss 4.2006 (3.4829)	grad_norm 3.3110 (nan)	mem 8931MB
[2022-04-07 01:53:01 large] (main.py 226): INFO Train: [113/300][300/2502]	eta 0:22:54 lr 0.000346	time 0.6951 (0.6243)	loss 3.9854 (3.4604)	grad_norm 3.6295 (nan)	mem 8931MB
[2022-04-07 01:54:05 large] (main.py 226): INFO Train: [113/300][400/2502]	eta 0:21:58 lr 0.000346	time 0.7152 (0.6270)	loss 3.6181 (3.4629)	grad_norm 3.1605 (nan)	mem 8931MB
[2022-04-07 01:55:07 large] (main.py 226): INFO Train: [113/300][500/2502]	eta 0:20:52 lr 0.000346	time 0.6220 (0.6257)	loss 3.5878 (3.4638)	grad_norm 2.4720 (nan)	mem 8931MB
[2022-04-07 01:56:09 large] (main.py 226): INFO Train: [113/300][600/2502]	eta 0:19:48 lr 0.000345	time 0.6149 (0.6248)	loss 4.0108 (3.4559)	grad_norm 3.4449 (nan)	mem 8931MB
[2022-04-07 01:57:10 large] (main.py 226): INFO Train: [113/300][700/2502]	eta 0:18:42 lr 0.000345	time 0.6789 (0.6227)	loss 3.6112 (3.4629)	grad_norm 3.5410 (nan)	mem 8931MB
[2022-04-07 01:58:13 large] (main.py 226): INFO Train: [113/300][800/2502]	eta 0:17:41 lr 0.000345	time 0.6044 (0.6237)	loss 4.1237 (3.4739)	grad_norm 3.9586 (nan)	mem 8931MB
[2022-04-07 01:59:16 large] (main.py 226): INFO Train: [113/300][900/2502]	eta 0:16:40 lr 0.000345	time 0.6922 (0.6247)	loss 3.2986 (3.4915)	grad_norm 2.7173 (nan)	mem 8931MB
[2022-04-07 02:00:18 large] (main.py 226): INFO Train: [113/300][1000/2502]	eta 0:15:37 lr 0.000345	time 0.4914 (0.6242)	loss 2.9696 (3.4884)	grad_norm 2.7073 (nan)	mem 8931MB
[2022-04-07 02:01:22 large] (main.py 226): INFO Train: [113/300][1100/2502]	eta 0:14:36 lr 0.000345	time 0.5978 (0.6253)	loss 3.7826 (3.4875)	grad_norm 2.7321 (nan)	mem 8931MB
[2022-04-07 02:02:24 large] (main.py 226): INFO Train: [113/300][1200/2502]	eta 0:13:33 lr 0.000345	time 0.7576 (0.6250)	loss 4.1218 (3.4859)	grad_norm 2.8739 (nan)	mem 8931MB
[2022-04-07 02:03:29 large] (main.py 226): INFO Train: [113/300][1300/2502]	eta 0:12:33 lr 0.000345	time 0.5168 (0.6265)	loss 2.4559 (3.4860)	grad_norm 4.2509 (nan)	mem 8931MB
[2022-04-07 02:04:30 large] (main.py 226): INFO Train: [113/300][1400/2502]	eta 0:11:29 lr 0.000345	time 0.5859 (0.6259)	loss 3.1543 (3.4889)	grad_norm 3.5643 (nan)	mem 8931MB
[2022-04-07 02:05:34 large] (main.py 226): INFO Train: [113/300][1500/2502]	eta 0:10:27 lr 0.000345	time 0.6565 (0.6264)	loss 3.2090 (3.4891)	grad_norm 2.7797 (nan)	mem 8931MB
[2022-04-07 02:06:37 large] (main.py 226): INFO Train: [113/300][1600/2502]	eta 0:09:25 lr 0.000344	time 0.7722 (0.6268)	loss 3.3393 (3.4887)	grad_norm 4.6843 (nan)	mem 8931MB
[2022-04-07 02:07:39 large] (main.py 226): INFO Train: [113/300][1700/2502]	eta 0:08:22 lr 0.000344	time 0.5606 (0.6263)	loss 3.5527 (3.4868)	grad_norm 2.4276 (nan)	mem 8931MB
[2022-04-07 02:08:41 large] (main.py 226): INFO Train: [113/300][1800/2502]	eta 0:07:19 lr 0.000344	time 0.5876 (0.6262)	loss 3.0686 (3.4841)	grad_norm 3.0194 (nan)	mem 8931MB
[2022-04-07 02:09:44 large] (main.py 226): INFO Train: [113/300][1900/2502]	eta 0:06:17 lr 0.000344	time 0.6860 (0.6264)	loss 3.9395 (3.4862)	grad_norm 3.9049 (nan)	mem 8931MB
[2022-04-07 02:10:46 large] (main.py 226): INFO Train: [113/300][2000/2502]	eta 0:05:14 lr 0.000344	time 0.4967 (0.6261)	loss 3.7734 (3.4845)	grad_norm 3.4784 (nan)	mem 8931MB
[2022-04-07 02:11:49 large] (main.py 226): INFO Train: [113/300][2100/2502]	eta 0:04:11 lr 0.000344	time 0.6125 (0.6263)	loss 2.7117 (3.4870)	grad_norm 3.2869 (nan)	mem 8931MB
[2022-04-07 02:12:51 large] (main.py 226): INFO Train: [113/300][2200/2502]	eta 0:03:09 lr 0.000344	time 0.6004 (0.6258)	loss 3.2894 (3.4831)	grad_norm 2.6039 (nan)	mem 8931MB
[2022-04-07 02:13:53 large] (main.py 226): INFO Train: [113/300][2300/2502]	eta 0:02:06 lr 0.000344	time 0.6889 (0.6256)	loss 3.7435 (3.4841)	grad_norm 2.6842 (nan)	mem 8931MB
[2022-04-07 02:14:56 large] (main.py 226): INFO Train: [113/300][2400/2502]	eta 0:01:03 lr 0.000344	time 0.6407 (0.6260)	loss 3.9609 (3.4825)	grad_norm 3.2757 (nan)	mem 8931MB
[2022-04-07 02:15:58 large] (main.py 226): INFO Train: [113/300][2500/2502]	eta 0:00:01 lr 0.000344	time 0.6157 (0.6258)	loss 2.3766 (3.4807)	grad_norm 5.6914 (nan)	mem 8931MB
[2022-04-07 02:16:00 large] (main.py 233): INFO EPOCH 113 training takes 0:26:06
[2022-04-07 02:16:06 large] (main.py 273): INFO Test: [0/98]	Time 6.475 (6.475)	Loss 1.0910 (1.0910)	Acc@1 75.781 (75.781)	Acc@5 95.117 (95.117)	Mem 8931MB
[2022-04-07 02:16:32 large] (main.py 279): INFO  * Acc@1 75.708 Acc@5 93.050
[2022-04-07 02:16:32 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 75.7%
[2022-04-07 02:16:32 large] (utils.py 57): INFO output/large/default/ckpt_epoch_113.pth saving......
[2022-04-07 02:16:33 large] (utils.py 59): INFO output/large/default/ckpt_epoch_113.pth saved !!!
[2022-04-07 02:16:33 large] (main.py 148): INFO Max accuracy: 75.71%
[2022-04-07 02:16:41 large] (main.py 226): INFO Train: [114/300][0/2502]	eta 5:40:45 lr 0.000344	time 8.1718 (8.1718)	loss 4.3398 (4.3398)	grad_norm 3.1354 (3.1354)	mem 8931MB
[2022-04-07 02:17:31 large] (main.py 226): INFO Train: [114/300][100/2502]	eta 0:22:54 lr 0.000344	time 0.5047 (0.5722)	loss 3.8736 (3.5470)	grad_norm 3.4451 (3.0479)	mem 8931MB
[2022-04-07 02:18:31 large] (main.py 226): INFO Train: [114/300][200/2502]	eta 0:22:32 lr 0.000343	time 0.6434 (0.5874)	loss 2.5268 (3.4692)	grad_norm 2.2352 (3.0470)	mem 8931MB
[2022-04-07 02:19:34 large] (main.py 226): INFO Train: [114/300][300/2502]	eta 0:22:03 lr 0.000343	time 0.6012 (0.6011)	loss 4.1440 (3.5046)	grad_norm 3.5548 (3.0973)	mem 8931MB
[2022-04-07 02:20:37 large] (main.py 226): INFO Train: [114/300][400/2502]	eta 0:21:22 lr 0.000343	time 0.7075 (0.6101)	loss 4.2621 (3.4938)	grad_norm 3.4013 (3.1037)	mem 8931MB
[2022-04-07 02:21:41 large] (main.py 226): INFO Train: [114/300][500/2502]	eta 0:20:32 lr 0.000343	time 0.6255 (0.6157)	loss 3.4642 (3.4939)	grad_norm 2.6348 (3.1374)	mem 8931MB
[2022-04-07 02:22:44 large] (main.py 226): INFO Train: [114/300][600/2502]	eta 0:19:33 lr 0.000343	time 0.6720 (0.6169)	loss 4.1001 (3.4937)	grad_norm 3.0049 (3.1404)	mem 8931MB
[2022-04-07 02:23:46 large] (main.py 226): INFO Train: [114/300][700/2502]	eta 0:18:33 lr 0.000343	time 0.6621 (0.6181)	loss 3.6529 (3.5021)	grad_norm 2.8389 (3.1294)	mem 8931MB
[2022-04-07 02:24:49 large] (main.py 226): INFO Train: [114/300][800/2502]	eta 0:17:35 lr 0.000343	time 0.6319 (0.6200)	loss 3.9740 (3.4891)	grad_norm 3.1785 (3.1448)	mem 8931MB
[2022-04-07 02:25:50 large] (main.py 226): INFO Train: [114/300][900/2502]	eta 0:16:31 lr 0.000343	time 0.5960 (0.6190)	loss 2.5455 (3.4894)	grad_norm 3.1967 (3.1458)	mem 8931MB
[2022-04-07 02:26:52 large] (main.py 226): INFO Train: [114/300][1000/2502]	eta 0:15:29 lr 0.000343	time 0.5661 (0.6190)	loss 2.3991 (3.4987)	grad_norm 3.1550 (3.1523)	mem 8931MB
[2022-04-07 02:27:56 large] (main.py 226): INFO Train: [114/300][1100/2502]	eta 0:14:29 lr 0.000343	time 0.7498 (0.6204)	loss 3.7981 (3.5036)	grad_norm 3.5810 (3.1546)	mem 8931MB
[2022-04-07 02:28:58 large] (main.py 226): INFO Train: [114/300][1200/2502]	eta 0:13:27 lr 0.000342	time 0.7147 (0.6203)	loss 4.0132 (3.5015)	grad_norm 2.1745 (3.1610)	mem 8931MB
[2022-04-07 02:30:00 large] (main.py 226): INFO Train: [114/300][1300/2502]	eta 0:12:25 lr 0.000342	time 0.6002 (0.6203)	loss 2.6731 (3.4945)	grad_norm 4.2494 (3.1476)	mem 8931MB
[2022-04-07 02:31:03 large] (main.py 226): INFO Train: [114/300][1400/2502]	eta 0:11:24 lr 0.000342	time 0.5703 (0.6209)	loss 2.9853 (3.4883)	grad_norm 2.9798 (3.1494)	mem 8931MB
[2022-04-07 02:32:05 large] (main.py 226): INFO Train: [114/300][1500/2502]	eta 0:10:22 lr 0.000342	time 0.5086 (0.6213)	loss 3.6755 (3.4913)	grad_norm 2.9061 (3.1437)	mem 8931MB
[2022-04-07 02:33:07 large] (main.py 226): INFO Train: [114/300][1600/2502]	eta 0:09:20 lr 0.000342	time 0.5718 (0.6212)	loss 3.5319 (3.4914)	grad_norm 2.8498 (3.1413)	mem 8931MB
[2022-04-07 02:34:09 large] (main.py 226): INFO Train: [114/300][1700/2502]	eta 0:08:18 lr 0.000342	time 0.6283 (0.6210)	loss 3.4008 (3.4830)	grad_norm 2.5239 (3.1417)	mem 8931MB
[2022-04-07 02:35:11 large] (main.py 226): INFO Train: [114/300][1800/2502]	eta 0:07:16 lr 0.000342	time 0.5821 (0.6211)	loss 4.4527 (3.4882)	grad_norm 3.6474 (3.1471)	mem 8931MB
[2022-04-07 02:36:14 large] (main.py 226): INFO Train: [114/300][1900/2502]	eta 0:06:14 lr 0.000342	time 0.6342 (0.6216)	loss 3.4940 (3.4875)	grad_norm 2.8260 (3.1413)	mem 8931MB
[2022-04-07 02:37:17 large] (main.py 226): INFO Train: [114/300][2000/2502]	eta 0:05:12 lr 0.000342	time 0.6199 (0.6218)	loss 3.9003 (3.4853)	grad_norm 2.9275 (3.1409)	mem 8931MB
[2022-04-07 02:38:19 large] (main.py 226): INFO Train: [114/300][2100/2502]	eta 0:04:09 lr 0.000342	time 0.6390 (0.6216)	loss 3.4623 (3.4779)	grad_norm 2.7907 (3.1375)	mem 8931MB
[2022-04-07 02:39:21 large] (main.py 226): INFO Train: [114/300][2200/2502]	eta 0:03:07 lr 0.000341	time 0.6070 (0.6215)	loss 3.7072 (3.4760)	grad_norm 3.1678 (3.1350)	mem 8931MB
[2022-04-07 02:40:21 large] (main.py 226): INFO Train: [114/300][2300/2502]	eta 0:02:05 lr 0.000341	time 0.7576 (0.6205)	loss 3.2104 (3.4772)	grad_norm 3.9228 (3.1380)	mem 8931MB
[2022-04-07 02:41:23 large] (main.py 226): INFO Train: [114/300][2400/2502]	eta 0:01:03 lr 0.000341	time 0.6077 (0.6208)	loss 4.0679 (3.4806)	grad_norm 4.5803 (3.1446)	mem 8931MB
[2022-04-07 02:42:25 large] (main.py 226): INFO Train: [114/300][2500/2502]	eta 0:00:01 lr 0.000341	time 0.6170 (0.6205)	loss 2.7275 (3.4835)	grad_norm 3.7734 (3.1496)	mem 8931MB
[2022-04-07 02:42:26 large] (main.py 233): INFO EPOCH 114 training takes 0:25:53
[2022-04-07 02:42:31 large] (main.py 273): INFO Test: [0/98]	Time 5.612 (5.612)	Loss 1.1371 (1.1371)	Acc@1 75.977 (75.977)	Acc@5 92.578 (92.578)	Mem 8931MB
[2022-04-07 02:42:58 large] (main.py 279): INFO  * Acc@1 75.696 Acc@5 92.904
[2022-04-07 02:42:58 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 75.7%
[2022-04-07 02:42:58 large] (main.py 148): INFO Max accuracy: 75.71%
[2022-04-07 02:43:05 large] (main.py 226): INFO Train: [115/300][0/2502]	eta 4:51:05 lr 0.000341	time 6.9808 (6.9808)	loss 3.8112 (3.8112)	grad_norm 3.2870 (3.2870)	mem 8931MB
[2022-04-07 02:43:56 large] (main.py 226): INFO Train: [115/300][100/2502]	eta 0:23:07 lr 0.000341	time 0.5988 (0.5778)	loss 2.7087 (3.3936)	grad_norm 3.2943 (3.1319)	mem 8931MB
[2022-04-07 02:44:59 large] (main.py 226): INFO Train: [115/300][200/2502]	eta 0:23:02 lr 0.000341	time 0.7846 (0.6007)	loss 4.0229 (3.4163)	grad_norm 3.4063 (3.1506)	mem 8931MB
[2022-04-07 02:46:02 large] (main.py 226): INFO Train: [115/300][300/2502]	eta 0:22:27 lr 0.000341	time 0.7560 (0.6118)	loss 3.6945 (3.3987)	grad_norm 3.1723 (3.1468)	mem 8931MB
[2022-04-07 02:47:05 large] (main.py 226): INFO Train: [115/300][400/2502]	eta 0:21:36 lr 0.000341	time 0.6532 (0.6168)	loss 3.7510 (3.4001)	grad_norm 2.6449 (3.1217)	mem 8931MB
[2022-04-07 02:48:08 large] (main.py 226): INFO Train: [115/300][500/2502]	eta 0:20:40 lr 0.000341	time 0.5915 (0.6195)	loss 4.2670 (3.4110)	grad_norm 3.4424 (nan)	mem 8931MB
[2022-04-07 02:49:11 large] (main.py 226): INFO Train: [115/300][600/2502]	eta 0:19:40 lr 0.000341	time 0.5204 (0.6208)	loss 3.4918 (3.4305)	grad_norm 2.9031 (nan)	mem 8931MB
[2022-04-07 02:50:13 large] (main.py 226): INFO Train: [115/300][700/2502]	eta 0:18:39 lr 0.000341	time 0.6209 (0.6213)	loss 3.8763 (3.4231)	grad_norm 3.0693 (nan)	mem 8931MB
[2022-04-07 02:51:15 large] (main.py 226): INFO Train: [115/300][800/2502]	eta 0:17:36 lr 0.000340	time 0.7623 (0.6206)	loss 3.0337 (3.4271)	grad_norm 2.4716 (nan)	mem 8931MB
[2022-04-07 02:52:17 large] (main.py 226): INFO Train: [115/300][900/2502]	eta 0:16:34 lr 0.000340	time 0.6995 (0.6210)	loss 3.9647 (3.4202)	grad_norm 2.7772 (nan)	mem 8931MB
[2022-04-07 02:53:21 large] (main.py 226): INFO Train: [115/300][1000/2502]	eta 0:15:34 lr 0.000340	time 0.6077 (0.6221)	loss 3.7662 (3.4303)	grad_norm 2.3780 (nan)	mem 8931MB
[2022-04-07 02:54:23 large] (main.py 226): INFO Train: [115/300][1100/2502]	eta 0:14:31 lr 0.000340	time 0.5063 (0.6219)	loss 3.6890 (3.4338)	grad_norm 2.7856 (nan)	mem 8931MB
[2022-04-07 02:55:24 large] (main.py 226): INFO Train: [115/300][1200/2502]	eta 0:13:29 lr 0.000340	time 0.6574 (0.6217)	loss 4.1069 (3.4355)	grad_norm 3.3170 (nan)	mem 8931MB
[2022-04-07 02:56:27 large] (main.py 226): INFO Train: [115/300][1300/2502]	eta 0:12:27 lr 0.000340	time 0.6565 (0.6217)	loss 3.7087 (3.4411)	grad_norm 3.2684 (nan)	mem 8931MB
[2022-04-07 02:57:29 large] (main.py 226): INFO Train: [115/300][1400/2502]	eta 0:11:25 lr 0.000340	time 0.5800 (0.6221)	loss 3.5357 (3.4500)	grad_norm 2.2732 (nan)	mem 8931MB
[2022-04-07 02:58:32 large] (main.py 226): INFO Train: [115/300][1500/2502]	eta 0:10:23 lr 0.000340	time 0.5701 (0.6222)	loss 3.3082 (3.4531)	grad_norm 2.9606 (nan)	mem 8931MB
[2022-04-07 02:59:34 large] (main.py 226): INFO Train: [115/300][1600/2502]	eta 0:09:21 lr 0.000340	time 0.6134 (0.6223)	loss 3.2706 (3.4505)	grad_norm 3.5947 (nan)	mem 8931MB
[2022-04-07 03:00:37 large] (main.py 226): INFO Train: [115/300][1700/2502]	eta 0:08:19 lr 0.000340	time 0.5134 (0.6224)	loss 3.3524 (3.4546)	grad_norm 3.1083 (nan)	mem 8931MB
[2022-04-07 03:01:39 large] (main.py 226): INFO Train: [115/300][1800/2502]	eta 0:07:17 lr 0.000339	time 0.6269 (0.6225)	loss 2.8976 (3.4588)	grad_norm 2.8533 (nan)	mem 8931MB
[2022-04-07 03:02:42 large] (main.py 226): INFO Train: [115/300][1900/2502]	eta 0:06:14 lr 0.000339	time 0.6225 (0.6227)	loss 3.8009 (3.4588)	grad_norm 2.7105 (nan)	mem 8931MB
[2022-04-07 03:03:42 large] (main.py 226): INFO Train: [115/300][2000/2502]	eta 0:05:12 lr 0.000339	time 0.5794 (0.6220)	loss 3.9290 (3.4600)	grad_norm 2.4696 (nan)	mem 8931MB
[2022-04-07 03:04:45 large] (main.py 226): INFO Train: [115/300][2100/2502]	eta 0:04:10 lr 0.000339	time 0.5823 (0.6223)	loss 3.1549 (3.4620)	grad_norm 3.4999 (nan)	mem 8931MB
[2022-04-07 03:05:48 large] (main.py 226): INFO Train: [115/300][2200/2502]	eta 0:03:07 lr 0.000339	time 0.7188 (0.6223)	loss 4.0935 (3.4595)	grad_norm 3.6015 (nan)	mem 8931MB
[2022-04-07 03:06:51 large] (main.py 226): INFO Train: [115/300][2300/2502]	eta 0:02:05 lr 0.000339	time 0.8024 (0.6227)	loss 3.5414 (3.4564)	grad_norm 3.3033 (nan)	mem 8931MB
[2022-04-07 03:07:54 large] (main.py 226): INFO Train: [115/300][2400/2502]	eta 0:01:03 lr 0.000339	time 0.5664 (0.6229)	loss 3.7201 (3.4570)	grad_norm 3.2385 (nan)	mem 8931MB
[2022-04-07 03:08:56 large] (main.py 226): INFO Train: [115/300][2500/2502]	eta 0:00:01 lr 0.000339	time 0.5522 (0.6228)	loss 3.9612 (3.4597)	grad_norm 2.6975 (nan)	mem 8931MB
[2022-04-07 03:08:57 large] (main.py 233): INFO EPOCH 115 training takes 0:25:58
[2022-04-07 03:09:02 large] (main.py 273): INFO Test: [0/98]	Time 5.603 (5.603)	Loss 1.1701 (1.1701)	Acc@1 78.125 (78.125)	Acc@5 92.969 (92.969)	Mem 8931MB
[2022-04-07 03:09:30 large] (main.py 279): INFO  * Acc@1 75.742 Acc@5 92.910
[2022-04-07 03:09:30 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 75.7%
[2022-04-07 03:09:30 large] (utils.py 57): INFO output/large/default/ckpt_epoch_115.pth saving......
[2022-04-07 03:09:30 large] (utils.py 59): INFO output/large/default/ckpt_epoch_115.pth saved !!!
[2022-04-07 03:09:30 large] (main.py 148): INFO Max accuracy: 75.74%
[2022-04-07 03:09:38 large] (main.py 226): INFO Train: [116/300][0/2502]	eta 5:31:12 lr 0.000339	time 7.9425 (7.9425)	loss 3.2254 (3.2254)	grad_norm 2.8987 (2.8987)	mem 8931MB
[2022-04-07 03:10:30 large] (main.py 226): INFO Train: [116/300][100/2502]	eta 0:23:35 lr 0.000339	time 0.5942 (0.5894)	loss 3.4704 (3.5127)	grad_norm 2.9745 (3.0548)	mem 8931MB
[2022-04-07 03:11:33 large] (main.py 226): INFO Train: [116/300][200/2502]	eta 0:23:20 lr 0.000339	time 0.5978 (0.6086)	loss 4.0522 (3.4645)	grad_norm 3.8410 (3.0664)	mem 8931MB
[2022-04-07 03:12:36 large] (main.py 226): INFO Train: [116/300][300/2502]	eta 0:22:40 lr 0.000338	time 0.6520 (0.6179)	loss 2.0696 (3.4603)	grad_norm 2.6587 (nan)	mem 8931MB
[2022-04-07 03:13:40 large] (main.py 226): INFO Train: [116/300][400/2502]	eta 0:21:47 lr 0.000338	time 0.6435 (0.6223)	loss 3.2854 (3.4540)	grad_norm 2.9154 (nan)	mem 8931MB
[2022-04-07 03:14:43 large] (main.py 226): INFO Train: [116/300][500/2502]	eta 0:20:49 lr 0.000338	time 0.6641 (0.6241)	loss 3.3837 (3.4561)	grad_norm 2.6559 (nan)	mem 8931MB
[2022-04-07 03:15:46 large] (main.py 226): INFO Train: [116/300][600/2502]	eta 0:19:48 lr 0.000338	time 0.6280 (0.6249)	loss 3.6797 (3.4573)	grad_norm 2.6856 (nan)	mem 8931MB
[2022-04-07 03:16:48 large] (main.py 226): INFO Train: [116/300][700/2502]	eta 0:18:45 lr 0.000338	time 0.6230 (0.6244)	loss 3.8131 (3.4671)	grad_norm 3.2862 (nan)	mem 8931MB
[2022-04-07 03:17:49 large] (main.py 226): INFO Train: [116/300][800/2502]	eta 0:17:40 lr 0.000338	time 0.6247 (0.6230)	loss 3.6966 (3.4584)	grad_norm 3.3462 (nan)	mem 8931MB
[2022-04-07 03:18:52 large] (main.py 226): INFO Train: [116/300][900/2502]	eta 0:16:38 lr 0.000338	time 0.7108 (0.6232)	loss 2.5478 (3.4474)	grad_norm 2.8148 (nan)	mem 8931MB
[2022-04-07 03:19:53 large] (main.py 226): INFO Train: [116/300][1000/2502]	eta 0:15:34 lr 0.000338	time 0.5217 (0.6223)	loss 4.0626 (3.4551)	grad_norm 3.4151 (nan)	mem 8931MB
[2022-04-07 03:20:56 large] (main.py 226): INFO Train: [116/300][1100/2502]	eta 0:14:32 lr 0.000338	time 0.6230 (0.6225)	loss 3.1796 (3.4530)	grad_norm 3.0844 (nan)	mem 8931MB
[2022-04-07 03:21:58 large] (main.py 226): INFO Train: [116/300][1200/2502]	eta 0:13:30 lr 0.000338	time 0.5848 (0.6225)	loss 4.0222 (3.4521)	grad_norm 2.7022 (nan)	mem 8931MB
[2022-04-07 03:23:00 large] (main.py 226): INFO Train: [116/300][1300/2502]	eta 0:12:28 lr 0.000338	time 0.6772 (0.6223)	loss 3.6940 (3.4627)	grad_norm 2.4811 (nan)	mem 8931MB
[2022-04-07 03:24:02 large] (main.py 226): INFO Train: [116/300][1400/2502]	eta 0:11:25 lr 0.000337	time 0.5405 (0.6219)	loss 3.4412 (3.4708)	grad_norm 3.2784 (nan)	mem 8931MB
[2022-04-07 03:25:03 large] (main.py 226): INFO Train: [116/300][1500/2502]	eta 0:10:22 lr 0.000337	time 0.6252 (0.6214)	loss 3.5683 (3.4744)	grad_norm 3.7941 (nan)	mem 8931MB
[2022-04-07 03:26:05 large] (main.py 226): INFO Train: [116/300][1600/2502]	eta 0:09:20 lr 0.000337	time 0.6602 (0.6211)	loss 3.4147 (3.4732)	grad_norm 3.0339 (nan)	mem 8931MB
[2022-04-07 03:27:07 large] (main.py 226): INFO Train: [116/300][1700/2502]	eta 0:08:18 lr 0.000337	time 0.5925 (0.6212)	loss 3.4248 (3.4799)	grad_norm 3.0775 (nan)	mem 8931MB
[2022-04-07 03:28:08 large] (main.py 226): INFO Train: [116/300][1800/2502]	eta 0:07:15 lr 0.000337	time 0.6459 (0.6206)	loss 2.4939 (3.4845)	grad_norm 2.4329 (nan)	mem 8931MB
[2022-04-07 03:29:09 large] (main.py 226): INFO Train: [116/300][1900/2502]	eta 0:06:13 lr 0.000337	time 0.6643 (0.6199)	loss 4.3956 (3.4802)	grad_norm 3.3466 (nan)	mem 8931MB
[2022-04-07 03:30:10 large] (main.py 226): INFO Train: [116/300][2000/2502]	eta 0:05:10 lr 0.000337	time 0.6212 (0.6195)	loss 3.0387 (3.4817)	grad_norm 2.6934 (nan)	mem 8931MB
[2022-04-07 03:31:12 large] (main.py 226): INFO Train: [116/300][2100/2502]	eta 0:04:09 lr 0.000337	time 0.6346 (0.6195)	loss 4.1548 (3.4794)	grad_norm 3.8366 (nan)	mem 8931MB
[2022-04-07 03:32:14 large] (main.py 226): INFO Train: [116/300][2200/2502]	eta 0:03:07 lr 0.000337	time 0.6044 (0.6194)	loss 3.7497 (3.4793)	grad_norm 2.7894 (nan)	mem 8931MB
[2022-04-07 03:33:15 large] (main.py 226): INFO Train: [116/300][2300/2502]	eta 0:02:05 lr 0.000337	time 0.6347 (0.6191)	loss 3.7587 (3.4837)	grad_norm 3.0987 (nan)	mem 8931MB
[2022-04-07 03:34:16 large] (main.py 226): INFO Train: [116/300][2400/2502]	eta 0:01:03 lr 0.000336	time 0.5327 (0.6188)	loss 3.6709 (3.4862)	grad_norm 3.1788 (nan)	mem 8931MB
[2022-04-07 03:35:18 large] (main.py 226): INFO Train: [116/300][2500/2502]	eta 0:00:01 lr 0.000336	time 0.6135 (0.6188)	loss 3.6326 (3.4889)	grad_norm 4.7272 (nan)	mem 8931MB
[2022-04-07 03:35:19 large] (main.py 233): INFO EPOCH 116 training takes 0:25:48
[2022-04-07 03:35:25 large] (main.py 273): INFO Test: [0/98]	Time 5.770 (5.770)	Loss 1.1189 (1.1189)	Acc@1 76.953 (76.953)	Acc@5 93.555 (93.555)	Mem 8931MB
[2022-04-07 03:35:51 large] (main.py 279): INFO  * Acc@1 75.844 Acc@5 93.142
[2022-04-07 03:35:51 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 75.8%
[2022-04-07 03:35:51 large] (utils.py 57): INFO output/large/default/ckpt_epoch_116.pth saving......
[2022-04-07 03:35:52 large] (utils.py 59): INFO output/large/default/ckpt_epoch_116.pth saved !!!
[2022-04-07 03:35:52 large] (main.py 148): INFO Max accuracy: 75.84%
[2022-04-07 03:36:00 large] (main.py 226): INFO Train: [117/300][0/2502]	eta 5:33:58 lr 0.000336	time 8.0090 (8.0090)	loss 3.8564 (3.8564)	grad_norm 2.5162 (2.5162)	mem 8931MB
[2022-04-07 03:36:48 large] (main.py 226): INFO Train: [117/300][100/2502]	eta 0:22:22 lr 0.000336	time 0.4765 (0.5589)	loss 3.9679 (3.5762)	grad_norm 2.9921 (3.2511)	mem 8931MB
[2022-04-07 03:37:38 large] (main.py 226): INFO Train: [117/300][200/2502]	eta 0:20:09 lr 0.000336	time 0.5990 (0.5255)	loss 2.8566 (3.5014)	grad_norm 2.5488 (3.2683)	mem 8931MB
[2022-04-07 03:38:40 large] (main.py 226): INFO Train: [117/300][300/2502]	eta 0:20:31 lr 0.000336	time 0.6911 (0.5592)	loss 3.7206 (3.4718)	grad_norm 2.2286 (3.2550)	mem 8931MB
[2022-04-07 03:39:45 large] (main.py 226): INFO Train: [117/300][400/2502]	eta 0:20:23 lr 0.000336	time 0.6601 (0.5821)	loss 2.7544 (3.4772)	grad_norm 2.9863 (3.2368)	mem 8931MB
[2022-04-07 03:40:49 large] (main.py 226): INFO Train: [117/300][500/2502]	eta 0:19:48 lr 0.000336	time 0.6058 (0.5937)	loss 4.0240 (3.4635)	grad_norm 3.0821 (3.2448)	mem 8931MB
[2022-04-07 03:41:54 large] (main.py 226): INFO Train: [117/300][600/2502]	eta 0:19:05 lr 0.000336	time 0.5163 (0.6022)	loss 4.1668 (3.4665)	grad_norm 2.8539 (3.2054)	mem 8931MB
[2022-04-07 03:42:57 large] (main.py 226): INFO Train: [117/300][700/2502]	eta 0:18:13 lr 0.000336	time 0.6204 (0.6066)	loss 3.7429 (3.4656)	grad_norm 4.1183 (3.2160)	mem 8931MB
[2022-04-07 03:44:00 large] (main.py 226): INFO Train: [117/300][800/2502]	eta 0:17:15 lr 0.000336	time 0.7204 (0.6086)	loss 2.7243 (3.4705)	grad_norm 3.3292 (3.2306)	mem 8931MB
[2022-04-07 03:45:01 large] (main.py 226): INFO Train: [117/300][900/2502]	eta 0:16:15 lr 0.000335	time 0.5867 (0.6092)	loss 3.6554 (3.4737)	grad_norm 3.0818 (3.2099)	mem 8931MB
[2022-04-07 03:46:03 large] (main.py 226): INFO Train: [117/300][1000/2502]	eta 0:15:16 lr 0.000335	time 0.6408 (0.6104)	loss 3.6602 (3.4726)	grad_norm 2.6982 (3.2047)	mem 8931MB
[2022-04-07 03:47:05 large] (main.py 226): INFO Train: [117/300][1100/2502]	eta 0:14:17 lr 0.000335	time 0.5844 (0.6113)	loss 4.0170 (3.4748)	grad_norm 3.1551 (3.2175)	mem 8931MB
[2022-04-07 03:48:08 large] (main.py 226): INFO Train: [117/300][1200/2502]	eta 0:13:17 lr 0.000335	time 0.6207 (0.6126)	loss 3.9306 (3.4712)	grad_norm 3.3085 (3.2180)	mem 8931MB
[2022-04-07 03:49:10 large] (main.py 226): INFO Train: [117/300][1300/2502]	eta 0:12:17 lr 0.000335	time 0.6320 (0.6133)	loss 3.9969 (3.4706)	grad_norm 3.1014 (3.2171)	mem 8931MB
[2022-04-07 03:50:13 large] (main.py 226): INFO Train: [117/300][1400/2502]	eta 0:11:17 lr 0.000335	time 0.6513 (0.6145)	loss 2.6071 (3.4665)	grad_norm 2.9779 (3.2122)	mem 8931MB
[2022-04-07 03:51:16 large] (main.py 226): INFO Train: [117/300][1500/2502]	eta 0:10:16 lr 0.000335	time 0.5713 (0.6155)	loss 3.6281 (3.4694)	grad_norm 3.5447 (3.2102)	mem 8931MB
[2022-04-07 03:52:19 large] (main.py 226): INFO Train: [117/300][1600/2502]	eta 0:09:15 lr 0.000335	time 0.6468 (0.6163)	loss 3.4544 (3.4737)	grad_norm 2.6612 (3.2094)	mem 8931MB
[2022-04-07 03:53:21 large] (main.py 226): INFO Train: [117/300][1700/2502]	eta 0:08:14 lr 0.000335	time 0.6606 (0.6166)	loss 2.7333 (3.4696)	grad_norm 2.9052 (nan)	mem 8931MB
[2022-04-07 03:54:24 large] (main.py 226): INFO Train: [117/300][1800/2502]	eta 0:07:13 lr 0.000335	time 0.6702 (0.6172)	loss 4.0211 (3.4715)	grad_norm 3.4263 (nan)	mem 8931MB
[2022-04-07 03:55:26 large] (main.py 226): INFO Train: [117/300][1900/2502]	eta 0:06:11 lr 0.000334	time 0.5262 (0.6176)	loss 2.9373 (3.4741)	grad_norm 2.6870 (nan)	mem 8931MB
[2022-04-07 03:56:28 large] (main.py 226): INFO Train: [117/300][2000/2502]	eta 0:05:10 lr 0.000334	time 0.5859 (0.6179)	loss 2.7651 (3.4701)	grad_norm 2.7937 (nan)	mem 8931MB
[2022-04-07 03:57:31 large] (main.py 226): INFO Train: [117/300][2100/2502]	eta 0:04:08 lr 0.000334	time 0.6416 (0.6181)	loss 3.5571 (3.4715)	grad_norm 2.9603 (nan)	mem 8931MB
[2022-04-07 03:58:26 large] (main.py 226): INFO Train: [117/300][2200/2502]	eta 0:03:05 lr 0.000334	time 0.6202 (0.6152)	loss 3.7145 (3.4695)	grad_norm 3.7814 (nan)	mem 8931MB
[2022-04-07 03:59:27 large] (main.py 226): INFO Train: [117/300][2300/2502]	eta 0:02:04 lr 0.000334	time 0.6154 (0.6151)	loss 4.0392 (3.4743)	grad_norm 2.8004 (nan)	mem 8931MB
[2022-04-07 04:00:30 large] (main.py 226): INFO Train: [117/300][2400/2502]	eta 0:01:02 lr 0.000334	time 0.6236 (0.6154)	loss 4.0395 (3.4734)	grad_norm 3.4487 (nan)	mem 8931MB
[2022-04-07 04:01:31 large] (main.py 226): INFO Train: [117/300][2500/2502]	eta 0:00:01 lr 0.000334	time 0.5739 (0.6154)	loss 3.3841 (3.4691)	grad_norm 2.8220 (nan)	mem 8931MB
[2022-04-07 04:01:32 large] (main.py 233): INFO EPOCH 117 training takes 0:25:40
[2022-04-07 04:01:39 large] (main.py 273): INFO Test: [0/98]	Time 6.304 (6.304)	Loss 1.2799 (1.2799)	Acc@1 74.023 (74.023)	Acc@5 91.406 (91.406)	Mem 8931MB
[2022-04-07 04:02:04 large] (main.py 279): INFO  * Acc@1 75.928 Acc@5 93.180
[2022-04-07 04:02:04 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 75.9%
[2022-04-07 04:02:04 large] (utils.py 57): INFO output/large/default/ckpt_epoch_117.pth saving......
[2022-04-07 04:02:05 large] (utils.py 59): INFO output/large/default/ckpt_epoch_117.pth saved !!!
[2022-04-07 04:02:05 large] (main.py 148): INFO Max accuracy: 75.93%
[2022-04-07 04:02:13 large] (main.py 226): INFO Train: [118/300][0/2502]	eta 5:53:28 lr 0.000334	time 8.4766 (8.4766)	loss 4.2705 (4.2705)	grad_norm 4.8262 (4.8262)	mem 8931MB
[2022-04-07 04:03:08 large] (main.py 226): INFO Train: [118/300][100/2502]	eta 0:24:49 lr 0.000334	time 0.7687 (0.6202)	loss 3.2835 (3.5100)	grad_norm 3.8212 (3.3361)	mem 8931MB
[2022-04-07 04:04:11 large] (main.py 226): INFO Train: [118/300][200/2502]	eta 0:24:06 lr 0.000334	time 0.5759 (0.6284)	loss 3.9029 (3.4676)	grad_norm 4.1419 (3.3125)	mem 8931MB
[2022-04-07 04:05:14 large] (main.py 226): INFO Train: [118/300][300/2502]	eta 0:23:02 lr 0.000334	time 0.6082 (0.6280)	loss 3.7299 (3.4407)	grad_norm 3.0353 (3.2736)	mem 8931MB
[2022-04-07 04:06:17 large] (main.py 226): INFO Train: [118/300][400/2502]	eta 0:21:59 lr 0.000334	time 0.7292 (0.6277)	loss 3.6053 (3.4379)	grad_norm 3.2614 (3.2161)	mem 8931MB
[2022-04-07 04:07:19 large] (main.py 226): INFO Train: [118/300][500/2502]	eta 0:20:55 lr 0.000333	time 0.6750 (0.6272)	loss 2.9068 (3.4426)	grad_norm 4.9416 (3.2405)	mem 8931MB
[2022-04-07 04:08:22 large] (main.py 226): INFO Train: [118/300][600/2502]	eta 0:19:53 lr 0.000333	time 1.3210 (0.6274)	loss 3.9852 (3.4386)	grad_norm 3.3887 (3.2256)	mem 8931MB
[2022-04-07 04:09:24 large] (main.py 226): INFO Train: [118/300][700/2502]	eta 0:18:48 lr 0.000333	time 0.5615 (0.6262)	loss 3.7146 (3.4349)	grad_norm 3.4748 (3.2255)	mem 8931MB
[2022-04-07 04:10:26 large] (main.py 226): INFO Train: [118/300][800/2502]	eta 0:17:44 lr 0.000333	time 0.6255 (0.6254)	loss 3.4793 (3.4387)	grad_norm 2.6781 (3.2054)	mem 8931MB
[2022-04-07 04:11:28 large] (main.py 226): INFO Train: [118/300][900/2502]	eta 0:16:41 lr 0.000333	time 0.6614 (0.6250)	loss 2.9824 (3.4341)	grad_norm 3.3553 (3.2072)	mem 8931MB
[2022-04-07 04:12:30 large] (main.py 226): INFO Train: [118/300][1000/2502]	eta 0:15:37 lr 0.000333	time 0.5517 (0.6244)	loss 4.5173 (3.4377)	grad_norm 3.2424 (3.2078)	mem 8931MB
[2022-04-07 04:13:32 large] (main.py 226): INFO Train: [118/300][1100/2502]	eta 0:14:34 lr 0.000333	time 0.5902 (0.6238)	loss 3.1738 (3.4415)	grad_norm 3.4037 (3.2075)	mem 8931MB
[2022-04-07 04:14:33 large] (main.py 226): INFO Train: [118/300][1200/2502]	eta 0:13:30 lr 0.000333	time 0.5739 (0.6227)	loss 4.0740 (3.4462)	grad_norm 3.6282 (3.2082)	mem 8931MB
[2022-04-07 04:15:35 large] (main.py 226): INFO Train: [118/300][1300/2502]	eta 0:12:28 lr 0.000333	time 0.6409 (0.6227)	loss 3.4077 (3.4515)	grad_norm 3.1131 (3.2098)	mem 8931MB
[2022-04-07 04:16:37 large] (main.py 226): INFO Train: [118/300][1400/2502]	eta 0:11:26 lr 0.000333	time 0.6177 (0.6228)	loss 4.1289 (3.4412)	grad_norm 2.7583 (3.2036)	mem 8931MB
[2022-04-07 04:17:38 large] (main.py 226): INFO Train: [118/300][1500/2502]	eta 0:10:22 lr 0.000332	time 0.6513 (0.6217)	loss 3.6515 (3.4451)	grad_norm 4.1243 (3.2016)	mem 8931MB
[2022-04-07 04:18:39 large] (main.py 226): INFO Train: [118/300][1600/2502]	eta 0:09:20 lr 0.000332	time 0.5585 (0.6211)	loss 3.9106 (3.4455)	grad_norm 3.7163 (3.2013)	mem 8931MB
[2022-04-07 04:19:41 large] (main.py 226): INFO Train: [118/300][1700/2502]	eta 0:08:17 lr 0.000332	time 0.4976 (0.6206)	loss 3.4757 (3.4501)	grad_norm 3.2622 (3.2050)	mem 8931MB
[2022-04-07 04:20:43 large] (main.py 226): INFO Train: [118/300][1800/2502]	eta 0:07:15 lr 0.000332	time 0.5407 (0.6208)	loss 3.6660 (3.4495)	grad_norm 4.2762 (3.1971)	mem 8931MB
[2022-04-07 04:21:44 large] (main.py 226): INFO Train: [118/300][1900/2502]	eta 0:06:13 lr 0.000332	time 0.6348 (0.6204)	loss 4.0159 (3.4525)	grad_norm 4.0447 (3.1973)	mem 8931MB
[2022-04-07 04:22:45 large] (main.py 226): INFO Train: [118/300][2000/2502]	eta 0:05:11 lr 0.000332	time 0.6022 (0.6198)	loss 3.4597 (3.4500)	grad_norm 3.5057 (3.2005)	mem 8931MB
[2022-04-07 04:23:48 large] (main.py 226): INFO Train: [118/300][2100/2502]	eta 0:04:09 lr 0.000332	time 0.6918 (0.6201)	loss 4.0084 (3.4523)	grad_norm 2.9449 (3.2005)	mem 8931MB
[2022-04-07 04:24:49 large] (main.py 226): INFO Train: [118/300][2200/2502]	eta 0:03:07 lr 0.000332	time 0.6237 (0.6197)	loss 4.0187 (3.4547)	grad_norm 2.6824 (nan)	mem 8931MB
[2022-04-07 04:25:50 large] (main.py 226): INFO Train: [118/300][2300/2502]	eta 0:02:05 lr 0.000332	time 0.6043 (0.6195)	loss 3.5397 (3.4545)	grad_norm 2.8256 (nan)	mem 8931MB
[2022-04-07 04:26:52 large] (main.py 226): INFO Train: [118/300][2400/2502]	eta 0:01:03 lr 0.000332	time 0.6251 (0.6192)	loss 3.0574 (3.4534)	grad_norm 3.3367 (nan)	mem 8931MB
[2022-04-07 04:27:53 large] (main.py 226): INFO Train: [118/300][2500/2502]	eta 0:00:01 lr 0.000331	time 0.6066 (0.6189)	loss 3.5934 (3.4542)	grad_norm 3.0239 (nan)	mem 8931MB
[2022-04-07 04:27:54 large] (main.py 233): INFO EPOCH 118 training takes 0:25:48
[2022-04-07 04:28:00 large] (main.py 273): INFO Test: [0/98]	Time 6.127 (6.127)	Loss 1.1054 (1.1054)	Acc@1 77.344 (77.344)	Acc@5 93.359 (93.359)	Mem 8931MB
[2022-04-07 04:28:26 large] (main.py 279): INFO  * Acc@1 76.042 Acc@5 93.230
[2022-04-07 04:28:26 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 76.0%
[2022-04-07 04:28:26 large] (utils.py 57): INFO output/large/default/ckpt_epoch_118.pth saving......
[2022-04-07 04:28:27 large] (utils.py 59): INFO output/large/default/ckpt_epoch_118.pth saved !!!
[2022-04-07 04:28:27 large] (main.py 148): INFO Max accuracy: 76.04%
[2022-04-07 04:28:35 large] (main.py 226): INFO Train: [119/300][0/2502]	eta 5:38:09 lr 0.000331	time 8.1092 (8.1092)	loss 3.6815 (3.6815)	grad_norm 2.7198 (2.7198)	mem 8931MB
[2022-04-07 04:29:26 large] (main.py 226): INFO Train: [119/300][100/2502]	eta 0:23:29 lr 0.000331	time 0.5655 (0.5869)	loss 3.8651 (3.5184)	grad_norm 3.3554 (3.0147)	mem 8931MB
[2022-04-07 04:30:28 large] (main.py 226): INFO Train: [119/300][200/2502]	eta 0:23:03 lr 0.000331	time 0.7212 (0.6009)	loss 3.5842 (3.4746)	grad_norm 3.4961 (3.1571)	mem 8931MB
[2022-04-07 04:31:30 large] (main.py 226): INFO Train: [119/300][300/2502]	eta 0:22:18 lr 0.000331	time 0.6559 (0.6080)	loss 3.5508 (3.4752)	grad_norm 2.7866 (3.1864)	mem 8931MB
[2022-04-07 04:32:32 large] (main.py 226): INFO Train: [119/300][400/2502]	eta 0:21:24 lr 0.000331	time 0.6081 (0.6113)	loss 4.0565 (3.4909)	grad_norm 2.6666 (3.1691)	mem 8931MB
[2022-04-07 04:33:35 large] (main.py 226): INFO Train: [119/300][500/2502]	eta 0:20:29 lr 0.000331	time 0.5860 (0.6143)	loss 3.6664 (3.4580)	grad_norm 2.5119 (3.1706)	mem 8931MB
[2022-04-07 04:34:36 large] (main.py 226): INFO Train: [119/300][600/2502]	eta 0:19:27 lr 0.000331	time 0.5222 (0.6141)	loss 2.6260 (3.4597)	grad_norm 2.7640 (3.1791)	mem 8931MB
[2022-04-07 04:35:37 large] (main.py 226): INFO Train: [119/300][700/2502]	eta 0:18:25 lr 0.000331	time 0.5440 (0.6137)	loss 3.4337 (3.4504)	grad_norm 3.6093 (3.1643)	mem 8931MB
[2022-04-07 04:36:40 large] (main.py 226): INFO Train: [119/300][800/2502]	eta 0:17:26 lr 0.000331	time 0.6108 (0.6151)	loss 3.9719 (3.4589)	grad_norm 3.0570 (3.1643)	mem 8931MB
[2022-04-07 04:37:42 large] (main.py 226): INFO Train: [119/300][900/2502]	eta 0:16:25 lr 0.000331	time 0.4595 (0.6153)	loss 3.6948 (3.4576)	grad_norm 3.1344 (3.1710)	mem 8931MB
[2022-04-07 04:38:43 large] (main.py 226): INFO Train: [119/300][1000/2502]	eta 0:15:24 lr 0.000330	time 0.5124 (0.6152)	loss 3.5483 (3.4640)	grad_norm 3.1238 (3.1778)	mem 8931MB
[2022-04-07 04:39:45 large] (main.py 226): INFO Train: [119/300][1100/2502]	eta 0:14:23 lr 0.000330	time 0.6183 (0.6156)	loss 3.8554 (3.4644)	grad_norm 3.5719 (3.1739)	mem 8931MB
[2022-04-07 04:40:47 large] (main.py 226): INFO Train: [119/300][1200/2502]	eta 0:13:21 lr 0.000330	time 0.6060 (0.6159)	loss 3.5369 (3.4630)	grad_norm 3.6589 (3.1693)	mem 8931MB
[2022-04-07 04:41:49 large] (main.py 226): INFO Train: [119/300][1300/2502]	eta 0:12:20 lr 0.000330	time 0.6547 (0.6161)	loss 3.6478 (3.4574)	grad_norm 2.3309 (3.1725)	mem 8931MB
[2022-04-07 04:42:50 large] (main.py 226): INFO Train: [119/300][1400/2502]	eta 0:11:18 lr 0.000330	time 0.5587 (0.6155)	loss 4.1479 (3.4622)	grad_norm 3.2385 (3.1779)	mem 8931MB
[2022-04-07 04:43:51 large] (main.py 226): INFO Train: [119/300][1500/2502]	eta 0:10:16 lr 0.000330	time 0.6547 (0.6158)	loss 3.6622 (3.4690)	grad_norm 2.7919 (3.1831)	mem 8931MB
[2022-04-07 04:44:52 large] (main.py 226): INFO Train: [119/300][1600/2502]	eta 0:09:14 lr 0.000330	time 0.5526 (0.6152)	loss 3.4280 (3.4703)	grad_norm 2.9132 (3.1837)	mem 8931MB
[2022-04-07 04:45:54 large] (main.py 226): INFO Train: [119/300][1700/2502]	eta 0:08:13 lr 0.000330	time 0.5212 (0.6155)	loss 4.1174 (3.4723)	grad_norm 2.7285 (3.1834)	mem 8931MB
[2022-04-07 04:46:56 large] (main.py 226): INFO Train: [119/300][1800/2502]	eta 0:07:12 lr 0.000330	time 0.5993 (0.6154)	loss 2.9289 (3.4709)	grad_norm 3.2182 (3.1814)	mem 8931MB
[2022-04-07 04:47:57 large] (main.py 226): INFO Train: [119/300][1900/2502]	eta 0:06:10 lr 0.000330	time 0.6228 (0.6154)	loss 3.7510 (3.4730)	grad_norm 3.7384 (3.1892)	mem 8931MB
[2022-04-07 04:48:58 large] (main.py 226): INFO Train: [119/300][2000/2502]	eta 0:05:08 lr 0.000329	time 0.5065 (0.6149)	loss 3.9828 (3.4735)	grad_norm 2.9067 (3.1973)	mem 8931MB
[2022-04-07 04:49:59 large] (main.py 226): INFO Train: [119/300][2100/2502]	eta 0:04:07 lr 0.000329	time 0.6381 (0.6147)	loss 3.6950 (3.4746)	grad_norm 3.1711 (3.2006)	mem 8931MB
[2022-04-07 04:50:59 large] (main.py 226): INFO Train: [119/300][2200/2502]	eta 0:03:05 lr 0.000329	time 0.5985 (0.6144)	loss 3.4179 (3.4699)	grad_norm 2.6906 (3.1996)	mem 8931MB
[2022-04-07 04:52:01 large] (main.py 226): INFO Train: [119/300][2300/2502]	eta 0:02:04 lr 0.000329	time 0.5669 (0.6146)	loss 3.5207 (3.4663)	grad_norm 3.8106 (3.1969)	mem 8931MB
[2022-04-07 04:53:02 large] (main.py 226): INFO Train: [119/300][2400/2502]	eta 0:01:02 lr 0.000329	time 0.7276 (0.6143)	loss 3.8658 (3.4687)	grad_norm 3.5933 (3.1931)	mem 8931MB
[2022-04-07 04:54:03 large] (main.py 226): INFO Train: [119/300][2500/2502]	eta 0:00:01 lr 0.000329	time 0.5834 (0.6140)	loss 3.9628 (3.4692)	grad_norm 3.0675 (3.1973)	mem 8931MB
[2022-04-07 04:54:04 large] (main.py 233): INFO EPOCH 119 training takes 0:25:36
[2022-04-07 04:54:10 large] (main.py 273): INFO Test: [0/98]	Time 5.793 (5.793)	Loss 1.1592 (1.1592)	Acc@1 77.539 (77.539)	Acc@5 93.555 (93.555)	Mem 8931MB
[2022-04-07 04:54:36 large] (main.py 279): INFO  * Acc@1 75.936 Acc@5 93.216
[2022-04-07 04:54:36 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 75.9%
[2022-04-07 04:54:36 large] (main.py 148): INFO Max accuracy: 76.04%
[2022-04-07 04:54:43 large] (main.py 226): INFO Train: [120/300][0/2502]	eta 4:43:47 lr 0.000329	time 6.8057 (6.8057)	loss 2.9551 (2.9551)	grad_norm 3.3210 (3.3210)	mem 8931MB
[2022-04-07 04:55:35 large] (main.py 226): INFO Train: [120/300][100/2502]	eta 0:23:15 lr 0.000329	time 0.5871 (0.5811)	loss 3.9114 (3.4912)	grad_norm 3.6202 (3.2358)	mem 8931MB
[2022-04-07 04:56:36 large] (main.py 226): INFO Train: [120/300][200/2502]	eta 0:22:55 lr 0.000329	time 0.6035 (0.5974)	loss 3.9010 (3.4584)	grad_norm 2.5595 (3.2768)	mem 8931MB
[2022-04-07 04:57:39 large] (main.py 226): INFO Train: [120/300][300/2502]	eta 0:22:17 lr 0.000329	time 0.5410 (0.6074)	loss 3.2955 (3.4647)	grad_norm 2.4965 (3.2389)	mem 8931MB
[2022-04-07 04:58:41 large] (main.py 226): INFO Train: [120/300][400/2502]	eta 0:21:23 lr 0.000329	time 0.7190 (0.6108)	loss 3.8854 (3.4623)	grad_norm 3.3996 (3.2527)	mem 8931MB
[2022-04-07 04:59:43 large] (main.py 226): INFO Train: [120/300][500/2502]	eta 0:20:28 lr 0.000328	time 0.6381 (0.6134)	loss 2.9142 (3.4784)	grad_norm 2.8565 (3.2393)	mem 8931MB
[2022-04-07 05:00:44 large] (main.py 226): INFO Train: [120/300][600/2502]	eta 0:19:26 lr 0.000328	time 0.5856 (0.6132)	loss 3.2149 (3.4624)	grad_norm 3.8011 (3.2363)	mem 8931MB
[2022-04-07 05:01:46 large] (main.py 226): INFO Train: [120/300][700/2502]	eta 0:18:26 lr 0.000328	time 0.6455 (0.6142)	loss 2.6298 (3.4660)	grad_norm 3.0960 (3.2243)	mem 8931MB
[2022-04-07 05:02:48 large] (main.py 226): INFO Train: [120/300][800/2502]	eta 0:17:24 lr 0.000328	time 0.5394 (0.6139)	loss 2.6684 (3.4625)	grad_norm 2.7138 (3.2154)	mem 8931MB
[2022-04-07 05:03:49 large] (main.py 226): INFO Train: [120/300][900/2502]	eta 0:16:23 lr 0.000328	time 0.5775 (0.6138)	loss 4.1301 (3.4722)	grad_norm 3.8334 (3.2234)	mem 8931MB
[2022-04-07 05:04:50 large] (main.py 226): INFO Train: [120/300][1000/2502]	eta 0:15:21 lr 0.000328	time 0.6463 (0.6138)	loss 3.8427 (3.4704)	grad_norm 2.9637 (3.2169)	mem 8931MB
[2022-04-07 05:05:51 large] (main.py 226): INFO Train: [120/300][1100/2502]	eta 0:14:20 lr 0.000328	time 0.6162 (0.6136)	loss 3.6583 (3.4637)	grad_norm 3.7784 (3.2161)	mem 8931MB
[2022-04-07 05:06:53 large] (main.py 226): INFO Train: [120/300][1200/2502]	eta 0:13:18 lr 0.000328	time 0.6932 (0.6135)	loss 3.1367 (3.4595)	grad_norm 2.6464 (nan)	mem 8931MB
[2022-04-07 05:07:54 large] (main.py 226): INFO Train: [120/300][1300/2502]	eta 0:12:17 lr 0.000328	time 0.5678 (0.6135)	loss 3.7964 (3.4563)	grad_norm 4.5986 (nan)	mem 8931MB
[2022-04-07 05:08:56 large] (main.py 226): INFO Train: [120/300][1400/2502]	eta 0:11:16 lr 0.000328	time 0.6126 (0.6138)	loss 2.6951 (3.4616)	grad_norm 3.5928 (nan)	mem 8931MB
[2022-04-07 05:09:57 large] (main.py 226): INFO Train: [120/300][1500/2502]	eta 0:10:14 lr 0.000328	time 0.5818 (0.6135)	loss 4.0733 (3.4667)	grad_norm 3.3013 (nan)	mem 8931MB
[2022-04-07 05:10:58 large] (main.py 226): INFO Train: [120/300][1600/2502]	eta 0:09:13 lr 0.000327	time 0.6617 (0.6136)	loss 3.9316 (3.4656)	grad_norm 2.9583 (nan)	mem 8931MB
[2022-04-07 05:12:00 large] (main.py 226): INFO Train: [120/300][1700/2502]	eta 0:08:12 lr 0.000327	time 0.6009 (0.6137)	loss 3.2215 (3.4684)	grad_norm 4.0963 (nan)	mem 8931MB
[2022-04-07 05:13:01 large] (main.py 226): INFO Train: [120/300][1800/2502]	eta 0:07:10 lr 0.000327	time 0.5585 (0.6136)	loss 3.9265 (3.4658)	grad_norm 2.4785 (nan)	mem 8931MB
[2022-04-07 05:14:01 large] (main.py 226): INFO Train: [120/300][1900/2502]	eta 0:06:08 lr 0.000327	time 0.5743 (0.6129)	loss 3.5995 (3.4663)	grad_norm 2.6495 (nan)	mem 8931MB
[2022-04-07 05:15:02 large] (main.py 226): INFO Train: [120/300][2000/2502]	eta 0:05:07 lr 0.000327	time 0.7070 (0.6130)	loss 3.4524 (3.4675)	grad_norm 2.9104 (nan)	mem 8931MB
[2022-04-07 05:16:03 large] (main.py 226): INFO Train: [120/300][2100/2502]	eta 0:04:06 lr 0.000327	time 0.5948 (0.6129)	loss 3.4251 (3.4662)	grad_norm 3.1462 (nan)	mem 8931MB
[2022-04-07 05:17:06 large] (main.py 226): INFO Train: [120/300][2200/2502]	eta 0:03:05 lr 0.000327	time 0.5852 (0.6135)	loss 3.5399 (3.4714)	grad_norm 2.5860 (nan)	mem 8931MB
[2022-04-07 05:18:06 large] (main.py 226): INFO Train: [120/300][2300/2502]	eta 0:02:03 lr 0.000327	time 0.6000 (0.6130)	loss 3.7360 (3.4694)	grad_norm 2.9893 (nan)	mem 8931MB
[2022-04-07 05:19:07 large] (main.py 226): INFO Train: [120/300][2400/2502]	eta 0:01:02 lr 0.000327	time 0.6633 (0.6127)	loss 2.9700 (3.4673)	grad_norm 2.8244 (nan)	mem 8931MB
[2022-04-07 05:20:09 large] (main.py 226): INFO Train: [120/300][2500/2502]	eta 0:00:01 lr 0.000327	time 0.6470 (0.6128)	loss 3.8003 (3.4706)	grad_norm 2.9677 (nan)	mem 8931MB
[2022-04-07 05:20:10 large] (main.py 233): INFO EPOCH 120 training takes 0:25:33
[2022-04-07 05:20:16 large] (main.py 273): INFO Test: [0/98]	Time 6.583 (6.583)	Loss 1.1140 (1.1140)	Acc@1 76.562 (76.562)	Acc@5 93.750 (93.750)	Mem 8931MB
[2022-04-07 05:20:42 large] (main.py 279): INFO  * Acc@1 75.836 Acc@5 93.156
[2022-04-07 05:20:42 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 75.8%
[2022-04-07 05:20:42 large] (main.py 148): INFO Max accuracy: 76.04%
[2022-04-07 05:20:49 large] (main.py 226): INFO Train: [121/300][0/2502]	eta 4:45:39 lr 0.000327	time 6.8504 (6.8504)	loss 3.9058 (3.9058)	grad_norm 2.8879 (2.8879)	mem 8931MB
[2022-04-07 05:21:45 large] (main.py 226): INFO Train: [121/300][100/2502]	eta 0:24:55 lr 0.000326	time 0.6710 (0.6225)	loss 3.8105 (3.3951)	grad_norm 2.4661 (3.3043)	mem 8931MB
[2022-04-07 05:22:48 large] (main.py 226): INFO Train: [121/300][200/2502]	eta 0:23:56 lr 0.000326	time 0.6180 (0.6242)	loss 3.7897 (3.4078)	grad_norm 2.7437 (3.2443)	mem 8931MB
[2022-04-07 05:23:50 large] (main.py 226): INFO Train: [121/300][300/2502]	eta 0:22:52 lr 0.000326	time 0.6775 (0.6231)	loss 3.7937 (3.4004)	grad_norm 3.8409 (3.2303)	mem 8931MB
[2022-04-07 05:24:52 large] (main.py 226): INFO Train: [121/300][400/2502]	eta 0:21:47 lr 0.000326	time 0.5817 (0.6219)	loss 3.9182 (3.3951)	grad_norm 3.2085 (3.2280)	mem 8931MB
[2022-04-07 05:25:52 large] (main.py 226): INFO Train: [121/300][500/2502]	eta 0:20:36 lr 0.000326	time 0.4807 (0.6177)	loss 3.6133 (3.4208)	grad_norm 2.9820 (3.2231)	mem 8931MB
[2022-04-07 05:26:41 large] (main.py 226): INFO Train: [121/300][600/2502]	eta 0:18:54 lr 0.000326	time 0.4889 (0.5964)	loss 3.8103 (3.4393)	grad_norm 3.6051 (nan)	mem 8931MB
[2022-04-07 05:27:33 large] (main.py 226): INFO Train: [121/300][700/2502]	eta 0:17:35 lr 0.000326	time 0.5984 (0.5857)	loss 3.9908 (3.4439)	grad_norm 3.5686 (nan)	mem 8931MB
[2022-04-07 05:28:35 large] (main.py 226): INFO Train: [121/300][800/2502]	eta 0:16:44 lr 0.000326	time 0.7068 (0.5900)	loss 3.7925 (3.4484)	grad_norm 3.7943 (nan)	mem 8931MB
[2022-04-07 05:29:36 large] (main.py 226): INFO Train: [121/300][900/2502]	eta 0:15:49 lr 0.000326	time 0.6420 (0.5929)	loss 2.7730 (3.4440)	grad_norm 3.3504 (nan)	mem 8931MB
[2022-04-07 05:30:39 large] (main.py 226): INFO Train: [121/300][1000/2502]	eta 0:14:55 lr 0.000326	time 0.6088 (0.5961)	loss 3.7335 (3.4447)	grad_norm 2.8064 (nan)	mem 8931MB
[2022-04-07 05:31:41 large] (main.py 226): INFO Train: [121/300][1100/2502]	eta 0:13:59 lr 0.000325	time 0.5803 (0.5987)	loss 2.3229 (3.4358)	grad_norm 2.6384 (nan)	mem 8931MB
[2022-04-07 05:32:43 large] (main.py 226): INFO Train: [121/300][1200/2502]	eta 0:13:01 lr 0.000325	time 0.5818 (0.6003)	loss 3.7337 (3.4245)	grad_norm 2.6186 (nan)	mem 8931MB
[2022-04-07 05:33:45 large] (main.py 226): INFO Train: [121/300][1300/2502]	eta 0:12:02 lr 0.000325	time 0.6141 (0.6015)	loss 4.2273 (3.4312)	grad_norm 3.3381 (nan)	mem 8931MB
[2022-04-07 05:34:46 large] (main.py 226): INFO Train: [121/300][1400/2502]	eta 0:11:04 lr 0.000325	time 0.6268 (0.6025)	loss 2.4249 (3.4355)	grad_norm 2.7279 (nan)	mem 8931MB
[2022-04-07 05:35:48 large] (main.py 226): INFO Train: [121/300][1500/2502]	eta 0:10:04 lr 0.000325	time 0.7032 (0.6035)	loss 4.2118 (3.4401)	grad_norm 4.3324 (nan)	mem 8931MB
[2022-04-07 05:36:49 large] (main.py 226): INFO Train: [121/300][1600/2502]	eta 0:09:04 lr 0.000325	time 0.5966 (0.6041)	loss 3.4816 (3.4417)	grad_norm 2.7091 (nan)	mem 8931MB
[2022-04-07 05:37:50 large] (main.py 226): INFO Train: [121/300][1700/2502]	eta 0:08:04 lr 0.000325	time 0.5382 (0.6044)	loss 3.3271 (3.4452)	grad_norm 3.5697 (nan)	mem 8931MB
[2022-04-07 05:38:52 large] (main.py 226): INFO Train: [121/300][1800/2502]	eta 0:07:04 lr 0.000325	time 0.6132 (0.6051)	loss 4.1764 (3.4494)	grad_norm 3.3487 (nan)	mem 8931MB
[2022-04-07 05:39:53 large] (main.py 226): INFO Train: [121/300][1900/2502]	eta 0:06:04 lr 0.000325	time 0.6517 (0.6056)	loss 3.6504 (3.4475)	grad_norm 2.9762 (nan)	mem 8931MB
[2022-04-07 05:40:55 large] (main.py 226): INFO Train: [121/300][2000/2502]	eta 0:05:04 lr 0.000325	time 0.6769 (0.6061)	loss 3.8500 (3.4443)	grad_norm 3.6352 (nan)	mem 8931MB
[2022-04-07 05:41:56 large] (main.py 226): INFO Train: [121/300][2100/2502]	eta 0:04:03 lr 0.000324	time 0.5362 (0.6061)	loss 3.5162 (3.4463)	grad_norm 2.4938 (nan)	mem 8931MB
[2022-04-07 05:42:57 large] (main.py 226): INFO Train: [121/300][2200/2502]	eta 0:03:03 lr 0.000324	time 0.6288 (0.6065)	loss 4.2389 (3.4515)	grad_norm 4.0399 (nan)	mem 8931MB
[2022-04-07 05:43:58 large] (main.py 226): INFO Train: [121/300][2300/2502]	eta 0:02:02 lr 0.000324	time 0.5080 (0.6066)	loss 3.4013 (3.4554)	grad_norm 2.8935 (nan)	mem 8931MB
[2022-04-07 05:45:00 large] (main.py 226): INFO Train: [121/300][2400/2502]	eta 0:01:01 lr 0.000324	time 0.6374 (0.6070)	loss 4.0808 (3.4541)	grad_norm 4.0693 (nan)	mem 8931MB
[2022-04-07 05:45:54 large] (main.py 226): INFO Train: [121/300][2500/2502]	eta 0:00:01 lr 0.000324	time 0.5323 (0.6045)	loss 2.8928 (3.4477)	grad_norm 2.9206 (nan)	mem 8931MB
[2022-04-07 05:45:55 large] (main.py 233): INFO EPOCH 121 training takes 0:25:12
[2022-04-07 05:46:01 large] (main.py 273): INFO Test: [0/98]	Time 5.969 (5.969)	Loss 1.0889 (1.0889)	Acc@1 78.125 (78.125)	Acc@5 92.969 (92.969)	Mem 8931MB
[2022-04-07 05:46:27 large] (main.py 279): INFO  * Acc@1 76.124 Acc@5 93.202
[2022-04-07 05:46:27 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 76.1%
[2022-04-07 05:46:27 large] (utils.py 57): INFO output/large/default/ckpt_epoch_121.pth saving......
[2022-04-07 05:46:28 large] (utils.py 59): INFO output/large/default/ckpt_epoch_121.pth saved !!!
[2022-04-07 05:46:28 large] (main.py 148): INFO Max accuracy: 76.12%
[2022-04-07 05:46:36 large] (main.py 226): INFO Train: [122/300][0/2502]	eta 5:45:21 lr 0.000324	time 8.2821 (8.2821)	loss 2.9079 (2.9079)	grad_norm 3.0397 (3.0397)	mem 8931MB
[2022-04-07 05:47:34 large] (main.py 226): INFO Train: [122/300][100/2502]	eta 0:26:00 lr 0.000324	time 0.6329 (0.6497)	loss 3.2280 (3.4983)	grad_norm 4.0393 (3.2707)	mem 8931MB
[2022-04-07 05:48:36 large] (main.py 226): INFO Train: [122/300][200/2502]	eta 0:24:27 lr 0.000324	time 0.5978 (0.6377)	loss 2.1534 (3.4671)	grad_norm 3.6101 (3.2135)	mem 8931MB
[2022-04-07 05:49:38 large] (main.py 226): INFO Train: [122/300][300/2502]	eta 0:23:10 lr 0.000324	time 0.6187 (0.6314)	loss 3.3211 (3.4575)	grad_norm 2.5310 (3.2338)	mem 8931MB
[2022-04-07 05:50:40 large] (main.py 226): INFO Train: [122/300][400/2502]	eta 0:21:59 lr 0.000324	time 0.5303 (0.6275)	loss 3.2652 (3.4408)	grad_norm 3.1356 (3.2735)	mem 8931MB
[2022-04-07 05:51:42 large] (main.py 226): INFO Train: [122/300][500/2502]	eta 0:20:55 lr 0.000324	time 0.6173 (0.6271)	loss 3.0877 (3.4458)	grad_norm 3.2720 (3.2679)	mem 8931MB
[2022-04-07 05:52:44 large] (main.py 226): INFO Train: [122/300][600/2502]	eta 0:19:49 lr 0.000323	time 0.5041 (0.6254)	loss 3.8963 (3.4403)	grad_norm 3.2530 (3.2497)	mem 8931MB
[2022-04-07 05:53:45 large] (main.py 226): INFO Train: [122/300][700/2502]	eta 0:18:44 lr 0.000323	time 0.6477 (0.6239)	loss 3.3996 (3.4339)	grad_norm 4.3532 (3.2583)	mem 8931MB
[2022-04-07 05:54:47 large] (main.py 226): INFO Train: [122/300][800/2502]	eta 0:17:39 lr 0.000323	time 0.5132 (0.6226)	loss 3.2069 (3.4331)	grad_norm 3.5198 (3.2650)	mem 8931MB
[2022-04-07 05:55:48 large] (main.py 226): INFO Train: [122/300][900/2502]	eta 0:16:35 lr 0.000323	time 0.5904 (0.6216)	loss 3.9436 (3.4371)	grad_norm 3.8899 (3.2573)	mem 8931MB
[2022-04-07 05:56:49 large] (main.py 226): INFO Train: [122/300][1000/2502]	eta 0:15:31 lr 0.000323	time 0.4785 (0.6202)	loss 3.7609 (3.4463)	grad_norm 3.2829 (3.2556)	mem 8931MB
[2022-04-07 05:57:51 large] (main.py 226): INFO Train: [122/300][1100/2502]	eta 0:14:29 lr 0.000323	time 0.5844 (0.6201)	loss 4.2170 (3.4445)	grad_norm 3.5728 (3.2636)	mem 8931MB
[2022-04-07 05:58:53 large] (main.py 226): INFO Train: [122/300][1200/2502]	eta 0:13:27 lr 0.000323	time 0.7047 (0.6199)	loss 3.4598 (3.4469)	grad_norm 3.2342 (3.2643)	mem 8931MB
[2022-04-07 05:59:54 large] (main.py 226): INFO Train: [122/300][1300/2502]	eta 0:12:24 lr 0.000323	time 0.6330 (0.6193)	loss 3.8049 (3.4520)	grad_norm 2.9163 (3.2664)	mem 8931MB
[2022-04-07 06:00:56 large] (main.py 226): INFO Train: [122/300][1400/2502]	eta 0:11:22 lr 0.000323	time 0.6763 (0.6196)	loss 2.6656 (3.4495)	grad_norm 3.1737 (3.2660)	mem 8931MB
[2022-04-07 06:01:57 large] (main.py 226): INFO Train: [122/300][1500/2502]	eta 0:10:19 lr 0.000323	time 0.7178 (0.6187)	loss 2.4557 (3.4450)	grad_norm 3.2425 (3.2678)	mem 8931MB
[2022-04-07 06:02:59 large] (main.py 226): INFO Train: [122/300][1600/2502]	eta 0:09:18 lr 0.000322	time 0.6175 (0.6191)	loss 3.4037 (3.4460)	grad_norm 3.5890 (3.2838)	mem 8931MB
[2022-04-07 06:04:00 large] (main.py 226): INFO Train: [122/300][1700/2502]	eta 0:08:16 lr 0.000322	time 0.5271 (0.6185)	loss 3.8896 (3.4461)	grad_norm 3.4826 (3.2929)	mem 8931MB
[2022-04-07 06:05:01 large] (main.py 226): INFO Train: [122/300][1800/2502]	eta 0:07:13 lr 0.000322	time 0.6530 (0.6182)	loss 3.3950 (3.4446)	grad_norm 3.1702 (3.2951)	mem 8931MB
[2022-04-07 06:06:04 large] (main.py 226): INFO Train: [122/300][1900/2502]	eta 0:06:12 lr 0.000322	time 0.7841 (0.6184)	loss 3.6275 (3.4453)	grad_norm 2.9978 (3.2887)	mem 8931MB
[2022-04-07 06:07:06 large] (main.py 226): INFO Train: [122/300][2000/2502]	eta 0:05:10 lr 0.000322	time 0.6236 (0.6187)	loss 3.0691 (3.4506)	grad_norm 3.2930 (3.2875)	mem 8931MB
[2022-04-07 06:08:08 large] (main.py 226): INFO Train: [122/300][2100/2502]	eta 0:04:08 lr 0.000322	time 0.6089 (0.6189)	loss 4.3753 (3.4479)	grad_norm 2.4868 (3.2837)	mem 8931MB
[2022-04-07 06:09:10 large] (main.py 226): INFO Train: [122/300][2200/2502]	eta 0:03:06 lr 0.000322	time 0.6805 (0.6189)	loss 2.4990 (3.4479)	grad_norm 3.0503 (3.2786)	mem 8931MB
[2022-04-07 06:10:11 large] (main.py 226): INFO Train: [122/300][2300/2502]	eta 0:02:04 lr 0.000322	time 0.5080 (0.6184)	loss 3.6917 (3.4495)	grad_norm 2.7916 (3.2742)	mem 8931MB
[2022-04-07 06:11:13 large] (main.py 226): INFO Train: [122/300][2400/2502]	eta 0:01:03 lr 0.000322	time 0.5920 (0.6183)	loss 2.7419 (3.4474)	grad_norm 2.9567 (3.2746)	mem 8931MB
[2022-04-07 06:12:14 large] (main.py 226): INFO Train: [122/300][2500/2502]	eta 0:00:01 lr 0.000322	time 0.6185 (0.6181)	loss 3.5313 (3.4501)	grad_norm 3.2792 (3.2803)	mem 8931MB
[2022-04-07 06:12:15 large] (main.py 233): INFO EPOCH 122 training takes 0:25:47
[2022-04-07 06:12:21 large] (main.py 273): INFO Test: [0/98]	Time 6.046 (6.046)	Loss 1.1403 (1.1403)	Acc@1 77.539 (77.539)	Acc@5 92.969 (92.969)	Mem 8931MB
[2022-04-07 06:12:48 large] (main.py 279): INFO  * Acc@1 76.096 Acc@5 93.214
[2022-04-07 06:12:48 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 76.1%
[2022-04-07 06:12:48 large] (main.py 148): INFO Max accuracy: 76.12%
[2022-04-07 06:12:55 large] (main.py 226): INFO Train: [123/300][0/2502]	eta 4:42:43 lr 0.000322	time 6.7798 (6.7798)	loss 4.0168 (4.0168)	grad_norm 3.0608 (3.0608)	mem 8931MB
[2022-04-07 06:13:54 large] (main.py 226): INFO Train: [123/300][100/2502]	eta 0:26:18 lr 0.000321	time 0.8194 (0.6573)	loss 3.6599 (3.4251)	grad_norm 2.7784 (3.3658)	mem 8931MB
[2022-04-07 06:14:57 large] (main.py 226): INFO Train: [123/300][200/2502]	eta 0:24:31 lr 0.000321	time 0.6580 (0.6394)	loss 3.8523 (3.3990)	grad_norm 3.7828 (3.3731)	mem 8931MB
[2022-04-07 06:15:58 large] (main.py 226): INFO Train: [123/300][300/2502]	eta 0:23:13 lr 0.000321	time 0.6017 (0.6328)	loss 2.8983 (3.4183)	grad_norm 2.6279 (3.3408)	mem 8931MB
[2022-04-07 06:17:01 large] (main.py 226): INFO Train: [123/300][400/2502]	eta 0:22:06 lr 0.000321	time 0.7492 (0.6312)	loss 2.5510 (3.4454)	grad_norm 3.3722 (3.3079)	mem 8931MB
[2022-04-07 06:18:03 large] (main.py 226): INFO Train: [123/300][500/2502]	eta 0:20:59 lr 0.000321	time 0.6065 (0.6289)	loss 2.6387 (3.4681)	grad_norm 4.2168 (nan)	mem 8931MB
[2022-04-07 06:19:05 large] (main.py 226): INFO Train: [123/300][600/2502]	eta 0:19:53 lr 0.000321	time 0.7337 (0.6274)	loss 4.0539 (3.4405)	grad_norm 3.6459 (nan)	mem 8931MB
[2022-04-07 06:20:06 large] (main.py 226): INFO Train: [123/300][700/2502]	eta 0:18:46 lr 0.000321	time 0.5084 (0.6254)	loss 2.6458 (3.4277)	grad_norm 2.8582 (nan)	mem 8931MB
[2022-04-07 06:21:08 large] (main.py 226): INFO Train: [123/300][800/2502]	eta 0:17:42 lr 0.000321	time 0.5244 (0.6242)	loss 3.8946 (3.4288)	grad_norm 3.3785 (nan)	mem 8931MB
[2022-04-07 06:22:10 large] (main.py 226): INFO Train: [123/300][900/2502]	eta 0:16:39 lr 0.000321	time 0.6256 (0.6237)	loss 3.6699 (3.4311)	grad_norm 3.8812 (nan)	mem 8931MB
[2022-04-07 06:23:12 large] (main.py 226): INFO Train: [123/300][1000/2502]	eta 0:15:36 lr 0.000321	time 0.5917 (0.6234)	loss 3.9254 (3.4397)	grad_norm 3.3202 (nan)	mem 8931MB
[2022-04-07 06:24:14 large] (main.py 226): INFO Train: [123/300][1100/2502]	eta 0:14:33 lr 0.000320	time 0.6206 (0.6233)	loss 3.0421 (3.4322)	grad_norm 3.8975 (nan)	mem 8931MB
[2022-04-07 06:25:16 large] (main.py 226): INFO Train: [123/300][1200/2502]	eta 0:13:30 lr 0.000320	time 0.6376 (0.6226)	loss 3.4559 (3.4354)	grad_norm 2.6128 (nan)	mem 8931MB
[2022-04-07 06:26:18 large] (main.py 226): INFO Train: [123/300][1300/2502]	eta 0:12:28 lr 0.000320	time 0.5705 (0.6228)	loss 3.6298 (3.4387)	grad_norm 3.3746 (nan)	mem 8931MB
[2022-04-07 06:27:21 large] (main.py 226): INFO Train: [123/300][1400/2502]	eta 0:11:26 lr 0.000320	time 0.7320 (0.6231)	loss 3.0241 (3.4372)	grad_norm 2.6408 (nan)	mem 8931MB
[2022-04-07 06:28:24 large] (main.py 226): INFO Train: [123/300][1500/2502]	eta 0:10:24 lr 0.000320	time 0.6892 (0.6234)	loss 2.8522 (3.4370)	grad_norm 3.4537 (nan)	mem 8931MB
[2022-04-07 06:29:26 large] (main.py 226): INFO Train: [123/300][1600/2502]	eta 0:09:22 lr 0.000320	time 0.5637 (0.6232)	loss 3.2969 (3.4405)	grad_norm 2.8608 (nan)	mem 8931MB
[2022-04-07 06:30:28 large] (main.py 226): INFO Train: [123/300][1700/2502]	eta 0:08:19 lr 0.000320	time 0.6076 (0.6230)	loss 3.3896 (3.4396)	grad_norm 2.6357 (nan)	mem 8931MB
[2022-04-07 06:31:30 large] (main.py 226): INFO Train: [123/300][1800/2502]	eta 0:07:17 lr 0.000320	time 0.7038 (0.6231)	loss 3.7814 (3.4419)	grad_norm 3.6029 (nan)	mem 8931MB
[2022-04-07 06:32:32 large] (main.py 226): INFO Train: [123/300][1900/2502]	eta 0:06:14 lr 0.000320	time 0.6148 (0.6229)	loss 2.4491 (3.4427)	grad_norm 3.9840 (nan)	mem 8931MB
[2022-04-07 06:33:34 large] (main.py 226): INFO Train: [123/300][2000/2502]	eta 0:05:12 lr 0.000320	time 0.5974 (0.6227)	loss 3.6742 (3.4462)	grad_norm 3.3208 (nan)	mem 8931MB
[2022-04-07 06:34:36 large] (main.py 226): INFO Train: [123/300][2100/2502]	eta 0:04:10 lr 0.000319	time 0.6166 (0.6226)	loss 2.8419 (3.4521)	grad_norm 2.7083 (nan)	mem 8931MB
[2022-04-07 06:35:37 large] (main.py 226): INFO Train: [123/300][2200/2502]	eta 0:03:07 lr 0.000319	time 0.6061 (0.6222)	loss 3.2660 (3.4554)	grad_norm 2.5305 (nan)	mem 8931MB
[2022-04-07 06:36:39 large] (main.py 226): INFO Train: [123/300][2300/2502]	eta 0:02:05 lr 0.000319	time 0.5269 (0.6220)	loss 3.8368 (3.4551)	grad_norm 3.5006 (nan)	mem 8931MB
[2022-04-07 06:37:42 large] (main.py 226): INFO Train: [123/300][2400/2502]	eta 0:01:03 lr 0.000319	time 0.6969 (0.6223)	loss 3.8165 (3.4546)	grad_norm 3.2464 (nan)	mem 8931MB
[2022-04-07 06:38:44 large] (main.py 226): INFO Train: [123/300][2500/2502]	eta 0:00:01 lr 0.000319	time 0.6088 (0.6220)	loss 3.2730 (3.4534)	grad_norm 3.8622 (nan)	mem 8931MB
[2022-04-07 06:38:45 large] (main.py 233): INFO EPOCH 123 training takes 0:25:56
[2022-04-07 06:38:52 large] (main.py 273): INFO Test: [0/98]	Time 7.120 (7.120)	Loss 1.1478 (1.1478)	Acc@1 77.344 (77.344)	Acc@5 93.750 (93.750)	Mem 8931MB
[2022-04-07 06:39:17 large] (main.py 279): INFO  * Acc@1 76.320 Acc@5 93.338
[2022-04-07 06:39:17 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 76.3%
[2022-04-07 06:39:17 large] (utils.py 57): INFO output/large/default/ckpt_epoch_123.pth saving......
[2022-04-07 06:39:18 large] (utils.py 59): INFO output/large/default/ckpt_epoch_123.pth saved !!!
[2022-04-07 06:39:18 large] (main.py 148): INFO Max accuracy: 76.32%
[2022-04-07 06:39:26 large] (main.py 226): INFO Train: [124/300][0/2502]	eta 5:27:35 lr 0.000319	time 7.8559 (7.8559)	loss 2.2302 (2.2302)	grad_norm 2.8432 (2.8432)	mem 8931MB
[2022-04-07 06:40:19 large] (main.py 226): INFO Train: [124/300][100/2502]	eta 0:24:19 lr 0.000319	time 0.6100 (0.6078)	loss 3.0796 (3.4046)	grad_norm 4.0558 (nan)	mem 8931MB
[2022-04-07 06:41:22 large] (main.py 226): INFO Train: [124/300][200/2502]	eta 0:23:41 lr 0.000319	time 0.6039 (0.6175)	loss 3.7623 (3.4448)	grad_norm 3.3472 (nan)	mem 8931MB
[2022-04-07 06:42:25 large] (main.py 226): INFO Train: [124/300][300/2502]	eta 0:22:50 lr 0.000319	time 0.5758 (0.6225)	loss 2.9732 (3.4335)	grad_norm 3.4381 (nan)	mem 8931MB
[2022-04-07 06:43:28 large] (main.py 226): INFO Train: [124/300][400/2502]	eta 0:21:50 lr 0.000319	time 0.6018 (0.6235)	loss 3.3427 (3.4502)	grad_norm 2.7414 (nan)	mem 8931MB
[2022-04-07 06:44:31 large] (main.py 226): INFO Train: [124/300][500/2502]	eta 0:20:51 lr 0.000319	time 0.6811 (0.6249)	loss 4.0245 (3.4546)	grad_norm 2.7700 (nan)	mem 8931MB
[2022-04-07 06:45:33 large] (main.py 226): INFO Train: [124/300][600/2502]	eta 0:19:47 lr 0.000318	time 0.5447 (0.6244)	loss 3.9966 (3.4632)	grad_norm 3.0862 (nan)	mem 8931MB
[2022-04-07 06:46:35 large] (main.py 226): INFO Train: [124/300][700/2502]	eta 0:18:44 lr 0.000318	time 0.5788 (0.6242)	loss 4.0590 (3.4541)	grad_norm 3.2227 (nan)	mem 8931MB
[2022-04-07 06:47:37 large] (main.py 226): INFO Train: [124/300][800/2502]	eta 0:17:41 lr 0.000318	time 0.5874 (0.6237)	loss 3.0397 (3.4455)	grad_norm 2.6491 (nan)	mem 8931MB
[2022-04-07 06:48:40 large] (main.py 226): INFO Train: [124/300][900/2502]	eta 0:16:39 lr 0.000318	time 0.5780 (0.6240)	loss 3.8417 (3.4468)	grad_norm 2.8575 (nan)	mem 8931MB
[2022-04-07 06:49:41 large] (main.py 226): INFO Train: [124/300][1000/2502]	eta 0:15:35 lr 0.000318	time 0.6399 (0.6226)	loss 4.1032 (3.4502)	grad_norm 3.5316 (nan)	mem 8931MB
[2022-04-07 06:50:41 large] (main.py 226): INFO Train: [124/300][1100/2502]	eta 0:14:30 lr 0.000318	time 0.6017 (0.6208)	loss 3.8150 (3.4621)	grad_norm 3.6351 (nan)	mem 8931MB
[2022-04-07 06:51:43 large] (main.py 226): INFO Train: [124/300][1200/2502]	eta 0:13:27 lr 0.000318	time 0.6050 (0.6206)	loss 4.2552 (3.4548)	grad_norm 3.7269 (nan)	mem 8931MB
[2022-04-07 06:52:45 large] (main.py 226): INFO Train: [124/300][1300/2502]	eta 0:12:25 lr 0.000318	time 0.6147 (0.6203)	loss 3.2444 (3.4497)	grad_norm 2.6963 (nan)	mem 8931MB
[2022-04-07 06:53:46 large] (main.py 226): INFO Train: [124/300][1400/2502]	eta 0:11:22 lr 0.000318	time 0.5745 (0.6197)	loss 4.0457 (3.4408)	grad_norm 3.4399 (nan)	mem 8931MB
[2022-04-07 06:54:48 large] (main.py 226): INFO Train: [124/300][1500/2502]	eta 0:10:20 lr 0.000318	time 0.6953 (0.6196)	loss 2.2318 (3.4435)	grad_norm 2.9741 (nan)	mem 8931MB
[2022-04-07 06:55:49 large] (main.py 226): INFO Train: [124/300][1600/2502]	eta 0:09:18 lr 0.000317	time 0.4947 (0.6191)	loss 4.2490 (3.4412)	grad_norm 3.1864 (nan)	mem 8931MB
[2022-04-07 06:56:50 large] (main.py 226): INFO Train: [124/300][1700/2502]	eta 0:08:16 lr 0.000317	time 0.5301 (0.6185)	loss 3.1309 (3.4355)	grad_norm 2.9137 (nan)	mem 8931MB
[2022-04-07 06:57:51 large] (main.py 226): INFO Train: [124/300][1800/2502]	eta 0:07:13 lr 0.000317	time 0.7299 (0.6181)	loss 4.2532 (3.4393)	grad_norm 3.7011 (nan)	mem 8931MB
[2022-04-07 06:58:51 large] (main.py 226): INFO Train: [124/300][1900/2502]	eta 0:06:11 lr 0.000317	time 0.5443 (0.6174)	loss 3.3057 (3.4403)	grad_norm 3.2196 (nan)	mem 8931MB
[2022-04-07 06:59:53 large] (main.py 226): INFO Train: [124/300][2000/2502]	eta 0:05:09 lr 0.000317	time 0.6095 (0.6172)	loss 3.4190 (3.4446)	grad_norm 3.5100 (nan)	mem 8931MB
[2022-04-07 07:00:54 large] (main.py 226): INFO Train: [124/300][2100/2502]	eta 0:04:08 lr 0.000317	time 0.5974 (0.6170)	loss 4.2039 (3.4471)	grad_norm 3.6012 (nan)	mem 8931MB
[2022-04-07 07:01:50 large] (main.py 226): INFO Train: [124/300][2200/2502]	eta 0:03:05 lr 0.000317	time 0.5280 (0.6144)	loss 2.7445 (3.4491)	grad_norm 2.3874 (nan)	mem 8931MB
[2022-04-07 07:02:50 large] (main.py 226): INFO Train: [124/300][2300/2502]	eta 0:02:03 lr 0.000317	time 0.6238 (0.6136)	loss 4.6383 (3.4470)	grad_norm 3.2882 (nan)	mem 8931MB
[2022-04-07 07:03:50 large] (main.py 226): INFO Train: [124/300][2400/2502]	eta 0:01:02 lr 0.000317	time 0.6067 (0.6132)	loss 3.6983 (3.4481)	grad_norm 3.6248 (nan)	mem 8931MB
[2022-04-07 07:04:51 large] (main.py 226): INFO Train: [124/300][2500/2502]	eta 0:00:01 lr 0.000317	time 0.6267 (0.6132)	loss 3.8582 (3.4465)	grad_norm 3.6009 (nan)	mem 8931MB
[2022-04-07 07:04:52 large] (main.py 233): INFO EPOCH 124 training takes 0:25:34
[2022-04-07 07:04:58 large] (main.py 273): INFO Test: [0/98]	Time 5.577 (5.577)	Loss 1.1192 (1.1192)	Acc@1 76.172 (76.172)	Acc@5 93.555 (93.555)	Mem 8931MB
[2022-04-07 07:05:25 large] (main.py 279): INFO  * Acc@1 76.060 Acc@5 93.182
[2022-04-07 07:05:25 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 76.1%
[2022-04-07 07:05:25 large] (main.py 148): INFO Max accuracy: 76.32%
[2022-04-07 07:05:32 large] (main.py 226): INFO Train: [125/300][0/2502]	eta 5:07:23 lr 0.000317	time 7.3715 (7.3715)	loss 2.7082 (2.7082)	grad_norm 2.9388 (2.9388)	mem 8931MB
[2022-04-07 07:06:27 large] (main.py 226): INFO Train: [125/300][100/2502]	eta 0:24:49 lr 0.000316	time 0.5887 (0.6200)	loss 3.8605 (3.3950)	grad_norm 2.6438 (3.2085)	mem 8931MB
[2022-04-07 07:07:29 large] (main.py 226): INFO Train: [125/300][200/2502]	eta 0:23:41 lr 0.000316	time 0.6143 (0.6177)	loss 3.3283 (3.4452)	grad_norm 3.4123 (3.2509)	mem 8931MB
[2022-04-07 07:08:30 large] (main.py 226): INFO Train: [125/300][300/2502]	eta 0:22:38 lr 0.000316	time 0.6055 (0.6170)	loss 4.0168 (3.4225)	grad_norm 4.1489 (3.2701)	mem 8931MB
[2022-04-07 07:09:32 large] (main.py 226): INFO Train: [125/300][400/2502]	eta 0:21:37 lr 0.000316	time 0.6010 (0.6171)	loss 3.6567 (3.4301)	grad_norm 3.0787 (3.3104)	mem 8931MB
[2022-04-07 07:10:33 large] (main.py 226): INFO Train: [125/300][500/2502]	eta 0:20:31 lr 0.000316	time 0.6450 (0.6149)	loss 3.4605 (3.4315)	grad_norm 3.5643 (3.3004)	mem 8931MB
[2022-04-07 07:11:34 large] (main.py 226): INFO Train: [125/300][600/2502]	eta 0:19:29 lr 0.000316	time 0.7070 (0.6148)	loss 3.1282 (3.4362)	grad_norm 3.1082 (3.2984)	mem 8931MB
[2022-04-07 07:12:35 large] (main.py 226): INFO Train: [125/300][700/2502]	eta 0:18:26 lr 0.000316	time 0.6060 (0.6140)	loss 2.5203 (3.4447)	grad_norm 3.4584 (3.2785)	mem 8931MB
[2022-04-07 07:13:36 large] (main.py 226): INFO Train: [125/300][800/2502]	eta 0:17:24 lr 0.000316	time 0.7944 (0.6134)	loss 3.3389 (3.4482)	grad_norm 3.1792 (3.2737)	mem 8931MB
[2022-04-07 07:14:36 large] (main.py 226): INFO Train: [125/300][900/2502]	eta 0:16:20 lr 0.000316	time 0.7588 (0.6122)	loss 3.6777 (3.4501)	grad_norm 3.1849 (3.2789)	mem 8931MB
[2022-04-07 07:15:37 large] (main.py 226): INFO Train: [125/300][1000/2502]	eta 0:15:18 lr 0.000316	time 0.6001 (0.6115)	loss 3.5700 (3.4456)	grad_norm 2.8343 (3.2927)	mem 8931MB
[2022-04-07 07:16:38 large] (main.py 226): INFO Train: [125/300][1100/2502]	eta 0:14:17 lr 0.000315	time 0.6208 (0.6118)	loss 3.9345 (3.4383)	grad_norm 2.5838 (3.2957)	mem 8931MB
[2022-04-07 07:17:38 large] (main.py 226): INFO Train: [125/300][1200/2502]	eta 0:13:15 lr 0.000315	time 0.5142 (0.6110)	loss 3.0778 (3.4325)	grad_norm 3.2308 (3.3053)	mem 8931MB
[2022-04-07 07:18:38 large] (main.py 226): INFO Train: [125/300][1300/2502]	eta 0:12:13 lr 0.000315	time 0.5230 (0.6101)	loss 3.1351 (3.4311)	grad_norm 4.2722 (3.2975)	mem 8931MB
[2022-04-07 07:19:39 large] (main.py 226): INFO Train: [125/300][1400/2502]	eta 0:11:12 lr 0.000315	time 0.6613 (0.6101)	loss 3.2674 (3.4315)	grad_norm 2.3688 (3.2997)	mem 8931MB
[2022-04-07 07:20:41 large] (main.py 226): INFO Train: [125/300][1500/2502]	eta 0:10:11 lr 0.000315	time 0.6647 (0.6104)	loss 4.0161 (3.4304)	grad_norm 3.2612 (3.2966)	mem 8931MB
[2022-04-07 07:21:41 large] (main.py 226): INFO Train: [125/300][1600/2502]	eta 0:09:10 lr 0.000315	time 0.6925 (0.6102)	loss 3.8929 (3.4313)	grad_norm 2.8612 (3.2945)	mem 8931MB
[2022-04-07 07:22:42 large] (main.py 226): INFO Train: [125/300][1700/2502]	eta 0:08:09 lr 0.000315	time 0.5878 (0.6098)	loss 3.5239 (3.4351)	grad_norm 2.4660 (3.2917)	mem 8931MB
[2022-04-07 07:23:42 large] (main.py 226): INFO Train: [125/300][1800/2502]	eta 0:07:07 lr 0.000315	time 0.6158 (0.6094)	loss 2.8354 (3.4339)	grad_norm 3.3663 (3.2894)	mem 8931MB
[2022-04-07 07:24:43 large] (main.py 226): INFO Train: [125/300][1900/2502]	eta 0:06:06 lr 0.000315	time 0.6276 (0.6096)	loss 3.7431 (3.4322)	grad_norm 2.9374 (3.2898)	mem 8931MB
[2022-04-07 07:25:44 large] (main.py 226): INFO Train: [125/300][2000/2502]	eta 0:05:05 lr 0.000315	time 0.6412 (0.6095)	loss 3.8613 (3.4333)	grad_norm 3.3289 (3.2884)	mem 8931MB
[2022-04-07 07:26:43 large] (main.py 226): INFO Train: [125/300][2100/2502]	eta 0:04:04 lr 0.000314	time 0.6140 (0.6087)	loss 2.4515 (3.4375)	grad_norm 2.4476 (3.2924)	mem 8931MB
[2022-04-07 07:27:43 large] (main.py 226): INFO Train: [125/300][2200/2502]	eta 0:03:03 lr 0.000314	time 0.6382 (0.6083)	loss 2.8542 (3.4353)	grad_norm 2.5469 (3.2895)	mem 8931MB
[2022-04-07 07:28:44 large] (main.py 226): INFO Train: [125/300][2300/2502]	eta 0:02:02 lr 0.000314	time 0.6080 (0.6081)	loss 3.4900 (3.4351)	grad_norm 2.2745 (3.2911)	mem 8931MB
[2022-04-07 07:29:45 large] (main.py 226): INFO Train: [125/300][2400/2502]	eta 0:01:02 lr 0.000314	time 0.6142 (0.6084)	loss 3.2043 (3.4361)	grad_norm 3.9316 (3.2936)	mem 8931MB
[2022-04-07 07:30:46 large] (main.py 226): INFO Train: [125/300][2500/2502]	eta 0:00:01 lr 0.000314	time 0.5781 (0.6082)	loss 3.4410 (3.4296)	grad_norm 3.5993 (3.2950)	mem 8931MB
[2022-04-07 07:30:47 large] (main.py 233): INFO EPOCH 125 training takes 0:25:22
[2022-04-07 07:30:53 large] (main.py 273): INFO Test: [0/98]	Time 6.072 (6.072)	Loss 1.1641 (1.1641)	Acc@1 75.391 (75.391)	Acc@5 92.188 (92.188)	Mem 8931MB
[2022-04-07 07:31:18 large] (main.py 279): INFO  * Acc@1 76.026 Acc@5 93.060
[2022-04-07 07:31:18 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 76.0%
[2022-04-07 07:31:18 large] (main.py 148): INFO Max accuracy: 76.32%
[2022-04-07 07:31:26 large] (main.py 226): INFO Train: [126/300][0/2502]	eta 4:58:06 lr 0.000314	time 7.1491 (7.1491)	loss 3.6035 (3.6035)	grad_norm 3.1337 (3.1337)	mem 8931MB
[2022-04-07 07:32:23 large] (main.py 226): INFO Train: [126/300][100/2502]	eta 0:25:25 lr 0.000314	time 0.6146 (0.6353)	loss 4.1353 (3.3700)	grad_norm 3.8120 (3.3056)	mem 8931MB
[2022-04-07 07:33:24 large] (main.py 226): INFO Train: [126/300][200/2502]	eta 0:24:02 lr 0.000314	time 0.6236 (0.6264)	loss 4.3494 (3.4013)	grad_norm 3.7507 (3.3579)	mem 8931MB
[2022-04-07 07:34:25 large] (main.py 226): INFO Train: [126/300][300/2502]	eta 0:22:44 lr 0.000314	time 0.7268 (0.6194)	loss 3.1057 (3.4156)	grad_norm 3.1968 (3.3592)	mem 8931MB
[2022-04-07 07:35:26 large] (main.py 226): INFO Train: [126/300][400/2502]	eta 0:21:39 lr 0.000314	time 0.6603 (0.6183)	loss 3.8163 (3.4283)	grad_norm 2.7449 (3.3608)	mem 8931MB
[2022-04-07 07:36:28 large] (main.py 226): INFO Train: [126/300][500/2502]	eta 0:20:35 lr 0.000314	time 0.6551 (0.6172)	loss 3.2077 (3.4207)	grad_norm 3.2661 (3.3551)	mem 8931MB
[2022-04-07 07:37:28 large] (main.py 226): INFO Train: [126/300][600/2502]	eta 0:19:28 lr 0.000313	time 0.6664 (0.6141)	loss 3.4610 (3.4191)	grad_norm 2.6707 (3.3471)	mem 8931MB
[2022-04-07 07:38:28 large] (main.py 226): INFO Train: [126/300][700/2502]	eta 0:18:24 lr 0.000313	time 0.4953 (0.6127)	loss 3.6199 (3.4154)	grad_norm 3.0988 (3.3305)	mem 8931MB
[2022-04-07 07:39:30 large] (main.py 226): INFO Train: [126/300][800/2502]	eta 0:17:24 lr 0.000313	time 0.5996 (0.6136)	loss 2.8836 (3.4282)	grad_norm 3.0531 (3.3299)	mem 8931MB
[2022-04-07 07:40:30 large] (main.py 226): INFO Train: [126/300][900/2502]	eta 0:16:21 lr 0.000313	time 0.6199 (0.6124)	loss 3.5278 (3.4358)	grad_norm 2.7395 (nan)	mem 8931MB
[2022-04-07 07:41:31 large] (main.py 226): INFO Train: [126/300][1000/2502]	eta 0:15:19 lr 0.000313	time 0.6584 (0.6123)	loss 2.7736 (3.4359)	grad_norm 3.0455 (nan)	mem 8931MB
[2022-04-07 07:42:32 large] (main.py 226): INFO Train: [126/300][1100/2502]	eta 0:14:17 lr 0.000313	time 0.5794 (0.6114)	loss 2.5034 (3.4379)	grad_norm 2.6472 (nan)	mem 8931MB
[2022-04-07 07:43:32 large] (main.py 226): INFO Train: [126/300][1200/2502]	eta 0:13:15 lr 0.000313	time 0.5385 (0.6106)	loss 3.3560 (3.4381)	grad_norm 3.2020 (nan)	mem 8931MB
[2022-04-07 07:44:32 large] (main.py 226): INFO Train: [126/300][1300/2502]	eta 0:12:13 lr 0.000313	time 0.6956 (0.6101)	loss 3.0497 (3.4343)	grad_norm 3.6317 (nan)	mem 8931MB
[2022-04-07 07:45:32 large] (main.py 226): INFO Train: [126/300][1400/2502]	eta 0:11:11 lr 0.000313	time 0.5594 (0.6092)	loss 3.6932 (3.4339)	grad_norm 3.4765 (nan)	mem 8931MB
[2022-04-07 07:46:33 large] (main.py 226): INFO Train: [126/300][1500/2502]	eta 0:10:10 lr 0.000313	time 0.5967 (0.6095)	loss 3.9298 (3.4359)	grad_norm 3.9342 (nan)	mem 8931MB
[2022-04-07 07:47:33 large] (main.py 226): INFO Train: [126/300][1600/2502]	eta 0:09:09 lr 0.000312	time 0.5359 (0.6089)	loss 3.2066 (3.4394)	grad_norm 2.6867 (nan)	mem 8931MB
[2022-04-07 07:48:33 large] (main.py 226): INFO Train: [126/300][1700/2502]	eta 0:08:07 lr 0.000312	time 0.4897 (0.6080)	loss 3.8526 (3.4404)	grad_norm 3.2874 (nan)	mem 8931MB
[2022-04-07 07:49:27 large] (main.py 226): INFO Train: [126/300][1800/2502]	eta 0:07:04 lr 0.000312	time 0.5947 (0.6045)	loss 3.8844 (3.4421)	grad_norm 2.8318 (nan)	mem 8931MB
[2022-04-07 07:50:27 large] (main.py 226): INFO Train: [126/300][1900/2502]	eta 0:06:03 lr 0.000312	time 0.6347 (0.6043)	loss 3.6998 (3.4453)	grad_norm 2.7757 (nan)	mem 8931MB
[2022-04-07 07:51:28 large] (main.py 226): INFO Train: [126/300][2000/2502]	eta 0:05:03 lr 0.000312	time 0.6340 (0.6043)	loss 3.7916 (3.4487)	grad_norm 3.3363 (nan)	mem 8931MB
[2022-04-07 07:52:30 large] (main.py 226): INFO Train: [126/300][2100/2502]	eta 0:04:03 lr 0.000312	time 0.6221 (0.6053)	loss 3.3847 (3.4501)	grad_norm 3.4796 (nan)	mem 8931MB
[2022-04-07 07:53:31 large] (main.py 226): INFO Train: [126/300][2200/2502]	eta 0:03:02 lr 0.000312	time 0.6138 (0.6053)	loss 4.0401 (3.4437)	grad_norm 3.4091 (nan)	mem 8931MB
[2022-04-07 07:54:31 large] (main.py 226): INFO Train: [126/300][2300/2502]	eta 0:02:02 lr 0.000312	time 0.6165 (0.6053)	loss 3.5277 (3.4470)	grad_norm 3.2529 (nan)	mem 8931MB
[2022-04-07 07:55:31 large] (main.py 226): INFO Train: [126/300][2400/2502]	eta 0:01:01 lr 0.000312	time 0.7158 (0.6049)	loss 3.7424 (3.4434)	grad_norm 2.8159 (nan)	mem 8931MB
[2022-04-07 07:56:33 large] (main.py 226): INFO Train: [126/300][2500/2502]	eta 0:00:01 lr 0.000312	time 0.6192 (0.6055)	loss 2.3443 (3.4403)	grad_norm 4.1271 (nan)	mem 8931MB
[2022-04-07 07:56:34 large] (main.py 233): INFO EPOCH 126 training takes 0:25:15
[2022-04-07 07:56:40 large] (main.py 273): INFO Test: [0/98]	Time 6.084 (6.084)	Loss 1.1358 (1.1358)	Acc@1 75.586 (75.586)	Acc@5 94.531 (94.531)	Mem 8931MB
[2022-04-07 07:57:06 large] (main.py 279): INFO  * Acc@1 76.456 Acc@5 93.346
[2022-04-07 07:57:06 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 76.5%
[2022-04-07 07:57:06 large] (utils.py 57): INFO output/large/default/ckpt_epoch_126.pth saving......
[2022-04-07 07:57:07 large] (utils.py 59): INFO output/large/default/ckpt_epoch_126.pth saved !!!
[2022-04-07 07:57:07 large] (main.py 148): INFO Max accuracy: 76.46%
[2022-04-07 07:57:15 large] (main.py 226): INFO Train: [127/300][0/2502]	eta 5:07:55 lr 0.000312	time 7.3842 (7.3842)	loss 3.9324 (3.9324)	grad_norm 3.1032 (3.1032)	mem 8931MB
[2022-04-07 07:58:05 large] (main.py 226): INFO Train: [127/300][100/2502]	eta 0:23:05 lr 0.000311	time 0.4528 (0.5768)	loss 3.9199 (3.4603)	grad_norm 3.8692 (3.4137)	mem 8931MB
[2022-04-07 07:59:06 large] (main.py 226): INFO Train: [127/300][200/2502]	eta 0:22:39 lr 0.000311	time 0.6310 (0.5908)	loss 3.8604 (3.4092)	grad_norm 3.5736 (3.3869)	mem 8931MB
[2022-04-07 08:00:06 large] (main.py 226): INFO Train: [127/300][300/2502]	eta 0:21:47 lr 0.000311	time 0.6582 (0.5940)	loss 2.3981 (3.3856)	grad_norm 3.6446 (3.3678)	mem 8931MB
[2022-04-07 08:01:07 large] (main.py 226): INFO Train: [127/300][400/2502]	eta 0:20:54 lr 0.000311	time 0.4980 (0.5969)	loss 3.1127 (3.3934)	grad_norm 3.0227 (3.3337)	mem 8931MB
[2022-04-07 08:02:08 large] (main.py 226): INFO Train: [127/300][500/2502]	eta 0:20:04 lr 0.000311	time 0.6033 (0.6014)	loss 3.5429 (3.3972)	grad_norm 2.7548 (3.3248)	mem 8931MB
[2022-04-07 08:03:10 large] (main.py 226): INFO Train: [127/300][600/2502]	eta 0:19:06 lr 0.000311	time 0.5069 (0.6029)	loss 4.0667 (3.3942)	grad_norm 2.9888 (3.3090)	mem 8931MB
[2022-04-07 08:04:10 large] (main.py 226): INFO Train: [127/300][700/2502]	eta 0:18:06 lr 0.000311	time 0.6032 (0.6028)	loss 3.9487 (3.3939)	grad_norm 2.9584 (nan)	mem 8931MB
[2022-04-07 08:05:11 large] (main.py 226): INFO Train: [127/300][800/2502]	eta 0:17:08 lr 0.000311	time 0.6004 (0.6043)	loss 3.5871 (3.3853)	grad_norm 4.0609 (nan)	mem 8931MB
[2022-04-07 08:06:12 large] (main.py 226): INFO Train: [127/300][900/2502]	eta 0:16:08 lr 0.000311	time 0.6559 (0.6048)	loss 3.6202 (3.3968)	grad_norm 2.9686 (nan)	mem 8931MB
[2022-04-07 08:07:13 large] (main.py 226): INFO Train: [127/300][1000/2502]	eta 0:15:09 lr 0.000311	time 0.5435 (0.6055)	loss 4.1745 (3.4096)	grad_norm 3.1173 (nan)	mem 8931MB
[2022-04-07 08:08:15 large] (main.py 226): INFO Train: [127/300][1100/2502]	eta 0:14:10 lr 0.000310	time 0.7040 (0.6064)	loss 2.5658 (3.4114)	grad_norm 3.3070 (nan)	mem 8931MB
[2022-04-07 08:09:15 large] (main.py 226): INFO Train: [127/300][1200/2502]	eta 0:13:09 lr 0.000310	time 0.6286 (0.6063)	loss 2.9436 (3.4082)	grad_norm 3.2664 (nan)	mem 8931MB
[2022-04-07 08:10:16 large] (main.py 226): INFO Train: [127/300][1300/2502]	eta 0:12:08 lr 0.000310	time 0.6890 (0.6063)	loss 3.9519 (3.4135)	grad_norm 3.8517 (nan)	mem 8931MB
[2022-04-07 08:11:17 large] (main.py 226): INFO Train: [127/300][1400/2502]	eta 0:11:08 lr 0.000310	time 0.5674 (0.6065)	loss 2.2338 (3.4183)	grad_norm 3.0367 (nan)	mem 8931MB
[2022-04-07 08:12:18 large] (main.py 226): INFO Train: [127/300][1500/2502]	eta 0:10:07 lr 0.000310	time 0.5180 (0.6065)	loss 2.4538 (3.4156)	grad_norm 3.0075 (nan)	mem 8931MB
[2022-04-07 08:13:20 large] (main.py 226): INFO Train: [127/300][1600/2502]	eta 0:09:07 lr 0.000310	time 0.6313 (0.6074)	loss 3.5294 (3.4130)	grad_norm 3.4878 (nan)	mem 8931MB
[2022-04-07 08:14:20 large] (main.py 226): INFO Train: [127/300][1700/2502]	eta 0:08:07 lr 0.000310	time 0.6191 (0.6074)	loss 3.8280 (3.4108)	grad_norm 3.6566 (nan)	mem 8931MB
[2022-04-07 08:15:22 large] (main.py 226): INFO Train: [127/300][1800/2502]	eta 0:07:06 lr 0.000310	time 0.6100 (0.6079)	loss 3.7766 (3.4110)	grad_norm 4.0407 (nan)	mem 8931MB
[2022-04-07 08:16:24 large] (main.py 226): INFO Train: [127/300][1900/2502]	eta 0:06:06 lr 0.000310	time 0.6774 (0.6085)	loss 2.4935 (3.4102)	grad_norm 3.5860 (nan)	mem 8931MB
[2022-04-07 08:17:24 large] (main.py 226): INFO Train: [127/300][2000/2502]	eta 0:05:05 lr 0.000310	time 0.5611 (0.6079)	loss 3.6348 (3.4123)	grad_norm 3.2607 (nan)	mem 8931MB
[2022-04-07 08:18:25 large] (main.py 226): INFO Train: [127/300][2100/2502]	eta 0:04:04 lr 0.000309	time 0.6289 (0.6081)	loss 3.8110 (3.4113)	grad_norm 2.5798 (nan)	mem 8931MB
[2022-04-07 08:19:26 large] (main.py 226): INFO Train: [127/300][2200/2502]	eta 0:03:03 lr 0.000309	time 0.6326 (0.6081)	loss 3.7423 (3.4151)	grad_norm 4.3915 (nan)	mem 8931MB
[2022-04-07 08:20:27 large] (main.py 226): INFO Train: [127/300][2300/2502]	eta 0:02:02 lr 0.000309	time 0.5792 (0.6083)	loss 3.2306 (3.4168)	grad_norm 3.5165 (nan)	mem 8931MB
[2022-04-07 08:21:27 large] (main.py 226): INFO Train: [127/300][2400/2502]	eta 0:01:01 lr 0.000309	time 0.6205 (0.6078)	loss 2.2121 (3.4194)	grad_norm 3.6724 (nan)	mem 8931MB
[2022-04-07 08:22:28 large] (main.py 226): INFO Train: [127/300][2500/2502]	eta 0:00:01 lr 0.000309	time 0.5340 (0.6080)	loss 3.8205 (3.4238)	grad_norm 3.1196 (nan)	mem 8931MB
[2022-04-07 08:22:29 large] (main.py 233): INFO EPOCH 127 training takes 0:25:21
[2022-04-07 08:22:35 large] (main.py 273): INFO Test: [0/98]	Time 5.969 (5.969)	Loss 1.1926 (1.1926)	Acc@1 74.414 (74.414)	Acc@5 93.359 (93.359)	Mem 8931MB
[2022-04-07 08:23:01 large] (main.py 279): INFO  * Acc@1 76.092 Acc@5 93.152
[2022-04-07 08:23:01 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 76.1%
[2022-04-07 08:23:01 large] (main.py 148): INFO Max accuracy: 76.46%
[2022-04-07 08:23:09 large] (main.py 226): INFO Train: [128/300][0/2502]	eta 5:06:57 lr 0.000309	time 7.3611 (7.3611)	loss 4.0496 (4.0496)	grad_norm 3.7073 (3.7073)	mem 8931MB
[2022-04-07 08:23:59 large] (main.py 226): INFO Train: [128/300][100/2502]	eta 0:22:57 lr 0.000309	time 0.5246 (0.5736)	loss 3.9907 (3.3501)	grad_norm 3.0727 (3.3204)	mem 8931MB
[2022-04-07 08:25:01 large] (main.py 226): INFO Train: [128/300][200/2502]	eta 0:22:43 lr 0.000309	time 0.6011 (0.5925)	loss 2.8977 (3.3966)	grad_norm 3.9172 (3.2772)	mem 8931MB
[2022-04-07 08:26:03 large] (main.py 226): INFO Train: [128/300][300/2502]	eta 0:22:05 lr 0.000309	time 0.6183 (0.6019)	loss 3.3814 (3.3967)	grad_norm 2.8165 (3.2930)	mem 8931MB
[2022-04-07 08:27:05 large] (main.py 226): INFO Train: [128/300][400/2502]	eta 0:21:14 lr 0.000309	time 0.6012 (0.6063)	loss 2.6999 (3.4187)	grad_norm 3.4208 (3.3133)	mem 8931MB
[2022-04-07 08:28:05 large] (main.py 226): INFO Train: [128/300][500/2502]	eta 0:20:13 lr 0.000309	time 0.5357 (0.6061)	loss 3.7926 (3.4299)	grad_norm 3.1179 (3.3018)	mem 8931MB
[2022-04-07 08:29:06 large] (main.py 226): INFO Train: [128/300][600/2502]	eta 0:19:12 lr 0.000308	time 0.7018 (0.6057)	loss 4.1355 (3.4218)	grad_norm 3.7572 (3.3046)	mem 8931MB
[2022-04-07 08:30:06 large] (main.py 226): INFO Train: [128/300][700/2502]	eta 0:18:11 lr 0.000308	time 0.6981 (0.6055)	loss 4.0920 (3.4259)	grad_norm 3.7593 (3.3147)	mem 8931MB
[2022-04-07 08:31:06 large] (main.py 226): INFO Train: [128/300][800/2502]	eta 0:17:10 lr 0.000308	time 0.6466 (0.6052)	loss 2.8741 (3.4232)	grad_norm 2.7559 (3.3227)	mem 8931MB
[2022-04-07 08:32:06 large] (main.py 226): INFO Train: [128/300][900/2502]	eta 0:16:08 lr 0.000308	time 0.6320 (0.6044)	loss 4.1284 (3.4224)	grad_norm 4.1458 (3.3338)	mem 8931MB
[2022-04-07 08:33:06 large] (main.py 226): INFO Train: [128/300][1000/2502]	eta 0:15:07 lr 0.000308	time 0.7231 (0.6039)	loss 3.5782 (3.4208)	grad_norm 3.2192 (3.3232)	mem 8931MB
[2022-04-07 08:34:07 large] (main.py 226): INFO Train: [128/300][1100/2502]	eta 0:14:07 lr 0.000308	time 0.5744 (0.6044)	loss 4.1409 (3.4281)	grad_norm 2.8393 (3.3176)	mem 8931MB
[2022-04-07 08:35:07 large] (main.py 226): INFO Train: [128/300][1200/2502]	eta 0:13:06 lr 0.000308	time 0.5804 (0.6037)	loss 3.4871 (3.4264)	grad_norm 3.0282 (3.3198)	mem 8931MB
[2022-04-07 08:36:07 large] (main.py 226): INFO Train: [128/300][1300/2502]	eta 0:12:05 lr 0.000308	time 0.6017 (0.6035)	loss 2.6419 (3.4293)	grad_norm 3.5710 (3.3168)	mem 8931MB
[2022-04-07 08:37:07 large] (main.py 226): INFO Train: [128/300][1400/2502]	eta 0:11:05 lr 0.000308	time 0.6345 (0.6038)	loss 2.5309 (3.4280)	grad_norm 3.2270 (3.3183)	mem 8931MB
[2022-04-07 08:38:08 large] (main.py 226): INFO Train: [128/300][1500/2502]	eta 0:10:05 lr 0.000308	time 0.6137 (0.6039)	loss 4.1742 (3.4260)	grad_norm 4.5355 (3.3178)	mem 8931MB
[2022-04-07 08:39:07 large] (main.py 226): INFO Train: [128/300][1600/2502]	eta 0:09:04 lr 0.000307	time 0.5710 (0.6032)	loss 2.5875 (3.4245)	grad_norm 3.5399 (3.3242)	mem 8931MB
[2022-04-07 08:40:08 large] (main.py 226): INFO Train: [128/300][1700/2502]	eta 0:08:03 lr 0.000307	time 0.7094 (0.6033)	loss 4.1896 (3.4233)	grad_norm 3.7941 (3.3306)	mem 8931MB
[2022-04-07 08:41:02 large] (main.py 226): INFO Train: [128/300][1800/2502]	eta 0:07:01 lr 0.000307	time 0.5564 (0.6001)	loss 3.7622 (3.4272)	grad_norm 3.7697 (3.3351)	mem 8931MB
[2022-04-07 08:42:02 large] (main.py 226): INFO Train: [128/300][1900/2502]	eta 0:06:01 lr 0.000307	time 0.5797 (0.6000)	loss 3.5900 (3.4250)	grad_norm 3.2838 (3.3340)	mem 8931MB
[2022-04-07 08:43:02 large] (main.py 226): INFO Train: [128/300][2000/2502]	eta 0:05:01 lr 0.000307	time 0.5595 (0.5999)	loss 2.7857 (3.4281)	grad_norm 3.0119 (3.3397)	mem 8931MB
[2022-04-07 08:44:02 large] (main.py 226): INFO Train: [128/300][2100/2502]	eta 0:04:01 lr 0.000307	time 0.6081 (0.6001)	loss 4.3729 (3.4298)	grad_norm 3.0563 (3.3356)	mem 8931MB
[2022-04-07 08:45:03 large] (main.py 226): INFO Train: [128/300][2200/2502]	eta 0:03:01 lr 0.000307	time 0.6496 (0.6004)	loss 2.2549 (3.4324)	grad_norm 3.1427 (3.3371)	mem 8931MB
[2022-04-07 08:46:04 large] (main.py 226): INFO Train: [128/300][2300/2502]	eta 0:02:01 lr 0.000307	time 0.7110 (0.6007)	loss 3.4960 (3.4310)	grad_norm 3.1330 (nan)	mem 8931MB
[2022-04-07 08:47:05 large] (main.py 226): INFO Train: [128/300][2400/2502]	eta 0:01:01 lr 0.000307	time 0.5898 (0.6011)	loss 4.1414 (3.4318)	grad_norm 3.2817 (nan)	mem 8931MB
[2022-04-07 08:48:05 large] (main.py 226): INFO Train: [128/300][2500/2502]	eta 0:00:01 lr 0.000306	time 0.5827 (0.6010)	loss 3.8508 (3.4351)	grad_norm 2.7442 (nan)	mem 8931MB
[2022-04-07 08:48:06 large] (main.py 233): INFO EPOCH 128 training takes 0:25:04
[2022-04-07 08:48:11 large] (main.py 273): INFO Test: [0/98]	Time 5.693 (5.693)	Loss 1.1440 (1.1440)	Acc@1 78.711 (78.711)	Acc@5 92.969 (92.969)	Mem 8931MB
[2022-04-07 08:48:38 large] (main.py 279): INFO  * Acc@1 76.528 Acc@5 93.488
[2022-04-07 08:48:38 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 76.5%
[2022-04-07 08:48:38 large] (utils.py 57): INFO output/large/default/ckpt_epoch_128.pth saving......
[2022-04-07 08:48:39 large] (utils.py 59): INFO output/large/default/ckpt_epoch_128.pth saved !!!
[2022-04-07 08:48:39 large] (main.py 148): INFO Max accuracy: 76.53%
[2022-04-07 08:48:47 large] (main.py 226): INFO Train: [129/300][0/2502]	eta 5:51:58 lr 0.000306	time 8.4408 (8.4408)	loss 3.7753 (3.7753)	grad_norm 2.9112 (2.9112)	mem 8931MB
[2022-04-07 08:49:42 large] (main.py 226): INFO Train: [129/300][100/2502]	eta 0:25:11 lr 0.000306	time 0.5731 (0.6291)	loss 4.3479 (3.3906)	grad_norm 4.7144 (3.3224)	mem 8931MB
[2022-04-07 08:50:44 large] (main.py 226): INFO Train: [129/300][200/2502]	eta 0:23:51 lr 0.000306	time 0.7204 (0.6218)	loss 3.7731 (3.4066)	grad_norm 3.2186 (3.3411)	mem 8931MB
[2022-04-07 08:51:45 large] (main.py 226): INFO Train: [129/300][300/2502]	eta 0:22:42 lr 0.000306	time 0.6282 (0.6190)	loss 3.7078 (3.3981)	grad_norm 3.5778 (3.3419)	mem 8931MB
[2022-04-07 08:52:46 large] (main.py 226): INFO Train: [129/300][400/2502]	eta 0:21:33 lr 0.000306	time 0.6573 (0.6156)	loss 3.4178 (3.3758)	grad_norm 5.6452 (3.3483)	mem 8931MB
[2022-04-07 08:53:47 large] (main.py 226): INFO Train: [129/300][500/2502]	eta 0:20:31 lr 0.000306	time 0.6505 (0.6150)	loss 2.7655 (3.3813)	grad_norm 3.5127 (3.3355)	mem 8931MB
[2022-04-07 08:54:48 large] (main.py 226): INFO Train: [129/300][600/2502]	eta 0:19:28 lr 0.000306	time 0.6311 (0.6145)	loss 4.0090 (3.3902)	grad_norm 3.3018 (3.3460)	mem 8931MB
[2022-04-07 08:55:48 large] (main.py 226): INFO Train: [129/300][700/2502]	eta 0:18:23 lr 0.000306	time 0.6092 (0.6126)	loss 4.0790 (3.3951)	grad_norm 3.6351 (3.3362)	mem 8931MB
[2022-04-07 08:56:48 large] (main.py 226): INFO Train: [129/300][800/2502]	eta 0:17:19 lr 0.000306	time 0.6082 (0.6107)	loss 3.3496 (3.3959)	grad_norm 3.0536 (3.3442)	mem 8931MB
[2022-04-07 08:57:47 large] (main.py 226): INFO Train: [129/300][900/2502]	eta 0:16:15 lr 0.000306	time 0.6079 (0.6089)	loss 3.7251 (3.4020)	grad_norm 2.4468 (3.3550)	mem 8931MB
[2022-04-07 08:58:47 large] (main.py 226): INFO Train: [129/300][1000/2502]	eta 0:15:13 lr 0.000305	time 0.6193 (0.6082)	loss 3.7118 (3.4082)	grad_norm 3.4950 (3.3672)	mem 8931MB
[2022-04-07 08:59:48 large] (main.py 226): INFO Train: [129/300][1100/2502]	eta 0:14:11 lr 0.000305	time 0.5535 (0.6077)	loss 3.5789 (3.4105)	grad_norm 3.1277 (3.3702)	mem 8931MB
[2022-04-07 09:00:46 large] (main.py 226): INFO Train: [129/300][1200/2502]	eta 0:13:08 lr 0.000305	time 0.5980 (0.6056)	loss 4.0018 (3.4045)	grad_norm 3.1578 (3.3689)	mem 8931MB
[2022-04-07 09:01:46 large] (main.py 226): INFO Train: [129/300][1300/2502]	eta 0:12:07 lr 0.000305	time 0.6688 (0.6055)	loss 2.3611 (3.4023)	grad_norm 3.1982 (3.3666)	mem 8931MB
[2022-04-07 09:02:47 large] (main.py 226): INFO Train: [129/300][1400/2502]	eta 0:11:07 lr 0.000305	time 0.5997 (0.6053)	loss 3.7326 (3.4088)	grad_norm 3.1026 (3.3673)	mem 8931MB
[2022-04-07 09:03:48 large] (main.py 226): INFO Train: [129/300][1500/2502]	eta 0:10:06 lr 0.000305	time 0.6595 (0.6057)	loss 3.0003 (3.4081)	grad_norm 3.1646 (3.3637)	mem 8931MB
[2022-04-07 09:04:44 large] (main.py 226): INFO Train: [129/300][1600/2502]	eta 0:09:03 lr 0.000305	time 0.4931 (0.6030)	loss 3.6103 (3.4083)	grad_norm 4.6137 (3.3653)	mem 8931MB
[2022-04-07 09:05:43 large] (main.py 226): INFO Train: [129/300][1700/2502]	eta 0:08:02 lr 0.000305	time 0.5917 (0.6019)	loss 2.9450 (3.4084)	grad_norm 3.6358 (3.3694)	mem 8931MB
[2022-04-07 09:06:42 large] (main.py 226): INFO Train: [129/300][1800/2502]	eta 0:07:02 lr 0.000305	time 0.6432 (0.6016)	loss 2.9873 (3.4043)	grad_norm 3.3884 (3.3724)	mem 8931MB
[2022-04-07 09:07:42 large] (main.py 226): INFO Train: [129/300][1900/2502]	eta 0:06:02 lr 0.000305	time 0.5989 (0.6017)	loss 2.8647 (3.3992)	grad_norm 4.7788 (3.3710)	mem 8931MB
[2022-04-07 09:08:42 large] (main.py 226): INFO Train: [129/300][2000/2502]	eta 0:05:01 lr 0.000304	time 0.5349 (0.6015)	loss 3.6807 (3.4023)	grad_norm 4.2631 (3.3627)	mem 8931MB
[2022-04-07 09:09:43 large] (main.py 226): INFO Train: [129/300][2100/2502]	eta 0:04:01 lr 0.000304	time 0.6330 (0.6016)	loss 3.2707 (3.4009)	grad_norm 3.2107 (3.3620)	mem 8931MB
[2022-04-07 09:10:42 large] (main.py 226): INFO Train: [129/300][2200/2502]	eta 0:03:01 lr 0.000304	time 0.5074 (0.6011)	loss 3.8038 (3.3999)	grad_norm 2.3697 (3.3634)	mem 8931MB
[2022-04-07 09:11:42 large] (main.py 226): INFO Train: [129/300][2300/2502]	eta 0:02:01 lr 0.000304	time 0.5804 (0.6012)	loss 2.6085 (3.4046)	grad_norm 2.7879 (3.3628)	mem 8931MB
[2022-04-07 09:12:43 large] (main.py 226): INFO Train: [129/300][2400/2502]	eta 0:01:01 lr 0.000304	time 0.6326 (0.6015)	loss 3.1670 (3.4048)	grad_norm 3.5017 (3.3627)	mem 8931MB
[2022-04-07 09:13:43 large] (main.py 226): INFO Train: [129/300][2500/2502]	eta 0:00:01 lr 0.000304	time 0.5761 (0.6016)	loss 3.9287 (3.4056)	grad_norm 3.3563 (3.3618)	mem 8931MB
[2022-04-07 09:13:44 large] (main.py 233): INFO EPOCH 129 training takes 0:25:05
[2022-04-07 09:13:50 large] (main.py 273): INFO Test: [0/98]	Time 6.029 (6.029)	Loss 1.2230 (1.2230)	Acc@1 74.023 (74.023)	Acc@5 92.773 (92.773)	Mem 8931MB
[2022-04-07 09:14:16 large] (main.py 279): INFO  * Acc@1 76.386 Acc@5 93.278
[2022-04-07 09:14:16 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 76.4%
[2022-04-07 09:14:16 large] (main.py 148): INFO Max accuracy: 76.53%
[2022-04-07 09:14:23 large] (main.py 226): INFO Train: [130/300][0/2502]	eta 4:54:13 lr 0.000304	time 7.0559 (7.0559)	loss 3.6218 (3.6218)	grad_norm 2.9225 (2.9225)	mem 8931MB
[2022-04-07 09:15:19 large] (main.py 226): INFO Train: [130/300][100/2502]	eta 0:24:39 lr 0.000304	time 0.5556 (0.6158)	loss 3.7169 (3.4720)	grad_norm 2.4335 (3.4055)	mem 8931MB
[2022-04-07 09:16:20 large] (main.py 226): INFO Train: [130/300][200/2502]	eta 0:23:38 lr 0.000304	time 0.6348 (0.6164)	loss 4.0352 (3.4235)	grad_norm 3.1756 (3.3718)	mem 8931MB
[2022-04-07 09:17:23 large] (main.py 226): INFO Train: [130/300][300/2502]	eta 0:22:45 lr 0.000304	time 0.6311 (0.6200)	loss 2.5149 (3.4153)	grad_norm 2.9261 (3.3996)	mem 8931MB
[2022-04-07 09:18:25 large] (main.py 226): INFO Train: [130/300][400/2502]	eta 0:21:42 lr 0.000304	time 0.5713 (0.6196)	loss 3.7541 (3.4334)	grad_norm 3.7664 (3.3858)	mem 8931MB
[2022-04-07 09:19:26 large] (main.py 226): INFO Train: [130/300][500/2502]	eta 0:20:36 lr 0.000303	time 0.5549 (0.6177)	loss 2.6150 (3.4269)	grad_norm 2.7759 (3.3801)	mem 8931MB
[2022-04-07 09:20:27 large] (main.py 226): INFO Train: [130/300][600/2502]	eta 0:19:33 lr 0.000303	time 0.5958 (0.6172)	loss 3.5526 (3.4273)	grad_norm 2.6927 (3.3883)	mem 8931MB
[2022-04-07 09:21:29 large] (main.py 226): INFO Train: [130/300][700/2502]	eta 0:18:33 lr 0.000303	time 0.5663 (0.6178)	loss 3.7035 (3.4345)	grad_norm 2.9944 (3.3989)	mem 8931MB
[2022-04-07 09:22:30 large] (main.py 226): INFO Train: [130/300][800/2502]	eta 0:17:28 lr 0.000303	time 0.6207 (0.6162)	loss 3.3955 (3.4422)	grad_norm 3.8365 (3.3974)	mem 8931MB
[2022-04-07 09:23:32 large] (main.py 226): INFO Train: [130/300][900/2502]	eta 0:16:27 lr 0.000303	time 0.6626 (0.6163)	loss 2.5280 (3.4336)	grad_norm 4.1532 (3.3930)	mem 8931MB
[2022-04-07 09:24:31 large] (main.py 226): INFO Train: [130/300][1000/2502]	eta 0:15:22 lr 0.000303	time 0.5663 (0.6141)	loss 2.9338 (3.4273)	grad_norm 2.8050 (3.3828)	mem 8931MB
[2022-04-07 09:25:28 large] (main.py 226): INFO Train: [130/300][1100/2502]	eta 0:14:15 lr 0.000303	time 0.5120 (0.6101)	loss 2.4002 (3.4263)	grad_norm 3.6688 (3.3733)	mem 8931MB
[2022-04-07 09:26:26 large] (main.py 226): INFO Train: [130/300][1200/2502]	eta 0:13:11 lr 0.000303	time 0.6334 (0.6078)	loss 3.2913 (3.4276)	grad_norm 2.5999 (3.3715)	mem 8931MB
[2022-04-07 09:27:27 large] (main.py 226): INFO Train: [130/300][1300/2502]	eta 0:12:10 lr 0.000303	time 0.6028 (0.6077)	loss 3.1471 (3.4278)	grad_norm 3.1848 (3.3661)	mem 8931MB
[2022-04-07 09:28:28 large] (main.py 226): INFO Train: [130/300][1400/2502]	eta 0:11:10 lr 0.000303	time 0.5917 (0.6081)	loss 3.5615 (3.4254)	grad_norm 3.8406 (3.3678)	mem 8931MB
[2022-04-07 09:29:30 large] (main.py 226): INFO Train: [130/300][1500/2502]	eta 0:10:10 lr 0.000302	time 0.6471 (0.6089)	loss 3.1329 (3.4271)	grad_norm 2.9051 (3.3726)	mem 8931MB
[2022-04-07 09:30:31 large] (main.py 226): INFO Train: [130/300][1600/2502]	eta 0:09:09 lr 0.000302	time 0.5748 (0.6090)	loss 4.1721 (3.4266)	grad_norm 3.2384 (3.3660)	mem 8931MB
[2022-04-07 09:31:34 large] (main.py 226): INFO Train: [130/300][1700/2502]	eta 0:08:09 lr 0.000302	time 0.6106 (0.6098)	loss 3.7598 (3.4249)	grad_norm 3.9320 (3.3657)	mem 8931MB
[2022-04-07 09:32:28 large] (main.py 226): INFO Train: [130/300][1800/2502]	eta 0:07:05 lr 0.000302	time 0.4851 (0.6062)	loss 3.9111 (3.4206)	grad_norm 4.1737 (3.3585)	mem 8931MB
[2022-04-07 09:33:24 large] (main.py 226): INFO Train: [130/300][1900/2502]	eta 0:06:03 lr 0.000302	time 0.6602 (0.6039)	loss 4.0216 (3.4201)	grad_norm 3.9498 (3.3625)	mem 8931MB
[2022-04-07 09:34:25 large] (main.py 226): INFO Train: [130/300][2000/2502]	eta 0:05:03 lr 0.000302	time 0.5561 (0.6042)	loss 3.7507 (3.4228)	grad_norm 4.4167 (nan)	mem 8931MB
[2022-04-07 09:35:29 large] (main.py 226): INFO Train: [130/300][2100/2502]	eta 0:04:03 lr 0.000302	time 0.5601 (0.6056)	loss 2.2551 (3.4270)	grad_norm 2.4798 (nan)	mem 8931MB
[2022-04-07 09:36:30 large] (main.py 226): INFO Train: [130/300][2200/2502]	eta 0:03:02 lr 0.000302	time 0.6942 (0.6059)	loss 2.8682 (3.4268)	grad_norm 9.3109 (nan)	mem 8931MB
[2022-04-07 09:37:32 large] (main.py 226): INFO Train: [130/300][2300/2502]	eta 0:02:02 lr 0.000302	time 0.6504 (0.6065)	loss 2.9097 (3.4270)	grad_norm 3.2404 (nan)	mem 8931MB
[2022-04-07 09:38:34 large] (main.py 226): INFO Train: [130/300][2400/2502]	eta 0:01:01 lr 0.000302	time 0.5500 (0.6070)	loss 3.6670 (3.4297)	grad_norm 2.8159 (nan)	mem 8931MB
[2022-04-07 09:39:34 large] (main.py 226): INFO Train: [130/300][2500/2502]	eta 0:00:01 lr 0.000301	time 0.5077 (0.6069)	loss 3.5300 (3.4309)	grad_norm 2.9047 (nan)	mem 8931MB
[2022-04-07 09:39:35 large] (main.py 233): INFO EPOCH 130 training takes 0:25:18
[2022-04-07 09:39:42 large] (main.py 273): INFO Test: [0/98]	Time 6.397 (6.397)	Loss 1.0938 (1.0938)	Acc@1 74.414 (74.414)	Acc@5 93.945 (93.945)	Mem 8931MB
[2022-04-07 09:40:08 large] (main.py 279): INFO  * Acc@1 76.630 Acc@5 93.494
[2022-04-07 09:40:08 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 76.6%
[2022-04-07 09:40:08 large] (utils.py 57): INFO output/large/default/ckpt_epoch_130.pth saving......
[2022-04-07 09:40:08 large] (utils.py 59): INFO output/large/default/ckpt_epoch_130.pth saved !!!
[2022-04-07 09:40:08 large] (main.py 148): INFO Max accuracy: 76.63%
[2022-04-07 09:40:17 large] (main.py 226): INFO Train: [131/300][0/2502]	eta 5:39:12 lr 0.000301	time 8.1344 (8.1344)	loss 3.5420 (3.5420)	grad_norm 3.1139 (3.1139)	mem 8931MB
[2022-04-07 09:41:06 large] (main.py 226): INFO Train: [131/300][100/2502]	eta 0:23:01 lr 0.000301	time 0.5376 (0.5750)	loss 3.7733 (3.3392)	grad_norm 4.5307 (3.4141)	mem 8931MB
[2022-04-07 09:42:08 large] (main.py 226): INFO Train: [131/300][200/2502]	eta 0:22:44 lr 0.000301	time 0.6215 (0.5925)	loss 4.1181 (3.3721)	grad_norm 3.5038 (3.3783)	mem 8931MB
[2022-04-07 09:43:09 large] (main.py 226): INFO Train: [131/300][300/2502]	eta 0:22:01 lr 0.000301	time 0.5324 (0.6003)	loss 2.4859 (3.3695)	grad_norm 2.7321 (3.3665)	mem 8931MB
[2022-04-07 09:44:10 large] (main.py 226): INFO Train: [131/300][400/2502]	eta 0:21:07 lr 0.000301	time 0.5808 (0.6030)	loss 2.4535 (3.3769)	grad_norm 4.2903 (3.3673)	mem 8931MB
[2022-04-07 09:45:11 large] (main.py 226): INFO Train: [131/300][500/2502]	eta 0:20:09 lr 0.000301	time 0.6089 (0.6043)	loss 3.8536 (3.3903)	grad_norm 3.3414 (3.3959)	mem 8931MB
[2022-04-07 09:46:14 large] (main.py 226): INFO Train: [131/300][600/2502]	eta 0:19:16 lr 0.000301	time 0.5987 (0.6081)	loss 3.4881 (3.4060)	grad_norm 3.0624 (nan)	mem 8931MB
[2022-04-07 09:47:16 large] (main.py 226): INFO Train: [131/300][700/2502]	eta 0:18:18 lr 0.000301	time 0.6028 (0.6093)	loss 3.5425 (3.4034)	grad_norm 3.4418 (nan)	mem 8931MB
[2022-04-07 09:48:16 large] (main.py 226): INFO Train: [131/300][800/2502]	eta 0:17:16 lr 0.000301	time 0.4805 (0.6092)	loss 4.3373 (3.4038)	grad_norm 2.9699 (nan)	mem 8931MB
[2022-04-07 09:49:12 large] (main.py 226): INFO Train: [131/300][900/2502]	eta 0:16:06 lr 0.000301	time 0.6084 (0.6034)	loss 4.0984 (3.4130)	grad_norm 4.9568 (nan)	mem 8931MB
[2022-04-07 09:50:13 large] (main.py 226): INFO Train: [131/300][1000/2502]	eta 0:15:07 lr 0.000300	time 0.5897 (0.6044)	loss 3.4661 (3.4201)	grad_norm 3.1301 (nan)	mem 8931MB
[2022-04-07 09:51:16 large] (main.py 226): INFO Train: [131/300][1100/2502]	eta 0:14:09 lr 0.000300	time 0.5143 (0.6060)	loss 2.8759 (3.4192)	grad_norm 3.6519 (nan)	mem 8931MB
[2022-04-07 09:52:18 large] (main.py 226): INFO Train: [131/300][1200/2502]	eta 0:13:11 lr 0.000300	time 0.5193 (0.6076)	loss 2.5947 (3.4210)	grad_norm 3.0848 (nan)	mem 8931MB
[2022-04-07 09:53:19 large] (main.py 226): INFO Train: [131/300][1300/2502]	eta 0:12:10 lr 0.000300	time 0.5766 (0.6077)	loss 3.3586 (3.4200)	grad_norm 3.7897 (nan)	mem 8931MB
[2022-04-07 09:54:20 large] (main.py 226): INFO Train: [131/300][1400/2502]	eta 0:11:09 lr 0.000300	time 0.6723 (0.6079)	loss 4.1846 (3.4146)	grad_norm 2.9346 (nan)	mem 8931MB
[2022-04-07 09:55:20 large] (main.py 226): INFO Train: [131/300][1500/2502]	eta 0:10:08 lr 0.000300	time 0.4992 (0.6075)	loss 3.6347 (3.4141)	grad_norm 4.9078 (nan)	mem 8931MB
[2022-04-07 09:56:21 large] (main.py 226): INFO Train: [131/300][1600/2502]	eta 0:09:08 lr 0.000300	time 0.5881 (0.6078)	loss 3.4188 (3.4161)	grad_norm 2.8893 (nan)	mem 8931MB
[2022-04-07 09:57:24 large] (main.py 226): INFO Train: [131/300][1700/2502]	eta 0:08:08 lr 0.000300	time 0.4983 (0.6086)	loss 3.5340 (3.4156)	grad_norm 3.7583 (nan)	mem 8931MB
[2022-04-07 09:58:25 large] (main.py 226): INFO Train: [131/300][1800/2502]	eta 0:07:07 lr 0.000300	time 0.5593 (0.6088)	loss 3.4105 (3.4137)	grad_norm 3.6883 (nan)	mem 8931MB
[2022-04-07 09:59:27 large] (main.py 226): INFO Train: [131/300][1900/2502]	eta 0:06:06 lr 0.000299	time 0.6109 (0.6093)	loss 4.1121 (3.4181)	grad_norm 3.7951 (nan)	mem 8931MB
[2022-04-07 10:00:28 large] (main.py 226): INFO Train: [131/300][2000/2502]	eta 0:05:06 lr 0.000299	time 0.6045 (0.6096)	loss 4.1338 (3.4216)	grad_norm 4.5196 (nan)	mem 8931MB
[2022-04-07 10:01:29 large] (main.py 226): INFO Train: [131/300][2100/2502]	eta 0:04:05 lr 0.000299	time 0.6198 (0.6097)	loss 3.9263 (3.4186)	grad_norm 3.3744 (nan)	mem 8931MB
[2022-04-07 10:02:31 large] (main.py 226): INFO Train: [131/300][2200/2502]	eta 0:03:04 lr 0.000299	time 0.5364 (0.6099)	loss 4.2940 (3.4196)	grad_norm 3.7970 (nan)	mem 8931MB
[2022-04-07 10:03:33 large] (main.py 226): INFO Train: [131/300][2300/2502]	eta 0:02:03 lr 0.000299	time 0.5607 (0.6104)	loss 3.1205 (3.4197)	grad_norm 4.6747 (nan)	mem 8931MB
[2022-04-07 10:04:34 large] (main.py 226): INFO Train: [131/300][2400/2502]	eta 0:01:02 lr 0.000299	time 0.6669 (0.6104)	loss 3.0540 (3.4184)	grad_norm 3.4714 (nan)	mem 8931MB
[2022-04-07 10:05:35 large] (main.py 226): INFO Train: [131/300][2500/2502]	eta 0:00:01 lr 0.000299	time 0.6072 (0.6106)	loss 3.8761 (3.4232)	grad_norm 2.5175 (nan)	mem 8931MB
[2022-04-07 10:05:36 large] (main.py 233): INFO EPOCH 131 training takes 0:25:28
[2022-04-07 10:05:42 large] (main.py 273): INFO Test: [0/98]	Time 5.996 (5.996)	Loss 1.1411 (1.1411)	Acc@1 76.367 (76.367)	Acc@5 94.727 (94.727)	Mem 8931MB
[2022-04-07 10:06:08 large] (main.py 279): INFO  * Acc@1 76.362 Acc@5 93.466
[2022-04-07 10:06:08 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 76.4%
[2022-04-07 10:06:08 large] (main.py 148): INFO Max accuracy: 76.63%
[2022-04-07 10:06:16 large] (main.py 226): INFO Train: [132/300][0/2502]	eta 5:08:37 lr 0.000299	time 7.4010 (7.4010)	loss 3.7409 (3.7409)	grad_norm 2.8209 (2.8209)	mem 8931MB
[2022-04-07 10:07:12 large] (main.py 226): INFO Train: [132/300][100/2502]	eta 0:25:06 lr 0.000299	time 0.6336 (0.6270)	loss 3.0768 (3.3587)	grad_norm 3.1720 (3.3826)	mem 8931MB
[2022-04-07 10:08:15 large] (main.py 226): INFO Train: [132/300][200/2502]	eta 0:24:08 lr 0.000299	time 0.5818 (0.6294)	loss 3.4443 (3.3867)	grad_norm 3.6713 (3.4500)	mem 8931MB
[2022-04-07 10:09:18 large] (main.py 226): INFO Train: [132/300][300/2502]	eta 0:23:07 lr 0.000299	time 0.6410 (0.6303)	loss 3.2554 (3.3878)	grad_norm 2.7833 (3.4487)	mem 8931MB
[2022-04-07 10:10:21 large] (main.py 226): INFO Train: [132/300][400/2502]	eta 0:22:05 lr 0.000298	time 0.6524 (0.6306)	loss 3.5566 (3.3964)	grad_norm 3.3732 (3.4400)	mem 8931MB
[2022-04-07 10:11:23 large] (main.py 226): INFO Train: [132/300][500/2502]	eta 0:20:58 lr 0.000298	time 0.5869 (0.6287)	loss 3.5076 (3.3838)	grad_norm 3.6173 (3.4251)	mem 8931MB
[2022-04-07 10:12:26 large] (main.py 226): INFO Train: [132/300][600/2502]	eta 0:19:55 lr 0.000298	time 0.6380 (0.6286)	loss 2.3751 (3.3876)	grad_norm 3.5121 (3.4273)	mem 8931MB
[2022-04-07 10:13:28 large] (main.py 226): INFO Train: [132/300][700/2502]	eta 0:18:49 lr 0.000298	time 0.5885 (0.6267)	loss 3.6240 (3.3912)	grad_norm 3.2852 (3.4135)	mem 8931MB
[2022-04-07 10:14:29 large] (main.py 226): INFO Train: [132/300][800/2502]	eta 0:17:44 lr 0.000298	time 0.6054 (0.6253)	loss 2.9897 (3.3797)	grad_norm 3.7249 (3.3972)	mem 8931MB
[2022-04-07 10:15:32 large] (main.py 226): INFO Train: [132/300][900/2502]	eta 0:16:41 lr 0.000298	time 0.4976 (0.6251)	loss 4.1798 (3.3814)	grad_norm 3.7600 (3.3999)	mem 8931MB
[2022-04-07 10:16:34 large] (main.py 226): INFO Train: [132/300][1000/2502]	eta 0:15:38 lr 0.000298	time 0.5975 (0.6248)	loss 3.5135 (3.3846)	grad_norm 3.8804 (3.4067)	mem 8931MB
[2022-04-07 10:17:36 large] (main.py 226): INFO Train: [132/300][1100/2502]	eta 0:14:35 lr 0.000298	time 0.6320 (0.6243)	loss 3.6930 (3.3901)	grad_norm 3.7953 (3.4138)	mem 8931MB
[2022-04-07 10:18:38 large] (main.py 226): INFO Train: [132/300][1200/2502]	eta 0:13:32 lr 0.000298	time 0.6462 (0.6240)	loss 4.0564 (3.3949)	grad_norm 3.2004 (3.4111)	mem 8931MB
[2022-04-07 10:19:40 large] (main.py 226): INFO Train: [132/300][1300/2502]	eta 0:12:29 lr 0.000298	time 0.6159 (0.6235)	loss 3.6084 (3.4029)	grad_norm 3.0276 (3.4052)	mem 8931MB
[2022-04-07 10:20:42 large] (main.py 226): INFO Train: [132/300][1400/2502]	eta 0:11:27 lr 0.000297	time 0.6086 (0.6235)	loss 4.0240 (3.4039)	grad_norm 4.3312 (3.4070)	mem 8931MB
[2022-04-07 10:21:44 large] (main.py 226): INFO Train: [132/300][1500/2502]	eta 0:10:24 lr 0.000297	time 0.6920 (0.6234)	loss 3.4455 (3.3979)	grad_norm 3.1312 (3.4081)	mem 8931MB
[2022-04-07 10:22:46 large] (main.py 226): INFO Train: [132/300][1600/2502]	eta 0:09:22 lr 0.000297	time 0.5345 (0.6232)	loss 2.6907 (3.4044)	grad_norm 3.2143 (3.4033)	mem 8931MB
[2022-04-07 10:23:47 large] (main.py 226): INFO Train: [132/300][1700/2502]	eta 0:08:19 lr 0.000297	time 0.4810 (0.6223)	loss 3.3725 (3.4043)	grad_norm 2.6369 (3.4056)	mem 8931MB
[2022-04-07 10:24:36 large] (main.py 226): INFO Train: [132/300][1800/2502]	eta 0:07:11 lr 0.000297	time 0.4813 (0.6151)	loss 3.7006 (3.4023)	grad_norm 3.4819 (3.4059)	mem 8931MB
[2022-04-07 10:25:34 large] (main.py 226): INFO Train: [132/300][1900/2502]	eta 0:06:09 lr 0.000297	time 0.6627 (0.6131)	loss 3.6862 (3.3994)	grad_norm 3.2006 (3.4043)	mem 8931MB
[2022-04-07 10:26:36 large] (main.py 226): INFO Train: [132/300][2000/2502]	eta 0:05:07 lr 0.000297	time 0.6086 (0.6134)	loss 4.0753 (3.3978)	grad_norm 3.9214 (3.4010)	mem 8931MB
[2022-04-07 10:27:38 large] (main.py 226): INFO Train: [132/300][2100/2502]	eta 0:04:06 lr 0.000297	time 0.5323 (0.6137)	loss 3.1334 (3.3977)	grad_norm 3.5501 (3.3911)	mem 8931MB
[2022-04-07 10:28:41 large] (main.py 226): INFO Train: [132/300][2200/2502]	eta 0:03:05 lr 0.000297	time 0.7210 (0.6145)	loss 4.3943 (3.3969)	grad_norm 3.0339 (3.4018)	mem 8931MB
[2022-04-07 10:29:44 large] (main.py 226): INFO Train: [132/300][2300/2502]	eta 0:02:04 lr 0.000297	time 0.6524 (0.6150)	loss 3.5258 (3.3985)	grad_norm 3.0596 (3.4016)	mem 8931MB
[2022-04-07 10:30:46 large] (main.py 226): INFO Train: [132/300][2400/2502]	eta 0:01:02 lr 0.000296	time 0.5691 (0.6154)	loss 2.7105 (3.4002)	grad_norm 3.1173 (3.4061)	mem 8931MB
[2022-04-07 10:31:49 large] (main.py 226): INFO Train: [132/300][2500/2502]	eta 0:00:01 lr 0.000296	time 0.6236 (0.6160)	loss 4.0074 (3.4022)	grad_norm 3.4840 (3.4041)	mem 8931MB
[2022-04-07 10:31:50 large] (main.py 233): INFO EPOCH 132 training takes 0:25:41
[2022-04-07 10:31:57 large] (main.py 273): INFO Test: [0/98]	Time 6.846 (6.846)	Loss 1.0961 (1.0961)	Acc@1 76.562 (76.562)	Acc@5 94.922 (94.922)	Mem 8931MB
[2022-04-07 10:32:22 large] (main.py 279): INFO  * Acc@1 76.894 Acc@5 93.560
[2022-04-07 10:32:22 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 76.9%
[2022-04-07 10:32:22 large] (utils.py 57): INFO output/large/default/ckpt_epoch_132.pth saving......
[2022-04-07 10:32:23 large] (utils.py 59): INFO output/large/default/ckpt_epoch_132.pth saved !!!
[2022-04-07 10:32:23 large] (main.py 148): INFO Max accuracy: 76.89%
[2022-04-07 10:32:32 large] (main.py 226): INFO Train: [133/300][0/2502]	eta 5:59:44 lr 0.000296	time 8.6269 (8.6269)	loss 4.0746 (4.0746)	grad_norm 2.7825 (2.7825)	mem 8931MB
[2022-04-07 10:33:30 large] (main.py 226): INFO Train: [133/300][100/2502]	eta 0:26:24 lr 0.000296	time 0.6819 (0.6597)	loss 3.6528 (3.3818)	grad_norm 2.7504 (3.4831)	mem 8931MB
[2022-04-07 10:34:32 large] (main.py 226): INFO Train: [133/300][200/2502]	eta 0:24:37 lr 0.000296	time 0.6030 (0.6419)	loss 3.1298 (3.3931)	grad_norm 2.9636 (3.3868)	mem 8931MB
[2022-04-07 10:35:35 large] (main.py 226): INFO Train: [133/300][300/2502]	eta 0:23:21 lr 0.000296	time 0.6040 (0.6363)	loss 3.4049 (3.3967)	grad_norm 2.6045 (3.3969)	mem 8931MB
[2022-04-07 10:36:37 large] (main.py 226): INFO Train: [133/300][400/2502]	eta 0:22:10 lr 0.000296	time 0.6309 (0.6330)	loss 3.4509 (3.4071)	grad_norm 2.6954 (3.4013)	mem 8931MB
[2022-04-07 10:37:40 large] (main.py 226): INFO Train: [133/300][500/2502]	eta 0:21:05 lr 0.000296	time 0.7198 (0.6322)	loss 3.2780 (3.3893)	grad_norm 2.8009 (3.4308)	mem 8931MB
[2022-04-07 10:38:42 large] (main.py 226): INFO Train: [133/300][600/2502]	eta 0:20:00 lr 0.000296	time 0.6863 (0.6312)	loss 3.7082 (3.3697)	grad_norm 2.4253 (3.4251)	mem 8931MB
[2022-04-07 10:39:45 large] (main.py 226): INFO Train: [133/300][700/2502]	eta 0:18:54 lr 0.000296	time 0.6912 (0.6299)	loss 4.2163 (3.3682)	grad_norm 3.4654 (3.4219)	mem 8931MB
[2022-04-07 10:40:48 large] (main.py 226): INFO Train: [133/300][800/2502]	eta 0:17:52 lr 0.000296	time 0.5875 (0.6300)	loss 3.4684 (3.3634)	grad_norm 3.8499 (3.4193)	mem 8931MB
[2022-04-07 10:41:51 large] (main.py 226): INFO Train: [133/300][900/2502]	eta 0:16:49 lr 0.000295	time 0.6233 (0.6300)	loss 3.6392 (3.3808)	grad_norm 2.9040 (nan)	mem 8931MB
[2022-04-07 10:42:53 large] (main.py 226): INFO Train: [133/300][1000/2502]	eta 0:15:45 lr 0.000295	time 0.6382 (0.6296)	loss 2.3720 (3.3826)	grad_norm 2.7560 (nan)	mem 8931MB
[2022-04-07 10:43:55 large] (main.py 226): INFO Train: [133/300][1100/2502]	eta 0:14:41 lr 0.000295	time 0.6047 (0.6288)	loss 3.5733 (3.3903)	grad_norm 2.8471 (nan)	mem 8931MB
[2022-04-07 10:44:57 large] (main.py 226): INFO Train: [133/300][1200/2502]	eta 0:13:37 lr 0.000295	time 0.6764 (0.6278)	loss 3.6257 (3.3999)	grad_norm 3.8079 (nan)	mem 8931MB
[2022-04-07 10:46:01 large] (main.py 226): INFO Train: [133/300][1300/2502]	eta 0:12:35 lr 0.000295	time 0.5452 (0.6283)	loss 3.6692 (3.4003)	grad_norm 3.9680 (nan)	mem 8931MB
[2022-04-07 10:47:03 large] (main.py 226): INFO Train: [133/300][1400/2502]	eta 0:11:32 lr 0.000295	time 0.6294 (0.6280)	loss 3.9973 (3.4067)	grad_norm 3.5639 (nan)	mem 8931MB
[2022-04-07 10:48:05 large] (main.py 226): INFO Train: [133/300][1500/2502]	eta 0:10:29 lr 0.000295	time 0.7833 (0.6277)	loss 4.1264 (3.4109)	grad_norm 3.3504 (nan)	mem 8931MB
[2022-04-07 10:49:08 large] (main.py 226): INFO Train: [133/300][1600/2502]	eta 0:09:25 lr 0.000295	time 0.6079 (0.6275)	loss 3.6016 (3.4104)	grad_norm 2.9996 (nan)	mem 8931MB
[2022-04-07 10:50:10 large] (main.py 226): INFO Train: [133/300][1700/2502]	eta 0:08:23 lr 0.000295	time 0.6187 (0.6275)	loss 4.1548 (3.4059)	grad_norm 3.5474 (nan)	mem 8931MB
[2022-04-07 10:51:12 large] (main.py 226): INFO Train: [133/300][1800/2502]	eta 0:07:20 lr 0.000294	time 0.5730 (0.6268)	loss 3.4865 (3.4085)	grad_norm 3.5316 (nan)	mem 8931MB
[2022-04-07 10:52:15 large] (main.py 226): INFO Train: [133/300][1900/2502]	eta 0:06:17 lr 0.000294	time 0.5732 (0.6268)	loss 3.1499 (3.4147)	grad_norm 4.4290 (nan)	mem 8931MB
[2022-04-07 10:53:19 large] (main.py 226): INFO Train: [133/300][2000/2502]	eta 0:05:15 lr 0.000294	time 0.6039 (0.6276)	loss 4.0208 (3.4188)	grad_norm 3.2128 (nan)	mem 8931MB
[2022-04-07 10:54:22 large] (main.py 226): INFO Train: [133/300][2100/2502]	eta 0:04:12 lr 0.000294	time 0.6110 (0.6277)	loss 3.6239 (3.4191)	grad_norm 4.0530 (nan)	mem 8931MB
[2022-04-07 10:55:25 large] (main.py 226): INFO Train: [133/300][2200/2502]	eta 0:03:09 lr 0.000294	time 0.5167 (0.6276)	loss 4.2613 (3.4170)	grad_norm 3.3097 (nan)	mem 8931MB
[2022-04-07 10:56:27 large] (main.py 226): INFO Train: [133/300][2300/2502]	eta 0:02:06 lr 0.000294	time 0.6410 (0.6276)	loss 1.9938 (3.4209)	grad_norm 3.7049 (nan)	mem 8931MB
[2022-04-07 10:57:29 large] (main.py 226): INFO Train: [133/300][2400/2502]	eta 0:01:03 lr 0.000294	time 0.6037 (0.6274)	loss 3.7242 (3.4189)	grad_norm 3.8458 (nan)	mem 8931MB
[2022-04-07 10:58:32 large] (main.py 226): INFO Train: [133/300][2500/2502]	eta 0:00:01 lr 0.000294	time 0.5912 (0.6274)	loss 4.4608 (3.4198)	grad_norm 3.5925 (nan)	mem 8931MB
[2022-04-07 10:58:33 large] (main.py 233): INFO EPOCH 133 training takes 0:26:10
[2022-04-07 10:58:39 large] (main.py 273): INFO Test: [0/98]	Time 5.860 (5.860)	Loss 1.1469 (1.1469)	Acc@1 75.781 (75.781)	Acc@5 93.359 (93.359)	Mem 8931MB
[2022-04-07 10:59:06 large] (main.py 279): INFO  * Acc@1 76.608 Acc@5 93.416
[2022-04-07 10:59:06 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 76.6%
[2022-04-07 10:59:06 large] (main.py 148): INFO Max accuracy: 76.89%
[2022-04-07 10:59:13 large] (main.py 226): INFO Train: [134/300][0/2502]	eta 4:50:01 lr 0.000294	time 6.9550 (6.9550)	loss 3.8347 (3.8347)	grad_norm 3.8096 (3.8096)	mem 8931MB
[2022-04-07 11:00:14 large] (main.py 226): INFO Train: [134/300][100/2502]	eta 0:26:53 lr 0.000294	time 0.6263 (0.6718)	loss 2.8056 (3.4019)	grad_norm 3.3305 (3.5822)	mem 8931MB
[2022-04-07 11:01:17 large] (main.py 226): INFO Train: [134/300][200/2502]	eta 0:25:02 lr 0.000294	time 0.6463 (0.6526)	loss 3.1479 (3.3955)	grad_norm 3.5219 (3.5731)	mem 8931MB
[2022-04-07 11:02:20 large] (main.py 226): INFO Train: [134/300][300/2502]	eta 0:23:44 lr 0.000293	time 0.5962 (0.6471)	loss 2.5578 (3.3979)	grad_norm 4.5999 (3.5130)	mem 8931MB
[2022-04-07 11:03:24 large] (main.py 226): INFO Train: [134/300][400/2502]	eta 0:22:34 lr 0.000293	time 0.6042 (0.6444)	loss 3.8479 (3.4253)	grad_norm 2.9585 (3.4897)	mem 8931MB
[2022-04-07 11:04:27 large] (main.py 226): INFO Train: [134/300][500/2502]	eta 0:21:25 lr 0.000293	time 0.6615 (0.6419)	loss 3.7355 (3.4100)	grad_norm 5.7854 (3.4666)	mem 8931MB
[2022-04-07 11:05:31 large] (main.py 226): INFO Train: [134/300][600/2502]	eta 0:20:18 lr 0.000293	time 0.7179 (0.6405)	loss 3.7306 (3.3985)	grad_norm 2.9777 (3.4567)	mem 8931MB
[2022-04-07 11:06:33 large] (main.py 226): INFO Train: [134/300][700/2502]	eta 0:19:10 lr 0.000293	time 0.6661 (0.6386)	loss 3.6126 (3.4064)	grad_norm 2.9079 (3.4569)	mem 8931MB
[2022-04-07 11:07:36 large] (main.py 226): INFO Train: [134/300][800/2502]	eta 0:18:04 lr 0.000293	time 0.5543 (0.6374)	loss 3.9209 (3.4144)	grad_norm 3.0162 (3.4518)	mem 8931MB
[2022-04-07 11:08:39 large] (main.py 226): INFO Train: [134/300][900/2502]	eta 0:17:00 lr 0.000293	time 0.6915 (0.6368)	loss 3.7335 (3.4131)	grad_norm 4.0883 (3.4686)	mem 8931MB
[2022-04-07 11:09:42 large] (main.py 226): INFO Train: [134/300][1000/2502]	eta 0:15:54 lr 0.000293	time 0.5074 (0.6354)	loss 3.0665 (3.4073)	grad_norm 2.7861 (3.4636)	mem 8931MB
[2022-04-07 11:10:44 large] (main.py 226): INFO Train: [134/300][1100/2502]	eta 0:14:49 lr 0.000293	time 0.6382 (0.6344)	loss 3.6433 (3.4098)	grad_norm 3.3177 (3.4528)	mem 8931MB
[2022-04-07 11:11:47 large] (main.py 226): INFO Train: [134/300][1200/2502]	eta 0:13:45 lr 0.000293	time 0.6130 (0.6340)	loss 3.4892 (3.4069)	grad_norm 3.2125 (3.4558)	mem 8931MB
[2022-04-07 11:12:50 large] (main.py 226): INFO Train: [134/300][1300/2502]	eta 0:12:41 lr 0.000292	time 0.7450 (0.6337)	loss 3.4881 (3.4098)	grad_norm 3.6637 (3.4437)	mem 8931MB
[2022-04-07 11:13:54 large] (main.py 226): INFO Train: [134/300][1400/2502]	eta 0:11:38 lr 0.000292	time 0.6328 (0.6338)	loss 3.1853 (3.4085)	grad_norm 3.7560 (3.4448)	mem 8931MB
[2022-04-07 11:14:56 large] (main.py 226): INFO Train: [134/300][1500/2502]	eta 0:10:34 lr 0.000292	time 0.7026 (0.6334)	loss 4.0008 (3.4090)	grad_norm 3.0233 (3.4500)	mem 8931MB
[2022-04-07 11:16:00 large] (main.py 226): INFO Train: [134/300][1600/2502]	eta 0:09:31 lr 0.000292	time 0.6133 (0.6337)	loss 2.7974 (3.3991)	grad_norm 3.2085 (3.4448)	mem 8931MB
[2022-04-07 11:17:03 large] (main.py 226): INFO Train: [134/300][1700/2502]	eta 0:08:27 lr 0.000292	time 0.6394 (0.6331)	loss 4.0966 (3.4008)	grad_norm 3.2857 (3.4345)	mem 8931MB
[2022-04-07 11:18:06 large] (main.py 226): INFO Train: [134/300][1800/2502]	eta 0:07:24 lr 0.000292	time 0.6794 (0.6331)	loss 3.1233 (3.4010)	grad_norm 2.8302 (nan)	mem 8931MB
[2022-04-07 11:19:03 large] (main.py 226): INFO Train: [134/300][1900/2502]	eta 0:06:19 lr 0.000292	time 0.5625 (0.6300)	loss 3.7501 (3.4058)	grad_norm 4.8202 (nan)	mem 8931MB
[2022-04-07 11:20:04 large] (main.py 226): INFO Train: [134/300][2000/2502]	eta 0:05:15 lr 0.000292	time 0.6230 (0.6291)	loss 3.8230 (3.4097)	grad_norm 3.2447 (nan)	mem 8931MB
[2022-04-07 11:21:08 large] (main.py 226): INFO Train: [134/300][2100/2502]	eta 0:04:12 lr 0.000292	time 0.6698 (0.6292)	loss 2.2547 (3.4083)	grad_norm 3.1343 (nan)	mem 8931MB
[2022-04-07 11:22:11 large] (main.py 226): INFO Train: [134/300][2200/2502]	eta 0:03:10 lr 0.000292	time 0.6160 (0.6293)	loss 3.0479 (3.4106)	grad_norm 3.1495 (nan)	mem 8931MB
[2022-04-07 11:23:14 large] (main.py 226): INFO Train: [134/300][2300/2502]	eta 0:02:07 lr 0.000291	time 0.5466 (0.6296)	loss 2.5618 (3.4066)	grad_norm 3.7008 (nan)	mem 8931MB
[2022-04-07 11:24:17 large] (main.py 226): INFO Train: [134/300][2400/2502]	eta 0:01:04 lr 0.000291	time 0.6690 (0.6294)	loss 3.5694 (3.4069)	grad_norm 3.0466 (nan)	mem 8931MB
[2022-04-07 11:25:19 large] (main.py 226): INFO Train: [134/300][2500/2502]	eta 0:00:01 lr 0.000291	time 0.5866 (0.6290)	loss 3.7684 (3.4074)	grad_norm 3.7217 (nan)	mem 8931MB
[2022-04-07 11:25:20 large] (main.py 233): INFO EPOCH 134 training takes 0:26:14
[2022-04-07 11:25:26 large] (main.py 273): INFO Test: [0/98]	Time 6.252 (6.252)	Loss 1.0946 (1.0946)	Acc@1 78.711 (78.711)	Acc@5 94.141 (94.141)	Mem 8931MB
[2022-04-07 11:25:52 large] (main.py 279): INFO  * Acc@1 76.334 Acc@5 93.262
[2022-04-07 11:25:52 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 76.3%
[2022-04-07 11:25:52 large] (main.py 148): INFO Max accuracy: 76.89%
[2022-04-07 11:25:59 large] (main.py 226): INFO Train: [135/300][0/2502]	eta 4:52:10 lr 0.000291	time 7.0065 (7.0065)	loss 3.9066 (3.9066)	grad_norm 3.0297 (3.0297)	mem 8931MB
[2022-04-07 11:26:57 large] (main.py 226): INFO Train: [135/300][100/2502]	eta 0:25:55 lr 0.000291	time 0.6234 (0.6475)	loss 3.7223 (3.4418)	grad_norm 3.7305 (3.5111)	mem 8931MB
[2022-04-07 11:28:01 large] (main.py 226): INFO Train: [135/300][200/2502]	eta 0:24:36 lr 0.000291	time 0.5956 (0.6413)	loss 3.3356 (3.4139)	grad_norm 3.4505 (3.4785)	mem 8931MB
[2022-04-07 11:29:05 large] (main.py 226): INFO Train: [135/300][300/2502]	eta 0:23:35 lr 0.000291	time 0.6099 (0.6426)	loss 2.4088 (3.4017)	grad_norm 2.8080 (3.4992)	mem 8931MB
[2022-04-07 11:30:09 large] (main.py 226): INFO Train: [135/300][400/2502]	eta 0:22:26 lr 0.000291	time 0.4894 (0.6408)	loss 3.5539 (3.4068)	grad_norm 3.3817 (3.4568)	mem 8931MB
[2022-04-07 11:31:13 large] (main.py 226): INFO Train: [135/300][500/2502]	eta 0:21:24 lr 0.000291	time 0.5205 (0.6415)	loss 3.3877 (3.4021)	grad_norm 2.4779 (3.4647)	mem 8931MB
[2022-04-07 11:32:19 large] (main.py 226): INFO Train: [135/300][600/2502]	eta 0:20:23 lr 0.000291	time 0.6261 (0.6434)	loss 3.8745 (3.3964)	grad_norm 2.9510 (3.4645)	mem 8931MB
[2022-04-07 11:33:21 large] (main.py 226): INFO Train: [135/300][700/2502]	eta 0:19:15 lr 0.000291	time 0.6514 (0.6411)	loss 3.0986 (3.3994)	grad_norm 3.1811 (3.4729)	mem 8931MB
[2022-04-07 11:34:18 large] (main.py 226): INFO Train: [135/300][800/2502]	eta 0:17:55 lr 0.000290	time 0.4759 (0.6317)	loss 3.1826 (3.4099)	grad_norm 3.1911 (3.4732)	mem 8931MB
[2022-04-07 11:35:14 large] (main.py 226): INFO Train: [135/300][900/2502]	eta 0:16:38 lr 0.000290	time 0.7158 (0.6236)	loss 3.4262 (3.4127)	grad_norm 4.1124 (3.4832)	mem 8931MB
[2022-04-07 11:36:19 large] (main.py 226): INFO Train: [135/300][1000/2502]	eta 0:15:40 lr 0.000290	time 0.6421 (0.6260)	loss 2.3066 (3.4121)	grad_norm 4.2358 (3.4788)	mem 8931MB
[2022-04-07 11:37:22 large] (main.py 226): INFO Train: [135/300][1100/2502]	eta 0:14:38 lr 0.000290	time 0.5804 (0.6268)	loss 3.1188 (3.4158)	grad_norm 5.7361 (3.4705)	mem 8931MB
[2022-04-07 11:38:25 large] (main.py 226): INFO Train: [135/300][1200/2502]	eta 0:13:36 lr 0.000290	time 0.6784 (0.6271)	loss 3.4761 (3.4188)	grad_norm 3.2130 (3.4648)	mem 8931MB
[2022-04-07 11:39:29 large] (main.py 226): INFO Train: [135/300][1300/2502]	eta 0:12:34 lr 0.000290	time 0.6559 (0.6276)	loss 2.9785 (3.4172)	grad_norm 3.1362 (3.4600)	mem 8931MB
[2022-04-07 11:40:32 large] (main.py 226): INFO Train: [135/300][1400/2502]	eta 0:11:32 lr 0.000290	time 0.6206 (0.6284)	loss 3.6623 (3.4209)	grad_norm 3.6849 (3.4605)	mem 8931MB
[2022-04-07 11:41:36 large] (main.py 226): INFO Train: [135/300][1500/2502]	eta 0:10:29 lr 0.000290	time 0.6666 (0.6286)	loss 2.2251 (3.4190)	grad_norm 2.8831 (3.4608)	mem 8931MB
[2022-04-07 11:42:39 large] (main.py 226): INFO Train: [135/300][1600/2502]	eta 0:09:27 lr 0.000290	time 0.6153 (0.6290)	loss 3.4672 (3.4174)	grad_norm 3.8124 (3.4568)	mem 8931MB
[2022-04-07 11:43:42 large] (main.py 226): INFO Train: [135/300][1700/2502]	eta 0:08:24 lr 0.000289	time 0.5999 (0.6289)	loss 3.7774 (3.4159)	grad_norm 2.7749 (3.4621)	mem 8931MB
[2022-04-07 11:44:46 large] (main.py 226): INFO Train: [135/300][1800/2502]	eta 0:07:22 lr 0.000289	time 0.7080 (0.6299)	loss 3.7740 (3.4138)	grad_norm 2.9996 (nan)	mem 8931MB
[2022-04-07 11:45:51 large] (main.py 226): INFO Train: [135/300][1900/2502]	eta 0:06:19 lr 0.000289	time 1.3330 (0.6305)	loss 3.7497 (3.4154)	grad_norm 3.5494 (nan)	mem 8931MB
[2022-04-07 11:46:53 large] (main.py 226): INFO Train: [135/300][2000/2502]	eta 0:05:16 lr 0.000289	time 0.5820 (0.6304)	loss 2.4892 (3.4169)	grad_norm 3.7587 (nan)	mem 8931MB
[2022-04-07 11:47:57 large] (main.py 226): INFO Train: [135/300][2100/2502]	eta 0:04:13 lr 0.000289	time 0.5134 (0.6307)	loss 3.1735 (3.4176)	grad_norm 3.0724 (nan)	mem 8931MB
[2022-04-07 11:49:00 large] (main.py 226): INFO Train: [135/300][2200/2502]	eta 0:03:10 lr 0.000289	time 0.5773 (0.6308)	loss 3.8659 (3.4138)	grad_norm 3.7527 (nan)	mem 8931MB
[2022-04-07 11:50:04 large] (main.py 226): INFO Train: [135/300][2300/2502]	eta 0:02:07 lr 0.000289	time 0.6153 (0.6309)	loss 3.7125 (3.4089)	grad_norm 3.0800 (nan)	mem 8931MB
[2022-04-07 11:51:08 large] (main.py 226): INFO Train: [135/300][2400/2502]	eta 0:01:04 lr 0.000289	time 0.6457 (0.6313)	loss 2.5470 (3.4113)	grad_norm 3.5563 (nan)	mem 8931MB
[2022-04-07 11:52:11 large] (main.py 226): INFO Train: [135/300][2500/2502]	eta 0:00:01 lr 0.000289	time 0.6078 (0.6315)	loss 3.6604 (3.4100)	grad_norm 2.8724 (nan)	mem 8931MB
[2022-04-07 11:52:12 large] (main.py 233): INFO EPOCH 135 training takes 0:26:20
[2022-04-07 11:52:18 large] (main.py 273): INFO Test: [0/98]	Time 5.940 (5.940)	Loss 1.1873 (1.1873)	Acc@1 73.828 (73.828)	Acc@5 92.969 (92.969)	Mem 8931MB
[2022-04-07 11:52:45 large] (main.py 279): INFO  * Acc@1 76.580 Acc@5 93.480
[2022-04-07 11:52:45 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 76.6%
[2022-04-07 11:52:45 large] (main.py 148): INFO Max accuracy: 76.89%
[2022-04-07 11:52:52 large] (main.py 226): INFO Train: [136/300][0/2502]	eta 4:48:59 lr 0.000289	time 6.9303 (6.9303)	loss 3.7339 (3.7339)	grad_norm 3.4960 (3.4960)	mem 8931MB
[2022-04-07 11:53:45 large] (main.py 226): INFO Train: [136/300][100/2502]	eta 0:23:58 lr 0.000289	time 0.5019 (0.5991)	loss 4.2200 (3.3775)	grad_norm 3.4986 (3.5227)	mem 8931MB
[2022-04-07 11:54:50 large] (main.py 226): INFO Train: [136/300][200/2502]	eta 0:24:00 lr 0.000288	time 0.5052 (0.6256)	loss 3.6780 (3.3972)	grad_norm 3.8773 (3.4585)	mem 8931MB
[2022-04-07 11:55:56 large] (main.py 226): INFO Train: [136/300][300/2502]	eta 0:23:20 lr 0.000288	time 0.6727 (0.6359)	loss 3.6070 (3.4148)	grad_norm 3.3509 (3.4898)	mem 8931MB
[2022-04-07 11:57:01 large] (main.py 226): INFO Train: [136/300][400/2502]	eta 0:22:24 lr 0.000288	time 0.5989 (0.6398)	loss 3.2606 (3.4184)	grad_norm 3.1978 (3.4885)	mem 8931MB
[2022-04-07 11:57:59 large] (main.py 226): INFO Train: [136/300][500/2502]	eta 0:20:55 lr 0.000288	time 0.6604 (0.6273)	loss 3.4119 (3.4275)	grad_norm 2.9798 (3.4791)	mem 8931MB
[2022-04-07 11:59:04 large] (main.py 226): INFO Train: [136/300][600/2502]	eta 0:20:00 lr 0.000288	time 0.5901 (0.6313)	loss 2.1819 (3.4170)	grad_norm 3.1788 (3.4859)	mem 8931MB
[2022-04-07 12:00:09 large] (main.py 226): INFO Train: [136/300][700/2502]	eta 0:19:01 lr 0.000288	time 0.7376 (0.6337)	loss 3.0242 (3.4096)	grad_norm 3.3985 (3.4883)	mem 8931MB
[2022-04-07 12:01:14 large] (main.py 226): INFO Train: [136/300][800/2502]	eta 0:18:01 lr 0.000288	time 0.6253 (0.6356)	loss 3.6309 (3.3999)	grad_norm 3.4091 (3.4790)	mem 8931MB
[2022-04-07 12:02:19 large] (main.py 226): INFO Train: [136/300][900/2502]	eta 0:17:00 lr 0.000288	time 0.7233 (0.6371)	loss 3.3403 (3.3939)	grad_norm 2.9632 (3.4686)	mem 8931MB
[2022-04-07 12:03:22 large] (main.py 226): INFO Train: [136/300][1000/2502]	eta 0:15:56 lr 0.000288	time 0.5674 (0.6369)	loss 2.4291 (3.3962)	grad_norm 3.6493 (3.4697)	mem 8931MB
[2022-04-07 12:04:27 large] (main.py 226): INFO Train: [136/300][1100/2502]	eta 0:14:54 lr 0.000288	time 0.5455 (0.6380)	loss 2.3486 (3.3970)	grad_norm 3.9845 (3.4697)	mem 8931MB
[2022-04-07 12:05:32 large] (main.py 226): INFO Train: [136/300][1200/2502]	eta 0:13:51 lr 0.000287	time 0.5323 (0.6388)	loss 3.4134 (3.3907)	grad_norm 3.1417 (3.4763)	mem 8931MB
[2022-04-07 12:06:36 large] (main.py 226): INFO Train: [136/300][1300/2502]	eta 0:12:48 lr 0.000287	time 0.5845 (0.6392)	loss 2.5202 (3.3862)	grad_norm 4.0575 (3.4837)	mem 8931MB
[2022-04-07 12:07:41 large] (main.py 226): INFO Train: [136/300][1400/2502]	eta 0:11:45 lr 0.000287	time 0.5828 (0.6398)	loss 3.3720 (3.3875)	grad_norm 3.9771 (3.4786)	mem 8931MB
[2022-04-07 12:08:46 large] (main.py 226): INFO Train: [136/300][1500/2502]	eta 0:10:41 lr 0.000287	time 0.5978 (0.6401)	loss 2.2979 (3.3833)	grad_norm 3.1698 (nan)	mem 8931MB
[2022-04-07 12:09:50 large] (main.py 226): INFO Train: [136/300][1600/2502]	eta 0:09:37 lr 0.000287	time 0.6676 (0.6407)	loss 3.2523 (3.3848)	grad_norm 3.2021 (nan)	mem 8931MB
[2022-04-07 12:10:54 large] (main.py 226): INFO Train: [136/300][1700/2502]	eta 0:08:33 lr 0.000287	time 0.7032 (0.6404)	loss 3.0294 (3.3809)	grad_norm 3.3366 (nan)	mem 8931MB
[2022-04-07 12:11:59 large] (main.py 226): INFO Train: [136/300][1800/2502]	eta 0:07:29 lr 0.000287	time 0.6973 (0.6408)	loss 3.3403 (3.3845)	grad_norm 3.8887 (nan)	mem 8931MB
[2022-04-07 12:13:03 large] (main.py 226): INFO Train: [136/300][1900/2502]	eta 0:06:25 lr 0.000287	time 0.6055 (0.6409)	loss 2.7377 (3.3843)	grad_norm 3.6368 (nan)	mem 8931MB
[2022-04-07 12:14:07 large] (main.py 226): INFO Train: [136/300][2000/2502]	eta 0:05:21 lr 0.000287	time 0.6806 (0.6411)	loss 2.0706 (3.3819)	grad_norm 2.4066 (nan)	mem 8931MB
[2022-04-07 12:15:11 large] (main.py 226): INFO Train: [136/300][2100/2502]	eta 0:04:17 lr 0.000287	time 0.7297 (0.6409)	loss 3.7193 (3.3793)	grad_norm 4.6434 (nan)	mem 8931MB
[2022-04-07 12:16:16 large] (main.py 226): INFO Train: [136/300][2200/2502]	eta 0:03:13 lr 0.000286	time 0.6588 (0.6413)	loss 3.6561 (3.3838)	grad_norm 3.6572 (nan)	mem 8931MB
[2022-04-07 12:17:20 large] (main.py 226): INFO Train: [136/300][2300/2502]	eta 0:02:09 lr 0.000286	time 0.6254 (0.6412)	loss 3.9463 (3.3836)	grad_norm 3.8480 (nan)	mem 8931MB
[2022-04-07 12:18:24 large] (main.py 226): INFO Train: [136/300][2400/2502]	eta 0:01:05 lr 0.000286	time 0.6740 (0.6410)	loss 3.2928 (3.3841)	grad_norm 2.6579 (nan)	mem 8931MB
[2022-04-07 12:19:28 large] (main.py 226): INFO Train: [136/300][2500/2502]	eta 0:00:01 lr 0.000286	time 0.7102 (0.6412)	loss 3.6642 (3.3884)	grad_norm 2.6520 (nan)	mem 8931MB
[2022-04-07 12:19:30 large] (main.py 233): INFO EPOCH 136 training takes 0:26:44
[2022-04-07 12:19:35 large] (main.py 273): INFO Test: [0/98]	Time 5.551 (5.551)	Loss 1.1296 (1.1296)	Acc@1 76.562 (76.562)	Acc@5 93.164 (93.164)	Mem 8931MB
[2022-04-07 12:20:02 large] (main.py 279): INFO  * Acc@1 76.822 Acc@5 93.490
[2022-04-07 12:20:02 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 76.8%
[2022-04-07 12:20:02 large] (main.py 148): INFO Max accuracy: 76.89%
[2022-04-07 12:20:09 large] (main.py 226): INFO Train: [137/300][0/2502]	eta 4:47:13 lr 0.000286	time 6.8879 (6.8879)	loss 3.9738 (3.9738)	grad_norm 3.3475 (3.3475)	mem 8931MB
[2022-04-07 12:21:08 large] (main.py 226): INFO Train: [137/300][100/2502]	eta 0:26:13 lr 0.000286	time 0.6542 (0.6552)	loss 3.7379 (3.2997)	grad_norm 2.9690 (3.4673)	mem 8931MB
[2022-04-07 12:22:14 large] (main.py 226): INFO Train: [137/300][200/2502]	eta 0:25:11 lr 0.000286	time 0.6417 (0.6566)	loss 3.3117 (3.2833)	grad_norm 2.8390 (3.4393)	mem 8931MB
[2022-04-07 12:23:20 large] (main.py 226): INFO Train: [137/300][300/2502]	eta 0:24:06 lr 0.000286	time 0.5963 (0.6571)	loss 3.9484 (3.3076)	grad_norm 3.9499 (3.5317)	mem 8931MB
[2022-04-07 12:24:24 large] (main.py 226): INFO Train: [137/300][400/2502]	eta 0:22:51 lr 0.000286	time 0.6662 (0.6526)	loss 3.6076 (3.3488)	grad_norm 4.1976 (3.5167)	mem 8931MB
[2022-04-07 12:25:28 large] (main.py 226): INFO Train: [137/300][500/2502]	eta 0:21:43 lr 0.000286	time 0.6034 (0.6513)	loss 3.3007 (3.3687)	grad_norm 3.5394 (3.5193)	mem 8931MB
[2022-04-07 12:26:34 large] (main.py 226): INFO Train: [137/300][600/2502]	eta 0:20:38 lr 0.000285	time 0.5970 (0.6514)	loss 3.6080 (3.3665)	grad_norm 5.6703 (3.5130)	mem 8931MB
[2022-04-07 12:27:38 large] (main.py 226): INFO Train: [137/300][700/2502]	eta 0:19:31 lr 0.000285	time 0.5613 (0.6502)	loss 3.4677 (3.3710)	grad_norm 2.8266 (3.5181)	mem 8931MB
[2022-04-07 12:28:42 large] (main.py 226): INFO Train: [137/300][800/2502]	eta 0:18:24 lr 0.000285	time 0.6692 (0.6490)	loss 3.4447 (3.3880)	grad_norm 4.2405 (3.5210)	mem 8931MB
[2022-04-07 12:29:46 large] (main.py 226): INFO Train: [137/300][900/2502]	eta 0:17:18 lr 0.000285	time 0.6925 (0.6480)	loss 3.1408 (3.3950)	grad_norm 3.2639 (3.5297)	mem 8931MB
[2022-04-07 12:30:50 large] (main.py 226): INFO Train: [137/300][1000/2502]	eta 0:16:12 lr 0.000285	time 0.6566 (0.6472)	loss 3.9046 (3.3971)	grad_norm 3.3675 (nan)	mem 8931MB
[2022-04-07 12:31:55 large] (main.py 226): INFO Train: [137/300][1100/2502]	eta 0:15:07 lr 0.000285	time 0.6051 (0.6473)	loss 2.2237 (3.3916)	grad_norm 2.6506 (nan)	mem 8931MB
[2022-04-07 12:32:59 large] (main.py 226): INFO Train: [137/300][1200/2502]	eta 0:14:02 lr 0.000285	time 0.6598 (0.6470)	loss 3.4689 (3.3858)	grad_norm 3.4271 (nan)	mem 8931MB
[2022-04-07 12:34:03 large] (main.py 226): INFO Train: [137/300][1300/2502]	eta 0:12:56 lr 0.000285	time 0.5813 (0.6463)	loss 3.3522 (3.3940)	grad_norm 2.8539 (nan)	mem 8931MB
[2022-04-07 12:35:07 large] (main.py 226): INFO Train: [137/300][1400/2502]	eta 0:11:51 lr 0.000285	time 0.5159 (0.6457)	loss 3.6295 (3.3919)	grad_norm 2.6011 (nan)	mem 8931MB
[2022-04-07 12:36:12 large] (main.py 226): INFO Train: [137/300][1500/2502]	eta 0:10:47 lr 0.000285	time 0.6947 (0.6460)	loss 3.8866 (3.3908)	grad_norm 3.4210 (nan)	mem 8931MB
[2022-04-07 12:37:17 large] (main.py 226): INFO Train: [137/300][1600/2502]	eta 0:09:43 lr 0.000284	time 0.7398 (0.6466)	loss 2.4216 (3.3885)	grad_norm 3.1413 (nan)	mem 8931MB
[2022-04-07 12:38:21 large] (main.py 226): INFO Train: [137/300][1700/2502]	eta 0:08:38 lr 0.000284	time 0.6228 (0.6459)	loss 3.2964 (3.3926)	grad_norm 3.8404 (nan)	mem 8931MB
[2022-04-07 12:39:24 large] (main.py 226): INFO Train: [137/300][1800/2502]	eta 0:07:33 lr 0.000284	time 0.6753 (0.6453)	loss 2.5982 (3.3910)	grad_norm 3.0058 (nan)	mem 8931MB
[2022-04-07 12:40:29 large] (main.py 226): INFO Train: [137/300][1900/2502]	eta 0:06:28 lr 0.000284	time 0.6718 (0.6457)	loss 3.7811 (3.3894)	grad_norm 2.5664 (nan)	mem 8931MB
[2022-04-07 12:41:34 large] (main.py 226): INFO Train: [137/300][2000/2502]	eta 0:05:24 lr 0.000284	time 0.7481 (0.6455)	loss 3.7180 (3.3938)	grad_norm 3.1236 (nan)	mem 8931MB
[2022-04-07 12:42:38 large] (main.py 226): INFO Train: [137/300][2100/2502]	eta 0:04:19 lr 0.000284	time 0.6591 (0.6455)	loss 3.3129 (3.3934)	grad_norm 3.8237 (nan)	mem 8931MB
[2022-04-07 12:43:43 large] (main.py 226): INFO Train: [137/300][2200/2502]	eta 0:03:15 lr 0.000284	time 0.7631 (0.6457)	loss 3.6416 (3.3953)	grad_norm 2.9554 (nan)	mem 8931MB
[2022-04-07 12:44:48 large] (main.py 226): INFO Train: [137/300][2300/2502]	eta 0:02:10 lr 0.000284	time 0.7592 (0.6456)	loss 2.0409 (3.3938)	grad_norm 3.8467 (nan)	mem 8931MB
[2022-04-07 12:45:52 large] (main.py 226): INFO Train: [137/300][2400/2502]	eta 0:01:05 lr 0.000284	time 0.6291 (0.6454)	loss 4.0693 (3.3972)	grad_norm 4.0890 (nan)	mem 8931MB
[2022-04-07 12:46:57 large] (main.py 226): INFO Train: [137/300][2500/2502]	eta 0:00:01 lr 0.000284	time 0.6374 (0.6458)	loss 3.2973 (3.3951)	grad_norm 3.3903 (nan)	mem 8931MB
[2022-04-07 12:46:58 large] (main.py 233): INFO EPOCH 137 training takes 0:26:56
[2022-04-07 12:47:05 large] (main.py 273): INFO Test: [0/98]	Time 6.584 (6.584)	Loss 1.1008 (1.1008)	Acc@1 76.953 (76.953)	Acc@5 92.773 (92.773)	Mem 8931MB
[2022-04-07 12:47:30 large] (main.py 279): INFO  * Acc@1 76.762 Acc@5 93.470
[2022-04-07 12:47:30 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 76.8%
[2022-04-07 12:47:30 large] (main.py 148): INFO Max accuracy: 76.89%
[2022-04-07 12:47:37 large] (main.py 226): INFO Train: [138/300][0/2502]	eta 4:43:13 lr 0.000284	time 6.7918 (6.7918)	loss 4.1509 (4.1509)	grad_norm 3.2850 (3.2850)	mem 8931MB
[2022-04-07 12:48:38 large] (main.py 226): INFO Train: [138/300][100/2502]	eta 0:26:42 lr 0.000283	time 0.6762 (0.6671)	loss 3.5959 (3.3535)	grad_norm 5.1811 (3.4003)	mem 8931MB
[2022-04-07 12:49:43 large] (main.py 226): INFO Train: [138/300][200/2502]	eta 0:25:22 lr 0.000283	time 0.6242 (0.6612)	loss 4.1498 (3.3852)	grad_norm 3.1601 (3.4501)	mem 8931MB
[2022-04-07 12:50:48 large] (main.py 226): INFO Train: [138/300][300/2502]	eta 0:24:09 lr 0.000283	time 0.7013 (0.6584)	loss 4.1318 (3.3713)	grad_norm 3.9348 (3.4709)	mem 8931MB
[2022-04-07 12:51:53 large] (main.py 226): INFO Train: [138/300][400/2502]	eta 0:22:58 lr 0.000283	time 0.6434 (0.6557)	loss 3.8637 (3.4028)	grad_norm 2.8868 (3.5141)	mem 8931MB
[2022-04-07 12:52:58 large] (main.py 226): INFO Train: [138/300][500/2502]	eta 0:21:50 lr 0.000283	time 0.6287 (0.6548)	loss 3.9812 (3.3981)	grad_norm 3.4171 (3.4976)	mem 8931MB
[2022-04-07 12:54:03 large] (main.py 226): INFO Train: [138/300][600/2502]	eta 0:20:44 lr 0.000283	time 0.6076 (0.6542)	loss 3.3845 (3.4031)	grad_norm 2.5273 (nan)	mem 8931MB
[2022-04-07 12:55:09 large] (main.py 226): INFO Train: [138/300][700/2502]	eta 0:19:39 lr 0.000283	time 0.6630 (0.6543)	loss 2.7926 (3.3985)	grad_norm 3.1727 (nan)	mem 8931MB
[2022-04-07 12:56:13 large] (main.py 226): INFO Train: [138/300][800/2502]	eta 0:18:31 lr 0.000283	time 0.7572 (0.6532)	loss 2.5461 (3.4097)	grad_norm 3.9863 (nan)	mem 8931MB
[2022-04-07 12:57:18 large] (main.py 226): INFO Train: [138/300][900/2502]	eta 0:17:25 lr 0.000283	time 0.6929 (0.6528)	loss 3.8947 (3.4122)	grad_norm 4.0015 (nan)	mem 8931MB
[2022-04-07 12:58:23 large] (main.py 226): INFO Train: [138/300][1000/2502]	eta 0:16:19 lr 0.000282	time 0.7127 (0.6522)	loss 2.3936 (3.4070)	grad_norm 4.0674 (nan)	mem 8931MB
[2022-04-07 12:59:27 large] (main.py 226): INFO Train: [138/300][1100/2502]	eta 0:15:12 lr 0.000282	time 0.6665 (0.6511)	loss 3.7447 (3.4077)	grad_norm 4.5328 (nan)	mem 8931MB
[2022-04-07 13:00:32 large] (main.py 226): INFO Train: [138/300][1200/2502]	eta 0:14:07 lr 0.000282	time 0.6511 (0.6508)	loss 3.7158 (3.4040)	grad_norm 3.4143 (nan)	mem 8931MB
[2022-04-07 13:01:36 large] (main.py 226): INFO Train: [138/300][1300/2502]	eta 0:13:01 lr 0.000282	time 0.5314 (0.6499)	loss 3.3797 (3.3978)	grad_norm 3.7139 (nan)	mem 8931MB
[2022-04-07 13:02:41 large] (main.py 226): INFO Train: [138/300][1400/2502]	eta 0:11:56 lr 0.000282	time 0.6205 (0.6503)	loss 3.5489 (3.3982)	grad_norm 4.2422 (nan)	mem 8931MB
[2022-04-07 13:03:45 large] (main.py 226): INFO Train: [138/300][1500/2502]	eta 0:10:50 lr 0.000282	time 0.5759 (0.6494)	loss 3.1709 (3.3947)	grad_norm 3.5497 (nan)	mem 8931MB
[2022-04-07 13:04:48 large] (main.py 226): INFO Train: [138/300][1600/2502]	eta 0:09:44 lr 0.000282	time 0.6282 (0.6482)	loss 4.0887 (3.3964)	grad_norm 4.1209 (nan)	mem 8931MB
[2022-04-07 13:05:52 large] (main.py 226): INFO Train: [138/300][1700/2502]	eta 0:08:39 lr 0.000282	time 0.6267 (0.6479)	loss 3.7986 (3.3982)	grad_norm 3.8641 (nan)	mem 8931MB
[2022-04-07 13:06:57 large] (main.py 226): INFO Train: [138/300][1800/2502]	eta 0:07:34 lr 0.000282	time 0.6173 (0.6478)	loss 3.5472 (3.4011)	grad_norm 3.3178 (nan)	mem 8931MB
[2022-04-07 13:08:01 large] (main.py 226): INFO Train: [138/300][1900/2502]	eta 0:06:29 lr 0.000282	time 0.5269 (0.6473)	loss 2.5531 (3.4017)	grad_norm 2.8536 (nan)	mem 8931MB
[2022-04-07 13:09:04 large] (main.py 226): INFO Train: [138/300][2000/2502]	eta 0:05:24 lr 0.000281	time 0.5934 (0.6467)	loss 2.6175 (3.4038)	grad_norm 3.8025 (nan)	mem 8931MB
[2022-04-07 13:10:08 large] (main.py 226): INFO Train: [138/300][2100/2502]	eta 0:04:19 lr 0.000281	time 0.6658 (0.6461)	loss 3.6325 (3.4059)	grad_norm 2.7744 (nan)	mem 8931MB
[2022-04-07 13:11:11 large] (main.py 226): INFO Train: [138/300][2200/2502]	eta 0:03:14 lr 0.000281	time 0.6548 (0.6457)	loss 3.6529 (3.4039)	grad_norm 2.8350 (nan)	mem 8931MB
[2022-04-07 13:12:16 large] (main.py 226): INFO Train: [138/300][2300/2502]	eta 0:02:10 lr 0.000281	time 0.6316 (0.6458)	loss 2.2315 (3.3975)	grad_norm 2.9787 (nan)	mem 8931MB
[2022-04-07 13:13:20 large] (main.py 226): INFO Train: [138/300][2400/2502]	eta 0:01:05 lr 0.000281	time 0.7082 (0.6456)	loss 3.6487 (3.3998)	grad_norm 2.9749 (nan)	mem 8931MB
[2022-04-07 13:14:25 large] (main.py 226): INFO Train: [138/300][2500/2502]	eta 0:00:01 lr 0.000281	time 0.6012 (0.6456)	loss 3.4901 (3.4013)	grad_norm 3.0376 (nan)	mem 8931MB
[2022-04-07 13:14:26 large] (main.py 233): INFO EPOCH 138 training takes 0:26:55
[2022-04-07 13:14:32 large] (main.py 273): INFO Test: [0/98]	Time 5.934 (5.934)	Loss 1.0891 (1.0891)	Acc@1 78.125 (78.125)	Acc@5 94.336 (94.336)	Mem 8931MB
[2022-04-07 13:14:58 large] (main.py 279): INFO  * Acc@1 76.794 Acc@5 93.530
[2022-04-07 13:14:58 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 76.8%
[2022-04-07 13:14:58 large] (main.py 148): INFO Max accuracy: 76.89%
[2022-04-07 13:15:06 large] (main.py 226): INFO Train: [139/300][0/2502]	eta 5:15:14 lr 0.000281	time 7.5598 (7.5598)	loss 3.7668 (3.7668)	grad_norm 3.5721 (3.5721)	mem 8931MB
[2022-04-07 13:15:59 large] (main.py 226): INFO Train: [139/300][100/2502]	eta 0:23:57 lr 0.000281	time 0.6326 (0.5987)	loss 3.5457 (3.3445)	grad_norm 3.8614 (3.3790)	mem 8931MB
[2022-04-07 13:17:04 large] (main.py 226): INFO Train: [139/300][200/2502]	eta 0:24:04 lr 0.000281	time 0.7112 (0.6273)	loss 3.6329 (3.3496)	grad_norm 3.7950 (3.3730)	mem 8931MB
[2022-04-07 13:18:10 large] (main.py 226): INFO Train: [139/300][300/2502]	eta 0:23:19 lr 0.000281	time 0.6502 (0.6358)	loss 3.8140 (3.3608)	grad_norm 3.9720 (3.4253)	mem 8931MB
[2022-04-07 13:19:17 large] (main.py 226): INFO Train: [139/300][400/2502]	eta 0:22:33 lr 0.000281	time 0.7242 (0.6438)	loss 3.3855 (3.3798)	grad_norm 2.8585 (3.4229)	mem 8931MB
[2022-04-07 13:20:21 large] (main.py 226): INFO Train: [139/300][500/2502]	eta 0:21:30 lr 0.000280	time 0.6545 (0.6447)	loss 3.8362 (3.3916)	grad_norm 3.2644 (3.4852)	mem 8931MB
[2022-04-07 13:21:26 large] (main.py 226): INFO Train: [139/300][600/2502]	eta 0:20:27 lr 0.000280	time 0.6286 (0.6452)	loss 4.2642 (3.3987)	grad_norm 3.9395 (3.4997)	mem 8931MB
[2022-04-07 13:22:31 large] (main.py 226): INFO Train: [139/300][700/2502]	eta 0:19:22 lr 0.000280	time 0.6817 (0.6451)	loss 3.3536 (3.3904)	grad_norm 3.4736 (3.4973)	mem 8931MB
[2022-04-07 13:23:35 large] (main.py 226): INFO Train: [139/300][800/2502]	eta 0:18:18 lr 0.000280	time 0.6865 (0.6453)	loss 3.7737 (3.3891)	grad_norm 4.3998 (3.4915)	mem 8931MB
[2022-04-07 13:24:39 large] (main.py 226): INFO Train: [139/300][900/2502]	eta 0:17:11 lr 0.000280	time 0.6286 (0.6442)	loss 3.0335 (3.3965)	grad_norm 3.5548 (3.4833)	mem 8931MB
[2022-04-07 13:25:42 large] (main.py 226): INFO Train: [139/300][1000/2502]	eta 0:16:06 lr 0.000280	time 0.5873 (0.6434)	loss 3.4600 (3.3976)	grad_norm 3.2447 (3.4869)	mem 8931MB
[2022-04-07 13:26:47 large] (main.py 226): INFO Train: [139/300][1100/2502]	eta 0:15:02 lr 0.000280	time 0.5686 (0.6436)	loss 3.3373 (3.3989)	grad_norm 3.3031 (3.4915)	mem 8931MB
[2022-04-07 13:27:51 large] (main.py 226): INFO Train: [139/300][1200/2502]	eta 0:13:58 lr 0.000280	time 0.6737 (0.6437)	loss 2.6842 (3.3975)	grad_norm 4.2247 (3.4918)	mem 8931MB
[2022-04-07 13:28:55 large] (main.py 226): INFO Train: [139/300][1300/2502]	eta 0:12:53 lr 0.000280	time 0.6266 (0.6432)	loss 3.6097 (3.4001)	grad_norm 3.9470 (3.4851)	mem 8931MB
[2022-04-07 13:30:00 large] (main.py 226): INFO Train: [139/300][1400/2502]	eta 0:11:49 lr 0.000280	time 0.6266 (0.6435)	loss 3.9990 (3.3995)	grad_norm 4.5845 (3.4971)	mem 8931MB
[2022-04-07 13:31:03 large] (main.py 226): INFO Train: [139/300][1500/2502]	eta 0:10:44 lr 0.000279	time 0.6268 (0.6430)	loss 3.8784 (3.3971)	grad_norm 3.0888 (3.5076)	mem 8931MB
[2022-04-07 13:32:07 large] (main.py 226): INFO Train: [139/300][1600/2502]	eta 0:09:39 lr 0.000279	time 0.6185 (0.6426)	loss 3.7609 (3.3979)	grad_norm 2.7683 (3.5021)	mem 8931MB
[2022-04-07 13:33:12 large] (main.py 226): INFO Train: [139/300][1700/2502]	eta 0:08:35 lr 0.000279	time 0.6644 (0.6427)	loss 3.6211 (3.3968)	grad_norm 3.8139 (3.5041)	mem 8931MB
[2022-04-07 13:34:17 large] (main.py 226): INFO Train: [139/300][1800/2502]	eta 0:07:31 lr 0.000279	time 0.7271 (0.6432)	loss 3.4936 (3.3947)	grad_norm 3.2627 (3.5050)	mem 8931MB
[2022-04-07 13:35:21 large] (main.py 226): INFO Train: [139/300][1900/2502]	eta 0:06:27 lr 0.000279	time 0.5904 (0.6432)	loss 4.0309 (3.4014)	grad_norm 3.3141 (3.4998)	mem 8931MB
[2022-04-07 13:36:26 large] (main.py 226): INFO Train: [139/300][2000/2502]	eta 0:05:22 lr 0.000279	time 0.6226 (0.6433)	loss 3.6550 (3.4020)	grad_norm 3.3270 (3.5000)	mem 8931MB
[2022-04-07 13:37:30 large] (main.py 226): INFO Train: [139/300][2100/2502]	eta 0:04:18 lr 0.000279	time 0.6086 (0.6435)	loss 3.3139 (3.4020)	grad_norm 4.0392 (3.4964)	mem 8931MB
[2022-04-07 13:38:34 large] (main.py 226): INFO Train: [139/300][2200/2502]	eta 0:03:14 lr 0.000279	time 0.6673 (0.6434)	loss 3.5652 (3.4038)	grad_norm 3.8410 (3.4909)	mem 8931MB
[2022-04-07 13:39:39 large] (main.py 226): INFO Train: [139/300][2300/2502]	eta 0:02:09 lr 0.000279	time 0.6538 (0.6434)	loss 2.7185 (3.4018)	grad_norm 3.4692 (3.4889)	mem 8931MB
[2022-04-07 13:40:42 large] (main.py 226): INFO Train: [139/300][2400/2502]	eta 0:01:05 lr 0.000278	time 0.7003 (0.6428)	loss 3.3879 (3.3997)	grad_norm 3.0256 (3.4935)	mem 8931MB
[2022-04-07 13:41:46 large] (main.py 226): INFO Train: [139/300][2500/2502]	eta 0:00:01 lr 0.000278	time 0.6424 (0.6426)	loss 3.0564 (3.4019)	grad_norm 3.6483 (3.4926)	mem 8931MB
[2022-04-07 13:41:47 large] (main.py 233): INFO EPOCH 139 training takes 0:26:48
[2022-04-07 13:41:53 large] (main.py 273): INFO Test: [0/98]	Time 6.147 (6.147)	Loss 1.1370 (1.1370)	Acc@1 77.734 (77.734)	Acc@5 92.188 (92.188)	Mem 8931MB
[2022-04-07 13:42:19 large] (main.py 279): INFO  * Acc@1 76.746 Acc@5 93.582
[2022-04-07 13:42:19 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 76.7%
[2022-04-07 13:42:19 large] (main.py 148): INFO Max accuracy: 76.89%
[2022-04-07 13:42:25 large] (main.py 226): INFO Train: [140/300][0/2502]	eta 4:38:01 lr 0.000278	time 6.6673 (6.6673)	loss 2.7567 (2.7567)	grad_norm 3.6980 (3.6980)	mem 8931MB
[2022-04-07 13:43:20 large] (main.py 226): INFO Train: [140/300][100/2502]	eta 0:24:25 lr 0.000278	time 0.6467 (0.6102)	loss 3.8310 (3.3913)	grad_norm 3.9370 (3.6263)	mem 8931MB
[2022-04-07 13:44:25 large] (main.py 226): INFO Train: [140/300][200/2502]	eta 0:24:05 lr 0.000278	time 0.7108 (0.6279)	loss 3.7064 (3.3758)	grad_norm 3.6798 (3.5446)	mem 8931MB
[2022-04-07 13:45:31 large] (main.py 226): INFO Train: [140/300][300/2502]	eta 0:23:24 lr 0.000278	time 0.6744 (0.6380)	loss 2.9314 (3.3750)	grad_norm 3.6287 (3.5619)	mem 8931MB
[2022-04-07 13:46:35 large] (main.py 226): INFO Train: [140/300][400/2502]	eta 0:22:25 lr 0.000278	time 0.6582 (0.6399)	loss 3.7241 (3.3862)	grad_norm 2.7485 (3.5395)	mem 8931MB
[2022-04-07 13:47:40 large] (main.py 226): INFO Train: [140/300][500/2502]	eta 0:21:23 lr 0.000278	time 0.6397 (0.6412)	loss 3.3271 (3.3696)	grad_norm 3.4323 (3.5600)	mem 8931MB
[2022-04-07 13:48:44 large] (main.py 226): INFO Train: [140/300][600/2502]	eta 0:20:19 lr 0.000278	time 0.6142 (0.6410)	loss 3.8071 (3.3804)	grad_norm 3.4233 (3.5387)	mem 8931MB
[2022-04-07 13:49:47 large] (main.py 226): INFO Train: [140/300][700/2502]	eta 0:19:13 lr 0.000278	time 0.6812 (0.6401)	loss 3.5028 (3.3730)	grad_norm 2.8112 (3.5045)	mem 8931MB
[2022-04-07 13:50:51 large] (main.py 226): INFO Train: [140/300][800/2502]	eta 0:18:09 lr 0.000278	time 0.6289 (0.6399)	loss 3.0599 (3.3731)	grad_norm 3.8365 (3.4952)	mem 8931MB
[2022-04-07 13:51:54 large] (main.py 226): INFO Train: [140/300][900/2502]	eta 0:17:03 lr 0.000277	time 0.6726 (0.6391)	loss 2.4680 (3.3786)	grad_norm 2.9463 (3.4961)	mem 8931MB
[2022-04-07 13:52:59 large] (main.py 226): INFO Train: [140/300][1000/2502]	eta 0:16:00 lr 0.000277	time 0.6840 (0.6396)	loss 3.6102 (3.3808)	grad_norm 3.0033 (3.4956)	mem 8931MB
[2022-04-07 13:54:02 large] (main.py 226): INFO Train: [140/300][1100/2502]	eta 0:14:55 lr 0.000277	time 0.6975 (0.6386)	loss 3.9040 (3.3817)	grad_norm 4.4945 (3.4952)	mem 8931MB
[2022-04-07 13:55:06 large] (main.py 226): INFO Train: [140/300][1200/2502]	eta 0:13:52 lr 0.000277	time 0.6361 (0.6390)	loss 3.2550 (3.3830)	grad_norm 2.9248 (3.5057)	mem 8931MB
[2022-04-07 13:56:11 large] (main.py 226): INFO Train: [140/300][1300/2502]	eta 0:12:48 lr 0.000277	time 0.6576 (0.6395)	loss 3.5799 (3.3817)	grad_norm 3.1669 (3.5049)	mem 8931MB
[2022-04-07 13:57:14 large] (main.py 226): INFO Train: [140/300][1400/2502]	eta 0:11:44 lr 0.000277	time 0.6385 (0.6393)	loss 2.9490 (3.3876)	grad_norm 3.4228 (nan)	mem 8931MB
[2022-04-07 13:58:18 large] (main.py 226): INFO Train: [140/300][1500/2502]	eta 0:10:40 lr 0.000277	time 0.7129 (0.6392)	loss 2.6575 (3.3866)	grad_norm 3.2868 (nan)	mem 8931MB
[2022-04-07 13:59:22 large] (main.py 226): INFO Train: [140/300][1600/2502]	eta 0:09:36 lr 0.000277	time 0.5944 (0.6394)	loss 3.3935 (3.3862)	grad_norm 3.0652 (nan)	mem 8931MB
[2022-04-07 14:00:25 large] (main.py 226): INFO Train: [140/300][1700/2502]	eta 0:08:32 lr 0.000277	time 0.7131 (0.6386)	loss 2.2945 (3.3833)	grad_norm 2.9165 (nan)	mem 8931MB
[2022-04-07 14:01:29 large] (main.py 226): INFO Train: [140/300][1800/2502]	eta 0:07:28 lr 0.000277	time 0.6377 (0.6386)	loss 3.1313 (3.3800)	grad_norm 3.1180 (nan)	mem 8931MB
[2022-04-07 14:02:32 large] (main.py 226): INFO Train: [140/300][1900/2502]	eta 0:06:24 lr 0.000276	time 0.6420 (0.6383)	loss 3.4343 (3.3788)	grad_norm 3.3574 (nan)	mem 8931MB
[2022-04-07 14:03:37 large] (main.py 226): INFO Train: [140/300][2000/2502]	eta 0:05:20 lr 0.000276	time 0.7332 (0.6388)	loss 4.1789 (3.3794)	grad_norm 3.5610 (nan)	mem 8931MB
[2022-04-07 14:04:41 large] (main.py 226): INFO Train: [140/300][2100/2502]	eta 0:04:16 lr 0.000276	time 0.6148 (0.6388)	loss 3.9792 (3.3824)	grad_norm 3.8034 (nan)	mem 8931MB
[2022-04-07 14:05:45 large] (main.py 226): INFO Train: [140/300][2200/2502]	eta 0:03:12 lr 0.000276	time 0.6603 (0.6389)	loss 4.2673 (3.3834)	grad_norm 4.4100 (nan)	mem 8931MB
[2022-04-07 14:06:49 large] (main.py 226): INFO Train: [140/300][2300/2502]	eta 0:02:09 lr 0.000276	time 0.6906 (0.6389)	loss 2.7094 (3.3848)	grad_norm 2.9410 (nan)	mem 8931MB
[2022-04-07 14:07:54 large] (main.py 226): INFO Train: [140/300][2400/2502]	eta 0:01:05 lr 0.000276	time 0.6271 (0.6393)	loss 3.8220 (3.3869)	grad_norm 3.5547 (nan)	mem 8931MB
[2022-04-07 14:08:57 large] (main.py 226): INFO Train: [140/300][2500/2502]	eta 0:00:01 lr 0.000276	time 0.6172 (0.6391)	loss 3.6900 (3.3865)	grad_norm 3.8598 (nan)	mem 8931MB
[2022-04-07 14:08:58 large] (main.py 233): INFO EPOCH 140 training takes 0:26:39
[2022-04-07 14:09:04 large] (main.py 273): INFO Test: [0/98]	Time 6.111 (6.111)	Loss 0.9876 (0.9876)	Acc@1 79.883 (79.883)	Acc@5 94.922 (94.922)	Mem 8931MB
[2022-04-07 14:09:31 large] (main.py 279): INFO  * Acc@1 76.370 Acc@5 93.440
[2022-04-07 14:09:31 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 76.4%
[2022-04-07 14:09:31 large] (main.py 148): INFO Max accuracy: 76.89%
[2022-04-07 14:09:38 large] (main.py 226): INFO Train: [141/300][0/2502]	eta 5:04:42 lr 0.000276	time 7.3072 (7.3072)	loss 4.0495 (4.0495)	grad_norm 2.6683 (2.6683)	mem 8931MB
[2022-04-07 14:10:29 large] (main.py 226): INFO Train: [141/300][100/2502]	eta 0:23:02 lr 0.000276	time 0.5067 (0.5756)	loss 3.5782 (3.3387)	grad_norm 3.7704 (3.4372)	mem 8931MB
[2022-04-07 14:11:32 large] (main.py 226): INFO Train: [141/300][200/2502]	eta 0:23:08 lr 0.000276	time 0.7035 (0.6032)	loss 3.1689 (3.3526)	grad_norm 3.0051 (3.4852)	mem 8931MB
[2022-04-07 14:12:37 large] (main.py 226): INFO Train: [141/300][300/2502]	eta 0:22:45 lr 0.000275	time 0.6625 (0.6203)	loss 3.5240 (3.3479)	grad_norm 2.9919 (3.4911)	mem 8931MB
[2022-04-07 14:13:44 large] (main.py 226): INFO Train: [141/300][400/2502]	eta 0:22:06 lr 0.000275	time 0.6929 (0.6310)	loss 3.9539 (3.3622)	grad_norm 3.9227 (3.4802)	mem 8931MB
[2022-04-07 14:14:48 large] (main.py 226): INFO Train: [141/300][500/2502]	eta 0:21:09 lr 0.000275	time 0.6309 (0.6339)	loss 3.1555 (3.3626)	grad_norm 4.5399 (3.5083)	mem 8931MB
[2022-04-07 14:15:53 large] (main.py 226): INFO Train: [141/300][600/2502]	eta 0:20:11 lr 0.000275	time 0.6046 (0.6367)	loss 4.1751 (3.3608)	grad_norm 3.9399 (3.5142)	mem 8931MB
[2022-04-07 14:16:57 large] (main.py 226): INFO Train: [141/300][700/2502]	eta 0:19:07 lr 0.000275	time 0.6261 (0.6370)	loss 3.7578 (3.3573)	grad_norm 3.5334 (3.5135)	mem 8931MB
[2022-04-07 14:18:02 large] (main.py 226): INFO Train: [141/300][800/2502]	eta 0:18:05 lr 0.000275	time 0.6387 (0.6377)	loss 3.5642 (3.3647)	grad_norm 3.6881 (3.5249)	mem 8931MB
[2022-04-07 14:19:05 large] (main.py 226): INFO Train: [141/300][900/2502]	eta 0:17:01 lr 0.000275	time 0.6056 (0.6375)	loss 4.2391 (3.3732)	grad_norm 3.2604 (3.5244)	mem 8931MB
[2022-04-07 14:20:10 large] (main.py 226): INFO Train: [141/300][1000/2502]	eta 0:15:59 lr 0.000275	time 0.6416 (0.6385)	loss 2.7929 (3.3730)	grad_norm 3.3466 (3.5179)	mem 8931MB
[2022-04-07 14:21:14 large] (main.py 226): INFO Train: [141/300][1100/2502]	eta 0:14:56 lr 0.000275	time 0.6321 (0.6391)	loss 3.3431 (3.3739)	grad_norm 3.2569 (3.5241)	mem 8931MB
[2022-04-07 14:22:19 large] (main.py 226): INFO Train: [141/300][1200/2502]	eta 0:13:52 lr 0.000275	time 1.3286 (0.6396)	loss 2.7628 (3.3796)	grad_norm 3.0123 (3.5255)	mem 8931MB
[2022-04-07 14:23:22 large] (main.py 226): INFO Train: [141/300][1300/2502]	eta 0:12:48 lr 0.000274	time 0.5121 (0.6393)	loss 3.7139 (3.3748)	grad_norm 3.4260 (3.5324)	mem 8931MB
[2022-04-07 14:24:27 large] (main.py 226): INFO Train: [141/300][1400/2502]	eta 0:11:44 lr 0.000274	time 0.6354 (0.6396)	loss 3.5435 (3.3702)	grad_norm 3.1621 (3.5339)	mem 8931MB
[2022-04-07 14:25:31 large] (main.py 226): INFO Train: [141/300][1500/2502]	eta 0:10:40 lr 0.000274	time 0.6260 (0.6396)	loss 3.3462 (3.3759)	grad_norm 3.0351 (3.5409)	mem 8931MB
[2022-04-07 14:26:35 large] (main.py 226): INFO Train: [141/300][1600/2502]	eta 0:09:37 lr 0.000274	time 0.6404 (0.6399)	loss 2.8823 (3.3798)	grad_norm 3.7813 (3.5440)	mem 8931MB
[2022-04-07 14:27:40 large] (main.py 226): INFO Train: [141/300][1700/2502]	eta 0:08:33 lr 0.000274	time 0.6502 (0.6405)	loss 3.2112 (3.3812)	grad_norm 3.7065 (3.5446)	mem 8931MB
[2022-04-07 14:28:45 large] (main.py 226): INFO Train: [141/300][1800/2502]	eta 0:07:29 lr 0.000274	time 0.6630 (0.6409)	loss 3.5756 (3.3796)	grad_norm 2.8651 (nan)	mem 8931MB
[2022-04-07 14:29:49 large] (main.py 226): INFO Train: [141/300][1900/2502]	eta 0:06:25 lr 0.000274	time 0.6252 (0.6408)	loss 3.3677 (3.3801)	grad_norm 3.7945 (nan)	mem 8931MB
[2022-04-07 14:30:54 large] (main.py 226): INFO Train: [141/300][2000/2502]	eta 0:05:21 lr 0.000274	time 0.6747 (0.6411)	loss 2.4096 (3.3809)	grad_norm 3.1878 (nan)	mem 8931MB
[2022-04-07 14:31:58 large] (main.py 226): INFO Train: [141/300][2100/2502]	eta 0:04:17 lr 0.000274	time 0.6129 (0.6413)	loss 4.1215 (3.3802)	grad_norm 2.9249 (nan)	mem 8931MB
[2022-04-07 14:33:02 large] (main.py 226): INFO Train: [141/300][2200/2502]	eta 0:03:13 lr 0.000274	time 0.6820 (0.6410)	loss 2.2155 (3.3790)	grad_norm 2.6134 (nan)	mem 8931MB
[2022-04-07 14:34:06 large] (main.py 226): INFO Train: [141/300][2300/2502]	eta 0:02:09 lr 0.000273	time 0.5720 (0.6413)	loss 3.6257 (3.3790)	grad_norm 2.6879 (nan)	mem 8931MB
[2022-04-07 14:35:09 large] (main.py 226): INFO Train: [141/300][2400/2502]	eta 0:01:05 lr 0.000273	time 0.6346 (0.6407)	loss 3.3422 (3.3779)	grad_norm 3.4154 (nan)	mem 8931MB
[2022-04-07 14:36:13 large] (main.py 226): INFO Train: [141/300][2500/2502]	eta 0:00:01 lr 0.000273	time 0.6609 (0.6407)	loss 3.8677 (3.3788)	grad_norm 2.9281 (nan)	mem 8931MB
[2022-04-07 14:36:14 large] (main.py 233): INFO EPOCH 141 training takes 0:26:43
[2022-04-07 14:36:21 large] (main.py 273): INFO Test: [0/98]	Time 6.781 (6.781)	Loss 1.2583 (1.2583)	Acc@1 74.219 (74.219)	Acc@5 92.188 (92.188)	Mem 8931MB
[2022-04-07 14:36:46 large] (main.py 279): INFO  * Acc@1 76.940 Acc@5 93.530
[2022-04-07 14:36:46 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 76.9%
[2022-04-07 14:36:46 large] (utils.py 57): INFO output/large/default/ckpt_epoch_141.pth saving......
[2022-04-07 14:36:47 large] (utils.py 59): INFO output/large/default/ckpt_epoch_141.pth saved !!!
[2022-04-07 14:36:47 large] (main.py 148): INFO Max accuracy: 76.94%
[2022-04-07 14:36:55 large] (main.py 226): INFO Train: [142/300][0/2502]	eta 5:30:38 lr 0.000273	time 7.9290 (7.9290)	loss 4.1924 (4.1924)	grad_norm 3.6355 (3.6355)	mem 8931MB
[2022-04-07 14:37:53 large] (main.py 226): INFO Train: [142/300][100/2502]	eta 0:26:14 lr 0.000273	time 0.6923 (0.6553)	loss 3.2935 (3.3266)	grad_norm 2.9502 (3.5510)	mem 8931MB
[2022-04-07 14:38:58 large] (main.py 226): INFO Train: [142/300][200/2502]	eta 0:24:52 lr 0.000273	time 0.6646 (0.6485)	loss 2.5812 (3.3711)	grad_norm 3.0449 (3.5163)	mem 8931MB
[2022-04-07 14:40:02 large] (main.py 226): INFO Train: [142/300][300/2502]	eta 0:23:46 lr 0.000273	time 0.5844 (0.6480)	loss 3.0353 (3.3572)	grad_norm 3.3132 (3.6022)	mem 8931MB
[2022-04-07 14:41:07 large] (main.py 226): INFO Train: [142/300][400/2502]	eta 0:22:44 lr 0.000273	time 0.6029 (0.6489)	loss 2.2313 (3.3549)	grad_norm 2.9616 (3.6565)	mem 8931MB
[2022-04-07 14:42:11 large] (main.py 226): INFO Train: [142/300][500/2502]	eta 0:21:33 lr 0.000273	time 0.7124 (0.6460)	loss 2.3334 (3.3592)	grad_norm 3.8948 (3.6544)	mem 8931MB
[2022-04-07 14:43:16 large] (main.py 226): INFO Train: [142/300][600/2502]	eta 0:20:29 lr 0.000273	time 0.6304 (0.6465)	loss 3.8117 (3.3704)	grad_norm 4.5836 (3.6355)	mem 8931MB
[2022-04-07 14:44:19 large] (main.py 226): INFO Train: [142/300][700/2502]	eta 0:19:22 lr 0.000272	time 0.6837 (0.6450)	loss 3.1649 (3.3724)	grad_norm 2.8818 (3.6071)	mem 8931MB
[2022-04-07 14:45:23 large] (main.py 226): INFO Train: [142/300][800/2502]	eta 0:18:16 lr 0.000272	time 0.6810 (0.6444)	loss 2.6099 (3.3710)	grad_norm 3.4835 (3.6066)	mem 8931MB
[2022-04-07 14:46:27 large] (main.py 226): INFO Train: [142/300][900/2502]	eta 0:17:11 lr 0.000272	time 0.6606 (0.6439)	loss 3.5760 (3.3784)	grad_norm 2.6480 (3.5885)	mem 8931MB
[2022-04-07 14:47:31 large] (main.py 226): INFO Train: [142/300][1000/2502]	eta 0:16:06 lr 0.000272	time 0.4859 (0.6436)	loss 3.5263 (3.3852)	grad_norm 3.0260 (3.5948)	mem 8931MB
[2022-04-07 14:48:36 large] (main.py 226): INFO Train: [142/300][1100/2502]	eta 0:15:02 lr 0.000272	time 0.6546 (0.6440)	loss 3.5201 (3.3840)	grad_norm 3.2732 (nan)	mem 8931MB
[2022-04-07 14:49:40 large] (main.py 226): INFO Train: [142/300][1200/2502]	eta 0:13:57 lr 0.000272	time 0.6823 (0.6431)	loss 3.7064 (3.3786)	grad_norm 2.9041 (nan)	mem 8931MB
[2022-04-07 14:50:44 large] (main.py 226): INFO Train: [142/300][1300/2502]	eta 0:12:53 lr 0.000272	time 0.6289 (0.6433)	loss 3.3712 (3.3787)	grad_norm 2.6114 (nan)	mem 8931MB
[2022-04-07 14:51:49 large] (main.py 226): INFO Train: [142/300][1400/2502]	eta 0:11:49 lr 0.000272	time 0.6441 (0.6434)	loss 3.3859 (3.3776)	grad_norm 3.5758 (nan)	mem 8931MB
[2022-04-07 14:52:52 large] (main.py 226): INFO Train: [142/300][1500/2502]	eta 0:10:43 lr 0.000272	time 0.6089 (0.6427)	loss 3.5366 (3.3753)	grad_norm 3.4133 (nan)	mem 8931MB
[2022-04-07 14:53:54 large] (main.py 226): INFO Train: [142/300][1600/2502]	eta 0:09:38 lr 0.000272	time 0.4664 (0.6416)	loss 3.3523 (3.3801)	grad_norm 3.2949 (nan)	mem 8931MB
[2022-04-07 14:54:53 large] (main.py 226): INFO Train: [142/300][1700/2502]	eta 0:08:31 lr 0.000271	time 0.6094 (0.6382)	loss 3.7195 (3.3782)	grad_norm 3.9473 (nan)	mem 8931MB
[2022-04-07 14:55:57 large] (main.py 226): INFO Train: [142/300][1800/2502]	eta 0:07:28 lr 0.000271	time 0.6346 (0.6384)	loss 3.6585 (3.3790)	grad_norm 3.4442 (nan)	mem 8931MB
[2022-04-07 14:57:01 large] (main.py 226): INFO Train: [142/300][1900/2502]	eta 0:06:24 lr 0.000271	time 0.5515 (0.6386)	loss 3.5662 (3.3754)	grad_norm 4.2480 (nan)	mem 8931MB
[2022-04-07 14:58:05 large] (main.py 226): INFO Train: [142/300][2000/2502]	eta 0:05:20 lr 0.000271	time 0.6037 (0.6388)	loss 2.4640 (3.3789)	grad_norm 2.6429 (nan)	mem 8931MB
[2022-04-07 14:59:10 large] (main.py 226): INFO Train: [142/300][2100/2502]	eta 0:04:16 lr 0.000271	time 0.6642 (0.6392)	loss 3.1506 (3.3809)	grad_norm 3.3692 (nan)	mem 8931MB
[2022-04-07 15:00:15 large] (main.py 226): INFO Train: [142/300][2200/2502]	eta 0:03:13 lr 0.000271	time 0.7056 (0.6395)	loss 3.9972 (3.3814)	grad_norm 3.1280 (nan)	mem 8931MB
[2022-04-07 15:01:18 large] (main.py 226): INFO Train: [142/300][2300/2502]	eta 0:02:09 lr 0.000271	time 0.7423 (0.6392)	loss 3.1798 (3.3839)	grad_norm 3.5832 (nan)	mem 8931MB
[2022-04-07 15:02:23 large] (main.py 226): INFO Train: [142/300][2400/2502]	eta 0:01:05 lr 0.000271	time 0.6648 (0.6396)	loss 2.9184 (3.3828)	grad_norm 3.6363 (nan)	mem 8931MB
[2022-04-07 15:03:27 large] (main.py 226): INFO Train: [142/300][2500/2502]	eta 0:00:01 lr 0.000271	time 0.6106 (0.6398)	loss 3.3780 (3.3852)	grad_norm 4.1420 (nan)	mem 8931MB
[2022-04-07 15:03:28 large] (main.py 233): INFO EPOCH 142 training takes 0:26:41
[2022-04-07 15:03:35 large] (main.py 273): INFO Test: [0/98]	Time 6.264 (6.264)	Loss 1.0896 (1.0896)	Acc@1 74.609 (74.609)	Acc@5 93.164 (93.164)	Mem 8931MB
[2022-04-07 15:04:01 large] (main.py 279): INFO  * Acc@1 77.112 Acc@5 93.630
[2022-04-07 15:04:01 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 77.1%
[2022-04-07 15:04:01 large] (utils.py 57): INFO output/large/default/ckpt_epoch_142.pth saving......
[2022-04-07 15:04:02 large] (utils.py 59): INFO output/large/default/ckpt_epoch_142.pth saved !!!
[2022-04-07 15:04:02 large] (main.py 148): INFO Max accuracy: 77.11%
[2022-04-07 15:04:09 large] (main.py 226): INFO Train: [143/300][0/2502]	eta 5:13:39 lr 0.000271	time 7.5216 (7.5216)	loss 3.5602 (3.5602)	grad_norm 3.5170 (3.5170)	mem 8931MB
[2022-04-07 15:04:59 large] (main.py 226): INFO Train: [143/300][100/2502]	eta 0:22:50 lr 0.000271	time 0.6228 (0.5707)	loss 2.3806 (3.3919)	grad_norm 4.7742 (3.5790)	mem 8931MB
[2022-04-07 15:06:02 large] (main.py 226): INFO Train: [143/300][200/2502]	eta 0:22:59 lr 0.000270	time 0.6498 (0.5992)	loss 3.4590 (3.3833)	grad_norm 3.1201 (3.5757)	mem 8931MB
[2022-04-07 15:07:08 large] (main.py 226): INFO Train: [143/300][300/2502]	eta 0:22:44 lr 0.000270	time 0.6451 (0.6197)	loss 4.1083 (3.3869)	grad_norm 3.9204 (3.5869)	mem 8931MB
[2022-04-07 15:08:14 large] (main.py 226): INFO Train: [143/300][400/2502]	eta 0:22:01 lr 0.000270	time 0.6586 (0.6286)	loss 3.5700 (3.3674)	grad_norm 2.6032 (3.5947)	mem 8931MB
[2022-04-07 15:09:18 large] (main.py 226): INFO Train: [143/300][500/2502]	eta 0:21:05 lr 0.000270	time 0.6799 (0.6321)	loss 3.8321 (3.3785)	grad_norm 3.7278 (3.5868)	mem 8931MB
[2022-04-07 15:10:23 large] (main.py 226): INFO Train: [143/300][600/2502]	eta 0:20:07 lr 0.000270	time 0.6340 (0.6346)	loss 3.5233 (3.3783)	grad_norm 3.6704 (3.5880)	mem 8931MB
[2022-04-07 15:11:28 large] (main.py 226): INFO Train: [143/300][700/2502]	eta 0:19:07 lr 0.000270	time 0.6526 (0.6367)	loss 3.5726 (3.3752)	grad_norm 3.1280 (3.6002)	mem 8931MB
[2022-04-07 15:12:32 large] (main.py 226): INFO Train: [143/300][800/2502]	eta 0:18:04 lr 0.000270	time 0.6725 (0.6374)	loss 2.4737 (3.3880)	grad_norm 2.6616 (3.5816)	mem 8931MB
[2022-04-07 15:13:36 large] (main.py 226): INFO Train: [143/300][900/2502]	eta 0:17:00 lr 0.000270	time 0.6933 (0.6370)	loss 3.6416 (3.3995)	grad_norm 2.9054 (3.5802)	mem 8931MB
[2022-04-07 15:14:40 large] (main.py 226): INFO Train: [143/300][1000/2502]	eta 0:15:57 lr 0.000270	time 0.7268 (0.6374)	loss 2.7924 (3.3986)	grad_norm 4.7262 (3.5746)	mem 8931MB
[2022-04-07 15:15:45 large] (main.py 226): INFO Train: [143/300][1100/2502]	eta 0:14:55 lr 0.000269	time 0.6538 (0.6385)	loss 2.4015 (3.3961)	grad_norm 3.4863 (3.5654)	mem 8931MB
[2022-04-07 15:16:47 large] (main.py 226): INFO Train: [143/300][1200/2502]	eta 0:13:49 lr 0.000269	time 0.6114 (0.6375)	loss 3.8952 (3.3912)	grad_norm 2.9926 (3.5682)	mem 8931MB
[2022-04-07 15:17:50 large] (main.py 226): INFO Train: [143/300][1300/2502]	eta 0:12:45 lr 0.000269	time 0.6208 (0.6370)	loss 2.1010 (3.3947)	grad_norm 3.6562 (3.5620)	mem 8931MB
[2022-04-07 15:18:54 large] (main.py 226): INFO Train: [143/300][1400/2502]	eta 0:11:41 lr 0.000269	time 0.6109 (0.6366)	loss 3.9873 (3.3938)	grad_norm 3.2289 (3.5612)	mem 8931MB
[2022-04-07 15:19:57 large] (main.py 226): INFO Train: [143/300][1500/2502]	eta 0:10:37 lr 0.000269	time 0.6637 (0.6363)	loss 3.7119 (3.3952)	grad_norm 3.2232 (3.5631)	mem 8931MB
[2022-04-07 15:21:01 large] (main.py 226): INFO Train: [143/300][1600/2502]	eta 0:09:34 lr 0.000269	time 0.6748 (0.6364)	loss 3.7321 (3.3949)	grad_norm 2.7000 (3.5620)	mem 8931MB
[2022-04-07 15:22:04 large] (main.py 226): INFO Train: [143/300][1700/2502]	eta 0:08:30 lr 0.000269	time 0.6204 (0.6365)	loss 3.5842 (3.4004)	grad_norm 3.6621 (3.5581)	mem 8931MB
[2022-04-07 15:23:07 large] (main.py 226): INFO Train: [143/300][1800/2502]	eta 0:07:26 lr 0.000269	time 0.5190 (0.6361)	loss 3.7365 (3.4002)	grad_norm 2.9189 (3.5524)	mem 8931MB
[2022-04-07 15:24:10 large] (main.py 226): INFO Train: [143/300][1900/2502]	eta 0:06:22 lr 0.000269	time 0.6611 (0.6356)	loss 2.4907 (3.4002)	grad_norm 3.2694 (3.5448)	mem 8931MB
[2022-04-07 15:25:13 large] (main.py 226): INFO Train: [143/300][2000/2502]	eta 0:05:18 lr 0.000269	time 0.6512 (0.6351)	loss 2.3874 (3.4039)	grad_norm 3.8245 (3.5483)	mem 8931MB
[2022-04-07 15:26:16 large] (main.py 226): INFO Train: [143/300][2100/2502]	eta 0:04:15 lr 0.000268	time 0.6274 (0.6352)	loss 2.5761 (3.4025)	grad_norm 3.3718 (3.5478)	mem 8931MB
[2022-04-07 15:27:18 large] (main.py 226): INFO Train: [143/300][2200/2502]	eta 0:03:11 lr 0.000268	time 0.5519 (0.6343)	loss 3.6678 (3.4042)	grad_norm 4.3244 (3.5632)	mem 8931MB
[2022-04-07 15:28:20 large] (main.py 226): INFO Train: [143/300][2300/2502]	eta 0:02:07 lr 0.000268	time 0.6146 (0.6336)	loss 3.6720 (3.3989)	grad_norm 3.3998 (3.5684)	mem 8931MB
[2022-04-07 15:29:23 large] (main.py 226): INFO Train: [143/300][2400/2502]	eta 0:01:04 lr 0.000268	time 0.6408 (0.6335)	loss 3.5301 (3.3976)	grad_norm 4.1616 (3.5661)	mem 8931MB
[2022-04-07 15:30:26 large] (main.py 226): INFO Train: [143/300][2500/2502]	eta 0:00:01 lr 0.000268	time 0.6096 (0.6334)	loss 3.3149 (3.4005)	grad_norm 3.7104 (3.5731)	mem 8931MB
[2022-04-07 15:30:27 large] (main.py 233): INFO EPOCH 143 training takes 0:26:25
[2022-04-07 15:30:34 large] (main.py 273): INFO Test: [0/98]	Time 6.509 (6.509)	Loss 1.0288 (1.0288)	Acc@1 79.102 (79.102)	Acc@5 95.703 (95.703)	Mem 8931MB
[2022-04-07 15:30:59 large] (main.py 279): INFO  * Acc@1 76.980 Acc@5 93.622
[2022-04-07 15:30:59 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 77.0%
[2022-04-07 15:30:59 large] (main.py 148): INFO Max accuracy: 77.11%
[2022-04-07 15:31:06 large] (main.py 226): INFO Train: [144/300][0/2502]	eta 4:44:19 lr 0.000268	time 6.8182 (6.8182)	loss 2.9871 (2.9871)	grad_norm 2.9975 (2.9975)	mem 8931MB
[2022-04-07 15:32:07 large] (main.py 226): INFO Train: [144/300][100/2502]	eta 0:26:50 lr 0.000268	time 0.6631 (0.6704)	loss 2.8247 (3.3613)	grad_norm 4.1414 (3.4776)	mem 8931MB
[2022-04-07 15:33:11 large] (main.py 226): INFO Train: [144/300][200/2502]	eta 0:25:03 lr 0.000268	time 0.7080 (0.6532)	loss 3.4884 (3.3580)	grad_norm 3.5339 (nan)	mem 8931MB
[2022-04-07 15:34:12 large] (main.py 226): INFO Train: [144/300][300/2502]	eta 0:23:30 lr 0.000268	time 0.6072 (0.6406)	loss 3.3014 (3.3645)	grad_norm 3.1378 (nan)	mem 8931MB
[2022-04-07 15:35:15 large] (main.py 226): INFO Train: [144/300][400/2502]	eta 0:22:19 lr 0.000268	time 0.6447 (0.6372)	loss 3.8895 (3.3638)	grad_norm 3.2731 (nan)	mem 8931MB
[2022-04-07 15:36:19 large] (main.py 226): INFO Train: [144/300][500/2502]	eta 0:21:16 lr 0.000268	time 0.6140 (0.6378)	loss 2.5409 (3.3773)	grad_norm 4.9482 (nan)	mem 8931MB
[2022-04-07 15:37:24 large] (main.py 226): INFO Train: [144/300][600/2502]	eta 0:20:15 lr 0.000267	time 0.6602 (0.6391)	loss 3.4691 (3.3862)	grad_norm 3.3473 (nan)	mem 8931MB
[2022-04-07 15:38:27 large] (main.py 226): INFO Train: [144/300][700/2502]	eta 0:19:09 lr 0.000267	time 0.6589 (0.6381)	loss 3.8150 (3.3843)	grad_norm 3.0423 (nan)	mem 8931MB
[2022-04-07 15:39:30 large] (main.py 226): INFO Train: [144/300][800/2502]	eta 0:18:05 lr 0.000267	time 0.6363 (0.6377)	loss 2.6773 (3.3824)	grad_norm 5.0242 (nan)	mem 8931MB
[2022-04-07 15:40:34 large] (main.py 226): INFO Train: [144/300][900/2502]	eta 0:17:01 lr 0.000267	time 0.6786 (0.6376)	loss 3.8252 (3.3872)	grad_norm 3.3057 (nan)	mem 8931MB
[2022-04-07 15:41:38 large] (main.py 226): INFO Train: [144/300][1000/2502]	eta 0:15:57 lr 0.000267	time 0.7332 (0.6378)	loss 2.9212 (3.3810)	grad_norm 4.6281 (nan)	mem 8931MB
[2022-04-07 15:42:42 large] (main.py 226): INFO Train: [144/300][1100/2502]	eta 0:14:55 lr 0.000267	time 0.6083 (0.6384)	loss 4.0399 (3.3806)	grad_norm 5.1256 (nan)	mem 8931MB
[2022-04-07 15:43:46 large] (main.py 226): INFO Train: [144/300][1200/2502]	eta 0:13:50 lr 0.000267	time 0.6495 (0.6379)	loss 2.9603 (3.3778)	grad_norm 3.1172 (nan)	mem 8931MB
[2022-04-07 15:44:49 large] (main.py 226): INFO Train: [144/300][1300/2502]	eta 0:12:46 lr 0.000267	time 0.6781 (0.6379)	loss 2.2541 (3.3749)	grad_norm 3.1963 (nan)	mem 8931MB
[2022-04-07 15:45:54 large] (main.py 226): INFO Train: [144/300][1400/2502]	eta 0:11:43 lr 0.000267	time 0.6760 (0.6384)	loss 3.2558 (3.3725)	grad_norm 4.0101 (nan)	mem 8931MB
[2022-04-07 15:46:58 large] (main.py 226): INFO Train: [144/300][1500/2502]	eta 0:10:40 lr 0.000266	time 0.5918 (0.6388)	loss 2.5646 (3.3738)	grad_norm 3.6504 (nan)	mem 8931MB
[2022-04-07 15:48:03 large] (main.py 226): INFO Train: [144/300][1600/2502]	eta 0:09:36 lr 0.000266	time 0.7003 (0.6394)	loss 3.8451 (3.3723)	grad_norm 3.3216 (nan)	mem 8931MB
[2022-04-07 15:49:07 large] (main.py 226): INFO Train: [144/300][1700/2502]	eta 0:08:32 lr 0.000266	time 0.6665 (0.6391)	loss 4.0613 (3.3693)	grad_norm 2.8118 (nan)	mem 8931MB
[2022-04-07 15:50:09 large] (main.py 226): INFO Train: [144/300][1800/2502]	eta 0:07:28 lr 0.000266	time 0.5861 (0.6385)	loss 3.6749 (3.3718)	grad_norm 3.4082 (nan)	mem 8931MB
[2022-04-07 15:51:14 large] (main.py 226): INFO Train: [144/300][1900/2502]	eta 0:06:24 lr 0.000266	time 0.6174 (0.6390)	loss 3.2998 (3.3702)	grad_norm 3.7789 (nan)	mem 8931MB
[2022-04-07 15:52:18 large] (main.py 226): INFO Train: [144/300][2000/2502]	eta 0:05:20 lr 0.000266	time 0.8087 (0.6388)	loss 3.5138 (3.3713)	grad_norm 4.0171 (nan)	mem 8931MB
[2022-04-07 15:53:23 large] (main.py 226): INFO Train: [144/300][2100/2502]	eta 0:04:16 lr 0.000266	time 0.6104 (0.6393)	loss 3.4914 (3.3746)	grad_norm 3.1482 (nan)	mem 8931MB
[2022-04-07 15:54:27 large] (main.py 226): INFO Train: [144/300][2200/2502]	eta 0:03:13 lr 0.000266	time 0.6832 (0.6394)	loss 3.7087 (3.3794)	grad_norm 3.4530 (nan)	mem 8931MB
[2022-04-07 15:55:31 large] (main.py 226): INFO Train: [144/300][2300/2502]	eta 0:02:09 lr 0.000266	time 0.6549 (0.6396)	loss 3.6244 (3.3787)	grad_norm 3.9027 (nan)	mem 8931MB
[2022-04-07 15:56:37 large] (main.py 226): INFO Train: [144/300][2400/2502]	eta 0:01:05 lr 0.000266	time 0.6573 (0.6403)	loss 3.8119 (3.3773)	grad_norm 3.9708 (nan)	mem 8931MB
[2022-04-07 15:57:42 large] (main.py 226): INFO Train: [144/300][2500/2502]	eta 0:00:01 lr 0.000265	time 0.5343 (0.6408)	loss 2.5637 (3.3781)	grad_norm 3.3297 (nan)	mem 8931MB
[2022-04-07 15:57:43 large] (main.py 233): INFO EPOCH 144 training takes 0:26:43
[2022-04-07 15:57:49 large] (main.py 273): INFO Test: [0/98]	Time 5.485 (5.485)	Loss 1.1077 (1.1077)	Acc@1 77.734 (77.734)	Acc@5 93.164 (93.164)	Mem 8931MB
[2022-04-07 15:58:16 large] (main.py 279): INFO  * Acc@1 77.256 Acc@5 93.602
[2022-04-07 15:58:16 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 77.3%
[2022-04-07 15:58:16 large] (utils.py 57): INFO output/large/default/ckpt_epoch_144.pth saving......
[2022-04-07 15:58:16 large] (utils.py 59): INFO output/large/default/ckpt_epoch_144.pth saved !!!
[2022-04-07 15:58:16 large] (main.py 148): INFO Max accuracy: 77.26%
[2022-04-07 15:58:25 large] (main.py 226): INFO Train: [145/300][0/2502]	eta 5:36:23 lr 0.000265	time 8.0670 (8.0670)	loss 3.2301 (3.2301)	grad_norm 3.4769 (3.4769)	mem 8931MB
[2022-04-07 15:59:26 large] (main.py 226): INFO Train: [145/300][100/2502]	eta 0:27:40 lr 0.000265	time 0.6633 (0.6914)	loss 2.4984 (3.3207)	grad_norm 4.3577 (3.4294)	mem 8931MB
[2022-04-07 16:00:32 large] (main.py 226): INFO Train: [145/300][200/2502]	eta 0:25:47 lr 0.000265	time 0.6721 (0.6723)	loss 2.1852 (3.3527)	grad_norm 4.6532 (3.6164)	mem 8931MB
[2022-04-07 16:01:37 large] (main.py 226): INFO Train: [145/300][300/2502]	eta 0:24:27 lr 0.000265	time 0.6717 (0.6664)	loss 2.7590 (3.3421)	grad_norm 2.5775 (3.5893)	mem 8931MB
[2022-04-07 16:02:42 large] (main.py 226): INFO Train: [145/300][400/2502]	eta 0:23:14 lr 0.000265	time 0.6682 (0.6632)	loss 2.4112 (3.3615)	grad_norm 3.2049 (3.6163)	mem 8931MB
[2022-04-07 16:03:48 large] (main.py 226): INFO Train: [145/300][500/2502]	eta 0:22:03 lr 0.000265	time 0.6181 (0.6612)	loss 3.5400 (3.3661)	grad_norm 4.1585 (3.6174)	mem 8931MB
[2022-04-07 16:04:52 large] (main.py 226): INFO Train: [145/300][600/2502]	eta 0:20:51 lr 0.000265	time 0.6096 (0.6582)	loss 3.8399 (3.3663)	grad_norm 4.0158 (3.6176)	mem 8931MB
[2022-04-07 16:05:58 large] (main.py 226): INFO Train: [145/300][700/2502]	eta 0:19:46 lr 0.000265	time 0.5421 (0.6585)	loss 2.6588 (3.3625)	grad_norm 3.9265 (3.6076)	mem 8931MB
[2022-04-07 16:07:03 large] (main.py 226): INFO Train: [145/300][800/2502]	eta 0:18:37 lr 0.000265	time 0.6288 (0.6567)	loss 3.4626 (3.3577)	grad_norm 2.8540 (3.6045)	mem 8931MB
[2022-04-07 16:08:08 large] (main.py 226): INFO Train: [145/300][900/2502]	eta 0:17:31 lr 0.000265	time 0.6567 (0.6564)	loss 4.2483 (3.3619)	grad_norm 3.9791 (3.5883)	mem 8931MB
[2022-04-07 16:09:13 large] (main.py 226): INFO Train: [145/300][1000/2502]	eta 0:16:24 lr 0.000264	time 0.7035 (0.6558)	loss 3.7804 (3.3605)	grad_norm 3.4965 (3.5864)	mem 8931MB
[2022-04-07 16:10:18 large] (main.py 226): INFO Train: [145/300][1100/2502]	eta 0:15:19 lr 0.000264	time 0.7062 (0.6555)	loss 2.7925 (3.3560)	grad_norm 2.9364 (3.5785)	mem 8931MB
[2022-04-07 16:11:22 large] (main.py 226): INFO Train: [145/300][1200/2502]	eta 0:14:11 lr 0.000264	time 0.5201 (0.6542)	loss 2.7962 (3.3530)	grad_norm 3.5594 (3.5835)	mem 8931MB
[2022-04-07 16:12:26 large] (main.py 226): INFO Train: [145/300][1300/2502]	eta 0:13:05 lr 0.000264	time 0.6813 (0.6532)	loss 3.9405 (3.3547)	grad_norm 3.3784 (3.5849)	mem 8931MB
[2022-04-07 16:13:31 large] (main.py 226): INFO Train: [145/300][1400/2502]	eta 0:11:59 lr 0.000264	time 0.6218 (0.6531)	loss 3.5034 (3.3586)	grad_norm 2.9762 (3.5982)	mem 8931MB
[2022-04-07 16:14:37 large] (main.py 226): INFO Train: [145/300][1500/2502]	eta 0:10:54 lr 0.000264	time 0.6436 (0.6532)	loss 3.1236 (3.3639)	grad_norm 3.8268 (3.5988)	mem 8931MB
[2022-04-07 16:15:42 large] (main.py 226): INFO Train: [145/300][1600/2502]	eta 0:09:49 lr 0.000264	time 0.6474 (0.6533)	loss 2.6496 (3.3617)	grad_norm 3.3447 (3.6061)	mem 8931MB
[2022-04-07 16:16:46 large] (main.py 226): INFO Train: [145/300][1700/2502]	eta 0:08:43 lr 0.000264	time 0.6487 (0.6523)	loss 2.3290 (3.3621)	grad_norm 3.1904 (3.6003)	mem 8931MB
[2022-04-07 16:17:48 large] (main.py 226): INFO Train: [145/300][1800/2502]	eta 0:07:36 lr 0.000264	time 0.5656 (0.6507)	loss 3.8396 (3.3578)	grad_norm 3.1203 (3.5940)	mem 8931MB
[2022-04-07 16:18:52 large] (main.py 226): INFO Train: [145/300][1900/2502]	eta 0:06:31 lr 0.000263	time 0.6741 (0.6497)	loss 3.7477 (3.3573)	grad_norm 7.0820 (3.6031)	mem 8931MB
[2022-04-07 16:19:57 large] (main.py 226): INFO Train: [145/300][2000/2502]	eta 0:05:26 lr 0.000263	time 1.3409 (0.6498)	loss 3.0626 (3.3615)	grad_norm 3.5877 (3.6057)	mem 8931MB
[2022-04-07 16:20:59 large] (main.py 226): INFO Train: [145/300][2100/2502]	eta 0:04:20 lr 0.000263	time 0.6417 (0.6486)	loss 3.7051 (3.3622)	grad_norm 3.0091 (3.6059)	mem 8931MB
[2022-04-07 16:22:03 large] (main.py 226): INFO Train: [145/300][2200/2502]	eta 0:03:15 lr 0.000263	time 0.7800 (0.6479)	loss 3.8470 (3.3674)	grad_norm 6.9084 (3.6125)	mem 8931MB
[2022-04-07 16:23:07 large] (main.py 226): INFO Train: [145/300][2300/2502]	eta 0:02:10 lr 0.000263	time 0.6692 (0.6478)	loss 3.5007 (3.3718)	grad_norm 4.1195 (3.6149)	mem 8931MB
[2022-04-07 16:24:11 large] (main.py 226): INFO Train: [145/300][2400/2502]	eta 0:01:06 lr 0.000263	time 0.6266 (0.6473)	loss 2.5254 (3.3714)	grad_norm 4.6937 (3.6149)	mem 8931MB
[2022-04-07 16:25:13 large] (main.py 226): INFO Train: [145/300][2500/2502]	eta 0:00:01 lr 0.000263	time 0.5528 (0.6462)	loss 4.0784 (3.3721)	grad_norm 4.5742 (3.6081)	mem 8931MB
[2022-04-07 16:25:14 large] (main.py 233): INFO EPOCH 145 training takes 0:26:57
[2022-04-07 16:25:20 large] (main.py 273): INFO Test: [0/98]	Time 6.127 (6.127)	Loss 1.2698 (1.2698)	Acc@1 73.438 (73.438)	Acc@5 91.797 (91.797)	Mem 8931MB
[2022-04-07 16:25:46 large] (main.py 279): INFO  * Acc@1 77.014 Acc@5 93.692
[2022-04-07 16:25:46 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 77.0%
[2022-04-07 16:25:46 large] (main.py 148): INFO Max accuracy: 77.26%
[2022-04-07 16:25:53 large] (main.py 226): INFO Train: [146/300][0/2502]	eta 4:43:46 lr 0.000263	time 6.8050 (6.8050)	loss 4.1653 (4.1653)	grad_norm 4.4213 (4.4213)	mem 8931MB
[2022-04-07 16:26:45 large] (main.py 226): INFO Train: [146/300][100/2502]	eta 0:23:18 lr 0.000263	time 0.5973 (0.5824)	loss 3.6333 (3.4233)	grad_norm 2.9365 (3.6669)	mem 8931MB
[2022-04-07 16:27:48 large] (main.py 226): INFO Train: [146/300][200/2502]	eta 0:23:25 lr 0.000263	time 0.6451 (0.6104)	loss 3.3753 (3.4439)	grad_norm 3.4025 (nan)	mem 8931MB
[2022-04-07 16:28:55 large] (main.py 226): INFO Train: [146/300][300/2502]	eta 0:23:05 lr 0.000263	time 0.6528 (0.6293)	loss 3.7435 (3.4483)	grad_norm 2.9565 (nan)	mem 8931MB
[2022-04-07 16:30:00 large] (main.py 226): INFO Train: [146/300][400/2502]	eta 0:22:11 lr 0.000262	time 0.6048 (0.6337)	loss 3.7848 (3.4293)	grad_norm 2.8759 (nan)	mem 8931MB
[2022-04-07 16:31:05 large] (main.py 226): INFO Train: [146/300][500/2502]	eta 0:21:15 lr 0.000262	time 0.6470 (0.6370)	loss 3.6384 (3.4381)	grad_norm 3.4754 (nan)	mem 8931MB
[2022-04-07 16:32:07 large] (main.py 226): INFO Train: [146/300][600/2502]	eta 0:20:07 lr 0.000262	time 0.6063 (0.6347)	loss 3.2040 (3.4352)	grad_norm 4.1335 (nan)	mem 8931MB
[2022-04-07 16:33:10 large] (main.py 226): INFO Train: [146/300][700/2502]	eta 0:19:02 lr 0.000262	time 0.5922 (0.6340)	loss 3.5541 (3.4119)	grad_norm 3.8357 (nan)	mem 8931MB
[2022-04-07 16:34:14 large] (main.py 226): INFO Train: [146/300][800/2502]	eta 0:18:00 lr 0.000262	time 0.6450 (0.6347)	loss 3.1535 (3.3935)	grad_norm 3.3456 (nan)	mem 8931MB
[2022-04-07 16:35:18 large] (main.py 226): INFO Train: [146/300][900/2502]	eta 0:16:56 lr 0.000262	time 0.5803 (0.6347)	loss 3.6595 (3.3882)	grad_norm 3.7708 (nan)	mem 8931MB
[2022-04-07 16:36:21 large] (main.py 226): INFO Train: [146/300][1000/2502]	eta 0:15:53 lr 0.000262	time 0.5958 (0.6350)	loss 4.0786 (3.3792)	grad_norm 3.2428 (nan)	mem 8931MB
[2022-04-07 16:37:25 large] (main.py 226): INFO Train: [146/300][1100/2502]	eta 0:14:50 lr 0.000262	time 0.6053 (0.6352)	loss 3.7112 (3.3688)	grad_norm 2.5155 (nan)	mem 8931MB
[2022-04-07 16:38:28 large] (main.py 226): INFO Train: [146/300][1200/2502]	eta 0:13:46 lr 0.000262	time 0.8138 (0.6351)	loss 3.2311 (3.3679)	grad_norm 3.3663 (nan)	mem 8931MB
[2022-04-07 16:39:33 large] (main.py 226): INFO Train: [146/300][1300/2502]	eta 0:12:44 lr 0.000262	time 0.5021 (0.6356)	loss 3.5594 (3.3686)	grad_norm 3.7232 (nan)	mem 8931MB
[2022-04-07 16:40:37 large] (main.py 226): INFO Train: [146/300][1400/2502]	eta 0:11:40 lr 0.000261	time 0.7412 (0.6360)	loss 3.8909 (3.3665)	grad_norm 4.2559 (nan)	mem 8931MB
[2022-04-07 16:41:40 large] (main.py 226): INFO Train: [146/300][1500/2502]	eta 0:10:37 lr 0.000261	time 0.6326 (0.6359)	loss 4.0390 (3.3650)	grad_norm 3.3929 (nan)	mem 8931MB
[2022-04-07 16:42:45 large] (main.py 226): INFO Train: [146/300][1600/2502]	eta 0:09:34 lr 0.000261	time 0.5765 (0.6366)	loss 3.9772 (3.3704)	grad_norm 3.5819 (nan)	mem 8931MB
[2022-04-07 16:43:49 large] (main.py 226): INFO Train: [146/300][1700/2502]	eta 0:08:30 lr 0.000261	time 0.5751 (0.6367)	loss 3.3364 (3.3727)	grad_norm 2.9295 (nan)	mem 8931MB
[2022-04-07 16:44:54 large] (main.py 226): INFO Train: [146/300][1800/2502]	eta 0:07:27 lr 0.000261	time 0.6779 (0.6374)	loss 3.8950 (3.3714)	grad_norm 3.1514 (nan)	mem 8931MB
[2022-04-07 16:45:58 large] (main.py 226): INFO Train: [146/300][1900/2502]	eta 0:06:24 lr 0.000261	time 0.6170 (0.6380)	loss 2.9936 (3.3676)	grad_norm 3.1429 (nan)	mem 8931MB
[2022-04-07 16:47:02 large] (main.py 226): INFO Train: [146/300][2000/2502]	eta 0:05:20 lr 0.000261	time 0.6228 (0.6378)	loss 4.2551 (3.3635)	grad_norm 3.4344 (nan)	mem 8931MB
[2022-04-07 16:48:06 large] (main.py 226): INFO Train: [146/300][2100/2502]	eta 0:04:16 lr 0.000261	time 0.6948 (0.6377)	loss 3.6304 (3.3637)	grad_norm 3.4834 (nan)	mem 8931MB
[2022-04-07 16:49:09 large] (main.py 226): INFO Train: [146/300][2200/2502]	eta 0:03:12 lr 0.000261	time 0.5828 (0.6375)	loss 3.6295 (3.3669)	grad_norm 3.1475 (nan)	mem 8931MB
[2022-04-07 16:50:12 large] (main.py 226): INFO Train: [146/300][2300/2502]	eta 0:02:08 lr 0.000260	time 0.6255 (0.6371)	loss 2.1770 (3.3622)	grad_norm 3.1806 (nan)	mem 8931MB
[2022-04-07 16:51:15 large] (main.py 226): INFO Train: [146/300][2400/2502]	eta 0:01:04 lr 0.000260	time 0.6941 (0.6371)	loss 3.8692 (3.3600)	grad_norm 3.1514 (nan)	mem 8931MB
[2022-04-07 16:52:19 large] (main.py 226): INFO Train: [146/300][2500/2502]	eta 0:00:01 lr 0.000260	time 0.6379 (0.6370)	loss 2.4779 (3.3567)	grad_norm 3.5007 (nan)	mem 8931MB
[2022-04-07 16:52:20 large] (main.py 233): INFO EPOCH 146 training takes 0:26:34
[2022-04-07 16:52:26 large] (main.py 273): INFO Test: [0/98]	Time 6.457 (6.457)	Loss 1.0140 (1.0140)	Acc@1 78.125 (78.125)	Acc@5 93.359 (93.359)	Mem 8931MB
[2022-04-07 16:52:52 large] (main.py 279): INFO  * Acc@1 77.008 Acc@5 93.774
[2022-04-07 16:52:52 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 77.0%
[2022-04-07 16:52:52 large] (main.py 148): INFO Max accuracy: 77.26%
[2022-04-07 16:52:59 large] (main.py 226): INFO Train: [147/300][0/2502]	eta 4:54:21 lr 0.000260	time 7.0588 (7.0588)	loss 3.9118 (3.9118)	grad_norm 4.9577 (4.9577)	mem 8931MB
[2022-04-07 16:53:59 large] (main.py 226): INFO Train: [147/300][100/2502]	eta 0:26:31 lr 0.000260	time 0.6254 (0.6626)	loss 3.0651 (3.3575)	grad_norm 3.4362 (3.7540)	mem 8931MB
[2022-04-07 16:55:04 large] (main.py 226): INFO Train: [147/300][200/2502]	eta 0:25:16 lr 0.000260	time 0.7920 (0.6587)	loss 3.0144 (3.3650)	grad_norm 4.5750 (3.7104)	mem 8931MB
[2022-04-07 16:56:10 large] (main.py 226): INFO Train: [147/300][300/2502]	eta 0:24:08 lr 0.000260	time 0.6706 (0.6579)	loss 2.2861 (3.3386)	grad_norm 2.3151 (3.7168)	mem 8931MB
[2022-04-07 16:57:15 large] (main.py 226): INFO Train: [147/300][400/2502]	eta 0:22:58 lr 0.000260	time 0.6723 (0.6559)	loss 3.3504 (3.3550)	grad_norm 3.5026 (3.7157)	mem 8931MB
[2022-04-07 16:58:20 large] (main.py 226): INFO Train: [147/300][500/2502]	eta 0:21:51 lr 0.000260	time 0.7360 (0.6552)	loss 2.8027 (3.3400)	grad_norm 3.3565 (3.7128)	mem 8931MB
[2022-04-07 16:59:24 large] (main.py 226): INFO Train: [147/300][600/2502]	eta 0:20:40 lr 0.000260	time 0.6761 (0.6520)	loss 3.9361 (3.3448)	grad_norm 3.3636 (3.6890)	mem 8931MB
[2022-04-07 17:00:28 large] (main.py 226): INFO Train: [147/300][700/2502]	eta 0:19:31 lr 0.000260	time 0.6134 (0.6504)	loss 4.1929 (3.3469)	grad_norm 3.7499 (3.6850)	mem 8931MB
[2022-04-07 17:01:33 large] (main.py 226): INFO Train: [147/300][800/2502]	eta 0:18:26 lr 0.000259	time 0.6108 (0.6504)	loss 2.8601 (3.3455)	grad_norm 5.2360 (3.7142)	mem 8931MB
[2022-04-07 17:02:37 large] (main.py 226): INFO Train: [147/300][900/2502]	eta 0:17:20 lr 0.000259	time 0.4386 (0.6496)	loss 2.9778 (3.3504)	grad_norm 4.9575 (3.7146)	mem 8931MB
[2022-04-07 17:03:42 large] (main.py 226): INFO Train: [147/300][1000/2502]	eta 0:16:16 lr 0.000259	time 0.7112 (0.6499)	loss 2.4685 (3.3543)	grad_norm 4.6250 (3.7079)	mem 8931MB
[2022-04-07 17:04:45 large] (main.py 226): INFO Train: [147/300][1100/2502]	eta 0:15:08 lr 0.000259	time 0.6128 (0.6481)	loss 3.7800 (3.3517)	grad_norm 3.8442 (3.7132)	mem 8931MB
[2022-04-07 17:05:49 large] (main.py 226): INFO Train: [147/300][1200/2502]	eta 0:14:02 lr 0.000259	time 0.6282 (0.6470)	loss 3.7246 (3.3540)	grad_norm 3.4887 (3.7136)	mem 8931MB
[2022-04-07 17:06:53 large] (main.py 226): INFO Train: [147/300][1300/2502]	eta 0:12:56 lr 0.000259	time 0.6928 (0.6463)	loss 3.7102 (3.3543)	grad_norm 3.0081 (3.7083)	mem 8931MB
[2022-04-07 17:07:56 large] (main.py 226): INFO Train: [147/300][1400/2502]	eta 0:11:51 lr 0.000259	time 0.5387 (0.6457)	loss 3.5312 (3.3544)	grad_norm 3.5185 (3.7068)	mem 8931MB
[2022-04-07 17:09:01 large] (main.py 226): INFO Train: [147/300][1500/2502]	eta 0:10:46 lr 0.000259	time 0.7140 (0.6454)	loss 3.9037 (3.3542)	grad_norm 4.0641 (3.7056)	mem 8931MB
[2022-04-07 17:10:04 large] (main.py 226): INFO Train: [147/300][1600/2502]	eta 0:09:41 lr 0.000259	time 0.6473 (0.6449)	loss 4.0635 (3.3604)	grad_norm 3.1721 (3.6933)	mem 8931MB
[2022-04-07 17:11:09 large] (main.py 226): INFO Train: [147/300][1700/2502]	eta 0:08:37 lr 0.000259	time 0.5938 (0.6449)	loss 3.8267 (3.3546)	grad_norm 3.6504 (3.6862)	mem 8931MB
[2022-04-07 17:12:13 large] (main.py 226): INFO Train: [147/300][1800/2502]	eta 0:07:32 lr 0.000258	time 0.6664 (0.6446)	loss 3.7130 (3.3571)	grad_norm 3.8787 (3.6811)	mem 8931MB
[2022-04-07 17:13:17 large] (main.py 226): INFO Train: [147/300][1900/2502]	eta 0:06:28 lr 0.000258	time 0.6350 (0.6447)	loss 2.9455 (3.3550)	grad_norm 3.5427 (3.6786)	mem 8931MB
[2022-04-07 17:14:21 large] (main.py 226): INFO Train: [147/300][2000/2502]	eta 0:05:23 lr 0.000258	time 0.5909 (0.6445)	loss 4.1410 (3.3530)	grad_norm 4.1281 (3.6725)	mem 8931MB
[2022-04-07 17:15:25 large] (main.py 226): INFO Train: [147/300][2100/2502]	eta 0:04:18 lr 0.000258	time 0.5726 (0.6439)	loss 2.5019 (3.3511)	grad_norm 3.2395 (nan)	mem 8931MB
[2022-04-07 17:16:27 large] (main.py 226): INFO Train: [147/300][2200/2502]	eta 0:03:14 lr 0.000258	time 0.5769 (0.6432)	loss 2.6178 (3.3539)	grad_norm 3.5268 (nan)	mem 8931MB
[2022-04-07 17:17:31 large] (main.py 226): INFO Train: [147/300][2300/2502]	eta 0:02:09 lr 0.000258	time 0.6736 (0.6429)	loss 3.6997 (3.3581)	grad_norm 3.7532 (nan)	mem 8931MB
[2022-04-07 17:18:35 large] (main.py 226): INFO Train: [147/300][2400/2502]	eta 0:01:05 lr 0.000258	time 0.6129 (0.6427)	loss 3.7757 (3.3588)	grad_norm 2.7170 (nan)	mem 8931MB
[2022-04-07 17:19:38 large] (main.py 226): INFO Train: [147/300][2500/2502]	eta 0:00:01 lr 0.000258	time 0.5975 (0.6423)	loss 2.2980 (3.3569)	grad_norm 3.9695 (nan)	mem 8931MB
[2022-04-07 17:19:39 large] (main.py 233): INFO EPOCH 147 training takes 0:26:47
[2022-04-07 17:19:46 large] (main.py 273): INFO Test: [0/98]	Time 6.370 (6.370)	Loss 1.0354 (1.0354)	Acc@1 77.344 (77.344)	Acc@5 94.336 (94.336)	Mem 8931MB
[2022-04-07 17:20:12 large] (main.py 279): INFO  * Acc@1 77.086 Acc@5 93.700
[2022-04-07 17:20:12 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 77.1%
[2022-04-07 17:20:12 large] (main.py 148): INFO Max accuracy: 77.26%
[2022-04-07 17:20:19 large] (main.py 226): INFO Train: [148/300][0/2502]	eta 5:11:09 lr 0.000258	time 7.4620 (7.4620)	loss 3.5832 (3.5832)	grad_norm 5.1323 (5.1323)	mem 8931MB
[2022-04-07 17:21:18 large] (main.py 226): INFO Train: [148/300][100/2502]	eta 0:26:11 lr 0.000258	time 0.6020 (0.6544)	loss 2.6974 (3.3649)	grad_norm 5.0925 (3.6745)	mem 8931MB
[2022-04-07 17:22:25 large] (main.py 226): INFO Train: [148/300][200/2502]	eta 0:25:24 lr 0.000257	time 0.7031 (0.6622)	loss 2.4218 (3.3402)	grad_norm 3.3105 (3.7196)	mem 8931MB
[2022-04-07 17:23:31 large] (main.py 226): INFO Train: [148/300][300/2502]	eta 0:24:16 lr 0.000257	time 0.6258 (0.6613)	loss 3.3382 (3.3716)	grad_norm 3.8885 (3.6610)	mem 8931MB
[2022-04-07 17:24:35 large] (main.py 226): INFO Train: [148/300][400/2502]	eta 0:23:02 lr 0.000257	time 0.6343 (0.6578)	loss 3.5072 (3.3627)	grad_norm 4.2392 (3.6944)	mem 8931MB
[2022-04-07 17:25:39 large] (main.py 226): INFO Train: [148/300][500/2502]	eta 0:21:47 lr 0.000257	time 0.6866 (0.6533)	loss 3.1091 (3.3634)	grad_norm 3.9403 (3.7112)	mem 8931MB
[2022-04-07 17:26:43 large] (main.py 226): INFO Train: [148/300][600/2502]	eta 0:20:39 lr 0.000257	time 0.5885 (0.6515)	loss 2.8486 (3.3534)	grad_norm 3.3357 (3.6961)	mem 8931MB
[2022-04-07 17:27:46 large] (main.py 226): INFO Train: [148/300][700/2502]	eta 0:19:29 lr 0.000257	time 0.5924 (0.6488)	loss 2.8395 (3.3557)	grad_norm 3.9825 (3.6879)	mem 8931MB
[2022-04-07 17:28:50 large] (main.py 226): INFO Train: [148/300][800/2502]	eta 0:18:22 lr 0.000257	time 0.6552 (0.6477)	loss 3.6629 (3.3528)	grad_norm 6.9420 (3.6704)	mem 8931MB
[2022-04-07 17:29:54 large] (main.py 226): INFO Train: [148/300][900/2502]	eta 0:17:15 lr 0.000257	time 0.6105 (0.6464)	loss 3.6700 (3.3405)	grad_norm 2.9176 (3.6959)	mem 8931MB
[2022-04-07 17:30:58 large] (main.py 226): INFO Train: [148/300][1000/2502]	eta 0:16:09 lr 0.000257	time 0.6327 (0.6454)	loss 3.4669 (3.3457)	grad_norm 3.3349 (3.6860)	mem 8931MB
[2022-04-07 17:32:02 large] (main.py 226): INFO Train: [148/300][1100/2502]	eta 0:15:04 lr 0.000257	time 0.6849 (0.6449)	loss 2.2261 (3.3484)	grad_norm 3.0670 (3.6789)	mem 8931MB
[2022-04-07 17:33:06 large] (main.py 226): INFO Train: [148/300][1200/2502]	eta 0:13:59 lr 0.000256	time 0.5109 (0.6445)	loss 2.8552 (3.3459)	grad_norm 4.4789 (3.6625)	mem 8931MB
[2022-04-07 17:34:09 large] (main.py 226): INFO Train: [148/300][1300/2502]	eta 0:12:53 lr 0.000256	time 0.6695 (0.6437)	loss 3.5239 (3.3544)	grad_norm 3.8632 (3.6592)	mem 8931MB
[2022-04-07 17:35:12 large] (main.py 226): INFO Train: [148/300][1400/2502]	eta 0:11:48 lr 0.000256	time 0.6244 (0.6430)	loss 3.8865 (3.3585)	grad_norm 3.0691 (3.6629)	mem 8931MB
[2022-04-07 17:36:17 large] (main.py 226): INFO Train: [148/300][1500/2502]	eta 0:10:44 lr 0.000256	time 0.6408 (0.6429)	loss 3.3845 (3.3519)	grad_norm 3.9861 (3.6742)	mem 8931MB
[2022-04-07 17:37:20 large] (main.py 226): INFO Train: [148/300][1600/2502]	eta 0:09:39 lr 0.000256	time 0.5058 (0.6426)	loss 3.6736 (3.3565)	grad_norm 3.8584 (3.6844)	mem 8931MB
[2022-04-07 17:38:25 large] (main.py 226): INFO Train: [148/300][1700/2502]	eta 0:08:35 lr 0.000256	time 0.6337 (0.6426)	loss 3.8013 (3.3597)	grad_norm 3.3961 (3.6885)	mem 8931MB
[2022-04-07 17:39:30 large] (main.py 226): INFO Train: [148/300][1800/2502]	eta 0:07:31 lr 0.000256	time 0.6946 (0.6430)	loss 3.6726 (3.3607)	grad_norm 3.9422 (3.6964)	mem 8931MB
[2022-04-07 17:40:34 large] (main.py 226): INFO Train: [148/300][1900/2502]	eta 0:06:27 lr 0.000256	time 0.6305 (0.6431)	loss 4.1836 (3.3581)	grad_norm 3.4848 (nan)	mem 8931MB
[2022-04-07 17:41:39 large] (main.py 226): INFO Train: [148/300][2000/2502]	eta 0:05:22 lr 0.000256	time 0.6672 (0.6432)	loss 3.3167 (3.3583)	grad_norm 4.1698 (nan)	mem 8931MB
[2022-04-07 17:42:43 large] (main.py 226): INFO Train: [148/300][2100/2502]	eta 0:04:18 lr 0.000256	time 0.5757 (0.6432)	loss 3.8077 (3.3534)	grad_norm 3.4502 (nan)	mem 8931MB
[2022-04-07 17:43:47 large] (main.py 226): INFO Train: [148/300][2200/2502]	eta 0:03:14 lr 0.000255	time 0.6413 (0.6433)	loss 3.2630 (3.3529)	grad_norm 3.2463 (nan)	mem 8931MB
[2022-04-07 17:44:52 large] (main.py 226): INFO Train: [148/300][2300/2502]	eta 0:02:09 lr 0.000255	time 0.6428 (0.6433)	loss 3.7129 (3.3547)	grad_norm 3.8821 (nan)	mem 8931MB
[2022-04-07 17:45:57 large] (main.py 226): INFO Train: [148/300][2400/2502]	eta 0:01:05 lr 0.000255	time 0.6896 (0.6437)	loss 2.3935 (3.3547)	grad_norm 4.5992 (nan)	mem 8931MB
[2022-04-07 17:47:00 large] (main.py 226): INFO Train: [148/300][2500/2502]	eta 0:00:01 lr 0.000255	time 0.6662 (0.6433)	loss 2.4425 (3.3542)	grad_norm 3.6457 (nan)	mem 8931MB
[2022-04-07 17:47:01 large] (main.py 233): INFO EPOCH 148 training takes 0:26:49
[2022-04-07 17:47:09 large] (main.py 273): INFO Test: [0/98]	Time 7.375 (7.375)	Loss 1.0952 (1.0952)	Acc@1 78.711 (78.711)	Acc@5 92.773 (92.773)	Mem 8931MB
[2022-04-07 17:47:34 large] (main.py 279): INFO  * Acc@1 77.218 Acc@5 93.736
[2022-04-07 17:47:34 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 77.2%
[2022-04-07 17:47:34 large] (main.py 148): INFO Max accuracy: 77.26%
[2022-04-07 17:47:41 large] (main.py 226): INFO Train: [149/300][0/2502]	eta 4:52:00 lr 0.000255	time 7.0027 (7.0027)	loss 3.3165 (3.3165)	grad_norm 4.3993 (4.3993)	mem 8931MB
[2022-04-07 17:48:35 large] (main.py 226): INFO Train: [149/300][100/2502]	eta 0:24:28 lr 0.000255	time 0.5929 (0.6115)	loss 3.8627 (3.3067)	grad_norm 3.3063 (3.6381)	mem 8931MB
[2022-04-07 17:49:41 large] (main.py 226): INFO Train: [149/300][200/2502]	eta 0:24:23 lr 0.000255	time 0.6697 (0.6358)	loss 3.9769 (3.3422)	grad_norm 3.2841 (nan)	mem 8931MB
[2022-04-07 17:50:48 large] (main.py 226): INFO Train: [149/300][300/2502]	eta 0:23:40 lr 0.000255	time 0.6905 (0.6453)	loss 3.8625 (3.3480)	grad_norm 4.0217 (nan)	mem 8931MB
[2022-04-07 17:51:53 large] (main.py 226): INFO Train: [149/300][400/2502]	eta 0:22:41 lr 0.000255	time 0.6381 (0.6479)	loss 3.8897 (3.3715)	grad_norm 3.0353 (nan)	mem 8931MB
[2022-04-07 17:53:00 large] (main.py 226): INFO Train: [149/300][500/2502]	eta 0:21:44 lr 0.000255	time 0.6226 (0.6516)	loss 3.4073 (3.3502)	grad_norm 3.3777 (nan)	mem 8931MB
[2022-04-07 17:54:04 large] (main.py 226): INFO Train: [149/300][600/2502]	eta 0:20:34 lr 0.000254	time 0.6175 (0.6491)	loss 2.7362 (3.3418)	grad_norm 3.9907 (nan)	mem 8931MB
[2022-04-07 17:55:07 large] (main.py 226): INFO Train: [149/300][700/2502]	eta 0:19:25 lr 0.000254	time 0.6437 (0.6467)	loss 2.8305 (3.3271)	grad_norm 2.9679 (nan)	mem 8931MB
[2022-04-07 17:56:10 large] (main.py 226): INFO Train: [149/300][800/2502]	eta 0:18:17 lr 0.000254	time 0.6402 (0.6451)	loss 4.1432 (3.3363)	grad_norm 3.8083 (nan)	mem 8931MB
[2022-04-07 17:57:15 large] (main.py 226): INFO Train: [149/300][900/2502]	eta 0:17:12 lr 0.000254	time 0.6684 (0.6447)	loss 3.6427 (3.3246)	grad_norm 3.8011 (nan)	mem 8931MB
[2022-04-07 17:58:18 large] (main.py 226): INFO Train: [149/300][1000/2502]	eta 0:16:06 lr 0.000254	time 0.6813 (0.6435)	loss 2.7692 (3.3251)	grad_norm 3.5283 (nan)	mem 8931MB
[2022-04-07 17:59:23 large] (main.py 226): INFO Train: [149/300][1100/2502]	eta 0:15:03 lr 0.000254	time 0.6410 (0.6447)	loss 3.7664 (3.3324)	grad_norm 3.0704 (nan)	mem 8931MB
[2022-04-07 18:00:27 large] (main.py 226): INFO Train: [149/300][1200/2502]	eta 0:13:58 lr 0.000254	time 0.6159 (0.6442)	loss 3.8275 (3.3356)	grad_norm 3.0767 (nan)	mem 8931MB
[2022-04-07 18:01:32 large] (main.py 226): INFO Train: [149/300][1300/2502]	eta 0:12:54 lr 0.000254	time 0.6602 (0.6444)	loss 3.7340 (3.3425)	grad_norm 3.2908 (nan)	mem 8931MB
[2022-04-07 18:02:37 large] (main.py 226): INFO Train: [149/300][1400/2502]	eta 0:11:50 lr 0.000254	time 0.6302 (0.6449)	loss 4.0239 (3.3477)	grad_norm 3.5635 (nan)	mem 8931MB
[2022-04-07 18:03:42 large] (main.py 226): INFO Train: [149/300][1500/2502]	eta 0:10:46 lr 0.000254	time 0.6805 (0.6450)	loss 3.5625 (3.3432)	grad_norm 4.7360 (nan)	mem 8931MB
[2022-04-07 18:04:48 large] (main.py 226): INFO Train: [149/300][1600/2502]	eta 0:09:42 lr 0.000253	time 0.6179 (0.6459)	loss 3.8148 (3.3407)	grad_norm 4.9529 (nan)	mem 8931MB
[2022-04-07 18:05:53 large] (main.py 226): INFO Train: [149/300][1700/2502]	eta 0:08:38 lr 0.000253	time 0.6187 (0.6464)	loss 2.4607 (3.3422)	grad_norm 5.3112 (nan)	mem 8931MB
[2022-04-07 18:06:59 large] (main.py 226): INFO Train: [149/300][1800/2502]	eta 0:07:34 lr 0.000253	time 0.5894 (0.6470)	loss 3.7606 (3.3428)	grad_norm 5.9232 (nan)	mem 8931MB
[2022-04-07 18:08:04 large] (main.py 226): INFO Train: [149/300][1900/2502]	eta 0:06:29 lr 0.000253	time 0.6755 (0.6471)	loss 3.9643 (3.3501)	grad_norm 4.0225 (nan)	mem 8931MB
[2022-04-07 18:09:09 large] (main.py 226): INFO Train: [149/300][2000/2502]	eta 0:05:24 lr 0.000253	time 0.7197 (0.6471)	loss 4.1819 (3.3479)	grad_norm 3.1685 (nan)	mem 8931MB
[2022-04-07 18:10:14 large] (main.py 226): INFO Train: [149/300][2100/2502]	eta 0:04:20 lr 0.000253	time 0.6933 (0.6474)	loss 2.2409 (3.3475)	grad_norm 4.1470 (nan)	mem 8931MB
[2022-04-07 18:11:19 large] (main.py 226): INFO Train: [149/300][2200/2502]	eta 0:03:15 lr 0.000253	time 0.7236 (0.6476)	loss 2.3316 (3.3458)	grad_norm 2.9112 (nan)	mem 8931MB
[2022-04-07 18:12:23 large] (main.py 226): INFO Train: [149/300][2300/2502]	eta 0:02:10 lr 0.000253	time 0.6641 (0.6474)	loss 3.2563 (3.3460)	grad_norm 3.8442 (nan)	mem 8931MB
[2022-04-07 18:13:28 large] (main.py 226): INFO Train: [149/300][2400/2502]	eta 0:01:06 lr 0.000253	time 0.6331 (0.6475)	loss 3.6696 (3.3463)	grad_norm 2.8956 (nan)	mem 8931MB
[2022-04-07 18:14:33 large] (main.py 226): INFO Train: [149/300][2500/2502]	eta 0:00:01 lr 0.000253	time 0.6072 (0.6473)	loss 3.8242 (3.3467)	grad_norm 3.5342 (nan)	mem 8931MB
[2022-04-07 18:14:34 large] (main.py 233): INFO EPOCH 149 training takes 0:27:00
[2022-04-07 18:14:40 large] (main.py 273): INFO Test: [0/98]	Time 6.737 (6.737)	Loss 1.1842 (1.1842)	Acc@1 76.172 (76.172)	Acc@5 92.578 (92.578)	Mem 8931MB
[2022-04-07 18:15:06 large] (main.py 279): INFO  * Acc@1 77.314 Acc@5 93.856
[2022-04-07 18:15:06 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 77.3%
[2022-04-07 18:15:06 large] (utils.py 57): INFO output/large/default/ckpt_epoch_149.pth saving......
[2022-04-07 18:15:07 large] (utils.py 59): INFO output/large/default/ckpt_epoch_149.pth saved !!!
[2022-04-07 18:15:07 large] (main.py 148): INFO Max accuracy: 77.31%
[2022-04-07 18:15:14 large] (main.py 226): INFO Train: [150/300][0/2502]	eta 5:11:45 lr 0.000252	time 7.4763 (7.4763)	loss 3.4828 (3.4828)	grad_norm 3.1619 (3.1619)	mem 8931MB
[2022-04-07 18:16:03 large] (main.py 226): INFO Train: [150/300][100/2502]	eta 0:22:17 lr 0.000252	time 0.4950 (0.5569)	loss 2.8679 (3.3064)	grad_norm 4.3241 (3.6824)	mem 8931MB
[2022-04-07 18:17:03 large] (main.py 226): INFO Train: [150/300][200/2502]	eta 0:22:12 lr 0.000252	time 0.6505 (0.5787)	loss 3.6801 (3.3592)	grad_norm 3.2862 (3.7732)	mem 8931MB
[2022-04-07 18:18:09 large] (main.py 226): INFO Train: [150/300][300/2502]	eta 0:22:15 lr 0.000252	time 0.7263 (0.6063)	loss 3.5619 (3.3462)	grad_norm 5.1378 (3.7877)	mem 8931MB
[2022-04-07 18:19:15 large] (main.py 226): INFO Train: [150/300][400/2502]	eta 0:21:41 lr 0.000252	time 0.6909 (0.6191)	loss 3.5714 (3.3656)	grad_norm 3.4539 (3.7589)	mem 8931MB
[2022-04-07 18:20:20 large] (main.py 226): INFO Train: [150/300][500/2502]	eta 0:20:49 lr 0.000252	time 0.6458 (0.6241)	loss 3.6452 (3.3471)	grad_norm 4.1227 (3.7687)	mem 8931MB
[2022-04-07 18:21:25 large] (main.py 226): INFO Train: [150/300][600/2502]	eta 0:19:57 lr 0.000252	time 0.6754 (0.6294)	loss 3.7801 (3.3477)	grad_norm 4.5219 (3.7914)	mem 8931MB
[2022-04-07 18:22:29 large] (main.py 226): INFO Train: [150/300][700/2502]	eta 0:18:57 lr 0.000252	time 0.6544 (0.6314)	loss 2.7974 (3.3419)	grad_norm 4.2528 (3.7747)	mem 8931MB
[2022-04-07 18:23:35 large] (main.py 226): INFO Train: [150/300][800/2502]	eta 0:17:59 lr 0.000252	time 0.6488 (0.6345)	loss 2.3058 (3.3269)	grad_norm 3.0070 (3.7644)	mem 8931MB
[2022-04-07 18:24:39 large] (main.py 226): INFO Train: [150/300][900/2502]	eta 0:16:57 lr 0.000252	time 0.5670 (0.6353)	loss 3.4967 (3.3208)	grad_norm 3.5400 (3.7696)	mem 8931MB
[2022-04-07 18:25:45 large] (main.py 226): INFO Train: [150/300][1000/2502]	eta 0:15:57 lr 0.000251	time 0.7269 (0.6376)	loss 3.7742 (3.3180)	grad_norm 3.8237 (3.7623)	mem 8931MB
[2022-04-07 18:26:49 large] (main.py 226): INFO Train: [150/300][1100/2502]	eta 0:14:54 lr 0.000251	time 0.6703 (0.6379)	loss 3.6158 (3.3188)	grad_norm 2.7139 (3.7621)	mem 8931MB
[2022-04-07 18:27:55 large] (main.py 226): INFO Train: [150/300][1200/2502]	eta 0:13:52 lr 0.000251	time 0.6366 (0.6392)	loss 2.6109 (3.3226)	grad_norm 3.6502 (3.7498)	mem 8931MB
[2022-04-07 18:28:59 large] (main.py 226): INFO Train: [150/300][1300/2502]	eta 0:12:48 lr 0.000251	time 0.6082 (0.6396)	loss 2.0527 (3.3259)	grad_norm 3.4182 (3.7551)	mem 8931MB
[2022-04-07 18:30:03 large] (main.py 226): INFO Train: [150/300][1400/2502]	eta 0:11:44 lr 0.000251	time 0.6236 (0.6396)	loss 3.8504 (3.3278)	grad_norm 3.0164 (3.7562)	mem 8931MB
[2022-04-07 18:31:08 large] (main.py 226): INFO Train: [150/300][1500/2502]	eta 0:10:41 lr 0.000251	time 0.6314 (0.6402)	loss 2.9979 (3.3309)	grad_norm 3.8419 (3.7691)	mem 8931MB
[2022-04-07 18:32:11 large] (main.py 226): INFO Train: [150/300][1600/2502]	eta 0:09:37 lr 0.000251	time 0.6354 (0.6399)	loss 3.5041 (3.3363)	grad_norm 4.4069 (3.7599)	mem 8931MB
[2022-04-07 18:33:16 large] (main.py 226): INFO Train: [150/300][1700/2502]	eta 0:08:33 lr 0.000251	time 0.6733 (0.6403)	loss 3.8270 (3.3344)	grad_norm 3.4074 (3.7508)	mem 8931MB
[2022-04-07 18:34:19 large] (main.py 226): INFO Train: [150/300][1800/2502]	eta 0:07:29 lr 0.000251	time 0.6034 (0.6396)	loss 3.9024 (3.3323)	grad_norm 3.9484 (3.7469)	mem 8931MB
[2022-04-07 18:35:22 large] (main.py 226): INFO Train: [150/300][1900/2502]	eta 0:06:24 lr 0.000251	time 0.6812 (0.6394)	loss 2.8611 (3.3359)	grad_norm 3.3577 (3.7461)	mem 8931MB
[2022-04-07 18:36:25 large] (main.py 226): INFO Train: [150/300][2000/2502]	eta 0:05:20 lr 0.000250	time 0.6908 (0.6389)	loss 3.5625 (3.3388)	grad_norm 4.3574 (3.7459)	mem 8931MB
[2022-04-07 18:37:29 large] (main.py 226): INFO Train: [150/300][2100/2502]	eta 0:04:16 lr 0.000250	time 0.7400 (0.6390)	loss 3.8534 (3.3382)	grad_norm 4.2418 (3.7595)	mem 8931MB
[2022-04-07 18:38:33 large] (main.py 226): INFO Train: [150/300][2200/2502]	eta 0:03:12 lr 0.000250	time 0.5883 (0.6390)	loss 3.2877 (3.3355)	grad_norm 3.4526 (inf)	mem 8931MB
[2022-04-07 18:39:36 large] (main.py 226): INFO Train: [150/300][2300/2502]	eta 0:02:08 lr 0.000250	time 0.5482 (0.6384)	loss 3.6344 (3.3354)	grad_norm 4.2329 (inf)	mem 8931MB
[2022-04-07 18:40:40 large] (main.py 226): INFO Train: [150/300][2400/2502]	eta 0:01:05 lr 0.000250	time 0.6257 (0.6385)	loss 3.3608 (3.3336)	grad_norm 3.2053 (inf)	mem 8931MB
[2022-04-07 18:41:43 large] (main.py 226): INFO Train: [150/300][2500/2502]	eta 0:00:01 lr 0.000250	time 0.6040 (0.6381)	loss 3.6824 (3.3359)	grad_norm 3.2703 (inf)	mem 8931MB
[2022-04-07 18:41:44 large] (main.py 233): INFO EPOCH 150 training takes 0:26:36
[2022-04-07 18:41:50 large] (main.py 273): INFO Test: [0/98]	Time 6.037 (6.037)	Loss 0.9787 (0.9787)	Acc@1 80.273 (80.273)	Acc@5 94.141 (94.141)	Mem 8931MB
[2022-04-07 18:42:16 large] (main.py 279): INFO  * Acc@1 77.446 Acc@5 93.922
[2022-04-07 18:42:16 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 77.4%
[2022-04-07 18:42:16 large] (utils.py 57): INFO output/large/default/ckpt_epoch_150.pth saving......
[2022-04-07 18:42:17 large] (utils.py 59): INFO output/large/default/ckpt_epoch_150.pth saved !!!
[2022-04-07 18:42:17 large] (main.py 148): INFO Max accuracy: 77.45%
[2022-04-07 18:42:24 large] (main.py 226): INFO Train: [151/300][0/2502]	eta 5:16:31 lr 0.000250	time 7.5906 (7.5906)	loss 2.5822 (2.5822)	grad_norm 3.6289 (3.6289)	mem 8931MB
[2022-04-07 18:43:18 large] (main.py 226): INFO Train: [151/300][100/2502]	eta 0:24:11 lr 0.000250	time 0.5933 (0.6043)	loss 3.3863 (3.3926)	grad_norm 3.9204 (3.8485)	mem 8931MB
[2022-04-07 18:44:22 large] (main.py 226): INFO Train: [151/300][200/2502]	eta 0:23:53 lr 0.000250	time 0.5295 (0.6225)	loss 4.0988 (3.3617)	grad_norm 3.7839 (3.7957)	mem 8931MB
[2022-04-07 18:45:27 large] (main.py 226): INFO Train: [151/300][300/2502]	eta 0:23:07 lr 0.000250	time 0.5926 (0.6302)	loss 4.0899 (3.3360)	grad_norm 3.8580 (3.7380)	mem 8931MB
[2022-04-07 18:46:31 large] (main.py 226): INFO Train: [151/300][400/2502]	eta 0:22:11 lr 0.000249	time 0.5821 (0.6333)	loss 2.6724 (3.3547)	grad_norm 3.0330 (3.7064)	mem 8931MB
[2022-04-07 18:47:36 large] (main.py 226): INFO Train: [151/300][500/2502]	eta 0:21:16 lr 0.000249	time 0.6306 (0.6378)	loss 3.5630 (3.3604)	grad_norm 3.7685 (3.7144)	mem 8931MB
[2022-04-07 18:48:41 large] (main.py 226): INFO Train: [151/300][600/2502]	eta 0:20:16 lr 0.000249	time 0.7227 (0.6395)	loss 3.9206 (3.3660)	grad_norm 4.9784 (3.7472)	mem 8931MB
[2022-04-07 18:49:46 large] (main.py 226): INFO Train: [151/300][700/2502]	eta 0:19:13 lr 0.000249	time 0.7168 (0.6403)	loss 3.8841 (3.3659)	grad_norm 3.8097 (3.7614)	mem 8931MB
[2022-04-07 18:50:50 large] (main.py 226): INFO Train: [151/300][800/2502]	eta 0:18:11 lr 0.000249	time 0.5985 (0.6410)	loss 4.0256 (3.3673)	grad_norm 3.8713 (3.7503)	mem 8931MB
[2022-04-07 18:51:55 large] (main.py 226): INFO Train: [151/300][900/2502]	eta 0:17:07 lr 0.000249	time 0.6310 (0.6416)	loss 2.3680 (3.3630)	grad_norm 3.7031 (3.7766)	mem 8931MB
[2022-04-07 18:53:00 large] (main.py 226): INFO Train: [151/300][1000/2502]	eta 0:16:05 lr 0.000249	time 0.6598 (0.6425)	loss 2.8337 (3.3544)	grad_norm 3.1549 (3.7874)	mem 8931MB
[2022-04-07 18:54:05 large] (main.py 226): INFO Train: [151/300][1100/2502]	eta 0:15:01 lr 0.000249	time 0.6137 (0.6431)	loss 3.3011 (3.3553)	grad_norm 3.4847 (3.7829)	mem 8931MB
[2022-04-07 18:55:10 large] (main.py 226): INFO Train: [151/300][1200/2502]	eta 0:13:57 lr 0.000249	time 0.5973 (0.6436)	loss 2.6259 (3.3509)	grad_norm 3.8297 (3.7765)	mem 8931MB
[2022-04-07 18:56:14 large] (main.py 226): INFO Train: [151/300][1300/2502]	eta 0:12:53 lr 0.000249	time 0.5425 (0.6433)	loss 3.3454 (3.3495)	grad_norm 4.5661 (3.7640)	mem 8931MB
[2022-04-07 18:57:19 large] (main.py 226): INFO Train: [151/300][1400/2502]	eta 0:11:49 lr 0.000248	time 0.5390 (0.6441)	loss 4.0758 (3.3493)	grad_norm 3.8772 (3.7544)	mem 8931MB
[2022-04-07 18:58:23 large] (main.py 226): INFO Train: [151/300][1500/2502]	eta 0:10:45 lr 0.000248	time 0.5480 (0.6437)	loss 3.3957 (3.3469)	grad_norm 3.6295 (3.7507)	mem 8931MB
[2022-04-07 18:59:29 large] (main.py 226): INFO Train: [151/300][1600/2502]	eta 0:09:41 lr 0.000248	time 0.6210 (0.6445)	loss 3.3972 (3.3453)	grad_norm 4.9960 (3.7511)	mem 8931MB
[2022-04-07 19:00:33 large] (main.py 226): INFO Train: [151/300][1700/2502]	eta 0:08:37 lr 0.000248	time 0.5290 (0.6447)	loss 2.3196 (3.3410)	grad_norm 3.0699 (3.7418)	mem 8931MB
[2022-04-07 19:01:37 large] (main.py 226): INFO Train: [151/300][1800/2502]	eta 0:07:32 lr 0.000248	time 0.6623 (0.6444)	loss 3.6376 (3.3445)	grad_norm 4.7179 (3.7380)	mem 8931MB
[2022-04-07 19:02:41 large] (main.py 226): INFO Train: [151/300][1900/2502]	eta 0:06:27 lr 0.000248	time 0.5988 (0.6439)	loss 2.1559 (3.3487)	grad_norm 4.1253 (3.7358)	mem 8931MB
[2022-04-07 19:03:44 large] (main.py 226): INFO Train: [151/300][2000/2502]	eta 0:05:22 lr 0.000248	time 0.5808 (0.6432)	loss 3.4071 (3.3429)	grad_norm 3.0133 (3.7389)	mem 8931MB
[2022-04-07 19:04:48 large] (main.py 226): INFO Train: [151/300][2100/2502]	eta 0:04:18 lr 0.000248	time 0.6452 (0.6429)	loss 3.5464 (3.3404)	grad_norm 2.8908 (3.7382)	mem 8931MB
[2022-04-07 19:05:51 large] (main.py 226): INFO Train: [151/300][2200/2502]	eta 0:03:14 lr 0.000248	time 0.6292 (0.6424)	loss 3.2322 (3.3397)	grad_norm 3.4161 (3.7340)	mem 8931MB
[2022-04-07 19:06:54 large] (main.py 226): INFO Train: [151/300][2300/2502]	eta 0:02:09 lr 0.000248	time 0.5573 (0.6421)	loss 4.0676 (3.3439)	grad_norm 3.8304 (3.7320)	mem 8931MB
[2022-04-07 19:07:57 large] (main.py 226): INFO Train: [151/300][2400/2502]	eta 0:01:05 lr 0.000247	time 0.6723 (0.6414)	loss 3.7057 (3.3430)	grad_norm 3.7486 (3.7328)	mem 8931MB
[2022-04-07 19:08:59 large] (main.py 226): INFO Train: [151/300][2500/2502]	eta 0:00:01 lr 0.000247	time 0.6167 (0.6407)	loss 3.6005 (3.3426)	grad_norm 4.5791 (3.7325)	mem 8931MB
[2022-04-07 19:09:00 large] (main.py 233): INFO EPOCH 151 training takes 0:26:43
[2022-04-07 19:09:07 large] (main.py 273): INFO Test: [0/98]	Time 7.210 (7.210)	Loss 1.1589 (1.1589)	Acc@1 74.805 (74.805)	Acc@5 92.578 (92.578)	Mem 8931MB
[2022-04-07 19:09:33 large] (main.py 279): INFO  * Acc@1 77.402 Acc@5 93.912
[2022-04-07 19:09:33 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 77.4%
[2022-04-07 19:09:33 large] (main.py 148): INFO Max accuracy: 77.45%
[2022-04-07 19:09:39 large] (main.py 226): INFO Train: [152/300][0/2502]	eta 4:34:49 lr 0.000247	time 6.5903 (6.5903)	loss 3.6294 (3.6294)	grad_norm 3.5860 (3.5860)	mem 8931MB
[2022-04-07 19:10:32 large] (main.py 226): INFO Train: [152/300][100/2502]	eta 0:23:29 lr 0.000247	time 0.5635 (0.5868)	loss 3.3066 (3.3164)	grad_norm 3.6387 (3.8568)	mem 8931MB
[2022-04-07 19:11:36 large] (main.py 226): INFO Train: [152/300][200/2502]	eta 0:23:29 lr 0.000247	time 0.6252 (0.6121)	loss 3.5845 (3.3333)	grad_norm 3.5977 (3.8411)	mem 8931MB
[2022-04-07 19:12:40 large] (main.py 226): INFO Train: [152/300][300/2502]	eta 0:22:53 lr 0.000247	time 0.6281 (0.6237)	loss 4.1113 (3.3436)	grad_norm 4.2367 (3.8160)	mem 8931MB
[2022-04-07 19:13:44 large] (main.py 226): INFO Train: [152/300][400/2502]	eta 0:21:55 lr 0.000247	time 0.5979 (0.6260)	loss 2.6195 (3.3500)	grad_norm 3.9794 (3.8421)	mem 8931MB
[2022-04-07 19:14:48 large] (main.py 226): INFO Train: [152/300][500/2502]	eta 0:20:59 lr 0.000247	time 0.7486 (0.6291)	loss 2.9531 (3.3420)	grad_norm 2.8290 (3.8331)	mem 8931MB
[2022-04-07 19:15:51 large] (main.py 226): INFO Train: [152/300][600/2502]	eta 0:19:58 lr 0.000247	time 0.6665 (0.6300)	loss 3.2637 (3.3297)	grad_norm 4.3348 (3.8268)	mem 8931MB
[2022-04-07 19:16:56 large] (main.py 226): INFO Train: [152/300][700/2502]	eta 0:18:58 lr 0.000247	time 0.6475 (0.6317)	loss 3.9364 (3.3325)	grad_norm 4.7544 (3.8188)	mem 8931MB
[2022-04-07 19:17:59 large] (main.py 226): INFO Train: [152/300][800/2502]	eta 0:17:56 lr 0.000246	time 0.6279 (0.6322)	loss 3.5340 (3.3336)	grad_norm 3.6796 (3.8096)	mem 8931MB
[2022-04-07 19:19:02 large] (main.py 226): INFO Train: [152/300][900/2502]	eta 0:16:52 lr 0.000246	time 0.6977 (0.6323)	loss 2.8355 (3.3243)	grad_norm 4.9092 (3.7896)	mem 8931MB
[2022-04-07 19:20:05 large] (main.py 226): INFO Train: [152/300][1000/2502]	eta 0:15:48 lr 0.000246	time 0.5820 (0.6317)	loss 3.3953 (3.3198)	grad_norm 4.0091 (3.7957)	mem 8931MB
[2022-04-07 19:21:08 large] (main.py 226): INFO Train: [152/300][1100/2502]	eta 0:14:45 lr 0.000246	time 0.6947 (0.6319)	loss 3.7048 (3.3186)	grad_norm 4.8830 (nan)	mem 8931MB
[2022-04-07 19:22:13 large] (main.py 226): INFO Train: [152/300][1200/2502]	eta 0:13:43 lr 0.000246	time 0.5747 (0.6328)	loss 3.8760 (3.3279)	grad_norm 3.4948 (nan)	mem 8931MB
[2022-04-07 19:23:17 large] (main.py 226): INFO Train: [152/300][1300/2502]	eta 0:12:41 lr 0.000246	time 0.5879 (0.6333)	loss 3.3202 (3.3322)	grad_norm 3.2357 (nan)	mem 8931MB
[2022-04-07 19:24:21 large] (main.py 226): INFO Train: [152/300][1400/2502]	eta 0:11:38 lr 0.000246	time 0.6009 (0.6338)	loss 3.0134 (3.3288)	grad_norm 5.2020 (nan)	mem 8931MB
[2022-04-07 19:25:25 large] (main.py 226): INFO Train: [152/300][1500/2502]	eta 0:10:35 lr 0.000246	time 0.6729 (0.6342)	loss 3.0637 (3.3329)	grad_norm 4.7025 (nan)	mem 8931MB
[2022-04-07 19:26:30 large] (main.py 226): INFO Train: [152/300][1600/2502]	eta 0:09:33 lr 0.000246	time 0.7776 (0.6353)	loss 3.5443 (3.3352)	grad_norm 3.2559 (nan)	mem 8931MB
[2022-04-07 19:27:34 large] (main.py 226): INFO Train: [152/300][1700/2502]	eta 0:08:29 lr 0.000246	time 0.5784 (0.6357)	loss 2.8398 (3.3340)	grad_norm 3.4045 (nan)	mem 8931MB
[2022-04-07 19:28:38 large] (main.py 226): INFO Train: [152/300][1800/2502]	eta 0:07:26 lr 0.000245	time 0.6303 (0.6360)	loss 3.0806 (3.3318)	grad_norm 4.3116 (nan)	mem 8931MB
[2022-04-07 19:29:42 large] (main.py 226): INFO Train: [152/300][1900/2502]	eta 0:06:23 lr 0.000245	time 0.6352 (0.6363)	loss 3.4533 (3.3328)	grad_norm 4.0839 (nan)	mem 8931MB
[2022-04-07 19:30:46 large] (main.py 226): INFO Train: [152/300][2000/2502]	eta 0:05:19 lr 0.000245	time 0.6677 (0.6364)	loss 3.5810 (3.3307)	grad_norm 3.6624 (nan)	mem 8931MB
[2022-04-07 19:31:50 large] (main.py 226): INFO Train: [152/300][2100/2502]	eta 0:04:15 lr 0.000245	time 0.7730 (0.6365)	loss 3.5622 (3.3315)	grad_norm 3.2426 (nan)	mem 8931MB
[2022-04-07 19:32:54 large] (main.py 226): INFO Train: [152/300][2200/2502]	eta 0:03:12 lr 0.000245	time 0.6932 (0.6365)	loss 3.5724 (3.3322)	grad_norm 4.6914 (nan)	mem 8931MB
[2022-04-07 19:33:57 large] (main.py 226): INFO Train: [152/300][2300/2502]	eta 0:02:08 lr 0.000245	time 0.7238 (0.6366)	loss 3.4056 (3.3314)	grad_norm 4.1721 (nan)	mem 8931MB
[2022-04-07 19:35:01 large] (main.py 226): INFO Train: [152/300][2400/2502]	eta 0:01:04 lr 0.000245	time 0.6453 (0.6367)	loss 3.8324 (3.3334)	grad_norm 3.6394 (nan)	mem 8931MB
[2022-04-07 19:36:05 large] (main.py 226): INFO Train: [152/300][2500/2502]	eta 0:00:01 lr 0.000245	time 0.6454 (0.6365)	loss 2.5174 (3.3339)	grad_norm 4.9818 (nan)	mem 8931MB
[2022-04-07 19:36:06 large] (main.py 233): INFO EPOCH 152 training takes 0:26:33
[2022-04-07 19:36:12 large] (main.py 273): INFO Test: [0/98]	Time 6.301 (6.301)	Loss 1.0500 (1.0500)	Acc@1 76.758 (76.758)	Acc@5 94.727 (94.727)	Mem 8931MB
[2022-04-07 19:36:39 large] (main.py 279): INFO  * Acc@1 77.590 Acc@5 94.028
[2022-04-07 19:36:39 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 77.6%
[2022-04-07 19:36:39 large] (utils.py 57): INFO output/large/default/ckpt_epoch_152.pth saving......
[2022-04-07 19:36:40 large] (utils.py 59): INFO output/large/default/ckpt_epoch_152.pth saved !!!
[2022-04-07 19:36:40 large] (main.py 148): INFO Max accuracy: 77.59%
[2022-04-07 19:36:48 large] (main.py 226): INFO Train: [153/300][0/2502]	eta 5:43:30 lr 0.000245	time 8.2375 (8.2375)	loss 3.9216 (3.9216)	grad_norm 3.4319 (3.4319)	mem 8931MB
[2022-04-07 19:37:40 large] (main.py 226): INFO Train: [153/300][100/2502]	eta 0:23:56 lr 0.000245	time 0.4639 (0.5979)	loss 3.7829 (3.2829)	grad_norm 4.5526 (3.6557)	mem 8931MB
[2022-04-07 19:38:34 large] (main.py 226): INFO Train: [153/300][200/2502]	eta 0:21:44 lr 0.000245	time 0.6372 (0.5665)	loss 3.3710 (3.3230)	grad_norm 4.3022 (3.7621)	mem 8931MB
[2022-04-07 19:39:38 large] (main.py 226): INFO Train: [153/300][300/2502]	eta 0:21:45 lr 0.000244	time 0.6155 (0.5930)	loss 2.4437 (3.3238)	grad_norm 3.4298 (nan)	mem 8931MB
[2022-04-07 19:40:44 large] (main.py 226): INFO Train: [153/300][400/2502]	eta 0:21:20 lr 0.000244	time 0.7326 (0.6093)	loss 3.6421 (3.3285)	grad_norm 3.5139 (nan)	mem 8931MB
[2022-04-07 19:41:51 large] (main.py 226): INFO Train: [153/300][500/2502]	eta 0:20:44 lr 0.000244	time 0.5937 (0.6215)	loss 3.6972 (3.3396)	grad_norm 3.6056 (nan)	mem 8931MB
[2022-04-07 19:42:57 large] (main.py 226): INFO Train: [153/300][600/2502]	eta 0:19:54 lr 0.000244	time 0.6946 (0.6278)	loss 3.3139 (3.3284)	grad_norm 3.7077 (nan)	mem 8931MB
[2022-04-07 19:44:03 large] (main.py 226): INFO Train: [153/300][700/2502]	eta 0:19:00 lr 0.000244	time 0.6330 (0.6329)	loss 3.4095 (3.3290)	grad_norm 3.9151 (nan)	mem 8931MB
[2022-04-07 19:45:10 large] (main.py 226): INFO Train: [153/300][800/2502]	eta 0:18:04 lr 0.000244	time 0.6504 (0.6374)	loss 2.4194 (3.3337)	grad_norm 3.3861 (nan)	mem 8931MB
[2022-04-07 19:46:15 large] (main.py 226): INFO Train: [153/300][900/2502]	eta 0:17:02 lr 0.000244	time 0.6252 (0.6383)	loss 3.4516 (3.3370)	grad_norm 3.6272 (nan)	mem 8931MB
[2022-04-07 19:47:21 large] (main.py 226): INFO Train: [153/300][1000/2502]	eta 0:16:02 lr 0.000244	time 0.6980 (0.6408)	loss 3.2359 (3.3376)	grad_norm 3.4005 (nan)	mem 8931MB
[2022-04-07 19:48:27 large] (main.py 226): INFO Train: [153/300][1100/2502]	eta 0:15:00 lr 0.000244	time 0.6772 (0.6423)	loss 3.0586 (3.3381)	grad_norm 3.5544 (nan)	mem 8931MB
[2022-04-07 19:49:33 large] (main.py 226): INFO Train: [153/300][1200/2502]	eta 0:13:58 lr 0.000243	time 0.6008 (0.6437)	loss 2.2220 (3.3405)	grad_norm 5.0256 (nan)	mem 8931MB
[2022-04-07 19:50:38 large] (main.py 226): INFO Train: [153/300][1300/2502]	eta 0:12:54 lr 0.000243	time 0.6833 (0.6445)	loss 3.8974 (3.3417)	grad_norm 3.8352 (nan)	mem 8931MB
[2022-04-07 19:51:44 large] (main.py 226): INFO Train: [153/300][1400/2502]	eta 0:11:51 lr 0.000243	time 0.6294 (0.6456)	loss 4.2026 (3.3402)	grad_norm 4.1030 (nan)	mem 8931MB
[2022-04-07 19:52:50 large] (main.py 226): INFO Train: [153/300][1500/2502]	eta 0:10:47 lr 0.000243	time 0.6032 (0.6466)	loss 3.8335 (3.3350)	grad_norm 3.4788 (nan)	mem 8931MB
[2022-04-07 19:53:55 large] (main.py 226): INFO Train: [153/300][1600/2502]	eta 0:09:43 lr 0.000243	time 0.6028 (0.6467)	loss 3.9835 (3.3398)	grad_norm 3.9182 (nan)	mem 8931MB
[2022-04-07 19:55:01 large] (main.py 226): INFO Train: [153/300][1700/2502]	eta 0:08:39 lr 0.000243	time 0.6797 (0.6473)	loss 2.9774 (3.3389)	grad_norm 3.3427 (nan)	mem 8931MB
[2022-04-07 19:56:07 large] (main.py 226): INFO Train: [153/300][1800/2502]	eta 0:07:34 lr 0.000243	time 0.7025 (0.6480)	loss 3.7601 (3.3427)	grad_norm 6.4980 (nan)	mem 8931MB
[2022-04-07 19:57:13 large] (main.py 226): INFO Train: [153/300][1900/2502]	eta 0:06:30 lr 0.000243	time 0.7434 (0.6487)	loss 3.6542 (3.3357)	grad_norm 4.5534 (nan)	mem 8931MB
[2022-04-07 19:58:19 large] (main.py 226): INFO Train: [153/300][2000/2502]	eta 0:05:25 lr 0.000243	time 0.7183 (0.6492)	loss 3.9391 (3.3363)	grad_norm 5.0343 (nan)	mem 8931MB
[2022-04-07 19:59:24 large] (main.py 226): INFO Train: [153/300][2100/2502]	eta 0:04:20 lr 0.000243	time 0.6684 (0.6492)	loss 3.4963 (3.3362)	grad_norm 3.8893 (nan)	mem 8931MB
[2022-04-07 20:00:30 large] (main.py 226): INFO Train: [153/300][2200/2502]	eta 0:03:16 lr 0.000242	time 0.6408 (0.6496)	loss 2.9350 (3.3335)	grad_norm 3.3341 (nan)	mem 8931MB
[2022-04-07 20:01:36 large] (main.py 226): INFO Train: [153/300][2300/2502]	eta 0:02:11 lr 0.000242	time 0.7348 (0.6501)	loss 3.7442 (3.3316)	grad_norm 4.0933 (nan)	mem 8931MB
[2022-04-07 20:02:41 large] (main.py 226): INFO Train: [153/300][2400/2502]	eta 0:01:06 lr 0.000242	time 0.6339 (0.6503)	loss 3.5509 (3.3310)	grad_norm 2.7999 (nan)	mem 8931MB
[2022-04-07 20:03:47 large] (main.py 226): INFO Train: [153/300][2500/2502]	eta 0:00:01 lr 0.000242	time 0.5872 (0.6506)	loss 3.8391 (3.3299)	grad_norm 3.1009 (nan)	mem 8931MB
[2022-04-07 20:03:48 large] (main.py 233): INFO EPOCH 153 training takes 0:27:08
[2022-04-07 20:03:54 large] (main.py 273): INFO Test: [0/98]	Time 5.648 (5.648)	Loss 1.1187 (1.1187)	Acc@1 75.000 (75.000)	Acc@5 93.164 (93.164)	Mem 8931MB
[2022-04-07 20:04:21 large] (main.py 279): INFO  * Acc@1 76.936 Acc@5 93.534
[2022-04-07 20:04:21 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 76.9%
[2022-04-07 20:04:21 large] (main.py 148): INFO Max accuracy: 77.59%
[2022-04-07 20:04:27 large] (main.py 226): INFO Train: [154/300][0/2502]	eta 4:31:52 lr 0.000242	time 6.5196 (6.5196)	loss 2.9524 (2.9524)	grad_norm 4.1305 (4.1305)	mem 8931MB
[2022-04-07 20:05:31 large] (main.py 226): INFO Train: [154/300][100/2502]	eta 0:27:52 lr 0.000242	time 0.7534 (0.6962)	loss 3.1634 (3.3661)	grad_norm 3.2490 (3.8558)	mem 8931MB
[2022-04-07 20:06:38 large] (main.py 226): INFO Train: [154/300][200/2502]	eta 0:26:15 lr 0.000242	time 0.6566 (0.6846)	loss 2.3611 (3.3358)	grad_norm 3.7251 (3.8504)	mem 8931MB
[2022-04-07 20:07:46 large] (main.py 226): INFO Train: [154/300][300/2502]	eta 0:25:01 lr 0.000242	time 0.6227 (0.6821)	loss 4.2899 (3.3681)	grad_norm 4.8074 (3.8518)	mem 8931MB
[2022-04-07 20:08:54 large] (main.py 226): INFO Train: [154/300][400/2502]	eta 0:23:51 lr 0.000242	time 0.7043 (0.6808)	loss 2.2437 (3.3649)	grad_norm 2.7476 (3.8515)	mem 8931MB
[2022-04-07 20:10:01 large] (main.py 226): INFO Train: [154/300][500/2502]	eta 0:22:38 lr 0.000242	time 0.6881 (0.6785)	loss 3.4918 (3.3615)	grad_norm 4.0740 (3.8454)	mem 8931MB
[2022-04-07 20:11:08 large] (main.py 226): INFO Train: [154/300][600/2502]	eta 0:21:28 lr 0.000242	time 0.7025 (0.6775)	loss 3.6793 (3.3366)	grad_norm 3.7856 (3.8532)	mem 8931MB
[2022-04-07 20:12:15 large] (main.py 226): INFO Train: [154/300][700/2502]	eta 0:20:18 lr 0.000241	time 0.6984 (0.6764)	loss 2.5015 (3.3335)	grad_norm 3.6729 (3.8655)	mem 8931MB
[2022-04-07 20:13:23 large] (main.py 226): INFO Train: [154/300][800/2502]	eta 0:19:11 lr 0.000241	time 0.7831 (0.6765)	loss 2.9774 (3.3382)	grad_norm 3.3797 (3.8627)	mem 8931MB
[2022-04-07 20:14:28 large] (main.py 226): INFO Train: [154/300][900/2502]	eta 0:18:00 lr 0.000241	time 0.5418 (0.6745)	loss 3.6849 (3.3353)	grad_norm 5.0023 (3.8486)	mem 8931MB
[2022-04-07 20:15:35 large] (main.py 226): INFO Train: [154/300][1000/2502]	eta 0:16:52 lr 0.000241	time 0.6674 (0.6740)	loss 2.3434 (3.3449)	grad_norm 3.2625 (3.8413)	mem 8931MB
[2022-04-07 20:16:42 large] (main.py 226): INFO Train: [154/300][1100/2502]	eta 0:15:44 lr 0.000241	time 0.6375 (0.6736)	loss 2.2635 (3.3411)	grad_norm 3.3829 (3.8337)	mem 8931MB
[2022-04-07 20:17:49 large] (main.py 226): INFO Train: [154/300][1200/2502]	eta 0:14:35 lr 0.000241	time 0.6924 (0.6727)	loss 2.3562 (3.3459)	grad_norm 3.0488 (3.8265)	mem 8931MB
[2022-04-07 20:18:55 large] (main.py 226): INFO Train: [154/300][1300/2502]	eta 0:13:28 lr 0.000241	time 0.7256 (0.6724)	loss 3.3451 (3.3427)	grad_norm 4.3158 (3.8067)	mem 8931MB
[2022-04-07 20:20:02 large] (main.py 226): INFO Train: [154/300][1400/2502]	eta 0:12:20 lr 0.000241	time 0.6552 (0.6720)	loss 3.3029 (3.3367)	grad_norm 3.8919 (3.8069)	mem 8931MB
[2022-04-07 20:21:08 large] (main.py 226): INFO Train: [154/300][1500/2502]	eta 0:11:12 lr 0.000241	time 0.6429 (0.6714)	loss 2.4563 (3.3352)	grad_norm 4.2124 (3.8012)	mem 8931MB
[2022-04-07 20:22:15 large] (main.py 226): INFO Train: [154/300][1600/2502]	eta 0:10:05 lr 0.000240	time 0.7312 (0.6710)	loss 3.7831 (3.3386)	grad_norm 3.8811 (3.8108)	mem 8931MB
[2022-04-07 20:23:22 large] (main.py 226): INFO Train: [154/300][1700/2502]	eta 0:08:58 lr 0.000240	time 0.6344 (0.6712)	loss 2.7760 (3.3399)	grad_norm 3.6672 (3.8130)	mem 8931MB
[2022-04-07 20:24:29 large] (main.py 226): INFO Train: [154/300][1800/2502]	eta 0:07:50 lr 0.000240	time 0.6526 (0.6708)	loss 3.2396 (3.3400)	grad_norm 4.9046 (3.8111)	mem 8931MB
[2022-04-07 20:25:36 large] (main.py 226): INFO Train: [154/300][1900/2502]	eta 0:06:43 lr 0.000240	time 0.7399 (0.6709)	loss 3.6801 (3.3412)	grad_norm 3.7992 (3.8046)	mem 8931MB
[2022-04-07 20:26:43 large] (main.py 226): INFO Train: [154/300][2000/2502]	eta 0:05:36 lr 0.000240	time 0.6689 (0.6708)	loss 4.1860 (3.3430)	grad_norm 4.0717 (3.8021)	mem 8931MB
[2022-04-07 20:27:49 large] (main.py 226): INFO Train: [154/300][2100/2502]	eta 0:04:29 lr 0.000240	time 0.6639 (0.6704)	loss 3.2090 (3.3458)	grad_norm 4.0006 (3.8044)	mem 8931MB
[2022-04-07 20:28:57 large] (main.py 226): INFO Train: [154/300][2200/2502]	eta 0:03:22 lr 0.000240	time 0.6099 (0.6705)	loss 3.5781 (3.3422)	grad_norm 3.4680 (3.8098)	mem 8931MB
[2022-04-07 20:30:03 large] (main.py 226): INFO Train: [154/300][2300/2502]	eta 0:02:15 lr 0.000240	time 0.7114 (0.6704)	loss 3.8764 (3.3411)	grad_norm 3.3034 (3.8118)	mem 8931MB
[2022-04-07 20:31:09 large] (main.py 226): INFO Train: [154/300][2400/2502]	eta 0:01:08 lr 0.000240	time 0.6501 (0.6700)	loss 3.3512 (3.3425)	grad_norm 5.4571 (3.8198)	mem 8931MB
[2022-04-07 20:32:16 large] (main.py 226): INFO Train: [154/300][2500/2502]	eta 0:00:01 lr 0.000240	time 0.6203 (0.6699)	loss 3.5633 (3.3406)	grad_norm 4.3409 (3.8171)	mem 8931MB
[2022-04-07 20:32:17 large] (main.py 233): INFO EPOCH 154 training takes 0:27:56
[2022-04-07 20:32:24 large] (main.py 273): INFO Test: [0/98]	Time 6.427 (6.427)	Loss 1.0501 (1.0501)	Acc@1 77.930 (77.930)	Acc@5 95.117 (95.117)	Mem 8931MB
[2022-04-07 20:32:50 large] (main.py 279): INFO  * Acc@1 77.508 Acc@5 93.992
[2022-04-07 20:32:50 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 77.5%
[2022-04-07 20:32:50 large] (main.py 148): INFO Max accuracy: 77.59%
[2022-04-07 20:32:57 large] (main.py 226): INFO Train: [155/300][0/2502]	eta 5:04:31 lr 0.000240	time 7.3030 (7.3030)	loss 3.6098 (3.6098)	grad_norm 4.4031 (4.4031)	mem 8931MB
[2022-04-07 20:34:02 large] (main.py 226): INFO Train: [155/300][100/2502]	eta 0:28:26 lr 0.000239	time 0.6587 (0.7104)	loss 3.2839 (3.2437)	grad_norm 3.3089 (3.7229)	mem 8931MB
[2022-04-07 20:35:09 large] (main.py 226): INFO Train: [155/300][200/2502]	eta 0:26:34 lr 0.000239	time 0.7217 (0.6928)	loss 3.3645 (3.2897)	grad_norm 4.2778 (3.7742)	mem 8931MB
[2022-04-07 20:36:17 large] (main.py 226): INFO Train: [155/300][300/2502]	eta 0:25:12 lr 0.000239	time 0.6483 (0.6867)	loss 3.5446 (3.3266)	grad_norm 3.1488 (3.7783)	mem 8931MB
[2022-04-07 20:37:24 large] (main.py 226): INFO Train: [155/300][400/2502]	eta 0:23:58 lr 0.000239	time 0.7756 (0.6842)	loss 3.5851 (3.3284)	grad_norm 3.7127 (3.7600)	mem 8931MB
[2022-04-07 20:38:33 large] (main.py 226): INFO Train: [155/300][500/2502]	eta 0:22:49 lr 0.000239	time 0.7458 (0.6839)	loss 2.3482 (3.3159)	grad_norm 5.7568 (3.8048)	mem 8931MB
[2022-04-07 20:39:40 large] (main.py 226): INFO Train: [155/300][600/2502]	eta 0:21:38 lr 0.000239	time 0.6000 (0.6825)	loss 3.7643 (3.3111)	grad_norm 3.8383 (3.8082)	mem 8931MB
[2022-04-07 20:40:47 large] (main.py 226): INFO Train: [155/300][700/2502]	eta 0:20:25 lr 0.000239	time 0.6950 (0.6800)	loss 3.8103 (3.3274)	grad_norm 3.3105 (3.8191)	mem 8931MB
[2022-04-07 20:41:54 large] (main.py 226): INFO Train: [155/300][800/2502]	eta 0:19:15 lr 0.000239	time 0.6752 (0.6787)	loss 3.2503 (3.3255)	grad_norm 3.7440 (3.8155)	mem 8931MB
[2022-04-07 20:43:01 large] (main.py 226): INFO Train: [155/300][900/2502]	eta 0:18:06 lr 0.000239	time 0.6638 (0.6781)	loss 3.2387 (3.3226)	grad_norm 3.1536 (3.8144)	mem 8931MB
[2022-04-07 20:44:06 large] (main.py 226): INFO Train: [155/300][1000/2502]	eta 0:16:55 lr 0.000239	time 0.5351 (0.6758)	loss 2.8307 (3.3254)	grad_norm 3.6801 (3.8126)	mem 8931MB
[2022-04-07 20:45:14 large] (main.py 226): INFO Train: [155/300][1100/2502]	eta 0:15:47 lr 0.000238	time 0.7283 (0.6755)	loss 3.8169 (3.3280)	grad_norm 4.5703 (3.7945)	mem 8931MB
[2022-04-07 20:46:22 large] (main.py 226): INFO Train: [155/300][1200/2502]	eta 0:14:39 lr 0.000238	time 0.6855 (0.6758)	loss 3.5088 (3.3252)	grad_norm 3.6643 (3.7863)	mem 8931MB
[2022-04-07 20:47:30 large] (main.py 226): INFO Train: [155/300][1300/2502]	eta 0:13:32 lr 0.000238	time 0.7866 (0.6762)	loss 2.3934 (3.3216)	grad_norm 2.9611 (3.7792)	mem 8931MB
[2022-04-07 20:48:38 large] (main.py 226): INFO Train: [155/300][1400/2502]	eta 0:12:25 lr 0.000238	time 0.8186 (0.6764)	loss 3.2263 (3.3171)	grad_norm 3.8783 (3.7763)	mem 8931MB
[2022-04-07 20:49:44 large] (main.py 226): INFO Train: [155/300][1500/2502]	eta 0:11:16 lr 0.000238	time 0.6726 (0.6752)	loss 3.7015 (3.3198)	grad_norm 3.4683 (3.7673)	mem 8931MB
[2022-04-07 20:50:51 large] (main.py 226): INFO Train: [155/300][1600/2502]	eta 0:10:09 lr 0.000238	time 0.7055 (0.6752)	loss 2.4108 (3.3237)	grad_norm 4.2065 (3.7725)	mem 8931MB
[2022-04-07 20:51:58 large] (main.py 226): INFO Train: [155/300][1700/2502]	eta 0:09:01 lr 0.000238	time 0.6591 (0.6749)	loss 3.2794 (3.3282)	grad_norm 3.3812 (3.7785)	mem 8931MB
[2022-04-07 20:53:06 large] (main.py 226): INFO Train: [155/300][1800/2502]	eta 0:07:53 lr 0.000238	time 0.5691 (0.6751)	loss 3.5487 (3.3347)	grad_norm 4.0375 (3.7890)	mem 8931MB
[2022-04-07 20:54:12 large] (main.py 226): INFO Train: [155/300][1900/2502]	eta 0:06:45 lr 0.000238	time 0.6696 (0.6743)	loss 3.8980 (3.3353)	grad_norm 4.4468 (3.7821)	mem 8931MB
[2022-04-07 20:55:20 large] (main.py 226): INFO Train: [155/300][2000/2502]	eta 0:05:38 lr 0.000237	time 0.6632 (0.6744)	loss 2.8967 (3.3373)	grad_norm 2.9658 (3.7849)	mem 8931MB
[2022-04-07 20:56:27 large] (main.py 226): INFO Train: [155/300][2100/2502]	eta 0:04:31 lr 0.000237	time 0.6679 (0.6745)	loss 3.9010 (3.3416)	grad_norm 3.4571 (nan)	mem 8931MB
[2022-04-07 20:57:35 large] (main.py 226): INFO Train: [155/300][2200/2502]	eta 0:03:23 lr 0.000237	time 1.5096 (0.6745)	loss 3.4873 (3.3448)	grad_norm 3.8449 (nan)	mem 8931MB
[2022-04-07 20:58:42 large] (main.py 226): INFO Train: [155/300][2300/2502]	eta 0:02:16 lr 0.000237	time 0.6724 (0.6743)	loss 3.7073 (3.3464)	grad_norm 4.1671 (nan)	mem 8931MB
[2022-04-07 20:59:48 large] (main.py 226): INFO Train: [155/300][2400/2502]	eta 0:01:08 lr 0.000237	time 0.6960 (0.6738)	loss 3.2752 (3.3442)	grad_norm 4.1675 (nan)	mem 8931MB
[2022-04-07 21:00:54 large] (main.py 226): INFO Train: [155/300][2500/2502]	eta 0:00:01 lr 0.000237	time 0.5671 (0.6733)	loss 3.0251 (3.3459)	grad_norm 3.4873 (nan)	mem 8931MB
[2022-04-07 21:00:55 large] (main.py 233): INFO EPOCH 155 training takes 0:28:04
[2022-04-07 21:01:02 large] (main.py 273): INFO Test: [0/98]	Time 6.711 (6.711)	Loss 1.0090 (1.0090)	Acc@1 77.930 (77.930)	Acc@5 96.094 (96.094)	Mem 8931MB
[2022-04-07 21:01:27 large] (main.py 279): INFO  * Acc@1 77.528 Acc@5 94.034
[2022-04-07 21:01:27 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 77.5%
[2022-04-07 21:01:27 large] (main.py 148): INFO Max accuracy: 77.59%
[2022-04-07 21:01:33 large] (main.py 226): INFO Train: [156/300][0/2502]	eta 4:17:40 lr 0.000237	time 6.1792 (6.1792)	loss 3.0375 (3.0375)	grad_norm 3.9815 (3.9815)	mem 8931MB
[2022-04-07 21:02:29 large] (main.py 226): INFO Train: [156/300][100/2502]	eta 0:24:31 lr 0.000237	time 0.6968 (0.6128)	loss 3.6019 (3.2958)	grad_norm 3.1505 (3.8716)	mem 8931MB
[2022-04-07 21:03:37 large] (main.py 226): INFO Train: [156/300][200/2502]	eta 0:24:49 lr 0.000237	time 0.6893 (0.6472)	loss 2.1659 (3.2932)	grad_norm 4.0064 (4.0129)	mem 8931MB
[2022-04-07 21:04:46 large] (main.py 226): INFO Train: [156/300][300/2502]	eta 0:24:14 lr 0.000237	time 0.6759 (0.6606)	loss 3.6933 (3.2754)	grad_norm 3.1902 (3.9883)	mem 8931MB
[2022-04-07 21:05:54 large] (main.py 226): INFO Train: [156/300][400/2502]	eta 0:23:18 lr 0.000237	time 0.6502 (0.6651)	loss 3.3462 (3.2983)	grad_norm 4.0034 (3.9404)	mem 8931MB
[2022-04-07 21:07:02 large] (main.py 226): INFO Train: [156/300][500/2502]	eta 0:22:17 lr 0.000236	time 0.6708 (0.6680)	loss 3.6950 (3.3103)	grad_norm 3.1488 (3.9390)	mem 8931MB
[2022-04-07 21:08:09 large] (main.py 226): INFO Train: [156/300][600/2502]	eta 0:21:12 lr 0.000236	time 0.6126 (0.6693)	loss 2.1320 (3.3152)	grad_norm 3.2125 (3.9551)	mem 8931MB
[2022-04-07 21:09:17 large] (main.py 226): INFO Train: [156/300][700/2502]	eta 0:20:07 lr 0.000236	time 0.6566 (0.6701)	loss 3.3729 (3.3186)	grad_norm 3.3252 (3.9540)	mem 8931MB
[2022-04-07 21:10:24 large] (main.py 226): INFO Train: [156/300][800/2502]	eta 0:19:01 lr 0.000236	time 0.6712 (0.6707)	loss 3.3855 (3.3216)	grad_norm 3.3023 (3.9690)	mem 8931MB
[2022-04-07 21:11:32 large] (main.py 226): INFO Train: [156/300][900/2502]	eta 0:17:55 lr 0.000236	time 0.6469 (0.6713)	loss 2.5069 (3.3260)	grad_norm 4.4368 (3.9608)	mem 8931MB
[2022-04-07 21:12:39 large] (main.py 226): INFO Train: [156/300][1000/2502]	eta 0:16:47 lr 0.000236	time 0.6091 (0.6710)	loss 2.9677 (3.3199)	grad_norm 3.1632 (3.9599)	mem 8931MB
[2022-04-07 21:13:46 large] (main.py 226): INFO Train: [156/300][1100/2502]	eta 0:15:40 lr 0.000236	time 0.7240 (0.6711)	loss 3.7197 (3.3203)	grad_norm 3.5303 (3.9474)	mem 8931MB
[2022-04-07 21:14:54 large] (main.py 226): INFO Train: [156/300][1200/2502]	eta 0:14:34 lr 0.000236	time 0.6145 (0.6717)	loss 3.8546 (3.3191)	grad_norm 4.2216 (3.9396)	mem 8931MB
[2022-04-07 21:16:02 large] (main.py 226): INFO Train: [156/300][1300/2502]	eta 0:13:27 lr 0.000236	time 0.7715 (0.6720)	loss 3.9309 (3.3133)	grad_norm 4.0330 (3.9326)	mem 8931MB
[2022-04-07 21:17:09 large] (main.py 226): INFO Train: [156/300][1400/2502]	eta 0:12:21 lr 0.000236	time 0.7021 (0.6724)	loss 3.2673 (3.3194)	grad_norm 4.3851 (3.9257)	mem 8931MB
[2022-04-07 21:18:16 large] (main.py 226): INFO Train: [156/300][1500/2502]	eta 0:11:13 lr 0.000235	time 0.6418 (0.6724)	loss 3.2149 (3.3235)	grad_norm 5.2073 (3.9167)	mem 8931MB
[2022-04-07 21:19:25 large] (main.py 226): INFO Train: [156/300][1600/2502]	eta 0:10:07 lr 0.000235	time 0.6521 (0.6733)	loss 3.3616 (3.3259)	grad_norm 4.1202 (3.9093)	mem 8931MB
[2022-04-07 21:20:31 large] (main.py 226): INFO Train: [156/300][1700/2502]	eta 0:08:59 lr 0.000235	time 0.7043 (0.6727)	loss 3.6704 (3.3266)	grad_norm 3.7100 (3.9087)	mem 8931MB
[2022-04-07 21:21:39 large] (main.py 226): INFO Train: [156/300][1800/2502]	eta 0:07:52 lr 0.000235	time 0.6757 (0.6729)	loss 2.9885 (3.3207)	grad_norm 4.0682 (nan)	mem 8931MB
[2022-04-07 21:22:47 large] (main.py 226): INFO Train: [156/300][1900/2502]	eta 0:06:45 lr 0.000235	time 0.6243 (0.6730)	loss 3.6780 (3.3198)	grad_norm 3.5133 (nan)	mem 8931MB
[2022-04-07 21:23:54 large] (main.py 226): INFO Train: [156/300][2000/2502]	eta 0:05:37 lr 0.000235	time 0.6245 (0.6730)	loss 3.6126 (3.3246)	grad_norm 3.5138 (nan)	mem 8931MB
[2022-04-07 21:25:00 large] (main.py 226): INFO Train: [156/300][2100/2502]	eta 0:04:30 lr 0.000235	time 0.6993 (0.6723)	loss 3.3155 (3.3249)	grad_norm 3.6310 (nan)	mem 8931MB
[2022-04-07 21:26:06 large] (main.py 226): INFO Train: [156/300][2200/2502]	eta 0:03:22 lr 0.000235	time 0.6927 (0.6719)	loss 3.6598 (3.3261)	grad_norm 3.1242 (nan)	mem 8931MB
[2022-04-07 21:27:13 large] (main.py 226): INFO Train: [156/300][2300/2502]	eta 0:02:15 lr 0.000235	time 0.6602 (0.6718)	loss 3.1371 (3.3273)	grad_norm 4.8324 (nan)	mem 8931MB
[2022-04-07 21:28:21 large] (main.py 226): INFO Train: [156/300][2400/2502]	eta 0:01:08 lr 0.000234	time 0.6517 (0.6721)	loss 4.0615 (3.3274)	grad_norm 4.2914 (nan)	mem 8931MB
[2022-04-07 21:29:27 large] (main.py 226): INFO Train: [156/300][2500/2502]	eta 0:00:01 lr 0.000234	time 0.6064 (0.6718)	loss 3.4217 (3.3303)	grad_norm 3.6388 (nan)	mem 8931MB
[2022-04-07 21:29:28 large] (main.py 233): INFO EPOCH 156 training takes 0:28:01
[2022-04-07 21:29:34 large] (main.py 273): INFO Test: [0/98]	Time 6.001 (6.001)	Loss 0.9765 (0.9765)	Acc@1 78.516 (78.516)	Acc@5 95.508 (95.508)	Mem 8931MB
[2022-04-07 21:30:01 large] (main.py 279): INFO  * Acc@1 77.704 Acc@5 94.000
[2022-04-07 21:30:01 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 77.7%
[2022-04-07 21:30:01 large] (utils.py 57): INFO output/large/default/ckpt_epoch_156.pth saving......
[2022-04-07 21:30:02 large] (utils.py 59): INFO output/large/default/ckpt_epoch_156.pth saved !!!
[2022-04-07 21:30:02 large] (main.py 148): INFO Max accuracy: 77.70%
[2022-04-07 21:30:10 large] (main.py 226): INFO Train: [157/300][0/2502]	eta 5:30:46 lr 0.000234	time 7.9323 (7.9323)	loss 2.7540 (2.7540)	grad_norm 3.3576 (3.3576)	mem 8931MB
[2022-04-07 21:31:13 large] (main.py 226): INFO Train: [157/300][100/2502]	eta 0:28:13 lr 0.000234	time 0.7225 (0.7049)	loss 3.8408 (3.3232)	grad_norm 5.4264 (3.8704)	mem 8931MB
[2022-04-07 21:32:21 large] (main.py 226): INFO Train: [157/300][200/2502]	eta 0:26:35 lr 0.000234	time 0.7519 (0.6931)	loss 3.7104 (3.3693)	grad_norm 3.8148 (3.9284)	mem 8931MB
[2022-04-07 21:33:29 large] (main.py 226): INFO Train: [157/300][300/2502]	eta 0:25:13 lr 0.000234	time 0.7467 (0.6875)	loss 2.6951 (3.3315)	grad_norm 3.2137 (3.9246)	mem 8931MB
[2022-04-07 21:34:37 large] (main.py 226): INFO Train: [157/300][400/2502]	eta 0:24:02 lr 0.000234	time 0.6271 (0.6860)	loss 3.2476 (3.3249)	grad_norm 3.6851 (3.9499)	mem 8931MB
[2022-04-07 21:35:45 large] (main.py 226): INFO Train: [157/300][500/2502]	eta 0:22:52 lr 0.000234	time 0.7069 (0.6854)	loss 3.4813 (3.3259)	grad_norm 3.8964 (3.9126)	mem 8931MB
[2022-04-07 21:36:52 large] (main.py 226): INFO Train: [157/300][600/2502]	eta 0:21:39 lr 0.000234	time 0.6673 (0.6831)	loss 4.0380 (3.3203)	grad_norm 4.5016 (3.9178)	mem 8931MB
[2022-04-07 21:37:59 large] (main.py 226): INFO Train: [157/300][700/2502]	eta 0:20:27 lr 0.000234	time 0.7418 (0.6812)	loss 3.2505 (3.3270)	grad_norm 3.5310 (3.9030)	mem 8931MB
[2022-04-07 21:39:07 large] (main.py 226): INFO Train: [157/300][800/2502]	eta 0:19:18 lr 0.000234	time 0.7009 (0.6805)	loss 2.3032 (3.3148)	grad_norm 3.5456 (3.9064)	mem 8931MB
[2022-04-07 21:40:14 large] (main.py 226): INFO Train: [157/300][900/2502]	eta 0:18:08 lr 0.000233	time 0.6209 (0.6792)	loss 3.5298 (3.3119)	grad_norm 4.6901 (3.9280)	mem 8931MB
[2022-04-07 21:41:22 large] (main.py 226): INFO Train: [157/300][1000/2502]	eta 0:17:01 lr 0.000233	time 0.6935 (0.6799)	loss 3.5491 (3.3165)	grad_norm 4.1875 (3.9578)	mem 8931MB
[2022-04-07 21:42:30 large] (main.py 226): INFO Train: [157/300][1100/2502]	eta 0:15:52 lr 0.000233	time 0.6442 (0.6796)	loss 4.0798 (3.3077)	grad_norm 4.4388 (3.9595)	mem 8931MB
[2022-04-07 21:43:38 large] (main.py 226): INFO Train: [157/300][1200/2502]	eta 0:14:44 lr 0.000233	time 0.6987 (0.6793)	loss 3.5946 (3.3102)	grad_norm 3.1434 (3.9516)	mem 8931MB
[2022-04-07 21:44:45 large] (main.py 226): INFO Train: [157/300][1300/2502]	eta 0:13:36 lr 0.000233	time 0.6882 (0.6790)	loss 3.7508 (3.3124)	grad_norm 5.1043 (nan)	mem 8931MB
[2022-04-07 21:45:52 large] (main.py 226): INFO Train: [157/300][1400/2502]	eta 0:12:27 lr 0.000233	time 0.6676 (0.6785)	loss 3.8220 (3.3197)	grad_norm 4.7419 (nan)	mem 8931MB
[2022-04-07 21:47:01 large] (main.py 226): INFO Train: [157/300][1500/2502]	eta 0:11:20 lr 0.000233	time 0.6712 (0.6790)	loss 3.3336 (3.3161)	grad_norm 4.0165 (nan)	mem 8931MB
[2022-04-07 21:48:10 large] (main.py 226): INFO Train: [157/300][1600/2502]	eta 0:10:12 lr 0.000233	time 0.7551 (0.6794)	loss 3.6413 (3.3195)	grad_norm 3.4577 (nan)	mem 8931MB
[2022-04-07 21:49:18 large] (main.py 226): INFO Train: [157/300][1700/2502]	eta 0:09:05 lr 0.000233	time 0.6872 (0.6798)	loss 3.2912 (3.3192)	grad_norm 4.0668 (nan)	mem 8931MB
[2022-04-07 21:50:27 large] (main.py 226): INFO Train: [157/300][1800/2502]	eta 0:07:57 lr 0.000233	time 0.7591 (0.6801)	loss 3.2250 (3.3209)	grad_norm 3.4557 (nan)	mem 8931MB
[2022-04-07 21:51:35 large] (main.py 226): INFO Train: [157/300][1900/2502]	eta 0:06:49 lr 0.000232	time 0.6087 (0.6800)	loss 3.2891 (3.3208)	grad_norm 3.3062 (nan)	mem 8931MB
[2022-04-07 21:52:44 large] (main.py 226): INFO Train: [157/300][2000/2502]	eta 0:05:41 lr 0.000232	time 0.7018 (0.6805)	loss 3.6206 (3.3208)	grad_norm 3.8898 (nan)	mem 8931MB
[2022-04-07 21:53:51 large] (main.py 226): INFO Train: [157/300][2100/2502]	eta 0:04:33 lr 0.000232	time 0.6766 (0.6801)	loss 2.5508 (3.3180)	grad_norm 3.2831 (nan)	mem 8931MB
[2022-04-07 21:54:58 large] (main.py 226): INFO Train: [157/300][2200/2502]	eta 0:03:25 lr 0.000232	time 0.6923 (0.6798)	loss 3.5438 (3.3165)	grad_norm 4.2195 (nan)	mem 8931MB
[2022-04-07 21:56:06 large] (main.py 226): INFO Train: [157/300][2300/2502]	eta 0:02:17 lr 0.000232	time 0.7267 (0.6796)	loss 3.5525 (3.3171)	grad_norm 3.7647 (nan)	mem 8931MB
[2022-04-07 21:57:13 large] (main.py 226): INFO Train: [157/300][2400/2502]	eta 0:01:09 lr 0.000232	time 0.6529 (0.6795)	loss 2.9884 (3.3163)	grad_norm 3.7722 (nan)	mem 8931MB
[2022-04-07 21:58:20 large] (main.py 226): INFO Train: [157/300][2500/2502]	eta 0:00:01 lr 0.000232	time 0.6076 (0.6788)	loss 3.9715 (3.3169)	grad_norm 4.1224 (nan)	mem 8931MB
[2022-04-07 21:58:21 large] (main.py 233): INFO EPOCH 157 training takes 0:28:18
[2022-04-07 21:58:27 large] (main.py 273): INFO Test: [0/98]	Time 6.055 (6.055)	Loss 1.0997 (1.0997)	Acc@1 75.000 (75.000)	Acc@5 94.336 (94.336)	Mem 8931MB
[2022-04-07 21:58:53 large] (main.py 279): INFO  * Acc@1 77.622 Acc@5 93.934
[2022-04-07 21:58:53 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 77.6%
[2022-04-07 21:58:53 large] (main.py 148): INFO Max accuracy: 77.70%
[2022-04-07 21:59:01 large] (main.py 226): INFO Train: [158/300][0/2502]	eta 4:59:23 lr 0.000232	time 7.1796 (7.1796)	loss 2.1732 (2.1732)	grad_norm 3.6558 (3.6558)	mem 8931MB
[2022-04-07 21:59:52 large] (main.py 226): INFO Train: [158/300][100/2502]	eta 0:23:05 lr 0.000232	time 0.5135 (0.5770)	loss 3.0751 (3.3550)	grad_norm 3.9309 (3.7421)	mem 8931MB
[2022-04-07 22:00:58 large] (main.py 226): INFO Train: [158/300][200/2502]	eta 0:23:48 lr 0.000232	time 0.8398 (0.6204)	loss 2.9325 (3.3203)	grad_norm 3.3001 (3.8433)	mem 8931MB
[2022-04-07 22:02:07 large] (main.py 226): INFO Train: [158/300][300/2502]	eta 0:23:34 lr 0.000231	time 0.6236 (0.6425)	loss 3.6267 (3.2964)	grad_norm 3.8981 (3.8337)	mem 8931MB
[2022-04-07 22:03:14 large] (main.py 226): INFO Train: [158/300][400/2502]	eta 0:22:46 lr 0.000231	time 0.6512 (0.6500)	loss 3.9026 (3.3015)	grad_norm 4.5658 (3.8388)	mem 8931MB
[2022-04-07 22:04:22 large] (main.py 226): INFO Train: [158/300][500/2502]	eta 0:21:52 lr 0.000231	time 0.6384 (0.6554)	loss 4.0021 (3.3018)	grad_norm 3.9623 (3.8802)	mem 8931MB
[2022-04-07 22:05:30 large] (main.py 226): INFO Train: [158/300][600/2502]	eta 0:20:54 lr 0.000231	time 0.6913 (0.6593)	loss 3.4701 (3.3129)	grad_norm 3.8822 (3.8727)	mem 8931MB
[2022-04-07 22:06:37 large] (main.py 226): INFO Train: [158/300][700/2502]	eta 0:19:52 lr 0.000231	time 0.6281 (0.6618)	loss 4.0939 (3.3117)	grad_norm 4.7651 (3.8872)	mem 8931MB
[2022-04-07 22:07:44 large] (main.py 226): INFO Train: [158/300][800/2502]	eta 0:18:48 lr 0.000231	time 0.6971 (0.6629)	loss 3.1984 (3.3123)	grad_norm 5.6313 (3.8884)	mem 8931MB
[2022-04-07 22:08:52 large] (main.py 226): INFO Train: [158/300][900/2502]	eta 0:17:43 lr 0.000231	time 0.6912 (0.6639)	loss 4.0359 (3.3157)	grad_norm 3.7565 (3.8926)	mem 8931MB
[2022-04-07 22:09:57 large] (main.py 226): INFO Train: [158/300][1000/2502]	eta 0:16:36 lr 0.000231	time 0.6947 (0.6633)	loss 3.2731 (3.3142)	grad_norm 4.4315 (3.8983)	mem 8931MB
[2022-04-07 22:11:04 large] (main.py 226): INFO Train: [158/300][1100/2502]	eta 0:15:30 lr 0.000231	time 0.6208 (0.6638)	loss 4.0911 (3.3125)	grad_norm 4.4306 (3.8963)	mem 8931MB
[2022-04-07 22:12:11 large] (main.py 226): INFO Train: [158/300][1200/2502]	eta 0:14:24 lr 0.000231	time 0.6285 (0.6638)	loss 2.9842 (3.3091)	grad_norm 4.4518 (3.8942)	mem 8931MB
[2022-04-07 22:13:17 large] (main.py 226): INFO Train: [158/300][1300/2502]	eta 0:13:17 lr 0.000230	time 0.6289 (0.6637)	loss 3.2444 (3.3123)	grad_norm 4.4653 (3.9094)	mem 8931MB
[2022-04-07 22:14:24 large] (main.py 226): INFO Train: [158/300][1400/2502]	eta 0:12:12 lr 0.000230	time 0.6367 (0.6643)	loss 2.6347 (3.3124)	grad_norm 4.7668 (3.9061)	mem 8931MB
[2022-04-07 22:15:30 large] (main.py 226): INFO Train: [158/300][1500/2502]	eta 0:11:05 lr 0.000230	time 0.6096 (0.6642)	loss 3.3669 (3.3141)	grad_norm 4.1559 (3.9102)	mem 8931MB
[2022-04-07 22:16:37 large] (main.py 226): INFO Train: [158/300][1600/2502]	eta 0:09:58 lr 0.000230	time 0.4894 (0.6640)	loss 3.6858 (3.3114)	grad_norm 4.8056 (3.9223)	mem 8931MB
[2022-04-07 22:17:29 large] (main.py 226): INFO Train: [158/300][1700/2502]	eta 0:08:46 lr 0.000230	time 0.6812 (0.6559)	loss 3.0724 (3.3169)	grad_norm 3.1069 (3.9213)	mem 8931MB
[2022-04-07 22:18:35 large] (main.py 226): INFO Train: [158/300][1800/2502]	eta 0:07:40 lr 0.000230	time 0.6972 (0.6562)	loss 3.5498 (3.3188)	grad_norm 4.5307 (3.9291)	mem 8931MB
[2022-04-07 22:19:43 large] (main.py 226): INFO Train: [158/300][1900/2502]	eta 0:06:35 lr 0.000230	time 0.6436 (0.6571)	loss 2.8667 (3.3188)	grad_norm 4.5314 (3.9264)	mem 8931MB
[2022-04-07 22:20:51 large] (main.py 226): INFO Train: [158/300][2000/2502]	eta 0:05:30 lr 0.000230	time 0.7718 (0.6585)	loss 3.6703 (3.3234)	grad_norm 3.8400 (3.9276)	mem 8931MB
[2022-04-07 22:21:59 large] (main.py 226): INFO Train: [158/300][2100/2502]	eta 0:04:25 lr 0.000230	time 0.7040 (0.6594)	loss 2.4844 (3.3228)	grad_norm 3.8434 (3.9235)	mem 8931MB
[2022-04-07 22:23:05 large] (main.py 226): INFO Train: [158/300][2200/2502]	eta 0:03:19 lr 0.000230	time 0.6758 (0.6596)	loss 3.6635 (3.3261)	grad_norm 7.3591 (3.9265)	mem 8931MB
[2022-04-07 22:24:13 large] (main.py 226): INFO Train: [158/300][2300/2502]	eta 0:02:13 lr 0.000229	time 0.6268 (0.6602)	loss 4.0100 (3.3271)	grad_norm 4.1147 (3.9226)	mem 8931MB
[2022-04-07 22:25:19 large] (main.py 226): INFO Train: [158/300][2400/2502]	eta 0:01:07 lr 0.000229	time 0.7605 (0.6606)	loss 3.4752 (3.3241)	grad_norm 4.1027 (nan)	mem 8931MB
[2022-04-07 22:26:26 large] (main.py 226): INFO Train: [158/300][2500/2502]	eta 0:00:01 lr 0.000229	time 0.7051 (0.6606)	loss 2.3282 (3.3244)	grad_norm 4.3153 (nan)	mem 8931MB
[2022-04-07 22:26:27 large] (main.py 233): INFO EPOCH 158 training takes 0:27:33
[2022-04-07 22:26:33 large] (main.py 273): INFO Test: [0/98]	Time 6.304 (6.304)	Loss 1.0947 (1.0947)	Acc@1 79.492 (79.492)	Acc@5 93.164 (93.164)	Mem 8931MB
[2022-04-07 22:26:59 large] (main.py 279): INFO  * Acc@1 77.578 Acc@5 93.990
[2022-04-07 22:26:59 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 77.6%
[2022-04-07 22:26:59 large] (main.py 148): INFO Max accuracy: 77.70%
[2022-04-07 22:27:06 large] (main.py 226): INFO Train: [159/300][0/2502]	eta 5:12:49 lr 0.000229	time 7.5019 (7.5019)	loss 2.7892 (2.7892)	grad_norm 3.9088 (3.9088)	mem 8931MB
[2022-04-07 22:28:01 large] (main.py 226): INFO Train: [159/300][100/2502]	eta 0:24:56 lr 0.000229	time 0.6791 (0.6228)	loss 3.6237 (3.2362)	grad_norm 3.2912 (3.9627)	mem 8931MB
[2022-04-07 22:29:09 large] (main.py 226): INFO Train: [159/300][200/2502]	eta 0:24:53 lr 0.000229	time 0.6881 (0.6487)	loss 3.7577 (3.2828)	grad_norm 5.7036 (3.9078)	mem 8931MB
[2022-04-07 22:30:18 large] (main.py 226): INFO Train: [159/300][300/2502]	eta 0:24:17 lr 0.000229	time 0.7072 (0.6617)	loss 3.2198 (3.3104)	grad_norm 3.5177 (3.9327)	mem 8931MB
[2022-04-07 22:31:25 large] (main.py 226): INFO Train: [159/300][400/2502]	eta 0:23:18 lr 0.000229	time 0.6849 (0.6655)	loss 2.7887 (3.2953)	grad_norm 4.7128 (3.9499)	mem 8931MB
[2022-04-07 22:32:33 large] (main.py 226): INFO Train: [159/300][500/2502]	eta 0:22:18 lr 0.000229	time 0.6802 (0.6686)	loss 3.8161 (3.3072)	grad_norm 3.4541 (3.9351)	mem 8931MB
[2022-04-07 22:33:41 large] (main.py 226): INFO Train: [159/300][600/2502]	eta 0:21:14 lr 0.000229	time 0.6527 (0.6700)	loss 3.9112 (3.3199)	grad_norm 3.9478 (3.9201)	mem 8931MB
[2022-04-07 22:34:49 large] (main.py 226): INFO Train: [159/300][700/2502]	eta 0:20:08 lr 0.000228	time 0.6638 (0.6706)	loss 3.6428 (3.3264)	grad_norm 3.6611 (3.9196)	mem 8931MB
[2022-04-07 22:35:54 large] (main.py 226): INFO Train: [159/300][800/2502]	eta 0:18:58 lr 0.000228	time 0.7022 (0.6690)	loss 2.7767 (3.3159)	grad_norm 3.6971 (3.9407)	mem 8931MB
[2022-04-07 22:37:02 large] (main.py 226): INFO Train: [159/300][900/2502]	eta 0:17:52 lr 0.000228	time 0.7229 (0.6694)	loss 3.2450 (3.3234)	grad_norm 3.7101 (3.9497)	mem 8931MB
[2022-04-07 22:38:09 large] (main.py 226): INFO Train: [159/300][1000/2502]	eta 0:16:45 lr 0.000228	time 0.6798 (0.6696)	loss 3.3860 (3.3301)	grad_norm 5.8473 (3.9546)	mem 8931MB
[2022-04-07 22:39:16 large] (main.py 226): INFO Train: [159/300][1100/2502]	eta 0:15:39 lr 0.000228	time 0.7547 (0.6700)	loss 3.7939 (3.3390)	grad_norm 3.5847 (3.9617)	mem 8931MB
[2022-04-07 22:40:23 large] (main.py 226): INFO Train: [159/300][1200/2502]	eta 0:14:31 lr 0.000228	time 0.6320 (0.6696)	loss 3.7969 (3.3316)	grad_norm 3.5632 (3.9561)	mem 8931MB
[2022-04-07 22:41:29 large] (main.py 226): INFO Train: [159/300][1300/2502]	eta 0:13:23 lr 0.000228	time 0.6795 (0.6688)	loss 2.7502 (3.3370)	grad_norm 3.8881 (3.9598)	mem 8931MB
[2022-04-07 22:42:35 large] (main.py 226): INFO Train: [159/300][1400/2502]	eta 0:12:16 lr 0.000228	time 0.6917 (0.6687)	loss 2.8042 (3.3373)	grad_norm 3.1181 (3.9664)	mem 8931MB
[2022-04-07 22:43:42 large] (main.py 226): INFO Train: [159/300][1500/2502]	eta 0:11:09 lr 0.000228	time 0.6448 (0.6683)	loss 3.2472 (3.3355)	grad_norm 3.8321 (3.9680)	mem 8931MB
[2022-04-07 22:44:48 large] (main.py 226): INFO Train: [159/300][1600/2502]	eta 0:10:02 lr 0.000228	time 0.6519 (0.6683)	loss 2.2337 (3.3330)	grad_norm 4.0208 (3.9700)	mem 8931MB
[2022-04-07 22:45:55 large] (main.py 226): INFO Train: [159/300][1700/2502]	eta 0:08:55 lr 0.000227	time 0.6839 (0.6682)	loss 3.7778 (3.3336)	grad_norm 5.1802 (3.9692)	mem 8931MB
[2022-04-07 22:47:03 large] (main.py 226): INFO Train: [159/300][1800/2502]	eta 0:07:49 lr 0.000227	time 0.6686 (0.6685)	loss 2.8276 (3.3353)	grad_norm 4.2143 (3.9680)	mem 8931MB
[2022-04-07 22:48:09 large] (main.py 226): INFO Train: [159/300][1900/2502]	eta 0:06:42 lr 0.000227	time 0.6931 (0.6684)	loss 3.8650 (3.3371)	grad_norm 4.1542 (3.9627)	mem 8931MB
[2022-04-07 22:49:16 large] (main.py 226): INFO Train: [159/300][2000/2502]	eta 0:05:35 lr 0.000227	time 0.6950 (0.6682)	loss 3.9336 (3.3317)	grad_norm 3.6462 (3.9600)	mem 8931MB
[2022-04-07 22:50:22 large] (main.py 226): INFO Train: [159/300][2100/2502]	eta 0:04:28 lr 0.000227	time 0.6566 (0.6682)	loss 3.4298 (3.3303)	grad_norm 3.1579 (3.9618)	mem 8931MB
[2022-04-07 22:51:30 large] (main.py 226): INFO Train: [159/300][2200/2502]	eta 0:03:21 lr 0.000227	time 0.6565 (0.6685)	loss 3.8408 (3.3317)	grad_norm 3.4051 (nan)	mem 8931MB
[2022-04-07 22:52:36 large] (main.py 226): INFO Train: [159/300][2300/2502]	eta 0:02:14 lr 0.000227	time 0.8179 (0.6681)	loss 2.5673 (3.3295)	grad_norm 3.2033 (nan)	mem 8931MB
[2022-04-07 22:53:42 large] (main.py 226): INFO Train: [159/300][2400/2502]	eta 0:01:08 lr 0.000227	time 0.6716 (0.6677)	loss 3.0448 (3.3314)	grad_norm 3.1426 (nan)	mem 8931MB
[2022-04-07 22:54:48 large] (main.py 226): INFO Train: [159/300][2500/2502]	eta 0:00:01 lr 0.000227	time 0.5927 (0.6677)	loss 3.8491 (3.3324)	grad_norm 5.7120 (nan)	mem 8931MB
[2022-04-07 22:54:49 large] (main.py 233): INFO EPOCH 159 training takes 0:27:50
[2022-04-07 22:54:55 large] (main.py 273): INFO Test: [0/98]	Time 5.943 (5.943)	Loss 1.0961 (1.0961)	Acc@1 77.344 (77.344)	Acc@5 93.359 (93.359)	Mem 8931MB
[2022-04-07 22:55:22 large] (main.py 279): INFO  * Acc@1 77.750 Acc@5 94.000
[2022-04-07 22:55:22 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 77.7%
[2022-04-07 22:55:22 large] (utils.py 57): INFO output/large/default/ckpt_epoch_159.pth saving......
[2022-04-07 22:55:23 large] (utils.py 59): INFO output/large/default/ckpt_epoch_159.pth saved !!!
[2022-04-07 22:55:23 large] (main.py 148): INFO Max accuracy: 77.75%
[2022-04-07 22:55:31 large] (main.py 226): INFO Train: [160/300][0/2502]	eta 5:41:50 lr 0.000227	time 8.1976 (8.1976)	loss 2.4183 (2.4183)	grad_norm 4.0269 (4.0269)	mem 8931MB
[2022-04-07 22:56:33 large] (main.py 226): INFO Train: [160/300][100/2502]	eta 0:27:54 lr 0.000227	time 0.7029 (0.6970)	loss 3.7816 (3.2205)	grad_norm 4.1344 (4.0893)	mem 8931MB
[2022-04-07 22:57:40 large] (main.py 226): INFO Train: [160/300][200/2502]	eta 0:26:18 lr 0.000226	time 0.7528 (0.6855)	loss 3.5627 (3.2881)	grad_norm 4.3467 (4.0608)	mem 8931MB
[2022-04-07 22:58:48 large] (main.py 226): INFO Train: [160/300][300/2502]	eta 0:25:01 lr 0.000226	time 0.7736 (0.6818)	loss 3.4358 (3.2909)	grad_norm 3.8968 (4.0268)	mem 8931MB
[2022-04-07 22:59:54 large] (main.py 226): INFO Train: [160/300][400/2502]	eta 0:23:44 lr 0.000226	time 0.6177 (0.6776)	loss 3.4452 (3.2867)	grad_norm 3.9886 (3.9923)	mem 8931MB
[2022-04-07 23:01:00 large] (main.py 226): INFO Train: [160/300][500/2502]	eta 0:22:27 lr 0.000226	time 0.5756 (0.6732)	loss 3.5808 (3.2802)	grad_norm 3.9441 (3.9634)	mem 8931MB
[2022-04-07 23:02:07 large] (main.py 226): INFO Train: [160/300][600/2502]	eta 0:21:20 lr 0.000226	time 0.6673 (0.6733)	loss 3.5764 (3.2681)	grad_norm 2.6683 (3.9643)	mem 8931MB
[2022-04-07 23:03:14 large] (main.py 226): INFO Train: [160/300][700/2502]	eta 0:20:10 lr 0.000226	time 0.6564 (0.6720)	loss 3.1902 (3.2626)	grad_norm 3.4498 (3.9497)	mem 8931MB
[2022-04-07 23:04:21 large] (main.py 226): INFO Train: [160/300][800/2502]	eta 0:19:03 lr 0.000226	time 0.6918 (0.6716)	loss 3.2243 (3.2651)	grad_norm 4.7268 (3.9439)	mem 8931MB
[2022-04-07 23:05:27 large] (main.py 226): INFO Train: [160/300][900/2502]	eta 0:17:54 lr 0.000226	time 0.7266 (0.6709)	loss 4.0925 (3.2781)	grad_norm 3.5338 (3.9531)	mem 8931MB
[2022-04-07 23:06:34 large] (main.py 226): INFO Train: [160/300][1000/2502]	eta 0:16:47 lr 0.000226	time 0.6727 (0.6708)	loss 2.3398 (3.2739)	grad_norm 5.1821 (3.9619)	mem 8931MB
[2022-04-07 23:07:40 large] (main.py 226): INFO Train: [160/300][1100/2502]	eta 0:15:39 lr 0.000225	time 0.6935 (0.6700)	loss 2.8166 (3.2787)	grad_norm 4.6408 (3.9706)	mem 8931MB
[2022-04-07 23:08:47 large] (main.py 226): INFO Train: [160/300][1200/2502]	eta 0:14:32 lr 0.000225	time 0.7210 (0.6698)	loss 3.6143 (3.2865)	grad_norm 4.9991 (3.9915)	mem 8931MB
[2022-04-07 23:09:53 large] (main.py 226): INFO Train: [160/300][1300/2502]	eta 0:13:23 lr 0.000225	time 0.6023 (0.6687)	loss 2.4436 (3.2866)	grad_norm 3.0691 (3.9816)	mem 8931MB
[2022-04-07 23:11:00 large] (main.py 226): INFO Train: [160/300][1400/2502]	eta 0:12:17 lr 0.000225	time 0.6440 (0.6689)	loss 2.2133 (3.2923)	grad_norm 3.9146 (3.9721)	mem 8931MB
[2022-04-07 23:12:06 large] (main.py 226): INFO Train: [160/300][1500/2502]	eta 0:11:09 lr 0.000225	time 0.6105 (0.6685)	loss 3.9347 (3.2953)	grad_norm 4.2764 (3.9642)	mem 8931MB
[2022-04-07 23:13:13 large] (main.py 226): INFO Train: [160/300][1600/2502]	eta 0:10:02 lr 0.000225	time 0.6624 (0.6684)	loss 3.3318 (3.2925)	grad_norm 4.1130 (3.9612)	mem 8931MB
[2022-04-07 23:14:19 large] (main.py 226): INFO Train: [160/300][1700/2502]	eta 0:08:55 lr 0.000225	time 0.6714 (0.6683)	loss 3.4311 (3.2964)	grad_norm 3.9142 (3.9535)	mem 8931MB
[2022-04-07 23:15:26 large] (main.py 226): INFO Train: [160/300][1800/2502]	eta 0:07:48 lr 0.000225	time 0.7203 (0.6680)	loss 3.8941 (3.2959)	grad_norm 4.4434 (3.9419)	mem 8931MB
[2022-04-07 23:16:33 large] (main.py 226): INFO Train: [160/300][1900/2502]	eta 0:06:42 lr 0.000225	time 0.6231 (0.6683)	loss 2.6618 (3.2960)	grad_norm 4.6139 (3.9377)	mem 8931MB
[2022-04-07 23:17:39 large] (main.py 226): INFO Train: [160/300][2000/2502]	eta 0:05:35 lr 0.000225	time 0.6827 (0.6677)	loss 3.0352 (3.2978)	grad_norm 3.2653 (3.9376)	mem 8931MB
[2022-04-07 23:18:46 large] (main.py 226): INFO Train: [160/300][2100/2502]	eta 0:04:28 lr 0.000224	time 0.6643 (0.6678)	loss 3.3740 (3.3017)	grad_norm 3.5271 (3.9406)	mem 8931MB
[2022-04-07 23:19:51 large] (main.py 226): INFO Train: [160/300][2200/2502]	eta 0:03:21 lr 0.000224	time 0.6890 (0.6671)	loss 3.9792 (3.3046)	grad_norm 4.2368 (3.9465)	mem 8931MB
[2022-04-07 23:20:57 large] (main.py 226): INFO Train: [160/300][2300/2502]	eta 0:02:14 lr 0.000224	time 0.6532 (0.6666)	loss 2.7382 (3.3044)	grad_norm 5.4059 (3.9465)	mem 8931MB
[2022-04-07 23:22:03 large] (main.py 226): INFO Train: [160/300][2400/2502]	eta 0:01:07 lr 0.000224	time 0.7182 (0.6663)	loss 3.3735 (3.3061)	grad_norm 5.0551 (3.9440)	mem 8931MB
[2022-04-07 23:23:09 large] (main.py 226): INFO Train: [160/300][2500/2502]	eta 0:00:01 lr 0.000224	time 0.6560 (0.6662)	loss 2.2819 (3.3059)	grad_norm 3.2184 (3.9399)	mem 8931MB
[2022-04-07 23:23:10 large] (main.py 233): INFO EPOCH 160 training takes 0:27:47
[2022-04-07 23:23:15 large] (main.py 273): INFO Test: [0/98]	Time 5.502 (5.502)	Loss 1.0802 (1.0802)	Acc@1 78.125 (78.125)	Acc@5 94.531 (94.531)	Mem 8931MB
[2022-04-07 23:23:42 large] (main.py 279): INFO  * Acc@1 77.780 Acc@5 93.896
[2022-04-07 23:23:42 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 77.8%
[2022-04-07 23:23:42 large] (utils.py 57): INFO output/large/default/ckpt_epoch_160.pth saving......
[2022-04-07 23:23:43 large] (utils.py 59): INFO output/large/default/ckpt_epoch_160.pth saved !!!
[2022-04-07 23:23:43 large] (main.py 148): INFO Max accuracy: 77.78%
[2022-04-07 23:23:51 large] (main.py 226): INFO Train: [161/300][0/2502]	eta 5:35:11 lr 0.000224	time 8.0382 (8.0382)	loss 3.0220 (3.0220)	grad_norm 4.1684 (4.1684)	mem 8931MB
[2022-04-07 23:24:51 large] (main.py 226): INFO Train: [161/300][100/2502]	eta 0:26:55 lr 0.000224	time 0.6626 (0.6725)	loss 3.4997 (3.3167)	grad_norm 3.7957 (3.8860)	mem 8931MB
[2022-04-07 23:25:59 large] (main.py 226): INFO Train: [161/300][200/2502]	eta 0:25:59 lr 0.000224	time 0.6339 (0.6773)	loss 3.6276 (3.2704)	grad_norm 4.8572 (3.9802)	mem 8931MB
[2022-04-07 23:27:03 large] (main.py 226): INFO Train: [161/300][300/2502]	eta 0:24:26 lr 0.000224	time 0.4860 (0.6658)	loss 3.7012 (3.2676)	grad_norm 3.5392 (3.9668)	mem 8931MB
[2022-04-07 23:28:04 large] (main.py 226): INFO Train: [161/300][400/2502]	eta 0:22:50 lr 0.000224	time 0.5332 (0.6521)	loss 3.5610 (3.2880)	grad_norm 4.5977 (3.9614)	mem 8931MB
[2022-04-07 23:29:11 large] (main.py 226): INFO Train: [161/300][500/2502]	eta 0:21:53 lr 0.000224	time 0.7192 (0.6560)	loss 3.5658 (3.2861)	grad_norm 3.2660 (3.9578)	mem 8931MB
[2022-04-07 23:30:19 large] (main.py 226): INFO Train: [161/300][600/2502]	eta 0:20:53 lr 0.000223	time 0.6887 (0.6588)	loss 2.4543 (3.3038)	grad_norm 3.2794 (3.9674)	mem 8931MB
[2022-04-07 23:31:25 large] (main.py 226): INFO Train: [161/300][700/2502]	eta 0:19:48 lr 0.000223	time 0.7244 (0.6593)	loss 3.2682 (3.3182)	grad_norm 5.9669 (3.9769)	mem 8931MB
[2022-04-07 23:32:31 large] (main.py 226): INFO Train: [161/300][800/2502]	eta 0:18:42 lr 0.000223	time 0.6978 (0.6596)	loss 2.7524 (3.3285)	grad_norm 3.4122 (3.9946)	mem 8931MB
[2022-04-07 23:33:38 large] (main.py 226): INFO Train: [161/300][900/2502]	eta 0:17:38 lr 0.000223	time 0.6399 (0.6607)	loss 3.4835 (3.3324)	grad_norm 3.1778 (4.0007)	mem 8931MB
[2022-04-07 23:34:44 large] (main.py 226): INFO Train: [161/300][1000/2502]	eta 0:16:31 lr 0.000223	time 0.6629 (0.6601)	loss 2.8886 (3.3299)	grad_norm 4.9306 (4.0149)	mem 8931MB
[2022-04-07 23:35:49 large] (main.py 226): INFO Train: [161/300][1100/2502]	eta 0:15:24 lr 0.000223	time 0.5930 (0.6594)	loss 3.8502 (3.3291)	grad_norm 3.3445 (4.0047)	mem 8931MB
[2022-04-07 23:36:56 large] (main.py 226): INFO Train: [161/300][1200/2502]	eta 0:14:19 lr 0.000223	time 0.7380 (0.6604)	loss 3.6341 (3.3234)	grad_norm 4.4505 (4.0075)	mem 8931MB
[2022-04-07 23:38:03 large] (main.py 226): INFO Train: [161/300][1300/2502]	eta 0:13:14 lr 0.000223	time 0.6346 (0.6610)	loss 2.2533 (3.3252)	grad_norm 4.0050 (nan)	mem 8931MB
[2022-04-07 23:39:10 large] (main.py 226): INFO Train: [161/300][1400/2502]	eta 0:12:09 lr 0.000223	time 0.5856 (0.6618)	loss 2.1020 (3.3228)	grad_norm 3.9798 (nan)	mem 8931MB
[2022-04-07 23:40:16 large] (main.py 226): INFO Train: [161/300][1500/2502]	eta 0:11:02 lr 0.000223	time 0.7341 (0.6616)	loss 3.7944 (3.3223)	grad_norm 4.4493 (nan)	mem 8931MB
[2022-04-07 23:41:21 large] (main.py 226): INFO Train: [161/300][1600/2502]	eta 0:09:56 lr 0.000222	time 0.6666 (0.6612)	loss 3.6495 (3.3187)	grad_norm 3.5531 (nan)	mem 8931MB
[2022-04-07 23:42:27 large] (main.py 226): INFO Train: [161/300][1700/2502]	eta 0:08:50 lr 0.000222	time 0.5267 (0.6612)	loss 4.0974 (3.3196)	grad_norm 4.1822 (nan)	mem 8931MB
[2022-04-07 23:43:34 large] (main.py 226): INFO Train: [161/300][1800/2502]	eta 0:07:44 lr 0.000222	time 0.7722 (0.6614)	loss 3.6198 (3.3212)	grad_norm 4.5194 (nan)	mem 8931MB
[2022-04-07 23:44:41 large] (main.py 226): INFO Train: [161/300][1900/2502]	eta 0:06:38 lr 0.000222	time 0.6550 (0.6617)	loss 3.4958 (3.3195)	grad_norm 4.2680 (nan)	mem 8931MB
[2022-04-07 23:45:47 large] (main.py 226): INFO Train: [161/300][2000/2502]	eta 0:05:32 lr 0.000222	time 0.6996 (0.6620)	loss 3.1436 (3.3232)	grad_norm 3.0829 (nan)	mem 8931MB
[2022-04-07 23:46:54 large] (main.py 226): INFO Train: [161/300][2100/2502]	eta 0:04:26 lr 0.000222	time 0.5884 (0.6620)	loss 2.8228 (3.3240)	grad_norm 4.0693 (nan)	mem 8931MB
[2022-04-07 23:48:00 large] (main.py 226): INFO Train: [161/300][2200/2502]	eta 0:03:19 lr 0.000222	time 0.6420 (0.6620)	loss 3.3896 (3.3247)	grad_norm 3.9070 (nan)	mem 8931MB
[2022-04-07 23:49:07 large] (main.py 226): INFO Train: [161/300][2300/2502]	eta 0:02:13 lr 0.000222	time 0.7038 (0.6623)	loss 2.5142 (3.3229)	grad_norm 2.9659 (nan)	mem 8931MB
[2022-04-07 23:50:13 large] (main.py 226): INFO Train: [161/300][2400/2502]	eta 0:01:07 lr 0.000222	time 0.7021 (0.6625)	loss 3.2544 (3.3182)	grad_norm 3.2474 (nan)	mem 8931MB
[2022-04-07 23:51:18 large] (main.py 226): INFO Train: [161/300][2500/2502]	eta 0:00:01 lr 0.000221	time 0.6408 (0.6619)	loss 3.8220 (3.3187)	grad_norm 3.5102 (nan)	mem 8931MB
[2022-04-07 23:51:19 large] (main.py 233): INFO EPOCH 161 training takes 0:27:36
[2022-04-07 23:51:25 large] (main.py 273): INFO Test: [0/98]	Time 5.964 (5.964)	Loss 0.9390 (0.9390)	Acc@1 82.227 (82.227)	Acc@5 95.117 (95.117)	Mem 8931MB
[2022-04-07 23:51:52 large] (main.py 279): INFO  * Acc@1 77.968 Acc@5 93.986
[2022-04-07 23:51:52 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 78.0%
[2022-04-07 23:51:52 large] (utils.py 57): INFO output/large/default/ckpt_epoch_161.pth saving......
[2022-04-07 23:51:53 large] (utils.py 59): INFO output/large/default/ckpt_epoch_161.pth saved !!!
[2022-04-07 23:51:53 large] (main.py 148): INFO Max accuracy: 77.97%
[2022-04-07 23:52:00 large] (main.py 226): INFO Train: [162/300][0/2502]	eta 5:12:39 lr 0.000221	time 7.4979 (7.4979)	loss 3.3125 (3.3125)	grad_norm 4.0706 (4.0706)	mem 8931MB
[2022-04-07 23:52:58 large] (main.py 226): INFO Train: [162/300][100/2502]	eta 0:25:58 lr 0.000221	time 0.6724 (0.6488)	loss 2.9361 (3.3833)	grad_norm 6.1425 (nan)	mem 8931MB
[2022-04-07 23:54:06 large] (main.py 226): INFO Train: [162/300][200/2502]	eta 0:25:26 lr 0.000221	time 0.7037 (0.6632)	loss 3.2737 (3.3704)	grad_norm 4.3660 (nan)	mem 8931MB
[2022-04-07 23:55:13 large] (main.py 226): INFO Train: [162/300][300/2502]	eta 0:24:29 lr 0.000221	time 0.6892 (0.6674)	loss 2.6799 (3.4006)	grad_norm 5.5920 (nan)	mem 8931MB
[2022-04-07 23:56:20 large] (main.py 226): INFO Train: [162/300][400/2502]	eta 0:23:23 lr 0.000221	time 0.6244 (0.6678)	loss 3.4877 (3.3863)	grad_norm 3.5060 (nan)	mem 8931MB
[2022-04-07 23:57:26 large] (main.py 226): INFO Train: [162/300][500/2502]	eta 0:22:13 lr 0.000221	time 0.7184 (0.6662)	loss 2.5794 (3.3918)	grad_norm 3.9059 (nan)	mem 8931MB
[2022-04-07 23:58:34 large] (main.py 226): INFO Train: [162/300][600/2502]	eta 0:21:10 lr 0.000221	time 0.6138 (0.6678)	loss 3.0430 (3.3760)	grad_norm 4.7367 (nan)	mem 8931MB
[2022-04-07 23:59:41 large] (main.py 226): INFO Train: [162/300][700/2502]	eta 0:20:02 lr 0.000221	time 0.6804 (0.6676)	loss 3.7553 (3.3658)	grad_norm 4.1430 (nan)	mem 8931MB
[2022-04-08 00:00:46 large] (main.py 226): INFO Train: [162/300][800/2502]	eta 0:18:54 lr 0.000221	time 0.6932 (0.6666)	loss 3.4352 (3.3685)	grad_norm 4.3468 (nan)	mem 8931MB
[2022-04-08 00:01:53 large] (main.py 226): INFO Train: [162/300][900/2502]	eta 0:17:47 lr 0.000221	time 0.6487 (0.6661)	loss 3.7105 (3.3677)	grad_norm 4.5572 (nan)	mem 8931MB
[2022-04-08 00:02:58 large] (main.py 226): INFO Train: [162/300][1000/2502]	eta 0:16:38 lr 0.000220	time 0.6431 (0.6647)	loss 3.9093 (3.3612)	grad_norm 6.0940 (nan)	mem 8931MB
[2022-04-08 00:04:04 large] (main.py 226): INFO Train: [162/300][1100/2502]	eta 0:15:31 lr 0.000220	time 0.6257 (0.6646)	loss 3.1053 (3.3542)	grad_norm 5.4785 (nan)	mem 8931MB
[2022-04-08 00:05:10 large] (main.py 226): INFO Train: [162/300][1200/2502]	eta 0:14:24 lr 0.000220	time 0.6062 (0.6636)	loss 3.8351 (3.3506)	grad_norm 4.2306 (nan)	mem 8931MB
[2022-04-08 00:06:15 large] (main.py 226): INFO Train: [162/300][1300/2502]	eta 0:13:16 lr 0.000220	time 0.6345 (0.6631)	loss 3.3812 (3.3440)	grad_norm 3.7023 (nan)	mem 8931MB
[2022-04-08 00:07:20 large] (main.py 226): INFO Train: [162/300][1400/2502]	eta 0:12:09 lr 0.000220	time 0.6419 (0.6623)	loss 2.5117 (3.3422)	grad_norm 4.2299 (nan)	mem 8931MB
[2022-04-08 00:08:26 large] (main.py 226): INFO Train: [162/300][1500/2502]	eta 0:11:03 lr 0.000220	time 0.6574 (0.6619)	loss 3.6717 (3.3372)	grad_norm 5.0884 (nan)	mem 8931MB
[2022-04-08 00:09:31 large] (main.py 226): INFO Train: [162/300][1600/2502]	eta 0:09:56 lr 0.000220	time 0.5279 (0.6609)	loss 3.4931 (3.3350)	grad_norm 3.4251 (nan)	mem 8931MB
[2022-04-08 00:10:37 large] (main.py 226): INFO Train: [162/300][1700/2502]	eta 0:08:50 lr 0.000220	time 0.6430 (0.6611)	loss 3.8071 (3.3382)	grad_norm 4.5024 (nan)	mem 8931MB
[2022-04-08 00:11:43 large] (main.py 226): INFO Train: [162/300][1800/2502]	eta 0:07:44 lr 0.000220	time 0.6252 (0.6611)	loss 3.7031 (3.3363)	grad_norm 5.0791 (nan)	mem 8931MB
[2022-04-08 00:12:49 large] (main.py 226): INFO Train: [162/300][1900/2502]	eta 0:06:37 lr 0.000220	time 0.5691 (0.6611)	loss 3.4775 (3.3369)	grad_norm 3.7001 (nan)	mem 8931MB
[2022-04-08 00:13:56 large] (main.py 226): INFO Train: [162/300][2000/2502]	eta 0:05:31 lr 0.000219	time 0.5057 (0.6613)	loss 3.0643 (3.3363)	grad_norm 4.7705 (nan)	mem 8931MB
[2022-04-08 00:15:02 large] (main.py 226): INFO Train: [162/300][2100/2502]	eta 0:04:25 lr 0.000219	time 0.6581 (0.6612)	loss 3.1244 (3.3377)	grad_norm 3.8667 (nan)	mem 8931MB
[2022-04-08 00:16:07 large] (main.py 226): INFO Train: [162/300][2200/2502]	eta 0:03:19 lr 0.000219	time 0.6674 (0.6607)	loss 3.3040 (3.3389)	grad_norm 4.0290 (nan)	mem 8931MB
[2022-04-08 00:17:13 large] (main.py 226): INFO Train: [162/300][2300/2502]	eta 0:02:13 lr 0.000219	time 0.6759 (0.6606)	loss 3.4222 (3.3372)	grad_norm 3.9694 (nan)	mem 8931MB
[2022-04-08 00:18:18 large] (main.py 226): INFO Train: [162/300][2400/2502]	eta 0:01:07 lr 0.000219	time 0.6254 (0.6604)	loss 2.5741 (3.3365)	grad_norm 3.4740 (nan)	mem 8931MB
[2022-04-08 00:19:23 large] (main.py 226): INFO Train: [162/300][2500/2502]	eta 0:00:01 lr 0.000219	time 0.7461 (0.6601)	loss 2.9960 (3.3354)	grad_norm 5.8492 (nan)	mem 8931MB
[2022-04-08 00:19:25 large] (main.py 233): INFO EPOCH 162 training takes 0:27:32
[2022-04-08 00:19:31 large] (main.py 273): INFO Test: [0/98]	Time 6.049 (6.049)	Loss 0.9985 (0.9985)	Acc@1 81.055 (81.055)	Acc@5 93.750 (93.750)	Mem 8931MB
[2022-04-08 00:19:57 large] (main.py 279): INFO  * Acc@1 77.672 Acc@5 93.970
[2022-04-08 00:19:57 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 77.7%
[2022-04-08 00:19:57 large] (main.py 148): INFO Max accuracy: 77.97%
[2022-04-08 00:20:04 large] (main.py 226): INFO Train: [163/300][0/2502]	eta 4:41:21 lr 0.000219	time 6.7470 (6.7470)	loss 2.0558 (2.0558)	grad_norm 4.3542 (4.3542)	mem 8931MB
[2022-04-08 00:21:05 large] (main.py 226): INFO Train: [163/300][100/2502]	eta 0:26:51 lr 0.000219	time 0.6607 (0.6710)	loss 2.5690 (3.2691)	grad_norm 4.4765 (4.1590)	mem 8931MB
[2022-04-08 00:22:12 large] (main.py 226): INFO Train: [163/300][200/2502]	eta 0:25:40 lr 0.000219	time 0.5058 (0.6693)	loss 3.5776 (3.2294)	grad_norm 3.1852 (4.2444)	mem 8931MB
[2022-04-08 00:23:19 large] (main.py 226): INFO Train: [163/300][300/2502]	eta 0:24:35 lr 0.000219	time 0.6965 (0.6701)	loss 3.2647 (3.2484)	grad_norm 5.8433 (4.2236)	mem 8931MB
[2022-04-08 00:24:25 large] (main.py 226): INFO Train: [163/300][400/2502]	eta 0:23:26 lr 0.000218	time 0.6664 (0.6691)	loss 2.1916 (3.2320)	grad_norm 3.4757 (4.2116)	mem 8931MB
[2022-04-08 00:25:32 large] (main.py 226): INFO Train: [163/300][500/2502]	eta 0:22:19 lr 0.000218	time 0.7168 (0.6692)	loss 3.1692 (3.2462)	grad_norm 3.8209 (4.1497)	mem 8931MB
[2022-04-08 00:26:38 large] (main.py 226): INFO Train: [163/300][600/2502]	eta 0:21:09 lr 0.000218	time 0.6627 (0.6675)	loss 4.2331 (3.2595)	grad_norm 4.4844 (4.1575)	mem 8931MB
[2022-04-08 00:27:44 large] (main.py 226): INFO Train: [163/300][700/2502]	eta 0:19:59 lr 0.000218	time 0.6399 (0.6659)	loss 3.3609 (3.2546)	grad_norm 3.8433 (4.1648)	mem 8931MB
[2022-04-08 00:28:50 large] (main.py 226): INFO Train: [163/300][800/2502]	eta 0:18:51 lr 0.000218	time 0.6354 (0.6649)	loss 3.4119 (3.2603)	grad_norm 3.2855 (4.1315)	mem 8931MB
[2022-04-08 00:29:56 large] (main.py 226): INFO Train: [163/300][900/2502]	eta 0:17:44 lr 0.000218	time 0.6366 (0.6644)	loss 3.4277 (3.2671)	grad_norm 3.8481 (4.1362)	mem 8931MB
[2022-04-08 00:31:00 large] (main.py 226): INFO Train: [163/300][1000/2502]	eta 0:16:35 lr 0.000218	time 0.6095 (0.6626)	loss 3.8838 (3.2848)	grad_norm 4.1613 (4.1284)	mem 8931MB
[2022-04-08 00:32:06 large] (main.py 226): INFO Train: [163/300][1100/2502]	eta 0:15:27 lr 0.000218	time 0.6645 (0.6619)	loss 3.5671 (3.2811)	grad_norm 3.4744 (4.1541)	mem 8931MB
[2022-04-08 00:33:12 large] (main.py 226): INFO Train: [163/300][1200/2502]	eta 0:14:21 lr 0.000218	time 0.6549 (0.6614)	loss 4.2076 (3.2820)	grad_norm 3.3338 (4.1461)	mem 8931MB
[2022-04-08 00:34:17 large] (main.py 226): INFO Train: [163/300][1300/2502]	eta 0:13:14 lr 0.000218	time 0.8069 (0.6609)	loss 3.9829 (3.2856)	grad_norm 6.3983 (4.1489)	mem 8931MB
[2022-04-08 00:35:24 large] (main.py 226): INFO Train: [163/300][1400/2502]	eta 0:12:08 lr 0.000217	time 0.6795 (0.6613)	loss 2.0261 (3.2838)	grad_norm 4.2224 (4.1396)	mem 8931MB
[2022-04-08 00:36:29 large] (main.py 226): INFO Train: [163/300][1500/2502]	eta 0:11:02 lr 0.000217	time 0.6021 (0.6610)	loss 3.7968 (3.2902)	grad_norm 5.4116 (4.1338)	mem 8931MB
[2022-04-08 00:37:35 large] (main.py 226): INFO Train: [163/300][1600/2502]	eta 0:09:55 lr 0.000217	time 0.5928 (0.6607)	loss 3.8510 (3.2908)	grad_norm 3.7468 (4.1232)	mem 8931MB
[2022-04-08 00:38:41 large] (main.py 226): INFO Train: [163/300][1700/2502]	eta 0:08:49 lr 0.000217	time 0.6333 (0.6605)	loss 3.2693 (3.2911)	grad_norm 3.8285 (4.1099)	mem 8931MB
[2022-04-08 00:39:47 large] (main.py 226): INFO Train: [163/300][1800/2502]	eta 0:07:43 lr 0.000217	time 0.7130 (0.6606)	loss 2.5765 (3.2990)	grad_norm 3.9094 (4.1079)	mem 8931MB
[2022-04-08 00:40:52 large] (main.py 226): INFO Train: [163/300][1900/2502]	eta 0:06:37 lr 0.000217	time 0.5486 (0.6601)	loss 3.6049 (3.3013)	grad_norm 3.7728 (4.1008)	mem 8931MB
[2022-04-08 00:41:56 large] (main.py 226): INFO Train: [163/300][2000/2502]	eta 0:05:30 lr 0.000217	time 0.6137 (0.6590)	loss 3.1767 (3.3039)	grad_norm 3.9161 (4.0897)	mem 8931MB
[2022-04-08 00:43:01 large] (main.py 226): INFO Train: [163/300][2100/2502]	eta 0:04:24 lr 0.000217	time 0.5754 (0.6586)	loss 3.5151 (3.3074)	grad_norm 4.7349 (4.0839)	mem 8931MB
[2022-04-08 00:44:05 large] (main.py 226): INFO Train: [163/300][2200/2502]	eta 0:03:18 lr 0.000217	time 0.7021 (0.6576)	loss 2.8468 (3.3059)	grad_norm 4.5095 (4.0844)	mem 8931MB
[2022-04-08 00:45:11 large] (main.py 226): INFO Train: [163/300][2300/2502]	eta 0:02:12 lr 0.000217	time 0.7573 (0.6577)	loss 3.7244 (3.3094)	grad_norm 3.5677 (4.0847)	mem 8931MB
[2022-04-08 00:46:16 large] (main.py 226): INFO Train: [163/300][2400/2502]	eta 0:01:07 lr 0.000216	time 0.6813 (0.6577)	loss 3.4077 (3.3119)	grad_norm 2.9250 (4.0829)	mem 8931MB
[2022-04-08 00:47:21 large] (main.py 226): INFO Train: [163/300][2500/2502]	eta 0:00:01 lr 0.000216	time 0.5762 (0.6574)	loss 2.8858 (3.3104)	grad_norm 3.9105 (4.0786)	mem 8931MB
[2022-04-08 00:47:22 large] (main.py 233): INFO EPOCH 163 training takes 0:27:25
[2022-04-08 00:47:28 large] (main.py 273): INFO Test: [0/98]	Time 6.003 (6.003)	Loss 1.0960 (1.0960)	Acc@1 77.734 (77.734)	Acc@5 92.969 (92.969)	Mem 8931MB
[2022-04-08 00:47:55 large] (main.py 279): INFO  * Acc@1 77.952 Acc@5 94.150
[2022-04-08 00:47:55 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 78.0%
[2022-04-08 00:47:55 large] (main.py 148): INFO Max accuracy: 77.97%
[2022-04-08 00:48:02 large] (main.py 226): INFO Train: [164/300][0/2502]	eta 5:04:51 lr 0.000216	time 7.3107 (7.3107)	loss 3.1215 (3.1215)	grad_norm 4.4029 (4.4029)	mem 8931MB
[2022-04-08 00:49:01 large] (main.py 226): INFO Train: [164/300][100/2502]	eta 0:26:07 lr 0.000216	time 0.5909 (0.6526)	loss 3.7666 (3.2502)	grad_norm 3.5517 (3.8796)	mem 8931MB
[2022-04-08 00:50:07 large] (main.py 226): INFO Train: [164/300][200/2502]	eta 0:25:20 lr 0.000216	time 0.6831 (0.6607)	loss 2.8266 (3.2971)	grad_norm 3.9241 (3.9898)	mem 8931MB
[2022-04-08 00:51:14 large] (main.py 226): INFO Train: [164/300][300/2502]	eta 0:24:18 lr 0.000216	time 0.7853 (0.6624)	loss 3.5612 (3.2833)	grad_norm 3.3416 (3.9700)	mem 8931MB
[2022-04-08 00:52:20 large] (main.py 226): INFO Train: [164/300][400/2502]	eta 0:23:12 lr 0.000216	time 0.6665 (0.6625)	loss 3.7381 (3.2869)	grad_norm 3.4217 (3.9706)	mem 8931MB
[2022-04-08 00:53:25 large] (main.py 226): INFO Train: [164/300][500/2502]	eta 0:22:01 lr 0.000216	time 0.5943 (0.6601)	loss 3.0453 (3.2994)	grad_norm 3.6941 (3.9918)	mem 8931MB
[2022-04-08 00:54:30 large] (main.py 226): INFO Train: [164/300][600/2502]	eta 0:20:52 lr 0.000216	time 0.5924 (0.6583)	loss 2.3330 (3.3009)	grad_norm 3.7620 (3.9854)	mem 8931MB
[2022-04-08 00:55:36 large] (main.py 226): INFO Train: [164/300][700/2502]	eta 0:19:47 lr 0.000216	time 0.7965 (0.6588)	loss 3.1495 (3.2989)	grad_norm 3.0355 (3.9754)	mem 8931MB
[2022-04-08 00:56:43 large] (main.py 226): INFO Train: [164/300][800/2502]	eta 0:18:41 lr 0.000216	time 0.6330 (0.6591)	loss 3.6138 (3.2988)	grad_norm 3.3561 (3.9748)	mem 8931MB
[2022-04-08 00:57:48 large] (main.py 226): INFO Train: [164/300][900/2502]	eta 0:17:35 lr 0.000215	time 0.6720 (0.6587)	loss 3.0172 (3.2959)	grad_norm 4.3500 (3.9674)	mem 8931MB
[2022-04-08 00:58:54 large] (main.py 226): INFO Train: [164/300][1000/2502]	eta 0:16:28 lr 0.000215	time 0.7091 (0.6583)	loss 3.3033 (3.2991)	grad_norm 4.1111 (3.9675)	mem 8931MB
[2022-04-08 00:59:59 large] (main.py 226): INFO Train: [164/300][1100/2502]	eta 0:15:22 lr 0.000215	time 0.6257 (0.6579)	loss 2.3598 (3.2987)	grad_norm 5.0873 (3.9646)	mem 8931MB
[2022-04-08 01:01:04 large] (main.py 226): INFO Train: [164/300][1200/2502]	eta 0:14:15 lr 0.000215	time 0.7216 (0.6572)	loss 3.5041 (3.2983)	grad_norm 4.4187 (3.9529)	mem 8931MB
[2022-04-08 01:02:09 large] (main.py 226): INFO Train: [164/300][1300/2502]	eta 0:13:09 lr 0.000215	time 0.7335 (0.6564)	loss 3.8698 (3.3004)	grad_norm 3.0826 (3.9513)	mem 8931MB
[2022-04-08 01:03:14 large] (main.py 226): INFO Train: [164/300][1400/2502]	eta 0:12:03 lr 0.000215	time 0.6024 (0.6564)	loss 2.5703 (3.3007)	grad_norm 4.3567 (3.9447)	mem 8931MB
[2022-04-08 01:04:19 large] (main.py 226): INFO Train: [164/300][1500/2502]	eta 0:10:57 lr 0.000215	time 0.8342 (0.6559)	loss 3.3050 (3.3019)	grad_norm 5.2690 (3.9524)	mem 8931MB
[2022-04-08 01:05:26 large] (main.py 226): INFO Train: [164/300][1600/2502]	eta 0:09:52 lr 0.000215	time 0.6496 (0.6565)	loss 4.0332 (3.2990)	grad_norm 3.5647 (3.9443)	mem 8931MB
[2022-04-08 01:06:31 large] (main.py 226): INFO Train: [164/300][1700/2502]	eta 0:08:46 lr 0.000215	time 0.6740 (0.6563)	loss 2.9888 (3.2981)	grad_norm 3.7737 (3.9420)	mem 8931MB
[2022-04-08 01:07:36 large] (main.py 226): INFO Train: [164/300][1800/2502]	eta 0:07:40 lr 0.000215	time 0.6888 (0.6561)	loss 2.3968 (3.2984)	grad_norm 3.0488 (3.9488)	mem 8931MB
[2022-04-08 01:08:41 large] (main.py 226): INFO Train: [164/300][1900/2502]	eta 0:06:34 lr 0.000214	time 0.7296 (0.6558)	loss 3.4609 (3.2990)	grad_norm 3.3103 (3.9538)	mem 8931MB
[2022-04-08 01:09:46 large] (main.py 226): INFO Train: [164/300][2000/2502]	eta 0:05:29 lr 0.000214	time 0.6676 (0.6556)	loss 4.2870 (3.3010)	grad_norm 4.4808 (3.9593)	mem 8931MB
[2022-04-08 01:10:51 large] (main.py 226): INFO Train: [164/300][2100/2502]	eta 0:04:23 lr 0.000214	time 0.7087 (0.6553)	loss 3.0323 (3.2991)	grad_norm 4.1069 (3.9699)	mem 8931MB
[2022-04-08 01:11:56 large] (main.py 226): INFO Train: [164/300][2200/2502]	eta 0:03:17 lr 0.000214	time 0.5652 (0.6548)	loss 3.9524 (3.3020)	grad_norm 4.5103 (3.9791)	mem 8931MB
[2022-04-08 01:13:01 large] (main.py 226): INFO Train: [164/300][2300/2502]	eta 0:02:12 lr 0.000214	time 0.6894 (0.6545)	loss 3.1483 (3.2970)	grad_norm 4.1132 (3.9712)	mem 8931MB
[2022-04-08 01:14:06 large] (main.py 226): INFO Train: [164/300][2400/2502]	eta 0:01:06 lr 0.000214	time 0.6857 (0.6546)	loss 3.6200 (3.2992)	grad_norm 4.9960 (3.9770)	mem 8931MB
[2022-04-08 01:15:10 large] (main.py 226): INFO Train: [164/300][2500/2502]	eta 0:00:01 lr 0.000214	time 0.5881 (0.6541)	loss 2.6320 (3.3031)	grad_norm 3.3159 (3.9787)	mem 8931MB
[2022-04-08 01:15:11 large] (main.py 233): INFO EPOCH 164 training takes 0:27:16
[2022-04-08 01:15:18 large] (main.py 273): INFO Test: [0/98]	Time 6.502 (6.502)	Loss 1.0970 (1.0970)	Acc@1 78.906 (78.906)	Acc@5 92.383 (92.383)	Mem 8931MB
[2022-04-08 01:15:44 large] (main.py 279): INFO  * Acc@1 77.906 Acc@5 94.104
[2022-04-08 01:15:44 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 77.9%
[2022-04-08 01:15:44 large] (main.py 148): INFO Max accuracy: 77.97%
[2022-04-08 01:15:51 large] (main.py 226): INFO Train: [165/300][0/2502]	eta 4:46:14 lr 0.000214	time 6.8643 (6.8643)	loss 2.9835 (2.9835)	grad_norm 3.7509 (3.7509)	mem 8931MB
[2022-04-08 01:16:48 large] (main.py 226): INFO Train: [165/300][100/2502]	eta 0:25:08 lr 0.000214	time 0.6604 (0.6281)	loss 3.6862 (3.3517)	grad_norm 3.4912 (4.1321)	mem 8931MB
[2022-04-08 01:17:53 large] (main.py 226): INFO Train: [165/300][200/2502]	eta 0:24:36 lr 0.000214	time 0.6732 (0.6416)	loss 3.5174 (3.2994)	grad_norm 3.8765 (4.2585)	mem 8931MB
[2022-04-08 01:18:58 large] (main.py 226): INFO Train: [165/300][300/2502]	eta 0:23:37 lr 0.000213	time 0.6428 (0.6436)	loss 3.0094 (3.3172)	grad_norm 3.8811 (4.1304)	mem 8931MB
[2022-04-08 01:20:03 large] (main.py 226): INFO Train: [165/300][400/2502]	eta 0:22:39 lr 0.000213	time 0.6829 (0.6466)	loss 2.9888 (3.3335)	grad_norm 2.9023 (4.1181)	mem 8931MB
[2022-04-08 01:21:07 large] (main.py 226): INFO Train: [165/300][500/2502]	eta 0:21:30 lr 0.000213	time 0.6765 (0.6447)	loss 3.5353 (3.3236)	grad_norm 5.1491 (4.0979)	mem 8931MB
[2022-04-08 01:22:12 large] (main.py 226): INFO Train: [165/300][600/2502]	eta 0:20:27 lr 0.000213	time 0.6583 (0.6454)	loss 3.9614 (3.3234)	grad_norm 4.8265 (4.1218)	mem 8931MB
[2022-04-08 01:23:18 large] (main.py 226): INFO Train: [165/300][700/2502]	eta 0:19:27 lr 0.000213	time 0.6295 (0.6477)	loss 3.6670 (3.3138)	grad_norm 3.4943 (4.1070)	mem 8931MB
[2022-04-08 01:24:24 large] (main.py 226): INFO Train: [165/300][800/2502]	eta 0:18:24 lr 0.000213	time 0.6645 (0.6492)	loss 3.1193 (3.3128)	grad_norm 3.9365 (4.1002)	mem 8931MB
[2022-04-08 01:25:29 large] (main.py 226): INFO Train: [165/300][900/2502]	eta 0:17:20 lr 0.000213	time 0.6667 (0.6493)	loss 3.8181 (3.2995)	grad_norm 3.2999 (4.0833)	mem 8931MB
[2022-04-08 01:26:35 large] (main.py 226): INFO Train: [165/300][1000/2502]	eta 0:16:16 lr 0.000213	time 0.7003 (0.6499)	loss 2.7027 (3.2971)	grad_norm 3.7186 (4.0724)	mem 8931MB
[2022-04-08 01:27:41 large] (main.py 226): INFO Train: [165/300][1100/2502]	eta 0:15:12 lr 0.000213	time 0.6588 (0.6510)	loss 3.4392 (3.2941)	grad_norm 3.6813 (4.0839)	mem 8931MB
[2022-04-08 01:28:46 large] (main.py 226): INFO Train: [165/300][1200/2502]	eta 0:14:08 lr 0.000213	time 0.6724 (0.6514)	loss 2.1788 (3.2985)	grad_norm 3.5837 (4.0808)	mem 8931MB
[2022-04-08 01:29:51 large] (main.py 226): INFO Train: [165/300][1300/2502]	eta 0:13:02 lr 0.000212	time 0.6683 (0.6507)	loss 2.2608 (3.3025)	grad_norm 3.2571 (4.0787)	mem 8931MB
[2022-04-08 01:30:57 large] (main.py 226): INFO Train: [165/300][1400/2502]	eta 0:11:57 lr 0.000212	time 0.6772 (0.6515)	loss 1.9198 (3.3054)	grad_norm 3.6534 (4.0688)	mem 8931MB
[2022-04-08 01:32:02 large] (main.py 226): INFO Train: [165/300][1500/2502]	eta 0:10:52 lr 0.000212	time 0.6448 (0.6513)	loss 3.9055 (3.3020)	grad_norm 3.8936 (4.0690)	mem 8931MB
[2022-04-08 01:33:07 large] (main.py 226): INFO Train: [165/300][1600/2502]	eta 0:09:47 lr 0.000212	time 0.6726 (0.6515)	loss 2.6472 (3.3021)	grad_norm 3.2254 (4.0700)	mem 8931MB
[2022-04-08 01:34:12 large] (main.py 226): INFO Train: [165/300][1700/2502]	eta 0:08:42 lr 0.000212	time 0.4942 (0.6513)	loss 4.4299 (3.3078)	grad_norm 4.0965 (4.0681)	mem 8931MB
[2022-04-08 01:35:17 large] (main.py 226): INFO Train: [165/300][1800/2502]	eta 0:07:37 lr 0.000212	time 0.5358 (0.6514)	loss 3.3473 (3.3047)	grad_norm 3.2049 (4.0862)	mem 8931MB
[2022-04-08 01:36:23 large] (main.py 226): INFO Train: [165/300][1900/2502]	eta 0:06:32 lr 0.000212	time 0.5635 (0.6516)	loss 3.5653 (3.3005)	grad_norm 4.3412 (4.0701)	mem 8931MB
[2022-04-08 01:37:28 large] (main.py 226): INFO Train: [165/300][2000/2502]	eta 0:05:27 lr 0.000212	time 0.7301 (0.6517)	loss 3.5676 (3.3034)	grad_norm 3.9305 (4.0653)	mem 8931MB
[2022-04-08 01:38:34 large] (main.py 226): INFO Train: [165/300][2100/2502]	eta 0:04:22 lr 0.000212	time 0.6622 (0.6520)	loss 3.6519 (3.3031)	grad_norm 3.9258 (4.0654)	mem 8931MB
[2022-04-08 01:39:39 large] (main.py 226): INFO Train: [165/300][2200/2502]	eta 0:03:16 lr 0.000212	time 0.6832 (0.6519)	loss 3.7384 (3.3044)	grad_norm 4.1644 (4.0695)	mem 8931MB
[2022-04-08 01:40:44 large] (main.py 226): INFO Train: [165/300][2300/2502]	eta 0:02:11 lr 0.000211	time 0.6766 (0.6517)	loss 2.9546 (3.3032)	grad_norm 3.6645 (4.0695)	mem 8931MB
[2022-04-08 01:41:50 large] (main.py 226): INFO Train: [165/300][2400/2502]	eta 0:01:06 lr 0.000211	time 0.6908 (0.6521)	loss 3.6381 (3.3035)	grad_norm 5.0164 (4.0718)	mem 8931MB
[2022-04-08 01:42:55 large] (main.py 226): INFO Train: [165/300][2500/2502]	eta 0:00:01 lr 0.000211	time 0.5324 (0.6520)	loss 3.3901 (3.3002)	grad_norm 3.9099 (nan)	mem 8931MB
[2022-04-08 01:42:56 large] (main.py 233): INFO EPOCH 165 training takes 0:27:11
[2022-04-08 01:43:02 large] (main.py 273): INFO Test: [0/98]	Time 6.661 (6.661)	Loss 1.0545 (1.0545)	Acc@1 79.102 (79.102)	Acc@5 95.703 (95.703)	Mem 8931MB
[2022-04-08 01:43:28 large] (main.py 279): INFO  * Acc@1 77.982 Acc@5 94.066
[2022-04-08 01:43:28 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 78.0%
[2022-04-08 01:43:28 large] (utils.py 57): INFO output/large/default/ckpt_epoch_165.pth saving......
[2022-04-08 01:43:29 large] (utils.py 59): INFO output/large/default/ckpt_epoch_165.pth saved !!!
[2022-04-08 01:43:29 large] (main.py 148): INFO Max accuracy: 77.98%
[2022-04-08 01:43:37 large] (main.py 226): INFO Train: [166/300][0/2502]	eta 5:43:07 lr 0.000211	time 8.2286 (8.2286)	loss 3.4727 (3.4727)	grad_norm 5.4958 (5.4958)	mem 8931MB
[2022-04-08 01:44:31 large] (main.py 226): INFO Train: [166/300][100/2502]	eta 0:24:46 lr 0.000211	time 0.5741 (0.6187)	loss 2.9301 (3.3227)	grad_norm 5.1801 (4.1813)	mem 8931MB
[2022-04-08 01:45:39 large] (main.py 226): INFO Train: [166/300][200/2502]	eta 0:24:51 lr 0.000211	time 0.7393 (0.6480)	loss 2.4789 (3.2941)	grad_norm 4.2763 (4.1531)	mem 8931MB
[2022-04-08 01:46:46 large] (main.py 226): INFO Train: [166/300][300/2502]	eta 0:23:59 lr 0.000211	time 0.6695 (0.6535)	loss 3.1975 (3.2870)	grad_norm 3.1784 (4.0950)	mem 8931MB
[2022-04-08 01:47:52 large] (main.py 226): INFO Train: [166/300][400/2502]	eta 0:22:58 lr 0.000211	time 0.7102 (0.6558)	loss 3.9823 (3.2579)	grad_norm 4.0734 (4.0986)	mem 8931MB
[2022-04-08 01:48:57 large] (main.py 226): INFO Train: [166/300][500/2502]	eta 0:21:52 lr 0.000211	time 0.6844 (0.6558)	loss 2.2838 (3.2627)	grad_norm 3.8653 (4.1297)	mem 8931MB
[2022-04-08 01:50:02 large] (main.py 226): INFO Train: [166/300][600/2502]	eta 0:20:43 lr 0.000211	time 0.6852 (0.6539)	loss 3.4480 (3.2651)	grad_norm 4.2250 (4.1184)	mem 8931MB
[2022-04-08 01:51:07 large] (main.py 226): INFO Train: [166/300][700/2502]	eta 0:19:36 lr 0.000211	time 0.6669 (0.6529)	loss 3.7096 (3.2699)	grad_norm 5.5748 (4.1170)	mem 8931MB
[2022-04-08 01:52:13 large] (main.py 226): INFO Train: [166/300][800/2502]	eta 0:18:33 lr 0.000210	time 0.6422 (0.6542)	loss 4.1129 (3.2804)	grad_norm 4.2284 (4.1272)	mem 8931MB
[2022-04-08 01:53:17 large] (main.py 226): INFO Train: [166/300][900/2502]	eta 0:17:25 lr 0.000210	time 0.6836 (0.6523)	loss 3.4748 (3.2761)	grad_norm 3.0423 (4.1031)	mem 8931MB
[2022-04-08 01:54:22 large] (main.py 226): INFO Train: [166/300][1000/2502]	eta 0:16:20 lr 0.000210	time 0.5998 (0.6526)	loss 3.5458 (3.2750)	grad_norm 4.3670 (4.1167)	mem 8931MB
[2022-04-08 01:55:27 large] (main.py 226): INFO Train: [166/300][1100/2502]	eta 0:15:15 lr 0.000210	time 0.6066 (0.6527)	loss 2.0597 (3.2800)	grad_norm 3.2590 (4.0963)	mem 8931MB
[2022-04-08 01:56:32 large] (main.py 226): INFO Train: [166/300][1200/2502]	eta 0:14:09 lr 0.000210	time 0.5041 (0.6524)	loss 2.6369 (3.2829)	grad_norm 4.0041 (4.0978)	mem 8931MB
[2022-04-08 01:57:36 large] (main.py 226): INFO Train: [166/300][1300/2502]	eta 0:13:02 lr 0.000210	time 0.6612 (0.6512)	loss 3.8844 (3.2759)	grad_norm 4.2265 (4.0868)	mem 8931MB
[2022-04-08 01:58:41 large] (main.py 226): INFO Train: [166/300][1400/2502]	eta 0:11:57 lr 0.000210	time 0.6488 (0.6513)	loss 3.5747 (3.2797)	grad_norm 3.5469 (4.0893)	mem 8931MB
[2022-04-08 01:59:47 large] (main.py 226): INFO Train: [166/300][1500/2502]	eta 0:10:52 lr 0.000210	time 0.7071 (0.6514)	loss 3.1206 (3.2854)	grad_norm 3.2905 (4.0880)	mem 8931MB
[2022-04-08 02:00:50 large] (main.py 226): INFO Train: [166/300][1600/2502]	eta 0:09:46 lr 0.000210	time 0.5819 (0.6502)	loss 3.3470 (3.2855)	grad_norm 3.6768 (4.0889)	mem 8931MB
[2022-04-08 02:01:54 large] (main.py 226): INFO Train: [166/300][1700/2502]	eta 0:08:41 lr 0.000209	time 0.7033 (0.6497)	loss 3.0054 (3.2857)	grad_norm 3.9805 (4.0862)	mem 8931MB
[2022-04-08 02:02:58 large] (main.py 226): INFO Train: [166/300][1800/2502]	eta 0:07:35 lr 0.000209	time 0.5833 (0.6491)	loss 2.7399 (3.2869)	grad_norm 4.5636 (4.0878)	mem 8931MB
[2022-04-08 02:04:02 large] (main.py 226): INFO Train: [166/300][1900/2502]	eta 0:06:30 lr 0.000209	time 0.6297 (0.6487)	loss 2.9958 (3.2939)	grad_norm 5.3748 (4.0843)	mem 8931MB
[2022-04-08 02:05:08 large] (main.py 226): INFO Train: [166/300][2000/2502]	eta 0:05:25 lr 0.000209	time 0.6441 (0.6491)	loss 2.7762 (3.2917)	grad_norm 4.0969 (4.0759)	mem 8931MB
[2022-04-08 02:06:12 large] (main.py 226): INFO Train: [166/300][2100/2502]	eta 0:04:20 lr 0.000209	time 0.6284 (0.6488)	loss 3.4962 (3.2915)	grad_norm 4.9374 (4.0738)	mem 8931MB
[2022-04-08 02:07:17 large] (main.py 226): INFO Train: [166/300][2200/2502]	eta 0:03:15 lr 0.000209	time 0.6361 (0.6487)	loss 3.1537 (3.2919)	grad_norm 4.2290 (4.0748)	mem 8931MB
[2022-04-08 02:08:21 large] (main.py 226): INFO Train: [166/300][2300/2502]	eta 0:02:11 lr 0.000209	time 0.6619 (0.6486)	loss 3.6176 (3.2905)	grad_norm 3.9602 (4.0790)	mem 8931MB
[2022-04-08 02:09:27 large] (main.py 226): INFO Train: [166/300][2400/2502]	eta 0:01:06 lr 0.000209	time 0.6859 (0.6490)	loss 2.3075 (3.2887)	grad_norm 3.8396 (4.0777)	mem 8931MB
[2022-04-08 02:10:31 large] (main.py 226): INFO Train: [166/300][2500/2502]	eta 0:00:01 lr 0.000209	time 0.6259 (0.6487)	loss 2.6230 (3.2910)	grad_norm 3.7925 (4.0762)	mem 8931MB
[2022-04-08 02:10:32 large] (main.py 233): INFO EPOCH 166 training takes 0:27:03
[2022-04-08 02:10:38 large] (main.py 273): INFO Test: [0/98]	Time 5.694 (5.694)	Loss 1.1398 (1.1398)	Acc@1 77.734 (77.734)	Acc@5 92.773 (92.773)	Mem 8931MB
[2022-04-08 02:11:04 large] (main.py 279): INFO  * Acc@1 78.278 Acc@5 94.230
[2022-04-08 02:11:04 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 78.3%
[2022-04-08 02:11:04 large] (utils.py 57): INFO output/large/default/ckpt_epoch_166.pth saving......
[2022-04-08 02:11:05 large] (utils.py 59): INFO output/large/default/ckpt_epoch_166.pth saved !!!
[2022-04-08 02:11:05 large] (main.py 148): INFO Max accuracy: 78.28%
[2022-04-08 02:11:12 large] (main.py 226): INFO Train: [167/300][0/2502]	eta 4:51:14 lr 0.000209	time 6.9843 (6.9843)	loss 2.8554 (2.8554)	grad_norm 3.4518 (3.4518)	mem 8931MB
[2022-04-08 02:12:11 large] (main.py 226): INFO Train: [167/300][100/2502]	eta 0:26:14 lr 0.000209	time 0.7418 (0.6554)	loss 3.8057 (3.2036)	grad_norm 3.6699 (4.1109)	mem 8931MB
[2022-04-08 02:13:17 large] (main.py 226): INFO Train: [167/300][200/2502]	eta 0:25:14 lr 0.000208	time 0.6529 (0.6581)	loss 2.8319 (3.2749)	grad_norm 3.9151 (3.9852)	mem 8931MB
[2022-04-08 02:14:23 large] (main.py 226): INFO Train: [167/300][300/2502]	eta 0:24:10 lr 0.000208	time 0.6280 (0.6585)	loss 3.7160 (3.2673)	grad_norm 3.7225 (3.9924)	mem 8931MB
[2022-04-08 02:15:29 large] (main.py 226): INFO Train: [167/300][400/2502]	eta 0:23:00 lr 0.000208	time 0.6658 (0.6568)	loss 3.4976 (3.2627)	grad_norm 3.9834 (3.9946)	mem 8931MB
[2022-04-08 02:16:34 large] (main.py 226): INFO Train: [167/300][500/2502]	eta 0:21:52 lr 0.000208	time 0.6783 (0.6558)	loss 3.2593 (3.2664)	grad_norm 3.7127 (4.0047)	mem 8931MB
[2022-04-08 02:17:38 large] (main.py 226): INFO Train: [167/300][600/2502]	eta 0:20:42 lr 0.000208	time 0.7264 (0.6534)	loss 3.1410 (3.2748)	grad_norm 4.4568 (4.0242)	mem 8931MB
[2022-04-08 02:18:43 large] (main.py 226): INFO Train: [167/300][700/2502]	eta 0:19:37 lr 0.000208	time 0.6289 (0.6534)	loss 2.2021 (3.2689)	grad_norm 3.4215 (4.0274)	mem 8931MB
[2022-04-08 02:19:47 large] (main.py 226): INFO Train: [167/300][800/2502]	eta 0:18:29 lr 0.000208	time 0.6107 (0.6521)	loss 2.3400 (3.2752)	grad_norm 3.5851 (4.0364)	mem 8931MB
[2022-04-08 02:20:53 large] (main.py 226): INFO Train: [167/300][900/2502]	eta 0:17:24 lr 0.000208	time 0.6456 (0.6521)	loss 2.8580 (3.2770)	grad_norm 4.0846 (4.0499)	mem 8931MB
[2022-04-08 02:21:57 large] (main.py 226): INFO Train: [167/300][1000/2502]	eta 0:16:18 lr 0.000208	time 0.6294 (0.6515)	loss 3.8350 (3.2819)	grad_norm 3.4930 (4.0420)	mem 8931MB
[2022-04-08 02:23:03 large] (main.py 226): INFO Train: [167/300][1100/2502]	eta 0:15:13 lr 0.000208	time 0.7349 (0.6517)	loss 2.2554 (3.2873)	grad_norm 3.1146 (4.0598)	mem 8931MB
[2022-04-08 02:24:09 large] (main.py 226): INFO Train: [167/300][1200/2502]	eta 0:14:09 lr 0.000207	time 0.6169 (0.6525)	loss 3.4886 (3.2851)	grad_norm 3.5228 (4.0560)	mem 8931MB
[2022-04-08 02:25:13 large] (main.py 226): INFO Train: [167/300][1300/2502]	eta 0:13:03 lr 0.000207	time 0.5989 (0.6519)	loss 2.2325 (3.2785)	grad_norm 6.5451 (4.0591)	mem 8931MB
[2022-04-08 02:26:18 large] (main.py 226): INFO Train: [167/300][1400/2502]	eta 0:11:58 lr 0.000207	time 0.6406 (0.6517)	loss 3.6434 (3.2752)	grad_norm 4.3519 (4.0694)	mem 8931MB
[2022-04-08 02:27:23 large] (main.py 226): INFO Train: [167/300][1500/2502]	eta 0:10:52 lr 0.000207	time 0.6701 (0.6514)	loss 2.3884 (3.2683)	grad_norm 3.4463 (4.0769)	mem 8931MB
[2022-04-08 02:28:28 large] (main.py 226): INFO Train: [167/300][1600/2502]	eta 0:09:47 lr 0.000207	time 0.6576 (0.6514)	loss 3.3707 (3.2691)	grad_norm 3.7783 (4.0750)	mem 8931MB
[2022-04-08 02:29:33 large] (main.py 226): INFO Train: [167/300][1700/2502]	eta 0:08:42 lr 0.000207	time 0.6355 (0.6513)	loss 3.0522 (3.2684)	grad_norm 4.3267 (4.0709)	mem 8931MB
[2022-04-08 02:30:36 large] (main.py 226): INFO Train: [167/300][1800/2502]	eta 0:07:36 lr 0.000207	time 0.6764 (0.6502)	loss 2.5948 (3.2677)	grad_norm 4.5718 (4.0746)	mem 8931MB
[2022-04-08 02:31:40 large] (main.py 226): INFO Train: [167/300][1900/2502]	eta 0:06:31 lr 0.000207	time 0.6797 (0.6497)	loss 3.0095 (3.2678)	grad_norm 3.6572 (nan)	mem 8931MB
[2022-04-08 02:32:45 large] (main.py 226): INFO Train: [167/300][2000/2502]	eta 0:05:26 lr 0.000207	time 0.6497 (0.6497)	loss 2.8827 (3.2682)	grad_norm 4.7514 (nan)	mem 8931MB
[2022-04-08 02:33:51 large] (main.py 226): INFO Train: [167/300][2100/2502]	eta 0:04:21 lr 0.000207	time 0.7248 (0.6500)	loss 3.3053 (3.2683)	grad_norm 5.0047 (nan)	mem 8931MB
[2022-04-08 02:34:54 large] (main.py 226): INFO Train: [167/300][2200/2502]	eta 0:03:16 lr 0.000206	time 0.6529 (0.6491)	loss 2.7040 (3.2654)	grad_norm 3.2777 (nan)	mem 8931MB
[2022-04-08 02:35:59 large] (main.py 226): INFO Train: [167/300][2300/2502]	eta 0:02:11 lr 0.000206	time 0.6818 (0.6492)	loss 3.1582 (3.2662)	grad_norm 3.9955 (nan)	mem 8931MB
[2022-04-08 02:37:03 large] (main.py 226): INFO Train: [167/300][2400/2502]	eta 0:01:06 lr 0.000206	time 0.6070 (0.6489)	loss 3.3360 (3.2685)	grad_norm 3.0409 (nan)	mem 8931MB
[2022-04-08 02:38:08 large] (main.py 226): INFO Train: [167/300][2500/2502]	eta 0:00:01 lr 0.000206	time 0.5861 (0.6489)	loss 2.4374 (3.2698)	grad_norm 4.2593 (nan)	mem 8931MB
[2022-04-08 02:38:09 large] (main.py 233): INFO EPOCH 167 training takes 0:27:03
[2022-04-08 02:38:15 large] (main.py 273): INFO Test: [0/98]	Time 6.337 (6.337)	Loss 1.0558 (1.0558)	Acc@1 78.516 (78.516)	Acc@5 94.727 (94.727)	Mem 8931MB
[2022-04-08 02:38:41 large] (main.py 279): INFO  * Acc@1 78.186 Acc@5 94.316
[2022-04-08 02:38:41 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 78.2%
[2022-04-08 02:38:41 large] (main.py 148): INFO Max accuracy: 78.28%
[2022-04-08 02:38:48 large] (main.py 226): INFO Train: [168/300][0/2502]	eta 4:40:10 lr 0.000206	time 6.7187 (6.7187)	loss 3.4546 (3.4546)	grad_norm 4.5679 (4.5679)	mem 8931MB
[2022-04-08 02:39:44 large] (main.py 226): INFO Train: [168/300][100/2502]	eta 0:24:44 lr 0.000206	time 0.6816 (0.6182)	loss 3.4998 (3.2871)	grad_norm 4.9706 (4.1256)	mem 8931MB
[2022-04-08 02:40:47 large] (main.py 226): INFO Train: [168/300][200/2502]	eta 0:24:04 lr 0.000206	time 0.5952 (0.6275)	loss 3.6613 (3.2870)	grad_norm 4.0744 (4.0809)	mem 8931MB
[2022-04-08 02:41:52 large] (main.py 226): INFO Train: [168/300][300/2502]	eta 0:23:17 lr 0.000206	time 0.6396 (0.6345)	loss 3.6644 (3.3106)	grad_norm 3.5471 (4.1055)	mem 8931MB
[2022-04-08 02:42:57 large] (main.py 226): INFO Train: [168/300][400/2502]	eta 0:22:20 lr 0.000206	time 0.6476 (0.6377)	loss 3.2365 (3.2942)	grad_norm 4.3822 (4.0871)	mem 8931MB
[2022-04-08 02:44:02 large] (main.py 226): INFO Train: [168/300][500/2502]	eta 0:21:22 lr 0.000206	time 0.6449 (0.6408)	loss 3.2766 (3.2870)	grad_norm 3.6259 (4.0872)	mem 8931MB
[2022-04-08 02:45:07 large] (main.py 226): INFO Train: [168/300][600/2502]	eta 0:20:21 lr 0.000206	time 0.6265 (0.6421)	loss 3.5363 (3.2849)	grad_norm 3.0548 (4.0928)	mem 8931MB
[2022-04-08 02:46:12 large] (main.py 226): INFO Train: [168/300][700/2502]	eta 0:19:18 lr 0.000205	time 0.6625 (0.6427)	loss 2.8087 (3.2868)	grad_norm 4.8379 (4.0878)	mem 8931MB
[2022-04-08 02:47:15 large] (main.py 226): INFO Train: [168/300][800/2502]	eta 0:18:12 lr 0.000205	time 0.6416 (0.6418)	loss 3.5203 (3.2801)	grad_norm 4.3969 (4.0978)	mem 8931MB
[2022-04-08 02:48:19 large] (main.py 226): INFO Train: [168/300][900/2502]	eta 0:17:07 lr 0.000205	time 0.6170 (0.6414)	loss 2.6302 (3.2762)	grad_norm 3.9040 (4.1039)	mem 8931MB
[2022-04-08 02:49:22 large] (main.py 226): INFO Train: [168/300][1000/2502]	eta 0:16:01 lr 0.000205	time 0.6545 (0.6403)	loss 3.5429 (3.2817)	grad_norm 3.7112 (4.1146)	mem 8931MB
[2022-04-08 02:50:26 large] (main.py 226): INFO Train: [168/300][1100/2502]	eta 0:14:57 lr 0.000205	time 0.6255 (0.6399)	loss 3.1378 (3.2770)	grad_norm 3.8993 (4.1274)	mem 8931MB
[2022-04-08 02:51:30 large] (main.py 226): INFO Train: [168/300][1200/2502]	eta 0:13:53 lr 0.000205	time 0.7481 (0.6404)	loss 3.5631 (3.2879)	grad_norm 4.0009 (4.1477)	mem 8931MB
[2022-04-08 02:52:34 large] (main.py 226): INFO Train: [168/300][1300/2502]	eta 0:12:49 lr 0.000205	time 0.6013 (0.6400)	loss 3.3091 (3.2866)	grad_norm 3.1172 (4.1455)	mem 8931MB
[2022-04-08 02:53:38 large] (main.py 226): INFO Train: [168/300][1400/2502]	eta 0:11:45 lr 0.000205	time 0.5821 (0.6404)	loss 3.0258 (3.2966)	grad_norm 3.8195 (4.1497)	mem 8931MB
[2022-04-08 02:54:42 large] (main.py 226): INFO Train: [168/300][1500/2502]	eta 0:10:41 lr 0.000205	time 0.6043 (0.6402)	loss 3.0133 (3.2987)	grad_norm 3.1323 (4.1477)	mem 8931MB
[2022-04-08 02:55:47 large] (main.py 226): INFO Train: [168/300][1600/2502]	eta 0:09:37 lr 0.000204	time 0.7407 (0.6407)	loss 3.3404 (3.2991)	grad_norm 3.8016 (4.1540)	mem 8931MB
[2022-04-08 02:56:52 large] (main.py 226): INFO Train: [168/300][1700/2502]	eta 0:08:34 lr 0.000204	time 0.6983 (0.6410)	loss 3.5970 (3.2961)	grad_norm 4.8324 (4.1514)	mem 8931MB
[2022-04-08 02:57:56 large] (main.py 226): INFO Train: [168/300][1800/2502]	eta 0:07:30 lr 0.000204	time 0.7188 (0.6410)	loss 2.6638 (3.2910)	grad_norm 3.3395 (4.1461)	mem 8931MB
[2022-04-08 02:59:01 large] (main.py 226): INFO Train: [168/300][1900/2502]	eta 0:06:26 lr 0.000204	time 0.6276 (0.6414)	loss 3.7132 (3.2932)	grad_norm 3.9453 (4.1551)	mem 8931MB
[2022-04-08 03:00:06 large] (main.py 226): INFO Train: [168/300][2000/2502]	eta 0:05:22 lr 0.000204	time 0.6715 (0.6419)	loss 2.5983 (3.2896)	grad_norm 3.1405 (4.1638)	mem 8931MB
[2022-04-08 03:01:10 large] (main.py 226): INFO Train: [168/300][2100/2502]	eta 0:04:18 lr 0.000204	time 0.6502 (0.6421)	loss 2.4622 (3.2847)	grad_norm 3.4959 (4.1606)	mem 8931MB
[2022-04-08 03:02:14 large] (main.py 226): INFO Train: [168/300][2200/2502]	eta 0:03:13 lr 0.000204	time 0.6546 (0.6421)	loss 2.3870 (3.2864)	grad_norm 4.1113 (4.1569)	mem 8931MB
[2022-04-08 03:03:20 large] (main.py 226): INFO Train: [168/300][2300/2502]	eta 0:02:09 lr 0.000204	time 0.6405 (0.6426)	loss 3.7257 (3.2885)	grad_norm 4.9884 (4.1538)	mem 8931MB
[2022-04-08 03:04:24 large] (main.py 226): INFO Train: [168/300][2400/2502]	eta 0:01:05 lr 0.000204	time 0.5761 (0.6424)	loss 3.0680 (3.2859)	grad_norm 4.0819 (4.1502)	mem 8931MB
[2022-04-08 03:05:27 large] (main.py 226): INFO Train: [168/300][2500/2502]	eta 0:00:01 lr 0.000204	time 0.6266 (0.6421)	loss 3.4918 (3.2862)	grad_norm 5.3233 (4.1489)	mem 8931MB
[2022-04-08 03:05:28 large] (main.py 233): INFO EPOCH 168 training takes 0:26:47
[2022-04-08 03:05:35 large] (main.py 273): INFO Test: [0/98]	Time 6.385 (6.385)	Loss 1.1219 (1.1219)	Acc@1 76.562 (76.562)	Acc@5 92.969 (92.969)	Mem 8931MB
[2022-04-08 03:06:00 large] (main.py 279): INFO  * Acc@1 78.124 Acc@5 94.192
[2022-04-08 03:06:00 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 78.1%
[2022-04-08 03:06:00 large] (main.py 148): INFO Max accuracy: 78.28%
[2022-04-08 03:06:08 large] (main.py 226): INFO Train: [169/300][0/2502]	eta 4:54:15 lr 0.000204	time 7.0564 (7.0564)	loss 3.4270 (3.4270)	grad_norm 4.8600 (4.8600)	mem 8931MB
[2022-04-08 03:06:57 large] (main.py 226): INFO Train: [169/300][100/2502]	eta 0:22:30 lr 0.000203	time 0.4551 (0.5624)	loss 2.5069 (3.2302)	grad_norm 4.0065 (4.2194)	mem 8931MB
[2022-04-08 03:07:58 large] (main.py 226): INFO Train: [169/300][200/2502]	eta 0:22:23 lr 0.000203	time 0.6937 (0.5836)	loss 3.5223 (3.2533)	grad_norm 4.1962 (4.1148)	mem 8931MB
[2022-04-08 03:09:05 large] (main.py 226): INFO Train: [169/300][300/2502]	eta 0:22:32 lr 0.000203	time 0.6644 (0.6141)	loss 2.8451 (3.2561)	grad_norm 4.0311 (4.1043)	mem 8931MB
[2022-04-08 03:10:09 large] (main.py 226): INFO Train: [169/300][400/2502]	eta 0:21:44 lr 0.000203	time 0.6554 (0.6205)	loss 3.8163 (3.2677)	grad_norm 5.0311 (4.1111)	mem 8931MB
[2022-04-08 03:11:15 large] (main.py 226): INFO Train: [169/300][500/2502]	eta 0:20:57 lr 0.000203	time 0.7046 (0.6280)	loss 3.7120 (3.2661)	grad_norm 4.6368 (4.1712)	mem 8931MB
[2022-04-08 03:12:20 large] (main.py 226): INFO Train: [169/300][600/2502]	eta 0:20:00 lr 0.000203	time 0.6270 (0.6310)	loss 3.0688 (3.2636)	grad_norm 3.7770 (4.1635)	mem 8931MB
[2022-04-08 03:13:25 large] (main.py 226): INFO Train: [169/300][700/2502]	eta 0:19:01 lr 0.000203	time 0.6460 (0.6336)	loss 3.9324 (3.2694)	grad_norm 4.0725 (4.1412)	mem 8931MB
[2022-04-08 03:14:30 large] (main.py 226): INFO Train: [169/300][800/2502]	eta 0:18:02 lr 0.000203	time 0.6924 (0.6360)	loss 3.4776 (3.2636)	grad_norm 4.2327 (4.1359)	mem 8931MB
[2022-04-08 03:15:35 large] (main.py 226): INFO Train: [169/300][900/2502]	eta 0:17:00 lr 0.000203	time 0.6112 (0.6371)	loss 2.6637 (3.2616)	grad_norm 3.9389 (4.1356)	mem 8931MB
[2022-04-08 03:16:40 large] (main.py 226): INFO Train: [169/300][1000/2502]	eta 0:15:59 lr 0.000203	time 0.4996 (0.6385)	loss 3.6132 (3.2522)	grad_norm 5.1310 (4.1386)	mem 8931MB
[2022-04-08 03:17:44 large] (main.py 226): INFO Train: [169/300][1100/2502]	eta 0:14:56 lr 0.000202	time 0.6063 (0.6391)	loss 3.6780 (3.2481)	grad_norm 3.7564 (4.1390)	mem 8931MB
[2022-04-08 03:18:48 large] (main.py 226): INFO Train: [169/300][1200/2502]	eta 0:13:52 lr 0.000202	time 0.6717 (0.6391)	loss 3.3054 (3.2585)	grad_norm 4.9261 (4.1427)	mem 8931MB
[2022-04-08 03:19:53 large] (main.py 226): INFO Train: [169/300][1300/2502]	eta 0:12:48 lr 0.000202	time 0.6150 (0.6396)	loss 3.5106 (3.2562)	grad_norm 4.6282 (4.1489)	mem 8931MB
[2022-04-08 03:20:57 large] (main.py 226): INFO Train: [169/300][1400/2502]	eta 0:11:44 lr 0.000202	time 0.6048 (0.6396)	loss 3.1486 (3.2665)	grad_norm 3.9728 (4.1615)	mem 8931MB
[2022-04-08 03:22:00 large] (main.py 226): INFO Train: [169/300][1500/2502]	eta 0:10:40 lr 0.000202	time 0.4906 (0.6393)	loss 3.9849 (3.2693)	grad_norm 5.1916 (4.1667)	mem 8931MB
[2022-04-08 03:22:59 large] (main.py 226): INFO Train: [169/300][1600/2502]	eta 0:09:33 lr 0.000202	time 0.7108 (0.6361)	loss 3.3399 (3.2742)	grad_norm 4.1572 (4.1647)	mem 8931MB
[2022-04-08 03:24:04 large] (main.py 226): INFO Train: [169/300][1700/2502]	eta 0:08:30 lr 0.000202	time 0.5739 (0.6371)	loss 3.6459 (3.2752)	grad_norm 4.3188 (4.1615)	mem 8931MB
[2022-04-08 03:25:10 large] (main.py 226): INFO Train: [169/300][1800/2502]	eta 0:07:28 lr 0.000202	time 0.5002 (0.6382)	loss 3.2012 (3.2719)	grad_norm 3.1676 (4.1654)	mem 8931MB
[2022-04-08 03:26:15 large] (main.py 226): INFO Train: [169/300][1900/2502]	eta 0:06:24 lr 0.000202	time 0.6849 (0.6388)	loss 3.1663 (3.2738)	grad_norm 4.4681 (4.1764)	mem 8931MB
[2022-04-08 03:27:20 large] (main.py 226): INFO Train: [169/300][2000/2502]	eta 0:05:20 lr 0.000202	time 0.6018 (0.6393)	loss 3.7151 (3.2774)	grad_norm 3.2191 (4.1775)	mem 8931MB
[2022-04-08 03:28:24 large] (main.py 226): INFO Train: [169/300][2100/2502]	eta 0:04:17 lr 0.000201	time 0.5770 (0.6394)	loss 3.2849 (3.2790)	grad_norm 4.1757 (nan)	mem 8931MB
[2022-04-08 03:29:29 large] (main.py 226): INFO Train: [169/300][2200/2502]	eta 0:03:13 lr 0.000201	time 0.5558 (0.6400)	loss 2.5381 (3.2795)	grad_norm 4.0631 (nan)	mem 8931MB
[2022-04-08 03:30:33 large] (main.py 226): INFO Train: [169/300][2300/2502]	eta 0:02:09 lr 0.000201	time 0.6471 (0.6399)	loss 3.4899 (3.2785)	grad_norm 4.2385 (nan)	mem 8931MB
[2022-04-08 03:31:37 large] (main.py 226): INFO Train: [169/300][2400/2502]	eta 0:01:05 lr 0.000201	time 0.6350 (0.6401)	loss 2.3773 (3.2802)	grad_norm 5.6456 (nan)	mem 8931MB
[2022-04-08 03:32:41 large] (main.py 226): INFO Train: [169/300][2500/2502]	eta 0:00:01 lr 0.000201	time 0.6139 (0.6401)	loss 2.8902 (3.2826)	grad_norm 3.9973 (nan)	mem 8931MB
[2022-04-08 03:32:43 large] (main.py 233): INFO EPOCH 169 training takes 0:26:42
[2022-04-08 03:32:49 large] (main.py 273): INFO Test: [0/98]	Time 6.623 (6.623)	Loss 1.1322 (1.1322)	Acc@1 76.367 (76.367)	Acc@5 93.750 (93.750)	Mem 8931MB
[2022-04-08 03:33:15 large] (main.py 279): INFO  * Acc@1 78.084 Acc@5 94.176
[2022-04-08 03:33:15 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 78.1%
[2022-04-08 03:33:15 large] (main.py 148): INFO Max accuracy: 78.28%
[2022-04-08 03:33:22 large] (main.py 226): INFO Train: [170/300][0/2502]	eta 4:47:16 lr 0.000201	time 6.8891 (6.8891)	loss 2.9235 (2.9235)	grad_norm 5.7263 (5.7263)	mem 8931MB
[2022-04-08 03:34:19 large] (main.py 226): INFO Train: [170/300][100/2502]	eta 0:25:29 lr 0.000201	time 0.6802 (0.6369)	loss 3.3046 (3.2916)	grad_norm 4.0481 (4.2268)	mem 8931MB
[2022-04-08 03:35:24 large] (main.py 226): INFO Train: [170/300][200/2502]	eta 0:24:45 lr 0.000201	time 0.6564 (0.6455)	loss 2.3395 (3.2932)	grad_norm 4.1019 (4.2041)	mem 8931MB
[2022-04-08 03:36:28 large] (main.py 226): INFO Train: [170/300][300/2502]	eta 0:23:35 lr 0.000201	time 0.6264 (0.6428)	loss 3.8450 (3.2531)	grad_norm 3.9399 (4.1943)	mem 8931MB
[2022-04-08 03:37:34 large] (main.py 226): INFO Train: [170/300][400/2502]	eta 0:22:40 lr 0.000201	time 0.5250 (0.6471)	loss 2.5367 (3.2453)	grad_norm 3.9774 (4.2209)	mem 8931MB
[2022-04-08 03:38:38 large] (main.py 226): INFO Train: [170/300][500/2502]	eta 0:21:31 lr 0.000201	time 0.5976 (0.6449)	loss 3.5908 (3.2624)	grad_norm 3.7458 (4.1984)	mem 8931MB
[2022-04-08 03:39:42 large] (main.py 226): INFO Train: [170/300][600/2502]	eta 0:20:26 lr 0.000200	time 0.7133 (0.6449)	loss 2.8891 (3.2571)	grad_norm 4.2653 (4.2119)	mem 8931MB
[2022-04-08 03:40:47 large] (main.py 226): INFO Train: [170/300][700/2502]	eta 0:19:22 lr 0.000200	time 0.5980 (0.6453)	loss 3.5838 (3.2567)	grad_norm 4.2460 (4.1958)	mem 8931MB
[2022-04-08 03:41:52 large] (main.py 226): INFO Train: [170/300][800/2502]	eta 0:18:19 lr 0.000200	time 0.5992 (0.6457)	loss 3.7277 (3.2525)	grad_norm 4.0224 (4.2073)	mem 8931MB
[2022-04-08 03:42:56 large] (main.py 226): INFO Train: [170/300][900/2502]	eta 0:17:13 lr 0.000200	time 0.6252 (0.6450)	loss 3.0703 (3.2488)	grad_norm 4.7310 (4.2028)	mem 8931MB
[2022-04-08 03:44:00 large] (main.py 226): INFO Train: [170/300][1000/2502]	eta 0:16:08 lr 0.000200	time 0.7907 (0.6448)	loss 3.2556 (3.2522)	grad_norm 4.4287 (4.2069)	mem 8931MB
[2022-04-08 03:45:05 large] (main.py 226): INFO Train: [170/300][1100/2502]	eta 0:15:04 lr 0.000200	time 0.6648 (0.6453)	loss 3.5981 (3.2554)	grad_norm 4.6463 (nan)	mem 8931MB
[2022-04-08 03:46:11 large] (main.py 226): INFO Train: [170/300][1200/2502]	eta 0:14:01 lr 0.000200	time 0.6065 (0.6460)	loss 3.7228 (3.2603)	grad_norm 3.8257 (nan)	mem 8931MB
[2022-04-08 03:47:15 large] (main.py 226): INFO Train: [170/300][1300/2502]	eta 0:12:56 lr 0.000200	time 0.6002 (0.6458)	loss 3.1886 (3.2671)	grad_norm 4.0285 (nan)	mem 8931MB
[2022-04-08 03:48:20 large] (main.py 226): INFO Train: [170/300][1400/2502]	eta 0:11:51 lr 0.000200	time 0.6184 (0.6459)	loss 3.7201 (3.2624)	grad_norm 5.1372 (nan)	mem 8931MB
[2022-04-08 03:49:25 large] (main.py 226): INFO Train: [170/300][1500/2502]	eta 0:10:47 lr 0.000200	time 0.6376 (0.6463)	loss 1.7512 (3.2580)	grad_norm 4.0198 (nan)	mem 8931MB
[2022-04-08 03:50:30 large] (main.py 226): INFO Train: [170/300][1600/2502]	eta 0:09:43 lr 0.000199	time 0.6432 (0.6466)	loss 3.7548 (3.2620)	grad_norm 3.3133 (nan)	mem 8931MB
[2022-04-08 03:51:35 large] (main.py 226): INFO Train: [170/300][1700/2502]	eta 0:08:38 lr 0.000199	time 0.5641 (0.6470)	loss 3.6033 (3.2637)	grad_norm 3.3721 (nan)	mem 8931MB
[2022-04-08 03:52:40 large] (main.py 226): INFO Train: [170/300][1800/2502]	eta 0:07:34 lr 0.000199	time 0.7207 (0.6469)	loss 3.8005 (3.2640)	grad_norm 3.9217 (nan)	mem 8931MB
[2022-04-08 03:53:45 large] (main.py 226): INFO Train: [170/300][1900/2502]	eta 0:06:29 lr 0.000199	time 0.7139 (0.6472)	loss 4.0494 (3.2659)	grad_norm 5.0251 (nan)	mem 8931MB
[2022-04-08 03:54:49 large] (main.py 226): INFO Train: [170/300][2000/2502]	eta 0:05:24 lr 0.000199	time 0.6161 (0.6470)	loss 3.8198 (3.2684)	grad_norm 3.6490 (nan)	mem 8931MB
[2022-04-08 03:55:54 large] (main.py 226): INFO Train: [170/300][2100/2502]	eta 0:04:19 lr 0.000199	time 0.6510 (0.6468)	loss 3.5500 (3.2658)	grad_norm 4.1416 (nan)	mem 8931MB
[2022-04-08 03:56:58 large] (main.py 226): INFO Train: [170/300][2200/2502]	eta 0:03:15 lr 0.000199	time 0.6921 (0.6466)	loss 3.9801 (3.2662)	grad_norm 5.1867 (nan)	mem 8931MB
[2022-04-08 03:58:01 large] (main.py 226): INFO Train: [170/300][2300/2502]	eta 0:02:10 lr 0.000199	time 0.5426 (0.6460)	loss 3.0703 (3.2638)	grad_norm 5.0239 (nan)	mem 8931MB
[2022-04-08 03:59:06 large] (main.py 226): INFO Train: [170/300][2400/2502]	eta 0:01:05 lr 0.000199	time 0.7449 (0.6461)	loss 3.4942 (3.2656)	grad_norm 4.1585 (nan)	mem 8931MB
[2022-04-08 04:00:10 large] (main.py 226): INFO Train: [170/300][2500/2502]	eta 0:00:01 lr 0.000199	time 0.6476 (0.6458)	loss 2.8409 (3.2678)	grad_norm 4.2302 (nan)	mem 8931MB
[2022-04-08 04:00:11 large] (main.py 233): INFO EPOCH 170 training takes 0:26:56
[2022-04-08 04:00:17 large] (main.py 273): INFO Test: [0/98]	Time 6.061 (6.061)	Loss 1.0621 (1.0621)	Acc@1 78.711 (78.711)	Acc@5 93.750 (93.750)	Mem 8931MB
[2022-04-08 04:00:43 large] (main.py 279): INFO  * Acc@1 78.404 Acc@5 94.292
[2022-04-08 04:00:43 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 78.4%
[2022-04-08 04:00:43 large] (utils.py 57): INFO output/large/default/ckpt_epoch_170.pth saving......
[2022-04-08 04:00:44 large] (utils.py 59): INFO output/large/default/ckpt_epoch_170.pth saved !!!
[2022-04-08 04:00:44 large] (main.py 148): INFO Max accuracy: 78.40%
[2022-04-08 04:00:52 large] (main.py 226): INFO Train: [171/300][0/2502]	eta 5:35:05 lr 0.000199	time 8.0360 (8.0360)	loss 3.3124 (3.3124)	grad_norm 3.6702 (3.6702)	mem 8931MB
[2022-04-08 04:01:50 large] (main.py 226): INFO Train: [171/300][100/2502]	eta 0:26:17 lr 0.000198	time 0.6076 (0.6567)	loss 3.7386 (3.2924)	grad_norm 3.9720 (4.3009)	mem 8931MB
[2022-04-08 04:02:54 large] (main.py 226): INFO Train: [171/300][200/2502]	eta 0:24:49 lr 0.000198	time 0.6383 (0.6472)	loss 3.4530 (3.2670)	grad_norm 3.8294 (4.2379)	mem 8931MB
[2022-04-08 04:03:59 large] (main.py 226): INFO Train: [171/300][300/2502]	eta 0:23:47 lr 0.000198	time 0.7170 (0.6483)	loss 4.0602 (3.2865)	grad_norm 4.9300 (4.2799)	mem 8931MB
[2022-04-08 04:05:04 large] (main.py 226): INFO Train: [171/300][400/2502]	eta 0:22:41 lr 0.000198	time 0.6457 (0.6478)	loss 3.6415 (3.2713)	grad_norm 4.1365 (4.2527)	mem 8931MB
[2022-04-08 04:06:08 large] (main.py 226): INFO Train: [171/300][500/2502]	eta 0:21:36 lr 0.000198	time 0.6119 (0.6476)	loss 2.0570 (3.2536)	grad_norm 4.1405 (4.2831)	mem 8931MB
[2022-04-08 04:07:13 large] (main.py 226): INFO Train: [171/300][600/2502]	eta 0:20:29 lr 0.000198	time 0.7106 (0.6466)	loss 3.6230 (3.2719)	grad_norm 5.1108 (4.2710)	mem 8931MB
[2022-04-08 04:08:18 large] (main.py 226): INFO Train: [171/300][700/2502]	eta 0:19:26 lr 0.000198	time 0.5974 (0.6471)	loss 2.5841 (3.2632)	grad_norm 3.9635 (4.2494)	mem 8931MB
[2022-04-08 04:09:23 large] (main.py 226): INFO Train: [171/300][800/2502]	eta 0:18:23 lr 0.000198	time 0.6892 (0.6481)	loss 2.8312 (3.2639)	grad_norm 4.7935 (4.2868)	mem 8931MB
[2022-04-08 04:10:26 large] (main.py 226): INFO Train: [171/300][900/2502]	eta 0:17:15 lr 0.000198	time 0.6255 (0.6463)	loss 3.2480 (3.2656)	grad_norm 5.2105 (4.2846)	mem 8931MB
[2022-04-08 04:11:31 large] (main.py 226): INFO Train: [171/300][1000/2502]	eta 0:16:10 lr 0.000197	time 0.6060 (0.6465)	loss 3.1804 (3.2608)	grad_norm 3.6112 (4.2962)	mem 8931MB
[2022-04-08 04:12:35 large] (main.py 226): INFO Train: [171/300][1100/2502]	eta 0:15:05 lr 0.000197	time 0.6382 (0.6459)	loss 4.0473 (3.2620)	grad_norm 4.4510 (4.3057)	mem 8931MB
[2022-04-08 04:13:38 large] (main.py 226): INFO Train: [171/300][1200/2502]	eta 0:13:59 lr 0.000197	time 0.4706 (0.6444)	loss 3.5717 (3.2638)	grad_norm 4.0297 (4.2991)	mem 8931MB
[2022-04-08 04:14:42 large] (main.py 226): INFO Train: [171/300][1300/2502]	eta 0:12:54 lr 0.000197	time 0.6042 (0.6440)	loss 3.5671 (3.2586)	grad_norm 4.1044 (4.2942)	mem 8931MB
[2022-04-08 04:15:46 large] (main.py 226): INFO Train: [171/300][1400/2502]	eta 0:11:49 lr 0.000197	time 0.6267 (0.6439)	loss 2.5096 (3.2519)	grad_norm 4.3707 (4.3043)	mem 8931MB
[2022-04-08 04:16:50 large] (main.py 226): INFO Train: [171/300][1500/2502]	eta 0:10:44 lr 0.000197	time 0.6766 (0.6437)	loss 3.4321 (3.2541)	grad_norm 3.5912 (4.3107)	mem 8931MB
[2022-04-08 04:17:54 large] (main.py 226): INFO Train: [171/300][1600/2502]	eta 0:09:40 lr 0.000197	time 0.6192 (0.6437)	loss 2.7442 (3.2510)	grad_norm 4.6217 (4.3083)	mem 8931MB
[2022-04-08 04:18:58 large] (main.py 226): INFO Train: [171/300][1700/2502]	eta 0:08:36 lr 0.000197	time 0.6641 (0.6434)	loss 3.4007 (3.2509)	grad_norm 4.5831 (4.3120)	mem 8931MB
[2022-04-08 04:20:03 large] (main.py 226): INFO Train: [171/300][1800/2502]	eta 0:07:31 lr 0.000197	time 0.6166 (0.6435)	loss 3.4594 (3.2524)	grad_norm 3.5383 (4.3077)	mem 8931MB
[2022-04-08 04:21:07 large] (main.py 226): INFO Train: [171/300][1900/2502]	eta 0:06:27 lr 0.000197	time 0.6141 (0.6436)	loss 3.4401 (3.2518)	grad_norm 3.6708 (4.2984)	mem 8931MB
[2022-04-08 04:22:11 large] (main.py 226): INFO Train: [171/300][2000/2502]	eta 0:05:22 lr 0.000196	time 0.6154 (0.6434)	loss 3.2354 (3.2564)	grad_norm 3.7081 (4.2985)	mem 8931MB
[2022-04-08 04:23:14 large] (main.py 226): INFO Train: [171/300][2100/2502]	eta 0:04:18 lr 0.000196	time 0.6834 (0.6427)	loss 2.5830 (3.2584)	grad_norm 4.0733 (4.2928)	mem 8931MB
[2022-04-08 04:24:18 large] (main.py 226): INFO Train: [171/300][2200/2502]	eta 0:03:14 lr 0.000196	time 0.6746 (0.6427)	loss 3.7976 (3.2561)	grad_norm 4.2088 (4.2972)	mem 8931MB
[2022-04-08 04:25:22 large] (main.py 226): INFO Train: [171/300][2300/2502]	eta 0:02:09 lr 0.000196	time 0.5932 (0.6423)	loss 2.7045 (3.2586)	grad_norm 3.0602 (4.2864)	mem 8931MB
[2022-04-08 04:26:26 large] (main.py 226): INFO Train: [171/300][2400/2502]	eta 0:01:05 lr 0.000196	time 0.6924 (0.6423)	loss 3.9423 (3.2580)	grad_norm 3.7946 (4.2863)	mem 8931MB
[2022-04-08 04:27:29 large] (main.py 226): INFO Train: [171/300][2500/2502]	eta 0:00:01 lr 0.000196	time 0.5817 (0.6418)	loss 2.4921 (3.2626)	grad_norm 3.5208 (4.2845)	mem 8931MB
[2022-04-08 04:27:30 large] (main.py 233): INFO EPOCH 171 training takes 0:26:46
[2022-04-08 04:27:37 large] (main.py 273): INFO Test: [0/98]	Time 6.841 (6.841)	Loss 1.1063 (1.1063)	Acc@1 75.977 (75.977)	Acc@5 94.922 (94.922)	Mem 8931MB
[2022-04-08 04:28:02 large] (main.py 279): INFO  * Acc@1 78.384 Acc@5 94.364
[2022-04-08 04:28:02 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 78.4%
[2022-04-08 04:28:02 large] (main.py 148): INFO Max accuracy: 78.40%
[2022-04-08 04:28:09 large] (main.py 226): INFO Train: [172/300][0/2502]	eta 4:18:29 lr 0.000196	time 6.1990 (6.1990)	loss 3.3820 (3.3820)	grad_norm 3.7922 (3.7922)	mem 8931MB
[2022-04-08 04:29:06 large] (main.py 226): INFO Train: [172/300][100/2502]	eta 0:25:02 lr 0.000196	time 0.6170 (0.6256)	loss 2.6813 (3.2431)	grad_norm 3.7031 (4.1912)	mem 8931MB
[2022-04-08 04:30:10 large] (main.py 226): INFO Train: [172/300][200/2502]	eta 0:24:26 lr 0.000196	time 0.6687 (0.6371)	loss 4.3745 (3.2415)	grad_norm 3.5144 (4.2767)	mem 8931MB
[2022-04-08 04:31:16 large] (main.py 226): INFO Train: [172/300][300/2502]	eta 0:23:39 lr 0.000196	time 0.6697 (0.6448)	loss 3.2804 (3.2329)	grad_norm 4.5446 (4.2444)	mem 8931MB
[2022-04-08 04:32:21 large] (main.py 226): INFO Train: [172/300][400/2502]	eta 0:22:36 lr 0.000196	time 0.6013 (0.6454)	loss 3.1498 (3.2408)	grad_norm 6.0584 (nan)	mem 8931MB
[2022-04-08 04:33:26 large] (main.py 226): INFO Train: [172/300][500/2502]	eta 0:21:33 lr 0.000195	time 0.6861 (0.6461)	loss 3.5210 (3.2451)	grad_norm 4.8791 (nan)	mem 8931MB
[2022-04-08 04:34:30 large] (main.py 226): INFO Train: [172/300][600/2502]	eta 0:20:28 lr 0.000195	time 0.5993 (0.6456)	loss 2.7641 (3.2466)	grad_norm 3.3264 (nan)	mem 8931MB
[2022-04-08 04:35:34 large] (main.py 226): INFO Train: [172/300][700/2502]	eta 0:19:22 lr 0.000195	time 0.6341 (0.6450)	loss 3.4064 (3.2515)	grad_norm 4.2540 (nan)	mem 8931MB
[2022-04-08 04:36:39 large] (main.py 226): INFO Train: [172/300][800/2502]	eta 0:18:18 lr 0.000195	time 0.5399 (0.6454)	loss 3.6579 (3.2531)	grad_norm 3.6324 (nan)	mem 8931MB
[2022-04-08 04:37:43 large] (main.py 226): INFO Train: [172/300][900/2502]	eta 0:17:13 lr 0.000195	time 0.6739 (0.6450)	loss 3.5341 (3.2511)	grad_norm 3.9897 (nan)	mem 8931MB
[2022-04-08 04:38:48 large] (main.py 226): INFO Train: [172/300][1000/2502]	eta 0:16:08 lr 0.000195	time 0.7231 (0.6446)	loss 3.8561 (3.2488)	grad_norm 4.6268 (nan)	mem 8931MB
[2022-04-08 04:39:51 large] (main.py 226): INFO Train: [172/300][1100/2502]	eta 0:15:02 lr 0.000195	time 0.5816 (0.6439)	loss 3.7204 (3.2520)	grad_norm 4.7854 (nan)	mem 8931MB
[2022-04-08 04:40:55 large] (main.py 226): INFO Train: [172/300][1200/2502]	eta 0:13:57 lr 0.000195	time 0.6687 (0.6434)	loss 2.6112 (3.2523)	grad_norm 4.7613 (nan)	mem 8931MB
[2022-04-08 04:41:58 large] (main.py 226): INFO Train: [172/300][1300/2502]	eta 0:12:52 lr 0.000195	time 0.6848 (0.6427)	loss 3.1052 (3.2553)	grad_norm 4.4247 (nan)	mem 8931MB
[2022-04-08 04:43:03 large] (main.py 226): INFO Train: [172/300][1400/2502]	eta 0:11:48 lr 0.000195	time 0.6703 (0.6432)	loss 2.5469 (3.2491)	grad_norm 4.4880 (nan)	mem 8931MB
[2022-04-08 04:44:06 large] (main.py 226): INFO Train: [172/300][1500/2502]	eta 0:10:43 lr 0.000194	time 0.4772 (0.6423)	loss 2.3536 (3.2532)	grad_norm 4.4005 (nan)	mem 8931MB
[2022-04-08 04:45:04 large] (main.py 226): INFO Train: [172/300][1600/2502]	eta 0:09:35 lr 0.000194	time 0.7224 (0.6383)	loss 3.5716 (3.2540)	grad_norm 3.1592 (nan)	mem 8931MB
[2022-04-08 04:46:08 large] (main.py 226): INFO Train: [172/300][1700/2502]	eta 0:08:32 lr 0.000194	time 0.5748 (0.6384)	loss 3.9557 (3.2606)	grad_norm 4.2623 (nan)	mem 8931MB
[2022-04-08 04:47:12 large] (main.py 226): INFO Train: [172/300][1800/2502]	eta 0:07:28 lr 0.000194	time 0.7394 (0.6384)	loss 3.4405 (3.2564)	grad_norm 4.6436 (nan)	mem 8931MB
[2022-04-08 04:48:17 large] (main.py 226): INFO Train: [172/300][1900/2502]	eta 0:06:24 lr 0.000194	time 0.6229 (0.6388)	loss 2.9911 (3.2601)	grad_norm 4.1341 (nan)	mem 8931MB
[2022-04-08 04:49:21 large] (main.py 226): INFO Train: [172/300][2000/2502]	eta 0:05:20 lr 0.000194	time 0.6347 (0.6391)	loss 3.4777 (3.2597)	grad_norm 3.2027 (nan)	mem 8931MB
[2022-04-08 04:50:26 large] (main.py 226): INFO Train: [172/300][2100/2502]	eta 0:04:17 lr 0.000194	time 0.6783 (0.6395)	loss 1.8965 (3.2569)	grad_norm 3.7681 (nan)	mem 8931MB
[2022-04-08 04:51:29 large] (main.py 226): INFO Train: [172/300][2200/2502]	eta 0:03:13 lr 0.000194	time 0.5818 (0.6393)	loss 2.2477 (3.2550)	grad_norm 4.5242 (nan)	mem 8931MB
[2022-04-08 04:52:33 large] (main.py 226): INFO Train: [172/300][2300/2502]	eta 0:02:09 lr 0.000194	time 0.6388 (0.6391)	loss 2.9482 (3.2570)	grad_norm 3.1370 (nan)	mem 8931MB
[2022-04-08 04:53:36 large] (main.py 226): INFO Train: [172/300][2400/2502]	eta 0:01:05 lr 0.000194	time 0.6371 (0.6390)	loss 3.4817 (3.2591)	grad_norm 3.8282 (nan)	mem 8931MB
[2022-04-08 04:54:39 large] (main.py 226): INFO Train: [172/300][2500/2502]	eta 0:00:01 lr 0.000193	time 0.6288 (0.6386)	loss 3.1825 (3.2592)	grad_norm 4.0596 (nan)	mem 8931MB
[2022-04-08 04:54:41 large] (main.py 233): INFO EPOCH 172 training takes 0:26:38
[2022-04-08 04:54:47 large] (main.py 273): INFO Test: [0/98]	Time 6.164 (6.164)	Loss 1.0212 (1.0212)	Acc@1 80.078 (80.078)	Acc@5 94.727 (94.727)	Mem 8931MB
[2022-04-08 04:55:13 large] (main.py 279): INFO  * Acc@1 78.526 Acc@5 94.254
[2022-04-08 04:55:13 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 78.5%
[2022-04-08 04:55:13 large] (utils.py 57): INFO output/large/default/ckpt_epoch_172.pth saving......
[2022-04-08 04:55:13 large] (utils.py 59): INFO output/large/default/ckpt_epoch_172.pth saved !!!
[2022-04-08 04:55:13 large] (main.py 148): INFO Max accuracy: 78.53%
[2022-04-08 04:55:21 large] (main.py 226): INFO Train: [173/300][0/2502]	eta 4:59:27 lr 0.000193	time 7.1814 (7.1814)	loss 3.4428 (3.4428)	grad_norm 3.8890 (3.8890)	mem 8931MB
[2022-04-08 04:56:14 large] (main.py 226): INFO Train: [173/300][100/2502]	eta 0:24:05 lr 0.000193	time 0.5876 (0.6020)	loss 3.6991 (3.2259)	grad_norm 3.7616 (4.3572)	mem 8931MB
[2022-04-08 04:57:18 large] (main.py 226): INFO Train: [173/300][200/2502]	eta 0:23:49 lr 0.000193	time 0.6411 (0.6210)	loss 2.5788 (3.2477)	grad_norm 4.7293 (4.3964)	mem 8931MB
[2022-04-08 04:58:23 large] (main.py 226): INFO Train: [173/300][300/2502]	eta 0:23:07 lr 0.000193	time 0.6992 (0.6300)	loss 3.5014 (3.2400)	grad_norm 5.0503 (4.3802)	mem 8931MB
[2022-04-08 04:59:28 large] (main.py 226): INFO Train: [173/300][400/2502]	eta 0:22:14 lr 0.000193	time 0.5937 (0.6351)	loss 3.7595 (3.2442)	grad_norm 3.7104 (4.4043)	mem 8931MB
[2022-04-08 05:00:32 large] (main.py 226): INFO Train: [173/300][500/2502]	eta 0:21:14 lr 0.000193	time 0.6255 (0.6366)	loss 4.0335 (3.2378)	grad_norm 5.7557 (4.3775)	mem 8931MB
[2022-04-08 05:01:37 large] (main.py 226): INFO Train: [173/300][600/2502]	eta 0:20:15 lr 0.000193	time 0.7116 (0.6389)	loss 3.2669 (3.2280)	grad_norm 4.5268 (4.3641)	mem 8931MB
[2022-04-08 05:02:42 large] (main.py 226): INFO Train: [173/300][700/2502]	eta 0:19:12 lr 0.000193	time 0.5799 (0.6393)	loss 3.2692 (3.2370)	grad_norm 3.4345 (4.3422)	mem 8931MB
[2022-04-08 05:03:46 large] (main.py 226): INFO Train: [173/300][800/2502]	eta 0:18:08 lr 0.000193	time 0.6527 (0.6397)	loss 2.3456 (3.2378)	grad_norm 4.3555 (4.3312)	mem 8931MB
[2022-04-08 05:04:50 large] (main.py 226): INFO Train: [173/300][900/2502]	eta 0:17:04 lr 0.000193	time 0.6683 (0.6397)	loss 3.8103 (3.2346)	grad_norm 10.7665 (4.3436)	mem 8931MB
[2022-04-08 05:05:52 large] (main.py 226): INFO Train: [173/300][1000/2502]	eta 0:15:58 lr 0.000192	time 0.5402 (0.6384)	loss 2.0032 (3.2402)	grad_norm 4.2320 (4.3503)	mem 8931MB
[2022-04-08 05:06:57 large] (main.py 226): INFO Train: [173/300][1100/2502]	eta 0:14:55 lr 0.000192	time 0.5273 (0.6388)	loss 3.1809 (3.2449)	grad_norm 4.1791 (4.3346)	mem 8931MB
[2022-04-08 05:08:00 large] (main.py 226): INFO Train: [173/300][1200/2502]	eta 0:13:51 lr 0.000192	time 0.6365 (0.6384)	loss 4.0825 (3.2432)	grad_norm 4.2625 (4.3444)	mem 8931MB
[2022-04-08 05:09:04 large] (main.py 226): INFO Train: [173/300][1300/2502]	eta 0:12:47 lr 0.000192	time 0.7077 (0.6382)	loss 3.3832 (3.2410)	grad_norm 3.6593 (4.3367)	mem 8931MB
[2022-04-08 05:10:07 large] (main.py 226): INFO Train: [173/300][1400/2502]	eta 0:11:42 lr 0.000192	time 0.6612 (0.6379)	loss 3.3870 (3.2459)	grad_norm 5.5385 (4.3479)	mem 8931MB
[2022-04-08 05:11:11 large] (main.py 226): INFO Train: [173/300][1500/2502]	eta 0:10:38 lr 0.000192	time 0.6173 (0.6377)	loss 3.6607 (3.2454)	grad_norm 4.4177 (4.3370)	mem 8931MB
[2022-04-08 05:12:14 large] (main.py 226): INFO Train: [173/300][1600/2502]	eta 0:09:34 lr 0.000192	time 0.6709 (0.6372)	loss 2.5593 (3.2510)	grad_norm 5.4886 (4.3260)	mem 8931MB
[2022-04-08 05:13:10 large] (main.py 226): INFO Train: [173/300][1700/2502]	eta 0:08:27 lr 0.000192	time 0.4995 (0.6327)	loss 2.7991 (3.2524)	grad_norm 4.6119 (4.3264)	mem 8931MB
[2022-04-08 05:14:13 large] (main.py 226): INFO Train: [173/300][1800/2502]	eta 0:07:24 lr 0.000192	time 0.5588 (0.6327)	loss 3.4246 (3.2524)	grad_norm 3.6956 (4.3357)	mem 8931MB
[2022-04-08 05:15:17 large] (main.py 226): INFO Train: [173/300][1900/2502]	eta 0:06:21 lr 0.000192	time 0.6514 (0.6331)	loss 2.7171 (3.2527)	grad_norm 4.5188 (4.3401)	mem 8931MB
[2022-04-08 05:16:20 large] (main.py 226): INFO Train: [173/300][2000/2502]	eta 0:05:17 lr 0.000191	time 0.7274 (0.6329)	loss 2.8334 (3.2546)	grad_norm 4.2974 (4.3433)	mem 8931MB
[2022-04-08 05:17:24 large] (main.py 226): INFO Train: [173/300][2100/2502]	eta 0:04:14 lr 0.000191	time 0.6283 (0.6332)	loss 3.5407 (3.2527)	grad_norm 4.3995 (4.3356)	mem 8931MB
[2022-04-08 05:18:28 large] (main.py 226): INFO Train: [173/300][2200/2502]	eta 0:03:11 lr 0.000191	time 0.6050 (0.6334)	loss 3.4100 (3.2564)	grad_norm 3.8736 (4.3342)	mem 8931MB
[2022-04-08 05:19:32 large] (main.py 226): INFO Train: [173/300][2300/2502]	eta 0:02:08 lr 0.000191	time 0.6216 (0.6338)	loss 3.8488 (3.2587)	grad_norm 4.7686 (4.3334)	mem 8931MB
[2022-04-08 05:20:36 large] (main.py 226): INFO Train: [173/300][2400/2502]	eta 0:01:04 lr 0.000191	time 0.6348 (0.6340)	loss 3.1324 (3.2564)	grad_norm 2.9576 (4.3398)	mem 8931MB
[2022-04-08 05:21:40 large] (main.py 226): INFO Train: [173/300][2500/2502]	eta 0:00:01 lr 0.000191	time 0.5820 (0.6343)	loss 3.3645 (3.2562)	grad_norm 3.8614 (4.3354)	mem 8931MB
[2022-04-08 05:21:41 large] (main.py 233): INFO EPOCH 173 training takes 0:26:27
[2022-04-08 05:21:47 large] (main.py 273): INFO Test: [0/98]	Time 6.366 (6.366)	Loss 1.1946 (1.1946)	Acc@1 75.586 (75.586)	Acc@5 92.188 (92.188)	Mem 8931MB
[2022-04-08 05:22:13 large] (main.py 279): INFO  * Acc@1 78.418 Acc@5 94.314
[2022-04-08 05:22:13 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 78.4%
[2022-04-08 05:22:13 large] (main.py 148): INFO Max accuracy: 78.53%
[2022-04-08 05:22:20 large] (main.py 226): INFO Train: [174/300][0/2502]	eta 4:48:14 lr 0.000191	time 6.9123 (6.9123)	loss 3.5969 (3.5969)	grad_norm 3.8947 (3.8947)	mem 8931MB
[2022-04-08 05:23:18 large] (main.py 226): INFO Train: [174/300][100/2502]	eta 0:25:46 lr 0.000191	time 0.6911 (0.6440)	loss 3.2766 (3.3252)	grad_norm 7.9780 (4.4121)	mem 8931MB
[2022-04-08 05:24:23 large] (main.py 226): INFO Train: [174/300][200/2502]	eta 0:24:44 lr 0.000191	time 0.5810 (0.6449)	loss 3.3068 (3.2710)	grad_norm 4.5499 (4.3286)	mem 8931MB
[2022-04-08 05:25:27 large] (main.py 226): INFO Train: [174/300][300/2502]	eta 0:23:35 lr 0.000191	time 0.6849 (0.6430)	loss 2.9275 (3.3018)	grad_norm 4.3030 (4.3034)	mem 8931MB
[2022-04-08 05:26:31 large] (main.py 226): INFO Train: [174/300][400/2502]	eta 0:22:30 lr 0.000191	time 0.6641 (0.6426)	loss 3.6922 (3.2937)	grad_norm 3.8064 (4.3352)	mem 8931MB
[2022-04-08 05:27:35 large] (main.py 226): INFO Train: [174/300][500/2502]	eta 0:21:24 lr 0.000190	time 0.6154 (0.6418)	loss 2.4321 (3.2825)	grad_norm 3.8376 (4.3442)	mem 8931MB
[2022-04-08 05:28:39 large] (main.py 226): INFO Train: [174/300][600/2502]	eta 0:20:20 lr 0.000190	time 1.5037 (0.6415)	loss 3.6534 (3.2751)	grad_norm 3.2855 (4.3376)	mem 8931MB
[2022-04-08 05:29:40 large] (main.py 226): INFO Train: [174/300][700/2502]	eta 0:19:08 lr 0.000190	time 0.6407 (0.6373)	loss 3.3267 (3.2684)	grad_norm 3.6941 (4.3388)	mem 8931MB
[2022-04-08 05:30:44 large] (main.py 226): INFO Train: [174/300][800/2502]	eta 0:18:04 lr 0.000190	time 0.6121 (0.6371)	loss 3.7596 (3.2625)	grad_norm 3.9899 (4.3170)	mem 8931MB
[2022-04-08 05:31:47 large] (main.py 226): INFO Train: [174/300][900/2502]	eta 0:16:59 lr 0.000190	time 0.6775 (0.6367)	loss 2.7539 (3.2679)	grad_norm 3.9247 (4.3069)	mem 8931MB
[2022-04-08 05:32:51 large] (main.py 226): INFO Train: [174/300][1000/2502]	eta 0:15:56 lr 0.000190	time 0.6597 (0.6367)	loss 3.7163 (3.2672)	grad_norm 4.4544 (4.2937)	mem 8931MB
[2022-04-08 05:33:54 large] (main.py 226): INFO Train: [174/300][1100/2502]	eta 0:14:52 lr 0.000190	time 0.6873 (0.6362)	loss 3.1009 (3.2711)	grad_norm 3.4320 (4.2987)	mem 8931MB
[2022-04-08 05:34:57 large] (main.py 226): INFO Train: [174/300][1200/2502]	eta 0:13:47 lr 0.000190	time 0.5997 (0.6359)	loss 3.2261 (3.2720)	grad_norm 4.2434 (4.2886)	mem 8931MB
[2022-04-08 05:36:00 large] (main.py 226): INFO Train: [174/300][1300/2502]	eta 0:12:43 lr 0.000190	time 0.5325 (0.6355)	loss 3.0508 (3.2644)	grad_norm 3.9862 (4.2970)	mem 8931MB
[2022-04-08 05:37:02 large] (main.py 226): INFO Train: [174/300][1400/2502]	eta 0:11:39 lr 0.000190	time 0.6450 (0.6346)	loss 3.2274 (3.2632)	grad_norm 3.7882 (4.2912)	mem 8931MB
[2022-04-08 05:38:06 large] (main.py 226): INFO Train: [174/300][1500/2502]	eta 0:10:35 lr 0.000189	time 0.6828 (0.6343)	loss 3.6166 (3.2639)	grad_norm 5.4530 (nan)	mem 8931MB
[2022-04-08 05:39:09 large] (main.py 226): INFO Train: [174/300][1600/2502]	eta 0:09:32 lr 0.000189	time 0.6131 (0.6346)	loss 2.9042 (3.2621)	grad_norm 3.3707 (nan)	mem 8931MB
[2022-04-08 05:40:13 large] (main.py 226): INFO Train: [174/300][1700/2502]	eta 0:08:28 lr 0.000189	time 0.5944 (0.6347)	loss 3.4270 (3.2596)	grad_norm 3.6631 (nan)	mem 8931MB
[2022-04-08 05:41:16 large] (main.py 226): INFO Train: [174/300][1800/2502]	eta 0:07:25 lr 0.000189	time 0.6211 (0.6344)	loss 2.2312 (3.2613)	grad_norm 4.2453 (nan)	mem 8931MB
[2022-04-08 05:42:19 large] (main.py 226): INFO Train: [174/300][1900/2502]	eta 0:06:21 lr 0.000189	time 0.5880 (0.6342)	loss 2.0974 (3.2578)	grad_norm 3.5618 (nan)	mem 8931MB
[2022-04-08 05:43:21 large] (main.py 226): INFO Train: [174/300][2000/2502]	eta 0:05:18 lr 0.000189	time 0.5041 (0.6337)	loss 3.0761 (3.2592)	grad_norm 3.9740 (nan)	mem 8931MB
[2022-04-08 05:44:26 large] (main.py 226): INFO Train: [174/300][2100/2502]	eta 0:04:14 lr 0.000189	time 0.5842 (0.6342)	loss 2.2687 (3.2581)	grad_norm 3.8289 (nan)	mem 8931MB
[2022-04-08 05:45:29 large] (main.py 226): INFO Train: [174/300][2200/2502]	eta 0:03:11 lr 0.000189	time 0.6890 (0.6343)	loss 3.8916 (3.2611)	grad_norm 10.2426 (nan)	mem 8931MB
[2022-04-08 05:46:33 large] (main.py 226): INFO Train: [174/300][2300/2502]	eta 0:02:08 lr 0.000189	time 0.6205 (0.6341)	loss 3.4971 (3.2608)	grad_norm 3.5593 (nan)	mem 8931MB
[2022-04-08 05:47:36 large] (main.py 226): INFO Train: [174/300][2400/2502]	eta 0:01:04 lr 0.000189	time 0.6029 (0.6343)	loss 3.2944 (3.2598)	grad_norm 3.7722 (nan)	mem 8931MB
[2022-04-08 05:48:39 large] (main.py 226): INFO Train: [174/300][2500/2502]	eta 0:00:01 lr 0.000188	time 0.6043 (0.6339)	loss 3.4468 (3.2609)	grad_norm 3.9584 (nan)	mem 8931MB
[2022-04-08 05:48:40 large] (main.py 233): INFO EPOCH 174 training takes 0:26:26
[2022-04-08 05:48:46 large] (main.py 273): INFO Test: [0/98]	Time 6.676 (6.676)	Loss 1.0655 (1.0655)	Acc@1 78.711 (78.711)	Acc@5 95.508 (95.508)	Mem 8931MB
[2022-04-08 05:49:12 large] (main.py 279): INFO  * Acc@1 78.608 Acc@5 94.422
[2022-04-08 05:49:12 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 78.6%
[2022-04-08 05:49:12 large] (utils.py 57): INFO output/large/default/ckpt_epoch_174.pth saving......
[2022-04-08 05:49:13 large] (utils.py 59): INFO output/large/default/ckpt_epoch_174.pth saved !!!
[2022-04-08 05:49:13 large] (main.py 148): INFO Max accuracy: 78.61%
[2022-04-08 05:49:21 large] (main.py 226): INFO Train: [175/300][0/2502]	eta 5:30:21 lr 0.000188	time 7.9224 (7.9224)	loss 3.2203 (3.2203)	grad_norm 3.1874 (3.1874)	mem 8931MB
[2022-04-08 05:50:14 large] (main.py 226): INFO Train: [175/300][100/2502]	eta 0:24:01 lr 0.000188	time 0.6260 (0.6002)	loss 3.4932 (3.2128)	grad_norm 4.6115 (4.3189)	mem 8931MB
[2022-04-08 05:51:18 large] (main.py 226): INFO Train: [175/300][200/2502]	eta 0:23:55 lr 0.000188	time 0.6790 (0.6234)	loss 3.2680 (3.1836)	grad_norm 4.9285 (4.3668)	mem 8931MB
[2022-04-08 05:52:22 large] (main.py 226): INFO Train: [175/300][300/2502]	eta 0:22:59 lr 0.000188	time 0.6707 (0.6265)	loss 3.0905 (3.2098)	grad_norm 4.4052 (4.4107)	mem 8931MB
[2022-04-08 05:53:26 large] (main.py 226): INFO Train: [175/300][400/2502]	eta 0:22:04 lr 0.000188	time 0.6289 (0.6303)	loss 3.1110 (3.2178)	grad_norm 3.6064 (4.4129)	mem 8931MB
[2022-04-08 05:54:30 large] (main.py 226): INFO Train: [175/300][500/2502]	eta 0:21:05 lr 0.000188	time 0.6343 (0.6321)	loss 3.2802 (3.2360)	grad_norm 4.0914 (4.4052)	mem 8931MB
[2022-04-08 05:55:34 large] (main.py 226): INFO Train: [175/300][600/2502]	eta 0:20:05 lr 0.000188	time 0.5274 (0.6338)	loss 2.4276 (3.2454)	grad_norm 3.8369 (4.3770)	mem 8931MB
[2022-04-08 05:56:37 large] (main.py 226): INFO Train: [175/300][700/2502]	eta 0:19:01 lr 0.000188	time 0.6713 (0.6332)	loss 3.5982 (3.2432)	grad_norm 3.8444 (4.3596)	mem 8931MB
[2022-04-08 05:57:40 large] (main.py 226): INFO Train: [175/300][800/2502]	eta 0:17:56 lr 0.000188	time 0.6542 (0.6328)	loss 3.0169 (3.2459)	grad_norm 4.5169 (4.3623)	mem 8931MB
[2022-04-08 05:58:43 large] (main.py 226): INFO Train: [175/300][900/2502]	eta 0:16:53 lr 0.000188	time 0.5911 (0.6326)	loss 3.5191 (3.2497)	grad_norm 4.2024 (4.3612)	mem 8931MB
[2022-04-08 05:59:47 large] (main.py 226): INFO Train: [175/300][1000/2502]	eta 0:15:51 lr 0.000187	time 0.6142 (0.6334)	loss 2.0593 (3.2460)	grad_norm 3.8981 (4.3734)	mem 8931MB
[2022-04-08 06:00:50 large] (main.py 226): INFO Train: [175/300][1100/2502]	eta 0:14:47 lr 0.000187	time 0.6098 (0.6327)	loss 3.7951 (3.2513)	grad_norm 5.3229 (4.3797)	mem 8931MB
[2022-04-08 06:01:52 large] (main.py 226): INFO Train: [175/300][1200/2502]	eta 0:13:43 lr 0.000187	time 0.6526 (0.6323)	loss 2.3604 (3.2505)	grad_norm 3.5652 (4.3779)	mem 8931MB
[2022-04-08 06:02:55 large] (main.py 226): INFO Train: [175/300][1300/2502]	eta 0:12:39 lr 0.000187	time 0.7300 (0.6320)	loss 2.7388 (3.2538)	grad_norm 4.6769 (4.3888)	mem 8931MB
[2022-04-08 06:03:55 large] (main.py 226): INFO Train: [175/300][1400/2502]	eta 0:11:33 lr 0.000187	time 0.5052 (0.6296)	loss 2.6146 (3.2596)	grad_norm 4.5600 (4.3780)	mem 8931MB
[2022-04-08 06:04:55 large] (main.py 226): INFO Train: [175/300][1500/2502]	eta 0:10:28 lr 0.000187	time 0.6355 (0.6276)	loss 1.9917 (3.2566)	grad_norm 5.0671 (4.3768)	mem 8931MB
[2022-04-08 06:05:58 large] (main.py 226): INFO Train: [175/300][1600/2502]	eta 0:09:26 lr 0.000187	time 0.5742 (0.6279)	loss 3.6450 (3.2555)	grad_norm 2.8289 (4.3659)	mem 8931MB
[2022-04-08 06:07:02 large] (main.py 226): INFO Train: [175/300][1700/2502]	eta 0:08:23 lr 0.000187	time 0.7273 (0.6282)	loss 2.3204 (3.2529)	grad_norm 3.2278 (4.3703)	mem 8931MB
[2022-04-08 06:08:05 large] (main.py 226): INFO Train: [175/300][1800/2502]	eta 0:07:21 lr 0.000187	time 0.5003 (0.6286)	loss 3.4635 (3.2569)	grad_norm 3.8341 (4.3628)	mem 8931MB
[2022-04-08 06:09:07 large] (main.py 226): INFO Train: [175/300][1900/2502]	eta 0:06:17 lr 0.000187	time 0.6055 (0.6279)	loss 2.3034 (3.2556)	grad_norm 4.9930 (nan)	mem 8931MB
[2022-04-08 06:10:09 large] (main.py 226): INFO Train: [175/300][2000/2502]	eta 0:05:15 lr 0.000186	time 0.6158 (0.6278)	loss 3.6608 (3.2523)	grad_norm 4.0447 (nan)	mem 8931MB
[2022-04-08 06:11:13 large] (main.py 226): INFO Train: [175/300][2100/2502]	eta 0:04:12 lr 0.000186	time 0.5876 (0.6282)	loss 3.5537 (3.2546)	grad_norm 5.2186 (nan)	mem 8931MB
[2022-04-08 06:12:16 large] (main.py 226): INFO Train: [175/300][2200/2502]	eta 0:03:09 lr 0.000186	time 0.5902 (0.6284)	loss 3.3297 (3.2579)	grad_norm 3.5331 (nan)	mem 8931MB
[2022-04-08 06:13:19 large] (main.py 226): INFO Train: [175/300][2300/2502]	eta 0:02:06 lr 0.000186	time 0.5554 (0.6282)	loss 2.3774 (3.2579)	grad_norm 6.1148 (nan)	mem 8931MB
[2022-04-08 06:14:22 large] (main.py 226): INFO Train: [175/300][2400/2502]	eta 0:01:04 lr 0.000186	time 0.6439 (0.6284)	loss 2.3911 (3.2599)	grad_norm 4.7443 (nan)	mem 8931MB
[2022-04-08 06:15:24 large] (main.py 226): INFO Train: [175/300][2500/2502]	eta 0:00:01 lr 0.000186	time 0.5721 (0.6282)	loss 3.5428 (3.2594)	grad_norm 5.8157 (nan)	mem 8931MB
[2022-04-08 06:15:25 large] (main.py 233): INFO EPOCH 175 training takes 0:26:12
[2022-04-08 06:15:31 large] (main.py 273): INFO Test: [0/98]	Time 5.725 (5.725)	Loss 1.0901 (1.0901)	Acc@1 79.102 (79.102)	Acc@5 93.164 (93.164)	Mem 8931MB
[2022-04-08 06:15:58 large] (main.py 279): INFO  * Acc@1 78.246 Acc@5 94.360
[2022-04-08 06:15:58 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 78.2%
[2022-04-08 06:15:58 large] (main.py 148): INFO Max accuracy: 78.61%
[2022-04-08 06:16:05 large] (main.py 226): INFO Train: [176/300][0/2502]	eta 4:51:59 lr 0.000186	time 7.0022 (7.0022)	loss 3.7983 (3.7983)	grad_norm 3.3725 (3.3725)	mem 8931MB
[2022-04-08 06:17:00 large] (main.py 226): INFO Train: [176/300][100/2502]	eta 0:24:43 lr 0.000186	time 0.6528 (0.6175)	loss 3.8875 (3.2085)	grad_norm 4.6490 (4.2752)	mem 8931MB
[2022-04-08 06:18:05 large] (main.py 226): INFO Train: [176/300][200/2502]	eta 0:24:17 lr 0.000186	time 0.5876 (0.6330)	loss 3.2228 (3.1487)	grad_norm 3.3209 (4.4145)	mem 8931MB
[2022-04-08 06:19:10 large] (main.py 226): INFO Train: [176/300][300/2502]	eta 0:23:25 lr 0.000186	time 0.6039 (0.6381)	loss 3.1673 (3.2015)	grad_norm 3.7028 (4.3722)	mem 8931MB
[2022-04-08 06:20:14 large] (main.py 226): INFO Train: [176/300][400/2502]	eta 0:22:22 lr 0.000186	time 0.6627 (0.6388)	loss 3.4615 (3.2066)	grad_norm 3.8113 (4.3216)	mem 8931MB
[2022-04-08 06:21:17 large] (main.py 226): INFO Train: [176/300][500/2502]	eta 0:21:15 lr 0.000185	time 0.7261 (0.6373)	loss 2.9088 (3.2076)	grad_norm 4.6856 (4.3174)	mem 8931MB
[2022-04-08 06:22:20 large] (main.py 226): INFO Train: [176/300][600/2502]	eta 0:20:09 lr 0.000185	time 0.6068 (0.6362)	loss 2.3049 (3.2247)	grad_norm 3.5157 (4.3344)	mem 8931MB
[2022-04-08 06:23:23 large] (main.py 226): INFO Train: [176/300][700/2502]	eta 0:19:05 lr 0.000185	time 0.5885 (0.6358)	loss 3.6574 (3.2254)	grad_norm 4.0544 (4.3285)	mem 8931MB
[2022-04-08 06:24:27 large] (main.py 226): INFO Train: [176/300][800/2502]	eta 0:18:02 lr 0.000185	time 0.5110 (0.6362)	loss 3.2038 (3.2327)	grad_norm 3.5645 (4.3016)	mem 8931MB
[2022-04-08 06:25:29 large] (main.py 226): INFO Train: [176/300][900/2502]	eta 0:16:55 lr 0.000185	time 0.6269 (0.6342)	loss 3.1244 (3.2433)	grad_norm 3.4282 (4.3017)	mem 8931MB
[2022-04-08 06:26:32 large] (main.py 226): INFO Train: [176/300][1000/2502]	eta 0:15:51 lr 0.000185	time 0.6375 (0.6336)	loss 3.7484 (3.2416)	grad_norm 4.4316 (4.3135)	mem 8931MB
[2022-04-08 06:27:35 large] (main.py 226): INFO Train: [176/300][1100/2502]	eta 0:14:47 lr 0.000185	time 0.6956 (0.6332)	loss 2.8144 (3.2442)	grad_norm 4.2925 (4.3203)	mem 8931MB
[2022-04-08 06:28:38 large] (main.py 226): INFO Train: [176/300][1200/2502]	eta 0:13:44 lr 0.000185	time 0.5957 (0.6333)	loss 3.0213 (3.2471)	grad_norm 3.5313 (4.3300)	mem 8931MB
[2022-04-08 06:29:40 large] (main.py 226): INFO Train: [176/300][1300/2502]	eta 0:12:40 lr 0.000185	time 0.6694 (0.6323)	loss 3.7173 (3.2487)	grad_norm 4.6823 (4.3385)	mem 8931MB
[2022-04-08 06:30:43 large] (main.py 226): INFO Train: [176/300][1400/2502]	eta 0:11:36 lr 0.000185	time 0.6234 (0.6321)	loss 3.9625 (3.2524)	grad_norm 4.7690 (4.3349)	mem 8931MB
[2022-04-08 06:31:47 large] (main.py 226): INFO Train: [176/300][1500/2502]	eta 0:10:33 lr 0.000184	time 0.6472 (0.6327)	loss 3.2186 (3.2491)	grad_norm 3.2521 (4.3414)	mem 8931MB
[2022-04-08 06:32:50 large] (main.py 226): INFO Train: [176/300][1600/2502]	eta 0:09:30 lr 0.000184	time 0.6699 (0.6324)	loss 3.3460 (3.2500)	grad_norm 4.2681 (4.3508)	mem 8931MB
[2022-04-08 06:33:54 large] (main.py 226): INFO Train: [176/300][1700/2502]	eta 0:08:27 lr 0.000184	time 0.5788 (0.6328)	loss 2.9135 (3.2490)	grad_norm 5.5399 (4.3594)	mem 8931MB
[2022-04-08 06:34:56 large] (main.py 226): INFO Train: [176/300][1800/2502]	eta 0:07:23 lr 0.000184	time 0.5997 (0.6319)	loss 3.2322 (3.2518)	grad_norm 4.6597 (4.3565)	mem 8931MB
[2022-04-08 06:35:56 large] (main.py 226): INFO Train: [176/300][1900/2502]	eta 0:06:19 lr 0.000184	time 0.6416 (0.6305)	loss 3.6599 (3.2452)	grad_norm 3.1833 (nan)	mem 8931MB
[2022-04-08 06:36:59 large] (main.py 226): INFO Train: [176/300][2000/2502]	eta 0:05:16 lr 0.000184	time 0.6140 (0.6303)	loss 3.3415 (3.2469)	grad_norm 4.0049 (nan)	mem 8931MB
[2022-04-08 06:38:02 large] (main.py 226): INFO Train: [176/300][2100/2502]	eta 0:04:13 lr 0.000184	time 0.6299 (0.6304)	loss 3.3857 (3.2499)	grad_norm 4.2120 (nan)	mem 8931MB
[2022-04-08 06:39:05 large] (main.py 226): INFO Train: [176/300][2200/2502]	eta 0:03:10 lr 0.000184	time 0.5982 (0.6301)	loss 3.5255 (3.2507)	grad_norm 3.9368 (nan)	mem 8931MB
[2022-04-08 06:40:08 large] (main.py 226): INFO Train: [176/300][2300/2502]	eta 0:02:07 lr 0.000184	time 0.6240 (0.6303)	loss 3.7187 (3.2477)	grad_norm 4.4736 (nan)	mem 8931MB
[2022-04-08 06:41:11 large] (main.py 226): INFO Train: [176/300][2400/2502]	eta 0:01:04 lr 0.000184	time 0.5204 (0.6302)	loss 3.8176 (3.2461)	grad_norm 4.1211 (nan)	mem 8931MB
[2022-04-08 06:42:12 large] (main.py 226): INFO Train: [176/300][2500/2502]	eta 0:00:01 lr 0.000183	time 0.6210 (0.6295)	loss 2.5849 (3.2476)	grad_norm 3.3584 (nan)	mem 8931MB
[2022-04-08 06:42:13 large] (main.py 233): INFO EPOCH 176 training takes 0:26:15
[2022-04-08 06:42:20 large] (main.py 273): INFO Test: [0/98]	Time 6.952 (6.952)	Loss 1.0338 (1.0338)	Acc@1 78.711 (78.711)	Acc@5 93.945 (93.945)	Mem 8931MB
[2022-04-08 06:42:46 large] (main.py 279): INFO  * Acc@1 78.544 Acc@5 94.344
[2022-04-08 06:42:46 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 78.5%
[2022-04-08 06:42:46 large] (main.py 148): INFO Max accuracy: 78.61%
[2022-04-08 06:42:52 large] (main.py 226): INFO Train: [177/300][0/2502]	eta 4:31:52 lr 0.000183	time 6.5196 (6.5196)	loss 4.1397 (4.1397)	grad_norm 4.7377 (4.7377)	mem 8931MB
[2022-04-08 06:43:51 large] (main.py 226): INFO Train: [177/300][100/2502]	eta 0:25:50 lr 0.000183	time 0.5629 (0.6455)	loss 3.5767 (3.1689)	grad_norm 6.5619 (4.3498)	mem 8931MB
[2022-04-08 06:44:55 large] (main.py 226): INFO Train: [177/300][200/2502]	eta 0:24:43 lr 0.000183	time 0.6595 (0.6446)	loss 3.4954 (3.1981)	grad_norm 4.1685 (4.3577)	mem 8931MB
[2022-04-08 06:45:58 large] (main.py 226): INFO Train: [177/300][300/2502]	eta 0:23:24 lr 0.000183	time 0.4968 (0.6378)	loss 2.8984 (3.2264)	grad_norm 4.4108 (4.4284)	mem 8931MB
[2022-04-08 06:46:59 large] (main.py 226): INFO Train: [177/300][400/2502]	eta 0:22:08 lr 0.000183	time 0.6143 (0.6318)	loss 2.8035 (3.2270)	grad_norm 4.4792 (4.4398)	mem 8931MB
[2022-04-08 07:27:33 large] (main.py 347): INFO Full config saved to output/large/default/config.json
[2022-04-08 07:27:33 large] (main.py 350): INFO AMP_OPT_LEVEL: O1
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: ../../Data/raw-data/imagenet-data/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 16
  PIN_MEMORY: true
  ZIP_MODE: false
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DFvT:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 128
    IN_CHANS: 3
    MLP_RATIO: 2.0
    NUM_HEADS:
    - 4
    - 8
    - 16
    - 32
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    SIZE: large
    WINDOW_SIZE: 7
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: large
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: DFvT
OUTPUT: output/large/default
PRINT_FREQ: 100
SAVE_FREQ: 1000
SEED: 0
TAG: default
TEST:
  CROP: true
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: true
  BASE_LR: 0.0005
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MIN_LR: 5.0e-06
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 5.0e-07
  WEIGHT_DECAY: 0.05

[2022-04-08 07:27:37 large] (main.py 80): INFO Creating model:DFvT/large
[2022-04-08 07:27:38 large] (main.py 85): INFO DFvT(
  (patch_embed): PatchEmbed(
    (proj1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (proj2): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (silu): SiLU(inplace=True)
    (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=128, input_resolution=(28, 28), depth=2
      (blocks): ModuleList(
        (0): TransformerBlock(
          dim=128, input_resolution=(28, 28), num_heads=4, window_size=7, shift_size=0, mlp_ratio=2.0
          (select): DANE(
            (fc_spatial): Sequential(
              (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=128, out_features=1, bias=False)
            )
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc_channel): Sequential(
              (0): Linear(in_features=128, out_features=8, bias=False)
              (1): SiLU(inplace=True)
              (2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)
              (3): Linear(in_features=8, out_features=128, bias=False)
            )
            (sigmoid): Sigmoid()
          )
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=256, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=256, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): TransformerBlock(
          dim=128, input_resolution=(28, 28), num_heads=4, window_size=7, shift_size=3, mlp_ratio=2.0
          (select): DANE(
            (fc_spatial): Sequential(
              (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=128, out_features=1, bias=False)
            )
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc_channel): Sequential(
              (0): Linear(in_features=128, out_features=8, bias=False)
              (1): SiLU(inplace=True)
              (2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)
              (3): Linear(in_features=8, out_features=128, bias=False)
            )
            (sigmoid): Sigmoid()
          )
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=256, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=256, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(28, 28), dim=128
        (reduction): Linear(in_features=128, out_features=256, bias=False)
        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=256, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): TransformerBlock(
          dim=256, input_resolution=(14, 14), num_heads=8, window_size=7, shift_size=0, mlp_ratio=2.0
          (select): DANE(
            (fc_spatial): Sequential(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=256, out_features=1, bias=False)
            )
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc_channel): Sequential(
              (0): Linear(in_features=256, out_features=16, bias=False)
              (1): SiLU(inplace=True)
              (2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
              (3): Linear(in_features=16, out_features=256, bias=False)
            )
            (sigmoid): Sigmoid()
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): TransformerBlock(
          dim=256, input_resolution=(14, 14), num_heads=8, window_size=7, shift_size=3, mlp_ratio=2.0
          (select): DANE(
            (fc_spatial): Sequential(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=256, out_features=1, bias=False)
            )
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc_channel): Sequential(
              (0): Linear(in_features=256, out_features=16, bias=False)
              (1): SiLU(inplace=True)
              (2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
              (3): Linear(in_features=16, out_features=256, bias=False)
            )
            (sigmoid): Sigmoid()
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=256
        (reduction): Linear(in_features=256, out_features=512, bias=False)
        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): BasicLayer(
      dim=512, input_resolution=(7, 7), depth=6
      (blocks): ModuleList(
        (0): TransformerBlock(
          dim=512, input_resolution=(7, 7), num_heads=16, window_size=7, shift_size=0, mlp_ratio=2.0
          (select): DANE(
            (fc_spatial): Sequential(
              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=512, out_features=1, bias=False)
            )
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc_channel): Sequential(
              (0): Linear(in_features=512, out_features=32, bias=False)
              (1): SiLU(inplace=True)
              (2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
              (3): Linear(in_features=32, out_features=512, bias=False)
            )
            (sigmoid): Sigmoid()
          )
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): TransformerBlock(
          dim=512, input_resolution=(7, 7), num_heads=16, window_size=7, shift_size=0, mlp_ratio=2.0
          (select): DANE(
            (fc_spatial): Sequential(
              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=512, out_features=1, bias=False)
            )
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc_channel): Sequential(
              (0): Linear(in_features=512, out_features=32, bias=False)
              (1): SiLU(inplace=True)
              (2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
              (3): Linear(in_features=32, out_features=512, bias=False)
            )
            (sigmoid): Sigmoid()
          )
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): TransformerBlock(
          dim=512, input_resolution=(7, 7), num_heads=16, window_size=7, shift_size=0, mlp_ratio=2.0
          (select): DANE(
            (fc_spatial): Sequential(
              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=512, out_features=1, bias=False)
            )
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc_channel): Sequential(
              (0): Linear(in_features=512, out_features=32, bias=False)
              (1): SiLU(inplace=True)
              (2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
              (3): Linear(in_features=32, out_features=512, bias=False)
            )
            (sigmoid): Sigmoid()
          )
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): TransformerBlock(
          dim=512, input_resolution=(7, 7), num_heads=16, window_size=7, shift_size=0, mlp_ratio=2.0
          (select): DANE(
            (fc_spatial): Sequential(
              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=512, out_features=1, bias=False)
            )
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc_channel): Sequential(
              (0): Linear(in_features=512, out_features=32, bias=False)
              (1): SiLU(inplace=True)
              (2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
              (3): Linear(in_features=32, out_features=512, bias=False)
            )
            (sigmoid): Sigmoid()
          )
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): TransformerBlock(
          dim=512, input_resolution=(7, 7), num_heads=16, window_size=7, shift_size=0, mlp_ratio=2.0
          (select): DANE(
            (fc_spatial): Sequential(
              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=512, out_features=1, bias=False)
            )
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc_channel): Sequential(
              (0): Linear(in_features=512, out_features=32, bias=False)
              (1): SiLU(inplace=True)
              (2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
              (3): Linear(in_features=32, out_features=512, bias=False)
            )
            (sigmoid): Sigmoid()
          )
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): TransformerBlock(
          dim=512, input_resolution=(7, 7), num_heads=16, window_size=7, shift_size=0, mlp_ratio=2.0
          (select): DANE(
            (fc_spatial): Sequential(
              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=512, out_features=1, bias=False)
            )
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc_channel): Sequential(
              (0): Linear(in_features=512, out_features=32, bias=False)
              (1): SiLU(inplace=True)
              (2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
              (3): Linear(in_features=32, out_features=512, bias=False)
            )
            (sigmoid): Sigmoid()
          )
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(7, 7), dim=512
        (reduction): Linear(in_features=512, out_features=1024, bias=False)
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (3): BasicLayer(
      dim=1024, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0): TransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=2.0
          (select): DANE(
            (fc_spatial): Sequential(
              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=1024, out_features=1, bias=False)
            )
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc_channel): Sequential(
              (0): Linear(in_features=1024, out_features=64, bias=False)
              (1): SiLU(inplace=True)
              (2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (3): Linear(in_features=64, out_features=1024, bias=False)
            )
            (sigmoid): Sigmoid()
          )
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): TransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=2.0
          (select): DANE(
            (fc_spatial): Sequential(
              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=1024, out_features=1, bias=False)
            )
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc_channel): Sequential(
              (0): Linear(in_features=1024, out_features=64, bias=False)
              (1): SiLU(inplace=True)
              (2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (3): Linear(in_features=64, out_features=1024, bias=False)
            )
            (sigmoid): Sigmoid()
          )
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (convlayers): ModuleList(
    (0): ConvBlock(
      (conv1x1_1): Sequential(
        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): SiLU(inplace=True)
        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (8): SiLU(inplace=True)
      )
      (conv1): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
      (conv1x1_2): Sequential(
        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
    )
    (1): ConvBlock(
      (conv1x1_1): Sequential(
        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): SiLU(inplace=True)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (8): SiLU(inplace=True)
      )
      (conv1): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
      (conv1x1_2): Sequential(
        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
    )
    (2): ConvBlock(
      (conv1x1_1): Sequential(
        (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): SiLU(inplace=True)
        (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
        (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (8): SiLU(inplace=True)
      )
      (conv1): Sequential(
        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
      (conv1x1_2): Sequential(
        (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
    )
    (3): ConvBlock(
      (conv1x1_1): Sequential(
        (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
        (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
        (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): SiLU(inplace=True)
        (6): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (8): SiLU(inplace=True)
      )
      (conv1): Sequential(
        (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
      (conv1x1_2): Sequential(
        (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
    )
  )
  (multiresolution_conv): ModuleList(
    (0): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Sequential(
      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): Sequential(
      (0): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048, bias=False)
      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2022-04-08 07:27:38 large] (main.py 94): INFO number of params: 37331136
[2022-04-08 07:27:38 large] (main.py 97): INFO number of GFLOPs: 2.503752704
[2022-04-08 07:27:38 large] (main.py 119): INFO auto resuming from output/large/default/ckpt_epoch_174.pth
[2022-04-08 07:27:38 large] (utils.py 20): INFO ==============> Resuming form output/large/default/ckpt_epoch_174.pth....................
[2022-04-08 07:27:38 large] (utils.py 27): INFO <All keys matched successfully>
[2022-04-08 07:27:38 large] (utils.py 37): INFO => loaded successfully 'output/large/default/ckpt_epoch_174.pth' (epoch 174)
[2022-04-08 07:27:48 large] (main.py 273): INFO Test: [0/98]	Time 9.143 (9.143)	Loss 1.0653 (1.0653)	Acc@1 76.953 (76.953)	Acc@5 94.922 (94.922)	Mem 2203MB
[2022-04-08 07:28:11 large] (main.py 279): INFO  * Acc@1 78.612 Acc@5 94.398
[2022-04-08 07:28:11 large] (main.py 126): INFO Accuracy of the network on the 50000 test images: 78.6%
[2022-04-08 07:28:11 large] (main.py 134): INFO Start training
[2022-04-08 07:28:20 large] (main.py 226): INFO Train: [175/300][0/2502]	eta 6:25:34 lr 0.000188	time 9.2465 (9.2465)	loss 3.6905 (3.6905)	grad_norm 4.9670 (4.9670)	mem 8774MB
[2022-04-08 07:29:09 large] (main.py 226): INFO Train: [175/300][100/2502]	eta 0:23:10 lr 0.000188	time 0.5139 (0.5788)	loss 3.3696 (3.3374)	grad_norm 5.3210 (4.4332)	mem 8922MB
[2022-04-08 07:30:01 large] (main.py 226): INFO Train: [175/300][200/2502]	eta 0:21:05 lr 0.000188	time 0.5493 (0.5497)	loss 3.3326 (3.2662)	grad_norm 4.6501 (4.2772)	mem 8922MB
[2022-04-08 07:30:57 large] (main.py 226): INFO Train: [175/300][300/2502]	eta 0:20:17 lr 0.000188	time 0.5515 (0.5527)	loss 2.8636 (3.2081)	grad_norm 4.3005 (4.2961)	mem 8923MB
[2022-04-08 07:31:55 large] (main.py 226): INFO Train: [175/300][400/2502]	eta 0:19:35 lr 0.000188	time 0.5959 (0.5590)	loss 3.1851 (3.2225)	grad_norm 4.8333 (4.3350)	mem 8924MB
[2022-04-08 07:32:53 large] (main.py 226): INFO Train: [175/300][500/2502]	eta 0:18:48 lr 0.000188	time 0.5508 (0.5638)	loss 3.4524 (3.2261)	grad_norm 3.2187 (4.3903)	mem 8925MB
[2022-04-08 07:33:53 large] (main.py 226): INFO Train: [175/300][600/2502]	eta 0:18:03 lr 0.000188	time 0.6028 (0.5696)	loss 2.2104 (3.2340)	grad_norm 5.3335 (4.4014)	mem 8925MB
[2022-04-08 07:34:54 large] (main.py 226): INFO Train: [175/300][700/2502]	eta 0:17:17 lr 0.000188	time 0.6040 (0.5755)	loss 3.8942 (3.2337)	grad_norm 4.0531 (4.4163)	mem 8925MB
[2022-04-08 07:35:55 large] (main.py 226): INFO Train: [175/300][800/2502]	eta 0:16:26 lr 0.000188	time 0.5318 (0.5799)	loss 3.8427 (3.2371)	grad_norm 3.9212 (4.4074)	mem 8925MB
[2022-04-08 07:36:56 large] (main.py 226): INFO Train: [175/300][900/2502]	eta 0:15:33 lr 0.000188	time 0.5854 (0.5830)	loss 3.4738 (3.2255)	grad_norm 3.9762 (4.4065)	mem 8925MB
[2022-04-08 07:37:58 large] (main.py 226): INFO Train: [175/300][1000/2502]	eta 0:14:41 lr 0.000187	time 0.5771 (0.5869)	loss 2.8573 (3.2262)	grad_norm 3.8553 (4.4038)	mem 8925MB
[2022-04-08 07:39:00 large] (main.py 226): INFO Train: [175/300][1100/2502]	eta 0:13:47 lr 0.000187	time 0.7013 (0.5899)	loss 3.7640 (3.2271)	grad_norm 5.4868 (4.4201)	mem 8925MB
[2022-04-08 07:40:02 large] (main.py 226): INFO Train: [175/300][1200/2502]	eta 0:12:51 lr 0.000187	time 0.5683 (0.5926)	loss 3.7421 (3.2364)	grad_norm 6.3945 (4.4171)	mem 8925MB
[2022-04-08 07:41:05 large] (main.py 226): INFO Train: [175/300][1300/2502]	eta 0:11:55 lr 0.000187	time 0.5790 (0.5954)	loss 3.9290 (3.2406)	grad_norm 3.2537 (4.4149)	mem 8925MB
[2022-04-08 07:42:08 large] (main.py 226): INFO Train: [175/300][1400/2502]	eta 0:10:58 lr 0.000187	time 0.6230 (0.5975)	loss 3.4153 (3.2439)	grad_norm 4.7385 (4.4178)	mem 8925MB
[2022-04-08 07:43:10 large] (main.py 226): INFO Train: [175/300][1500/2502]	eta 0:10:00 lr 0.000187	time 0.6582 (0.5990)	loss 3.0008 (3.2430)	grad_norm 5.0845 (4.4124)	mem 8925MB
[2022-04-08 07:44:12 large] (main.py 226): INFO Train: [175/300][1600/2502]	eta 0:09:01 lr 0.000187	time 0.5239 (0.6007)	loss 3.6750 (3.2461)	grad_norm 5.1822 (4.4364)	mem 8925MB
[2022-04-08 07:45:15 large] (main.py 226): INFO Train: [175/300][1700/2502]	eta 0:08:03 lr 0.000187	time 0.7363 (0.6024)	loss 3.9949 (3.2454)	grad_norm 6.6949 (4.4374)	mem 8925MB
[2022-04-08 07:46:18 large] (main.py 226): INFO Train: [175/300][1800/2502]	eta 0:07:03 lr 0.000187	time 0.6812 (0.6039)	loss 3.0166 (3.2477)	grad_norm 3.8930 (4.4323)	mem 8925MB
[2022-04-08 07:47:22 large] (main.py 226): INFO Train: [175/300][1900/2502]	eta 0:06:04 lr 0.000187	time 0.5976 (0.6055)	loss 3.8348 (3.2459)	grad_norm 4.7785 (4.4261)	mem 8925MB
[2022-04-08 07:48:25 large] (main.py 226): INFO Train: [175/300][2000/2502]	eta 0:05:04 lr 0.000186	time 0.6315 (0.6067)	loss 3.6110 (3.2390)	grad_norm 3.6588 (4.4232)	mem 8925MB
[2022-04-08 07:49:28 large] (main.py 226): INFO Train: [175/300][2100/2502]	eta 0:04:04 lr 0.000186	time 0.6786 (0.6079)	loss 3.4110 (3.2410)	grad_norm 5.6155 (nan)	mem 8925MB
[2022-04-08 07:50:31 large] (main.py 226): INFO Train: [175/300][2200/2502]	eta 0:03:03 lr 0.000186	time 0.5626 (0.6087)	loss 3.7001 (3.2448)	grad_norm 3.3116 (nan)	mem 8925MB
[2022-04-08 07:51:34 large] (main.py 226): INFO Train: [175/300][2300/2502]	eta 0:02:03 lr 0.000186	time 0.7956 (0.6097)	loss 3.2085 (3.2421)	grad_norm 3.4946 (nan)	mem 8925MB
[2022-04-08 07:52:37 large] (main.py 226): INFO Train: [175/300][2400/2502]	eta 0:01:02 lr 0.000186	time 0.5849 (0.6107)	loss 3.7157 (3.2432)	grad_norm 3.1325 (nan)	mem 8925MB
[2022-04-08 07:53:40 large] (main.py 226): INFO Train: [175/300][2500/2502]	eta 0:00:01 lr 0.000186	time 0.6975 (0.6112)	loss 3.7884 (3.2453)	grad_norm 4.2440 (nan)	mem 8925MB
[2022-04-08 07:53:41 large] (main.py 233): INFO EPOCH 175 training takes 0:25:29
[2022-04-08 07:53:47 large] (main.py 273): INFO Test: [0/98]	Time 6.418 (6.418)	Loss 1.1655 (1.1655)	Acc@1 77.148 (77.148)	Acc@5 94.141 (94.141)	Mem 8925MB
[2022-04-08 07:54:13 large] (main.py 279): INFO  * Acc@1 78.334 Acc@5 94.326
[2022-04-08 07:54:13 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 78.3%
[2022-04-08 07:54:13 large] (main.py 148): INFO Max accuracy: 78.61%
[2022-04-08 07:54:20 large] (main.py 226): INFO Train: [176/300][0/2502]	eta 5:02:31 lr 0.000186	time 7.2546 (7.2546)	loss 3.1278 (3.1278)	grad_norm 3.9540 (3.9540)	mem 8925MB
[2022-04-08 07:55:16 large] (main.py 226): INFO Train: [176/300][100/2502]	eta 0:24:49 lr 0.000186	time 0.6563 (0.6201)	loss 3.2136 (3.3439)	grad_norm 5.9127 (4.7354)	mem 8925MB
[2022-04-08 07:56:20 large] (main.py 226): INFO Train: [176/300][200/2502]	eta 0:24:10 lr 0.000186	time 0.6722 (0.6300)	loss 3.1833 (3.3117)	grad_norm 4.8040 (4.5992)	mem 8925MB
[2022-04-08 07:57:23 large] (main.py 226): INFO Train: [176/300][300/2502]	eta 0:23:11 lr 0.000186	time 0.6132 (0.6319)	loss 3.7043 (3.2797)	grad_norm 3.0673 (4.5454)	mem 8925MB
[2022-04-08 07:58:27 large] (main.py 226): INFO Train: [176/300][400/2502]	eta 0:22:11 lr 0.000186	time 0.5693 (0.6335)	loss 2.4845 (3.2549)	grad_norm 4.3736 (4.5257)	mem 8925MB
[2022-04-08 07:59:29 large] (main.py 226): INFO Train: [176/300][500/2502]	eta 0:21:03 lr 0.000185	time 0.6650 (0.6312)	loss 3.5519 (3.2554)	grad_norm 3.2453 (4.5025)	mem 8925MB
[2022-04-08 08:00:33 large] (main.py 226): INFO Train: [176/300][600/2502]	eta 0:20:01 lr 0.000185	time 0.6390 (0.6316)	loss 2.9316 (3.2488)	grad_norm 4.6721 (4.5315)	mem 8925MB
[2022-04-08 08:01:35 large] (main.py 226): INFO Train: [176/300][700/2502]	eta 0:18:55 lr 0.000185	time 0.6014 (0.6301)	loss 3.7516 (3.2450)	grad_norm 4.0130 (4.5230)	mem 8925MB
[2022-04-08 08:02:37 large] (main.py 226): INFO Train: [176/300][800/2502]	eta 0:17:51 lr 0.000185	time 0.6271 (0.6294)	loss 3.5940 (3.2555)	grad_norm 5.1322 (4.5051)	mem 8925MB
[2022-04-08 08:03:40 large] (main.py 226): INFO Train: [176/300][900/2502]	eta 0:16:47 lr 0.000185	time 0.6208 (0.6290)	loss 3.5342 (3.2515)	grad_norm 4.8839 (4.4831)	mem 8925MB
[2022-04-08 08:04:42 large] (main.py 226): INFO Train: [176/300][1000/2502]	eta 0:15:43 lr 0.000185	time 0.6330 (0.6282)	loss 3.8402 (3.2482)	grad_norm 5.2609 (4.4799)	mem 8925MB
[2022-04-08 08:05:45 large] (main.py 226): INFO Train: [176/300][1100/2502]	eta 0:14:40 lr 0.000185	time 0.6285 (0.6283)	loss 1.9575 (3.2470)	grad_norm 4.9452 (4.4945)	mem 8925MB
[2022-04-08 08:06:47 large] (main.py 226): INFO Train: [176/300][1200/2502]	eta 0:13:37 lr 0.000185	time 0.6233 (0.6277)	loss 3.5287 (3.2531)	grad_norm 4.2899 (4.4959)	mem 8925MB
[2022-04-08 08:07:50 large] (main.py 226): INFO Train: [176/300][1300/2502]	eta 0:12:34 lr 0.000185	time 0.6509 (0.6280)	loss 3.4838 (3.2581)	grad_norm 3.6085 (4.5093)	mem 8925MB
[2022-04-08 08:08:52 large] (main.py 226): INFO Train: [176/300][1400/2502]	eta 0:11:31 lr 0.000185	time 0.5535 (0.6275)	loss 3.9085 (3.2514)	grad_norm 3.2407 (4.4993)	mem 8925MB
[2022-04-08 08:09:55 large] (main.py 226): INFO Train: [176/300][1500/2502]	eta 0:10:29 lr 0.000184	time 0.6002 (0.6279)	loss 2.0536 (3.2514)	grad_norm 3.2694 (4.4951)	mem 8925MB
[2022-04-08 08:10:58 large] (main.py 226): INFO Train: [176/300][1600/2502]	eta 0:09:26 lr 0.000184	time 0.6498 (0.6276)	loss 2.3082 (3.2498)	grad_norm 5.3705 (4.4957)	mem 8925MB
[2022-04-08 08:12:01 large] (main.py 226): INFO Train: [176/300][1700/2502]	eta 0:08:23 lr 0.000184	time 0.7333 (0.6276)	loss 3.7642 (3.2502)	grad_norm 5.3617 (4.5025)	mem 8925MB
[2022-04-08 08:13:03 large] (main.py 226): INFO Train: [176/300][1800/2502]	eta 0:07:20 lr 0.000184	time 0.7010 (0.6276)	loss 2.6055 (3.2480)	grad_norm 4.2454 (4.5024)	mem 8925MB
[2022-04-08 08:14:05 large] (main.py 226): INFO Train: [176/300][1900/2502]	eta 0:06:17 lr 0.000184	time 0.5946 (0.6271)	loss 3.4752 (3.2478)	grad_norm 5.3801 (4.5124)	mem 8925MB
[2022-04-08 08:15:07 large] (main.py 226): INFO Train: [176/300][2000/2502]	eta 0:05:14 lr 0.000184	time 0.6174 (0.6266)	loss 3.8893 (3.2470)	grad_norm 3.9265 (4.5149)	mem 8925MB
[2022-04-08 08:16:09 large] (main.py 226): INFO Train: [176/300][2100/2502]	eta 0:04:11 lr 0.000184	time 0.6106 (0.6265)	loss 3.6123 (3.2495)	grad_norm 5.4178 (4.5153)	mem 8925MB
[2022-04-08 08:17:11 large] (main.py 226): INFO Train: [176/300][2200/2502]	eta 0:03:09 lr 0.000184	time 0.5848 (0.6263)	loss 2.7531 (3.2536)	grad_norm 4.5787 (4.5108)	mem 8925MB
[2022-04-08 08:18:14 large] (main.py 226): INFO Train: [176/300][2300/2502]	eta 0:02:06 lr 0.000184	time 0.6425 (0.6263)	loss 3.2531 (3.2525)	grad_norm 3.4814 (4.4988)	mem 8925MB
[2022-04-08 08:19:17 large] (main.py 226): INFO Train: [176/300][2400/2502]	eta 0:01:03 lr 0.000184	time 0.6624 (0.6263)	loss 3.5136 (3.2495)	grad_norm 4.4256 (4.5107)	mem 8925MB
[2022-04-08 08:20:19 large] (main.py 226): INFO Train: [176/300][2500/2502]	eta 0:00:01 lr 0.000183	time 0.6130 (0.6263)	loss 2.5560 (3.2528)	grad_norm 4.5553 (4.5026)	mem 8925MB
[2022-04-08 08:20:21 large] (main.py 233): INFO EPOCH 176 training takes 0:26:07
[2022-04-08 08:20:27 large] (main.py 273): INFO Test: [0/98]	Time 6.071 (6.071)	Loss 1.2592 (1.2592)	Acc@1 74.023 (74.023)	Acc@5 93.164 (93.164)	Mem 8925MB
[2022-04-08 08:20:53 large] (main.py 279): INFO  * Acc@1 78.474 Acc@5 94.386
[2022-04-08 08:20:53 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 78.5%
[2022-04-08 08:20:53 large] (main.py 148): INFO Max accuracy: 78.61%
[2022-04-08 08:20:59 large] (main.py 226): INFO Train: [177/300][0/2502]	eta 4:26:15 lr 0.000183	time 6.3850 (6.3850)	loss 3.6568 (3.6568)	grad_norm 3.5720 (3.5720)	mem 8925MB
[2022-04-08 08:21:55 large] (main.py 226): INFO Train: [177/300][100/2502]	eta 0:24:31 lr 0.000183	time 0.6148 (0.6128)	loss 3.8336 (3.1746)	grad_norm 4.3041 (4.4720)	mem 8925MB
[2022-04-08 08:22:57 large] (main.py 226): INFO Train: [177/300][200/2502]	eta 0:23:39 lr 0.000183	time 0.6971 (0.6167)	loss 3.4696 (3.2103)	grad_norm 4.4634 (4.3826)	mem 8925MB
[2022-04-08 08:24:00 large] (main.py 226): INFO Train: [177/300][300/2502]	eta 0:22:49 lr 0.000183	time 0.7622 (0.6220)	loss 3.2681 (3.2388)	grad_norm 4.0642 (4.4562)	mem 8925MB
[2022-04-08 08:25:04 large] (main.py 226): INFO Train: [177/300][400/2502]	eta 0:21:56 lr 0.000183	time 0.6350 (0.6261)	loss 3.5299 (3.2325)	grad_norm 3.9627 (4.4771)	mem 8925MB
[2022-04-08 08:26:07 large] (main.py 226): INFO Train: [177/300][500/2502]	eta 0:20:53 lr 0.000183	time 0.6400 (0.6262)	loss 3.7067 (3.2370)	grad_norm 4.7782 (4.5028)	mem 8925MB
[2022-04-08 08:27:10 large] (main.py 226): INFO Train: [177/300][600/2502]	eta 0:19:53 lr 0.000183	time 0.5656 (0.6276)	loss 2.7246 (3.2280)	grad_norm 5.1849 (4.4731)	mem 8925MB
[2022-04-08 08:28:12 large] (main.py 226): INFO Train: [177/300][700/2502]	eta 0:18:48 lr 0.000183	time 0.6241 (0.6264)	loss 2.9088 (3.2366)	grad_norm 4.3733 (4.4612)	mem 8925MB
[2022-04-08 08:29:15 large] (main.py 226): INFO Train: [177/300][800/2502]	eta 0:17:45 lr 0.000183	time 0.5964 (0.6263)	loss 3.9782 (3.2306)	grad_norm 4.4358 (4.4366)	mem 8925MB
[2022-04-08 08:30:17 large] (main.py 226): INFO Train: [177/300][900/2502]	eta 0:16:42 lr 0.000183	time 0.5927 (0.6260)	loss 3.5855 (3.2393)	grad_norm 3.4392 (4.4258)	mem 8925MB
[2022-04-08 08:31:19 large] (main.py 226): INFO Train: [177/300][1000/2502]	eta 0:15:39 lr 0.000182	time 0.7832 (0.6258)	loss 3.6051 (3.2492)	grad_norm 3.1234 (4.4124)	mem 8925MB
[2022-04-08 08:32:22 large] (main.py 226): INFO Train: [177/300][1100/2502]	eta 0:14:37 lr 0.000182	time 0.7510 (0.6262)	loss 2.4006 (3.2512)	grad_norm 3.8870 (nan)	mem 8925MB
[2022-04-08 08:33:26 large] (main.py 226): INFO Train: [177/300][1200/2502]	eta 0:13:35 lr 0.000182	time 0.6608 (0.6266)	loss 2.5691 (3.2482)	grad_norm 3.7428 (nan)	mem 8925MB
[2022-04-08 08:34:29 large] (main.py 226): INFO Train: [177/300][1300/2502]	eta 0:12:33 lr 0.000182	time 0.6102 (0.6272)	loss 3.6374 (3.2547)	grad_norm 4.9279 (nan)	mem 8925MB
[2022-04-08 08:35:32 large] (main.py 226): INFO Train: [177/300][1400/2502]	eta 0:11:31 lr 0.000182	time 0.6729 (0.6276)	loss 3.5108 (3.2592)	grad_norm 4.4047 (nan)	mem 8925MB
[2022-04-08 08:36:35 large] (main.py 226): INFO Train: [177/300][1500/2502]	eta 0:10:28 lr 0.000182	time 0.5520 (0.6273)	loss 3.6241 (3.2537)	grad_norm 3.6908 (nan)	mem 8925MB
[2022-04-08 08:37:37 large] (main.py 226): INFO Train: [177/300][1600/2502]	eta 0:09:25 lr 0.000182	time 0.6480 (0.6271)	loss 2.9680 (3.2546)	grad_norm 5.0164 (nan)	mem 8925MB
[2022-04-08 08:38:39 large] (main.py 226): INFO Train: [177/300][1700/2502]	eta 0:08:22 lr 0.000182	time 0.6160 (0.6267)	loss 3.5200 (3.2525)	grad_norm 3.5548 (nan)	mem 8925MB
[2022-04-08 08:39:42 large] (main.py 226): INFO Train: [177/300][1800/2502]	eta 0:07:19 lr 0.000182	time 0.5255 (0.6266)	loss 3.5282 (3.2530)	grad_norm 3.5650 (nan)	mem 8925MB
[2022-04-08 08:40:44 large] (main.py 226): INFO Train: [177/300][1900/2502]	eta 0:06:17 lr 0.000182	time 0.5544 (0.6266)	loss 2.3670 (3.2496)	grad_norm 3.9865 (nan)	mem 8925MB
[2022-04-08 08:41:46 large] (main.py 226): INFO Train: [177/300][2000/2502]	eta 0:05:14 lr 0.000181	time 0.7571 (0.6264)	loss 2.9173 (3.2446)	grad_norm 3.8390 (nan)	mem 8925MB
[2022-04-08 08:42:50 large] (main.py 226): INFO Train: [177/300][2100/2502]	eta 0:04:11 lr 0.000181	time 0.6409 (0.6267)	loss 3.5183 (3.2428)	grad_norm 3.4577 (nan)	mem 8925MB
[2022-04-08 08:43:53 large] (main.py 226): INFO Train: [177/300][2200/2502]	eta 0:03:09 lr 0.000181	time 0.6316 (0.6271)	loss 3.9863 (3.2454)	grad_norm 4.7392 (nan)	mem 8926MB
[2022-04-08 08:44:56 large] (main.py 226): INFO Train: [177/300][2300/2502]	eta 0:02:06 lr 0.000181	time 0.7079 (0.6272)	loss 3.3158 (3.2468)	grad_norm 6.9790 (nan)	mem 8926MB
[2022-04-08 08:46:00 large] (main.py 226): INFO Train: [177/300][2400/2502]	eta 0:01:04 lr 0.000181	time 0.6288 (0.6275)	loss 3.7065 (3.2464)	grad_norm 3.8461 (nan)	mem 8926MB
[2022-04-08 08:47:02 large] (main.py 226): INFO Train: [177/300][2500/2502]	eta 0:00:01 lr 0.000181	time 0.5768 (0.6274)	loss 3.7293 (3.2465)	grad_norm 4.5741 (nan)	mem 8926MB
[2022-04-08 08:47:03 large] (main.py 233): INFO EPOCH 177 training takes 0:26:10
[2022-04-08 08:47:09 large] (main.py 273): INFO Test: [0/98]	Time 5.721 (5.721)	Loss 1.1064 (1.1064)	Acc@1 78.711 (78.711)	Acc@5 94.727 (94.727)	Mem 8926MB
[2022-04-08 08:47:36 large] (main.py 279): INFO  * Acc@1 78.330 Acc@5 94.162
[2022-04-08 08:47:36 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 78.3%
[2022-04-08 08:47:36 large] (main.py 148): INFO Max accuracy: 78.61%
[2022-04-08 08:47:43 large] (main.py 226): INFO Train: [178/300][0/2502]	eta 5:11:18 lr 0.000181	time 7.4654 (7.4654)	loss 2.2718 (2.2718)	grad_norm 5.2087 (5.2087)	mem 8926MB
[2022-04-08 08:48:34 large] (main.py 226): INFO Train: [178/300][100/2502]	eta 0:22:52 lr 0.000181	time 0.4850 (0.5715)	loss 3.7431 (3.1767)	grad_norm 4.5488 (4.4451)	mem 8926MB
[2022-04-08 08:49:32 large] (main.py 226): INFO Train: [178/300][200/2502]	eta 0:22:05 lr 0.000181	time 0.7452 (0.5760)	loss 3.1489 (3.2177)	grad_norm 5.9532 (4.3388)	mem 8926MB
[2022-04-08 08:50:37 large] (main.py 226): INFO Train: [178/300][300/2502]	eta 0:22:03 lr 0.000181	time 0.6560 (0.6012)	loss 3.5105 (3.1983)	grad_norm 3.6623 (4.3691)	mem 8926MB
[2022-04-08 08:51:41 large] (main.py 226): INFO Train: [178/300][400/2502]	eta 0:21:26 lr 0.000181	time 0.5489 (0.6122)	loss 3.7541 (3.2134)	grad_norm 4.1651 (4.3738)	mem 8926MB
[2022-04-08 08:52:46 large] (main.py 226): INFO Train: [178/300][500/2502]	eta 0:20:38 lr 0.000180	time 0.6438 (0.6189)	loss 3.7522 (3.2077)	grad_norm 4.1036 (4.3964)	mem 8926MB
[2022-04-08 08:53:50 large] (main.py 226): INFO Train: [178/300][600/2502]	eta 0:19:42 lr 0.000180	time 0.6660 (0.6219)	loss 3.5166 (3.2058)	grad_norm 4.4664 (4.3870)	mem 8926MB
[2022-04-08 08:54:53 large] (main.py 226): INFO Train: [178/300][700/2502]	eta 0:18:44 lr 0.000180	time 0.7023 (0.6241)	loss 3.6505 (3.2108)	grad_norm 4.6029 (4.3964)	mem 8926MB
[2022-04-08 08:55:57 large] (main.py 226): INFO Train: [178/300][800/2502]	eta 0:17:45 lr 0.000180	time 0.6344 (0.6261)	loss 2.6168 (3.2151)	grad_norm 3.7229 (4.4121)	mem 8926MB
[2022-04-08 08:57:01 large] (main.py 226): INFO Train: [178/300][900/2502]	eta 0:16:43 lr 0.000180	time 0.6381 (0.6267)	loss 3.2316 (3.2187)	grad_norm 4.4660 (4.4076)	mem 8926MB
[2022-04-08 08:58:03 large] (main.py 226): INFO Train: [178/300][1000/2502]	eta 0:15:41 lr 0.000180	time 0.5577 (0.6267)	loss 3.6207 (3.2235)	grad_norm 4.4222 (4.4142)	mem 8926MB
[2022-04-08 08:59:07 large] (main.py 226): INFO Train: [178/300][1100/2502]	eta 0:14:39 lr 0.000180	time 0.6818 (0.6273)	loss 3.3803 (3.2325)	grad_norm 3.7553 (4.4262)	mem 8926MB
[2022-04-08 09:00:09 large] (main.py 226): INFO Train: [178/300][1200/2502]	eta 0:13:36 lr 0.000180	time 0.5326 (0.6275)	loss 2.9347 (3.2319)	grad_norm 4.9190 (4.4230)	mem 8926MB
[2022-04-08 09:01:15 large] (main.py 226): INFO Train: [178/300][1300/2502]	eta 0:12:36 lr 0.000180	time 0.6102 (0.6293)	loss 2.9699 (3.2384)	grad_norm 5.0501 (4.4143)	mem 8926MB
[2022-04-08 09:02:18 large] (main.py 226): INFO Train: [178/300][1400/2502]	eta 0:11:33 lr 0.000180	time 0.5612 (0.6296)	loss 3.1324 (3.2357)	grad_norm 3.7200 (4.4112)	mem 8926MB
[2022-04-08 09:03:19 large] (main.py 226): INFO Train: [178/300][1500/2502]	eta 0:10:29 lr 0.000179	time 0.5640 (0.6283)	loss 3.5347 (3.2380)	grad_norm 3.5486 (4.4046)	mem 8926MB
[2022-04-08 09:04:10 large] (main.py 226): INFO Train: [178/300][1600/2502]	eta 0:09:19 lr 0.000179	time 0.5321 (0.6206)	loss 4.0071 (3.2373)	grad_norm 5.5772 (4.4088)	mem 8926MB
[2022-04-08 09:05:03 large] (main.py 226): INFO Train: [178/300][1700/2502]	eta 0:08:13 lr 0.000179	time 0.5506 (0.6157)	loss 2.3598 (3.2332)	grad_norm 4.1007 (4.4059)	mem 8926MB
[2022-04-08 09:05:55 large] (main.py 226): INFO Train: [178/300][1800/2502]	eta 0:07:08 lr 0.000179	time 0.5102 (0.6101)	loss 3.7431 (3.2353)	grad_norm 4.3865 (nan)	mem 8926MB
[2022-04-08 09:06:46 large] (main.py 226): INFO Train: [178/300][1900/2502]	eta 0:06:04 lr 0.000179	time 0.5126 (0.6051)	loss 3.8065 (3.2343)	grad_norm 5.7484 (nan)	mem 8926MB
[2022-04-08 09:07:37 large] (main.py 226): INFO Train: [178/300][2000/2502]	eta 0:05:01 lr 0.000179	time 0.4986 (0.6003)	loss 2.5936 (3.2373)	grad_norm 3.9384 (nan)	mem 8926MB
[2022-04-08 09:08:26 large] (main.py 226): INFO Train: [178/300][2100/2502]	eta 0:03:59 lr 0.000179	time 0.4620 (0.5952)	loss 3.0666 (3.2360)	grad_norm 5.3525 (nan)	mem 8926MB
[2022-04-08 09:09:16 large] (main.py 226): INFO Train: [178/300][2200/2502]	eta 0:02:58 lr 0.000179	time 0.4878 (0.5908)	loss 3.5793 (3.2392)	grad_norm 5.5294 (nan)	mem 8926MB
[2022-04-08 09:10:04 large] (main.py 226): INFO Train: [178/300][2300/2502]	eta 0:01:58 lr 0.000179	time 0.4832 (0.5858)	loss 3.8716 (3.2385)	grad_norm 4.4080 (nan)	mem 8926MB
[2022-04-08 09:10:52 large] (main.py 226): INFO Train: [178/300][2400/2502]	eta 0:00:59 lr 0.000179	time 0.4827 (0.5814)	loss 2.4764 (3.2364)	grad_norm 4.7425 (nan)	mem 8926MB
[2022-04-08 09:11:41 large] (main.py 226): INFO Train: [178/300][2500/2502]	eta 0:00:01 lr 0.000178	time 0.4602 (0.5777)	loss 3.7070 (3.2352)	grad_norm 6.2752 (nan)	mem 8926MB
[2022-04-08 09:11:42 large] (main.py 233): INFO EPOCH 178 training takes 0:24:05
[2022-04-08 09:11:47 large] (main.py 273): INFO Test: [0/98]	Time 5.460 (5.460)	Loss 1.0765 (1.0765)	Acc@1 76.562 (76.562)	Acc@5 94.922 (94.922)	Mem 8926MB
[2022-04-08 09:12:14 large] (main.py 279): INFO  * Acc@1 78.528 Acc@5 94.406
[2022-04-08 09:12:14 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 78.5%
[2022-04-08 09:12:14 large] (main.py 148): INFO Max accuracy: 78.61%
[2022-04-08 09:12:21 large] (main.py 226): INFO Train: [179/300][0/2502]	eta 5:14:17 lr 0.000178	time 7.5368 (7.5368)	loss 3.3267 (3.3267)	grad_norm 5.0565 (5.0565)	mem 8926MB
[2022-04-08 09:13:11 large] (main.py 226): INFO Train: [179/300][100/2502]	eta 0:22:34 lr 0.000178	time 0.4788 (0.5641)	loss 2.6772 (3.3040)	grad_norm 5.1606 (4.5889)	mem 8926MB
[2022-04-08 09:14:01 large] (main.py 226): INFO Train: [179/300][200/2502]	eta 0:20:26 lr 0.000178	time 0.5482 (0.5330)	loss 2.6910 (3.2813)	grad_norm 5.1436 (4.5657)	mem 8926MB
[2022-04-08 09:14:53 large] (main.py 226): INFO Train: [179/300][300/2502]	eta 0:19:21 lr 0.000178	time 0.5025 (0.5274)	loss 2.6591 (3.2762)	grad_norm 4.0283 (4.5746)	mem 8926MB
[2022-04-08 09:15:42 large] (main.py 226): INFO Train: [179/300][400/2502]	eta 0:18:11 lr 0.000178	time 0.5262 (0.5194)	loss 3.5139 (3.2548)	grad_norm 3.9355 (4.5896)	mem 8926MB
[2022-04-08 09:16:34 large] (main.py 226): INFO Train: [179/300][500/2502]	eta 0:17:17 lr 0.000178	time 0.5106 (0.5184)	loss 3.3179 (3.2445)	grad_norm 3.9197 (4.5694)	mem 8926MB
[2022-04-08 09:17:25 large] (main.py 226): INFO Train: [179/300][600/2502]	eta 0:16:24 lr 0.000178	time 0.5020 (0.5175)	loss 3.6877 (3.2353)	grad_norm 4.6209 (4.5621)	mem 8926MB
[2022-04-08 09:18:16 large] (main.py 226): INFO Train: [179/300][700/2502]	eta 0:15:31 lr 0.000178	time 0.5485 (0.5170)	loss 2.6251 (3.2411)	grad_norm 3.5891 (4.5678)	mem 8926MB
[2022-04-08 09:19:07 large] (main.py 226): INFO Train: [179/300][800/2502]	eta 0:14:38 lr 0.000178	time 0.4809 (0.5160)	loss 3.5727 (3.2392)	grad_norm 6.2560 (4.5478)	mem 8926MB
[2022-04-08 09:19:57 large] (main.py 226): INFO Train: [179/300][900/2502]	eta 0:13:43 lr 0.000178	time 0.5286 (0.5138)	loss 3.4506 (3.2408)	grad_norm 3.8629 (4.5843)	mem 8926MB
[2022-04-08 09:20:48 large] (main.py 226): INFO Train: [179/300][1000/2502]	eta 0:12:50 lr 0.000177	time 0.4952 (0.5132)	loss 3.1390 (3.2394)	grad_norm 3.6748 (4.5721)	mem 8926MB
[2022-04-08 09:21:38 large] (main.py 226): INFO Train: [179/300][1100/2502]	eta 0:11:58 lr 0.000177	time 0.4989 (0.5128)	loss 3.5838 (3.2416)	grad_norm 4.4277 (4.5622)	mem 8926MB
[2022-04-08 09:22:29 large] (main.py 226): INFO Train: [179/300][1200/2502]	eta 0:11:07 lr 0.000177	time 0.5060 (0.5125)	loss 2.8817 (3.2410)	grad_norm 4.8600 (4.5549)	mem 8926MB
[2022-04-08 09:23:19 large] (main.py 226): INFO Train: [179/300][1300/2502]	eta 0:10:14 lr 0.000177	time 0.5219 (0.5111)	loss 3.8597 (3.2426)	grad_norm 3.8176 (4.5512)	mem 8926MB
[2022-04-08 09:24:07 large] (main.py 226): INFO Train: [179/300][1400/2502]	eta 0:09:21 lr 0.000177	time 0.4683 (0.5093)	loss 3.2585 (3.2444)	grad_norm 3.8277 (4.5573)	mem 8926MB
[2022-04-08 09:24:57 large] (main.py 226): INFO Train: [179/300][1500/2502]	eta 0:08:29 lr 0.000177	time 0.5027 (0.5086)	loss 3.3073 (3.2499)	grad_norm 4.1228 (4.5588)	mem 8926MB
[2022-04-08 09:25:46 large] (main.py 226): INFO Train: [179/300][1600/2502]	eta 0:07:37 lr 0.000177	time 0.5066 (0.5075)	loss 2.6755 (3.2469)	grad_norm 4.0106 (4.5672)	mem 8926MB
[2022-04-08 09:26:38 large] (main.py 226): INFO Train: [179/300][1700/2502]	eta 0:06:47 lr 0.000177	time 0.5028 (0.5078)	loss 3.5523 (3.2462)	grad_norm 4.4699 (4.5576)	mem 8926MB
[2022-04-08 09:27:29 large] (main.py 226): INFO Train: [179/300][1800/2502]	eta 0:05:56 lr 0.000177	time 0.5001 (0.5079)	loss 3.4872 (3.2431)	grad_norm 5.6486 (4.5516)	mem 8926MB
[2022-04-08 09:28:20 large] (main.py 226): INFO Train: [179/300][1900/2502]	eta 0:05:05 lr 0.000177	time 0.4665 (0.5081)	loss 3.4263 (3.2427)	grad_norm 4.7184 (4.5562)	mem 8926MB
[2022-04-08 09:29:11 large] (main.py 226): INFO Train: [179/300][2000/2502]	eta 0:04:15 lr 0.000177	time 0.5022 (0.5082)	loss 3.3222 (3.2425)	grad_norm 5.2509 (4.5501)	mem 8926MB
[2022-04-08 09:30:02 large] (main.py 226): INFO Train: [179/300][2100/2502]	eta 0:03:24 lr 0.000176	time 0.4793 (0.5083)	loss 3.1626 (3.2423)	grad_norm 3.5874 (4.5430)	mem 8926MB
[2022-04-08 09:30:52 large] (main.py 226): INFO Train: [179/300][2200/2502]	eta 0:02:33 lr 0.000176	time 0.4883 (0.5078)	loss 2.0882 (3.2360)	grad_norm 4.0895 (4.5342)	mem 8926MB
[2022-04-08 09:31:42 large] (main.py 226): INFO Train: [179/300][2300/2502]	eta 0:01:42 lr 0.000176	time 0.5067 (0.5076)	loss 3.3661 (3.2368)	grad_norm 6.5908 (4.5463)	mem 8926MB
[2022-04-08 09:32:33 large] (main.py 226): INFO Train: [179/300][2400/2502]	eta 0:00:51 lr 0.000176	time 0.4890 (0.5076)	loss 4.1866 (3.2342)	grad_norm 4.7029 (4.5497)	mem 8926MB
[2022-04-08 09:33:23 large] (main.py 226): INFO Train: [179/300][2500/2502]	eta 0:00:01 lr 0.000176	time 0.4976 (0.5076)	loss 2.2245 (3.2317)	grad_norm 5.3317 (4.5508)	mem 8926MB
[2022-04-08 09:33:24 large] (main.py 233): INFO EPOCH 179 training takes 0:21:10
[2022-04-08 09:33:31 large] (main.py 273): INFO Test: [0/98]	Time 6.888 (6.888)	Loss 1.1017 (1.1017)	Acc@1 77.344 (77.344)	Acc@5 93.555 (93.555)	Mem 8926MB
[2022-04-08 09:33:57 large] (main.py 279): INFO  * Acc@1 78.578 Acc@5 94.348
[2022-04-08 09:33:57 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 78.6%
[2022-04-08 09:33:57 large] (main.py 148): INFO Max accuracy: 78.61%
[2022-04-08 09:34:04 large] (main.py 226): INFO Train: [180/300][0/2502]	eta 5:12:41 lr 0.000176	time 7.4986 (7.4986)	loss 3.5766 (3.5766)	grad_norm 3.6971 (3.6971)	mem 8926MB
[2022-04-08 09:34:54 large] (main.py 226): INFO Train: [180/300][100/2502]	eta 0:22:44 lr 0.000176	time 0.4731 (0.5682)	loss 3.2483 (3.2701)	grad_norm 4.9301 (nan)	mem 8926MB
[2022-04-08 09:35:42 large] (main.py 226): INFO Train: [180/300][200/2502]	eta 0:20:12 lr 0.000176	time 0.5037 (0.5266)	loss 3.5044 (3.2575)	grad_norm 5.1293 (nan)	mem 8926MB
[2022-04-08 09:36:31 large] (main.py 226): INFO Train: [180/300][300/2502]	eta 0:18:47 lr 0.000176	time 0.4770 (0.5120)	loss 3.6528 (3.2350)	grad_norm 3.6103 (nan)	mem 8926MB
[2022-04-08 09:37:21 large] (main.py 226): INFO Train: [180/300][400/2502]	eta 0:17:51 lr 0.000176	time 0.5714 (0.5098)	loss 2.1458 (3.2464)	grad_norm 4.7936 (nan)	mem 8926MB
[2022-04-08 09:38:13 large] (main.py 226): INFO Train: [180/300][500/2502]	eta 0:17:04 lr 0.000176	time 0.5013 (0.5118)	loss 3.6534 (3.2436)	grad_norm 3.5809 (nan)	mem 8926MB
[2022-04-08 09:39:05 large] (main.py 226): INFO Train: [180/300][600/2502]	eta 0:16:16 lr 0.000175	time 0.5238 (0.5133)	loss 3.1066 (3.2466)	grad_norm 3.6899 (nan)	mem 8926MB
[2022-04-08 09:39:56 large] (main.py 226): INFO Train: [180/300][700/2502]	eta 0:15:24 lr 0.000175	time 0.5087 (0.5130)	loss 3.5497 (3.2482)	grad_norm 3.8145 (nan)	mem 8926MB
[2022-04-08 09:40:48 large] (main.py 226): INFO Train: [180/300][800/2502]	eta 0:14:33 lr 0.000175	time 0.5010 (0.5130)	loss 2.0177 (3.2348)	grad_norm 6.3385 (nan)	mem 8926MB
[2022-04-08 09:41:39 large] (main.py 226): INFO Train: [180/300][900/2502]	eta 0:13:42 lr 0.000175	time 0.5263 (0.5131)	loss 1.8606 (3.2315)	grad_norm 2.9952 (nan)	mem 8926MB
[2022-04-08 09:42:30 large] (main.py 226): INFO Train: [180/300][1000/2502]	eta 0:12:50 lr 0.000175	time 0.4964 (0.5131)	loss 3.7098 (3.2361)	grad_norm 4.3097 (nan)	mem 8926MB
[2022-04-08 09:43:20 large] (main.py 226): INFO Train: [180/300][1100/2502]	eta 0:11:57 lr 0.000175	time 0.4707 (0.5120)	loss 3.6482 (3.2247)	grad_norm 5.0029 (nan)	mem 8926MB
[2022-04-08 09:44:10 large] (main.py 226): INFO Train: [180/300][1200/2502]	eta 0:11:05 lr 0.000175	time 0.5511 (0.5111)	loss 3.7698 (3.2204)	grad_norm 4.9273 (nan)	mem 8926MB
[2022-04-08 09:45:01 large] (main.py 226): INFO Train: [180/300][1300/2502]	eta 0:10:14 lr 0.000175	time 0.5051 (0.5109)	loss 3.5500 (3.2255)	grad_norm 4.3437 (nan)	mem 8926MB
[2022-04-08 09:45:52 large] (main.py 226): INFO Train: [180/300][1400/2502]	eta 0:09:22 lr 0.000175	time 0.4839 (0.5108)	loss 3.9011 (3.2255)	grad_norm 4.8509 (nan)	mem 8926MB
[2022-04-08 09:46:43 large] (main.py 226): INFO Train: [180/300][1500/2502]	eta 0:08:31 lr 0.000175	time 0.5084 (0.5106)	loss 3.9381 (3.2243)	grad_norm 5.1815 (nan)	mem 8926MB
[2022-04-08 09:47:34 large] (main.py 226): INFO Train: [180/300][1600/2502]	eta 0:07:40 lr 0.000174	time 0.5554 (0.5105)	loss 3.8868 (3.2311)	grad_norm 4.4353 (nan)	mem 8926MB
[2022-04-08 09:48:25 large] (main.py 226): INFO Train: [180/300][1700/2502]	eta 0:06:49 lr 0.000174	time 0.5313 (0.5103)	loss 3.2337 (3.2306)	grad_norm 4.9968 (nan)	mem 8926MB
[2022-04-08 09:49:15 large] (main.py 226): INFO Train: [180/300][1800/2502]	eta 0:05:58 lr 0.000174	time 0.5226 (0.5102)	loss 2.2728 (3.2271)	grad_norm 3.0508 (nan)	mem 8926MB
[2022-04-08 09:50:06 large] (main.py 226): INFO Train: [180/300][1900/2502]	eta 0:05:06 lr 0.000174	time 0.4729 (0.5099)	loss 3.6785 (3.2319)	grad_norm 4.0824 (nan)	mem 8926MB
[2022-04-08 09:50:57 large] (main.py 226): INFO Train: [180/300][2000/2502]	eta 0:04:15 lr 0.000174	time 0.5004 (0.5098)	loss 3.8213 (3.2373)	grad_norm 5.1000 (nan)	mem 8926MB
[2022-04-08 09:51:47 large] (main.py 226): INFO Train: [180/300][2100/2502]	eta 0:03:24 lr 0.000174	time 0.4968 (0.5096)	loss 3.9363 (3.2414)	grad_norm 4.0872 (nan)	mem 8926MB
[2022-04-08 09:52:36 large] (main.py 226): INFO Train: [180/300][2200/2502]	eta 0:02:33 lr 0.000174	time 0.5147 (0.5088)	loss 3.0228 (3.2354)	grad_norm 5.3126 (nan)	mem 8926MB
[2022-04-08 09:53:25 large] (main.py 226): INFO Train: [180/300][2300/2502]	eta 0:01:42 lr 0.000174	time 0.4816 (0.5080)	loss 2.2004 (3.2340)	grad_norm 4.7226 (nan)	mem 8926MB
[2022-04-08 09:54:16 large] (main.py 226): INFO Train: [180/300][2400/2502]	eta 0:00:51 lr 0.000174	time 0.4474 (0.5079)	loss 3.6987 (3.2347)	grad_norm 5.5815 (nan)	mem 8926MB
[2022-04-08 09:55:05 large] (main.py 226): INFO Train: [180/300][2500/2502]	eta 0:00:01 lr 0.000174	time 0.4915 (0.5073)	loss 3.4101 (3.2350)	grad_norm 4.1020 (nan)	mem 8926MB
[2022-04-08 09:55:06 large] (main.py 233): INFO EPOCH 180 training takes 0:21:09
[2022-04-08 09:55:13 large] (main.py 273): INFO Test: [0/98]	Time 6.493 (6.493)	Loss 1.1199 (1.1199)	Acc@1 78.906 (78.906)	Acc@5 94.141 (94.141)	Mem 8926MB
[2022-04-08 09:55:39 large] (main.py 279): INFO  * Acc@1 78.360 Acc@5 94.388
[2022-04-08 09:55:39 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 78.4%
[2022-04-08 09:55:39 large] (main.py 148): INFO Max accuracy: 78.61%
[2022-04-08 09:55:46 large] (main.py 226): INFO Train: [181/300][0/2502]	eta 4:50:12 lr 0.000174	time 6.9593 (6.9593)	loss 4.0528 (4.0528)	grad_norm 4.3466 (4.3466)	mem 8926MB
[2022-04-08 09:56:37 large] (main.py 226): INFO Train: [181/300][100/2502]	eta 0:22:57 lr 0.000173	time 0.5150 (0.5736)	loss 3.1344 (3.1644)	grad_norm 3.9889 (4.5357)	mem 8926MB
[2022-04-08 09:57:25 large] (main.py 226): INFO Train: [181/300][200/2502]	eta 0:20:14 lr 0.000173	time 0.4814 (0.5275)	loss 3.4629 (3.2055)	grad_norm 2.9803 (4.5338)	mem 8926MB
[2022-04-08 09:58:15 large] (main.py 226): INFO Train: [181/300][300/2502]	eta 0:19:00 lr 0.000173	time 0.5055 (0.5180)	loss 3.9548 (3.2223)	grad_norm 4.1801 (4.5257)	mem 8926MB
[2022-04-08 09:59:06 large] (main.py 226): INFO Train: [181/300][400/2502]	eta 0:18:03 lr 0.000173	time 0.4805 (0.5156)	loss 3.3478 (3.2139)	grad_norm 4.2722 (4.5479)	mem 8926MB
[2022-04-08 09:59:55 large] (main.py 226): INFO Train: [181/300][500/2502]	eta 0:17:04 lr 0.000173	time 0.5341 (0.5117)	loss 3.8354 (3.2051)	grad_norm 4.5628 (4.5427)	mem 8926MB
[2022-04-08 10:00:45 large] (main.py 226): INFO Train: [181/300][600/2502]	eta 0:16:07 lr 0.000173	time 0.4834 (0.5089)	loss 3.6612 (3.2129)	grad_norm 3.6971 (4.5448)	mem 8926MB
[2022-04-08 10:01:33 large] (main.py 226): INFO Train: [181/300][700/2502]	eta 0:15:10 lr 0.000173	time 0.4533 (0.5051)	loss 3.0430 (3.2160)	grad_norm 3.2049 (4.5549)	mem 8926MB
[2022-04-08 10:02:21 large] (main.py 226): INFO Train: [181/300][800/2502]	eta 0:14:14 lr 0.000173	time 0.4869 (0.5023)	loss 2.7803 (3.2164)	grad_norm 4.1824 (4.5802)	mem 8926MB
[2022-04-08 10:03:12 large] (main.py 226): INFO Train: [181/300][900/2502]	eta 0:13:25 lr 0.000173	time 0.5057 (0.5028)	loss 3.5554 (3.2267)	grad_norm 3.6232 (4.5896)	mem 8926MB
[2022-04-08 10:04:03 large] (main.py 226): INFO Train: [181/300][1000/2502]	eta 0:12:36 lr 0.000173	time 0.5284 (0.5040)	loss 3.0384 (3.2154)	grad_norm 5.3400 (4.5924)	mem 8926MB
[2022-04-08 10:04:55 large] (main.py 226): INFO Train: [181/300][1100/2502]	eta 0:11:47 lr 0.000172	time 0.5654 (0.5048)	loss 3.0875 (3.2132)	grad_norm 3.8964 (4.6032)	mem 8926MB
[2022-04-08 10:05:44 large] (main.py 226): INFO Train: [181/300][1200/2502]	eta 0:10:56 lr 0.000172	time 0.4965 (0.5039)	loss 2.6897 (3.2176)	grad_norm 7.3110 (4.6140)	mem 8926MB
[2022-04-08 10:06:34 large] (main.py 226): INFO Train: [181/300][1300/2502]	eta 0:10:05 lr 0.000172	time 0.4696 (0.5037)	loss 3.5971 (3.2127)	grad_norm 4.2587 (4.6233)	mem 8926MB
[2022-04-08 10:07:23 large] (main.py 226): INFO Train: [181/300][1400/2502]	eta 0:09:13 lr 0.000172	time 0.4876 (0.5026)	loss 3.6344 (3.2122)	grad_norm 4.8001 (4.6171)	mem 8926MB
[2022-04-08 10:08:12 large] (main.py 226): INFO Train: [181/300][1500/2502]	eta 0:08:22 lr 0.000172	time 0.5089 (0.5018)	loss 3.5924 (3.2150)	grad_norm 3.4916 (4.6104)	mem 8926MB
[2022-04-08 10:09:03 large] (main.py 226): INFO Train: [181/300][1600/2502]	eta 0:07:33 lr 0.000172	time 0.5373 (0.5024)	loss 3.5385 (3.2128)	grad_norm 3.4160 (4.5938)	mem 8926MB
[2022-04-08 10:09:53 large] (main.py 226): INFO Train: [181/300][1700/2502]	eta 0:06:42 lr 0.000172	time 0.5081 (0.5022)	loss 3.6685 (3.2177)	grad_norm 4.0580 (4.6051)	mem 8926MB
[2022-04-08 10:10:42 large] (main.py 226): INFO Train: [181/300][1800/2502]	eta 0:05:52 lr 0.000172	time 0.4935 (0.5015)	loss 3.0152 (3.2166)	grad_norm 3.8136 (4.5954)	mem 8926MB
[2022-04-08 10:11:30 large] (main.py 226): INFO Train: [181/300][1900/2502]	eta 0:05:01 lr 0.000172	time 0.4933 (0.5004)	loss 2.8025 (3.2177)	grad_norm 3.1915 (4.5897)	mem 8926MB
[2022-04-08 10:12:21 large] (main.py 226): INFO Train: [181/300][2000/2502]	eta 0:04:11 lr 0.000172	time 0.4757 (0.5008)	loss 2.3456 (3.2179)	grad_norm 3.7584 (4.5817)	mem 8926MB
[2022-04-08 10:13:12 large] (main.py 226): INFO Train: [181/300][2100/2502]	eta 0:03:21 lr 0.000171	time 0.5621 (0.5014)	loss 3.4303 (3.2161)	grad_norm 4.8370 (4.5763)	mem 8926MB
[2022-04-08 10:14:03 large] (main.py 226): INFO Train: [181/300][2200/2502]	eta 0:02:31 lr 0.000171	time 0.5057 (0.5018)	loss 2.9602 (3.2162)	grad_norm 3.7180 (nan)	mem 8926MB
[2022-04-08 10:14:53 large] (main.py 226): INFO Train: [181/300][2300/2502]	eta 0:01:41 lr 0.000171	time 0.4706 (0.5014)	loss 4.0480 (3.2175)	grad_norm 4.7005 (nan)	mem 8926MB
[2022-04-08 10:15:41 large] (main.py 226): INFO Train: [181/300][2400/2502]	eta 0:00:51 lr 0.000171	time 0.4804 (0.5005)	loss 2.8038 (3.2161)	grad_norm 6.7884 (nan)	mem 8926MB
[2022-04-08 10:16:30 large] (main.py 226): INFO Train: [181/300][2500/2502]	eta 0:00:01 lr 0.000171	time 0.5044 (0.5005)	loss 2.2981 (3.2153)	grad_norm 5.6747 (nan)	mem 8926MB
[2022-04-08 10:16:32 large] (main.py 233): INFO EPOCH 181 training takes 0:20:52
[2022-04-08 10:16:38 large] (main.py 273): INFO Test: [0/98]	Time 6.630 (6.630)	Loss 1.0430 (1.0430)	Acc@1 78.711 (78.711)	Acc@5 94.336 (94.336)	Mem 8926MB
[2022-04-08 10:17:04 large] (main.py 279): INFO  * Acc@1 78.654 Acc@5 94.510
[2022-04-08 10:17:04 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 78.7%
[2022-04-08 10:17:04 large] (utils.py 57): INFO output/large/default/ckpt_epoch_181.pth saving......
[2022-04-08 10:17:05 large] (utils.py 59): INFO output/large/default/ckpt_epoch_181.pth saved !!!
[2022-04-08 10:17:05 large] (main.py 148): INFO Max accuracy: 78.65%
[2022-04-08 10:17:13 large] (main.py 226): INFO Train: [182/300][0/2502]	eta 5:19:35 lr 0.000171	time 7.6641 (7.6641)	loss 3.5726 (3.5726)	grad_norm 3.6487 (3.6487)	mem 8926MB
[2022-04-08 10:18:02 large] (main.py 226): INFO Train: [182/300][100/2502]	eta 0:22:37 lr 0.000171	time 0.4577 (0.5653)	loss 3.1715 (3.2573)	grad_norm 3.7384 (4.4149)	mem 8926MB
[2022-04-08 10:18:52 large] (main.py 226): INFO Train: [182/300][200/2502]	eta 0:20:22 lr 0.000171	time 0.4798 (0.5310)	loss 3.6630 (3.2049)	grad_norm 3.5612 (4.4419)	mem 8926MB
[2022-04-08 10:19:43 large] (main.py 226): INFO Train: [182/300][300/2502]	eta 0:19:13 lr 0.000171	time 0.5678 (0.5241)	loss 2.8345 (3.2014)	grad_norm 4.1959 (4.5646)	mem 8926MB
[2022-04-08 10:20:33 large] (main.py 226): INFO Train: [182/300][400/2502]	eta 0:18:10 lr 0.000171	time 0.4960 (0.5186)	loss 3.3648 (3.1949)	grad_norm 5.3088 (4.5222)	mem 8926MB
[2022-04-08 10:21:24 large] (main.py 226): INFO Train: [182/300][500/2502]	eta 0:17:13 lr 0.000171	time 0.4554 (0.5164)	loss 3.8143 (3.1904)	grad_norm 5.8353 (4.5467)	mem 8926MB
[2022-04-08 10:22:15 large] (main.py 226): INFO Train: [182/300][600/2502]	eta 0:16:21 lr 0.000171	time 0.5069 (0.5159)	loss 3.2981 (3.2084)	grad_norm 3.7402 (4.5745)	mem 8926MB
[2022-04-08 10:23:06 large] (main.py 226): INFO Train: [182/300][700/2502]	eta 0:15:28 lr 0.000170	time 0.4935 (0.5151)	loss 3.4256 (3.2114)	grad_norm 4.0472 (4.5548)	mem 8926MB
[2022-04-08 10:23:57 large] (main.py 226): INFO Train: [182/300][800/2502]	eta 0:14:35 lr 0.000170	time 0.5486 (0.5145)	loss 1.9639 (3.2231)	grad_norm 5.0677 (4.5783)	mem 8926MB
[2022-04-08 10:24:48 large] (main.py 226): INFO Train: [182/300][900/2502]	eta 0:13:43 lr 0.000170	time 0.6379 (0.5141)	loss 2.5560 (3.2250)	grad_norm 4.1285 (4.5726)	mem 8926MB
[2022-04-08 10:25:38 large] (main.py 226): INFO Train: [182/300][1000/2502]	eta 0:12:50 lr 0.000170	time 0.4577 (0.5128)	loss 2.9083 (3.2202)	grad_norm 4.1127 (4.5831)	mem 8926MB
[2022-04-08 10:26:26 large] (main.py 226): INFO Train: [182/300][1100/2502]	eta 0:11:55 lr 0.000170	time 0.4889 (0.5100)	loss 3.7442 (3.2149)	grad_norm 6.4159 (4.6077)	mem 8926MB
[2022-04-08 10:27:17 large] (main.py 226): INFO Train: [182/300][1200/2502]	eta 0:11:03 lr 0.000170	time 0.5131 (0.5095)	loss 3.3153 (3.2111)	grad_norm 4.5319 (4.6087)	mem 8926MB
[2022-04-08 10:28:08 large] (main.py 226): INFO Train: [182/300][1300/2502]	eta 0:10:12 lr 0.000170	time 0.5082 (0.5098)	loss 3.2656 (3.2120)	grad_norm 3.9452 (4.6135)	mem 8926MB
[2022-04-08 10:28:57 large] (main.py 226): INFO Train: [182/300][1400/2502]	eta 0:09:20 lr 0.000170	time 0.4730 (0.5084)	loss 3.7983 (3.2116)	grad_norm 4.1402 (4.6268)	mem 8926MB
[2022-04-08 10:29:46 large] (main.py 226): INFO Train: [182/300][1500/2502]	eta 0:08:27 lr 0.000170	time 0.4922 (0.5069)	loss 3.4176 (3.2099)	grad_norm 4.8791 (4.6437)	mem 8926MB
[2022-04-08 10:30:37 large] (main.py 226): INFO Train: [182/300][1600/2502]	eta 0:07:37 lr 0.000170	time 0.5079 (0.5070)	loss 3.3711 (3.2140)	grad_norm 4.7913 (4.6659)	mem 8926MB
[2022-04-08 10:31:26 large] (main.py 226): INFO Train: [182/300][1700/2502]	eta 0:06:46 lr 0.000169	time 0.4965 (0.5063)	loss 3.1069 (3.2132)	grad_norm 3.0934 (4.6783)	mem 8926MB
[2022-04-08 10:32:17 large] (main.py 226): INFO Train: [182/300][1800/2502]	eta 0:05:55 lr 0.000169	time 0.5068 (0.5066)	loss 2.6992 (3.2120)	grad_norm 5.3138 (4.7000)	mem 8926MB
[2022-04-08 10:33:08 large] (main.py 226): INFO Train: [182/300][1900/2502]	eta 0:05:05 lr 0.000169	time 0.4788 (0.5068)	loss 3.1316 (3.2103)	grad_norm 4.5779 (4.7028)	mem 8926MB
[2022-04-08 10:33:58 large] (main.py 226): INFO Train: [182/300][2000/2502]	eta 0:04:14 lr 0.000169	time 0.4893 (0.5061)	loss 3.7690 (3.2137)	grad_norm 4.7643 (4.6929)	mem 8926MB
[2022-04-08 10:34:48 large] (main.py 226): INFO Train: [182/300][2100/2502]	eta 0:03:23 lr 0.000169	time 0.4842 (0.5061)	loss 3.0285 (3.2167)	grad_norm 4.5326 (4.6963)	mem 8926MB
[2022-04-08 10:35:38 large] (main.py 226): INFO Train: [182/300][2200/2502]	eta 0:02:32 lr 0.000169	time 0.5004 (0.5056)	loss 3.1144 (3.2140)	grad_norm 4.3951 (4.6987)	mem 8926MB
[2022-04-08 10:36:28 large] (main.py 226): INFO Train: [182/300][2300/2502]	eta 0:01:42 lr 0.000169	time 0.5030 (0.5056)	loss 3.3066 (3.2141)	grad_norm 4.2203 (4.6984)	mem 8926MB
[2022-04-08 10:37:19 large] (main.py 226): INFO Train: [182/300][2400/2502]	eta 0:00:51 lr 0.000169	time 0.5202 (0.5058)	loss 3.9410 (3.2141)	grad_norm 7.1201 (4.7035)	mem 8926MB
[2022-04-08 10:38:08 large] (main.py 226): INFO Train: [182/300][2500/2502]	eta 0:00:01 lr 0.000169	time 0.4960 (0.5052)	loss 2.7505 (3.2140)	grad_norm 4.2228 (4.7061)	mem 8926MB
[2022-04-08 10:38:09 large] (main.py 233): INFO EPOCH 182 training takes 0:21:04
[2022-04-08 10:38:16 large] (main.py 273): INFO Test: [0/98]	Time 6.234 (6.234)	Loss 1.0624 (1.0624)	Acc@1 78.711 (78.711)	Acc@5 95.117 (95.117)	Mem 8926MB
[2022-04-08 10:38:42 large] (main.py 279): INFO  * Acc@1 78.678 Acc@5 94.446
[2022-04-08 10:38:42 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 78.7%
[2022-04-08 10:38:42 large] (utils.py 57): INFO output/large/default/ckpt_epoch_182.pth saving......
[2022-04-08 10:38:43 large] (utils.py 59): INFO output/large/default/ckpt_epoch_182.pth saved !!!
[2022-04-08 10:38:43 large] (main.py 148): INFO Max accuracy: 78.68%
[2022-04-08 10:38:51 large] (main.py 226): INFO Train: [183/300][0/2502]	eta 5:43:58 lr 0.000169	time 8.2487 (8.2487)	loss 3.6224 (3.6224)	grad_norm 4.6402 (4.6402)	mem 8926MB
[2022-04-08 10:39:40 large] (main.py 226): INFO Train: [183/300][100/2502]	eta 0:22:53 lr 0.000169	time 0.5299 (0.5718)	loss 3.2087 (3.2877)	grad_norm 4.9513 (4.7014)	mem 8926MB
[2022-04-08 10:40:31 large] (main.py 226): INFO Train: [183/300][200/2502]	eta 0:20:45 lr 0.000168	time 0.4959 (0.5412)	loss 3.5112 (3.2074)	grad_norm 4.8882 (4.7438)	mem 8926MB
[2022-04-08 10:41:22 large] (main.py 226): INFO Train: [183/300][300/2502]	eta 0:19:28 lr 0.000168	time 0.5023 (0.5305)	loss 3.1324 (3.2048)	grad_norm 3.7856 (nan)	mem 8926MB
[2022-04-08 10:42:14 large] (main.py 226): INFO Train: [183/300][400/2502]	eta 0:18:26 lr 0.000168	time 0.5409 (0.5262)	loss 3.6450 (3.2060)	grad_norm 3.6530 (nan)	mem 8926MB
[2022-04-08 10:43:04 large] (main.py 226): INFO Train: [183/300][500/2502]	eta 0:17:24 lr 0.000168	time 0.5156 (0.5218)	loss 3.3302 (3.2179)	grad_norm 3.3518 (nan)	mem 8926MB
[2022-04-08 10:43:54 large] (main.py 226): INFO Train: [183/300][600/2502]	eta 0:16:25 lr 0.000168	time 0.5592 (0.5180)	loss 3.3328 (3.2325)	grad_norm 6.2362 (nan)	mem 8926MB
[2022-04-08 10:44:42 large] (main.py 226): INFO Train: [183/300][700/2502]	eta 0:15:24 lr 0.000168	time 0.5162 (0.5130)	loss 3.5748 (3.2321)	grad_norm 6.1500 (nan)	mem 8926MB
[2022-04-08 10:45:31 large] (main.py 226): INFO Train: [183/300][800/2502]	eta 0:14:27 lr 0.000168	time 0.5057 (0.5097)	loss 3.7064 (3.2316)	grad_norm 6.1251 (nan)	mem 8926MB
[2022-04-08 10:46:19 large] (main.py 226): INFO Train: [183/300][900/2502]	eta 0:13:31 lr 0.000168	time 0.4422 (0.5065)	loss 3.6206 (3.2283)	grad_norm 4.3551 (nan)	mem 8926MB
[2022-04-08 10:47:08 large] (main.py 226): INFO Train: [183/300][1000/2502]	eta 0:12:37 lr 0.000168	time 0.5044 (0.5045)	loss 3.6318 (3.2226)	grad_norm 4.8250 (nan)	mem 8926MB
[2022-04-08 10:47:59 large] (main.py 226): INFO Train: [183/300][1100/2502]	eta 0:11:48 lr 0.000168	time 0.5102 (0.5053)	loss 3.2734 (3.2146)	grad_norm 5.5982 (nan)	mem 8926MB
[2022-04-08 10:48:51 large] (main.py 226): INFO Train: [183/300][1200/2502]	eta 0:10:59 lr 0.000167	time 0.5069 (0.5062)	loss 3.2766 (3.2180)	grad_norm 4.1043 (nan)	mem 8926MB
[2022-04-08 10:49:41 large] (main.py 226): INFO Train: [183/300][1300/2502]	eta 0:10:08 lr 0.000167	time 0.5302 (0.5060)	loss 2.9405 (3.2128)	grad_norm 5.0478 (nan)	mem 8926MB
[2022-04-08 10:50:32 large] (main.py 226): INFO Train: [183/300][1400/2502]	eta 0:09:17 lr 0.000167	time 0.4981 (0.5062)	loss 2.4067 (3.2168)	grad_norm 3.7207 (nan)	mem 8926MB
[2022-04-08 10:51:23 large] (main.py 226): INFO Train: [183/300][1500/2502]	eta 0:08:27 lr 0.000167	time 0.4894 (0.5063)	loss 2.0616 (3.2102)	grad_norm 4.1862 (nan)	mem 8926MB
[2022-04-08 10:52:14 large] (main.py 226): INFO Train: [183/300][1600/2502]	eta 0:07:37 lr 0.000167	time 0.5039 (0.5068)	loss 2.6940 (3.2044)	grad_norm 3.0711 (nan)	mem 8926MB
[2022-04-08 10:53:03 large] (main.py 226): INFO Train: [183/300][1700/2502]	eta 0:06:45 lr 0.000167	time 0.5054 (0.5055)	loss 2.7272 (3.2088)	grad_norm 5.3651 (nan)	mem 8926MB
[2022-04-08 10:53:53 large] (main.py 226): INFO Train: [183/300][1800/2502]	eta 0:05:54 lr 0.000167	time 0.5769 (0.5053)	loss 3.7793 (3.2111)	grad_norm 6.4035 (nan)	mem 8926MB
[2022-04-08 10:54:44 large] (main.py 226): INFO Train: [183/300][1900/2502]	eta 0:05:04 lr 0.000167	time 0.5034 (0.5055)	loss 3.4663 (3.2118)	grad_norm 3.6061 (nan)	mem 8926MB
[2022-04-08 10:55:34 large] (main.py 226): INFO Train: [183/300][2000/2502]	eta 0:04:13 lr 0.000167	time 0.4876 (0.5053)	loss 3.3536 (3.2126)	grad_norm 6.2422 (nan)	mem 8926MB
[2022-04-08 10:56:24 large] (main.py 226): INFO Train: [183/300][2100/2502]	eta 0:03:23 lr 0.000167	time 0.4999 (0.5050)	loss 3.0636 (3.2089)	grad_norm 3.7521 (nan)	mem 8926MB
[2022-04-08 10:57:15 large] (main.py 226): INFO Train: [183/300][2200/2502]	eta 0:02:32 lr 0.000167	time 0.5345 (0.5053)	loss 3.8942 (3.2080)	grad_norm 4.7069 (nan)	mem 8926MB
[2022-04-08 10:58:06 large] (main.py 226): INFO Train: [183/300][2300/2502]	eta 0:01:42 lr 0.000166	time 0.4774 (0.5057)	loss 3.4274 (3.2114)	grad_norm 4.3223 (nan)	mem 8926MB
[2022-04-08 10:58:57 large] (main.py 226): INFO Train: [183/300][2400/2502]	eta 0:00:51 lr 0.000166	time 0.4848 (0.5057)	loss 3.3146 (3.2142)	grad_norm 4.9473 (nan)	mem 8926MB
[2022-04-08 10:59:45 large] (main.py 226): INFO Train: [183/300][2500/2502]	eta 0:00:01 lr 0.000166	time 0.5054 (0.5048)	loss 3.7387 (3.2188)	grad_norm 6.1254 (nan)	mem 8926MB
[2022-04-08 10:59:46 large] (main.py 233): INFO EPOCH 183 training takes 0:21:03
[2022-04-08 10:59:53 large] (main.py 273): INFO Test: [0/98]	Time 6.818 (6.818)	Loss 1.1040 (1.1040)	Acc@1 77.344 (77.344)	Acc@5 93.750 (93.750)	Mem 8926MB
[2022-04-08 11:00:18 large] (main.py 279): INFO  * Acc@1 78.576 Acc@5 94.400
[2022-04-08 11:00:18 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 78.6%
[2022-04-08 11:00:18 large] (main.py 148): INFO Max accuracy: 78.68%
[2022-04-08 11:00:26 large] (main.py 226): INFO Train: [184/300][0/2502]	eta 5:00:24 lr 0.000166	time 7.2042 (7.2042)	loss 3.3341 (3.3341)	grad_norm 4.5167 (4.5167)	mem 8926MB
[2022-04-08 11:01:15 large] (main.py 226): INFO Train: [184/300][100/2502]	eta 0:22:34 lr 0.000166	time 0.4916 (0.5638)	loss 2.8633 (3.1381)	grad_norm 3.7301 (4.8160)	mem 8926MB
[2022-04-08 11:02:04 large] (main.py 226): INFO Train: [184/300][200/2502]	eta 0:20:12 lr 0.000166	time 0.5559 (0.5266)	loss 3.6234 (3.1528)	grad_norm 4.5140 (4.7399)	mem 8926MB
[2022-04-08 11:02:56 large] (main.py 226): INFO Train: [184/300][300/2502]	eta 0:19:12 lr 0.000166	time 0.5035 (0.5234)	loss 3.3768 (3.1772)	grad_norm 4.2253 (4.7200)	mem 8926MB
[2022-04-08 11:03:48 large] (main.py 226): INFO Train: [184/300][400/2502]	eta 0:18:17 lr 0.000166	time 0.5282 (0.5220)	loss 3.6006 (3.1720)	grad_norm 3.4912 (4.7146)	mem 8926MB
[2022-04-08 11:04:36 large] (main.py 226): INFO Train: [184/300][500/2502]	eta 0:17:09 lr 0.000166	time 0.4914 (0.5144)	loss 3.1739 (3.1789)	grad_norm 4.1024 (4.6990)	mem 8926MB
[2022-04-08 11:05:27 large] (main.py 226): INFO Train: [184/300][600/2502]	eta 0:16:15 lr 0.000166	time 0.4676 (0.5131)	loss 3.9080 (3.1708)	grad_norm 4.1146 (4.7291)	mem 8926MB
[2022-04-08 11:06:16 large] (main.py 226): INFO Train: [184/300][700/2502]	eta 0:15:19 lr 0.000166	time 0.4718 (0.5103)	loss 3.4932 (3.1722)	grad_norm 3.9177 (4.7471)	mem 8926MB
[2022-04-08 11:07:06 large] (main.py 226): INFO Train: [184/300][800/2502]	eta 0:14:27 lr 0.000165	time 0.5059 (0.5094)	loss 3.1781 (3.1803)	grad_norm 4.2749 (4.7927)	mem 8926MB
[2022-04-08 11:07:58 large] (main.py 226): INFO Train: [184/300][900/2502]	eta 0:13:37 lr 0.000165	time 0.5251 (0.5100)	loss 3.4332 (3.1756)	grad_norm 4.8973 (4.8097)	mem 8926MB
[2022-04-08 11:08:50 large] (main.py 226): INFO Train: [184/300][1000/2502]	eta 0:12:47 lr 0.000165	time 0.4826 (0.5111)	loss 3.6777 (3.1798)	grad_norm 4.5144 (4.8000)	mem 8926MB
[2022-04-08 11:09:39 large] (main.py 226): INFO Train: [184/300][1100/2502]	eta 0:11:54 lr 0.000165	time 0.5013 (0.5097)	loss 3.5607 (3.1883)	grad_norm 4.6259 (4.7940)	mem 8926MB
[2022-04-08 11:10:28 large] (main.py 226): INFO Train: [184/300][1200/2502]	eta 0:11:01 lr 0.000165	time 0.4808 (0.5079)	loss 3.8534 (3.1918)	grad_norm 4.5924 (4.8184)	mem 8926MB
[2022-04-08 11:11:18 large] (main.py 226): INFO Train: [184/300][1300/2502]	eta 0:10:09 lr 0.000165	time 0.4994 (0.5068)	loss 2.0179 (3.1877)	grad_norm 4.7805 (4.8263)	mem 8926MB
[2022-04-08 11:12:08 large] (main.py 226): INFO Train: [184/300][1400/2502]	eta 0:09:18 lr 0.000165	time 0.4461 (0.5065)	loss 3.4249 (3.1920)	grad_norm 4.1990 (4.8488)	mem 8926MB
[2022-04-08 11:12:59 large] (main.py 226): INFO Train: [184/300][1500/2502]	eta 0:08:27 lr 0.000165	time 0.4862 (0.5066)	loss 3.5204 (3.1970)	grad_norm 4.3801 (4.8342)	mem 8926MB
[2022-04-08 11:13:50 large] (main.py 226): INFO Train: [184/300][1600/2502]	eta 0:07:37 lr 0.000165	time 0.4813 (0.5072)	loss 2.1195 (3.1988)	grad_norm 4.7501 (4.8221)	mem 8926MB
[2022-04-08 11:14:42 large] (main.py 226): INFO Train: [184/300][1700/2502]	eta 0:06:47 lr 0.000165	time 0.5530 (0.5076)	loss 2.6304 (3.2007)	grad_norm 5.6540 (4.8145)	mem 8926MB
[2022-04-08 11:15:32 large] (main.py 226): INFO Train: [184/300][1800/2502]	eta 0:05:56 lr 0.000164	time 0.4835 (0.5073)	loss 3.7519 (3.2021)	grad_norm 4.1215 (4.8180)	mem 8926MB
[2022-04-08 11:16:22 large] (main.py 226): INFO Train: [184/300][1900/2502]	eta 0:05:05 lr 0.000164	time 0.5024 (0.5072)	loss 3.0009 (3.2026)	grad_norm 4.5102 (4.8179)	mem 8926MB
[2022-04-08 11:17:13 large] (main.py 226): INFO Train: [184/300][2000/2502]	eta 0:04:14 lr 0.000164	time 0.5398 (0.5070)	loss 3.5667 (3.1996)	grad_norm 3.3625 (4.8027)	mem 8926MB
[2022-04-08 11:18:02 large] (main.py 226): INFO Train: [184/300][2100/2502]	eta 0:03:23 lr 0.000164	time 0.5032 (0.5065)	loss 2.4278 (3.2020)	grad_norm 4.6420 (4.8014)	mem 8926MB
[2022-04-08 11:18:51 large] (main.py 226): INFO Train: [184/300][2200/2502]	eta 0:02:32 lr 0.000164	time 0.5039 (0.5054)	loss 3.5534 (3.2061)	grad_norm 3.8212 (4.7939)	mem 8926MB
[2022-04-08 11:19:41 large] (main.py 226): INFO Train: [184/300][2300/2502]	eta 0:01:42 lr 0.000164	time 0.5095 (0.5054)	loss 3.4508 (3.2084)	grad_norm 4.3410 (4.7907)	mem 8926MB
[2022-04-08 11:20:30 large] (main.py 226): INFO Train: [184/300][2400/2502]	eta 0:00:51 lr 0.000164	time 0.4632 (0.5045)	loss 3.1232 (3.2082)	grad_norm 4.3138 (4.7846)	mem 8926MB
[2022-04-08 11:21:18 large] (main.py 226): INFO Train: [184/300][2500/2502]	eta 0:00:01 lr 0.000164	time 0.4679 (0.5036)	loss 2.1839 (3.2104)	grad_norm 5.1717 (4.7887)	mem 8926MB
[2022-04-08 11:21:19 large] (main.py 233): INFO EPOCH 184 training takes 0:21:00
[2022-04-08 11:21:25 large] (main.py 273): INFO Test: [0/98]	Time 6.585 (6.585)	Loss 0.9843 (0.9843)	Acc@1 80.664 (80.664)	Acc@5 95.312 (95.312)	Mem 8926MB
[2022-04-08 11:21:51 large] (main.py 279): INFO  * Acc@1 78.804 Acc@5 94.458
[2022-04-08 11:21:51 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 78.8%
[2022-04-08 11:21:51 large] (utils.py 57): INFO output/large/default/ckpt_epoch_184.pth saving......
[2022-04-08 11:21:52 large] (utils.py 59): INFO output/large/default/ckpt_epoch_184.pth saved !!!
[2022-04-08 11:21:52 large] (main.py 148): INFO Max accuracy: 78.80%
[2022-04-08 11:22:00 large] (main.py 226): INFO Train: [185/300][0/2502]	eta 5:25:04 lr 0.000164	time 7.7955 (7.7955)	loss 3.1162 (3.1162)	grad_norm 4.2576 (4.2576)	mem 8926MB
[2022-04-08 11:22:50 large] (main.py 226): INFO Train: [185/300][100/2502]	eta 0:22:47 lr 0.000164	time 0.5062 (0.5693)	loss 2.9873 (3.1205)	grad_norm 5.9242 (4.7226)	mem 8926MB
[2022-04-08 11:23:39 large] (main.py 226): INFO Train: [185/300][200/2502]	eta 0:20:28 lr 0.000164	time 0.4513 (0.5336)	loss 3.2545 (3.1816)	grad_norm 5.5940 (4.6862)	mem 8926MB
[2022-04-08 11:24:29 large] (main.py 226): INFO Train: [185/300][300/2502]	eta 0:19:09 lr 0.000164	time 0.4973 (0.5219)	loss 2.0501 (3.1843)	grad_norm 5.6808 (4.7093)	mem 8926MB
[2022-04-08 11:25:18 large] (main.py 226): INFO Train: [185/300][400/2502]	eta 0:18:01 lr 0.000163	time 0.5370 (0.5146)	loss 3.3923 (3.1838)	grad_norm 4.1230 (4.6864)	mem 8926MB
[2022-04-08 11:26:08 large] (main.py 226): INFO Train: [185/300][500/2502]	eta 0:17:03 lr 0.000163	time 0.5034 (0.5114)	loss 3.4916 (3.1740)	grad_norm 6.6719 (4.7275)	mem 8926MB
[2022-04-08 11:27:00 large] (main.py 226): INFO Train: [185/300][600/2502]	eta 0:16:14 lr 0.000163	time 0.4978 (0.5126)	loss 3.4125 (3.1735)	grad_norm 4.1568 (4.7273)	mem 8926MB
[2022-04-08 11:27:52 large] (main.py 226): INFO Train: [185/300][700/2502]	eta 0:15:25 lr 0.000163	time 0.5088 (0.5134)	loss 3.9843 (3.1695)	grad_norm 4.0738 (4.7541)	mem 8926MB
[2022-04-08 11:28:43 large] (main.py 226): INFO Train: [185/300][800/2502]	eta 0:14:33 lr 0.000163	time 0.5153 (0.5134)	loss 3.1667 (3.1674)	grad_norm 7.8750 (4.7509)	mem 8926MB
[2022-04-08 11:29:35 large] (main.py 226): INFO Train: [185/300][900/2502]	eta 0:13:42 lr 0.000163	time 0.4970 (0.5135)	loss 3.6687 (3.1673)	grad_norm 5.4515 (4.7933)	mem 8926MB
[2022-04-08 11:30:24 large] (main.py 226): INFO Train: [185/300][1000/2502]	eta 0:12:47 lr 0.000163	time 0.4994 (0.5113)	loss 3.5837 (3.1638)	grad_norm 6.1215 (4.7842)	mem 8926MB
[2022-04-08 11:31:14 large] (main.py 226): INFO Train: [185/300][1100/2502]	eta 0:11:54 lr 0.000163	time 0.5166 (0.5100)	loss 3.0987 (3.1634)	grad_norm 3.5708 (4.8090)	mem 8926MB
[2022-04-08 11:32:04 large] (main.py 226): INFO Train: [185/300][1200/2502]	eta 0:11:03 lr 0.000163	time 0.5044 (0.5094)	loss 3.1754 (3.1660)	grad_norm 5.6913 (4.8178)	mem 8926MB
[2022-04-08 11:32:54 large] (main.py 226): INFO Train: [185/300][1300/2502]	eta 0:10:11 lr 0.000163	time 0.4687 (0.5088)	loss 3.7538 (3.1738)	grad_norm 4.3669 (4.8099)	mem 8926MB
[2022-04-08 11:33:44 large] (main.py 226): INFO Train: [185/300][1400/2502]	eta 0:09:20 lr 0.000162	time 0.5080 (0.5084)	loss 3.3584 (3.1785)	grad_norm 7.3428 (nan)	mem 8926MB
[2022-04-08 11:34:35 large] (main.py 226): INFO Train: [185/300][1500/2502]	eta 0:08:29 lr 0.000162	time 0.5459 (0.5086)	loss 2.9915 (3.1779)	grad_norm 6.4277 (nan)	mem 8926MB
[2022-04-08 11:35:26 large] (main.py 226): INFO Train: [185/300][1600/2502]	eta 0:07:38 lr 0.000162	time 0.4991 (0.5086)	loss 3.1568 (3.1812)	grad_norm 5.0153 (nan)	mem 8926MB
[2022-04-08 11:36:16 large] (main.py 226): INFO Train: [185/300][1700/2502]	eta 0:06:47 lr 0.000162	time 0.4940 (0.5080)	loss 3.2856 (3.1860)	grad_norm 4.2052 (nan)	mem 8926MB
[2022-04-08 11:37:06 large] (main.py 226): INFO Train: [185/300][1800/2502]	eta 0:05:56 lr 0.000162	time 0.4654 (0.5077)	loss 3.2879 (3.1875)	grad_norm 5.2615 (nan)	mem 8926MB
[2022-04-08 11:37:55 large] (main.py 226): INFO Train: [185/300][1900/2502]	eta 0:05:04 lr 0.000162	time 0.4940 (0.5063)	loss 3.7509 (3.1910)	grad_norm 4.7830 (nan)	mem 8926MB
[2022-04-08 11:38:44 large] (main.py 226): INFO Train: [185/300][2000/2502]	eta 0:04:13 lr 0.000162	time 0.4896 (0.5055)	loss 2.8830 (3.1919)	grad_norm 6.8489 (nan)	mem 8926MB
[2022-04-08 11:39:34 large] (main.py 226): INFO Train: [185/300][2100/2502]	eta 0:03:23 lr 0.000162	time 0.6136 (0.5057)	loss 4.1307 (3.1973)	grad_norm 4.0933 (nan)	mem 8926MB
[2022-04-08 11:40:26 large] (main.py 226): INFO Train: [185/300][2200/2502]	eta 0:02:32 lr 0.000162	time 0.5072 (0.5060)	loss 2.3430 (3.2008)	grad_norm 3.7798 (nan)	mem 8926MB
[2022-04-08 11:41:17 large] (main.py 226): INFO Train: [185/300][2300/2502]	eta 0:01:42 lr 0.000162	time 0.5050 (0.5064)	loss 3.6684 (3.1998)	grad_norm 3.8341 (nan)	mem 8926MB
[2022-04-08 11:42:09 large] (main.py 226): INFO Train: [185/300][2400/2502]	eta 0:00:51 lr 0.000161	time 0.5003 (0.5067)	loss 3.5357 (3.2009)	grad_norm 5.1909 (nan)	mem 8926MB
[2022-04-08 11:42:59 large] (main.py 226): INFO Train: [185/300][2500/2502]	eta 0:00:01 lr 0.000161	time 0.4947 (0.5068)	loss 3.7224 (3.1996)	grad_norm 5.8168 (nan)	mem 8926MB
[2022-04-08 11:43:00 large] (main.py 233): INFO EPOCH 185 training takes 0:21:08
[2022-04-08 11:43:08 large] (main.py 273): INFO Test: [0/98]	Time 7.592 (7.592)	Loss 1.0787 (1.0787)	Acc@1 78.906 (78.906)	Acc@5 93.359 (93.359)	Mem 8926MB
[2022-04-08 11:43:33 large] (main.py 279): INFO  * Acc@1 78.768 Acc@5 94.380
[2022-04-08 11:43:33 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 78.8%
[2022-04-08 11:43:33 large] (main.py 148): INFO Max accuracy: 78.80%
[2022-04-08 11:43:41 large] (main.py 226): INFO Train: [186/300][0/2502]	eta 5:14:55 lr 0.000161	time 7.5523 (7.5523)	loss 3.9264 (3.9264)	grad_norm 7.3759 (7.3759)	mem 8926MB
[2022-04-08 11:44:30 large] (main.py 226): INFO Train: [186/300][100/2502]	eta 0:22:29 lr 0.000161	time 0.4464 (0.5618)	loss 3.4526 (3.1822)	grad_norm 4.3697 (5.1162)	mem 8926MB
[2022-04-08 11:45:19 large] (main.py 226): INFO Train: [186/300][200/2502]	eta 0:20:15 lr 0.000161	time 0.4765 (0.5280)	loss 3.4592 (3.1840)	grad_norm 4.2013 (4.8345)	mem 8926MB
[2022-04-08 11:46:10 large] (main.py 226): INFO Train: [186/300][300/2502]	eta 0:19:05 lr 0.000161	time 0.5009 (0.5200)	loss 3.0333 (3.1890)	grad_norm 3.6198 (4.8817)	mem 8926MB
[2022-04-08 11:47:01 large] (main.py 226): INFO Train: [186/300][400/2502]	eta 0:18:12 lr 0.000161	time 0.5143 (0.5199)	loss 3.2167 (3.1957)	grad_norm 4.1858 (4.8922)	mem 8926MB
[2022-04-08 11:47:53 large] (main.py 226): INFO Train: [186/300][500/2502]	eta 0:17:19 lr 0.000161	time 0.4413 (0.5193)	loss 3.3378 (3.1960)	grad_norm 3.8288 (4.8709)	mem 8926MB
[2022-04-08 11:48:42 large] (main.py 226): INFO Train: [186/300][600/2502]	eta 0:16:17 lr 0.000161	time 0.4886 (0.5139)	loss 3.1892 (3.1968)	grad_norm 5.2500 (4.8263)	mem 8926MB
[2022-04-08 11:49:33 large] (main.py 226): INFO Train: [186/300][700/2502]	eta 0:15:25 lr 0.000161	time 0.5307 (0.5135)	loss 3.4224 (3.1929)	grad_norm 5.0471 (4.8085)	mem 8926MB
[2022-04-08 11:50:25 large] (main.py 226): INFO Train: [186/300][800/2502]	eta 0:14:34 lr 0.000161	time 0.5402 (0.5139)	loss 3.2193 (3.1956)	grad_norm 3.0365 (4.7768)	mem 8926MB
[2022-04-08 11:51:16 large] (main.py 226): INFO Train: [186/300][900/2502]	eta 0:13:43 lr 0.000161	time 0.4986 (0.5143)	loss 3.4242 (3.1898)	grad_norm 4.2347 (4.7626)	mem 8926MB
[2022-04-08 11:52:08 large] (main.py 226): INFO Train: [186/300][1000/2502]	eta 0:12:52 lr 0.000160	time 0.5067 (0.5146)	loss 3.4466 (3.1873)	grad_norm 4.6291 (4.7294)	mem 8926MB
[2022-04-08 11:52:59 large] (main.py 226): INFO Train: [186/300][1100/2502]	eta 0:12:01 lr 0.000160	time 0.5337 (0.5145)	loss 3.7948 (3.1950)	grad_norm 6.6253 (4.7407)	mem 8926MB
[2022-04-08 11:53:48 large] (main.py 226): INFO Train: [186/300][1200/2502]	eta 0:11:07 lr 0.000160	time 0.4684 (0.5124)	loss 3.2553 (3.1969)	grad_norm 5.1190 (4.7551)	mem 8926MB
[2022-04-08 11:54:38 large] (main.py 226): INFO Train: [186/300][1300/2502]	eta 0:10:14 lr 0.000160	time 0.4813 (0.5113)	loss 2.1691 (3.1932)	grad_norm 4.8301 (4.7593)	mem 8926MB
[2022-04-08 11:55:29 large] (main.py 226): INFO Train: [186/300][1400/2502]	eta 0:09:23 lr 0.000160	time 0.5084 (0.5114)	loss 2.5955 (3.1910)	grad_norm 4.8472 (4.7592)	mem 8926MB
[2022-04-08 11:56:18 large] (main.py 226): INFO Train: [186/300][1500/2502]	eta 0:08:30 lr 0.000160	time 0.4676 (0.5096)	loss 3.4936 (3.1889)	grad_norm 4.3295 (4.7740)	mem 8926MB
[2022-04-08 11:57:09 large] (main.py 226): INFO Train: [186/300][1600/2502]	eta 0:07:39 lr 0.000160	time 0.5132 (0.5094)	loss 3.1473 (3.1906)	grad_norm 4.0245 (4.7746)	mem 8926MB
[2022-04-08 11:58:00 large] (main.py 226): INFO Train: [186/300][1700/2502]	eta 0:06:48 lr 0.000160	time 0.5040 (0.5097)	loss 3.7020 (3.1899)	grad_norm 4.4475 (4.7766)	mem 8926MB
[2022-04-08 11:58:51 large] (main.py 226): INFO Train: [186/300][1800/2502]	eta 0:05:58 lr 0.000160	time 0.5754 (0.5100)	loss 2.6271 (3.1932)	grad_norm 5.1376 (4.7880)	mem 8926MB
[2022-04-08 11:59:43 large] (main.py 226): INFO Train: [186/300][1900/2502]	eta 0:05:07 lr 0.000160	time 0.4691 (0.5101)	loss 3.5933 (3.1944)	grad_norm 4.6113 (4.7929)	mem 8926MB
[2022-04-08 12:00:34 large] (main.py 226): INFO Train: [186/300][2000/2502]	eta 0:04:16 lr 0.000159	time 0.4972 (0.5101)	loss 2.7508 (3.1954)	grad_norm 3.6588 (4.7964)	mem 8926MB
[2022-04-08 12:01:23 large] (main.py 226): INFO Train: [186/300][2100/2502]	eta 0:03:24 lr 0.000159	time 0.4648 (0.5092)	loss 3.6142 (3.1940)	grad_norm 4.3070 (4.8085)	mem 8926MB
[2022-04-08 12:02:12 large] (main.py 226): INFO Train: [186/300][2200/2502]	eta 0:02:33 lr 0.000159	time 0.5087 (0.5085)	loss 3.3207 (3.1987)	grad_norm 4.0101 (4.8127)	mem 8926MB
[2022-04-08 12:03:02 large] (main.py 226): INFO Train: [186/300][2300/2502]	eta 0:01:42 lr 0.000159	time 0.6010 (0.5080)	loss 3.4990 (3.1979)	grad_norm 4.2642 (4.8035)	mem 8926MB
[2022-04-08 12:03:52 large] (main.py 226): INFO Train: [186/300][2400/2502]	eta 0:00:51 lr 0.000159	time 0.4875 (0.5075)	loss 3.1671 (3.1963)	grad_norm 5.3400 (nan)	mem 8926MB
[2022-04-08 12:04:41 large] (main.py 226): INFO Train: [186/300][2500/2502]	eta 0:00:01 lr 0.000159	time 0.4809 (0.5070)	loss 3.0941 (3.1979)	grad_norm 5.1234 (nan)	mem 8926MB
[2022-04-08 12:04:42 large] (main.py 233): INFO EPOCH 186 training takes 0:21:09
[2022-04-08 12:04:48 large] (main.py 273): INFO Test: [0/98]	Time 6.099 (6.099)	Loss 1.1541 (1.1541)	Acc@1 76.172 (76.172)	Acc@5 92.383 (92.383)	Mem 8926MB
[2022-04-08 12:05:15 large] (main.py 279): INFO  * Acc@1 78.990 Acc@5 94.542
[2022-04-08 12:05:15 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 79.0%
[2022-04-08 12:05:15 large] (utils.py 57): INFO output/large/default/ckpt_epoch_186.pth saving......
[2022-04-08 12:05:15 large] (utils.py 59): INFO output/large/default/ckpt_epoch_186.pth saved !!!
[2022-04-08 12:05:15 large] (main.py 148): INFO Max accuracy: 78.99%
[2022-04-08 12:05:23 large] (main.py 226): INFO Train: [187/300][0/2502]	eta 5:40:54 lr 0.000159	time 8.1752 (8.1752)	loss 3.3990 (3.3990)	grad_norm 5.8814 (5.8814)	mem 8926MB
[2022-04-08 12:06:13 large] (main.py 226): INFO Train: [187/300][100/2502]	eta 0:22:48 lr 0.000159	time 0.4859 (0.5699)	loss 3.6445 (3.2101)	grad_norm 4.9827 (5.0388)	mem 8926MB
[2022-04-08 12:07:04 large] (main.py 226): INFO Train: [187/300][200/2502]	eta 0:20:47 lr 0.000159	time 0.5015 (0.5421)	loss 2.1197 (3.2083)	grad_norm 4.7908 (4.9105)	mem 8926MB
[2022-04-08 12:07:56 large] (main.py 226): INFO Train: [187/300][300/2502]	eta 0:19:34 lr 0.000159	time 0.5079 (0.5332)	loss 3.2652 (3.2100)	grad_norm 4.5262 (4.8765)	mem 8926MB
[2022-04-08 12:08:48 large] (main.py 226): INFO Train: [187/300][400/2502]	eta 0:18:32 lr 0.000159	time 0.5056 (0.5294)	loss 3.5145 (3.2023)	grad_norm 4.5078 (4.8856)	mem 8926MB
[2022-04-08 12:09:39 large] (main.py 226): INFO Train: [187/300][500/2502]	eta 0:17:34 lr 0.000159	time 0.4956 (0.5266)	loss 2.3269 (3.1999)	grad_norm 4.0692 (4.8379)	mem 8926MB
[2022-04-08 12:10:30 large] (main.py 226): INFO Train: [187/300][600/2502]	eta 0:16:36 lr 0.000158	time 0.5164 (0.5240)	loss 3.1142 (3.1891)	grad_norm 5.2449 (4.7771)	mem 8926MB
[2022-04-08 12:11:22 large] (main.py 226): INFO Train: [187/300][700/2502]	eta 0:15:42 lr 0.000158	time 0.5997 (0.5230)	loss 3.5419 (3.1853)	grad_norm 4.7963 (4.7576)	mem 8926MB
[2022-04-08 12:12:12 large] (main.py 226): INFO Train: [187/300][800/2502]	eta 0:14:46 lr 0.000158	time 0.5015 (0.5207)	loss 3.5291 (3.2046)	grad_norm 5.0198 (4.7541)	mem 8926MB
[2022-04-08 12:13:03 large] (main.py 226): INFO Train: [187/300][900/2502]	eta 0:13:50 lr 0.000158	time 0.4765 (0.5185)	loss 2.5850 (3.2115)	grad_norm 5.4373 (4.7549)	mem 8926MB
[2022-04-08 12:13:52 large] (main.py 226): INFO Train: [187/300][1000/2502]	eta 0:12:55 lr 0.000158	time 0.5060 (0.5165)	loss 3.6162 (3.2065)	grad_norm 7.1730 (4.7643)	mem 8926MB
[2022-04-08 12:14:41 large] (main.py 226): INFO Train: [187/300][1100/2502]	eta 0:12:00 lr 0.000158	time 0.4735 (0.5142)	loss 3.4578 (3.2172)	grad_norm 4.4359 (4.7715)	mem 8926MB
[2022-04-08 12:15:30 large] (main.py 226): INFO Train: [187/300][1200/2502]	eta 0:11:06 lr 0.000158	time 0.5253 (0.5118)	loss 3.4420 (3.2139)	grad_norm 5.1291 (4.7687)	mem 8926MB
[2022-04-08 12:16:20 large] (main.py 226): INFO Train: [187/300][1300/2502]	eta 0:10:13 lr 0.000158	time 0.5095 (0.5107)	loss 4.0499 (3.2103)	grad_norm 5.3775 (4.7902)	mem 8926MB
[2022-04-08 12:17:08 large] (main.py 226): INFO Train: [187/300][1400/2502]	eta 0:09:20 lr 0.000158	time 0.4954 (0.5089)	loss 3.8834 (3.2120)	grad_norm 5.2864 (4.7957)	mem 8926MB
[2022-04-08 12:17:58 large] (main.py 226): INFO Train: [187/300][1500/2502]	eta 0:08:29 lr 0.000158	time 0.4507 (0.5081)	loss 3.7920 (3.2154)	grad_norm 4.9073 (4.7946)	mem 8926MB
[2022-04-08 12:18:46 large] (main.py 226): INFO Train: [187/300][1600/2502]	eta 0:07:36 lr 0.000157	time 0.5542 (0.5066)	loss 3.3080 (3.2133)	grad_norm 7.0060 (4.7957)	mem 8926MB
[2022-04-08 12:19:35 large] (main.py 226): INFO Train: [187/300][1700/2502]	eta 0:06:45 lr 0.000157	time 0.4897 (0.5055)	loss 3.5200 (3.2171)	grad_norm 5.1896 (4.8237)	mem 8926MB
[2022-04-08 12:20:27 large] (main.py 226): INFO Train: [187/300][1800/2502]	eta 0:05:55 lr 0.000157	time 0.6157 (0.5060)	loss 3.5427 (3.2192)	grad_norm 5.1637 (4.8288)	mem 8926MB
[2022-04-08 12:21:19 large] (main.py 226): INFO Train: [187/300][1900/2502]	eta 0:05:05 lr 0.000157	time 0.5157 (0.5068)	loss 3.7681 (3.2180)	grad_norm 6.0231 (4.8234)	mem 8926MB
[2022-04-08 12:22:09 large] (main.py 226): INFO Train: [187/300][2000/2502]	eta 0:04:14 lr 0.000157	time 0.4982 (0.5067)	loss 3.6912 (3.2142)	grad_norm 5.0156 (4.8322)	mem 8926MB
[2022-04-08 12:22:58 large] (main.py 226): INFO Train: [187/300][2100/2502]	eta 0:03:23 lr 0.000157	time 0.4963 (0.5057)	loss 3.9887 (3.2163)	grad_norm 4.7129 (4.8347)	mem 8926MB
[2022-04-08 12:23:49 large] (main.py 226): INFO Train: [187/300][2200/2502]	eta 0:02:32 lr 0.000157	time 0.5041 (0.5059)	loss 3.4518 (3.2193)	grad_norm 5.4271 (4.8299)	mem 8926MB
[2022-04-08 12:24:41 large] (main.py 226): INFO Train: [187/300][2300/2502]	eta 0:01:42 lr 0.000157	time 0.5090 (0.5067)	loss 3.4517 (3.2201)	grad_norm 4.3449 (4.8288)	mem 8926MB
[2022-04-08 12:25:33 large] (main.py 226): INFO Train: [187/300][2400/2502]	eta 0:00:51 lr 0.000157	time 0.4971 (0.5071)	loss 3.1774 (3.2205)	grad_norm 4.9457 (4.8285)	mem 8926MB
[2022-04-08 12:26:24 large] (main.py 226): INFO Train: [187/300][2500/2502]	eta 0:00:01 lr 0.000157	time 0.5066 (0.5071)	loss 2.5373 (3.2176)	grad_norm 4.7108 (4.8345)	mem 8926MB
[2022-04-08 12:26:25 large] (main.py 233): INFO EPOCH 187 training takes 0:21:09
[2022-04-08 12:26:31 large] (main.py 273): INFO Test: [0/98]	Time 6.484 (6.484)	Loss 1.0807 (1.0807)	Acc@1 80.273 (80.273)	Acc@5 94.531 (94.531)	Mem 8926MB
[2022-04-08 12:26:57 large] (main.py 279): INFO  * Acc@1 78.902 Acc@5 94.552
[2022-04-08 12:26:57 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 78.9%
[2022-04-08 12:26:57 large] (main.py 148): INFO Max accuracy: 78.99%
[2022-04-08 12:27:04 large] (main.py 226): INFO Train: [188/300][0/2502]	eta 4:52:12 lr 0.000157	time 7.0074 (7.0074)	loss 3.3603 (3.3603)	grad_norm 4.7609 (4.7609)	mem 8926MB
[2022-04-08 12:27:54 large] (main.py 226): INFO Train: [188/300][100/2502]	eta 0:22:37 lr 0.000156	time 0.4875 (0.5650)	loss 4.1654 (3.1492)	grad_norm 4.4438 (4.7002)	mem 8926MB
[2022-04-08 12:28:45 large] (main.py 226): INFO Train: [188/300][200/2502]	eta 0:20:33 lr 0.000156	time 0.5221 (0.5358)	loss 3.5323 (3.1435)	grad_norm 3.7014 (4.6714)	mem 8926MB
[2022-04-08 12:29:33 large] (main.py 226): INFO Train: [188/300][300/2502]	eta 0:19:05 lr 0.000156	time 0.4984 (0.5201)	loss 3.8891 (3.1748)	grad_norm 5.1779 (4.7094)	mem 8926MB
[2022-04-08 12:30:23 large] (main.py 226): INFO Train: [188/300][400/2502]	eta 0:18:01 lr 0.000156	time 0.5161 (0.5145)	loss 3.5572 (3.1805)	grad_norm 5.5078 (4.7290)	mem 8926MB
[2022-04-08 12:31:14 large] (main.py 226): INFO Train: [188/300][500/2502]	eta 0:17:08 lr 0.000156	time 0.4785 (0.5139)	loss 3.6343 (3.1829)	grad_norm 5.4969 (4.7544)	mem 8926MB
[2022-04-08 12:32:05 large] (main.py 226): INFO Train: [188/300][600/2502]	eta 0:16:15 lr 0.000156	time 0.5428 (0.5131)	loss 3.3512 (3.1944)	grad_norm 3.9823 (4.8269)	mem 8926MB
[2022-04-08 12:32:57 large] (main.py 226): INFO Train: [188/300][700/2502]	eta 0:15:26 lr 0.000156	time 0.4929 (0.5140)	loss 3.7630 (3.1883)	grad_norm 4.6884 (4.8152)	mem 8926MB
[2022-04-08 12:33:47 large] (main.py 226): INFO Train: [188/300][800/2502]	eta 0:14:31 lr 0.000156	time 0.5617 (0.5121)	loss 3.9210 (3.1975)	grad_norm 4.8461 (4.8633)	mem 8926MB
[2022-04-08 12:34:39 large] (main.py 226): INFO Train: [188/300][900/2502]	eta 0:13:41 lr 0.000156	time 0.5031 (0.5126)	loss 3.8613 (3.1948)	grad_norm 4.8121 (4.8583)	mem 8926MB
[2022-04-08 12:35:30 large] (main.py 226): INFO Train: [188/300][1000/2502]	eta 0:12:50 lr 0.000156	time 0.4932 (0.5131)	loss 3.3251 (3.2004)	grad_norm 4.1951 (4.8433)	mem 8926MB
[2022-04-08 12:36:22 large] (main.py 226): INFO Train: [188/300][1100/2502]	eta 0:12:00 lr 0.000156	time 0.5253 (0.5136)	loss 3.7364 (3.2089)	grad_norm 3.9882 (4.8433)	mem 8926MB
[2022-04-08 12:37:12 large] (main.py 226): INFO Train: [188/300][1200/2502]	eta 0:11:07 lr 0.000155	time 0.4795 (0.5125)	loss 3.2344 (3.1966)	grad_norm 4.1020 (4.8440)	mem 8926MB
[2022-04-08 12:38:01 large] (main.py 226): INFO Train: [188/300][1300/2502]	eta 0:10:13 lr 0.000155	time 0.5000 (0.5107)	loss 3.5862 (3.1950)	grad_norm 5.5396 (4.8303)	mem 8926MB
[2022-04-08 12:38:52 large] (main.py 226): INFO Train: [188/300][1400/2502]	eta 0:09:22 lr 0.000155	time 0.5029 (0.5107)	loss 3.9697 (3.1970)	grad_norm 5.8475 (4.8313)	mem 8926MB
[2022-04-08 12:39:44 large] (main.py 226): INFO Train: [188/300][1500/2502]	eta 0:08:32 lr 0.000155	time 0.5382 (0.5111)	loss 3.5155 (3.1931)	grad_norm 4.0617 (4.8318)	mem 8926MB
[2022-04-08 12:40:34 large] (main.py 226): INFO Train: [188/300][1600/2502]	eta 0:07:40 lr 0.000155	time 0.4781 (0.5103)	loss 3.5834 (3.1916)	grad_norm 3.9667 (4.8416)	mem 8926MB
[2022-04-08 12:41:23 large] (main.py 226): INFO Train: [188/300][1700/2502]	eta 0:06:48 lr 0.000155	time 0.5051 (0.5092)	loss 2.2642 (3.1846)	grad_norm 3.6792 (4.8274)	mem 8926MB
[2022-04-08 12:42:14 large] (main.py 226): INFO Train: [188/300][1800/2502]	eta 0:05:57 lr 0.000155	time 0.5428 (0.5094)	loss 3.6542 (3.1879)	grad_norm 5.1173 (4.8196)	mem 8926MB
[2022-04-08 12:43:04 large] (main.py 226): INFO Train: [188/300][1900/2502]	eta 0:05:06 lr 0.000155	time 0.5259 (0.5089)	loss 2.9756 (3.1888)	grad_norm 3.2707 (4.8188)	mem 8926MB
[2022-04-08 12:43:56 large] (main.py 226): INFO Train: [188/300][2000/2502]	eta 0:04:15 lr 0.000155	time 0.5908 (0.5091)	loss 3.3810 (3.1899)	grad_norm 4.5764 (4.8140)	mem 8926MB
[2022-04-08 12:44:47 large] (main.py 226): INFO Train: [188/300][2100/2502]	eta 0:03:24 lr 0.000155	time 0.5207 (0.5095)	loss 2.4075 (3.1858)	grad_norm 3.1846 (4.8098)	mem 8926MB
[2022-04-08 12:45:39 large] (main.py 226): INFO Train: [188/300][2200/2502]	eta 0:02:33 lr 0.000154	time 0.5063 (0.5096)	loss 3.3760 (3.1900)	grad_norm 4.3052 (4.8090)	mem 8926MB
[2022-04-08 12:46:29 large] (main.py 226): INFO Train: [188/300][2300/2502]	eta 0:01:42 lr 0.000154	time 0.5432 (0.5095)	loss 2.8723 (3.1905)	grad_norm 3.5265 (nan)	mem 8926MB
[2022-04-08 12:47:18 large] (main.py 226): INFO Train: [188/300][2400/2502]	eta 0:00:51 lr 0.000154	time 0.4917 (0.5088)	loss 3.7201 (3.1922)	grad_norm 5.3696 (nan)	mem 8926MB
[2022-04-08 12:48:06 large] (main.py 226): INFO Train: [188/300][2500/2502]	eta 0:00:01 lr 0.000154	time 0.4804 (0.5076)	loss 3.6273 (3.1925)	grad_norm 3.8929 (nan)	mem 8926MB
[2022-04-08 12:48:07 large] (main.py 233): INFO EPOCH 188 training takes 0:21:10
[2022-04-08 12:48:14 large] (main.py 273): INFO Test: [0/98]	Time 6.336 (6.336)	Loss 1.0196 (1.0196)	Acc@1 79.492 (79.492)	Acc@5 95.117 (95.117)	Mem 8926MB
[2022-04-08 12:48:40 large] (main.py 279): INFO  * Acc@1 78.850 Acc@5 94.654
[2022-04-08 12:48:40 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 78.8%
[2022-04-08 12:48:40 large] (main.py 148): INFO Max accuracy: 78.99%
[2022-04-08 12:48:47 large] (main.py 226): INFO Train: [189/300][0/2502]	eta 4:54:26 lr 0.000154	time 7.0608 (7.0608)	loss 3.3870 (3.3870)	grad_norm 4.9690 (4.9690)	mem 8926MB
[2022-04-08 12:49:37 large] (main.py 226): INFO Train: [189/300][100/2502]	eta 0:22:33 lr 0.000154	time 0.5134 (0.5633)	loss 3.5729 (3.1896)	grad_norm 4.4653 (4.6340)	mem 8926MB
[2022-04-08 12:50:28 large] (main.py 226): INFO Train: [189/300][200/2502]	eta 0:20:41 lr 0.000154	time 0.6245 (0.5394)	loss 2.9679 (3.2387)	grad_norm 5.4390 (4.8089)	mem 8926MB
[2022-04-08 12:51:20 large] (main.py 226): INFO Train: [189/300][300/2502]	eta 0:19:32 lr 0.000154	time 0.4805 (0.5323)	loss 2.5393 (3.2139)	grad_norm 4.4201 (4.8067)	mem 8926MB
[2022-04-08 12:52:10 large] (main.py 226): INFO Train: [189/300][400/2502]	eta 0:18:23 lr 0.000154	time 0.5019 (0.5249)	loss 2.5767 (3.1795)	grad_norm 4.4398 (4.8030)	mem 8926MB
[2022-04-08 12:53:02 large] (main.py 226): INFO Train: [189/300][500/2502]	eta 0:17:29 lr 0.000154	time 0.5024 (0.5243)	loss 2.6009 (3.1842)	grad_norm 4.0170 (4.8142)	mem 8926MB
[2022-04-08 12:53:54 large] (main.py 226): INFO Train: [189/300][600/2502]	eta 0:16:34 lr 0.000154	time 0.5229 (0.5228)	loss 3.6510 (3.1956)	grad_norm 5.5754 (4.8350)	mem 8926MB
[2022-04-08 12:54:45 large] (main.py 226): INFO Train: [189/300][700/2502]	eta 0:15:40 lr 0.000154	time 0.5354 (0.5217)	loss 3.2860 (3.1809)	grad_norm 3.5671 (nan)	mem 8926MB
[2022-04-08 12:55:37 large] (main.py 226): INFO Train: [189/300][800/2502]	eta 0:14:46 lr 0.000153	time 0.5225 (0.5208)	loss 3.3212 (3.1803)	grad_norm 3.9408 (nan)	mem 8926MB
[2022-04-08 12:56:29 large] (main.py 226): INFO Train: [189/300][900/2502]	eta 0:13:54 lr 0.000153	time 0.5205 (0.5206)	loss 3.4719 (3.1755)	grad_norm 3.7947 (nan)	mem 8926MB
[2022-04-08 12:57:20 large] (main.py 226): INFO Train: [189/300][1000/2502]	eta 0:13:00 lr 0.000153	time 0.4991 (0.5199)	loss 2.8592 (3.1723)	grad_norm 3.5355 (nan)	mem 8926MB
[2022-04-08 12:58:11 large] (main.py 226): INFO Train: [189/300][1100/2502]	eta 0:12:08 lr 0.000153	time 0.5371 (0.5193)	loss 3.3011 (3.1703)	grad_norm 3.7738 (nan)	mem 8926MB
[2022-04-08 12:59:02 large] (main.py 226): INFO Train: [189/300][1200/2502]	eta 0:11:15 lr 0.000153	time 0.4492 (0.5184)	loss 3.2547 (3.1701)	grad_norm 6.4406 (nan)	mem 8926MB
[2022-04-08 12:59:52 large] (main.py 226): INFO Train: [189/300][1300/2502]	eta 0:10:20 lr 0.000153	time 0.4747 (0.5165)	loss 2.4768 (3.1700)	grad_norm 4.2341 (nan)	mem 8926MB
[2022-04-08 13:00:41 large] (main.py 226): INFO Train: [189/300][1400/2502]	eta 0:09:27 lr 0.000153	time 0.5064 (0.5151)	loss 3.8666 (3.1662)	grad_norm 5.1989 (nan)	mem 8926MB
[2022-04-08 13:01:33 large] (main.py 226): INFO Train: [189/300][1500/2502]	eta 0:08:35 lr 0.000153	time 0.5200 (0.5149)	loss 3.1023 (3.1685)	grad_norm 4.3739 (nan)	mem 8926MB
[2022-04-08 13:02:23 large] (main.py 226): INFO Train: [189/300][1600/2502]	eta 0:07:43 lr 0.000153	time 0.4976 (0.5140)	loss 3.0354 (3.1689)	grad_norm 3.7166 (nan)	mem 8926MB
[2022-04-08 13:03:12 large] (main.py 226): INFO Train: [189/300][1700/2502]	eta 0:06:51 lr 0.000153	time 0.4991 (0.5129)	loss 2.9361 (3.1682)	grad_norm 4.9994 (nan)	mem 8926MB
[2022-04-08 13:04:02 large] (main.py 226): INFO Train: [189/300][1800/2502]	eta 0:05:59 lr 0.000152	time 0.5011 (0.5121)	loss 3.1539 (3.1689)	grad_norm 5.2866 (nan)	mem 8926MB
[2022-04-08 13:04:53 large] (main.py 226): INFO Train: [189/300][1900/2502]	eta 0:05:08 lr 0.000152	time 0.5221 (0.5120)	loss 3.8758 (3.1698)	grad_norm 4.2607 (nan)	mem 8926MB
[2022-04-08 13:05:45 large] (main.py 226): INFO Train: [189/300][2000/2502]	eta 0:04:17 lr 0.000152	time 0.4848 (0.5122)	loss 2.3294 (3.1729)	grad_norm 6.3988 (nan)	mem 8926MB
[2022-04-08 13:06:33 large] (main.py 226): INFO Train: [189/300][2100/2502]	eta 0:03:25 lr 0.000152	time 0.4799 (0.5110)	loss 3.6910 (3.1731)	grad_norm 4.5443 (nan)	mem 8926MB
[2022-04-08 13:07:24 large] (main.py 226): INFO Train: [189/300][2200/2502]	eta 0:02:34 lr 0.000152	time 0.4788 (0.5108)	loss 2.9508 (3.1733)	grad_norm 5.0130 (nan)	mem 8926MB
[2022-04-08 13:08:14 large] (main.py 226): INFO Train: [189/300][2300/2502]	eta 0:01:43 lr 0.000152	time 0.4880 (0.5105)	loss 3.5085 (3.1773)	grad_norm 5.6051 (nan)	mem 8926MB
[2022-04-08 13:09:05 large] (main.py 226): INFO Train: [189/300][2400/2502]	eta 0:00:52 lr 0.000152	time 0.5048 (0.5105)	loss 2.9806 (3.1781)	grad_norm 4.6067 (nan)	mem 8926MB
[2022-04-08 13:09:57 large] (main.py 226): INFO Train: [189/300][2500/2502]	eta 0:00:01 lr 0.000152	time 0.4966 (0.5105)	loss 3.2416 (3.1755)	grad_norm 3.9427 (nan)	mem 8926MB
[2022-04-08 13:09:58 large] (main.py 233): INFO EPOCH 189 training takes 0:21:17
[2022-04-08 13:10:04 large] (main.py 273): INFO Test: [0/98]	Time 6.423 (6.423)	Loss 1.0616 (1.0616)	Acc@1 78.125 (78.125)	Acc@5 95.117 (95.117)	Mem 8926MB
[2022-04-08 13:10:30 large] (main.py 279): INFO  * Acc@1 79.000 Acc@5 94.432
[2022-04-08 13:10:30 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 79.0%
[2022-04-08 13:10:30 large] (utils.py 57): INFO output/large/default/ckpt_epoch_189.pth saving......
[2022-04-08 13:10:31 large] (utils.py 59): INFO output/large/default/ckpt_epoch_189.pth saved !!!
[2022-04-08 13:10:31 large] (main.py 148): INFO Max accuracy: 79.00%
[2022-04-08 13:10:39 large] (main.py 226): INFO Train: [190/300][0/2502]	eta 5:26:21 lr 0.000152	time 7.8264 (7.8264)	loss 3.5760 (3.5760)	grad_norm 4.1915 (4.1915)	mem 8926MB
[2022-04-08 13:11:27 large] (main.py 226): INFO Train: [190/300][100/2502]	eta 0:22:24 lr 0.000152	time 0.4656 (0.5596)	loss 2.3832 (3.1707)	grad_norm 5.1010 (4.8489)	mem 8926MB
[2022-04-08 13:12:17 large] (main.py 226): INFO Train: [190/300][200/2502]	eta 0:20:14 lr 0.000152	time 0.5166 (0.5276)	loss 3.6853 (3.2192)	grad_norm 6.8988 (4.8623)	mem 8926MB
[2022-04-08 13:13:09 large] (main.py 226): INFO Train: [190/300][300/2502]	eta 0:19:16 lr 0.000152	time 0.5060 (0.5253)	loss 3.0637 (3.1789)	grad_norm 3.3543 (4.8662)	mem 8926MB
[2022-04-08 13:14:01 large] (main.py 226): INFO Train: [190/300][400/2502]	eta 0:18:20 lr 0.000151	time 0.4969 (0.5237)	loss 3.3981 (3.1865)	grad_norm 4.3844 (4.8530)	mem 8926MB
[2022-04-08 13:14:52 large] (main.py 226): INFO Train: [190/300][500/2502]	eta 0:17:24 lr 0.000151	time 0.4840 (0.5215)	loss 2.1040 (3.1691)	grad_norm 5.9072 (4.8309)	mem 8926MB
[2022-04-08 13:15:42 large] (main.py 226): INFO Train: [190/300][600/2502]	eta 0:16:24 lr 0.000151	time 0.5217 (0.5176)	loss 2.3034 (3.1742)	grad_norm 3.7604 (4.8154)	mem 8926MB
[2022-04-08 13:16:34 large] (main.py 226): INFO Train: [190/300][700/2502]	eta 0:15:32 lr 0.000151	time 0.4855 (0.5176)	loss 2.7985 (3.1795)	grad_norm 4.6895 (4.8090)	mem 8926MB
[2022-04-08 13:17:23 large] (main.py 226): INFO Train: [190/300][800/2502]	eta 0:14:35 lr 0.000151	time 0.4933 (0.5145)	loss 3.4432 (3.1770)	grad_norm 4.9944 (4.8083)	mem 8926MB
[2022-04-08 13:18:11 large] (main.py 226): INFO Train: [190/300][900/2502]	eta 0:13:38 lr 0.000151	time 0.4580 (0.5112)	loss 2.6914 (3.1755)	grad_norm 4.8702 (4.8261)	mem 8926MB
[2022-04-08 13:19:01 large] (main.py 226): INFO Train: [190/300][1000/2502]	eta 0:12:44 lr 0.000151	time 0.5003 (0.5093)	loss 3.4402 (3.1742)	grad_norm 4.3220 (4.8292)	mem 8926MB
[2022-04-08 13:19:52 large] (main.py 226): INFO Train: [190/300][1100/2502]	eta 0:11:54 lr 0.000151	time 0.5056 (0.5099)	loss 3.3379 (3.1673)	grad_norm 6.3802 (4.8485)	mem 8926MB
[2022-04-08 13:20:42 large] (main.py 226): INFO Train: [190/300][1200/2502]	eta 0:11:02 lr 0.000151	time 0.5178 (0.5086)	loss 3.2977 (3.1649)	grad_norm 5.0938 (4.8504)	mem 8926MB
[2022-04-08 13:21:31 large] (main.py 226): INFO Train: [190/300][1300/2502]	eta 0:10:10 lr 0.000151	time 0.4556 (0.5077)	loss 2.9650 (3.1601)	grad_norm 5.3178 (4.8536)	mem 8926MB
[2022-04-08 13:22:20 large] (main.py 226): INFO Train: [190/300][1400/2502]	eta 0:09:17 lr 0.000151	time 0.5302 (0.5061)	loss 3.1456 (3.1624)	grad_norm 4.6156 (4.8727)	mem 8926MB
[2022-04-08 13:23:08 large] (main.py 226): INFO Train: [190/300][1500/2502]	eta 0:08:25 lr 0.000150	time 0.4964 (0.5045)	loss 3.4675 (3.1642)	grad_norm 4.9057 (4.8712)	mem 8926MB
[2022-04-08 13:23:56 large] (main.py 226): INFO Train: [190/300][1600/2502]	eta 0:07:33 lr 0.000150	time 0.4773 (0.5030)	loss 2.6573 (3.1706)	grad_norm 3.8719 (4.8598)	mem 8926MB
[2022-04-08 13:24:46 large] (main.py 226): INFO Train: [190/300][1700/2502]	eta 0:06:43 lr 0.000150	time 0.5344 (0.5026)	loss 3.5005 (3.1705)	grad_norm 4.1205 (4.8626)	mem 8926MB
[2022-04-08 13:25:36 large] (main.py 226): INFO Train: [190/300][1800/2502]	eta 0:05:52 lr 0.000150	time 0.5220 (0.5025)	loss 2.3338 (3.1680)	grad_norm 5.0292 (4.8530)	mem 8926MB
[2022-04-08 13:26:28 large] (main.py 226): INFO Train: [190/300][1900/2502]	eta 0:05:02 lr 0.000150	time 0.5440 (0.5033)	loss 3.3344 (3.1702)	grad_norm 4.2571 (4.8666)	mem 8926MB
[2022-04-08 13:27:20 large] (main.py 226): INFO Train: [190/300][2000/2502]	eta 0:04:13 lr 0.000150	time 0.5129 (0.5042)	loss 3.3373 (3.1729)	grad_norm 4.5761 (4.8799)	mem 8926MB
[2022-04-08 13:28:12 large] (main.py 226): INFO Train: [190/300][2100/2502]	eta 0:03:22 lr 0.000150	time 0.4952 (0.5049)	loss 3.7078 (3.1746)	grad_norm 4.7086 (4.8638)	mem 8926MB
[2022-04-08 13:29:03 large] (main.py 226): INFO Train: [190/300][2200/2502]	eta 0:02:32 lr 0.000150	time 0.5039 (0.5054)	loss 2.0032 (3.1765)	grad_norm 4.9226 (4.8565)	mem 8926MB
[2022-04-08 13:29:55 large] (main.py 226): INFO Train: [190/300][2300/2502]	eta 0:01:42 lr 0.000150	time 0.5148 (0.5058)	loss 3.2054 (3.1762)	grad_norm 5.3481 (nan)	mem 8926MB
[2022-04-08 13:30:46 large] (main.py 226): INFO Train: [190/300][2400/2502]	eta 0:00:51 lr 0.000150	time 0.5109 (0.5061)	loss 2.6246 (3.1751)	grad_norm 4.2176 (nan)	mem 8926MB
[2022-04-08 13:31:37 large] (main.py 226): INFO Train: [190/300][2500/2502]	eta 0:00:01 lr 0.000149	time 0.5048 (0.5063)	loss 2.8394 (3.1765)	grad_norm 5.9645 (nan)	mem 8926MB
[2022-04-08 13:31:38 large] (main.py 233): INFO EPOCH 190 training takes 0:21:07
[2022-04-08 13:31:44 large] (main.py 273): INFO Test: [0/98]	Time 6.113 (6.113)	Loss 0.9715 (0.9715)	Acc@1 80.469 (80.469)	Acc@5 95.312 (95.312)	Mem 8926MB
[2022-04-08 13:32:10 large] (main.py 279): INFO  * Acc@1 78.878 Acc@5 94.504
[2022-04-08 13:32:10 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 78.9%
[2022-04-08 13:32:10 large] (main.py 148): INFO Max accuracy: 79.00%
[2022-04-08 13:32:18 large] (main.py 226): INFO Train: [191/300][0/2502]	eta 5:08:32 lr 0.000149	time 7.3990 (7.3990)	loss 3.0129 (3.0129)	grad_norm 4.3189 (4.3189)	mem 8926MB
[2022-04-08 13:33:08 large] (main.py 226): INFO Train: [191/300][100/2502]	eta 0:22:45 lr 0.000149	time 0.4877 (0.5685)	loss 3.3078 (3.1234)	grad_norm 4.4980 (5.0210)	mem 8926MB
[2022-04-08 13:33:58 large] (main.py 226): INFO Train: [191/300][200/2502]	eta 0:20:28 lr 0.000149	time 0.5249 (0.5337)	loss 3.0507 (3.1674)	grad_norm 4.8542 (4.9571)	mem 8926MB
[2022-04-08 13:34:49 large] (main.py 226): INFO Train: [191/300][300/2502]	eta 0:19:16 lr 0.000149	time 0.5496 (0.5250)	loss 3.5602 (3.1918)	grad_norm 4.9494 (4.8547)	mem 8926MB
[2022-04-08 13:35:41 large] (main.py 226): INFO Train: [191/300][400/2502]	eta 0:18:22 lr 0.000149	time 0.5872 (0.5247)	loss 2.4575 (3.1728)	grad_norm 4.5285 (4.8550)	mem 8926MB
[2022-04-08 13:36:31 large] (main.py 226): INFO Train: [191/300][500/2502]	eta 0:17:22 lr 0.000149	time 0.5079 (0.5208)	loss 2.8730 (3.1929)	grad_norm 4.3463 (4.8397)	mem 8926MB
[2022-04-08 13:37:20 large] (main.py 226): INFO Train: [191/300][600/2502]	eta 0:16:20 lr 0.000149	time 0.5263 (0.5157)	loss 2.2714 (3.1727)	grad_norm 5.0821 (4.8214)	mem 8926MB
[2022-04-08 13:38:12 large] (main.py 226): INFO Train: [191/300][700/2502]	eta 0:15:29 lr 0.000149	time 0.5240 (0.5157)	loss 3.2647 (3.1746)	grad_norm 4.8332 (nan)	mem 8926MB
[2022-04-08 13:39:04 large] (main.py 226): INFO Train: [191/300][800/2502]	eta 0:14:37 lr 0.000149	time 0.5780 (0.5157)	loss 3.3660 (3.1624)	grad_norm 6.1957 (nan)	mem 8926MB
[2022-04-08 13:39:53 large] (main.py 226): INFO Train: [191/300][900/2502]	eta 0:13:42 lr 0.000149	time 0.5037 (0.5135)	loss 3.4971 (3.1587)	grad_norm 4.0175 (nan)	mem 8926MB
[2022-04-08 13:40:43 large] (main.py 226): INFO Train: [191/300][1000/2502]	eta 0:12:48 lr 0.000149	time 0.4908 (0.5116)	loss 3.1643 (3.1617)	grad_norm 5.2412 (nan)	mem 8926MB
[2022-04-08 13:41:34 large] (main.py 226): INFO Train: [191/300][1100/2502]	eta 0:11:57 lr 0.000148	time 0.5022 (0.5115)	loss 3.3032 (3.1719)	grad_norm 4.7279 (nan)	mem 8926MB
[2022-04-08 13:42:26 large] (main.py 226): INFO Train: [191/300][1200/2502]	eta 0:11:06 lr 0.000148	time 0.4699 (0.5123)	loss 4.0606 (3.1738)	grad_norm 4.6509 (nan)	mem 8926MB
[2022-04-08 13:43:17 large] (main.py 226): INFO Train: [191/300][1300/2502]	eta 0:10:16 lr 0.000148	time 0.5391 (0.5125)	loss 2.3823 (3.1745)	grad_norm 3.9277 (nan)	mem 8926MB
[2022-04-08 13:44:07 large] (main.py 226): INFO Train: [191/300][1400/2502]	eta 0:09:23 lr 0.000148	time 0.4881 (0.5116)	loss 2.8453 (3.1710)	grad_norm 5.0705 (nan)	mem 8926MB
[2022-04-08 13:44:56 large] (main.py 226): INFO Train: [191/300][1500/2502]	eta 0:08:31 lr 0.000148	time 0.4527 (0.5101)	loss 3.1785 (3.1673)	grad_norm 3.2580 (nan)	mem 8926MB
[2022-04-08 13:45:46 large] (main.py 226): INFO Train: [191/300][1600/2502]	eta 0:07:39 lr 0.000148	time 0.5512 (0.5091)	loss 3.4106 (3.1689)	grad_norm 4.0852 (nan)	mem 8926MB
[2022-04-08 13:46:36 large] (main.py 226): INFO Train: [191/300][1700/2502]	eta 0:06:48 lr 0.000148	time 0.5047 (0.5090)	loss 2.7587 (3.1657)	grad_norm 6.2595 (nan)	mem 8926MB
[2022-04-08 13:47:27 large] (main.py 226): INFO Train: [191/300][1800/2502]	eta 0:05:57 lr 0.000148	time 0.6459 (0.5087)	loss 2.7219 (3.1625)	grad_norm 4.5146 (nan)	mem 8926MB
[2022-04-08 13:48:18 large] (main.py 226): INFO Train: [191/300][1900/2502]	eta 0:05:06 lr 0.000148	time 0.4436 (0.5089)	loss 2.6347 (3.1635)	grad_norm 4.2482 (nan)	mem 8926MB
[2022-04-08 13:49:08 large] (main.py 226): INFO Train: [191/300][2000/2502]	eta 0:04:15 lr 0.000148	time 0.4962 (0.5083)	loss 3.5354 (3.1686)	grad_norm 5.6078 (nan)	mem 8926MB
[2022-04-08 13:49:57 large] (main.py 226): INFO Train: [191/300][2100/2502]	eta 0:03:24 lr 0.000147	time 0.5085 (0.5077)	loss 3.9226 (3.1708)	grad_norm 5.4208 (nan)	mem 8926MB
[2022-04-08 13:50:48 large] (main.py 226): INFO Train: [191/300][2200/2502]	eta 0:02:33 lr 0.000147	time 0.5172 (0.5079)	loss 3.1160 (3.1730)	grad_norm 4.0950 (nan)	mem 8926MB
[2022-04-08 13:51:40 large] (main.py 226): INFO Train: [191/300][2300/2502]	eta 0:01:42 lr 0.000147	time 0.5205 (0.5082)	loss 3.2282 (3.1743)	grad_norm 5.0735 (nan)	mem 8926MB
[2022-04-08 13:52:31 large] (main.py 226): INFO Train: [191/300][2400/2502]	eta 0:00:51 lr 0.000147	time 0.5152 (0.5082)	loss 3.7249 (3.1744)	grad_norm 3.4901 (nan)	mem 8926MB
[2022-04-08 13:53:20 large] (main.py 226): INFO Train: [191/300][2500/2502]	eta 0:00:01 lr 0.000147	time 0.4988 (0.5077)	loss 3.0161 (3.1753)	grad_norm 4.2292 (nan)	mem 8926MB
[2022-04-08 13:53:21 large] (main.py 233): INFO EPOCH 191 training takes 0:21:10
[2022-04-08 13:53:28 large] (main.py 273): INFO Test: [0/98]	Time 6.853 (6.853)	Loss 1.0340 (1.0340)	Acc@1 79.883 (79.883)	Acc@5 93.555 (93.555)	Mem 8926MB
[2022-04-08 13:53:54 large] (main.py 279): INFO  * Acc@1 78.970 Acc@5 94.542
[2022-04-08 13:53:54 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 79.0%
[2022-04-08 13:53:54 large] (main.py 148): INFO Max accuracy: 79.00%
[2022-04-08 13:54:01 large] (main.py 226): INFO Train: [192/300][0/2502]	eta 4:46:53 lr 0.000147	time 6.8800 (6.8800)	loss 3.1991 (3.1991)	grad_norm 3.9834 (3.9834)	mem 8926MB
[2022-04-08 13:54:52 large] (main.py 226): INFO Train: [192/300][100/2502]	eta 0:23:08 lr 0.000147	time 0.5026 (0.5780)	loss 3.4956 (3.0892)	grad_norm 5.3542 (4.8219)	mem 8926MB
[2022-04-08 13:55:42 large] (main.py 226): INFO Train: [192/300][200/2502]	eta 0:20:44 lr 0.000147	time 0.4593 (0.5406)	loss 3.5076 (3.1237)	grad_norm 3.1596 (4.8347)	mem 8926MB
[2022-04-08 13:56:31 large] (main.py 226): INFO Train: [192/300][300/2502]	eta 0:19:11 lr 0.000147	time 0.5001 (0.5231)	loss 3.2121 (3.1322)	grad_norm 5.5071 (4.8508)	mem 8926MB
[2022-04-08 13:57:21 large] (main.py 226): INFO Train: [192/300][400/2502]	eta 0:18:04 lr 0.000147	time 0.4860 (0.5159)	loss 2.4354 (3.1334)	grad_norm 3.8722 (4.8696)	mem 8926MB
[2022-04-08 13:58:10 large] (main.py 226): INFO Train: [192/300][500/2502]	eta 0:17:04 lr 0.000147	time 0.5239 (0.5117)	loss 3.3022 (3.1277)	grad_norm 5.5098 (inf)	mem 8926MB
[2022-04-08 13:59:02 large] (main.py 226): INFO Train: [192/300][600/2502]	eta 0:16:16 lr 0.000147	time 0.5213 (0.5132)	loss 2.7398 (3.1415)	grad_norm 5.1087 (inf)	mem 8926MB
[2022-04-08 13:59:53 large] (main.py 226): INFO Train: [192/300][700/2502]	eta 0:15:22 lr 0.000146	time 0.4898 (0.5117)	loss 3.5824 (3.1555)	grad_norm 6.0623 (inf)	mem 8926MB
[2022-04-08 14:00:43 large] (main.py 226): INFO Train: [192/300][800/2502]	eta 0:14:30 lr 0.000146	time 0.5208 (0.5114)	loss 3.3624 (3.1681)	grad_norm 4.6278 (inf)	mem 8926MB
[2022-04-08 14:01:33 large] (main.py 226): INFO Train: [192/300][900/2502]	eta 0:13:36 lr 0.000146	time 0.4906 (0.5098)	loss 3.5557 (3.1736)	grad_norm 4.1416 (inf)	mem 8926MB
[2022-04-08 14:02:22 large] (main.py 226): INFO Train: [192/300][1000/2502]	eta 0:12:43 lr 0.000146	time 0.5019 (0.5080)	loss 3.6896 (3.1693)	grad_norm 3.3972 (inf)	mem 8926MB
[2022-04-08 14:03:14 large] (main.py 226): INFO Train: [192/300][1100/2502]	eta 0:11:53 lr 0.000146	time 0.4963 (0.5088)	loss 2.9734 (3.1676)	grad_norm 4.7975 (inf)	mem 8926MB
[2022-04-08 14:04:05 large] (main.py 226): INFO Train: [192/300][1200/2502]	eta 0:11:02 lr 0.000146	time 0.5195 (0.5091)	loss 3.6865 (3.1685)	grad_norm 4.3359 (inf)	mem 8926MB
[2022-04-08 14:04:55 large] (main.py 226): INFO Train: [192/300][1300/2502]	eta 0:10:10 lr 0.000146	time 0.5065 (0.5081)	loss 2.7289 (3.1657)	grad_norm 3.7788 (inf)	mem 8926MB
[2022-04-08 14:05:45 large] (main.py 226): INFO Train: [192/300][1400/2502]	eta 0:09:19 lr 0.000146	time 0.4838 (0.5076)	loss 3.2552 (3.1680)	grad_norm 3.6884 (inf)	mem 8926MB
[2022-04-08 14:06:35 large] (main.py 226): INFO Train: [192/300][1500/2502]	eta 0:08:28 lr 0.000146	time 0.5013 (0.5073)	loss 3.7747 (3.1690)	grad_norm 4.1616 (inf)	mem 8926MB
[2022-04-08 14:07:26 large] (main.py 226): INFO Train: [192/300][1600/2502]	eta 0:07:37 lr 0.000146	time 0.5024 (0.5071)	loss 3.2689 (3.1734)	grad_norm 5.8316 (inf)	mem 8926MB
[2022-04-08 14:08:16 large] (main.py 226): INFO Train: [192/300][1700/2502]	eta 0:06:46 lr 0.000146	time 0.5017 (0.5067)	loss 3.2722 (3.1791)	grad_norm 5.9021 (inf)	mem 8926MB
[2022-04-08 14:09:05 large] (main.py 226): INFO Train: [192/300][1800/2502]	eta 0:05:55 lr 0.000145	time 0.5011 (0.5059)	loss 3.0306 (3.1799)	grad_norm 4.4274 (inf)	mem 8926MB
[2022-04-08 14:09:56 large] (main.py 226): INFO Train: [192/300][1900/2502]	eta 0:05:04 lr 0.000145	time 0.4951 (0.5061)	loss 2.7737 (3.1799)	grad_norm 7.5813 (inf)	mem 8926MB
[2022-04-08 14:10:47 large] (main.py 226): INFO Train: [192/300][2000/2502]	eta 0:04:14 lr 0.000145	time 0.4376 (0.5063)	loss 3.4630 (3.1757)	grad_norm 3.8942 (inf)	mem 8926MB
[2022-04-08 14:11:37 large] (main.py 226): INFO Train: [192/300][2100/2502]	eta 0:03:23 lr 0.000145	time 0.4871 (0.5058)	loss 3.7455 (3.1766)	grad_norm 4.2677 (inf)	mem 8926MB
[2022-04-08 14:12:27 large] (main.py 226): INFO Train: [192/300][2200/2502]	eta 0:02:32 lr 0.000145	time 0.5354 (0.5057)	loss 2.9276 (3.1780)	grad_norm 3.6590 (inf)	mem 8926MB
[2022-04-08 14:13:17 large] (main.py 226): INFO Train: [192/300][2300/2502]	eta 0:01:42 lr 0.000145	time 0.5279 (0.5054)	loss 3.8551 (3.1775)	grad_norm 3.7325 (inf)	mem 8926MB
[2022-04-08 14:14:08 large] (main.py 226): INFO Train: [192/300][2400/2502]	eta 0:00:51 lr 0.000145	time 0.5273 (0.5057)	loss 3.7419 (3.1751)	grad_norm 5.5400 (inf)	mem 8926MB
[2022-04-08 14:14:59 large] (main.py 226): INFO Train: [192/300][2500/2502]	eta 0:00:01 lr 0.000145	time 0.4863 (0.5057)	loss 3.6192 (3.1775)	grad_norm 4.4514 (inf)	mem 8926MB
[2022-04-08 14:15:00 large] (main.py 233): INFO EPOCH 192 training takes 0:21:05
[2022-04-08 14:15:06 large] (main.py 273): INFO Test: [0/98]	Time 6.487 (6.487)	Loss 0.9724 (0.9724)	Acc@1 81.055 (81.055)	Acc@5 95.312 (95.312)	Mem 8926MB
[2022-04-08 14:15:32 large] (main.py 279): INFO  * Acc@1 79.040 Acc@5 94.528
[2022-04-08 14:15:32 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 79.0%
[2022-04-08 14:15:32 large] (utils.py 57): INFO output/large/default/ckpt_epoch_192.pth saving......
[2022-04-08 14:15:33 large] (utils.py 59): INFO output/large/default/ckpt_epoch_192.pth saved !!!
[2022-04-08 14:15:33 large] (main.py 148): INFO Max accuracy: 79.04%
[2022-04-08 14:15:42 large] (main.py 226): INFO Train: [193/300][0/2502]	eta 6:02:27 lr 0.000145	time 8.6919 (8.6919)	loss 3.4323 (3.4323)	grad_norm 3.9359 (3.9359)	mem 8926MB
[2022-04-08 14:16:30 large] (main.py 226): INFO Train: [193/300][100/2502]	eta 0:22:35 lr 0.000145	time 0.4399 (0.5643)	loss 3.4204 (3.2136)	grad_norm 4.0717 (4.6707)	mem 8926MB
[2022-04-08 14:17:19 large] (main.py 226): INFO Train: [193/300][200/2502]	eta 0:20:18 lr 0.000145	time 0.5025 (0.5295)	loss 4.0618 (3.1908)	grad_norm 6.0977 (4.8393)	mem 8926MB
[2022-04-08 14:18:10 large] (main.py 226): INFO Train: [193/300][300/2502]	eta 0:19:10 lr 0.000145	time 0.5217 (0.5225)	loss 3.5814 (3.1908)	grad_norm 6.4571 (4.8791)	mem 8926MB
[2022-04-08 14:19:00 large] (main.py 226): INFO Train: [193/300][400/2502]	eta 0:18:04 lr 0.000144	time 0.4791 (0.5160)	loss 3.6334 (3.1687)	grad_norm 4.9249 (4.9809)	mem 8926MB
[2022-04-08 14:19:49 large] (main.py 226): INFO Train: [193/300][500/2502]	eta 0:17:05 lr 0.000144	time 0.5065 (0.5121)	loss 2.9735 (3.1469)	grad_norm 4.4520 (4.9898)	mem 8926MB
[2022-04-08 14:20:39 large] (main.py 226): INFO Train: [193/300][600/2502]	eta 0:16:07 lr 0.000144	time 0.5479 (0.5084)	loss 3.4794 (3.1427)	grad_norm 5.8943 (5.0193)	mem 8926MB
[2022-04-08 14:21:27 large] (main.py 226): INFO Train: [193/300][700/2502]	eta 0:15:10 lr 0.000144	time 0.4907 (0.5053)	loss 3.3016 (3.1500)	grad_norm 5.0688 (5.0057)	mem 8926MB
[2022-04-08 14:22:18 large] (main.py 226): INFO Train: [193/300][800/2502]	eta 0:14:21 lr 0.000144	time 0.5138 (0.5063)	loss 2.5545 (3.1462)	grad_norm 4.3476 (4.9986)	mem 8926MB
[2022-04-08 14:23:10 large] (main.py 226): INFO Train: [193/300][900/2502]	eta 0:13:33 lr 0.000144	time 0.4909 (0.5076)	loss 2.5912 (3.1419)	grad_norm 4.1981 (4.9846)	mem 8926MB
[2022-04-08 14:24:02 large] (main.py 226): INFO Train: [193/300][1000/2502]	eta 0:12:44 lr 0.000144	time 0.5178 (0.5087)	loss 2.1122 (3.1529)	grad_norm 4.8572 (4.9786)	mem 8926MB
[2022-04-08 14:24:54 large] (main.py 226): INFO Train: [193/300][1100/2502]	eta 0:11:54 lr 0.000144	time 0.5027 (0.5093)	loss 2.8674 (3.1508)	grad_norm 4.3473 (4.9513)	mem 8926MB
[2022-04-08 14:25:45 large] (main.py 226): INFO Train: [193/300][1200/2502]	eta 0:11:03 lr 0.000144	time 0.5926 (0.5097)	loss 3.6243 (3.1616)	grad_norm 5.0573 (4.9579)	mem 8926MB
[2022-04-08 14:26:36 large] (main.py 226): INFO Train: [193/300][1300/2502]	eta 0:10:12 lr 0.000144	time 0.4942 (0.5093)	loss 3.1773 (3.1654)	grad_norm 3.7239 (4.9842)	mem 8926MB
[2022-04-08 14:27:24 large] (main.py 226): INFO Train: [193/300][1400/2502]	eta 0:09:19 lr 0.000143	time 0.4827 (0.5076)	loss 2.7162 (3.1690)	grad_norm 3.9114 (4.9588)	mem 8926MB
[2022-04-08 14:28:13 large] (main.py 226): INFO Train: [193/300][1500/2502]	eta 0:08:27 lr 0.000143	time 0.5177 (0.5062)	loss 3.3965 (3.1654)	grad_norm 5.1597 (4.9475)	mem 8926MB
[2022-04-08 14:29:04 large] (main.py 226): INFO Train: [193/300][1600/2502]	eta 0:07:37 lr 0.000143	time 0.4884 (0.5067)	loss 3.2493 (3.1654)	grad_norm 4.6090 (4.9457)	mem 8926MB
[2022-04-08 14:29:56 large] (main.py 226): INFO Train: [193/300][1700/2502]	eta 0:06:47 lr 0.000143	time 0.5052 (0.5077)	loss 3.7798 (3.1622)	grad_norm 4.4407 (4.9539)	mem 8926MB
[2022-04-08 14:30:48 large] (main.py 226): INFO Train: [193/300][1800/2502]	eta 0:05:56 lr 0.000143	time 0.5410 (0.5081)	loss 3.5515 (3.1669)	grad_norm 6.1900 (4.9419)	mem 8926MB
[2022-04-08 14:31:40 large] (main.py 226): INFO Train: [193/300][1900/2502]	eta 0:05:06 lr 0.000143	time 0.4504 (0.5088)	loss 3.6287 (3.1665)	grad_norm 5.8792 (4.9344)	mem 8926MB
[2022-04-08 14:32:30 large] (main.py 226): INFO Train: [193/300][2000/2502]	eta 0:04:15 lr 0.000143	time 0.4418 (0.5085)	loss 3.9913 (3.1715)	grad_norm 4.7019 (4.9253)	mem 8926MB
[2022-04-08 14:33:19 large] (main.py 226): INFO Train: [193/300][2100/2502]	eta 0:03:23 lr 0.000143	time 0.4737 (0.5074)	loss 3.6355 (3.1687)	grad_norm 3.8002 (4.9349)	mem 8926MB
[2022-04-08 14:34:07 large] (main.py 226): INFO Train: [193/300][2200/2502]	eta 0:02:32 lr 0.000143	time 0.4508 (0.5061)	loss 3.7516 (3.1706)	grad_norm 4.5744 (4.9364)	mem 8926MB
[2022-04-08 14:34:57 large] (main.py 226): INFO Train: [193/300][2300/2502]	eta 0:01:42 lr 0.000143	time 0.6051 (0.5061)	loss 3.5285 (3.1724)	grad_norm 4.3599 (4.9362)	mem 8926MB
[2022-04-08 14:35:50 large] (main.py 226): INFO Train: [193/300][2400/2502]	eta 0:00:51 lr 0.000143	time 0.5065 (0.5068)	loss 3.4519 (3.1752)	grad_norm 4.4537 (4.9363)	mem 8926MB
[2022-04-08 14:36:42 large] (main.py 226): INFO Train: [193/300][2500/2502]	eta 0:00:01 lr 0.000142	time 0.5103 (0.5073)	loss 3.6420 (3.1755)	grad_norm 4.9905 (4.9294)	mem 8926MB
[2022-04-08 14:36:43 large] (main.py 233): INFO EPOCH 193 training takes 0:21:09
[2022-04-08 14:36:50 large] (main.py 273): INFO Test: [0/98]	Time 6.967 (6.967)	Loss 0.9530 (0.9530)	Acc@1 80.664 (80.664)	Acc@5 95.898 (95.898)	Mem 8926MB
[2022-04-08 14:37:15 large] (main.py 279): INFO  * Acc@1 79.328 Acc@5 94.568
[2022-04-08 14:37:15 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 79.3%
[2022-04-08 14:37:15 large] (utils.py 57): INFO output/large/default/ckpt_epoch_193.pth saving......
[2022-04-08 14:37:15 large] (utils.py 59): INFO output/large/default/ckpt_epoch_193.pth saved !!!
[2022-04-08 14:37:15 large] (main.py 148): INFO Max accuracy: 79.33%
[2022-04-08 14:37:23 large] (main.py 226): INFO Train: [194/300][0/2502]	eta 5:33:44 lr 0.000142	time 8.0033 (8.0033)	loss 3.3205 (3.3205)	grad_norm 3.9115 (3.9115)	mem 8926MB
[2022-04-08 14:38:14 large] (main.py 226): INFO Train: [194/300][100/2502]	eta 0:23:14 lr 0.000142	time 0.5403 (0.5806)	loss 2.2232 (3.1374)	grad_norm 3.4583 (4.7839)	mem 8926MB
[2022-04-08 14:39:06 large] (main.py 226): INFO Train: [194/300][200/2502]	eta 0:21:07 lr 0.000142	time 0.5058 (0.5506)	loss 3.4274 (3.1759)	grad_norm 4.9209 (4.7761)	mem 8926MB
[2022-04-08 14:39:58 large] (main.py 226): INFO Train: [194/300][300/2502]	eta 0:19:51 lr 0.000142	time 0.5398 (0.5409)	loss 3.2967 (3.1977)	grad_norm 4.8669 (4.8122)	mem 8926MB
[2022-04-08 14:40:51 large] (main.py 226): INFO Train: [194/300][400/2502]	eta 0:18:47 lr 0.000142	time 0.5051 (0.5363)	loss 3.9178 (3.2027)	grad_norm 4.4389 (4.8546)	mem 8926MB
[2022-04-08 14:41:43 large] (main.py 226): INFO Train: [194/300][500/2502]	eta 0:17:48 lr 0.000142	time 0.5220 (0.5337)	loss 3.5339 (3.2020)	grad_norm 5.3987 (nan)	mem 8926MB
[2022-04-08 14:42:33 large] (main.py 226): INFO Train: [194/300][600/2502]	eta 0:16:45 lr 0.000142	time 0.5188 (0.5284)	loss 3.6879 (3.1867)	grad_norm 4.4501 (nan)	mem 8926MB
[2022-04-08 14:43:23 large] (main.py 226): INFO Train: [194/300][700/2502]	eta 0:15:44 lr 0.000142	time 0.5147 (0.5239)	loss 3.8137 (3.1912)	grad_norm 6.5818 (nan)	mem 8926MB
[2022-04-08 14:44:15 large] (main.py 226): INFO Train: [194/300][800/2502]	eta 0:14:51 lr 0.000142	time 0.5488 (0.5238)	loss 3.1974 (3.1864)	grad_norm 4.6410 (nan)	mem 8926MB
[2022-04-08 14:45:07 large] (main.py 226): INFO Train: [194/300][900/2502]	eta 0:13:59 lr 0.000142	time 0.5938 (0.5238)	loss 3.2125 (3.1948)	grad_norm 5.5518 (nan)	mem 8926MB
[2022-04-08 14:45:59 large] (main.py 226): INFO Train: [194/300][1000/2502]	eta 0:13:06 lr 0.000142	time 0.4854 (0.5234)	loss 3.7781 (3.1931)	grad_norm 4.4148 (nan)	mem 8926MB
[2022-04-08 14:46:50 large] (main.py 226): INFO Train: [194/300][1100/2502]	eta 0:12:11 lr 0.000141	time 0.4783 (0.5220)	loss 2.1338 (3.1899)	grad_norm 4.5375 (nan)	mem 8926MB
[2022-04-08 14:47:40 large] (main.py 226): INFO Train: [194/300][1200/2502]	eta 0:11:16 lr 0.000141	time 0.6144 (0.5198)	loss 2.7639 (3.1841)	grad_norm 4.4345 (nan)	mem 8926MB
[2022-04-08 14:48:32 large] (main.py 226): INFO Train: [194/300][1300/2502]	eta 0:10:24 lr 0.000141	time 0.5111 (0.5198)	loss 3.7476 (3.1842)	grad_norm 4.5198 (nan)	mem 8926MB
[2022-04-08 14:49:24 large] (main.py 226): INFO Train: [194/300][1400/2502]	eta 0:09:32 lr 0.000141	time 0.5335 (0.5199)	loss 3.7015 (3.1888)	grad_norm 5.2673 (nan)	mem 8926MB
[2022-04-08 14:50:16 large] (main.py 226): INFO Train: [194/300][1500/2502]	eta 0:08:40 lr 0.000141	time 0.5991 (0.5198)	loss 3.0219 (3.1891)	grad_norm 5.0764 (nan)	mem 8926MB
[2022-04-08 14:51:08 large] (main.py 226): INFO Train: [194/300][1600/2502]	eta 0:07:48 lr 0.000141	time 0.5104 (0.5198)	loss 3.7090 (3.1865)	grad_norm 4.9740 (nan)	mem 8926MB
[2022-04-08 14:51:59 large] (main.py 226): INFO Train: [194/300][1700/2502]	eta 0:06:56 lr 0.000141	time 0.5037 (0.5197)	loss 3.2446 (3.1883)	grad_norm 4.0327 (nan)	mem 8926MB
[2022-04-08 14:52:50 large] (main.py 226): INFO Train: [194/300][1800/2502]	eta 0:06:04 lr 0.000141	time 0.4832 (0.5188)	loss 3.0190 (3.1877)	grad_norm 4.8467 (nan)	mem 8926MB
[2022-04-08 14:53:39 large] (main.py 226): INFO Train: [194/300][1900/2502]	eta 0:05:11 lr 0.000141	time 0.4905 (0.5174)	loss 3.1179 (3.1921)	grad_norm 3.8611 (nan)	mem 8926MB
[2022-04-08 14:54:28 large] (main.py 226): INFO Train: [194/300][2000/2502]	eta 0:04:19 lr 0.000141	time 0.4765 (0.5160)	loss 2.3606 (3.1899)	grad_norm 4.7947 (nan)	mem 8926MB
[2022-04-08 14:55:19 large] (main.py 226): INFO Train: [194/300][2100/2502]	eta 0:03:27 lr 0.000141	time 0.5120 (0.5157)	loss 2.4147 (3.1866)	grad_norm 5.0277 (nan)	mem 8926MB
[2022-04-08 14:56:11 large] (main.py 226): INFO Train: [194/300][2200/2502]	eta 0:02:35 lr 0.000140	time 0.5204 (0.5159)	loss 4.2818 (3.1862)	grad_norm 4.2540 (nan)	mem 8926MB
[2022-04-08 14:57:03 large] (main.py 226): INFO Train: [194/300][2300/2502]	eta 0:01:44 lr 0.000140	time 0.5053 (0.5159)	loss 3.0928 (3.1867)	grad_norm 4.0740 (nan)	mem 8926MB
[2022-04-08 14:57:54 large] (main.py 226): INFO Train: [194/300][2400/2502]	eta 0:00:52 lr 0.000140	time 0.5087 (0.5159)	loss 3.9901 (3.1899)	grad_norm 5.2646 (nan)	mem 8926MB
[2022-04-08 14:58:43 large] (main.py 226): INFO Train: [194/300][2500/2502]	eta 0:00:01 lr 0.000140	time 0.4712 (0.5147)	loss 2.7323 (3.1872)	grad_norm 4.8675 (nan)	mem 8926MB
[2022-04-08 14:58:44 large] (main.py 233): INFO EPOCH 194 training takes 0:21:28
[2022-04-08 14:58:50 large] (main.py 273): INFO Test: [0/98]	Time 5.866 (5.866)	Loss 1.0007 (1.0007)	Acc@1 79.688 (79.688)	Acc@5 94.727 (94.727)	Mem 8926MB
[2022-04-08 14:59:16 large] (main.py 279): INFO  * Acc@1 79.082 Acc@5 94.552
[2022-04-08 14:59:16 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 79.1%
[2022-04-08 14:59:16 large] (main.py 148): INFO Max accuracy: 79.33%
[2022-04-08 14:59:23 large] (main.py 226): INFO Train: [195/300][0/2502]	eta 4:33:41 lr 0.000140	time 6.5633 (6.5633)	loss 2.1670 (2.1670)	grad_norm 6.6371 (6.6371)	mem 8926MB
[2022-04-08 15:00:14 large] (main.py 226): INFO Train: [195/300][100/2502]	eta 0:22:50 lr 0.000140	time 0.4961 (0.5704)	loss 3.4827 (3.1112)	grad_norm 4.9565 (4.6794)	mem 8926MB
[2022-04-08 15:01:06 large] (main.py 226): INFO Train: [195/300][200/2502]	eta 0:20:50 lr 0.000140	time 0.5093 (0.5433)	loss 3.0111 (3.1199)	grad_norm 3.9166 (4.7756)	mem 8926MB
[2022-04-08 15:01:55 large] (main.py 226): INFO Train: [195/300][300/2502]	eta 0:19:24 lr 0.000140	time 0.5218 (0.5287)	loss 3.7724 (3.1375)	grad_norm 6.8390 (4.7759)	mem 8926MB
[2022-04-08 15:02:47 large] (main.py 226): INFO Train: [195/300][400/2502]	eta 0:18:23 lr 0.000140	time 0.5512 (0.5248)	loss 3.5997 (3.1708)	grad_norm 4.5989 (4.7948)	mem 8926MB
[2022-04-08 15:03:37 large] (main.py 226): INFO Train: [195/300][500/2502]	eta 0:17:19 lr 0.000140	time 0.4769 (0.5194)	loss 3.7409 (3.1768)	grad_norm 5.1589 (nan)	mem 8926MB
[2022-04-08 15:04:27 large] (main.py 226): INFO Train: [195/300][600/2502]	eta 0:16:23 lr 0.000140	time 0.4805 (0.5173)	loss 3.3841 (3.1678)	grad_norm 4.4452 (nan)	mem 8926MB
[2022-04-08 15:05:19 large] (main.py 226): INFO Train: [195/300][700/2502]	eta 0:15:31 lr 0.000139	time 0.4899 (0.5167)	loss 3.1330 (3.1785)	grad_norm 4.0683 (nan)	mem 8926MB
[2022-04-08 15:06:08 large] (main.py 226): INFO Train: [195/300][800/2502]	eta 0:14:34 lr 0.000139	time 0.5012 (0.5138)	loss 2.6066 (3.1659)	grad_norm 5.8000 (nan)	mem 8926MB
[2022-04-08 15:06:56 large] (main.py 226): INFO Train: [195/300][900/2502]	eta 0:13:38 lr 0.000139	time 0.4657 (0.5107)	loss 3.5360 (3.1816)	grad_norm 5.4126 (nan)	mem 8926MB
[2022-04-08 15:07:45 large] (main.py 226): INFO Train: [195/300][1000/2502]	eta 0:12:43 lr 0.000139	time 0.4410 (0.5086)	loss 3.2871 (3.1837)	grad_norm 3.9458 (nan)	mem 8926MB
[2022-04-08 15:08:35 large] (main.py 226): INFO Train: [195/300][1100/2502]	eta 0:11:51 lr 0.000139	time 0.5413 (0.5073)	loss 3.0729 (3.1787)	grad_norm 4.6779 (nan)	mem 8926MB
[2022-04-08 15:09:25 large] (main.py 226): INFO Train: [195/300][1200/2502]	eta 0:11:00 lr 0.000139	time 0.4770 (0.5072)	loss 3.7969 (3.1690)	grad_norm 5.1163 (nan)	mem 8926MB
[2022-04-08 15:10:15 large] (main.py 226): INFO Train: [195/300][1300/2502]	eta 0:10:08 lr 0.000139	time 0.4940 (0.5062)	loss 2.8072 (3.1634)	grad_norm 6.4663 (nan)	mem 8926MB
[2022-04-08 15:11:06 large] (main.py 226): INFO Train: [195/300][1400/2502]	eta 0:09:18 lr 0.000139	time 0.5023 (0.5065)	loss 3.2083 (3.1693)	grad_norm 7.4237 (nan)	mem 8926MB
[2022-04-08 15:11:57 large] (main.py 226): INFO Train: [195/300][1500/2502]	eta 0:08:27 lr 0.000139	time 0.5199 (0.5065)	loss 3.1089 (3.1705)	grad_norm 4.5392 (nan)	mem 8926MB
[2022-04-08 15:12:47 large] (main.py 226): INFO Train: [195/300][1600/2502]	eta 0:07:37 lr 0.000139	time 0.5251 (0.5067)	loss 3.7974 (3.1729)	grad_norm 4.6792 (nan)	mem 8926MB
[2022-04-08 15:13:38 large] (main.py 226): INFO Train: [195/300][1700/2502]	eta 0:06:46 lr 0.000139	time 0.4826 (0.5064)	loss 3.4662 (3.1710)	grad_norm 6.0033 (nan)	mem 8926MB
[2022-04-08 15:14:26 large] (main.py 226): INFO Train: [195/300][1800/2502]	eta 0:05:54 lr 0.000138	time 0.4790 (0.5052)	loss 2.9619 (3.1690)	grad_norm 4.6898 (nan)	mem 8926MB
[2022-04-08 15:15:16 large] (main.py 226): INFO Train: [195/300][1900/2502]	eta 0:05:04 lr 0.000138	time 0.4926 (0.5050)	loss 3.2431 (3.1722)	grad_norm 4.0062 (nan)	mem 8926MB
[2022-04-08 15:16:06 large] (main.py 226): INFO Train: [195/300][2000/2502]	eta 0:04:13 lr 0.000138	time 0.5093 (0.5044)	loss 3.6284 (3.1729)	grad_norm 5.5092 (nan)	mem 8926MB
[2022-04-08 15:16:55 large] (main.py 226): INFO Train: [195/300][2100/2502]	eta 0:03:22 lr 0.000138	time 0.4923 (0.5037)	loss 3.0592 (3.1757)	grad_norm 5.4047 (nan)	mem 8926MB
[2022-04-08 15:17:44 large] (main.py 226): INFO Train: [195/300][2200/2502]	eta 0:02:31 lr 0.000138	time 0.4621 (0.5032)	loss 2.7933 (3.1786)	grad_norm 4.3538 (nan)	mem 8926MB
[2022-04-08 15:18:33 large] (main.py 226): INFO Train: [195/300][2300/2502]	eta 0:01:41 lr 0.000138	time 0.4969 (0.5027)	loss 3.0148 (3.1788)	grad_norm 4.4983 (nan)	mem 8926MB
[2022-04-08 15:19:21 large] (main.py 226): INFO Train: [195/300][2400/2502]	eta 0:00:51 lr 0.000138	time 0.4770 (0.5019)	loss 2.9976 (3.1793)	grad_norm 4.6070 (nan)	mem 8926MB
[2022-04-08 15:20:10 large] (main.py 226): INFO Train: [195/300][2500/2502]	eta 0:00:01 lr 0.000138	time 0.4820 (0.5011)	loss 3.5247 (3.1799)	grad_norm 4.8729 (nan)	mem 8926MB
[2022-04-08 15:20:11 large] (main.py 233): INFO EPOCH 195 training takes 0:20:54
[2022-04-08 15:20:17 large] (main.py 273): INFO Test: [0/98]	Time 6.264 (6.264)	Loss 1.0406 (1.0406)	Acc@1 80.469 (80.469)	Acc@5 94.336 (94.336)	Mem 8926MB
[2022-04-08 15:20:43 large] (main.py 279): INFO  * Acc@1 79.138 Acc@5 94.604
[2022-04-08 15:20:43 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 79.1%
[2022-04-08 15:20:43 large] (main.py 148): INFO Max accuracy: 79.33%
[2022-04-08 15:20:50 large] (main.py 226): INFO Train: [196/300][0/2502]	eta 5:12:19 lr 0.000138	time 7.4897 (7.4897)	loss 3.1890 (3.1890)	grad_norm 4.6805 (4.6805)	mem 8926MB
[2022-04-08 15:21:40 large] (main.py 226): INFO Train: [196/300][100/2502]	eta 0:22:52 lr 0.000138	time 0.5372 (0.5712)	loss 3.9041 (3.2252)	grad_norm 5.7933 (5.0913)	mem 8926MB
[2022-04-08 15:22:32 large] (main.py 226): INFO Train: [196/300][200/2502]	eta 0:20:50 lr 0.000138	time 0.4921 (0.5434)	loss 2.0523 (3.1659)	grad_norm 3.7422 (5.0392)	mem 8926MB
[2022-04-08 15:23:24 large] (main.py 226): INFO Train: [196/300][300/2502]	eta 0:19:39 lr 0.000138	time 0.5068 (0.5355)	loss 3.4473 (3.1444)	grad_norm 4.3996 (4.9803)	mem 8926MB
[2022-04-08 15:24:16 large] (main.py 226): INFO Train: [196/300][400/2502]	eta 0:18:35 lr 0.000137	time 0.4755 (0.5307)	loss 2.9132 (3.1434)	grad_norm 4.2347 (5.0303)	mem 8926MB
[2022-04-08 15:25:05 large] (main.py 226): INFO Train: [196/300][500/2502]	eta 0:17:29 lr 0.000137	time 0.5430 (0.5244)	loss 2.6937 (3.1426)	grad_norm 5.8642 (5.0038)	mem 8926MB
[2022-04-08 15:25:55 large] (main.py 226): INFO Train: [196/300][600/2502]	eta 0:16:27 lr 0.000137	time 0.5017 (0.5194)	loss 2.9434 (3.1409)	grad_norm 3.7192 (4.9685)	mem 8926MB
[2022-04-08 15:26:44 large] (main.py 226): INFO Train: [196/300][700/2502]	eta 0:15:29 lr 0.000137	time 0.4406 (0.5160)	loss 2.7934 (3.1365)	grad_norm 4.7526 (5.0415)	mem 8926MB
[2022-04-08 15:27:34 large] (main.py 226): INFO Train: [196/300][800/2502]	eta 0:14:33 lr 0.000137	time 0.4571 (0.5134)	loss 2.6361 (3.1311)	grad_norm 5.0663 (5.0416)	mem 8926MB
[2022-04-08 15:28:24 large] (main.py 226): INFO Train: [196/300][900/2502]	eta 0:13:40 lr 0.000137	time 0.4614 (0.5123)	loss 3.8697 (3.1308)	grad_norm 4.4880 (5.0219)	mem 8926MB
[2022-04-08 15:29:14 large] (main.py 226): INFO Train: [196/300][1000/2502]	eta 0:12:47 lr 0.000137	time 0.5159 (0.5108)	loss 2.5782 (3.1343)	grad_norm 6.0097 (5.0532)	mem 8926MB
[2022-04-08 15:30:04 large] (main.py 226): INFO Train: [196/300][1100/2502]	eta 0:11:54 lr 0.000137	time 0.5811 (0.5095)	loss 3.4831 (3.1362)	grad_norm 5.0494 (5.0377)	mem 8926MB
[2022-04-08 15:30:52 large] (main.py 226): INFO Train: [196/300][1200/2502]	eta 0:11:00 lr 0.000137	time 0.4808 (0.5077)	loss 3.8636 (3.1358)	grad_norm 7.6431 (5.0679)	mem 8926MB
[2022-04-08 15:31:42 large] (main.py 226): INFO Train: [196/300][1300/2502]	eta 0:10:08 lr 0.000137	time 0.4753 (0.5064)	loss 3.4165 (3.1372)	grad_norm 4.7921 (5.0610)	mem 8926MB
[2022-04-08 15:32:33 large] (main.py 226): INFO Train: [196/300][1400/2502]	eta 0:09:18 lr 0.000137	time 0.5055 (0.5069)	loss 3.4262 (3.1406)	grad_norm 4.7065 (5.0598)	mem 8926MB
[2022-04-08 15:33:23 large] (main.py 226): INFO Train: [196/300][1500/2502]	eta 0:08:27 lr 0.000136	time 0.4722 (0.5066)	loss 3.4808 (3.1392)	grad_norm 4.1264 (5.0602)	mem 8926MB
[2022-04-08 15:34:13 large] (main.py 226): INFO Train: [196/300][1600/2502]	eta 0:07:36 lr 0.000136	time 0.5072 (0.5062)	loss 3.1036 (3.1403)	grad_norm 3.3383 (5.0709)	mem 8926MB
[2022-04-08 15:35:04 large] (main.py 226): INFO Train: [196/300][1700/2502]	eta 0:06:46 lr 0.000136	time 0.4775 (0.5065)	loss 3.1301 (3.1418)	grad_norm 4.2224 (nan)	mem 8926MB
[2022-04-08 15:35:55 large] (main.py 226): INFO Train: [196/300][1800/2502]	eta 0:05:55 lr 0.000136	time 0.4918 (0.5067)	loss 2.5734 (3.1440)	grad_norm 5.6980 (nan)	mem 8926MB
[2022-04-08 15:36:46 large] (main.py 226): INFO Train: [196/300][1900/2502]	eta 0:05:05 lr 0.000136	time 0.4951 (0.5069)	loss 2.3621 (3.1407)	grad_norm 4.6278 (nan)	mem 8926MB
[2022-04-08 15:37:37 large] (main.py 226): INFO Train: [196/300][2000/2502]	eta 0:04:14 lr 0.000136	time 0.5007 (0.5068)	loss 3.5352 (3.1410)	grad_norm 4.1914 (nan)	mem 8926MB
[2022-04-08 15:38:27 large] (main.py 226): INFO Train: [196/300][2100/2502]	eta 0:03:23 lr 0.000136	time 0.4737 (0.5067)	loss 2.7506 (3.1454)	grad_norm 5.9880 (nan)	mem 8926MB
[2022-04-08 15:39:16 large] (main.py 226): INFO Train: [196/300][2200/2502]	eta 0:02:32 lr 0.000136	time 0.4447 (0.5057)	loss 3.5812 (3.1400)	grad_norm 4.6375 (nan)	mem 8926MB
[2022-04-08 15:40:05 large] (main.py 226): INFO Train: [196/300][2300/2502]	eta 0:01:42 lr 0.000136	time 0.4796 (0.5052)	loss 3.3616 (3.1393)	grad_norm 5.3157 (nan)	mem 8926MB
[2022-04-08 15:40:53 large] (main.py 226): INFO Train: [196/300][2400/2502]	eta 0:00:51 lr 0.000136	time 0.4721 (0.5042)	loss 3.1180 (3.1442)	grad_norm 4.7128 (nan)	mem 8926MB
[2022-04-08 15:41:42 large] (main.py 226): INFO Train: [196/300][2500/2502]	eta 0:00:01 lr 0.000136	time 0.5051 (0.5035)	loss 3.0870 (3.1426)	grad_norm 5.2124 (nan)	mem 8926MB
[2022-04-08 15:41:43 large] (main.py 233): INFO EPOCH 196 training takes 0:21:00
[2022-04-08 15:41:49 large] (main.py 273): INFO Test: [0/98]	Time 5.661 (5.661)	Loss 1.0850 (1.0850)	Acc@1 78.516 (78.516)	Acc@5 92.969 (92.969)	Mem 8926MB
[2022-04-08 15:42:15 large] (main.py 279): INFO  * Acc@1 79.184 Acc@5 94.684
[2022-04-08 15:42:15 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 79.2%
[2022-04-08 15:42:15 large] (main.py 148): INFO Max accuracy: 79.33%
[2022-04-08 15:42:23 large] (main.py 226): INFO Train: [197/300][0/2502]	eta 5:13:36 lr 0.000136	time 7.5204 (7.5204)	loss 2.9895 (2.9895)	grad_norm 3.6315 (3.6315)	mem 8926MB
[2022-04-08 15:43:13 large] (main.py 226): INFO Train: [197/300][100/2502]	eta 0:22:46 lr 0.000135	time 0.4880 (0.5690)	loss 3.1262 (3.1710)	grad_norm 4.4174 (4.9600)	mem 8926MB
[2022-04-08 15:44:03 large] (main.py 226): INFO Train: [197/300][200/2502]	eta 0:20:29 lr 0.000135	time 0.4953 (0.5339)	loss 2.5606 (3.1576)	grad_norm 4.5617 (5.1326)	mem 8926MB
[2022-04-08 15:44:54 large] (main.py 226): INFO Train: [197/300][300/2502]	eta 0:19:21 lr 0.000135	time 0.4742 (0.5273)	loss 3.0071 (3.1580)	grad_norm 3.9060 (5.1362)	mem 8926MB
[2022-04-08 15:45:44 large] (main.py 226): INFO Train: [197/300][400/2502]	eta 0:18:12 lr 0.000135	time 0.5349 (0.5199)	loss 3.1476 (3.1652)	grad_norm 4.3795 (5.1373)	mem 8926MB
[2022-04-08 15:46:33 large] (main.py 226): INFO Train: [197/300][500/2502]	eta 0:17:09 lr 0.000135	time 0.4737 (0.5142)	loss 2.1715 (3.1597)	grad_norm 4.1757 (5.1029)	mem 8926MB
[2022-04-08 15:47:24 large] (main.py 226): INFO Train: [197/300][600/2502]	eta 0:16:17 lr 0.000135	time 0.5204 (0.5141)	loss 3.2134 (3.1688)	grad_norm 6.6869 (5.1105)	mem 8926MB
[2022-04-08 15:48:15 large] (main.py 226): INFO Train: [197/300][700/2502]	eta 0:15:23 lr 0.000135	time 0.4983 (0.5123)	loss 2.1889 (3.1586)	grad_norm 5.2335 (5.1652)	mem 8926MB
[2022-04-08 15:49:05 large] (main.py 226): INFO Train: [197/300][800/2502]	eta 0:14:30 lr 0.000135	time 0.5146 (0.5113)	loss 2.8790 (3.1532)	grad_norm 4.0103 (5.1646)	mem 8926MB
[2022-04-08 15:49:56 large] (main.py 226): INFO Train: [197/300][900/2502]	eta 0:13:39 lr 0.000135	time 0.5021 (0.5114)	loss 2.9721 (3.1542)	grad_norm 5.6441 (5.1525)	mem 8926MB
[2022-04-08 15:50:46 large] (main.py 226): INFO Train: [197/300][1000/2502]	eta 0:12:46 lr 0.000135	time 0.5113 (0.5102)	loss 3.0424 (3.1581)	grad_norm 4.2348 (5.1437)	mem 8926MB
[2022-04-08 15:51:35 large] (main.py 226): INFO Train: [197/300][1100/2502]	eta 0:11:52 lr 0.000135	time 0.5001 (0.5083)	loss 3.3654 (3.1535)	grad_norm 8.5936 (5.1493)	mem 8926MB
[2022-04-08 15:52:25 large] (main.py 226): INFO Train: [197/300][1200/2502]	eta 0:11:00 lr 0.000134	time 0.4963 (0.5072)	loss 3.3023 (3.1523)	grad_norm 4.8196 (5.1210)	mem 8926MB
[2022-04-08 15:53:14 large] (main.py 226): INFO Train: [197/300][1300/2502]	eta 0:10:08 lr 0.000134	time 0.5091 (0.5066)	loss 1.9267 (3.1586)	grad_norm 4.1361 (5.1337)	mem 8926MB
[2022-04-08 15:54:06 large] (main.py 226): INFO Train: [197/300][1400/2502]	eta 0:09:18 lr 0.000134	time 0.4652 (0.5070)	loss 3.7671 (3.1646)	grad_norm 4.8908 (5.1697)	mem 8926MB
[2022-04-08 15:54:56 large] (main.py 226): INFO Train: [197/300][1500/2502]	eta 0:08:27 lr 0.000134	time 0.5676 (0.5064)	loss 3.7616 (3.1640)	grad_norm 5.7795 (5.1779)	mem 8926MB
[2022-04-08 15:55:46 large] (main.py 226): INFO Train: [197/300][1600/2502]	eta 0:07:36 lr 0.000134	time 0.4952 (0.5064)	loss 3.6355 (3.1641)	grad_norm 7.6013 (5.1891)	mem 8926MB
[2022-04-08 15:56:35 large] (main.py 226): INFO Train: [197/300][1700/2502]	eta 0:06:45 lr 0.000134	time 0.4613 (0.5052)	loss 3.2335 (3.1640)	grad_norm 3.9058 (5.2040)	mem 8926MB
[2022-04-08 15:57:24 large] (main.py 226): INFO Train: [197/300][1800/2502]	eta 0:05:54 lr 0.000134	time 0.4732 (0.5048)	loss 3.3559 (3.1661)	grad_norm 3.8225 (5.1959)	mem 8926MB
[2022-04-08 15:58:13 large] (main.py 226): INFO Train: [197/300][1900/2502]	eta 0:05:03 lr 0.000134	time 0.4787 (0.5036)	loss 3.2542 (3.1637)	grad_norm 6.2584 (5.1917)	mem 8926MB
[2022-04-08 15:59:03 large] (main.py 226): INFO Train: [197/300][2000/2502]	eta 0:04:12 lr 0.000134	time 0.5098 (0.5033)	loss 3.4283 (3.1614)	grad_norm 5.7325 (5.2038)	mem 8926MB
[2022-04-08 15:59:54 large] (main.py 226): INFO Train: [197/300][2100/2502]	eta 0:03:22 lr 0.000134	time 0.5035 (0.5038)	loss 3.2066 (3.1612)	grad_norm 5.4838 (5.2101)	mem 8926MB
[2022-04-08 16:00:45 large] (main.py 226): INFO Train: [197/300][2200/2502]	eta 0:02:32 lr 0.000134	time 0.5168 (0.5043)	loss 3.4235 (3.1561)	grad_norm 4.3153 (5.2004)	mem 8926MB
[2022-04-08 16:01:37 large] (main.py 226): INFO Train: [197/300][2300/2502]	eta 0:01:41 lr 0.000133	time 0.5132 (0.5046)	loss 3.1955 (3.1591)	grad_norm 5.8439 (5.1968)	mem 8926MB
[2022-04-08 16:02:25 large] (main.py 226): INFO Train: [197/300][2400/2502]	eta 0:00:51 lr 0.000133	time 0.5925 (0.5039)	loss 2.5306 (3.1565)	grad_norm 3.9708 (5.2082)	mem 8926MB
[2022-04-08 16:03:13 large] (main.py 226): INFO Train: [197/300][2500/2502]	eta 0:00:01 lr 0.000133	time 0.4734 (0.5030)	loss 2.1029 (3.1540)	grad_norm 4.8629 (5.2028)	mem 8926MB
[2022-04-08 16:03:14 large] (main.py 233): INFO EPOCH 197 training takes 0:20:58
[2022-04-08 16:03:20 large] (main.py 273): INFO Test: [0/98]	Time 5.833 (5.833)	Loss 0.9411 (0.9411)	Acc@1 81.836 (81.836)	Acc@5 95.898 (95.898)	Mem 8926MB
[2022-04-08 16:03:47 large] (main.py 279): INFO  * Acc@1 79.246 Acc@5 94.618
[2022-04-08 16:03:47 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 79.2%
[2022-04-08 16:03:47 large] (main.py 148): INFO Max accuracy: 79.33%
[2022-04-08 16:03:53 large] (main.py 226): INFO Train: [198/300][0/2502]	eta 4:36:42 lr 0.000133	time 6.6355 (6.6355)	loss 2.2363 (2.2363)	grad_norm 6.5462 (6.5462)	mem 8926MB
[2022-04-08 16:04:44 large] (main.py 226): INFO Train: [198/300][100/2502]	eta 0:22:56 lr 0.000133	time 0.5325 (0.5731)	loss 3.4809 (3.2276)	grad_norm 4.5324 (5.1311)	mem 8926MB
[2022-04-08 16:05:36 large] (main.py 226): INFO Train: [198/300][200/2502]	eta 0:20:51 lr 0.000133	time 0.5112 (0.5435)	loss 3.5128 (3.1862)	grad_norm 5.7864 (4.9629)	mem 8926MB
[2022-04-08 16:06:27 large] (main.py 226): INFO Train: [198/300][300/2502]	eta 0:19:34 lr 0.000133	time 0.5311 (0.5334)	loss 3.4977 (3.1709)	grad_norm 4.9616 (5.0500)	mem 8926MB
[2022-04-08 16:07:15 large] (main.py 226): INFO Train: [198/300][400/2502]	eta 0:18:15 lr 0.000133	time 0.4830 (0.5210)	loss 3.3976 (3.1436)	grad_norm 3.2178 (5.0314)	mem 8926MB
[2022-04-08 16:08:05 large] (main.py 226): INFO Train: [198/300][500/2502]	eta 0:17:11 lr 0.000133	time 0.5006 (0.5153)	loss 3.7187 (3.1469)	grad_norm 4.6034 (5.1411)	mem 8926MB
[2022-04-08 16:08:55 large] (main.py 226): INFO Train: [198/300][600/2502]	eta 0:16:15 lr 0.000133	time 0.4665 (0.5130)	loss 2.8627 (3.1550)	grad_norm 6.7419 (nan)	mem 8926MB
[2022-04-08 16:09:43 large] (main.py 226): INFO Train: [198/300][700/2502]	eta 0:15:17 lr 0.000133	time 0.4911 (0.5089)	loss 3.2137 (3.1443)	grad_norm 5.7073 (nan)	mem 8926MB
[2022-04-08 16:10:33 large] (main.py 226): INFO Train: [198/300][800/2502]	eta 0:14:23 lr 0.000133	time 0.4775 (0.5072)	loss 3.6140 (3.1477)	grad_norm 4.6921 (nan)	mem 8926MB
[2022-04-08 16:11:21 large] (main.py 226): INFO Train: [198/300][900/2502]	eta 0:13:28 lr 0.000132	time 0.5259 (0.5048)	loss 3.6176 (3.1428)	grad_norm 5.3440 (nan)	mem 8926MB
[2022-04-08 16:12:10 large] (main.py 226): INFO Train: [198/300][1000/2502]	eta 0:12:35 lr 0.000132	time 0.4973 (0.5030)	loss 2.4605 (3.1430)	grad_norm 3.7460 (nan)	mem 8926MB
[2022-04-08 16:12:59 large] (main.py 226): INFO Train: [198/300][1100/2502]	eta 0:11:43 lr 0.000132	time 0.4675 (0.5019)	loss 1.9872 (3.1331)	grad_norm 4.4711 (nan)	mem 8926MB
[2022-04-08 16:13:49 large] (main.py 226): INFO Train: [198/300][1200/2502]	eta 0:10:52 lr 0.000132	time 0.4679 (0.5013)	loss 3.5256 (3.1348)	grad_norm 5.1288 (nan)	mem 8926MB
[2022-04-08 16:14:37 large] (main.py 226): INFO Train: [198/300][1300/2502]	eta 0:10:00 lr 0.000132	time 0.5337 (0.4996)	loss 3.1576 (3.1369)	grad_norm 5.3481 (nan)	mem 8926MB
[2022-04-08 16:15:25 large] (main.py 226): INFO Train: [198/300][1400/2502]	eta 0:09:09 lr 0.000132	time 0.5398 (0.4987)	loss 2.6859 (3.1378)	grad_norm 5.3388 (nan)	mem 8926MB
[2022-04-08 16:16:16 large] (main.py 226): INFO Train: [198/300][1500/2502]	eta 0:08:20 lr 0.000132	time 0.5119 (0.4994)	loss 3.0765 (3.1442)	grad_norm 6.4547 (nan)	mem 8926MB
[2022-04-08 16:17:08 large] (main.py 226): INFO Train: [198/300][1600/2502]	eta 0:07:31 lr 0.000132	time 0.4982 (0.5004)	loss 2.8820 (3.1449)	grad_norm 4.8777 (nan)	mem 8926MB
[2022-04-08 16:17:59 large] (main.py 226): INFO Train: [198/300][1700/2502]	eta 0:06:41 lr 0.000132	time 0.5012 (0.5011)	loss 3.7587 (3.1470)	grad_norm 4.7769 (nan)	mem 8926MB
[2022-04-08 16:18:49 large] (main.py 226): INFO Train: [198/300][1800/2502]	eta 0:05:51 lr 0.000132	time 0.5131 (0.5012)	loss 3.9223 (3.1459)	grad_norm 5.0146 (nan)	mem 8926MB
[2022-04-08 16:19:39 large] (main.py 226): INFO Train: [198/300][1900/2502]	eta 0:05:01 lr 0.000132	time 0.5081 (0.5012)	loss 2.9651 (3.1511)	grad_norm 5.8398 (nan)	mem 8926MB
[2022-04-08 16:20:29 large] (main.py 226): INFO Train: [198/300][2000/2502]	eta 0:04:11 lr 0.000131	time 0.5047 (0.5011)	loss 3.2570 (3.1495)	grad_norm 4.4147 (nan)	mem 8926MB
[2022-04-08 16:21:18 large] (main.py 226): INFO Train: [198/300][2100/2502]	eta 0:03:21 lr 0.000131	time 0.4737 (0.5004)	loss 3.5118 (3.1520)	grad_norm 7.1493 (nan)	mem 8926MB
[2022-04-08 16:22:06 large] (main.py 226): INFO Train: [198/300][2200/2502]	eta 0:02:30 lr 0.000131	time 0.5682 (0.4996)	loss 3.3885 (3.1458)	grad_norm 5.0304 (nan)	mem 8926MB
[2022-04-08 16:22:55 large] (main.py 226): INFO Train: [198/300][2300/2502]	eta 0:01:40 lr 0.000131	time 0.5005 (0.4990)	loss 3.3960 (3.1441)	grad_norm 5.9604 (nan)	mem 8926MB
[2022-04-08 16:23:45 large] (main.py 226): INFO Train: [198/300][2400/2502]	eta 0:00:50 lr 0.000131	time 0.4966 (0.4990)	loss 3.7136 (3.1440)	grad_norm 4.1608 (nan)	mem 8926MB
[2022-04-08 16:24:35 large] (main.py 226): INFO Train: [198/300][2500/2502]	eta 0:00:00 lr 0.000131	time 0.4940 (0.4993)	loss 3.6068 (3.1469)	grad_norm 6.4648 (nan)	mem 8926MB
[2022-04-08 16:24:36 large] (main.py 233): INFO EPOCH 198 training takes 0:20:49
[2022-04-08 16:24:43 large] (main.py 273): INFO Test: [0/98]	Time 6.561 (6.561)	Loss 0.9732 (0.9732)	Acc@1 80.859 (80.859)	Acc@5 95.508 (95.508)	Mem 8926MB
[2022-04-08 16:25:08 large] (main.py 279): INFO  * Acc@1 79.454 Acc@5 94.800
[2022-04-08 16:25:08 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 79.5%
[2022-04-08 16:25:08 large] (utils.py 57): INFO output/large/default/ckpt_epoch_198.pth saving......
[2022-04-08 16:25:09 large] (utils.py 59): INFO output/large/default/ckpt_epoch_198.pth saved !!!
[2022-04-08 16:25:09 large] (main.py 148): INFO Max accuracy: 79.45%
[2022-04-08 16:25:17 large] (main.py 226): INFO Train: [199/300][0/2502]	eta 5:29:22 lr 0.000131	time 7.8985 (7.8985)	loss 3.5879 (3.5879)	grad_norm 4.1269 (4.1269)	mem 8926MB
[2022-04-08 16:26:06 large] (main.py 226): INFO Train: [199/300][100/2502]	eta 0:22:33 lr 0.000131	time 0.5064 (0.5636)	loss 2.5106 (3.1822)	grad_norm 5.9159 (5.0927)	mem 8926MB
[2022-04-08 16:26:55 large] (main.py 226): INFO Train: [199/300][200/2502]	eta 0:20:06 lr 0.000131	time 0.4476 (0.5243)	loss 3.7860 (3.1692)	grad_norm 4.3721 (5.0836)	mem 8926MB
[2022-04-08 16:27:45 large] (main.py 226): INFO Train: [199/300][300/2502]	eta 0:19:03 lr 0.000131	time 0.5112 (0.5191)	loss 3.3726 (3.1419)	grad_norm 4.5841 (5.0859)	mem 8926MB
[2022-04-08 16:28:35 large] (main.py 226): INFO Train: [199/300][400/2502]	eta 0:17:57 lr 0.000131	time 0.5036 (0.5128)	loss 3.5132 (3.1460)	grad_norm 4.1008 (5.1178)	mem 8926MB
[2022-04-08 16:29:26 large] (main.py 226): INFO Train: [199/300][500/2502]	eta 0:17:05 lr 0.000131	time 0.4901 (0.5121)	loss 3.4413 (3.1483)	grad_norm 4.5216 (5.1594)	mem 8926MB
[2022-04-08 16:30:17 large] (main.py 226): INFO Train: [199/300][600/2502]	eta 0:16:13 lr 0.000130	time 0.5082 (0.5118)	loss 3.4138 (3.1560)	grad_norm 3.9463 (5.1583)	mem 8926MB
[2022-04-08 16:31:07 large] (main.py 226): INFO Train: [199/300][700/2502]	eta 0:15:20 lr 0.000130	time 0.4455 (0.5107)	loss 3.1341 (3.1582)	grad_norm 3.8104 (5.1743)	mem 8926MB
[2022-04-08 16:31:56 large] (main.py 226): INFO Train: [199/300][800/2502]	eta 0:14:24 lr 0.000130	time 0.4678 (0.5081)	loss 3.1714 (3.1659)	grad_norm 4.5968 (5.2033)	mem 8926MB
[2022-04-08 16:32:44 large] (main.py 226): INFO Train: [199/300][900/2502]	eta 0:13:28 lr 0.000130	time 0.4842 (0.5047)	loss 3.5294 (3.1573)	grad_norm 4.2870 (5.2169)	mem 8926MB
[2022-04-08 16:33:34 large] (main.py 226): INFO Train: [199/300][1000/2502]	eta 0:12:37 lr 0.000130	time 0.4939 (0.5042)	loss 3.0501 (3.1597)	grad_norm 6.5319 (5.2296)	mem 8926MB
[2022-04-08 16:34:25 large] (main.py 226): INFO Train: [199/300][1100/2502]	eta 0:11:47 lr 0.000130	time 0.5441 (0.5049)	loss 3.3489 (3.1563)	grad_norm 5.5453 (5.2404)	mem 8926MB
[2022-04-08 16:35:15 large] (main.py 226): INFO Train: [199/300][1200/2502]	eta 0:10:56 lr 0.000130	time 0.4960 (0.5040)	loss 2.6325 (3.1541)	grad_norm 6.0146 (5.2381)	mem 8926MB
[2022-04-08 16:36:05 large] (main.py 226): INFO Train: [199/300][1300/2502]	eta 0:10:06 lr 0.000130	time 0.5109 (0.5043)	loss 3.1853 (3.1536)	grad_norm 5.0590 (5.2364)	mem 8926MB
[2022-04-08 16:36:55 large] (main.py 226): INFO Train: [199/300][1400/2502]	eta 0:09:14 lr 0.000130	time 0.4920 (0.5036)	loss 2.8939 (3.1474)	grad_norm 6.1058 (5.2140)	mem 8926MB
[2022-04-08 16:37:43 large] (main.py 226): INFO Train: [199/300][1500/2502]	eta 0:08:23 lr 0.000130	time 0.5050 (0.5025)	loss 2.0362 (3.1438)	grad_norm 5.0971 (5.2193)	mem 8926MB
[2022-04-08 16:38:32 large] (main.py 226): INFO Train: [199/300][1600/2502]	eta 0:07:32 lr 0.000130	time 0.5494 (0.5016)	loss 3.1227 (3.1409)	grad_norm 5.3209 (5.2183)	mem 8926MB
[2022-04-08 16:39:22 large] (main.py 226): INFO Train: [199/300][1700/2502]	eta 0:06:41 lr 0.000129	time 0.5016 (0.5011)	loss 3.4180 (3.1451)	grad_norm 4.3019 (5.2053)	mem 8926MB
[2022-04-08 16:40:13 large] (main.py 226): INFO Train: [199/300][1800/2502]	eta 0:05:52 lr 0.000129	time 0.4986 (0.5015)	loss 2.9356 (3.1424)	grad_norm 4.6226 (5.2100)	mem 8926MB
[2022-04-08 16:41:02 large] (main.py 226): INFO Train: [199/300][1900/2502]	eta 0:05:01 lr 0.000129	time 0.5606 (0.5014)	loss 3.3429 (3.1480)	grad_norm 5.9648 (5.2123)	mem 8926MB
[2022-04-08 16:41:53 large] (main.py 226): INFO Train: [199/300][2000/2502]	eta 0:04:11 lr 0.000129	time 0.5070 (0.5017)	loss 3.3222 (3.1479)	grad_norm 5.2547 (5.2036)	mem 8926MB
[2022-04-08 16:42:44 large] (main.py 226): INFO Train: [199/300][2100/2502]	eta 0:03:21 lr 0.000129	time 0.5219 (0.5021)	loss 3.7209 (3.1430)	grad_norm 6.6552 (5.1988)	mem 8926MB
[2022-04-08 16:43:35 large] (main.py 226): INFO Train: [199/300][2200/2502]	eta 0:02:31 lr 0.000129	time 0.5236 (0.5024)	loss 3.7383 (3.1431)	grad_norm 4.3567 (5.1935)	mem 8926MB
[2022-04-08 16:44:26 large] (main.py 226): INFO Train: [199/300][2300/2502]	eta 0:01:41 lr 0.000129	time 0.5032 (0.5027)	loss 3.4581 (3.1425)	grad_norm 4.8364 (5.1847)	mem 8926MB
[2022-04-08 16:45:16 large] (main.py 226): INFO Train: [199/300][2400/2502]	eta 0:00:51 lr 0.000129	time 0.4960 (0.5028)	loss 3.6237 (3.1424)	grad_norm 4.4088 (5.1881)	mem 8926MB
[2022-04-08 16:46:05 large] (main.py 226): INFO Train: [199/300][2500/2502]	eta 0:00:01 lr 0.000129	time 0.4784 (0.5022)	loss 2.6683 (3.1422)	grad_norm 5.0723 (5.1884)	mem 8926MB
[2022-04-08 16:46:06 large] (main.py 233): INFO EPOCH 199 training takes 0:20:57
[2022-04-08 16:46:12 large] (main.py 273): INFO Test: [0/98]	Time 5.763 (5.763)	Loss 0.9906 (0.9906)	Acc@1 80.078 (80.078)	Acc@5 95.312 (95.312)	Mem 8926MB
[2022-04-08 16:46:39 large] (main.py 279): INFO  * Acc@1 79.578 Acc@5 94.886
[2022-04-08 16:46:39 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 79.6%
[2022-04-08 16:46:39 large] (utils.py 57): INFO output/large/default/ckpt_epoch_199.pth saving......
[2022-04-08 16:46:40 large] (utils.py 59): INFO output/large/default/ckpt_epoch_199.pth saved !!!
[2022-04-08 16:46:40 large] (main.py 148): INFO Max accuracy: 79.58%
[2022-04-08 16:46:47 large] (main.py 226): INFO Train: [200/300][0/2502]	eta 5:26:17 lr 0.000129	time 7.8249 (7.8249)	loss 2.7750 (2.7750)	grad_norm 4.7968 (4.7968)	mem 8926MB
[2022-04-08 16:47:37 large] (main.py 226): INFO Train: [200/300][100/2502]	eta 0:22:34 lr 0.000129	time 0.4405 (0.5640)	loss 3.0868 (3.0499)	grad_norm 4.1517 (4.9597)	mem 8926MB
[2022-04-08 16:48:27 large] (main.py 226): INFO Train: [200/300][200/2502]	eta 0:20:32 lr 0.000129	time 0.5336 (0.5353)	loss 3.0695 (3.1184)	grad_norm 6.1493 (5.0624)	mem 8926MB
[2022-04-08 16:49:18 large] (main.py 226): INFO Train: [200/300][300/2502]	eta 0:19:21 lr 0.000128	time 0.5032 (0.5276)	loss 2.0299 (3.1161)	grad_norm 6.8991 (5.0959)	mem 8926MB
[2022-04-08 16:50:09 large] (main.py 226): INFO Train: [200/300][400/2502]	eta 0:18:19 lr 0.000128	time 0.5211 (0.5232)	loss 3.1227 (3.1427)	grad_norm 7.2485 (5.1114)	mem 8926MB
[2022-04-08 16:51:00 large] (main.py 226): INFO Train: [200/300][500/2502]	eta 0:17:21 lr 0.000128	time 0.5190 (0.5203)	loss 3.5281 (3.1448)	grad_norm 5.7198 (5.1943)	mem 8926MB
[2022-04-08 16:51:51 large] (main.py 226): INFO Train: [200/300][600/2502]	eta 0:16:25 lr 0.000128	time 0.5125 (0.5182)	loss 2.9293 (3.1435)	grad_norm 6.0956 (5.1849)	mem 8926MB
[2022-04-08 16:52:42 large] (main.py 226): INFO Train: [200/300][700/2502]	eta 0:15:31 lr 0.000128	time 0.5050 (0.5169)	loss 2.7099 (3.1354)	grad_norm 3.7519 (5.2054)	mem 8926MB
[2022-04-08 16:53:32 large] (main.py 226): INFO Train: [200/300][800/2502]	eta 0:14:36 lr 0.000128	time 0.5755 (0.5150)	loss 1.9171 (3.1425)	grad_norm 4.5330 (5.1939)	mem 8926MB
[2022-04-08 16:54:22 large] (main.py 226): INFO Train: [200/300][900/2502]	eta 0:13:41 lr 0.000128	time 0.5163 (0.5130)	loss 3.7908 (3.1464)	grad_norm 5.2201 (5.2264)	mem 8926MB
[2022-04-08 16:55:12 large] (main.py 226): INFO Train: [200/300][1000/2502]	eta 0:12:48 lr 0.000128	time 0.4623 (0.5117)	loss 2.5044 (3.1423)	grad_norm 4.7506 (5.2306)	mem 8926MB
[2022-04-08 16:56:02 large] (main.py 226): INFO Train: [200/300][1100/2502]	eta 0:11:55 lr 0.000128	time 0.5158 (0.5107)	loss 2.9932 (3.1361)	grad_norm 5.4513 (5.2461)	mem 8926MB
[2022-04-08 16:56:53 large] (main.py 226): INFO Train: [200/300][1200/2502]	eta 0:11:04 lr 0.000128	time 0.5002 (0.5106)	loss 3.0390 (3.1404)	grad_norm 4.7289 (5.2432)	mem 8926MB
[2022-04-08 16:57:42 large] (main.py 226): INFO Train: [200/300][1300/2502]	eta 0:10:12 lr 0.000128	time 0.4994 (0.5094)	loss 3.3351 (3.1440)	grad_norm 5.1219 (5.2620)	mem 8926MB
[2022-04-08 16:58:32 large] (main.py 226): INFO Train: [200/300][1400/2502]	eta 0:09:20 lr 0.000127	time 0.5134 (0.5088)	loss 2.8911 (3.1443)	grad_norm 4.0205 (5.2349)	mem 8926MB
[2022-04-08 16:59:21 large] (main.py 226): INFO Train: [200/300][1500/2502]	eta 0:08:28 lr 0.000127	time 0.5519 (0.5074)	loss 2.7037 (3.1465)	grad_norm 6.7981 (5.2478)	mem 8926MB
[2022-04-08 17:00:10 large] (main.py 226): INFO Train: [200/300][1600/2502]	eta 0:07:36 lr 0.000127	time 0.4916 (0.5063)	loss 3.2886 (3.1438)	grad_norm 4.6803 (5.2375)	mem 8926MB
[2022-04-08 17:01:01 large] (main.py 226): INFO Train: [200/300][1700/2502]	eta 0:06:45 lr 0.000127	time 0.5653 (0.5062)	loss 3.6718 (3.1414)	grad_norm 4.6998 (5.2450)	mem 8926MB
[2022-04-08 17:01:52 large] (main.py 226): INFO Train: [200/300][1800/2502]	eta 0:05:55 lr 0.000127	time 0.5198 (0.5063)	loss 3.4604 (3.1416)	grad_norm 4.2867 (5.2382)	mem 8926MB
[2022-04-08 17:02:42 large] (main.py 226): INFO Train: [200/300][1900/2502]	eta 0:05:04 lr 0.000127	time 0.4682 (0.5062)	loss 3.7633 (3.1409)	grad_norm 6.8559 (5.2499)	mem 8926MB
[2022-04-08 17:03:30 large] (main.py 226): INFO Train: [200/300][2000/2502]	eta 0:04:13 lr 0.000127	time 0.4784 (0.5050)	loss 2.8255 (3.1395)	grad_norm 5.6672 (nan)	mem 8926MB
[2022-04-08 17:04:20 large] (main.py 226): INFO Train: [200/300][2100/2502]	eta 0:03:22 lr 0.000127	time 0.5066 (0.5045)	loss 1.9632 (3.1408)	grad_norm 6.0921 (nan)	mem 8926MB
[2022-04-08 17:05:11 large] (main.py 226): INFO Train: [200/300][2200/2502]	eta 0:02:32 lr 0.000127	time 0.4880 (0.5049)	loss 3.4178 (3.1407)	grad_norm 4.4698 (nan)	mem 8926MB
[2022-04-08 17:06:02 large] (main.py 226): INFO Train: [200/300][2300/2502]	eta 0:01:42 lr 0.000127	time 0.5109 (0.5054)	loss 2.7370 (3.1357)	grad_norm 5.1955 (nan)	mem 8926MB
[2022-04-08 17:06:53 large] (main.py 226): INFO Train: [200/300][2400/2502]	eta 0:00:51 lr 0.000127	time 0.5398 (0.5052)	loss 3.2161 (3.1392)	grad_norm 6.4754 (nan)	mem 8926MB
[2022-04-08 17:07:41 large] (main.py 226): INFO Train: [200/300][2500/2502]	eta 0:00:01 lr 0.000127	time 0.4750 (0.5045)	loss 3.3381 (3.1383)	grad_norm 4.4101 (nan)	mem 8926MB
[2022-04-08 17:07:42 large] (main.py 233): INFO EPOCH 200 training takes 0:21:02
[2022-04-08 17:07:48 large] (main.py 273): INFO Test: [0/98]	Time 5.389 (5.389)	Loss 1.0315 (1.0315)	Acc@1 78.516 (78.516)	Acc@5 94.727 (94.727)	Mem 8926MB
[2022-04-08 17:08:14 large] (main.py 279): INFO  * Acc@1 79.138 Acc@5 94.600
[2022-04-08 17:08:14 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 79.1%
[2022-04-08 17:08:14 large] (main.py 148): INFO Max accuracy: 79.58%
[2022-04-08 17:08:21 large] (main.py 226): INFO Train: [201/300][0/2502]	eta 4:53:26 lr 0.000127	time 7.0370 (7.0370)	loss 2.8672 (2.8672)	grad_norm 5.4208 (5.4208)	mem 8926MB
[2022-04-08 17:09:11 large] (main.py 226): INFO Train: [201/300][100/2502]	eta 0:22:38 lr 0.000126	time 0.4966 (0.5654)	loss 3.6989 (3.0924)	grad_norm 5.1122 (5.6310)	mem 8926MB
[2022-04-08 17:10:02 large] (main.py 226): INFO Train: [201/300][200/2502]	eta 0:20:29 lr 0.000126	time 0.4927 (0.5343)	loss 3.1444 (3.1650)	grad_norm 4.9906 (5.4704)	mem 8926MB
[2022-04-08 17:10:52 large] (main.py 226): INFO Train: [201/300][300/2502]	eta 0:19:10 lr 0.000126	time 0.5153 (0.5227)	loss 3.6506 (3.1505)	grad_norm 6.1990 (5.4321)	mem 8926MB
[2022-04-08 17:11:43 large] (main.py 226): INFO Train: [201/300][400/2502]	eta 0:18:14 lr 0.000126	time 0.5277 (0.5209)	loss 3.4662 (3.1638)	grad_norm 6.4366 (5.3889)	mem 8926MB
[2022-04-08 17:12:34 large] (main.py 226): INFO Train: [201/300][500/2502]	eta 0:17:18 lr 0.000126	time 0.4950 (0.5188)	loss 3.8416 (3.1805)	grad_norm 4.7611 (5.3433)	mem 8926MB
[2022-04-08 17:13:24 large] (main.py 226): INFO Train: [201/300][600/2502]	eta 0:16:19 lr 0.000126	time 0.4698 (0.5150)	loss 3.1024 (3.1637)	grad_norm 6.2645 (5.3196)	mem 8926MB
[2022-04-08 17:14:15 large] (main.py 226): INFO Train: [201/300][700/2502]	eta 0:15:27 lr 0.000126	time 0.5732 (0.5145)	loss 3.2586 (3.1513)	grad_norm 4.0000 (5.3386)	mem 8926MB
[2022-04-08 17:15:05 large] (main.py 226): INFO Train: [201/300][800/2502]	eta 0:14:33 lr 0.000126	time 0.4686 (0.5131)	loss 3.7188 (3.1459)	grad_norm 4.9991 (5.3651)	mem 8926MB
[2022-04-08 17:15:55 large] (main.py 226): INFO Train: [201/300][900/2502]	eta 0:13:40 lr 0.000126	time 0.5330 (0.5119)	loss 3.4911 (3.1501)	grad_norm 5.0023 (5.3460)	mem 8926MB
[2022-04-08 17:16:46 large] (main.py 226): INFO Train: [201/300][1000/2502]	eta 0:12:48 lr 0.000126	time 0.5073 (0.5116)	loss 3.2992 (3.1473)	grad_norm 4.8785 (5.3592)	mem 8926MB
[2022-04-08 17:17:35 large] (main.py 226): INFO Train: [201/300][1100/2502]	eta 0:11:53 lr 0.000126	time 0.4692 (0.5091)	loss 3.3621 (3.1526)	grad_norm 4.4593 (5.3574)	mem 8926MB
[2022-04-08 17:18:23 large] (main.py 226): INFO Train: [201/300][1200/2502]	eta 0:11:00 lr 0.000125	time 0.4847 (0.5072)	loss 2.8529 (3.1543)	grad_norm 5.0808 (inf)	mem 8926MB
[2022-04-08 17:19:11 large] (main.py 226): INFO Train: [201/300][1300/2502]	eta 0:10:07 lr 0.000125	time 0.4832 (0.5052)	loss 2.4838 (3.1478)	grad_norm 4.9693 (inf)	mem 8926MB
[2022-04-08 17:20:01 large] (main.py 226): INFO Train: [201/300][1400/2502]	eta 0:09:15 lr 0.000125	time 0.5079 (0.5043)	loss 3.4255 (3.1473)	grad_norm 5.0409 (inf)	mem 8926MB
[2022-04-08 17:20:50 large] (main.py 226): INFO Train: [201/300][1500/2502]	eta 0:08:24 lr 0.000125	time 0.4927 (0.5032)	loss 3.3512 (3.1461)	grad_norm 6.2472 (inf)	mem 8926MB
[2022-04-08 17:21:38 large] (main.py 226): INFO Train: [201/300][1600/2502]	eta 0:07:33 lr 0.000125	time 0.4843 (0.5023)	loss 3.2199 (3.1444)	grad_norm 3.6277 (inf)	mem 8926MB
[2022-04-08 17:22:30 large] (main.py 226): INFO Train: [201/300][1700/2502]	eta 0:06:43 lr 0.000125	time 0.5752 (0.5028)	loss 3.1417 (3.1453)	grad_norm 5.8213 (nan)	mem 8926MB
[2022-04-08 17:23:21 large] (main.py 226): INFO Train: [201/300][1800/2502]	eta 0:05:53 lr 0.000125	time 0.5247 (0.5034)	loss 3.3747 (3.1494)	grad_norm 5.0262 (nan)	mem 8926MB
[2022-04-08 17:24:12 large] (main.py 226): INFO Train: [201/300][1900/2502]	eta 0:05:03 lr 0.000125	time 0.5249 (0.5038)	loss 2.3252 (3.1476)	grad_norm 5.5831 (nan)	mem 8926MB
[2022-04-08 17:25:03 large] (main.py 226): INFO Train: [201/300][2000/2502]	eta 0:04:13 lr 0.000125	time 0.5082 (0.5042)	loss 1.9685 (3.1436)	grad_norm 5.1219 (nan)	mem 8926MB
[2022-04-08 17:25:54 large] (main.py 226): INFO Train: [201/300][2100/2502]	eta 0:03:22 lr 0.000125	time 0.5055 (0.5044)	loss 2.5083 (3.1401)	grad_norm 6.2767 (nan)	mem 8926MB
[2022-04-08 17:26:44 large] (main.py 226): INFO Train: [201/300][2200/2502]	eta 0:02:32 lr 0.000125	time 0.4738 (0.5042)	loss 2.5434 (3.1396)	grad_norm 3.7749 (nan)	mem 8926MB
[2022-04-08 17:27:33 large] (main.py 226): INFO Train: [201/300][2300/2502]	eta 0:01:41 lr 0.000124	time 0.5071 (0.5036)	loss 2.5039 (3.1395)	grad_norm 7.1907 (nan)	mem 8926MB
[2022-04-08 17:28:22 large] (main.py 226): INFO Train: [201/300][2400/2502]	eta 0:00:51 lr 0.000124	time 0.5102 (0.5031)	loss 2.8580 (3.1373)	grad_norm 7.3495 (nan)	mem 8926MB
[2022-04-08 17:29:13 large] (main.py 226): INFO Train: [201/300][2500/2502]	eta 0:00:01 lr 0.000124	time 0.5012 (0.5034)	loss 2.3481 (3.1343)	grad_norm 5.8452 (nan)	mem 8926MB
[2022-04-08 17:29:14 large] (main.py 233): INFO EPOCH 201 training takes 0:20:59
[2022-04-08 17:29:20 large] (main.py 273): INFO Test: [0/98]	Time 5.805 (5.805)	Loss 1.0861 (1.0861)	Acc@1 78.125 (78.125)	Acc@5 93.555 (93.555)	Mem 8926MB
[2022-04-08 17:29:47 large] (main.py 279): INFO  * Acc@1 79.426 Acc@5 94.738
[2022-04-08 17:29:47 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 79.4%
[2022-04-08 17:29:47 large] (main.py 148): INFO Max accuracy: 79.58%
[2022-04-08 17:29:54 large] (main.py 226): INFO Train: [202/300][0/2502]	eta 5:03:01 lr 0.000124	time 7.2668 (7.2668)	loss 1.7845 (1.7845)	grad_norm 5.2427 (5.2427)	mem 8926MB
[2022-04-08 17:30:44 large] (main.py 226): INFO Train: [202/300][100/2502]	eta 0:22:38 lr 0.000124	time 0.4579 (0.5657)	loss 3.2404 (3.1588)	grad_norm 4.9085 (5.4763)	mem 8926MB
[2022-04-08 17:31:32 large] (main.py 226): INFO Train: [202/300][200/2502]	eta 0:20:05 lr 0.000124	time 0.4835 (0.5235)	loss 3.2609 (3.1615)	grad_norm 5.3992 (5.5670)	mem 8926MB
[2022-04-08 17:32:21 large] (main.py 226): INFO Train: [202/300][300/2502]	eta 0:18:47 lr 0.000124	time 0.4958 (0.5119)	loss 2.7923 (3.1419)	grad_norm 4.3918 (5.5298)	mem 8926MB
[2022-04-08 17:33:10 large] (main.py 226): INFO Train: [202/300][400/2502]	eta 0:17:45 lr 0.000124	time 0.4935 (0.5067)	loss 3.2816 (3.1256)	grad_norm 5.3128 (5.4763)	mem 8926MB
[2022-04-08 17:34:01 large] (main.py 226): INFO Train: [202/300][500/2502]	eta 0:16:56 lr 0.000124	time 0.4587 (0.5076)	loss 2.2935 (3.1122)	grad_norm 4.8966 (5.4360)	mem 8926MB
[2022-04-08 17:34:52 large] (main.py 226): INFO Train: [202/300][600/2502]	eta 0:16:06 lr 0.000124	time 0.5531 (0.5080)	loss 3.0708 (3.1164)	grad_norm 5.6088 (5.4142)	mem 8926MB
[2022-04-08 17:35:43 large] (main.py 226): INFO Train: [202/300][700/2502]	eta 0:15:15 lr 0.000124	time 0.5435 (0.5081)	loss 3.5049 (3.1328)	grad_norm 4.2189 (5.3827)	mem 8926MB
[2022-04-08 17:36:34 large] (main.py 226): INFO Train: [202/300][800/2502]	eta 0:14:25 lr 0.000124	time 0.5541 (0.5088)	loss 3.2794 (3.1404)	grad_norm 3.7174 (5.3777)	mem 8926MB
[2022-04-08 17:37:26 large] (main.py 226): INFO Train: [202/300][900/2502]	eta 0:13:37 lr 0.000123	time 0.5091 (0.5102)	loss 3.5721 (3.1520)	grad_norm 6.3690 (5.4015)	mem 8926MB
[2022-04-08 17:38:19 large] (main.py 226): INFO Train: [202/300][1000/2502]	eta 0:12:48 lr 0.000123	time 0.5488 (0.5119)	loss 3.2228 (3.1518)	grad_norm 5.8793 (5.4534)	mem 8926MB
[2022-04-08 17:39:11 large] (main.py 226): INFO Train: [202/300][1100/2502]	eta 0:11:58 lr 0.000123	time 0.5212 (0.5123)	loss 3.6988 (3.1517)	grad_norm 6.1927 (5.5590)	mem 8926MB
[2022-04-08 17:40:02 large] (main.py 226): INFO Train: [202/300][1200/2502]	eta 0:11:07 lr 0.000123	time 0.4946 (0.5125)	loss 3.3533 (3.1512)	grad_norm 7.3571 (5.5494)	mem 8926MB
[2022-04-08 17:40:54 large] (main.py 226): INFO Train: [202/300][1300/2502]	eta 0:10:17 lr 0.000123	time 0.5124 (0.5133)	loss 3.4599 (3.1466)	grad_norm 3.7016 (5.5488)	mem 8926MB
[2022-04-08 17:41:45 large] (main.py 226): INFO Train: [202/300][1400/2502]	eta 0:09:25 lr 0.000123	time 0.5206 (0.5128)	loss 3.4023 (3.1459)	grad_norm 3.9739 (5.5323)	mem 8926MB
[2022-04-08 17:42:34 large] (main.py 226): INFO Train: [202/300][1500/2502]	eta 0:08:32 lr 0.000123	time 0.4755 (0.5112)	loss 3.4313 (3.1467)	grad_norm 5.7929 (5.5253)	mem 8926MB
[2022-04-08 17:43:26 large] (main.py 226): INFO Train: [202/300][1600/2502]	eta 0:07:41 lr 0.000123	time 0.5510 (0.5116)	loss 3.5858 (3.1409)	grad_norm 5.4629 (5.5083)	mem 8926MB
[2022-04-08 17:44:17 large] (main.py 226): INFO Train: [202/300][1700/2502]	eta 0:06:50 lr 0.000123	time 0.5046 (0.5118)	loss 3.0568 (3.1379)	grad_norm 4.5870 (5.4920)	mem 8926MB
[2022-04-08 17:45:08 large] (main.py 226): INFO Train: [202/300][1800/2502]	eta 0:05:59 lr 0.000123	time 0.4699 (0.5118)	loss 3.7692 (3.1390)	grad_norm 5.0239 (5.4860)	mem 8926MB
[2022-04-08 17:45:57 large] (main.py 226): INFO Train: [202/300][1900/2502]	eta 0:05:07 lr 0.000123	time 0.4839 (0.5106)	loss 2.0613 (3.1395)	grad_norm 4.7454 (5.4704)	mem 8926MB
[2022-04-08 17:46:47 large] (main.py 226): INFO Train: [202/300][2000/2502]	eta 0:04:15 lr 0.000123	time 0.4991 (0.5099)	loss 2.1937 (3.1384)	grad_norm 4.4844 (5.4809)	mem 8926MB
[2022-04-08 17:47:36 large] (main.py 226): INFO Train: [202/300][2100/2502]	eta 0:03:24 lr 0.000122	time 0.5442 (0.5092)	loss 3.3706 (3.1323)	grad_norm 4.5493 (5.4690)	mem 8926MB
[2022-04-08 17:48:28 large] (main.py 226): INFO Train: [202/300][2200/2502]	eta 0:02:33 lr 0.000122	time 0.5073 (0.5095)	loss 2.3297 (3.1351)	grad_norm 5.2356 (5.4657)	mem 8926MB
[2022-04-08 17:49:20 large] (main.py 226): INFO Train: [202/300][2300/2502]	eta 0:01:42 lr 0.000122	time 0.5051 (0.5098)	loss 3.5668 (3.1350)	grad_norm 4.8576 (5.4636)	mem 8926MB
[2022-04-08 17:50:11 large] (main.py 226): INFO Train: [202/300][2400/2502]	eta 0:00:52 lr 0.000122	time 0.4903 (0.5101)	loss 2.8517 (3.1333)	grad_norm 4.8173 (5.4625)	mem 8926MB
[2022-04-08 17:51:02 large] (main.py 226): INFO Train: [202/300][2500/2502]	eta 0:00:01 lr 0.000122	time 0.4815 (0.5102)	loss 3.3442 (3.1288)	grad_norm 5.4530 (5.4619)	mem 8926MB
[2022-04-08 17:51:03 large] (main.py 233): INFO EPOCH 202 training takes 0:21:16
[2022-04-08 17:51:10 large] (main.py 273): INFO Test: [0/98]	Time 6.232 (6.232)	Loss 0.9632 (0.9632)	Acc@1 81.641 (81.641)	Acc@5 95.508 (95.508)	Mem 8926MB
[2022-04-08 17:51:35 large] (main.py 279): INFO  * Acc@1 79.616 Acc@5 94.836
[2022-04-08 17:51:35 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 79.6%
[2022-04-08 17:51:35 large] (utils.py 57): INFO output/large/default/ckpt_epoch_202.pth saving......
[2022-04-08 17:51:36 large] (utils.py 59): INFO output/large/default/ckpt_epoch_202.pth saved !!!
[2022-04-08 17:51:36 large] (main.py 148): INFO Max accuracy: 79.62%
[2022-04-08 17:51:44 large] (main.py 226): INFO Train: [203/300][0/2502]	eta 5:39:53 lr 0.000122	time 8.1507 (8.1507)	loss 2.8699 (2.8699)	grad_norm 6.8824 (6.8824)	mem 8926MB
[2022-04-08 17:52:33 large] (main.py 226): INFO Train: [203/300][100/2502]	eta 0:22:22 lr 0.000122	time 0.4983 (0.5591)	loss 2.4014 (3.0821)	grad_norm 4.7141 (5.3948)	mem 8926MB
[2022-04-08 17:53:23 large] (main.py 226): INFO Train: [203/300][200/2502]	eta 0:20:24 lr 0.000122	time 0.5260 (0.5320)	loss 2.1896 (3.0805)	grad_norm 5.7361 (5.4643)	mem 8926MB
[2022-04-08 17:54:15 large] (main.py 226): INFO Train: [203/300][300/2502]	eta 0:19:22 lr 0.000122	time 0.5296 (0.5280)	loss 3.4186 (3.1057)	grad_norm 5.0792 (5.4673)	mem 8926MB
[2022-04-08 17:55:05 large] (main.py 226): INFO Train: [203/300][400/2502]	eta 0:18:15 lr 0.000122	time 0.4990 (0.5213)	loss 3.8423 (3.1327)	grad_norm 4.8117 (5.4532)	mem 8926MB
[2022-04-08 17:55:56 large] (main.py 226): INFO Train: [203/300][500/2502]	eta 0:17:20 lr 0.000122	time 0.5132 (0.5197)	loss 3.5489 (3.1330)	grad_norm 3.7142 (5.4005)	mem 8926MB
[2022-04-08 17:56:48 large] (main.py 226): INFO Train: [203/300][600/2502]	eta 0:16:28 lr 0.000122	time 0.5621 (0.5195)	loss 3.2975 (3.1376)	grad_norm 5.8479 (5.4010)	mem 8926MB
[2022-04-08 17:57:40 large] (main.py 226): INFO Train: [203/300][700/2502]	eta 0:15:36 lr 0.000121	time 0.4646 (0.5194)	loss 2.2863 (3.1440)	grad_norm 4.8360 (5.4340)	mem 8926MB
[2022-04-08 17:58:29 large] (main.py 226): INFO Train: [203/300][800/2502]	eta 0:14:38 lr 0.000121	time 0.4803 (0.5159)	loss 3.4612 (3.1339)	grad_norm 5.1151 (5.5004)	mem 8926MB
[2022-04-08 17:59:20 large] (main.py 226): INFO Train: [203/300][900/2502]	eta 0:13:44 lr 0.000121	time 0.5699 (0.5145)	loss 3.4033 (3.1355)	grad_norm 6.7408 (5.4770)	mem 8926MB
[2022-04-08 18:00:11 large] (main.py 226): INFO Train: [203/300][1000/2502]	eta 0:12:52 lr 0.000121	time 0.5257 (0.5146)	loss 3.4746 (3.1448)	grad_norm 4.8861 (5.4468)	mem 8926MB
[2022-04-08 18:01:03 large] (main.py 226): INFO Train: [203/300][1100/2502]	eta 0:12:01 lr 0.000121	time 0.5175 (0.5149)	loss 2.4167 (3.1369)	grad_norm 5.2653 (5.4483)	mem 8926MB
[2022-04-08 18:01:55 large] (main.py 226): INFO Train: [203/300][1200/2502]	eta 0:11:10 lr 0.000121	time 0.5342 (0.5150)	loss 2.6586 (3.1354)	grad_norm 5.7577 (nan)	mem 8926MB
[2022-04-08 18:02:46 large] (main.py 226): INFO Train: [203/300][1300/2502]	eta 0:10:18 lr 0.000121	time 0.5141 (0.5149)	loss 3.5945 (3.1271)	grad_norm 7.2760 (nan)	mem 8926MB
[2022-04-08 18:03:37 large] (main.py 226): INFO Train: [203/300][1400/2502]	eta 0:09:27 lr 0.000121	time 0.4997 (0.5148)	loss 1.9032 (3.1309)	grad_norm 4.5886 (nan)	mem 8926MB
[2022-04-08 18:04:29 large] (main.py 226): INFO Train: [203/300][1500/2502]	eta 0:08:36 lr 0.000121	time 0.4956 (0.5150)	loss 2.9258 (3.1261)	grad_norm 4.9481 (nan)	mem 8926MB
[2022-04-08 18:05:19 large] (main.py 226): INFO Train: [203/300][1600/2502]	eta 0:07:43 lr 0.000121	time 0.5062 (0.5141)	loss 2.5509 (3.1235)	grad_norm 3.7816 (nan)	mem 8926MB
[2022-04-08 18:06:10 large] (main.py 226): INFO Train: [203/300][1700/2502]	eta 0:06:52 lr 0.000121	time 0.5104 (0.5137)	loss 3.5618 (3.1282)	grad_norm 4.7291 (nan)	mem 8926MB
[2022-04-08 18:07:00 large] (main.py 226): INFO Train: [203/300][1800/2502]	eta 0:05:59 lr 0.000120	time 0.4954 (0.5127)	loss 3.2170 (3.1257)	grad_norm 5.7575 (nan)	mem 8926MB
[2022-04-08 18:07:51 large] (main.py 226): INFO Train: [203/300][1900/2502]	eta 0:05:08 lr 0.000120	time 0.5038 (0.5127)	loss 3.6739 (3.1231)	grad_norm 4.6370 (nan)	mem 8926MB
[2022-04-08 18:08:42 large] (main.py 226): INFO Train: [203/300][2000/2502]	eta 0:04:17 lr 0.000120	time 0.5111 (0.5129)	loss 2.3813 (3.1249)	grad_norm 8.5337 (nan)	mem 8926MB
[2022-04-08 18:09:33 large] (main.py 226): INFO Train: [203/300][2100/2502]	eta 0:03:26 lr 0.000120	time 0.4891 (0.5126)	loss 2.7183 (3.1264)	grad_norm 5.2799 (nan)	mem 8926MB
[2022-04-08 18:10:23 large] (main.py 226): INFO Train: [203/300][2200/2502]	eta 0:02:34 lr 0.000120	time 0.5112 (0.5122)	loss 3.1169 (3.1258)	grad_norm 5.2828 (nan)	mem 8926MB
[2022-04-08 18:11:15 large] (main.py 226): INFO Train: [203/300][2300/2502]	eta 0:01:43 lr 0.000120	time 0.4870 (0.5123)	loss 2.9446 (3.1273)	grad_norm 6.1926 (nan)	mem 8926MB
[2022-04-08 18:12:06 large] (main.py 226): INFO Train: [203/300][2400/2502]	eta 0:00:52 lr 0.000120	time 0.5179 (0.5123)	loss 3.6934 (3.1264)	grad_norm 4.6312 (nan)	mem 8926MB
[2022-04-08 18:12:56 large] (main.py 226): INFO Train: [203/300][2500/2502]	eta 0:00:01 lr 0.000120	time 0.5146 (0.5118)	loss 3.1755 (3.1234)	grad_norm 6.9691 (nan)	mem 8926MB
[2022-04-08 18:12:57 large] (main.py 233): INFO EPOCH 203 training takes 0:21:20
[2022-04-08 18:13:03 large] (main.py 273): INFO Test: [0/98]	Time 5.836 (5.836)	Loss 0.9856 (0.9856)	Acc@1 81.836 (81.836)	Acc@5 94.141 (94.141)	Mem 8926MB
[2022-04-08 18:13:30 large] (main.py 279): INFO  * Acc@1 79.768 Acc@5 94.852
[2022-04-08 18:13:30 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 79.8%
[2022-04-08 18:13:30 large] (utils.py 57): INFO output/large/default/ckpt_epoch_203.pth saving......
[2022-04-08 18:13:30 large] (utils.py 59): INFO output/large/default/ckpt_epoch_203.pth saved !!!
[2022-04-08 18:13:30 large] (main.py 148): INFO Max accuracy: 79.77%
[2022-04-08 18:13:38 large] (main.py 226): INFO Train: [204/300][0/2502]	eta 5:31:47 lr 0.000120	time 7.9567 (7.9567)	loss 3.3868 (3.3868)	grad_norm 5.2675 (5.2675)	mem 8926MB
[2022-04-08 18:14:28 large] (main.py 226): INFO Train: [204/300][100/2502]	eta 0:22:38 lr 0.000120	time 0.4767 (0.5657)	loss 3.7818 (3.0617)	grad_norm 4.5731 (6.0616)	mem 8926MB
[2022-04-08 18:15:19 large] (main.py 226): INFO Train: [204/300][200/2502]	eta 0:20:38 lr 0.000120	time 0.5243 (0.5382)	loss 2.6038 (3.0922)	grad_norm 5.1327 (6.0057)	mem 8926MB
[2022-04-08 18:16:10 large] (main.py 226): INFO Train: [204/300][300/2502]	eta 0:19:30 lr 0.000120	time 0.5096 (0.5316)	loss 3.5641 (3.0941)	grad_norm 4.7266 (5.7539)	mem 8926MB
[2022-04-08 18:17:02 large] (main.py 226): INFO Train: [204/300][400/2502]	eta 0:18:31 lr 0.000120	time 0.5871 (0.5286)	loss 2.9500 (3.1118)	grad_norm 5.4967 (5.6353)	mem 8926MB
[2022-04-08 18:17:54 large] (main.py 226): INFO Train: [204/300][500/2502]	eta 0:17:34 lr 0.000119	time 0.6059 (0.5269)	loss 2.1585 (3.1206)	grad_norm 4.3614 (5.6460)	mem 8926MB
[2022-04-08 18:18:44 large] (main.py 226): INFO Train: [204/300][600/2502]	eta 0:16:32 lr 0.000119	time 0.4702 (0.5218)	loss 3.4402 (3.1353)	grad_norm 7.2610 (5.6547)	mem 8926MB
[2022-04-08 18:19:35 large] (main.py 226): INFO Train: [204/300][700/2502]	eta 0:15:38 lr 0.000119	time 0.5334 (0.5207)	loss 3.3150 (3.1385)	grad_norm 4.2970 (5.6584)	mem 8926MB
[2022-04-08 18:20:25 large] (main.py 226): INFO Train: [204/300][800/2502]	eta 0:14:39 lr 0.000119	time 0.4805 (0.5170)	loss 2.0733 (3.1373)	grad_norm 5.5607 (5.7180)	mem 8926MB
[2022-04-08 18:21:12 large] (main.py 226): INFO Train: [204/300][900/2502]	eta 0:13:41 lr 0.000119	time 0.4862 (0.5129)	loss 2.9342 (3.1342)	grad_norm 3.9047 (5.7002)	mem 8926MB
[2022-04-08 18:22:03 large] (main.py 226): INFO Train: [204/300][1000/2502]	eta 0:12:49 lr 0.000119	time 0.5564 (0.5125)	loss 2.9795 (3.1332)	grad_norm 5.2123 (5.7375)	mem 8926MB
[2022-04-08 18:22:55 large] (main.py 226): INFO Train: [204/300][1100/2502]	eta 0:11:58 lr 0.000119	time 0.5020 (0.5128)	loss 3.3229 (3.1339)	grad_norm 4.0014 (5.7183)	mem 8926MB
[2022-04-08 18:23:45 large] (main.py 226): INFO Train: [204/300][1200/2502]	eta 0:11:06 lr 0.000119	time 0.5077 (0.5120)	loss 3.3805 (3.1291)	grad_norm 6.1613 (5.7014)	mem 8926MB
[2022-04-08 18:24:36 large] (main.py 226): INFO Train: [204/300][1300/2502]	eta 0:10:15 lr 0.000119	time 0.5173 (0.5117)	loss 3.5470 (3.1279)	grad_norm 5.3483 (5.7006)	mem 8926MB
[2022-04-08 18:25:28 large] (main.py 226): INFO Train: [204/300][1400/2502]	eta 0:09:24 lr 0.000119	time 0.5132 (0.5120)	loss 3.2302 (3.1194)	grad_norm 4.9819 (5.6922)	mem 8926MB
[2022-04-08 18:26:19 large] (main.py 226): INFO Train: [204/300][1500/2502]	eta 0:08:33 lr 0.000119	time 0.4929 (0.5122)	loss 3.4676 (3.1244)	grad_norm 5.9433 (5.6777)	mem 8926MB
[2022-04-08 18:27:09 large] (main.py 226): INFO Train: [204/300][1600/2502]	eta 0:07:41 lr 0.000118	time 0.5002 (0.5111)	loss 3.3361 (3.1268)	grad_norm 6.1285 (nan)	mem 8926MB
[2022-04-08 18:28:00 large] (main.py 226): INFO Train: [204/300][1700/2502]	eta 0:06:49 lr 0.000118	time 0.4756 (0.5111)	loss 2.7553 (3.1209)	grad_norm 5.8136 (nan)	mem 8926MB
[2022-04-08 18:28:49 large] (main.py 226): INFO Train: [204/300][1800/2502]	eta 0:05:58 lr 0.000118	time 0.4714 (0.5103)	loss 2.5115 (3.1270)	grad_norm 5.2570 (nan)	mem 8926MB
[2022-04-08 18:29:39 large] (main.py 226): INFO Train: [204/300][1900/2502]	eta 0:05:06 lr 0.000118	time 0.5359 (0.5094)	loss 2.8709 (3.1258)	grad_norm 5.4847 (nan)	mem 8926MB
[2022-04-08 18:30:28 large] (main.py 226): INFO Train: [204/300][2000/2502]	eta 0:04:15 lr 0.000118	time 0.5160 (0.5084)	loss 3.6117 (3.1248)	grad_norm 6.7808 (nan)	mem 8926MB
[2022-04-08 18:31:17 large] (main.py 226): INFO Train: [204/300][2100/2502]	eta 0:03:24 lr 0.000118	time 0.4893 (0.5076)	loss 3.2307 (3.1264)	grad_norm 4.8414 (nan)	mem 8926MB
[2022-04-08 18:32:05 large] (main.py 226): INFO Train: [204/300][2200/2502]	eta 0:02:32 lr 0.000118	time 0.4869 (0.5066)	loss 3.8191 (3.1312)	grad_norm 6.8866 (nan)	mem 8926MB
[2022-04-08 18:32:55 large] (main.py 226): INFO Train: [204/300][2300/2502]	eta 0:01:42 lr 0.000118	time 0.5126 (0.5062)	loss 3.7178 (3.1320)	grad_norm 5.1408 (nan)	mem 8926MB
[2022-04-08 18:33:44 large] (main.py 226): INFO Train: [204/300][2400/2502]	eta 0:00:51 lr 0.000118	time 0.4814 (0.5053)	loss 3.5320 (3.1329)	grad_norm 5.2776 (nan)	mem 8926MB
[2022-04-08 18:34:33 large] (main.py 226): INFO Train: [204/300][2500/2502]	eta 0:00:01 lr 0.000118	time 0.4945 (0.5050)	loss 3.2094 (3.1301)	grad_norm 4.2335 (nan)	mem 8926MB
[2022-04-08 18:34:34 large] (main.py 233): INFO EPOCH 204 training takes 0:21:04
[2022-04-08 18:34:40 large] (main.py 273): INFO Test: [0/98]	Time 5.439 (5.439)	Loss 1.0267 (1.0267)	Acc@1 78.906 (78.906)	Acc@5 96.094 (96.094)	Mem 8926MB
[2022-04-08 18:35:07 large] (main.py 279): INFO  * Acc@1 79.726 Acc@5 94.832
[2022-04-08 18:35:07 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 79.7%
[2022-04-08 18:35:07 large] (main.py 148): INFO Max accuracy: 79.77%
[2022-04-08 18:35:14 large] (main.py 226): INFO Train: [205/300][0/2502]	eta 4:40:56 lr 0.000118	time 6.7371 (6.7371)	loss 2.8704 (2.8704)	grad_norm 4.1093 (4.1093)	mem 8926MB
[2022-04-08 18:36:04 large] (main.py 226): INFO Train: [205/300][100/2502]	eta 0:22:38 lr 0.000118	time 0.4538 (0.5655)	loss 3.7580 (3.0860)	grad_norm 6.1300 (5.4215)	mem 8926MB
[2022-04-08 18:36:55 large] (main.py 226): INFO Train: [205/300][200/2502]	eta 0:20:34 lr 0.000118	time 0.5115 (0.5362)	loss 3.2602 (3.1123)	grad_norm 5.5476 (5.6272)	mem 8926MB
[2022-04-08 18:37:47 large] (main.py 226): INFO Train: [205/300][300/2502]	eta 0:19:28 lr 0.000117	time 0.5255 (0.5305)	loss 3.7933 (3.1187)	grad_norm 5.8721 (5.7081)	mem 8926MB
[2022-04-08 18:38:37 large] (main.py 226): INFO Train: [205/300][400/2502]	eta 0:18:19 lr 0.000117	time 0.5040 (0.5233)	loss 3.5943 (3.1284)	grad_norm 5.4223 (5.7064)	mem 8926MB
[2022-04-08 18:39:28 large] (main.py 226): INFO Train: [205/300][500/2502]	eta 0:17:23 lr 0.000117	time 0.5685 (0.5211)	loss 3.2348 (3.1265)	grad_norm 8.2641 (5.6809)	mem 8926MB
[2022-04-08 18:40:18 large] (main.py 226): INFO Train: [205/300][600/2502]	eta 0:16:23 lr 0.000117	time 0.5068 (0.5168)	loss 3.4472 (3.1425)	grad_norm 5.3431 (5.6970)	mem 8926MB
[2022-04-08 18:41:09 large] (main.py 226): INFO Train: [205/300][700/2502]	eta 0:15:30 lr 0.000117	time 0.5149 (0.5161)	loss 3.2527 (3.1461)	grad_norm 5.9362 (5.6900)	mem 8926MB
[2022-04-08 18:42:00 large] (main.py 226): INFO Train: [205/300][800/2502]	eta 0:14:37 lr 0.000117	time 0.5054 (0.5157)	loss 2.2027 (3.1390)	grad_norm 4.7454 (5.6828)	mem 8926MB
[2022-04-08 18:42:51 large] (main.py 226): INFO Train: [205/300][900/2502]	eta 0:13:45 lr 0.000117	time 0.4973 (0.5153)	loss 2.0699 (3.1309)	grad_norm 5.2125 (5.6771)	mem 8926MB
[2022-04-08 18:43:41 large] (main.py 226): INFO Train: [205/300][1000/2502]	eta 0:12:51 lr 0.000117	time 0.5023 (0.5136)	loss 2.3789 (3.1238)	grad_norm 5.1508 (5.6840)	mem 8926MB
[2022-04-08 18:44:32 large] (main.py 226): INFO Train: [205/300][1100/2502]	eta 0:11:59 lr 0.000117	time 0.5003 (0.5133)	loss 1.9085 (3.1263)	grad_norm 5.2904 (5.6630)	mem 8926MB
[2022-04-08 18:45:22 large] (main.py 226): INFO Train: [205/300][1200/2502]	eta 0:11:06 lr 0.000117	time 0.4930 (0.5120)	loss 3.5647 (3.1245)	grad_norm 5.7231 (5.6380)	mem 8926MB
[2022-04-08 18:46:10 large] (main.py 226): INFO Train: [205/300][1300/2502]	eta 0:10:13 lr 0.000117	time 0.4902 (0.5100)	loss 3.7793 (3.1213)	grad_norm 6.3176 (5.6474)	mem 8926MB
[2022-04-08 18:47:00 large] (main.py 226): INFO Train: [205/300][1400/2502]	eta 0:09:21 lr 0.000116	time 0.4741 (0.5092)	loss 2.6708 (3.1190)	grad_norm 7.2500 (5.6512)	mem 8926MB
[2022-04-08 18:47:49 large] (main.py 226): INFO Train: [205/300][1500/2502]	eta 0:08:28 lr 0.000116	time 0.4702 (0.5075)	loss 3.2471 (3.1189)	grad_norm 5.6932 (5.7203)	mem 8926MB
[2022-04-08 18:48:38 large] (main.py 226): INFO Train: [205/300][1600/2502]	eta 0:07:37 lr 0.000116	time 0.5864 (0.5069)	loss 3.4784 (3.1187)	grad_norm 4.5314 (5.7066)	mem 8926MB
[2022-04-08 18:49:30 large] (main.py 226): INFO Train: [205/300][1700/2502]	eta 0:06:46 lr 0.000116	time 0.5035 (0.5074)	loss 3.3174 (3.1180)	grad_norm 4.7809 (5.7075)	mem 8926MB
[2022-04-08 18:50:19 large] (main.py 226): INFO Train: [205/300][1800/2502]	eta 0:05:55 lr 0.000116	time 0.4768 (0.5067)	loss 3.2529 (3.1208)	grad_norm 4.8024 (5.6922)	mem 8926MB
[2022-04-08 18:51:09 large] (main.py 226): INFO Train: [205/300][1900/2502]	eta 0:05:04 lr 0.000116	time 0.5137 (0.5061)	loss 2.6435 (3.1232)	grad_norm 3.9618 (5.6734)	mem 8926MB
[2022-04-08 18:52:00 large] (main.py 226): INFO Train: [205/300][2000/2502]	eta 0:04:14 lr 0.000116	time 0.5167 (0.5065)	loss 3.1399 (3.1216)	grad_norm 5.4220 (5.6491)	mem 8926MB
[2022-04-08 18:52:52 large] (main.py 226): INFO Train: [205/300][2100/2502]	eta 0:03:23 lr 0.000116	time 0.5120 (0.5071)	loss 3.7386 (3.1256)	grad_norm 5.8012 (5.6392)	mem 8926MB
[2022-04-08 18:53:44 large] (main.py 226): INFO Train: [205/300][2200/2502]	eta 0:02:33 lr 0.000116	time 0.5182 (0.5074)	loss 3.3665 (3.1301)	grad_norm 4.5804 (5.6446)	mem 8926MB
[2022-04-08 18:54:34 large] (main.py 226): INFO Train: [205/300][2300/2502]	eta 0:01:42 lr 0.000116	time 0.4995 (0.5071)	loss 3.2257 (3.1327)	grad_norm 5.3019 (5.6538)	mem 8926MB
[2022-04-08 18:55:23 large] (main.py 226): INFO Train: [205/300][2400/2502]	eta 0:00:51 lr 0.000116	time 0.4926 (0.5065)	loss 3.2536 (3.1315)	grad_norm 4.1782 (5.6519)	mem 8926MB
[2022-04-08 18:56:13 large] (main.py 226): INFO Train: [205/300][2500/2502]	eta 0:00:01 lr 0.000116	time 0.4714 (0.5063)	loss 2.8078 (3.1306)	grad_norm 4.4797 (5.6424)	mem 8926MB
[2022-04-08 18:56:14 large] (main.py 233): INFO EPOCH 205 training takes 0:21:07
[2022-04-08 18:56:21 large] (main.py 273): INFO Test: [0/98]	Time 6.674 (6.674)	Loss 1.0509 (1.0509)	Acc@1 76.367 (76.367)	Acc@5 95.703 (95.703)	Mem 8926MB
[2022-04-08 18:56:47 large] (main.py 279): INFO  * Acc@1 79.618 Acc@5 94.890
[2022-04-08 18:56:47 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 79.6%
[2022-04-08 18:56:47 large] (main.py 148): INFO Max accuracy: 79.77%
[2022-04-08 18:56:54 large] (main.py 226): INFO Train: [206/300][0/2502]	eta 4:53:38 lr 0.000116	time 7.0416 (7.0416)	loss 3.2254 (3.2254)	grad_norm 5.1658 (5.1658)	mem 8926MB
[2022-04-08 18:57:44 large] (main.py 226): INFO Train: [206/300][100/2502]	eta 0:22:50 lr 0.000115	time 0.5806 (0.5707)	loss 3.7250 (3.0440)	grad_norm 5.3855 (5.3413)	mem 8926MB
[2022-04-08 18:58:36 large] (main.py 226): INFO Train: [206/300][200/2502]	eta 0:20:45 lr 0.000115	time 0.5480 (0.5409)	loss 3.4074 (3.0318)	grad_norm 5.0942 (5.4130)	mem 8926MB
[2022-04-08 18:59:28 large] (main.py 226): INFO Train: [206/300][300/2502]	eta 0:19:36 lr 0.000115	time 0.5364 (0.5344)	loss 3.0878 (3.0591)	grad_norm 5.1466 (5.4708)	mem 8926MB
[2022-04-08 19:00:19 large] (main.py 226): INFO Train: [206/300][400/2502]	eta 0:18:34 lr 0.000115	time 0.4862 (0.5302)	loss 3.4282 (3.0750)	grad_norm 7.9765 (5.5366)	mem 8926MB
[2022-04-08 19:01:11 large] (main.py 226): INFO Train: [206/300][500/2502]	eta 0:17:34 lr 0.000115	time 0.5070 (0.5269)	loss 3.0734 (3.0736)	grad_norm 9.1994 (5.5632)	mem 8926MB
[2022-04-08 19:02:01 large] (main.py 226): INFO Train: [206/300][600/2502]	eta 0:16:33 lr 0.000115	time 0.5908 (0.5222)	loss 2.8418 (3.0866)	grad_norm 4.8480 (5.5613)	mem 8926MB
[2022-04-08 19:02:52 large] (main.py 226): INFO Train: [206/300][700/2502]	eta 0:15:38 lr 0.000115	time 0.5060 (0.5208)	loss 3.7519 (3.0906)	grad_norm 5.5558 (5.5479)	mem 8926MB
[2022-04-08 19:03:43 large] (main.py 226): INFO Train: [206/300][800/2502]	eta 0:14:45 lr 0.000115	time 0.5152 (0.5202)	loss 2.1059 (3.0920)	grad_norm 6.2989 (5.5563)	mem 8926MB
[2022-04-08 19:04:35 large] (main.py 226): INFO Train: [206/300][900/2502]	eta 0:13:52 lr 0.000115	time 0.5466 (0.5194)	loss 2.8271 (3.0845)	grad_norm 5.8657 (5.5567)	mem 8926MB
[2022-04-08 19:05:26 large] (main.py 226): INFO Train: [206/300][1000/2502]	eta 0:12:59 lr 0.000115	time 0.5090 (0.5188)	loss 2.7350 (3.0846)	grad_norm 15.0122 (5.5463)	mem 8926MB
[2022-04-08 19:06:17 large] (main.py 226): INFO Train: [206/300][1100/2502]	eta 0:12:06 lr 0.000115	time 0.5133 (0.5182)	loss 3.4036 (3.0904)	grad_norm 8.4890 (5.5535)	mem 8926MB
[2022-04-08 19:07:09 large] (main.py 226): INFO Train: [206/300][1200/2502]	eta 0:11:14 lr 0.000115	time 0.5515 (0.5177)	loss 3.4092 (3.0958)	grad_norm 5.7400 (5.5717)	mem 8926MB
[2022-04-08 19:08:00 large] (main.py 226): INFO Train: [206/300][1300/2502]	eta 0:10:22 lr 0.000114	time 0.4972 (0.5175)	loss 2.9936 (3.0927)	grad_norm 6.7220 (5.6051)	mem 8926MB
[2022-04-08 19:08:51 large] (main.py 226): INFO Train: [206/300][1400/2502]	eta 0:09:29 lr 0.000114	time 0.5552 (0.5172)	loss 2.3225 (3.0932)	grad_norm 5.9283 (5.6048)	mem 8926MB
[2022-04-08 19:09:43 large] (main.py 226): INFO Train: [206/300][1500/2502]	eta 0:08:37 lr 0.000114	time 0.5095 (0.5168)	loss 2.9013 (3.0954)	grad_norm 6.6752 (5.5884)	mem 8926MB
[2022-04-08 19:10:33 large] (main.py 226): INFO Train: [206/300][1600/2502]	eta 0:07:45 lr 0.000114	time 0.5137 (0.5163)	loss 3.3404 (3.0927)	grad_norm 5.5190 (5.5638)	mem 8926MB
[2022-04-08 19:11:23 large] (main.py 226): INFO Train: [206/300][1700/2502]	eta 0:06:53 lr 0.000114	time 0.4680 (0.5152)	loss 3.3206 (3.1030)	grad_norm 4.3870 (5.5596)	mem 8926MB
[2022-04-08 19:12:13 large] (main.py 226): INFO Train: [206/300][1800/2502]	eta 0:06:00 lr 0.000114	time 0.4992 (0.5140)	loss 3.3534 (3.1064)	grad_norm 6.2277 (5.5555)	mem 8926MB
[2022-04-08 19:13:04 large] (main.py 226): INFO Train: [206/300][1900/2502]	eta 0:05:09 lr 0.000114	time 0.5064 (0.5138)	loss 3.3703 (3.1089)	grad_norm 5.8627 (5.5524)	mem 8926MB
[2022-04-08 19:13:55 large] (main.py 226): INFO Train: [206/300][2000/2502]	eta 0:04:17 lr 0.000114	time 0.5870 (0.5138)	loss 3.5257 (3.1079)	grad_norm 7.7986 (5.5509)	mem 8926MB
[2022-04-08 19:14:45 large] (main.py 226): INFO Train: [206/300][2100/2502]	eta 0:03:26 lr 0.000114	time 0.4860 (0.5132)	loss 3.3735 (3.1054)	grad_norm 4.9846 (5.5569)	mem 8926MB
[2022-04-08 19:15:36 large] (main.py 226): INFO Train: [206/300][2200/2502]	eta 0:02:34 lr 0.000114	time 0.5258 (0.5130)	loss 3.1128 (3.1030)	grad_norm 5.0666 (5.5483)	mem 8926MB
[2022-04-08 19:16:27 large] (main.py 226): INFO Train: [206/300][2300/2502]	eta 0:01:43 lr 0.000114	time 0.5412 (0.5128)	loss 3.4551 (3.1025)	grad_norm 5.7900 (5.5519)	mem 8926MB
[2022-04-08 19:17:18 large] (main.py 226): INFO Train: [206/300][2400/2502]	eta 0:00:52 lr 0.000113	time 0.4984 (0.5127)	loss 3.0294 (3.1041)	grad_norm 4.2102 (5.5610)	mem 8926MB
[2022-04-08 19:18:09 large] (main.py 226): INFO Train: [206/300][2500/2502]	eta 0:00:01 lr 0.000113	time 0.4977 (0.5125)	loss 3.1777 (3.1045)	grad_norm 5.3765 (nan)	mem 8926MB
[2022-04-08 19:18:10 large] (main.py 233): INFO EPOCH 206 training takes 0:21:22
[2022-04-08 19:18:16 large] (main.py 273): INFO Test: [0/98]	Time 6.566 (6.566)	Loss 0.9969 (0.9969)	Acc@1 80.273 (80.273)	Acc@5 93.945 (93.945)	Mem 8926MB
[2022-04-08 19:18:42 large] (main.py 279): INFO  * Acc@1 79.764 Acc@5 94.874
[2022-04-08 19:18:42 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 79.8%
[2022-04-08 19:18:42 large] (main.py 148): INFO Max accuracy: 79.77%
[2022-04-08 19:18:51 large] (main.py 226): INFO Train: [207/300][0/2502]	eta 6:10:08 lr 0.000113	time 8.8763 (8.8763)	loss 3.2791 (3.2791)	grad_norm 5.1373 (5.1373)	mem 8926MB
[2022-04-08 19:19:40 large] (main.py 226): INFO Train: [207/300][100/2502]	eta 0:23:06 lr 0.000113	time 0.4952 (0.5774)	loss 3.3845 (3.0846)	grad_norm 5.1901 (5.3622)	mem 8926MB
[2022-04-08 19:20:30 large] (main.py 226): INFO Train: [207/300][200/2502]	eta 0:20:42 lr 0.000113	time 0.4822 (0.5398)	loss 2.9701 (3.0875)	grad_norm 4.5754 (5.4923)	mem 8926MB
[2022-04-08 19:21:21 large] (main.py 226): INFO Train: [207/300][300/2502]	eta 0:19:25 lr 0.000113	time 0.4985 (0.5291)	loss 2.8216 (3.0901)	grad_norm 4.7455 (5.6097)	mem 8926MB
[2022-04-08 19:22:11 large] (main.py 226): INFO Train: [207/300][400/2502]	eta 0:18:15 lr 0.000113	time 0.4977 (0.5211)	loss 3.1627 (3.0848)	grad_norm 4.7100 (5.5475)	mem 8926MB
[2022-04-08 19:23:02 large] (main.py 226): INFO Train: [207/300][500/2502]	eta 0:17:20 lr 0.000113	time 0.4957 (0.5196)	loss 2.8064 (3.0876)	grad_norm 6.5908 (5.6165)	mem 8926MB
[2022-04-08 19:23:53 large] (main.py 226): INFO Train: [207/300][600/2502]	eta 0:16:24 lr 0.000113	time 0.4952 (0.5177)	loss 3.6148 (3.0976)	grad_norm 5.5637 (5.5926)	mem 8926MB
[2022-04-08 19:24:42 large] (main.py 226): INFO Train: [207/300][700/2502]	eta 0:15:25 lr 0.000113	time 0.4895 (0.5138)	loss 2.7865 (3.0945)	grad_norm 5.8311 (5.6138)	mem 8926MB
[2022-04-08 19:25:31 large] (main.py 226): INFO Train: [207/300][800/2502]	eta 0:14:29 lr 0.000113	time 0.5262 (0.5108)	loss 3.6906 (3.0992)	grad_norm 5.7902 (5.5969)	mem 8926MB
[2022-04-08 19:26:21 large] (main.py 226): INFO Train: [207/300][900/2502]	eta 0:13:36 lr 0.000113	time 0.4899 (0.5096)	loss 3.0666 (3.1079)	grad_norm 6.5566 (5.6121)	mem 8926MB
[2022-04-08 19:27:13 large] (main.py 226): INFO Train: [207/300][1000/2502]	eta 0:12:46 lr 0.000113	time 0.4821 (0.5103)	loss 3.1796 (3.1100)	grad_norm 4.2826 (5.6241)	mem 8926MB
[2022-04-08 19:28:01 large] (main.py 226): INFO Train: [207/300][1100/2502]	eta 0:11:52 lr 0.000112	time 0.4918 (0.5083)	loss 2.8513 (3.1085)	grad_norm 4.5067 (5.6128)	mem 8926MB
[2022-04-08 19:28:52 large] (main.py 226): INFO Train: [207/300][1200/2502]	eta 0:11:01 lr 0.000112	time 0.5081 (0.5079)	loss 3.3125 (3.1057)	grad_norm 5.5967 (5.5955)	mem 8926MB
[2022-04-08 19:29:43 large] (main.py 226): INFO Train: [207/300][1300/2502]	eta 0:10:11 lr 0.000112	time 0.5417 (0.5085)	loss 3.5420 (3.1014)	grad_norm 6.1922 (5.6071)	mem 8926MB
[2022-04-08 19:30:33 large] (main.py 226): INFO Train: [207/300][1400/2502]	eta 0:09:19 lr 0.000112	time 0.4944 (0.5078)	loss 3.4886 (3.0998)	grad_norm 4.3091 (5.5811)	mem 8926MB
[2022-04-08 19:31:23 large] (main.py 226): INFO Train: [207/300][1500/2502]	eta 0:08:28 lr 0.000112	time 0.4825 (0.5070)	loss 2.7731 (3.0943)	grad_norm 4.0781 (5.5721)	mem 8926MB
[2022-04-08 19:32:11 large] (main.py 226): INFO Train: [207/300][1600/2502]	eta 0:07:36 lr 0.000112	time 0.4698 (0.5058)	loss 3.3848 (3.0995)	grad_norm 4.5480 (5.5834)	mem 8926MB
[2022-04-08 19:33:02 large] (main.py 226): INFO Train: [207/300][1700/2502]	eta 0:06:45 lr 0.000112	time 0.4976 (0.5055)	loss 3.8756 (3.0981)	grad_norm 5.4482 (5.5832)	mem 8926MB
[2022-04-08 19:33:53 large] (main.py 226): INFO Train: [207/300][1800/2502]	eta 0:05:55 lr 0.000112	time 0.4868 (0.5059)	loss 3.1739 (3.1014)	grad_norm 4.4786 (5.5804)	mem 8926MB
[2022-04-08 19:34:43 large] (main.py 226): INFO Train: [207/300][1900/2502]	eta 0:05:04 lr 0.000112	time 0.4855 (0.5057)	loss 2.6539 (3.1020)	grad_norm 5.7157 (5.5723)	mem 8926MB
[2022-04-08 19:35:33 large] (main.py 226): INFO Train: [207/300][2000/2502]	eta 0:04:13 lr 0.000112	time 0.4521 (0.5053)	loss 3.4842 (3.1104)	grad_norm 5.3034 (5.5714)	mem 8926MB
[2022-04-08 19:36:22 large] (main.py 226): INFO Train: [207/300][2100/2502]	eta 0:03:22 lr 0.000112	time 0.4941 (0.5045)	loss 3.5209 (3.1116)	grad_norm 4.4054 (5.5860)	mem 8926MB
[2022-04-08 19:37:12 large] (main.py 226): INFO Train: [207/300][2200/2502]	eta 0:02:32 lr 0.000112	time 0.4608 (0.5043)	loss 3.6180 (3.1106)	grad_norm 4.4824 (5.6034)	mem 8926MB
[2022-04-08 19:38:01 large] (main.py 226): INFO Train: [207/300][2300/2502]	eta 0:01:41 lr 0.000111	time 0.4879 (0.5040)	loss 3.3989 (3.1099)	grad_norm 4.9048 (5.6059)	mem 8926MB
[2022-04-08 19:38:52 large] (main.py 226): INFO Train: [207/300][2400/2502]	eta 0:00:51 lr 0.000111	time 0.5191 (0.5039)	loss 3.4110 (3.1113)	grad_norm 4.9063 (5.6074)	mem 8926MB
[2022-04-08 19:39:41 large] (main.py 226): INFO Train: [207/300][2500/2502]	eta 0:00:01 lr 0.000111	time 0.4766 (0.5035)	loss 2.8574 (3.1144)	grad_norm 4.8305 (5.6122)	mem 8926MB
[2022-04-08 19:39:42 large] (main.py 233): INFO EPOCH 207 training takes 0:21:00
[2022-04-08 19:39:49 large] (main.py 273): INFO Test: [0/98]	Time 6.530 (6.530)	Loss 1.0604 (1.0604)	Acc@1 77.734 (77.734)	Acc@5 96.094 (96.094)	Mem 8926MB
[2022-04-08 19:40:14 large] (main.py 279): INFO  * Acc@1 79.900 Acc@5 94.810
[2022-04-08 19:40:14 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 79.9%
[2022-04-08 19:40:14 large] (utils.py 57): INFO output/large/default/ckpt_epoch_207.pth saving......
[2022-04-08 19:40:15 large] (utils.py 59): INFO output/large/default/ckpt_epoch_207.pth saved !!!
[2022-04-08 19:40:15 large] (main.py 148): INFO Max accuracy: 79.90%
[2022-04-08 19:40:23 large] (main.py 226): INFO Train: [208/300][0/2502]	eta 5:36:09 lr 0.000111	time 8.0615 (8.0615)	loss 2.4854 (2.4854)	grad_norm 4.7010 (4.7010)	mem 8926MB
[2022-04-08 19:41:13 large] (main.py 226): INFO Train: [208/300][100/2502]	eta 0:22:50 lr 0.000111	time 0.4929 (0.5706)	loss 2.8732 (3.1248)	grad_norm 5.2934 (nan)	mem 8926MB
[2022-04-08 19:42:04 large] (main.py 226): INFO Train: [208/300][200/2502]	eta 0:20:43 lr 0.000111	time 0.5366 (0.5404)	loss 2.4971 (3.1139)	grad_norm 5.9595 (nan)	mem 8926MB
[2022-04-08 19:42:56 large] (main.py 226): INFO Train: [208/300][300/2502]	eta 0:19:36 lr 0.000111	time 0.5172 (0.5342)	loss 3.1995 (3.1197)	grad_norm 8.4983 (nan)	mem 8926MB
[2022-04-08 19:43:48 large] (main.py 226): INFO Train: [208/300][400/2502]	eta 0:18:37 lr 0.000111	time 0.5207 (0.5316)	loss 3.5882 (3.1216)	grad_norm 4.9695 (nan)	mem 8926MB
[2022-04-08 19:44:41 large] (main.py 226): INFO Train: [208/300][500/2502]	eta 0:17:41 lr 0.000111	time 0.5176 (0.5300)	loss 3.3099 (3.1001)	grad_norm 5.7431 (nan)	mem 8926MB
[2022-04-08 19:45:32 large] (main.py 226): INFO Train: [208/300][600/2502]	eta 0:16:44 lr 0.000111	time 0.5101 (0.5279)	loss 2.8407 (3.1112)	grad_norm 4.7985 (nan)	mem 8926MB
[2022-04-08 19:46:24 large] (main.py 226): INFO Train: [208/300][700/2502]	eta 0:15:49 lr 0.000111	time 0.4961 (0.5268)	loss 2.5462 (3.1190)	grad_norm 4.5462 (nan)	mem 8926MB
[2022-04-08 19:47:16 large] (main.py 226): INFO Train: [208/300][800/2502]	eta 0:14:54 lr 0.000111	time 0.5102 (0.5254)	loss 2.9375 (3.1129)	grad_norm 6.4809 (nan)	mem 8926MB
[2022-04-08 19:48:06 large] (main.py 226): INFO Train: [208/300][900/2502]	eta 0:13:56 lr 0.000110	time 0.4409 (0.5223)	loss 2.3129 (3.1084)	grad_norm 3.8842 (nan)	mem 8926MB
[2022-04-08 19:48:57 large] (main.py 226): INFO Train: [208/300][1000/2502]	eta 0:13:03 lr 0.000110	time 0.5092 (0.5215)	loss 2.2880 (3.1058)	grad_norm 6.5675 (nan)	mem 8926MB
[2022-04-08 19:49:49 large] (main.py 226): INFO Train: [208/300][1100/2502]	eta 0:12:10 lr 0.000110	time 0.5246 (0.5214)	loss 3.2245 (3.1094)	grad_norm 5.8687 (nan)	mem 8926MB
[2022-04-08 19:50:41 large] (main.py 226): INFO Train: [208/300][1200/2502]	eta 0:11:18 lr 0.000110	time 0.6230 (0.5214)	loss 3.4867 (3.1102)	grad_norm 5.1814 (nan)	mem 8926MB
[2022-04-08 19:51:33 large] (main.py 226): INFO Train: [208/300][1300/2502]	eta 0:10:26 lr 0.000110	time 0.5180 (0.5208)	loss 2.3422 (3.1104)	grad_norm 5.6906 (nan)	mem 8926MB
[2022-04-08 19:52:24 large] (main.py 226): INFO Train: [208/300][1400/2502]	eta 0:09:33 lr 0.000110	time 0.4925 (0.5205)	loss 3.6319 (3.1074)	grad_norm 6.5198 (nan)	mem 8926MB
[2022-04-08 19:53:16 large] (main.py 226): INFO Train: [208/300][1500/2502]	eta 0:08:41 lr 0.000110	time 0.5290 (0.5206)	loss 3.4604 (3.1075)	grad_norm 4.8898 (nan)	mem 8926MB
[2022-04-08 19:54:08 large] (main.py 226): INFO Train: [208/300][1600/2502]	eta 0:07:49 lr 0.000110	time 0.5112 (0.5203)	loss 3.6939 (3.1092)	grad_norm 5.7731 (nan)	mem 8926MB
[2022-04-08 19:55:00 large] (main.py 226): INFO Train: [208/300][1700/2502]	eta 0:06:57 lr 0.000110	time 0.5112 (0.5201)	loss 3.5919 (3.1099)	grad_norm 5.7118 (nan)	mem 8926MB
[2022-04-08 19:55:51 large] (main.py 226): INFO Train: [208/300][1800/2502]	eta 0:06:04 lr 0.000110	time 0.4952 (0.5198)	loss 3.8733 (3.1136)	grad_norm 4.9097 (nan)	mem 8926MB
[2022-04-08 19:56:41 large] (main.py 226): INFO Train: [208/300][1900/2502]	eta 0:05:12 lr 0.000110	time 0.4890 (0.5188)	loss 3.4202 (3.1119)	grad_norm 4.2337 (nan)	mem 8926MB
[2022-04-08 19:57:31 large] (main.py 226): INFO Train: [208/300][2000/2502]	eta 0:04:19 lr 0.000110	time 0.4555 (0.5179)	loss 3.2536 (3.1098)	grad_norm 4.3857 (nan)	mem 8926MB
[2022-04-08 19:58:22 large] (main.py 226): INFO Train: [208/300][2100/2502]	eta 0:03:27 lr 0.000109	time 0.5244 (0.5174)	loss 3.3812 (3.1115)	grad_norm 4.6005 (nan)	mem 8926MB
[2022-04-08 19:59:12 large] (main.py 226): INFO Train: [208/300][2200/2502]	eta 0:02:35 lr 0.000109	time 0.4846 (0.5165)	loss 3.6093 (3.1132)	grad_norm 5.7996 (nan)	mem 8926MB
[2022-04-08 20:00:04 large] (main.py 226): INFO Train: [208/300][2300/2502]	eta 0:01:44 lr 0.000109	time 0.5081 (0.5168)	loss 1.9272 (3.1152)	grad_norm 4.9673 (nan)	mem 8926MB
[2022-04-08 20:00:56 large] (main.py 226): INFO Train: [208/300][2400/2502]	eta 0:00:52 lr 0.000109	time 0.5268 (0.5169)	loss 3.6535 (3.1171)	grad_norm 7.1870 (nan)	mem 8926MB
[2022-04-08 20:01:48 large] (main.py 226): INFO Train: [208/300][2500/2502]	eta 0:00:01 lr 0.000109	time 0.5050 (0.5169)	loss 3.2650 (3.1150)	grad_norm 5.6420 (nan)	mem 8926MB
[2022-04-08 20:01:49 large] (main.py 233): INFO EPOCH 208 training takes 0:21:33
[2022-04-08 20:01:55 large] (main.py 273): INFO Test: [0/98]	Time 5.806 (5.806)	Loss 1.0181 (1.0181)	Acc@1 78.906 (78.906)	Acc@5 94.727 (94.727)	Mem 8926MB
[2022-04-08 20:02:21 large] (main.py 279): INFO  * Acc@1 79.630 Acc@5 94.788
[2022-04-08 20:02:21 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 79.6%
[2022-04-08 20:02:21 large] (main.py 148): INFO Max accuracy: 79.90%
[2022-04-08 20:02:28 large] (main.py 226): INFO Train: [209/300][0/2502]	eta 4:50:30 lr 0.000109	time 6.9666 (6.9666)	loss 3.7200 (3.7200)	grad_norm 6.4539 (6.4539)	mem 8926MB
[2022-04-08 20:03:19 large] (main.py 226): INFO Train: [209/300][100/2502]	eta 0:22:38 lr 0.000109	time 0.4699 (0.5658)	loss 2.2145 (3.1341)	grad_norm 5.4214 (nan)	mem 8926MB
[2022-04-08 20:04:08 large] (main.py 226): INFO Train: [209/300][200/2502]	eta 0:20:26 lr 0.000109	time 0.5559 (0.5327)	loss 1.9385 (3.0986)	grad_norm 5.0107 (nan)	mem 8926MB
[2022-04-08 20:05:01 large] (main.py 226): INFO Train: [209/300][300/2502]	eta 0:19:25 lr 0.000109	time 0.4575 (0.5293)	loss 3.5620 (3.0998)	grad_norm 6.6947 (nan)	mem 8926MB
[2022-04-08 20:05:53 large] (main.py 226): INFO Train: [209/300][400/2502]	eta 0:18:31 lr 0.000109	time 0.5266 (0.5288)	loss 3.5504 (3.1008)	grad_norm 6.7474 (nan)	mem 8926MB
[2022-04-08 20:06:46 large] (main.py 226): INFO Train: [209/300][500/2502]	eta 0:17:36 lr 0.000109	time 0.4839 (0.5278)	loss 3.5793 (3.1018)	grad_norm 5.3449 (nan)	mem 8926MB
[2022-04-08 20:07:35 large] (main.py 226): INFO Train: [209/300][600/2502]	eta 0:16:32 lr 0.000109	time 0.5190 (0.5220)	loss 2.5768 (3.0998)	grad_norm 4.6321 (nan)	mem 8926MB
[2022-04-08 20:08:26 large] (main.py 226): INFO Train: [209/300][700/2502]	eta 0:15:37 lr 0.000109	time 0.5855 (0.5205)	loss 3.3003 (3.1093)	grad_norm 4.1666 (nan)	mem 8926MB
[2022-04-08 20:09:18 large] (main.py 226): INFO Train: [209/300][800/2502]	eta 0:14:45 lr 0.000108	time 0.5341 (0.5204)	loss 2.3588 (3.1105)	grad_norm 5.6623 (nan)	mem 8926MB
[2022-04-08 20:10:10 large] (main.py 226): INFO Train: [209/300][900/2502]	eta 0:13:53 lr 0.000108	time 0.5066 (0.5206)	loss 2.7100 (3.1032)	grad_norm 4.7800 (nan)	mem 8926MB
[2022-04-08 20:11:02 large] (main.py 226): INFO Train: [209/300][1000/2502]	eta 0:13:01 lr 0.000108	time 0.4891 (0.5205)	loss 3.5613 (3.0963)	grad_norm 5.5226 (nan)	mem 8926MB
[2022-04-08 20:11:52 large] (main.py 226): INFO Train: [209/300][1100/2502]	eta 0:12:06 lr 0.000108	time 0.4648 (0.5183)	loss 2.3386 (3.0913)	grad_norm 5.9406 (nan)	mem 8926MB
[2022-04-08 20:12:40 large] (main.py 226): INFO Train: [209/300][1200/2502]	eta 0:11:11 lr 0.000108	time 0.4832 (0.5154)	loss 2.1954 (3.0888)	grad_norm 5.8113 (nan)	mem 8926MB
[2022-04-08 20:13:29 large] (main.py 226): INFO Train: [209/300][1300/2502]	eta 0:10:17 lr 0.000108	time 0.5048 (0.5134)	loss 2.9985 (3.0902)	grad_norm 7.7836 (nan)	mem 8926MB
[2022-04-08 20:14:21 large] (main.py 226): INFO Train: [209/300][1400/2502]	eta 0:09:26 lr 0.000108	time 0.5525 (0.5139)	loss 1.9070 (3.0915)	grad_norm 5.0314 (nan)	mem 8926MB
[2022-04-08 20:15:12 large] (main.py 226): INFO Train: [209/300][1500/2502]	eta 0:08:34 lr 0.000108	time 0.4989 (0.5132)	loss 2.9767 (3.0848)	grad_norm 6.4564 (nan)	mem 8926MB
[2022-04-08 20:16:04 large] (main.py 226): INFO Train: [209/300][1600/2502]	eta 0:07:43 lr 0.000108	time 0.5257 (0.5136)	loss 3.7053 (3.0857)	grad_norm 6.6645 (nan)	mem 8926MB
[2022-04-08 20:16:55 large] (main.py 226): INFO Train: [209/300][1700/2502]	eta 0:06:52 lr 0.000108	time 0.4736 (0.5137)	loss 3.1625 (3.0844)	grad_norm 4.9463 (nan)	mem 8926MB
[2022-04-08 20:17:45 large] (main.py 226): INFO Train: [209/300][1800/2502]	eta 0:05:59 lr 0.000108	time 0.5354 (0.5126)	loss 3.0673 (3.0849)	grad_norm 5.9095 (nan)	mem 8926MB
[2022-04-08 20:18:35 large] (main.py 226): INFO Train: [209/300][1900/2502]	eta 0:05:08 lr 0.000108	time 0.4994 (0.5121)	loss 3.0323 (3.0890)	grad_norm 6.7390 (nan)	mem 8926MB
[2022-04-08 20:19:27 large] (main.py 226): INFO Train: [209/300][2000/2502]	eta 0:04:17 lr 0.000107	time 0.5619 (0.5127)	loss 3.0601 (3.0913)	grad_norm 5.3413 (nan)	mem 8926MB
[2022-04-08 20:20:19 large] (main.py 226): INFO Train: [209/300][2100/2502]	eta 0:03:26 lr 0.000107	time 0.4848 (0.5130)	loss 2.3512 (3.0888)	grad_norm 6.2252 (nan)	mem 8926MB
[2022-04-08 20:21:08 large] (main.py 226): INFO Train: [209/300][2200/2502]	eta 0:02:34 lr 0.000107	time 0.5018 (0.5120)	loss 3.1023 (3.0927)	grad_norm 7.3142 (nan)	mem 8926MB
[2022-04-08 20:21:58 large] (main.py 226): INFO Train: [209/300][2300/2502]	eta 0:01:43 lr 0.000107	time 0.5221 (0.5112)	loss 2.7493 (3.0946)	grad_norm 5.6938 (nan)	mem 8926MB
[2022-04-08 20:22:49 large] (main.py 226): INFO Train: [209/300][2400/2502]	eta 0:00:52 lr 0.000107	time 0.5380 (0.5115)	loss 2.3598 (3.0937)	grad_norm 4.3288 (nan)	mem 8926MB
[2022-04-08 20:23:39 large] (main.py 226): INFO Train: [209/300][2500/2502]	eta 0:00:01 lr 0.000107	time 0.5040 (0.5110)	loss 2.4169 (3.0930)	grad_norm 4.8503 (nan)	mem 8926MB
[2022-04-08 20:23:40 large] (main.py 233): INFO EPOCH 209 training takes 0:21:18
[2022-04-08 20:23:47 large] (main.py 273): INFO Test: [0/98]	Time 6.753 (6.753)	Loss 1.1030 (1.1030)	Acc@1 80.469 (80.469)	Acc@5 93.164 (93.164)	Mem 8926MB
[2022-04-08 20:24:12 large] (main.py 279): INFO  * Acc@1 79.764 Acc@5 94.984
[2022-04-08 20:24:12 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 79.8%
[2022-04-08 20:24:12 large] (main.py 148): INFO Max accuracy: 79.90%
[2022-04-08 20:24:20 large] (main.py 226): INFO Train: [210/300][0/2502]	eta 5:08:44 lr 0.000107	time 7.4037 (7.4037)	loss 3.3236 (3.3236)	grad_norm 8.7131 (8.7131)	mem 8926MB
[2022-04-08 20:25:10 large] (main.py 226): INFO Train: [210/300][100/2502]	eta 0:22:35 lr 0.000107	time 0.4655 (0.5645)	loss 2.4866 (3.0640)	grad_norm 5.5789 (5.8733)	mem 8926MB
[2022-04-08 20:25:59 large] (main.py 226): INFO Train: [210/300][200/2502]	eta 0:20:23 lr 0.000107	time 0.5150 (0.5316)	loss 2.7746 (3.0855)	grad_norm 4.3514 (5.8286)	mem 8926MB
[2022-04-08 20:26:52 large] (main.py 226): INFO Train: [210/300][300/2502]	eta 0:19:26 lr 0.000107	time 0.5111 (0.5299)	loss 3.7400 (3.0758)	grad_norm 6.6774 (5.8227)	mem 8926MB
[2022-04-08 20:27:44 large] (main.py 226): INFO Train: [210/300][400/2502]	eta 0:18:30 lr 0.000107	time 0.5054 (0.5283)	loss 3.4957 (3.0744)	grad_norm 5.8096 (5.8004)	mem 8926MB
[2022-04-08 20:28:37 large] (main.py 226): INFO Train: [210/300][500/2502]	eta 0:17:36 lr 0.000107	time 0.5215 (0.5278)	loss 3.0283 (3.0775)	grad_norm 5.4808 (5.7691)	mem 8926MB
[2022-04-08 20:29:29 large] (main.py 226): INFO Train: [210/300][600/2502]	eta 0:16:40 lr 0.000107	time 0.5407 (0.5260)	loss 3.3375 (3.0697)	grad_norm 4.8910 (nan)	mem 8926MB
[2022-04-08 20:30:18 large] (main.py 226): INFO Train: [210/300][700/2502]	eta 0:15:38 lr 0.000106	time 0.4854 (0.5210)	loss 2.7218 (3.0708)	grad_norm 5.6747 (nan)	mem 8926MB
[2022-04-08 20:31:07 large] (main.py 226): INFO Train: [210/300][800/2502]	eta 0:14:40 lr 0.000106	time 0.4969 (0.5174)	loss 3.5394 (3.0741)	grad_norm 5.1796 (nan)	mem 8926MB
[2022-04-08 20:31:57 large] (main.py 226): INFO Train: [210/300][900/2502]	eta 0:13:45 lr 0.000106	time 0.4765 (0.5152)	loss 3.5786 (3.0846)	grad_norm 9.6500 (nan)	mem 8926MB
[2022-04-08 20:32:45 large] (main.py 226): INFO Train: [210/300][1000/2502]	eta 0:12:48 lr 0.000106	time 0.4977 (0.5119)	loss 3.6895 (3.0870)	grad_norm 6.2807 (nan)	mem 8926MB
[2022-04-08 20:33:36 large] (main.py 226): INFO Train: [210/300][1100/2502]	eta 0:11:57 lr 0.000106	time 0.5245 (0.5116)	loss 4.0552 (3.0951)	grad_norm 8.3718 (nan)	mem 8926MB
[2022-04-08 20:34:28 large] (main.py 226): INFO Train: [210/300][1200/2502]	eta 0:11:07 lr 0.000106	time 0.4484 (0.5127)	loss 2.7858 (3.0937)	grad_norm 6.7184 (nan)	mem 8926MB
[2022-04-08 20:35:19 large] (main.py 226): INFO Train: [210/300][1300/2502]	eta 0:10:15 lr 0.000106	time 0.5211 (0.5120)	loss 3.5650 (3.0901)	grad_norm 6.0048 (nan)	mem 8926MB
[2022-04-08 20:36:10 large] (main.py 226): INFO Train: [210/300][1400/2502]	eta 0:09:24 lr 0.000106	time 0.4777 (0.5124)	loss 2.4575 (3.0904)	grad_norm 6.3481 (nan)	mem 8926MB
[2022-04-08 20:36:59 large] (main.py 226): INFO Train: [210/300][1500/2502]	eta 0:08:31 lr 0.000106	time 0.4919 (0.5110)	loss 1.8001 (3.0844)	grad_norm 6.6627 (nan)	mem 8926MB
[2022-04-08 20:37:51 large] (main.py 226): INFO Train: [210/300][1600/2502]	eta 0:07:41 lr 0.000106	time 0.5138 (0.5112)	loss 2.7342 (3.0804)	grad_norm 5.4179 (nan)	mem 8926MB
[2022-04-08 20:38:43 large] (main.py 226): INFO Train: [210/300][1700/2502]	eta 0:06:50 lr 0.000106	time 0.5124 (0.5117)	loss 2.0770 (3.0773)	grad_norm 5.1391 (nan)	mem 8926MB
[2022-04-08 20:39:34 large] (main.py 226): INFO Train: [210/300][1800/2502]	eta 0:05:59 lr 0.000106	time 0.4385 (0.5116)	loss 2.1119 (3.0792)	grad_norm 4.5472 (nan)	mem 8926MB
[2022-04-08 20:40:25 large] (main.py 226): INFO Train: [210/300][1900/2502]	eta 0:05:07 lr 0.000105	time 0.5128 (0.5115)	loss 3.3998 (3.0815)	grad_norm 7.2061 (nan)	mem 8926MB
[2022-04-08 20:41:17 large] (main.py 226): INFO Train: [210/300][2000/2502]	eta 0:04:16 lr 0.000105	time 0.4869 (0.5117)	loss 2.8613 (3.0830)	grad_norm 5.4178 (nan)	mem 8926MB
[2022-04-08 20:42:06 large] (main.py 226): INFO Train: [210/300][2100/2502]	eta 0:03:25 lr 0.000105	time 0.5280 (0.5111)	loss 2.9176 (3.0879)	grad_norm 7.7055 (nan)	mem 8926MB
[2022-04-08 20:42:58 large] (main.py 226): INFO Train: [210/300][2200/2502]	eta 0:02:34 lr 0.000105	time 0.5624 (0.5114)	loss 3.2440 (3.0874)	grad_norm 5.9153 (nan)	mem 8926MB
[2022-04-08 20:43:50 large] (main.py 226): INFO Train: [210/300][2300/2502]	eta 0:01:43 lr 0.000105	time 0.5104 (0.5118)	loss 3.5199 (3.0872)	grad_norm 9.1050 (nan)	mem 8926MB
[2022-04-08 20:44:42 large] (main.py 226): INFO Train: [210/300][2400/2502]	eta 0:00:52 lr 0.000105	time 0.5631 (0.5120)	loss 3.5743 (3.0881)	grad_norm 7.2491 (nan)	mem 8926MB
[2022-04-08 20:45:33 large] (main.py 226): INFO Train: [210/300][2500/2502]	eta 0:00:01 lr 0.000105	time 0.4992 (0.5120)	loss 3.2922 (3.0838)	grad_norm 5.2709 (nan)	mem 8926MB
[2022-04-08 20:45:34 large] (main.py 233): INFO EPOCH 210 training takes 0:21:21
[2022-04-08 20:45:41 large] (main.py 273): INFO Test: [0/98]	Time 6.343 (6.343)	Loss 1.1064 (1.1064)	Acc@1 77.734 (77.734)	Acc@5 93.945 (93.945)	Mem 8926MB
[2022-04-08 20:46:06 large] (main.py 279): INFO  * Acc@1 79.582 Acc@5 94.842
[2022-04-08 20:46:06 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 79.6%
[2022-04-08 20:46:06 large] (main.py 148): INFO Max accuracy: 79.90%
[2022-04-08 20:46:13 large] (main.py 226): INFO Train: [211/300][0/2502]	eta 5:05:47 lr 0.000105	time 7.3333 (7.3333)	loss 3.1547 (3.1547)	grad_norm 4.9385 (4.9385)	mem 8926MB
[2022-04-08 20:47:04 large] (main.py 226): INFO Train: [211/300][100/2502]	eta 0:22:49 lr 0.000105	time 0.4722 (0.5704)	loss 2.2724 (3.0693)	grad_norm 4.9281 (6.0449)	mem 8926MB
[2022-04-08 20:47:54 large] (main.py 226): INFO Train: [211/300][200/2502]	eta 0:20:41 lr 0.000105	time 0.5075 (0.5392)	loss 3.8560 (3.0844)	grad_norm 9.3079 (5.8563)	mem 8926MB
[2022-04-08 20:48:43 large] (main.py 226): INFO Train: [211/300][300/2502]	eta 0:19:09 lr 0.000105	time 0.4630 (0.5222)	loss 3.3694 (3.0603)	grad_norm 4.9871 (5.8404)	mem 8926MB
[2022-04-08 20:49:34 large] (main.py 226): INFO Train: [211/300][400/2502]	eta 0:18:11 lr 0.000105	time 0.4901 (0.5190)	loss 3.5437 (3.0720)	grad_norm 5.4152 (nan)	mem 8926MB
[2022-04-08 20:50:23 large] (main.py 226): INFO Train: [211/300][500/2502]	eta 0:17:07 lr 0.000105	time 0.4981 (0.5132)	loss 2.1602 (3.0670)	grad_norm 5.1074 (nan)	mem 8926MB
[2022-04-08 20:51:16 large] (main.py 226): INFO Train: [211/300][600/2502]	eta 0:16:19 lr 0.000104	time 0.5537 (0.5151)	loss 3.3789 (3.0531)	grad_norm 8.8294 (nan)	mem 8926MB
[2022-04-08 20:52:08 large] (main.py 226): INFO Train: [211/300][700/2502]	eta 0:15:30 lr 0.000104	time 0.4913 (0.5164)	loss 3.6676 (3.0672)	grad_norm 6.4860 (nan)	mem 8926MB
[2022-04-08 20:52:59 large] (main.py 226): INFO Train: [211/300][800/2502]	eta 0:14:38 lr 0.000104	time 0.4836 (0.5160)	loss 3.6587 (3.0737)	grad_norm 6.8191 (nan)	mem 8926MB
[2022-04-08 20:53:49 large] (main.py 226): INFO Train: [211/300][900/2502]	eta 0:13:43 lr 0.000104	time 0.5538 (0.5138)	loss 3.5038 (3.0818)	grad_norm 5.2966 (nan)	mem 8926MB
[2022-04-08 20:54:40 large] (main.py 226): INFO Train: [211/300][1000/2502]	eta 0:12:51 lr 0.000104	time 0.4829 (0.5137)	loss 2.8376 (3.0760)	grad_norm 7.0315 (nan)	mem 8926MB
[2022-04-08 20:55:29 large] (main.py 226): INFO Train: [211/300][1100/2502]	eta 0:11:57 lr 0.000104	time 0.4940 (0.5117)	loss 3.6800 (3.0849)	grad_norm 13.6668 (nan)	mem 8926MB
[2022-04-08 20:56:18 large] (main.py 226): INFO Train: [211/300][1200/2502]	eta 0:11:03 lr 0.000104	time 0.5348 (0.5099)	loss 2.4098 (3.0785)	grad_norm 6.1537 (nan)	mem 8926MB
[2022-04-08 20:57:09 large] (main.py 226): INFO Train: [211/300][1300/2502]	eta 0:10:12 lr 0.000104	time 0.5128 (0.5097)	loss 3.6449 (3.0719)	grad_norm 5.7714 (nan)	mem 8926MB
[2022-04-08 20:58:01 large] (main.py 226): INFO Train: [211/300][1400/2502]	eta 0:09:22 lr 0.000104	time 0.5035 (0.5104)	loss 3.5439 (3.0705)	grad_norm 4.4894 (nan)	mem 8926MB
[2022-04-08 20:58:53 large] (main.py 226): INFO Train: [211/300][1500/2502]	eta 0:08:32 lr 0.000104	time 0.4764 (0.5111)	loss 3.5992 (3.0706)	grad_norm 6.7460 (nan)	mem 8926MB
[2022-04-08 20:59:46 large] (main.py 226): INFO Train: [211/300][1600/2502]	eta 0:07:41 lr 0.000104	time 0.4495 (0.5120)	loss 2.9298 (3.0719)	grad_norm 5.8771 (nan)	mem 8926MB
[2022-04-08 21:00:36 large] (main.py 226): INFO Train: [211/300][1700/2502]	eta 0:06:50 lr 0.000104	time 0.5202 (0.5115)	loss 3.0247 (3.0704)	grad_norm 6.5409 (nan)	mem 8926MB
[2022-04-08 21:01:27 large] (main.py 226): INFO Train: [211/300][1800/2502]	eta 0:05:59 lr 0.000103	time 0.4878 (0.5115)	loss 2.9608 (3.0639)	grad_norm 4.7189 (nan)	mem 8926MB
[2022-04-08 21:02:19 large] (main.py 226): INFO Train: [211/300][1900/2502]	eta 0:05:08 lr 0.000103	time 0.4961 (0.5119)	loss 2.3846 (3.0632)	grad_norm 4.4149 (nan)	mem 8926MB
[2022-04-08 21:03:11 large] (main.py 226): INFO Train: [211/300][2000/2502]	eta 0:04:17 lr 0.000103	time 0.4918 (0.5120)	loss 3.2394 (3.0649)	grad_norm 4.1346 (nan)	mem 8926MB
[2022-04-08 21:04:02 large] (main.py 226): INFO Train: [211/300][2100/2502]	eta 0:03:25 lr 0.000103	time 0.5282 (0.5122)	loss 3.0848 (3.0662)	grad_norm 3.9005 (nan)	mem 8926MB
[2022-04-08 21:04:54 large] (main.py 226): INFO Train: [211/300][2200/2502]	eta 0:02:34 lr 0.000103	time 0.5228 (0.5125)	loss 2.9899 (3.0688)	grad_norm 5.2706 (nan)	mem 8926MB
[2022-04-08 21:05:45 large] (main.py 226): INFO Train: [211/300][2300/2502]	eta 0:01:43 lr 0.000103	time 0.5626 (0.5125)	loss 1.9568 (3.0664)	grad_norm 4.9444 (nan)	mem 8926MB
[2022-04-08 21:06:37 large] (main.py 226): INFO Train: [211/300][2400/2502]	eta 0:00:52 lr 0.000103	time 0.5051 (0.5129)	loss 3.9489 (3.0662)	grad_norm 5.6389 (nan)	mem 8926MB
[2022-04-08 21:07:28 large] (main.py 226): INFO Train: [211/300][2500/2502]	eta 0:00:01 lr 0.000103	time 0.5021 (0.5127)	loss 2.0155 (3.0655)	grad_norm 5.1265 (nan)	mem 8926MB
[2022-04-08 21:07:29 large] (main.py 233): INFO EPOCH 211 training takes 0:21:23
[2022-04-08 21:07:36 large] (main.py 273): INFO Test: [0/98]	Time 6.823 (6.823)	Loss 1.0838 (1.0838)	Acc@1 78.711 (78.711)	Acc@5 94.336 (94.336)	Mem 8926MB
[2022-04-08 21:08:02 large] (main.py 279): INFO  * Acc@1 79.940 Acc@5 95.026
[2022-04-08 21:08:02 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 79.9%
[2022-04-08 21:08:02 large] (utils.py 57): INFO output/large/default/ckpt_epoch_211.pth saving......
[2022-04-08 21:08:02 large] (utils.py 59): INFO output/large/default/ckpt_epoch_211.pth saved !!!
[2022-04-08 21:08:02 large] (main.py 148): INFO Max accuracy: 79.94%
[2022-04-08 21:08:10 large] (main.py 226): INFO Train: [212/300][0/2502]	eta 5:38:04 lr 0.000103	time 8.1071 (8.1071)	loss 3.0192 (3.0192)	grad_norm 5.0387 (5.0387)	mem 8926MB
[2022-04-08 21:09:00 large] (main.py 226): INFO Train: [212/300][100/2502]	eta 0:22:56 lr 0.000103	time 0.5052 (0.5732)	loss 3.0357 (3.0542)	grad_norm 8.3026 (5.8925)	mem 8926MB
[2022-04-08 21:09:52 large] (main.py 226): INFO Train: [212/300][200/2502]	eta 0:20:56 lr 0.000103	time 0.5013 (0.5459)	loss 1.9721 (3.0538)	grad_norm 4.1128 (6.0254)	mem 8926MB
[2022-04-08 21:10:44 large] (main.py 226): INFO Train: [212/300][300/2502]	eta 0:19:40 lr 0.000103	time 0.4888 (0.5360)	loss 3.7184 (3.0254)	grad_norm 6.1022 (5.8628)	mem 8926MB
[2022-04-08 21:11:36 large] (main.py 226): INFO Train: [212/300][400/2502]	eta 0:18:39 lr 0.000103	time 0.5366 (0.5324)	loss 3.0369 (3.0496)	grad_norm 5.5724 (5.9651)	mem 8926MB
[2022-04-08 21:12:28 large] (main.py 226): INFO Train: [212/300][500/2502]	eta 0:17:40 lr 0.000102	time 0.4815 (0.5298)	loss 2.6380 (3.0567)	grad_norm 6.2673 (6.0049)	mem 8926MB
[2022-04-08 21:13:20 large] (main.py 226): INFO Train: [212/300][600/2502]	eta 0:16:44 lr 0.000102	time 0.5173 (0.5279)	loss 2.4435 (3.0679)	grad_norm 4.7886 (5.9872)	mem 8926MB
[2022-04-08 21:14:12 large] (main.py 226): INFO Train: [212/300][700/2502]	eta 0:15:49 lr 0.000102	time 0.5027 (0.5267)	loss 3.4102 (3.0585)	grad_norm 5.7184 (5.9573)	mem 8926MB
[2022-04-08 21:15:03 large] (main.py 226): INFO Train: [212/300][800/2502]	eta 0:14:54 lr 0.000102	time 0.5100 (0.5254)	loss 3.5201 (3.0566)	grad_norm 7.2970 (6.0047)	mem 8926MB
[2022-04-08 21:15:55 large] (main.py 226): INFO Train: [212/300][900/2502]	eta 0:14:00 lr 0.000102	time 0.4815 (0.5245)	loss 3.4452 (3.0643)	grad_norm 6.3832 (5.9954)	mem 8926MB
[2022-04-08 21:16:44 large] (main.py 226): INFO Train: [212/300][1000/2502]	eta 0:13:02 lr 0.000102	time 0.5095 (0.5209)	loss 3.2005 (3.0663)	grad_norm 5.0423 (6.0021)	mem 8926MB
[2022-04-08 21:17:33 large] (main.py 226): INFO Train: [212/300][1100/2502]	eta 0:12:06 lr 0.000102	time 0.4859 (0.5183)	loss 3.3976 (3.0695)	grad_norm 5.8733 (5.9923)	mem 8926MB
[2022-04-08 21:18:22 large] (main.py 226): INFO Train: [212/300][1200/2502]	eta 0:11:12 lr 0.000102	time 0.5278 (0.5161)	loss 2.5527 (3.0705)	grad_norm 5.8445 (5.9897)	mem 8926MB
[2022-04-08 21:19:14 large] (main.py 226): INFO Train: [212/300][1300/2502]	eta 0:10:20 lr 0.000102	time 0.4772 (0.5162)	loss 3.9477 (3.0763)	grad_norm 7.4992 (nan)	mem 8926MB
[2022-04-08 21:20:03 large] (main.py 226): INFO Train: [212/300][1400/2502]	eta 0:09:27 lr 0.000102	time 0.4935 (0.5147)	loss 2.8566 (3.0772)	grad_norm 5.4045 (nan)	mem 8926MB
[2022-04-08 21:20:54 large] (main.py 226): INFO Train: [212/300][1500/2502]	eta 0:08:35 lr 0.000102	time 0.5629 (0.5142)	loss 2.9781 (3.0783)	grad_norm 4.8934 (nan)	mem 8926MB
[2022-04-08 21:21:46 large] (main.py 226): INFO Train: [212/300][1600/2502]	eta 0:07:44 lr 0.000102	time 0.5030 (0.5146)	loss 2.8561 (3.0805)	grad_norm 6.2638 (nan)	mem 8926MB
[2022-04-08 21:22:38 large] (main.py 226): INFO Train: [212/300][1700/2502]	eta 0:06:52 lr 0.000101	time 0.5225 (0.5148)	loss 2.8434 (3.0813)	grad_norm 8.8351 (nan)	mem 8926MB
[2022-04-08 21:23:30 large] (main.py 226): INFO Train: [212/300][1800/2502]	eta 0:06:01 lr 0.000101	time 0.5563 (0.5149)	loss 1.9943 (3.0846)	grad_norm 6.9857 (nan)	mem 8926MB
[2022-04-08 21:24:21 large] (main.py 226): INFO Train: [212/300][1900/2502]	eta 0:05:09 lr 0.000101	time 0.4845 (0.5146)	loss 3.4513 (3.0910)	grad_norm 5.9753 (nan)	mem 8926MB
[2022-04-08 21:25:09 large] (main.py 226): INFO Train: [212/300][2000/2502]	eta 0:04:17 lr 0.000101	time 0.4903 (0.5131)	loss 3.6127 (3.0892)	grad_norm 5.0733 (nan)	mem 8926MB
[2022-04-08 21:26:00 large] (main.py 226): INFO Train: [212/300][2100/2502]	eta 0:03:26 lr 0.000101	time 0.4855 (0.5129)	loss 2.2199 (3.0909)	grad_norm 5.7284 (nan)	mem 8926MB
[2022-04-08 21:26:50 large] (main.py 226): INFO Train: [212/300][2200/2502]	eta 0:02:34 lr 0.000101	time 0.4817 (0.5124)	loss 3.5305 (3.0902)	grad_norm 4.2117 (nan)	mem 8926MB
[2022-04-08 21:27:40 large] (main.py 226): INFO Train: [212/300][2300/2502]	eta 0:01:43 lr 0.000101	time 0.5190 (0.5120)	loss 3.6010 (3.0938)	grad_norm 6.0833 (nan)	mem 8926MB
[2022-04-08 21:28:33 large] (main.py 226): INFO Train: [212/300][2400/2502]	eta 0:00:52 lr 0.000101	time 0.5366 (0.5125)	loss 2.5260 (3.0907)	grad_norm 6.2050 (nan)	mem 8926MB
[2022-04-08 21:29:22 large] (main.py 226): INFO Train: [212/300][2500/2502]	eta 0:00:01 lr 0.000101	time 0.5051 (0.5118)	loss 3.5445 (3.0885)	grad_norm 8.9784 (nan)	mem 8926MB
[2022-04-08 21:29:23 large] (main.py 233): INFO EPOCH 212 training takes 0:21:20
[2022-04-08 21:29:29 large] (main.py 273): INFO Test: [0/98]	Time 5.684 (5.684)	Loss 1.0305 (1.0305)	Acc@1 78.906 (78.906)	Acc@5 95.703 (95.703)	Mem 8926MB
[2022-04-08 21:29:56 large] (main.py 279): INFO  * Acc@1 80.022 Acc@5 94.972
[2022-04-08 21:29:56 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 80.0%
[2022-04-08 21:29:56 large] (utils.py 57): INFO output/large/default/ckpt_epoch_212.pth saving......
[2022-04-08 21:29:56 large] (utils.py 59): INFO output/large/default/ckpt_epoch_212.pth saved !!!
[2022-04-08 21:29:56 large] (main.py 148): INFO Max accuracy: 80.02%
[2022-04-08 21:30:04 large] (main.py 226): INFO Train: [213/300][0/2502]	eta 5:18:47 lr 0.000101	time 7.6449 (7.6449)	loss 3.1991 (3.1991)	grad_norm 4.3277 (4.3277)	mem 8926MB
[2022-04-08 21:30:55 large] (main.py 226): INFO Train: [213/300][100/2502]	eta 0:23:13 lr 0.000101	time 0.5352 (0.5803)	loss 3.3689 (3.1093)	grad_norm 5.9443 (6.5197)	mem 8926MB
[2022-04-08 21:31:47 large] (main.py 226): INFO Train: [213/300][200/2502]	eta 0:21:01 lr 0.000101	time 0.5060 (0.5481)	loss 2.3740 (3.0969)	grad_norm 5.2414 (nan)	mem 8926MB
[2022-04-08 21:32:39 large] (main.py 226): INFO Train: [213/300][300/2502]	eta 0:19:47 lr 0.000101	time 0.5047 (0.5393)	loss 2.7180 (3.0601)	grad_norm 5.7632 (nan)	mem 8926MB
[2022-04-08 21:33:31 large] (main.py 226): INFO Train: [213/300][400/2502]	eta 0:18:46 lr 0.000100	time 0.5220 (0.5358)	loss 2.4168 (3.0495)	grad_norm 7.1989 (nan)	mem 8926MB
[2022-04-08 21:34:24 large] (main.py 226): INFO Train: [213/300][500/2502]	eta 0:17:47 lr 0.000100	time 0.5142 (0.5331)	loss 2.8631 (3.0608)	grad_norm 5.6531 (nan)	mem 8926MB
[2022-04-08 21:35:16 large] (main.py 226): INFO Train: [213/300][600/2502]	eta 0:16:50 lr 0.000100	time 0.4979 (0.5311)	loss 3.2885 (3.0573)	grad_norm 5.6321 (nan)	mem 8926MB
[2022-04-08 21:36:05 large] (main.py 226): INFO Train: [213/300][700/2502]	eta 0:15:46 lr 0.000100	time 0.4797 (0.5252)	loss 3.9081 (3.0695)	grad_norm 5.6086 (nan)	mem 8926MB
[2022-04-08 21:36:54 large] (main.py 226): INFO Train: [213/300][800/2502]	eta 0:14:46 lr 0.000100	time 0.4812 (0.5212)	loss 3.2178 (3.0747)	grad_norm 4.9170 (nan)	mem 8926MB
[2022-04-08 21:37:45 large] (main.py 226): INFO Train: [213/300][900/2502]	eta 0:13:52 lr 0.000100	time 0.5648 (0.5198)	loss 3.3200 (3.0768)	grad_norm 5.9952 (nan)	mem 8926MB
[2022-04-08 21:38:35 large] (main.py 226): INFO Train: [213/300][1000/2502]	eta 0:12:57 lr 0.000100	time 0.5844 (0.5176)	loss 3.3844 (3.0715)	grad_norm 6.1947 (nan)	mem 8926MB
[2022-04-08 21:39:25 large] (main.py 226): INFO Train: [213/300][1100/2502]	eta 0:12:03 lr 0.000100	time 0.5462 (0.5164)	loss 2.8594 (3.0729)	grad_norm 5.5113 (nan)	mem 8926MB
[2022-04-08 21:40:15 large] (main.py 226): INFO Train: [213/300][1200/2502]	eta 0:11:10 lr 0.000100	time 0.4956 (0.5151)	loss 3.5193 (3.0659)	grad_norm 5.6727 (nan)	mem 8926MB
[2022-04-08 21:41:07 large] (main.py 226): INFO Train: [213/300][1300/2502]	eta 0:10:19 lr 0.000100	time 0.5083 (0.5153)	loss 2.7016 (3.0624)	grad_norm 5.4115 (nan)	mem 8926MB
[2022-04-08 21:41:57 large] (main.py 226): INFO Train: [213/300][1400/2502]	eta 0:09:26 lr 0.000100	time 0.4990 (0.5142)	loss 2.8972 (3.0698)	grad_norm 4.8146 (nan)	mem 8926MB
[2022-04-08 21:42:46 large] (main.py 226): INFO Train: [213/300][1500/2502]	eta 0:08:33 lr 0.000100	time 0.4512 (0.5129)	loss 3.3490 (3.0723)	grad_norm 5.3701 (nan)	mem 8926MB
[2022-04-08 21:43:37 large] (main.py 226): INFO Train: [213/300][1600/2502]	eta 0:07:42 lr 0.000099	time 0.5020 (0.5124)	loss 3.0102 (3.0771)	grad_norm 6.1299 (nan)	mem 8926MB
[2022-04-08 21:44:28 large] (main.py 226): INFO Train: [213/300][1700/2502]	eta 0:06:51 lr 0.000099	time 0.5262 (0.5126)	loss 3.4487 (3.0800)	grad_norm 7.0518 (nan)	mem 8926MB
[2022-04-08 21:45:18 large] (main.py 226): INFO Train: [213/300][1800/2502]	eta 0:05:59 lr 0.000099	time 0.4929 (0.5119)	loss 3.0664 (3.0800)	grad_norm 6.0036 (nan)	mem 8926MB
[2022-04-08 21:46:07 large] (main.py 226): INFO Train: [213/300][1900/2502]	eta 0:05:07 lr 0.000099	time 0.5068 (0.5108)	loss 2.9975 (3.0795)	grad_norm 5.2810 (nan)	mem 8926MB
[2022-04-08 21:46:59 large] (main.py 226): INFO Train: [213/300][2000/2502]	eta 0:04:16 lr 0.000099	time 0.5147 (0.5112)	loss 3.1968 (3.0822)	grad_norm 4.5707 (nan)	mem 8926MB
[2022-04-08 21:47:51 large] (main.py 226): INFO Train: [213/300][2100/2502]	eta 0:03:25 lr 0.000099	time 0.5097 (0.5115)	loss 3.5799 (3.0826)	grad_norm 5.8905 (nan)	mem 8926MB
[2022-04-08 21:48:43 large] (main.py 226): INFO Train: [213/300][2200/2502]	eta 0:02:34 lr 0.000099	time 0.5261 (0.5117)	loss 3.2714 (3.0817)	grad_norm 5.2898 (nan)	mem 8926MB
[2022-04-08 21:49:35 large] (main.py 226): INFO Train: [213/300][2300/2502]	eta 0:01:43 lr 0.000099	time 0.5088 (0.5120)	loss 3.3098 (3.0836)	grad_norm 5.1581 (nan)	mem 8926MB
[2022-04-08 21:50:26 large] (main.py 226): INFO Train: [213/300][2400/2502]	eta 0:00:52 lr 0.000099	time 0.4999 (0.5123)	loss 2.4796 (3.0814)	grad_norm 4.8567 (nan)	mem 8926MB
[2022-04-08 21:51:18 large] (main.py 226): INFO Train: [213/300][2500/2502]	eta 0:00:01 lr 0.000099	time 0.5031 (0.5122)	loss 2.7812 (3.0789)	grad_norm 5.5241 (nan)	mem 8926MB
[2022-04-08 21:51:19 large] (main.py 233): INFO EPOCH 213 training takes 0:21:22
[2022-04-08 21:51:24 large] (main.py 273): INFO Test: [0/98]	Time 5.948 (5.948)	Loss 0.9104 (0.9104)	Acc@1 82.617 (82.617)	Acc@5 96.289 (96.289)	Mem 8926MB
[2022-04-08 21:51:51 large] (main.py 279): INFO  * Acc@1 79.878 Acc@5 94.990
[2022-04-08 21:51:51 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 79.9%
[2022-04-08 21:51:51 large] (main.py 148): INFO Max accuracy: 80.02%
[2022-04-08 21:51:58 large] (main.py 226): INFO Train: [214/300][0/2502]	eta 4:54:10 lr 0.000099	time 7.0547 (7.0547)	loss 3.6703 (3.6703)	grad_norm 5.5300 (5.5300)	mem 8926MB
[2022-04-08 21:52:48 large] (main.py 226): INFO Train: [214/300][100/2502]	eta 0:22:51 lr 0.000099	time 0.5455 (0.5710)	loss 3.4094 (3.0803)	grad_norm 5.1259 (5.7588)	mem 8926MB
[2022-04-08 21:53:38 large] (main.py 226): INFO Train: [214/300][200/2502]	eta 0:20:27 lr 0.000099	time 0.5316 (0.5331)	loss 3.2736 (3.0321)	grad_norm 4.9393 (5.7933)	mem 8926MB
[2022-04-08 21:54:27 large] (main.py 226): INFO Train: [214/300][300/2502]	eta 0:19:04 lr 0.000099	time 0.4909 (0.5196)	loss 2.3118 (3.0321)	grad_norm 6.1023 (5.7746)	mem 8926MB
[2022-04-08 21:55:15 large] (main.py 226): INFO Train: [214/300][400/2502]	eta 0:17:52 lr 0.000098	time 0.5125 (0.5101)	loss 3.6477 (3.0332)	grad_norm 9.3018 (5.7837)	mem 8926MB
[2022-04-08 21:56:04 large] (main.py 226): INFO Train: [214/300][500/2502]	eta 0:16:52 lr 0.000098	time 0.5413 (0.5057)	loss 3.9320 (3.0457)	grad_norm 6.6617 (5.8667)	mem 8926MB
[2022-04-08 21:56:54 large] (main.py 226): INFO Train: [214/300][600/2502]	eta 0:15:59 lr 0.000098	time 0.4938 (0.5044)	loss 2.0245 (3.0310)	grad_norm 4.6485 (5.8791)	mem 8926MB
[2022-04-08 21:57:46 large] (main.py 226): INFO Train: [214/300][700/2502]	eta 0:15:14 lr 0.000098	time 0.5680 (0.5072)	loss 3.4818 (3.0327)	grad_norm 4.9485 (5.8751)	mem 8926MB
[2022-04-08 21:58:39 large] (main.py 226): INFO Train: [214/300][800/2502]	eta 0:14:28 lr 0.000098	time 0.5070 (0.5101)	loss 2.1656 (3.0439)	grad_norm 4.7416 (5.8823)	mem 8926MB
[2022-04-08 21:59:31 large] (main.py 226): INFO Train: [214/300][900/2502]	eta 0:13:38 lr 0.000098	time 0.4493 (0.5107)	loss 3.2539 (3.0483)	grad_norm 5.8796 (5.9273)	mem 8926MB
[2022-04-08 22:00:22 large] (main.py 226): INFO Train: [214/300][1000/2502]	eta 0:12:46 lr 0.000098	time 0.5347 (0.5104)	loss 1.8530 (3.0559)	grad_norm 6.4642 (5.9383)	mem 8926MB
[2022-04-08 22:01:14 large] (main.py 226): INFO Train: [214/300][1100/2502]	eta 0:11:56 lr 0.000098	time 0.5011 (0.5112)	loss 2.2259 (3.0600)	grad_norm 5.7650 (5.9572)	mem 8926MB
[2022-04-08 22:02:06 large] (main.py 226): INFO Train: [214/300][1200/2502]	eta 0:11:07 lr 0.000098	time 0.5253 (0.5124)	loss 3.5880 (3.0633)	grad_norm 7.4249 (5.9546)	mem 8926MB
[2022-04-08 22:02:56 large] (main.py 226): INFO Train: [214/300][1300/2502]	eta 0:10:14 lr 0.000098	time 0.4848 (0.5111)	loss 3.2010 (3.0648)	grad_norm 5.0125 (5.9520)	mem 8926MB
[2022-04-08 22:03:45 large] (main.py 226): INFO Train: [214/300][1400/2502]	eta 0:09:21 lr 0.000098	time 0.5290 (0.5096)	loss 2.5577 (3.0631)	grad_norm 4.0128 (5.9946)	mem 8926MB
[2022-04-08 22:04:34 large] (main.py 226): INFO Train: [214/300][1500/2502]	eta 0:08:29 lr 0.000098	time 0.5277 (0.5087)	loss 3.6819 (3.0642)	grad_norm 5.4465 (5.9919)	mem 8926MB
[2022-04-08 22:05:26 large] (main.py 226): INFO Train: [214/300][1600/2502]	eta 0:07:39 lr 0.000097	time 0.5351 (0.5093)	loss 3.6411 (3.0641)	grad_norm 7.6678 (5.9882)	mem 8926MB
[2022-04-08 22:06:18 large] (main.py 226): INFO Train: [214/300][1700/2502]	eta 0:06:48 lr 0.000097	time 0.4994 (0.5100)	loss 2.4338 (3.0675)	grad_norm 5.9412 (5.9838)	mem 8926MB
[2022-04-08 22:07:10 large] (main.py 226): INFO Train: [214/300][1800/2502]	eta 0:05:58 lr 0.000097	time 0.5061 (0.5104)	loss 3.3151 (3.0685)	grad_norm 5.5820 (nan)	mem 8926MB
[2022-04-08 22:07:59 large] (main.py 226): INFO Train: [214/300][1900/2502]	eta 0:05:06 lr 0.000097	time 0.5975 (0.5093)	loss 2.4439 (3.0734)	grad_norm 5.3038 (nan)	mem 8926MB
[2022-04-08 22:08:47 large] (main.py 226): INFO Train: [214/300][2000/2502]	eta 0:04:14 lr 0.000097	time 0.5027 (0.5079)	loss 2.8279 (3.0742)	grad_norm 6.4811 (nan)	mem 8926MB
[2022-04-08 22:09:36 large] (main.py 226): INFO Train: [214/300][2100/2502]	eta 0:03:23 lr 0.000097	time 0.4803 (0.5072)	loss 2.2685 (3.0733)	grad_norm 5.3178 (nan)	mem 8926MB
[2022-04-08 22:10:28 large] (main.py 226): INFO Train: [214/300][2200/2502]	eta 0:02:33 lr 0.000097	time 0.5338 (0.5075)	loss 3.3764 (3.0699)	grad_norm 5.7641 (nan)	mem 8926MB
[2022-04-08 22:11:19 large] (main.py 226): INFO Train: [214/300][2300/2502]	eta 0:01:42 lr 0.000097	time 0.4797 (0.5079)	loss 2.7395 (3.0714)	grad_norm 5.5865 (nan)	mem 8926MB
[2022-04-08 22:12:09 large] (main.py 226): INFO Train: [214/300][2400/2502]	eta 0:00:51 lr 0.000097	time 0.4744 (0.5074)	loss 3.3123 (3.0730)	grad_norm 4.8564 (nan)	mem 8926MB
[2022-04-08 22:12:57 large] (main.py 226): INFO Train: [214/300][2500/2502]	eta 0:00:01 lr 0.000097	time 0.4602 (0.5064)	loss 3.0476 (3.0715)	grad_norm 7.9002 (nan)	mem 8926MB
[2022-04-08 22:12:58 large] (main.py 233): INFO EPOCH 214 training takes 0:21:07
[2022-04-08 22:13:05 large] (main.py 273): INFO Test: [0/98]	Time 6.861 (6.861)	Loss 0.9487 (0.9487)	Acc@1 83.008 (83.008)	Acc@5 96.289 (96.289)	Mem 8926MB
[2022-04-08 22:13:30 large] (main.py 279): INFO  * Acc@1 80.014 Acc@5 94.908
[2022-04-08 22:13:30 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 80.0%
[2022-04-08 22:13:30 large] (main.py 148): INFO Max accuracy: 80.02%
[2022-04-08 22:13:38 large] (main.py 226): INFO Train: [215/300][0/2502]	eta 5:11:41 lr 0.000097	time 7.4746 (7.4746)	loss 2.3098 (2.3098)	grad_norm 7.2277 (7.2277)	mem 8926MB
[2022-04-08 22:14:28 large] (main.py 226): INFO Train: [215/300][100/2502]	eta 0:22:54 lr 0.000097	time 0.5216 (0.5724)	loss 3.2300 (3.0413)	grad_norm 5.1521 (5.6233)	mem 8926MB
[2022-04-08 22:15:21 large] (main.py 226): INFO Train: [215/300][200/2502]	eta 0:21:00 lr 0.000097	time 0.4952 (0.5477)	loss 3.1783 (3.0817)	grad_norm 7.9544 (6.0096)	mem 8926MB
[2022-04-08 22:16:13 large] (main.py 226): INFO Train: [215/300][300/2502]	eta 0:19:50 lr 0.000097	time 0.5960 (0.5408)	loss 2.5938 (3.0854)	grad_norm 6.6072 (6.0397)	mem 8926MB
[2022-04-08 22:17:04 large] (main.py 226): INFO Train: [215/300][400/2502]	eta 0:18:39 lr 0.000096	time 0.5059 (0.5327)	loss 3.1470 (3.0635)	grad_norm 4.1739 (5.9802)	mem 8926MB
[2022-04-08 22:17:56 large] (main.py 226): INFO Train: [215/300][500/2502]	eta 0:17:40 lr 0.000096	time 0.4940 (0.5297)	loss 3.3348 (3.0548)	grad_norm 7.3569 (nan)	mem 8926MB
[2022-04-08 22:18:48 large] (main.py 226): INFO Train: [215/300][600/2502]	eta 0:16:45 lr 0.000096	time 0.4995 (0.5287)	loss 2.4894 (3.0504)	grad_norm 4.6501 (nan)	mem 8926MB
[2022-04-08 22:19:40 large] (main.py 226): INFO Train: [215/300][700/2502]	eta 0:15:51 lr 0.000096	time 0.5819 (0.5278)	loss 2.1041 (3.0557)	grad_norm 3.8261 (nan)	mem 8926MB
[2022-04-08 22:20:32 large] (main.py 226): INFO Train: [215/300][800/2502]	eta 0:14:55 lr 0.000096	time 0.4699 (0.5262)	loss 3.3006 (3.0566)	grad_norm 14.5156 (nan)	mem 8926MB
[2022-04-08 22:21:21 large] (main.py 226): INFO Train: [215/300][900/2502]	eta 0:13:56 lr 0.000096	time 0.4967 (0.5221)	loss 3.3512 (3.0477)	grad_norm 4.8979 (nan)	mem 8926MB
[2022-04-08 22:22:11 large] (main.py 226): INFO Train: [215/300][1000/2502]	eta 0:13:00 lr 0.000096	time 0.5005 (0.5197)	loss 2.1751 (3.0514)	grad_norm 5.9893 (nan)	mem 8926MB
[2022-04-08 22:23:01 large] (main.py 226): INFO Train: [215/300][1100/2502]	eta 0:12:06 lr 0.000096	time 0.4875 (0.5179)	loss 2.1703 (3.0520)	grad_norm 6.4409 (nan)	mem 8926MB
[2022-04-08 22:23:50 large] (main.py 226): INFO Train: [215/300][1200/2502]	eta 0:11:11 lr 0.000096	time 0.5291 (0.5157)	loss 3.6231 (3.0512)	grad_norm 6.4220 (nan)	mem 8926MB
[2022-04-08 22:24:41 large] (main.py 226): INFO Train: [215/300][1300/2502]	eta 0:10:19 lr 0.000096	time 0.5173 (0.5151)	loss 1.9745 (3.0565)	grad_norm 16.0647 (nan)	mem 8926MB
[2022-04-08 22:25:32 large] (main.py 226): INFO Train: [215/300][1400/2502]	eta 0:09:27 lr 0.000096	time 0.4939 (0.5154)	loss 3.3082 (3.0591)	grad_norm 8.6333 (nan)	mem 8926MB
[2022-04-08 22:26:22 large] (main.py 226): INFO Train: [215/300][1500/2502]	eta 0:08:34 lr 0.000096	time 0.5004 (0.5139)	loss 1.9196 (3.0606)	grad_norm 16.9489 (nan)	mem 8926MB
[2022-04-08 22:27:11 large] (main.py 226): INFO Train: [215/300][1600/2502]	eta 0:07:42 lr 0.000095	time 0.4973 (0.5125)	loss 2.8980 (3.0598)	grad_norm 4.7394 (nan)	mem 8926MB
[2022-04-08 22:28:03 large] (main.py 226): INFO Train: [215/300][1700/2502]	eta 0:06:51 lr 0.000095	time 0.5239 (0.5128)	loss 3.3225 (3.0637)	grad_norm 4.9965 (nan)	mem 8926MB
[2022-04-08 22:28:55 large] (main.py 226): INFO Train: [215/300][1800/2502]	eta 0:06:00 lr 0.000095	time 0.5604 (0.5131)	loss 3.1312 (3.0620)	grad_norm 6.3550 (nan)	mem 8926MB
[2022-04-08 22:29:44 large] (main.py 226): INFO Train: [215/300][1900/2502]	eta 0:05:08 lr 0.000095	time 0.4823 (0.5119)	loss 3.0791 (3.0676)	grad_norm 5.9230 (nan)	mem 8926MB
[2022-04-08 22:30:32 large] (main.py 226): INFO Train: [215/300][2000/2502]	eta 0:04:16 lr 0.000095	time 0.4752 (0.5105)	loss 2.8200 (3.0674)	grad_norm 6.5806 (nan)	mem 8926MB
[2022-04-08 22:31:21 large] (main.py 226): INFO Train: [215/300][2100/2502]	eta 0:03:24 lr 0.000095	time 0.5218 (0.5093)	loss 2.3042 (3.0678)	grad_norm 6.6584 (nan)	mem 8926MB
[2022-04-08 22:32:12 large] (main.py 226): INFO Train: [215/300][2200/2502]	eta 0:02:33 lr 0.000095	time 0.5110 (0.5097)	loss 3.5293 (3.0662)	grad_norm 5.3806 (nan)	mem 8926MB
[2022-04-08 22:33:05 large] (main.py 226): INFO Train: [215/300][2300/2502]	eta 0:01:43 lr 0.000095	time 0.4476 (0.5103)	loss 3.5284 (3.0661)	grad_norm 5.3070 (nan)	mem 8926MB
[2022-04-08 22:33:57 large] (main.py 226): INFO Train: [215/300][2400/2502]	eta 0:00:52 lr 0.000095	time 0.5070 (0.5108)	loss 3.1251 (3.0620)	grad_norm 5.7960 (nan)	mem 8926MB
[2022-04-08 22:34:49 large] (main.py 226): INFO Train: [215/300][2500/2502]	eta 0:00:01 lr 0.000095	time 0.4957 (0.5110)	loss 3.5813 (3.0649)	grad_norm 4.9787 (nan)	mem 8926MB
[2022-04-08 22:34:50 large] (main.py 233): INFO EPOCH 215 training takes 0:21:19
[2022-04-08 22:34:56 large] (main.py 273): INFO Test: [0/98]	Time 6.290 (6.290)	Loss 0.9654 (0.9654)	Acc@1 81.250 (81.250)	Acc@5 95.898 (95.898)	Mem 8926MB
[2022-04-08 22:35:22 large] (main.py 279): INFO  * Acc@1 79.976 Acc@5 94.978
[2022-04-08 22:35:22 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 80.0%
[2022-04-08 22:35:22 large] (main.py 148): INFO Max accuracy: 80.02%
[2022-04-08 22:35:28 large] (main.py 226): INFO Train: [216/300][0/2502]	eta 4:14:06 lr 0.000095	time 6.0937 (6.0937)	loss 1.8877 (1.8877)	grad_norm 5.0758 (5.0758)	mem 8926MB
[2022-04-08 22:36:19 large] (main.py 226): INFO Train: [216/300][100/2502]	eta 0:22:43 lr 0.000095	time 0.4987 (0.5676)	loss 3.2503 (3.0477)	grad_norm 5.3106 (5.9054)	mem 8926MB
[2022-04-08 22:37:11 large] (main.py 226): INFO Train: [216/300][200/2502]	eta 0:20:49 lr 0.000095	time 0.5169 (0.5428)	loss 2.0319 (3.0827)	grad_norm 5.2127 (5.9319)	mem 8926MB
[2022-04-08 22:38:03 large] (main.py 226): INFO Train: [216/300][300/2502]	eta 0:19:42 lr 0.000094	time 0.5583 (0.5369)	loss 3.2155 (3.0779)	grad_norm 6.0442 (5.9522)	mem 8926MB
[2022-04-08 22:38:54 large] (main.py 226): INFO Train: [216/300][400/2502]	eta 0:18:32 lr 0.000094	time 0.4917 (0.5292)	loss 1.8469 (3.0711)	grad_norm 4.7382 (5.9779)	mem 8926MB
[2022-04-08 22:39:44 large] (main.py 226): INFO Train: [216/300][500/2502]	eta 0:17:26 lr 0.000094	time 0.5090 (0.5226)	loss 3.3291 (3.0629)	grad_norm 5.4195 (nan)	mem 8926MB
[2022-04-08 22:40:36 large] (main.py 226): INFO Train: [216/300][600/2502]	eta 0:16:33 lr 0.000094	time 0.5148 (0.5224)	loss 3.8808 (3.0556)	grad_norm 5.8074 (nan)	mem 8926MB
[2022-04-08 22:41:28 large] (main.py 226): INFO Train: [216/300][700/2502]	eta 0:15:42 lr 0.000094	time 0.4635 (0.5229)	loss 3.6296 (3.0662)	grad_norm 6.9927 (nan)	mem 8926MB
[2022-04-08 22:42:20 large] (main.py 226): INFO Train: [216/300][800/2502]	eta 0:14:48 lr 0.000094	time 0.4881 (0.5222)	loss 2.4294 (3.0629)	grad_norm 5.1893 (nan)	mem 8926MB
[2022-04-08 22:43:12 large] (main.py 226): INFO Train: [216/300][900/2502]	eta 0:13:56 lr 0.000094	time 0.5157 (0.5219)	loss 3.0822 (3.0657)	grad_norm 4.1804 (nan)	mem 8926MB
[2022-04-08 22:44:04 large] (main.py 226): INFO Train: [216/300][1000/2502]	eta 0:13:03 lr 0.000094	time 0.5326 (0.5213)	loss 2.5519 (3.0681)	grad_norm 6.5456 (nan)	mem 8926MB
[2022-04-08 22:44:55 large] (main.py 226): INFO Train: [216/300][1100/2502]	eta 0:12:10 lr 0.000094	time 0.5285 (0.5208)	loss 3.3732 (3.0641)	grad_norm 5.8601 (nan)	mem 8926MB
[2022-04-08 22:45:46 large] (main.py 226): INFO Train: [216/300][1200/2502]	eta 0:11:16 lr 0.000094	time 0.5040 (0.5198)	loss 3.6976 (3.0529)	grad_norm 6.6207 (nan)	mem 8926MB
[2022-04-08 22:46:35 large] (main.py 226): INFO Train: [216/300][1300/2502]	eta 0:10:22 lr 0.000094	time 0.4810 (0.5178)	loss 3.8567 (3.0548)	grad_norm 5.3628 (nan)	mem 8926MB
[2022-04-08 22:47:26 large] (main.py 226): INFO Train: [216/300][1400/2502]	eta 0:09:29 lr 0.000094	time 0.5110 (0.5166)	loss 2.9348 (3.0593)	grad_norm 5.4907 (nan)	mem 8926MB
[2022-04-08 22:48:17 large] (main.py 226): INFO Train: [216/300][1500/2502]	eta 0:08:37 lr 0.000094	time 0.5426 (0.5166)	loss 2.6321 (3.0586)	grad_norm 6.2744 (nan)	mem 8926MB
[2022-04-08 22:49:09 large] (main.py 226): INFO Train: [216/300][1600/2502]	eta 0:07:45 lr 0.000093	time 0.5210 (0.5164)	loss 2.6410 (3.0547)	grad_norm 8.4892 (nan)	mem 8926MB
[2022-04-08 22:50:00 large] (main.py 226): INFO Train: [216/300][1700/2502]	eta 0:06:54 lr 0.000093	time 0.5204 (0.5164)	loss 3.4549 (3.0524)	grad_norm 5.7860 (nan)	mem 8926MB
[2022-04-08 22:50:52 large] (main.py 226): INFO Train: [216/300][1800/2502]	eta 0:06:02 lr 0.000093	time 0.5305 (0.5165)	loss 2.5266 (3.0512)	grad_norm 4.8200 (nan)	mem 8926MB
[2022-04-08 22:51:43 large] (main.py 226): INFO Train: [216/300][1900/2502]	eta 0:05:10 lr 0.000093	time 0.4917 (0.5164)	loss 3.7339 (3.0537)	grad_norm 6.2401 (nan)	mem 8926MB
[2022-04-08 22:52:32 large] (main.py 226): INFO Train: [216/300][2000/2502]	eta 0:04:18 lr 0.000093	time 0.4907 (0.5149)	loss 3.4316 (3.0518)	grad_norm 7.4684 (nan)	mem 8926MB
[2022-04-08 22:53:22 large] (main.py 226): INFO Train: [216/300][2100/2502]	eta 0:03:26 lr 0.000093	time 0.4968 (0.5143)	loss 2.9385 (3.0481)	grad_norm 6.5949 (nan)	mem 8926MB
[2022-04-08 22:54:14 large] (main.py 226): INFO Train: [216/300][2200/2502]	eta 0:02:35 lr 0.000093	time 0.4851 (0.5145)	loss 3.5784 (3.0515)	grad_norm 9.4964 (nan)	mem 8926MB
[2022-04-08 22:55:06 large] (main.py 226): INFO Train: [216/300][2300/2502]	eta 0:01:43 lr 0.000093	time 0.5104 (0.5146)	loss 3.6586 (3.0491)	grad_norm 5.2748 (nan)	mem 8926MB
[2022-04-08 22:55:58 large] (main.py 226): INFO Train: [216/300][2400/2502]	eta 0:00:52 lr 0.000093	time 0.5359 (0.5147)	loss 2.9403 (3.0493)	grad_norm 5.2382 (nan)	mem 8926MB
[2022-04-08 22:56:48 large] (main.py 226): INFO Train: [216/300][2500/2502]	eta 0:00:01 lr 0.000093	time 0.4749 (0.5141)	loss 3.3711 (3.0495)	grad_norm 8.9361 (nan)	mem 8926MB
[2022-04-08 22:56:49 large] (main.py 233): INFO EPOCH 216 training takes 0:21:26
[2022-04-08 22:56:55 large] (main.py 273): INFO Test: [0/98]	Time 6.705 (6.705)	Loss 0.9455 (0.9455)	Acc@1 82.227 (82.227)	Acc@5 95.508 (95.508)	Mem 8926MB
[2022-04-08 22:57:21 large] (main.py 279): INFO  * Acc@1 80.340 Acc@5 95.060
[2022-04-08 22:57:21 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 80.3%
[2022-04-08 22:57:21 large] (utils.py 57): INFO output/large/default/ckpt_epoch_216.pth saving......
[2022-04-08 22:57:22 large] (utils.py 59): INFO output/large/default/ckpt_epoch_216.pth saved !!!
[2022-04-08 22:57:22 large] (main.py 148): INFO Max accuracy: 80.34%
[2022-04-08 22:57:29 large] (main.py 226): INFO Train: [217/300][0/2502]	eta 5:05:06 lr 0.000093	time 7.3168 (7.3168)	loss 2.7798 (2.7798)	grad_norm 5.9918 (5.9918)	mem 8926MB
[2022-04-08 22:58:19 large] (main.py 226): INFO Train: [217/300][100/2502]	eta 0:22:43 lr 0.000093	time 0.4787 (0.5678)	loss 2.0137 (3.0549)	grad_norm 4.5942 (6.5094)	mem 8926MB
[2022-04-08 22:59:10 large] (main.py 226): INFO Train: [217/300][200/2502]	eta 0:20:31 lr 0.000093	time 0.5220 (0.5352)	loss 3.2636 (3.0504)	grad_norm 8.3490 (6.5534)	mem 8926MB
[2022-04-08 23:00:02 large] (main.py 226): INFO Train: [217/300][300/2502]	eta 0:19:28 lr 0.000093	time 0.5055 (0.5308)	loss 1.9049 (3.0213)	grad_norm 4.6110 (6.5078)	mem 8926MB
[2022-04-08 23:00:52 large] (main.py 226): INFO Train: [217/300][400/2502]	eta 0:18:20 lr 0.000092	time 0.5419 (0.5236)	loss 1.8386 (3.0405)	grad_norm 17.5609 (nan)	mem 8926MB
[2022-04-08 23:01:44 large] (main.py 226): INFO Train: [217/300][500/2502]	eta 0:17:25 lr 0.000092	time 0.5197 (0.5222)	loss 3.1104 (3.0517)	grad_norm 8.0433 (nan)	mem 8926MB
[2022-04-08 23:02:34 large] (main.py 226): INFO Train: [217/300][600/2502]	eta 0:16:26 lr 0.000092	time 0.5618 (0.5187)	loss 3.1247 (3.0424)	grad_norm 5.4602 (nan)	mem 8926MB
[2022-04-08 23:03:24 large] (main.py 226): INFO Train: [217/300][700/2502]	eta 0:15:30 lr 0.000092	time 0.4913 (0.5165)	loss 2.4045 (3.0517)	grad_norm 6.0180 (nan)	mem 8926MB
[2022-04-08 23:04:14 large] (main.py 226): INFO Train: [217/300][800/2502]	eta 0:14:34 lr 0.000092	time 0.5052 (0.5136)	loss 3.5663 (3.0553)	grad_norm 6.4774 (nan)	mem 8926MB
[2022-04-08 23:05:03 large] (main.py 226): INFO Train: [217/300][900/2502]	eta 0:13:40 lr 0.000092	time 0.4463 (0.5120)	loss 3.4501 (3.0602)	grad_norm 7.7629 (nan)	mem 8926MB
[2022-04-08 23:05:53 large] (main.py 226): INFO Train: [217/300][1000/2502]	eta 0:12:47 lr 0.000092	time 0.5045 (0.5107)	loss 2.4162 (3.0612)	grad_norm 5.2132 (nan)	mem 8926MB
[2022-04-08 23:06:45 large] (main.py 226): INFO Train: [217/300][1100/2502]	eta 0:11:57 lr 0.000092	time 0.4996 (0.5115)	loss 2.2226 (3.0590)	grad_norm 4.3559 (nan)	mem 8926MB
[2022-04-08 23:07:37 large] (main.py 226): INFO Train: [217/300][1200/2502]	eta 0:11:06 lr 0.000092	time 0.4953 (0.5117)	loss 3.2212 (3.0573)	grad_norm 5.5058 (nan)	mem 8926MB
[2022-04-08 23:08:28 large] (main.py 226): INFO Train: [217/300][1300/2502]	eta 0:10:14 lr 0.000092	time 0.5066 (0.5116)	loss 2.7975 (3.0590)	grad_norm 7.7631 (nan)	mem 8926MB
[2022-04-08 23:09:17 large] (main.py 226): INFO Train: [217/300][1400/2502]	eta 0:09:22 lr 0.000092	time 0.5051 (0.5102)	loss 3.7495 (3.0572)	grad_norm 6.8064 (nan)	mem 8926MB
[2022-04-08 23:10:09 large] (main.py 226): INFO Train: [217/300][1500/2502]	eta 0:08:31 lr 0.000092	time 0.4952 (0.5107)	loss 2.4657 (3.0555)	grad_norm 4.7724 (nan)	mem 8926MB
[2022-04-08 23:11:01 large] (main.py 226): INFO Train: [217/300][1600/2502]	eta 0:07:41 lr 0.000091	time 0.5019 (0.5113)	loss 1.9206 (3.0577)	grad_norm 5.9392 (nan)	mem 8926MB
[2022-04-08 23:11:51 large] (main.py 226): INFO Train: [217/300][1700/2502]	eta 0:06:49 lr 0.000091	time 0.5181 (0.5105)	loss 3.1867 (3.0578)	grad_norm 6.3914 (nan)	mem 8926MB
[2022-04-08 23:12:42 large] (main.py 226): INFO Train: [217/300][1800/2502]	eta 0:05:58 lr 0.000091	time 0.5304 (0.5106)	loss 3.1061 (3.0539)	grad_norm 9.7039 (nan)	mem 8926MB
[2022-04-08 23:13:34 large] (main.py 226): INFO Train: [217/300][1900/2502]	eta 0:05:07 lr 0.000091	time 0.5206 (0.5110)	loss 2.1790 (3.0565)	grad_norm 5.3174 (nan)	mem 8926MB
[2022-04-08 23:14:26 large] (main.py 226): INFO Train: [217/300][2000/2502]	eta 0:04:16 lr 0.000091	time 0.4955 (0.5116)	loss 3.1334 (3.0566)	grad_norm 6.6327 (nan)	mem 8926MB
[2022-04-08 23:15:17 large] (main.py 226): INFO Train: [217/300][2100/2502]	eta 0:03:25 lr 0.000091	time 0.5368 (0.5118)	loss 1.7161 (3.0533)	grad_norm 4.5412 (nan)	mem 8926MB
[2022-04-08 23:16:07 large] (main.py 226): INFO Train: [217/300][2200/2502]	eta 0:02:34 lr 0.000091	time 0.5064 (0.5112)	loss 2.9278 (3.0544)	grad_norm 5.5505 (nan)	mem 8926MB
[2022-04-08 23:16:57 large] (main.py 226): INFO Train: [217/300][2300/2502]	eta 0:01:43 lr 0.000091	time 0.4941 (0.5107)	loss 1.8469 (3.0540)	grad_norm 6.8338 (nan)	mem 8926MB
[2022-04-08 23:17:47 large] (main.py 226): INFO Train: [217/300][2400/2502]	eta 0:00:52 lr 0.000091	time 0.4712 (0.5100)	loss 3.4544 (3.0568)	grad_norm 4.9444 (nan)	mem 8926MB
[2022-04-08 23:18:35 large] (main.py 226): INFO Train: [217/300][2500/2502]	eta 0:00:01 lr 0.000091	time 0.5080 (0.5088)	loss 3.3982 (3.0564)	grad_norm 4.7572 (nan)	mem 8926MB
[2022-04-08 23:18:36 large] (main.py 233): INFO EPOCH 217 training takes 0:21:13
[2022-04-08 23:18:42 large] (main.py 273): INFO Test: [0/98]	Time 6.773 (6.773)	Loss 0.9120 (0.9120)	Acc@1 82.227 (82.227)	Acc@5 96.875 (96.875)	Mem 8926MB
[2022-04-08 23:19:08 large] (main.py 279): INFO  * Acc@1 80.098 Acc@5 95.084
[2022-04-08 23:19:08 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 80.1%
[2022-04-08 23:19:08 large] (main.py 148): INFO Max accuracy: 80.34%
[2022-04-08 23:19:15 large] (main.py 226): INFO Train: [218/300][0/2502]	eta 4:40:39 lr 0.000091	time 6.7305 (6.7305)	loss 3.7129 (3.7129)	grad_norm 7.2616 (7.2616)	mem 8926MB
[2022-04-08 23:20:06 large] (main.py 226): INFO Train: [218/300][100/2502]	eta 0:22:43 lr 0.000091	time 0.4860 (0.5675)	loss 3.7699 (3.1161)	grad_norm 6.5892 (nan)	mem 8926MB
[2022-04-08 23:20:54 large] (main.py 226): INFO Train: [218/300][200/2502]	eta 0:20:15 lr 0.000091	time 0.4930 (0.5279)	loss 3.2490 (3.0977)	grad_norm 5.6840 (nan)	mem 8926MB
[2022-04-08 23:21:45 large] (main.py 226): INFO Train: [218/300][300/2502]	eta 0:19:04 lr 0.000091	time 0.5076 (0.5196)	loss 3.5008 (3.1332)	grad_norm 6.2772 (nan)	mem 8926MB
[2022-04-08 23:22:38 large] (main.py 226): INFO Train: [218/300][400/2502]	eta 0:18:17 lr 0.000090	time 0.6216 (0.5222)	loss 3.4051 (3.1106)	grad_norm 5.8191 (nan)	mem 8926MB
[2022-04-08 23:23:30 large] (main.py 226): INFO Train: [218/300][500/2502]	eta 0:17:26 lr 0.000090	time 0.4913 (0.5227)	loss 3.1552 (3.0886)	grad_norm 4.7016 (nan)	mem 8926MB
[2022-04-08 23:24:22 large] (main.py 226): INFO Train: [218/300][600/2502]	eta 0:16:32 lr 0.000090	time 0.4886 (0.5219)	loss 3.6775 (3.0816)	grad_norm 7.6728 (nan)	mem 8926MB
[2022-04-08 23:25:14 large] (main.py 226): INFO Train: [218/300][700/2502]	eta 0:15:40 lr 0.000090	time 0.5344 (0.5218)	loss 2.2878 (3.0837)	grad_norm 9.5389 (nan)	mem 8926MB
[2022-04-08 23:26:06 large] (main.py 226): INFO Train: [218/300][800/2502]	eta 0:14:47 lr 0.000090	time 0.5305 (0.5215)	loss 3.5795 (3.0806)	grad_norm 6.2963 (nan)	mem 8926MB
[2022-04-08 23:26:56 large] (main.py 226): INFO Train: [218/300][900/2502]	eta 0:13:51 lr 0.000090	time 0.4596 (0.5189)	loss 3.8170 (3.0805)	grad_norm 9.4285 (nan)	mem 8926MB
[2022-04-08 23:27:46 large] (main.py 226): INFO Train: [218/300][1000/2502]	eta 0:12:56 lr 0.000090	time 0.5062 (0.5168)	loss 3.3740 (3.0718)	grad_norm 21.7602 (nan)	mem 8926MB
[2022-04-08 23:28:37 large] (main.py 226): INFO Train: [218/300][1100/2502]	eta 0:12:04 lr 0.000090	time 0.5172 (0.5166)	loss 3.0454 (3.0688)	grad_norm 5.6314 (nan)	mem 8926MB
[2022-04-08 23:29:27 large] (main.py 226): INFO Train: [218/300][1200/2502]	eta 0:11:10 lr 0.000090	time 0.5240 (0.5151)	loss 3.1560 (3.0636)	grad_norm 6.1619 (nan)	mem 8926MB
[2022-04-08 23:30:18 large] (main.py 226): INFO Train: [218/300][1300/2502]	eta 0:10:19 lr 0.000090	time 0.4651 (0.5150)	loss 2.7858 (3.0648)	grad_norm 6.3046 (nan)	mem 8926MB
[2022-04-08 23:31:10 large] (main.py 226): INFO Train: [218/300][1400/2502]	eta 0:09:27 lr 0.000090	time 0.5168 (0.5151)	loss 2.2924 (3.0603)	grad_norm 5.8270 (nan)	mem 8926MB
[2022-04-08 23:32:02 large] (main.py 226): INFO Train: [218/300][1500/2502]	eta 0:08:36 lr 0.000090	time 0.5047 (0.5151)	loss 3.2386 (3.0571)	grad_norm 6.4186 (nan)	mem 8926MB
[2022-04-08 23:32:53 large] (main.py 226): INFO Train: [218/300][1600/2502]	eta 0:07:44 lr 0.000090	time 0.5750 (0.5151)	loss 3.0934 (3.0553)	grad_norm 8.2198 (nan)	mem 8926MB
[2022-04-08 23:33:44 large] (main.py 226): INFO Train: [218/300][1700/2502]	eta 0:06:52 lr 0.000089	time 0.5078 (0.5150)	loss 3.3513 (3.0520)	grad_norm 5.5372 (nan)	mem 8926MB
[2022-04-08 23:34:36 large] (main.py 226): INFO Train: [218/300][1800/2502]	eta 0:06:01 lr 0.000089	time 0.5240 (0.5149)	loss 2.5416 (3.0539)	grad_norm 4.8602 (nan)	mem 8926MB
[2022-04-08 23:35:27 large] (main.py 226): INFO Train: [218/300][1900/2502]	eta 0:05:09 lr 0.000089	time 0.5210 (0.5149)	loss 3.5573 (3.0579)	grad_norm 5.8654 (nan)	mem 8926MB
[2022-04-08 23:36:16 large] (main.py 226): INFO Train: [218/300][2000/2502]	eta 0:04:17 lr 0.000089	time 0.4988 (0.5138)	loss 3.0322 (3.0572)	grad_norm 7.1986 (nan)	mem 8926MB
[2022-04-08 23:37:08 large] (main.py 226): INFO Train: [218/300][2100/2502]	eta 0:03:26 lr 0.000089	time 0.5107 (0.5137)	loss 3.1967 (3.0538)	grad_norm 6.2586 (nan)	mem 8926MB
[2022-04-08 23:37:59 large] (main.py 226): INFO Train: [218/300][2200/2502]	eta 0:02:35 lr 0.000089	time 0.4944 (0.5137)	loss 3.1197 (3.0532)	grad_norm 7.1047 (nan)	mem 8926MB
[2022-04-08 23:38:50 large] (main.py 226): INFO Train: [218/300][2300/2502]	eta 0:01:43 lr 0.000089	time 0.4605 (0.5135)	loss 3.4292 (3.0556)	grad_norm 5.5437 (nan)	mem 8926MB
[2022-04-08 23:39:39 large] (main.py 226): INFO Train: [218/300][2400/2502]	eta 0:00:52 lr 0.000089	time 0.4871 (0.5124)	loss 3.8242 (3.0573)	grad_norm 7.3218 (nan)	mem 8926MB
[2022-04-08 23:40:28 large] (main.py 226): INFO Train: [218/300][2500/2502]	eta 0:00:01 lr 0.000089	time 0.4914 (0.5117)	loss 3.1944 (3.0573)	grad_norm 41.2135 (nan)	mem 8926MB
[2022-04-08 23:40:29 large] (main.py 233): INFO EPOCH 218 training takes 0:21:20
[2022-04-08 23:40:36 large] (main.py 273): INFO Test: [0/98]	Time 6.980 (6.980)	Loss 1.0193 (1.0193)	Acc@1 80.078 (80.078)	Acc@5 94.336 (94.336)	Mem 8926MB
[2022-04-08 23:41:02 large] (main.py 279): INFO  * Acc@1 80.274 Acc@5 95.032
[2022-04-08 23:41:02 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 80.3%
[2022-04-08 23:41:02 large] (main.py 148): INFO Max accuracy: 80.34%
[2022-04-08 23:41:10 large] (main.py 226): INFO Train: [219/300][0/2502]	eta 5:42:58 lr 0.000089	time 8.2247 (8.2247)	loss 3.2263 (3.2263)	grad_norm 5.0090 (5.0090)	mem 8926MB
[2022-04-08 23:42:01 large] (main.py 226): INFO Train: [219/300][100/2502]	eta 0:23:26 lr 0.000089	time 0.5185 (0.5858)	loss 3.3188 (3.0026)	grad_norm 5.5469 (7.1595)	mem 8926MB
[2022-04-08 23:42:53 large] (main.py 226): INFO Train: [219/300][200/2502]	eta 0:21:13 lr 0.000089	time 0.4911 (0.5532)	loss 3.7427 (3.0122)	grad_norm 5.8785 (6.6951)	mem 8926MB
[2022-04-08 23:43:43 large] (main.py 226): INFO Train: [219/300][300/2502]	eta 0:19:37 lr 0.000089	time 0.5105 (0.5350)	loss 3.2654 (3.0153)	grad_norm 4.9691 (6.5065)	mem 8926MB
[2022-04-08 23:44:32 large] (main.py 226): INFO Train: [219/300][400/2502]	eta 0:18:24 lr 0.000089	time 0.6834 (0.5254)	loss 2.9675 (3.0020)	grad_norm 6.0143 (6.4394)	mem 8926MB
[2022-04-08 23:45:24 large] (main.py 226): INFO Train: [219/300][500/2502]	eta 0:17:27 lr 0.000088	time 0.5218 (0.5230)	loss 2.2713 (3.0175)	grad_norm 4.9772 (6.3693)	mem 8926MB
[2022-04-08 23:46:15 large] (main.py 226): INFO Train: [219/300][600/2502]	eta 0:16:32 lr 0.000088	time 0.4992 (0.5220)	loss 3.4716 (3.0200)	grad_norm 8.0232 (6.3679)	mem 8926MB
[2022-04-08 23:47:05 large] (main.py 226): INFO Train: [219/300][700/2502]	eta 0:15:33 lr 0.000088	time 0.5703 (0.5183)	loss 3.7459 (3.0138)	grad_norm 6.3893 (6.3494)	mem 8926MB
[2022-04-08 23:47:56 large] (main.py 226): INFO Train: [219/300][800/2502]	eta 0:14:41 lr 0.000088	time 0.5192 (0.5178)	loss 2.1372 (3.0119)	grad_norm 5.0732 (6.3134)	mem 8926MB
[2022-04-08 23:48:48 large] (main.py 226): INFO Train: [219/300][900/2502]	eta 0:13:49 lr 0.000088	time 0.4654 (0.5175)	loss 2.5633 (3.0203)	grad_norm 4.7769 (6.4167)	mem 8926MB
[2022-04-08 23:49:38 large] (main.py 226): INFO Train: [219/300][1000/2502]	eta 0:12:54 lr 0.000088	time 0.4786 (0.5158)	loss 3.1225 (3.0330)	grad_norm 4.6435 (6.4273)	mem 8926MB
[2022-04-08 23:50:28 large] (main.py 226): INFO Train: [219/300][1100/2502]	eta 0:12:01 lr 0.000088	time 0.4669 (0.5148)	loss 2.4397 (3.0418)	grad_norm 5.6446 (6.4334)	mem 8926MB
[2022-04-08 23:51:18 large] (main.py 226): INFO Train: [219/300][1200/2502]	eta 0:11:08 lr 0.000088	time 0.4875 (0.5133)	loss 3.3890 (3.0388)	grad_norm 6.1330 (6.4502)	mem 8926MB
[2022-04-08 23:52:07 large] (main.py 226): INFO Train: [219/300][1300/2502]	eta 0:10:14 lr 0.000088	time 0.4963 (0.5111)	loss 2.9355 (3.0347)	grad_norm 5.3882 (6.4241)	mem 8926MB
[2022-04-08 23:52:57 large] (main.py 226): INFO Train: [219/300][1400/2502]	eta 0:09:22 lr 0.000088	time 0.5035 (0.5103)	loss 3.2200 (3.0315)	grad_norm 10.2679 (6.3919)	mem 8926MB
[2022-04-08 23:53:46 large] (main.py 226): INFO Train: [219/300][1500/2502]	eta 0:08:30 lr 0.000088	time 0.4694 (0.5090)	loss 2.3598 (3.0345)	grad_norm 5.9318 (6.3920)	mem 8926MB
[2022-04-08 23:54:34 large] (main.py 226): INFO Train: [219/300][1600/2502]	eta 0:07:37 lr 0.000088	time 0.5031 (0.5077)	loss 3.2428 (3.0370)	grad_norm 5.3303 (6.3832)	mem 8926MB
[2022-04-08 23:55:26 large] (main.py 226): INFO Train: [219/300][1700/2502]	eta 0:06:47 lr 0.000088	time 0.4524 (0.5080)	loss 2.5879 (3.0341)	grad_norm 7.4823 (6.3488)	mem 8926MB
[2022-04-08 23:56:15 large] (main.py 226): INFO Train: [219/300][1800/2502]	eta 0:05:56 lr 0.000087	time 0.5098 (0.5075)	loss 2.8510 (3.0327)	grad_norm 5.1829 (6.3518)	mem 8926MB
[2022-04-08 23:57:07 large] (main.py 226): INFO Train: [219/300][1900/2502]	eta 0:05:05 lr 0.000087	time 0.5022 (0.5078)	loss 3.7934 (3.0321)	grad_norm 6.4592 (6.3574)	mem 8926MB
[2022-04-08 23:57:57 large] (main.py 226): INFO Train: [219/300][2000/2502]	eta 0:04:14 lr 0.000087	time 0.5176 (0.5075)	loss 2.7019 (3.0361)	grad_norm 6.3546 (6.3737)	mem 8926MB
[2022-04-08 23:58:49 large] (main.py 226): INFO Train: [219/300][2100/2502]	eta 0:03:24 lr 0.000087	time 0.4968 (0.5079)	loss 3.2627 (3.0392)	grad_norm 6.4008 (6.3903)	mem 8926MB
[2022-04-08 23:59:40 large] (main.py 226): INFO Train: [219/300][2200/2502]	eta 0:02:33 lr 0.000087	time 0.5126 (0.5082)	loss 3.3947 (3.0419)	grad_norm 5.7219 (6.3732)	mem 8926MB
[2022-04-09 00:00:32 large] (main.py 226): INFO Train: [219/300][2300/2502]	eta 0:01:42 lr 0.000087	time 0.4951 (0.5086)	loss 3.0109 (3.0406)	grad_norm 5.0103 (6.3635)	mem 8926MB
[2022-04-09 00:01:22 large] (main.py 226): INFO Train: [219/300][2400/2502]	eta 0:00:51 lr 0.000087	time 0.4454 (0.5083)	loss 2.3100 (3.0394)	grad_norm 4.7096 (6.3546)	mem 8926MB
[2022-04-09 00:02:12 large] (main.py 226): INFO Train: [219/300][2500/2502]	eta 0:00:01 lr 0.000087	time 0.5103 (0.5082)	loss 2.4599 (3.0384)	grad_norm 5.7459 (6.3318)	mem 8926MB
[2022-04-09 00:02:13 large] (main.py 233): INFO EPOCH 219 training takes 0:21:11
[2022-04-09 00:02:20 large] (main.py 273): INFO Test: [0/98]	Time 6.376 (6.376)	Loss 1.0391 (1.0391)	Acc@1 79.492 (79.492)	Acc@5 94.141 (94.141)	Mem 8926MB
[2022-04-09 00:02:46 large] (main.py 279): INFO  * Acc@1 79.996 Acc@5 95.044
[2022-04-09 00:02:46 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 80.0%
[2022-04-09 00:02:46 large] (main.py 148): INFO Max accuracy: 80.34%
[2022-04-09 00:02:52 large] (main.py 226): INFO Train: [220/300][0/2502]	eta 4:35:11 lr 0.000087	time 6.5992 (6.5992)	loss 3.5747 (3.5747)	grad_norm 7.3547 (7.3547)	mem 8926MB
[2022-04-09 00:03:43 large] (main.py 226): INFO Train: [220/300][100/2502]	eta 0:22:34 lr 0.000087	time 0.4981 (0.5639)	loss 3.8673 (3.1038)	grad_norm 6.6777 (6.4512)	mem 8926MB
[2022-04-09 00:04:31 large] (main.py 226): INFO Train: [220/300][200/2502]	eta 0:20:03 lr 0.000087	time 0.4606 (0.5227)	loss 3.1006 (3.0171)	grad_norm 4.9248 (6.3514)	mem 8926MB
[2022-04-09 00:05:20 large] (main.py 226): INFO Train: [220/300][300/2502]	eta 0:18:49 lr 0.000087	time 0.4838 (0.5129)	loss 3.4525 (3.0289)	grad_norm 3.9348 (6.3335)	mem 8926MB
[2022-04-09 00:06:10 large] (main.py 226): INFO Train: [220/300][400/2502]	eta 0:17:49 lr 0.000087	time 0.4754 (0.5090)	loss 2.1712 (3.0359)	grad_norm 3.9980 (6.3419)	mem 8926MB
[2022-04-09 00:07:02 large] (main.py 226): INFO Train: [220/300][500/2502]	eta 0:17:03 lr 0.000087	time 0.4951 (0.5111)	loss 3.3342 (3.0413)	grad_norm 6.2810 (6.3461)	mem 8926MB
[2022-04-09 00:07:53 large] (main.py 226): INFO Train: [220/300][600/2502]	eta 0:16:12 lr 0.000086	time 0.5322 (0.5112)	loss 3.1124 (3.0312)	grad_norm 6.2729 (6.3676)	mem 8926MB
[2022-04-09 00:08:44 large] (main.py 226): INFO Train: [220/300][700/2502]	eta 0:15:22 lr 0.000086	time 0.5015 (0.5117)	loss 3.6789 (3.0341)	grad_norm 5.2728 (6.3228)	mem 8926MB
[2022-04-09 00:09:35 large] (main.py 226): INFO Train: [220/300][800/2502]	eta 0:14:28 lr 0.000086	time 0.4966 (0.5106)	loss 3.4764 (3.0289)	grad_norm 6.0684 (6.2658)	mem 8926MB
[2022-04-09 00:10:23 large] (main.py 226): INFO Train: [220/300][900/2502]	eta 0:13:33 lr 0.000086	time 0.4849 (0.5075)	loss 2.9994 (3.0317)	grad_norm 5.4572 (6.2641)	mem 8926MB
[2022-04-09 00:11:14 large] (main.py 226): INFO Train: [220/300][1000/2502]	eta 0:12:43 lr 0.000086	time 0.5284 (0.5080)	loss 2.7032 (3.0298)	grad_norm 8.4304 (6.2539)	mem 8926MB
[2022-04-09 00:12:06 large] (main.py 226): INFO Train: [220/300][1100/2502]	eta 0:11:53 lr 0.000086	time 0.4885 (0.5091)	loss 3.2173 (3.0305)	grad_norm 7.7040 (6.2512)	mem 8926MB
[2022-04-09 00:12:59 large] (main.py 226): INFO Train: [220/300][1200/2502]	eta 0:11:04 lr 0.000086	time 0.5160 (0.5105)	loss 2.3633 (3.0239)	grad_norm 7.3771 (6.2818)	mem 8926MB
[2022-04-09 00:13:48 large] (main.py 226): INFO Train: [220/300][1300/2502]	eta 0:10:11 lr 0.000086	time 0.4979 (0.5088)	loss 2.8511 (3.0272)	grad_norm 5.1592 (6.2956)	mem 8926MB
[2022-04-09 00:14:37 large] (main.py 226): INFO Train: [220/300][1400/2502]	eta 0:09:19 lr 0.000086	time 0.4656 (0.5076)	loss 2.5700 (3.0306)	grad_norm 5.8861 (6.2856)	mem 8926MB
[2022-04-09 00:15:25 large] (main.py 226): INFO Train: [220/300][1500/2502]	eta 0:08:27 lr 0.000086	time 0.4748 (0.5062)	loss 2.9310 (3.0311)	grad_norm 4.8507 (6.3402)	mem 8926MB
[2022-04-09 00:16:17 large] (main.py 226): INFO Train: [220/300][1600/2502]	eta 0:07:37 lr 0.000086	time 0.5206 (0.5067)	loss 3.1958 (3.0335)	grad_norm 5.0041 (6.3323)	mem 8926MB
[2022-04-09 00:17:08 large] (main.py 226): INFO Train: [220/300][1700/2502]	eta 0:06:46 lr 0.000086	time 0.5463 (0.5072)	loss 1.9870 (3.0329)	grad_norm 6.2018 (6.3170)	mem 8926MB
[2022-04-09 00:18:00 large] (main.py 226): INFO Train: [220/300][1800/2502]	eta 0:05:56 lr 0.000086	time 0.5012 (0.5078)	loss 2.7834 (3.0384)	grad_norm 5.0365 (6.3252)	mem 8926MB
[2022-04-09 00:18:49 large] (main.py 226): INFO Train: [220/300][1900/2502]	eta 0:05:05 lr 0.000085	time 0.4768 (0.5068)	loss 2.4383 (3.0408)	grad_norm 5.5346 (6.3269)	mem 8926MB
[2022-04-09 00:19:38 large] (main.py 226): INFO Train: [220/300][2000/2502]	eta 0:04:14 lr 0.000085	time 0.4997 (0.5062)	loss 3.2077 (3.0434)	grad_norm 8.0878 (6.3108)	mem 8926MB
[2022-04-09 00:20:30 large] (main.py 226): INFO Train: [220/300][2100/2502]	eta 0:03:23 lr 0.000085	time 0.4967 (0.5066)	loss 3.3243 (3.0477)	grad_norm 4.9669 (6.3454)	mem 8926MB
[2022-04-09 00:21:22 large] (main.py 226): INFO Train: [220/300][2200/2502]	eta 0:02:33 lr 0.000085	time 0.4824 (0.5070)	loss 3.6016 (3.0498)	grad_norm 6.8595 (6.3434)	mem 8926MB
[2022-04-09 00:22:11 large] (main.py 226): INFO Train: [220/300][2300/2502]	eta 0:01:42 lr 0.000085	time 0.5111 (0.5065)	loss 3.6514 (3.0512)	grad_norm 6.1095 (6.3644)	mem 8926MB
[2022-04-09 00:23:00 large] (main.py 226): INFO Train: [220/300][2400/2502]	eta 0:00:51 lr 0.000085	time 0.4955 (0.5059)	loss 3.6281 (3.0522)	grad_norm 4.6435 (6.3548)	mem 8926MB
[2022-04-09 00:23:51 large] (main.py 226): INFO Train: [220/300][2500/2502]	eta 0:00:01 lr 0.000085	time 0.5042 (0.5061)	loss 2.8344 (3.0495)	grad_norm 7.1946 (6.3423)	mem 8926MB
[2022-04-09 00:23:53 large] (main.py 233): INFO EPOCH 220 training takes 0:21:06
[2022-04-09 00:23:59 large] (main.py 273): INFO Test: [0/98]	Time 6.290 (6.290)	Loss 0.9686 (0.9686)	Acc@1 79.688 (79.688)	Acc@5 95.312 (95.312)	Mem 8926MB
[2022-04-09 00:24:25 large] (main.py 279): INFO  * Acc@1 80.342 Acc@5 95.014
[2022-04-09 00:24:25 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 80.3%
[2022-04-09 00:24:25 large] (utils.py 57): INFO output/large/default/ckpt_epoch_220.pth saving......
[2022-04-09 00:24:26 large] (utils.py 59): INFO output/large/default/ckpt_epoch_220.pth saved !!!
[2022-04-09 00:24:26 large] (main.py 148): INFO Max accuracy: 80.34%
[2022-04-09 00:24:33 large] (main.py 226): INFO Train: [221/300][0/2502]	eta 5:24:21 lr 0.000085	time 7.7784 (7.7784)	loss 3.0564 (3.0564)	grad_norm 5.4502 (5.4502)	mem 8926MB
[2022-04-09 00:25:22 large] (main.py 226): INFO Train: [221/300][100/2502]	eta 0:22:15 lr 0.000085	time 0.4779 (0.5560)	loss 3.3428 (2.9414)	grad_norm 8.2897 (6.5810)	mem 8926MB
[2022-04-09 00:26:12 large] (main.py 226): INFO Train: [221/300][200/2502]	eta 0:20:22 lr 0.000085	time 0.5582 (0.5308)	loss 2.4522 (3.0174)	grad_norm 6.8177 (6.4731)	mem 8926MB
[2022-04-09 00:27:03 large] (main.py 226): INFO Train: [221/300][300/2502]	eta 0:19:10 lr 0.000085	time 0.4817 (0.5223)	loss 2.6854 (3.0322)	grad_norm 7.3006 (6.4864)	mem 8926MB
[2022-04-09 00:27:53 large] (main.py 226): INFO Train: [221/300][400/2502]	eta 0:18:05 lr 0.000085	time 0.5412 (0.5163)	loss 2.9332 (3.0461)	grad_norm 5.5035 (6.4607)	mem 8926MB
[2022-04-09 00:28:41 large] (main.py 226): INFO Train: [221/300][500/2502]	eta 0:17:02 lr 0.000085	time 0.4474 (0.5108)	loss 1.9892 (3.0556)	grad_norm 6.9338 (6.4297)	mem 8926MB
[2022-04-09 00:29:33 large] (main.py 226): INFO Train: [221/300][600/2502]	eta 0:16:12 lr 0.000085	time 0.5378 (0.5111)	loss 3.1811 (3.0516)	grad_norm 5.2402 (6.3838)	mem 8926MB
[2022-04-09 00:30:25 large] (main.py 226): INFO Train: [221/300][700/2502]	eta 0:15:23 lr 0.000084	time 0.5203 (0.5124)	loss 2.8854 (3.0523)	grad_norm 6.8803 (6.4125)	mem 8926MB
[2022-04-09 00:31:17 large] (main.py 226): INFO Train: [221/300][800/2502]	eta 0:14:33 lr 0.000084	time 0.5010 (0.5133)	loss 3.1317 (3.0494)	grad_norm 4.7752 (nan)	mem 8926MB
[2022-04-09 00:32:08 large] (main.py 226): INFO Train: [221/300][900/2502]	eta 0:13:42 lr 0.000084	time 0.5455 (0.5137)	loss 3.4537 (3.0459)	grad_norm 7.1801 (nan)	mem 8926MB
[2022-04-09 00:33:00 large] (main.py 226): INFO Train: [221/300][1000/2502]	eta 0:12:52 lr 0.000084	time 0.4940 (0.5144)	loss 3.5111 (3.0411)	grad_norm 7.0195 (nan)	mem 8926MB
[2022-04-09 00:33:52 large] (main.py 226): INFO Train: [221/300][1100/2502]	eta 0:12:01 lr 0.000084	time 0.5066 (0.5144)	loss 3.0929 (3.0391)	grad_norm 5.5530 (nan)	mem 8926MB
[2022-04-09 00:34:43 large] (main.py 226): INFO Train: [221/300][1200/2502]	eta 0:11:09 lr 0.000084	time 0.4897 (0.5142)	loss 2.7551 (3.0384)	grad_norm 10.5456 (nan)	mem 8926MB
[2022-04-09 00:35:32 large] (main.py 226): INFO Train: [221/300][1300/2502]	eta 0:10:15 lr 0.000084	time 0.5268 (0.5124)	loss 2.8932 (3.0418)	grad_norm 5.6811 (nan)	mem 8926MB
[2022-04-09 00:36:21 large] (main.py 226): INFO Train: [221/300][1400/2502]	eta 0:09:22 lr 0.000084	time 0.5471 (0.5108)	loss 2.3760 (3.0460)	grad_norm 5.6624 (nan)	mem 8926MB
[2022-04-09 00:37:12 large] (main.py 226): INFO Train: [221/300][1500/2502]	eta 0:08:31 lr 0.000084	time 0.5233 (0.5108)	loss 3.0780 (3.0438)	grad_norm 6.1625 (nan)	mem 8926MB
[2022-04-09 00:38:01 large] (main.py 226): INFO Train: [221/300][1600/2502]	eta 0:07:39 lr 0.000084	time 0.5009 (0.5095)	loss 3.3950 (3.0493)	grad_norm 5.6042 (nan)	mem 8926MB
[2022-04-09 00:38:52 large] (main.py 226): INFO Train: [221/300][1700/2502]	eta 0:06:48 lr 0.000084	time 0.5926 (0.5093)	loss 3.6449 (3.0503)	grad_norm 6.8067 (nan)	mem 8926MB
[2022-04-09 00:39:40 large] (main.py 226): INFO Train: [221/300][1800/2502]	eta 0:05:56 lr 0.000084	time 0.4903 (0.5079)	loss 3.1610 (3.0482)	grad_norm 8.4461 (nan)	mem 8926MB
[2022-04-09 00:40:29 large] (main.py 226): INFO Train: [221/300][1900/2502]	eta 0:05:05 lr 0.000084	time 0.4893 (0.5067)	loss 3.3972 (3.0509)	grad_norm 5.1419 (nan)	mem 8926MB
[2022-04-09 00:41:20 large] (main.py 226): INFO Train: [221/300][2000/2502]	eta 0:04:14 lr 0.000083	time 0.5514 (0.5069)	loss 3.6053 (3.0522)	grad_norm 7.2010 (nan)	mem 8926MB
[2022-04-09 00:42:10 large] (main.py 226): INFO Train: [221/300][2100/2502]	eta 0:03:23 lr 0.000083	time 0.5068 (0.5065)	loss 3.2913 (3.0518)	grad_norm 5.0678 (nan)	mem 8926MB
[2022-04-09 00:43:01 large] (main.py 226): INFO Train: [221/300][2200/2502]	eta 0:02:33 lr 0.000083	time 0.4749 (0.5067)	loss 2.8535 (3.0519)	grad_norm 6.2514 (nan)	mem 8926MB
[2022-04-09 00:43:50 large] (main.py 226): INFO Train: [221/300][2300/2502]	eta 0:01:42 lr 0.000083	time 0.4748 (0.5059)	loss 2.1502 (3.0502)	grad_norm 6.1458 (nan)	mem 8926MB
[2022-04-09 00:44:39 large] (main.py 226): INFO Train: [221/300][2400/2502]	eta 0:00:51 lr 0.000083	time 0.4983 (0.5053)	loss 2.4022 (3.0500)	grad_norm 5.5982 (nan)	mem 8926MB
[2022-04-09 00:45:27 large] (main.py 226): INFO Train: [221/300][2500/2502]	eta 0:00:01 lr 0.000083	time 0.4907 (0.5044)	loss 1.9047 (3.0528)	grad_norm 7.2692 (nan)	mem 8926MB
[2022-04-09 00:45:28 large] (main.py 233): INFO EPOCH 221 training takes 0:21:02
[2022-04-09 00:45:35 large] (main.py 273): INFO Test: [0/98]	Time 6.713 (6.713)	Loss 0.8510 (0.8510)	Acc@1 83.789 (83.789)	Acc@5 96.289 (96.289)	Mem 8926MB
[2022-04-09 00:46:00 large] (main.py 279): INFO  * Acc@1 80.226 Acc@5 95.114
[2022-04-09 00:46:00 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 80.2%
[2022-04-09 00:46:00 large] (main.py 148): INFO Max accuracy: 80.34%
[2022-04-09 00:46:08 large] (main.py 226): INFO Train: [222/300][0/2502]	eta 5:22:37 lr 0.000083	time 7.7369 (7.7369)	loss 2.9977 (2.9977)	grad_norm 5.3500 (5.3500)	mem 8926MB
[2022-04-09 00:46:58 large] (main.py 226): INFO Train: [222/300][100/2502]	eta 0:22:56 lr 0.000083	time 0.5137 (0.5729)	loss 3.5646 (2.9914)	grad_norm 11.5482 (6.5332)	mem 8926MB
[2022-04-09 00:47:50 large] (main.py 226): INFO Train: [222/300][200/2502]	eta 0:20:53 lr 0.000083	time 0.5275 (0.5446)	loss 2.0100 (3.0208)	grad_norm 5.6869 (6.3900)	mem 8926MB
[2022-04-09 00:48:42 large] (main.py 226): INFO Train: [222/300][300/2502]	eta 0:19:41 lr 0.000083	time 0.5134 (0.5367)	loss 2.7521 (3.0251)	grad_norm 5.0522 (6.3028)	mem 8926MB
[2022-04-09 00:49:34 large] (main.py 226): INFO Train: [222/300][400/2502]	eta 0:18:38 lr 0.000083	time 0.5445 (0.5321)	loss 3.3205 (3.0512)	grad_norm 5.7467 (6.2958)	mem 8926MB
[2022-04-09 00:50:25 large] (main.py 226): INFO Train: [222/300][500/2502]	eta 0:17:38 lr 0.000083	time 0.5448 (0.5288)	loss 3.2863 (3.0281)	grad_norm 5.8669 (6.2283)	mem 8926MB
[2022-04-09 00:51:16 large] (main.py 226): INFO Train: [222/300][600/2502]	eta 0:16:38 lr 0.000083	time 0.4844 (0.5248)	loss 2.3070 (3.0242)	grad_norm 5.5542 (6.2911)	mem 8926MB
[2022-04-09 00:52:07 large] (main.py 226): INFO Train: [222/300][700/2502]	eta 0:15:41 lr 0.000083	time 0.5150 (0.5223)	loss 2.7496 (3.0296)	grad_norm 6.3720 (6.2811)	mem 8926MB
[2022-04-09 00:52:58 large] (main.py 226): INFO Train: [222/300][800/2502]	eta 0:14:47 lr 0.000082	time 0.5116 (0.5217)	loss 3.1672 (3.0374)	grad_norm 6.8615 (6.3557)	mem 8926MB
[2022-04-09 00:53:48 large] (main.py 226): INFO Train: [222/300][900/2502]	eta 0:13:51 lr 0.000082	time 0.4607 (0.5192)	loss 3.2965 (3.0345)	grad_norm 4.8625 (6.3641)	mem 8926MB
[2022-04-09 00:54:38 large] (main.py 226): INFO Train: [222/300][1000/2502]	eta 0:12:57 lr 0.000082	time 0.5006 (0.5175)	loss 3.9311 (3.0320)	grad_norm 5.6273 (6.4121)	mem 8926MB
[2022-04-09 00:55:29 large] (main.py 226): INFO Train: [222/300][1100/2502]	eta 0:12:04 lr 0.000082	time 0.4929 (0.5165)	loss 3.1771 (3.0287)	grad_norm 18.3097 (6.4696)	mem 8926MB
[2022-04-09 00:56:20 large] (main.py 226): INFO Train: [222/300][1200/2502]	eta 0:11:11 lr 0.000082	time 0.5377 (0.5159)	loss 2.7763 (3.0214)	grad_norm 6.3898 (6.4521)	mem 8926MB
[2022-04-09 00:57:09 large] (main.py 226): INFO Train: [222/300][1300/2502]	eta 0:10:18 lr 0.000082	time 0.5017 (0.5142)	loss 2.9739 (3.0200)	grad_norm 5.2907 (6.4405)	mem 8926MB
[2022-04-09 00:58:00 large] (main.py 226): INFO Train: [222/300][1400/2502]	eta 0:09:26 lr 0.000082	time 0.4492 (0.5139)	loss 3.1477 (3.0232)	grad_norm 7.0965 (6.4568)	mem 8926MB
[2022-04-09 00:58:51 large] (main.py 226): INFO Train: [222/300][1500/2502]	eta 0:08:34 lr 0.000082	time 0.5738 (0.5132)	loss 2.9050 (3.0231)	grad_norm 6.1057 (6.5054)	mem 8926MB
[2022-04-09 00:59:42 large] (main.py 226): INFO Train: [222/300][1600/2502]	eta 0:07:43 lr 0.000082	time 0.5065 (0.5133)	loss 3.2041 (3.0298)	grad_norm 4.9482 (6.5260)	mem 8926MB
[2022-04-09 01:00:34 large] (main.py 226): INFO Train: [222/300][1700/2502]	eta 0:06:51 lr 0.000082	time 0.5408 (0.5133)	loss 2.1514 (3.0270)	grad_norm 6.3829 (6.5142)	mem 8926MB
[2022-04-09 01:01:23 large] (main.py 226): INFO Train: [222/300][1800/2502]	eta 0:05:59 lr 0.000082	time 0.4885 (0.5125)	loss 3.3868 (3.0280)	grad_norm 7.0248 (6.5013)	mem 8926MB
[2022-04-09 01:02:13 large] (main.py 226): INFO Train: [222/300][1900/2502]	eta 0:05:08 lr 0.000082	time 0.4930 (0.5118)	loss 2.3035 (3.0265)	grad_norm 5.2946 (6.4904)	mem 8926MB
[2022-04-09 01:03:04 large] (main.py 226): INFO Train: [222/300][2000/2502]	eta 0:04:16 lr 0.000082	time 0.4689 (0.5116)	loss 2.1631 (3.0242)	grad_norm 4.8148 (6.4747)	mem 8926MB
[2022-04-09 01:03:55 large] (main.py 226): INFO Train: [222/300][2100/2502]	eta 0:03:25 lr 0.000081	time 0.5185 (0.5117)	loss 3.2089 (3.0254)	grad_norm 5.7879 (6.4574)	mem 8926MB
[2022-04-09 01:04:47 large] (main.py 226): INFO Train: [222/300][2200/2502]	eta 0:02:34 lr 0.000081	time 0.5071 (0.5118)	loss 3.3853 (3.0265)	grad_norm 5.8982 (6.4491)	mem 8926MB
[2022-04-09 01:05:38 large] (main.py 226): INFO Train: [222/300][2300/2502]	eta 0:01:43 lr 0.000081	time 0.4854 (0.5117)	loss 2.8407 (3.0246)	grad_norm 7.7221 (6.4787)	mem 8926MB
[2022-04-09 01:06:26 large] (main.py 226): INFO Train: [222/300][2400/2502]	eta 0:00:52 lr 0.000081	time 0.5297 (0.5106)	loss 3.1038 (3.0257)	grad_norm 5.5184 (6.4712)	mem 8926MB
[2022-04-09 01:07:15 large] (main.py 226): INFO Train: [222/300][2500/2502]	eta 0:00:01 lr 0.000081	time 0.4729 (0.5094)	loss 3.2789 (3.0265)	grad_norm 6.0425 (6.4530)	mem 8926MB
[2022-04-09 01:07:16 large] (main.py 233): INFO EPOCH 222 training takes 0:21:15
[2022-04-09 01:07:22 large] (main.py 273): INFO Test: [0/98]	Time 5.998 (5.998)	Loss 0.9776 (0.9776)	Acc@1 80.859 (80.859)	Acc@5 95.117 (95.117)	Mem 8926MB
[2022-04-09 01:07:48 large] (main.py 279): INFO  * Acc@1 80.406 Acc@5 95.110
[2022-04-09 01:07:48 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 80.4%
[2022-04-09 01:07:48 large] (utils.py 57): INFO output/large/default/ckpt_epoch_222.pth saving......
[2022-04-09 01:07:48 large] (utils.py 59): INFO output/large/default/ckpt_epoch_222.pth saved !!!
[2022-04-09 01:07:48 large] (main.py 148): INFO Max accuracy: 80.41%
[2022-04-09 01:07:56 large] (main.py 226): INFO Train: [223/300][0/2502]	eta 5:33:48 lr 0.000081	time 8.0050 (8.0050)	loss 3.8933 (3.8933)	grad_norm 7.8451 (7.8451)	mem 8926MB
[2022-04-09 01:08:46 large] (main.py 226): INFO Train: [223/300][100/2502]	eta 0:22:59 lr 0.000081	time 0.5240 (0.5744)	loss 3.6979 (2.9486)	grad_norm 7.9403 (6.7714)	mem 8926MB
[2022-04-09 01:09:39 large] (main.py 226): INFO Train: [223/300][200/2502]	eta 0:21:04 lr 0.000081	time 0.5273 (0.5495)	loss 1.9826 (3.0199)	grad_norm 5.2520 (6.6628)	mem 8926MB
[2022-04-09 01:10:29 large] (main.py 226): INFO Train: [223/300][300/2502]	eta 0:19:35 lr 0.000081	time 0.5258 (0.5336)	loss 2.1862 (3.0113)	grad_norm 6.4307 (6.7071)	mem 8926MB
[2022-04-09 01:11:20 large] (main.py 226): INFO Train: [223/300][400/2502]	eta 0:18:28 lr 0.000081	time 0.5234 (0.5274)	loss 2.0410 (3.0290)	grad_norm 7.3761 (6.8071)	mem 8926MB
[2022-04-09 01:12:08 large] (main.py 226): INFO Train: [223/300][500/2502]	eta 0:17:18 lr 0.000081	time 0.4649 (0.5187)	loss 2.4733 (3.0184)	grad_norm 5.2226 (6.7636)	mem 8926MB
[2022-04-09 01:12:59 large] (main.py 226): INFO Train: [223/300][600/2502]	eta 0:16:24 lr 0.000081	time 0.5005 (0.5175)	loss 3.0096 (3.0381)	grad_norm 5.6005 (nan)	mem 8926MB
[2022-04-09 01:13:51 large] (main.py 226): INFO Train: [223/300][700/2502]	eta 0:15:32 lr 0.000081	time 0.5142 (0.5175)	loss 3.5346 (3.0366)	grad_norm 5.9950 (nan)	mem 8926MB
[2022-04-09 01:14:43 large] (main.py 226): INFO Train: [223/300][800/2502]	eta 0:14:40 lr 0.000081	time 0.5370 (0.5171)	loss 3.5592 (3.0459)	grad_norm 5.1082 (nan)	mem 8926MB
[2022-04-09 01:15:34 large] (main.py 226): INFO Train: [223/300][900/2502]	eta 0:13:48 lr 0.000081	time 0.5024 (0.5170)	loss 3.7197 (3.0471)	grad_norm 6.8720 (nan)	mem 8926MB
[2022-04-09 01:16:26 large] (main.py 226): INFO Train: [223/300][1000/2502]	eta 0:12:56 lr 0.000080	time 0.4726 (0.5169)	loss 2.8352 (3.0420)	grad_norm 5.1010 (nan)	mem 8926MB
[2022-04-09 01:17:16 large] (main.py 226): INFO Train: [223/300][1100/2502]	eta 0:12:02 lr 0.000080	time 0.5140 (0.5151)	loss 2.5670 (3.0412)	grad_norm 8.3933 (nan)	mem 8926MB
[2022-04-09 01:18:07 large] (main.py 226): INFO Train: [223/300][1200/2502]	eta 0:11:10 lr 0.000080	time 0.5616 (0.5153)	loss 3.2586 (3.0433)	grad_norm 5.7630 (nan)	mem 8926MB
[2022-04-09 01:18:57 large] (main.py 226): INFO Train: [223/300][1300/2502]	eta 0:10:17 lr 0.000080	time 0.4998 (0.5137)	loss 3.6902 (3.0446)	grad_norm 6.7768 (nan)	mem 8926MB
[2022-04-09 01:19:46 large] (main.py 226): INFO Train: [223/300][1400/2502]	eta 0:09:24 lr 0.000080	time 0.4641 (0.5124)	loss 3.3164 (3.0465)	grad_norm 11.3801 (nan)	mem 8926MB
[2022-04-09 01:20:37 large] (main.py 226): INFO Train: [223/300][1500/2502]	eta 0:08:33 lr 0.000080	time 0.5357 (0.5124)	loss 3.2796 (3.0494)	grad_norm 5.0840 (nan)	mem 8926MB
[2022-04-09 01:21:29 large] (main.py 226): INFO Train: [223/300][1600/2502]	eta 0:07:42 lr 0.000080	time 0.4777 (0.5125)	loss 3.6287 (3.0516)	grad_norm 4.9297 (nan)	mem 8926MB
[2022-04-09 01:22:19 large] (main.py 226): INFO Train: [223/300][1700/2502]	eta 0:06:50 lr 0.000080	time 0.4986 (0.5115)	loss 3.0347 (3.0502)	grad_norm 6.0785 (nan)	mem 8926MB
[2022-04-09 01:23:08 large] (main.py 226): INFO Train: [223/300][1800/2502]	eta 0:05:58 lr 0.000080	time 0.5192 (0.5103)	loss 3.3190 (3.0490)	grad_norm 6.3028 (nan)	mem 8926MB
[2022-04-09 01:23:59 large] (main.py 226): INFO Train: [223/300][1900/2502]	eta 0:05:07 lr 0.000080	time 0.5297 (0.5105)	loss 3.1100 (3.0511)	grad_norm 7.1822 (nan)	mem 8926MB
[2022-04-09 01:24:51 large] (main.py 226): INFO Train: [223/300][2000/2502]	eta 0:04:16 lr 0.000080	time 0.5793 (0.5109)	loss 2.7101 (3.0473)	grad_norm 5.8496 (nan)	mem 8926MB
[2022-04-09 01:25:42 large] (main.py 226): INFO Train: [223/300][2100/2502]	eta 0:03:25 lr 0.000080	time 0.5148 (0.5111)	loss 3.4449 (3.0478)	grad_norm 6.7736 (nan)	mem 8926MB
[2022-04-09 01:26:34 large] (main.py 226): INFO Train: [223/300][2200/2502]	eta 0:02:34 lr 0.000080	time 0.5125 (0.5112)	loss 3.6291 (3.0461)	grad_norm 6.8582 (nan)	mem 8926MB
[2022-04-09 01:27:25 large] (main.py 226): INFO Train: [223/300][2300/2502]	eta 0:01:43 lr 0.000079	time 0.5033 (0.5114)	loss 2.7417 (3.0427)	grad_norm 5.9652 (nan)	mem 8926MB
[2022-04-09 01:28:15 large] (main.py 226): INFO Train: [223/300][2400/2502]	eta 0:00:52 lr 0.000079	time 0.4964 (0.5111)	loss 2.7290 (3.0398)	grad_norm 10.0665 (nan)	mem 8926MB
[2022-04-09 01:29:04 large] (main.py 226): INFO Train: [223/300][2500/2502]	eta 0:00:01 lr 0.000079	time 0.4746 (0.5099)	loss 3.2057 (3.0390)	grad_norm 12.0538 (nan)	mem 8926MB
[2022-04-09 01:29:05 large] (main.py 233): INFO EPOCH 223 training takes 0:21:16
[2022-04-09 01:29:11 large] (main.py 273): INFO Test: [0/98]	Time 6.876 (6.876)	Loss 1.0691 (1.0691)	Acc@1 78.516 (78.516)	Acc@5 95.508 (95.508)	Mem 8926MB
[2022-04-09 01:29:37 large] (main.py 279): INFO  * Acc@1 80.412 Acc@5 95.098
[2022-04-09 01:29:37 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 80.4%
[2022-04-09 01:29:37 large] (utils.py 57): INFO output/large/default/ckpt_epoch_223.pth saving......
[2022-04-09 01:29:38 large] (utils.py 59): INFO output/large/default/ckpt_epoch_223.pth saved !!!
[2022-04-09 01:29:38 large] (main.py 148): INFO Max accuracy: 80.41%
[2022-04-09 01:29:46 large] (main.py 226): INFO Train: [224/300][0/2502]	eta 5:46:33 lr 0.000079	time 8.3107 (8.3107)	loss 3.5638 (3.5638)	grad_norm 7.3136 (7.3136)	mem 8926MB
[2022-04-09 01:30:36 large] (main.py 226): INFO Train: [224/300][100/2502]	eta 0:23:15 lr 0.000079	time 0.5055 (0.5809)	loss 3.5178 (3.0035)	grad_norm 8.9674 (6.4425)	mem 8926MB
[2022-04-09 01:31:26 large] (main.py 226): INFO Train: [224/300][200/2502]	eta 0:20:36 lr 0.000079	time 0.4993 (0.5372)	loss 3.5995 (3.0133)	grad_norm 6.9371 (6.3126)	mem 8926MB
[2022-04-09 01:32:14 large] (main.py 226): INFO Train: [224/300][300/2502]	eta 0:19:03 lr 0.000079	time 0.4802 (0.5191)	loss 3.3072 (3.0335)	grad_norm 6.4817 (6.5686)	mem 8926MB
[2022-04-09 01:33:05 large] (main.py 226): INFO Train: [224/300][400/2502]	eta 0:18:05 lr 0.000079	time 0.4948 (0.5166)	loss 2.6384 (3.0280)	grad_norm 7.3255 (6.4739)	mem 8926MB
[2022-04-09 01:33:57 large] (main.py 226): INFO Train: [224/300][500/2502]	eta 0:17:16 lr 0.000079	time 0.5896 (0.5178)	loss 3.0178 (3.0258)	grad_norm 5.0117 (6.4030)	mem 8926MB
[2022-04-09 01:34:48 large] (main.py 226): INFO Train: [224/300][600/2502]	eta 0:16:20 lr 0.000079	time 0.5144 (0.5157)	loss 3.4626 (3.0167)	grad_norm 5.4032 (6.3794)	mem 8926MB
[2022-04-09 01:35:37 large] (main.py 226): INFO Train: [224/300][700/2502]	eta 0:15:23 lr 0.000079	time 0.4887 (0.5125)	loss 2.2521 (3.0128)	grad_norm 8.9610 (6.3921)	mem 8926MB
[2022-04-09 01:36:27 large] (main.py 226): INFO Train: [224/300][800/2502]	eta 0:14:29 lr 0.000079	time 0.4793 (0.5106)	loss 2.7803 (3.0133)	grad_norm 7.0771 (6.5376)	mem 8926MB
[2022-04-09 01:37:18 large] (main.py 226): INFO Train: [224/300][900/2502]	eta 0:13:39 lr 0.000079	time 0.5068 (0.5114)	loss 2.7668 (3.0084)	grad_norm 5.9507 (6.5841)	mem 8926MB
[2022-04-09 01:38:08 large] (main.py 226): INFO Train: [224/300][1000/2502]	eta 0:12:45 lr 0.000079	time 0.5014 (0.5095)	loss 3.5517 (3.0174)	grad_norm 5.9771 (6.5969)	mem 8926MB
[2022-04-09 01:38:58 large] (main.py 226): INFO Train: [224/300][1100/2502]	eta 0:11:53 lr 0.000079	time 0.5212 (0.5087)	loss 3.2890 (3.0221)	grad_norm 8.1035 (6.5723)	mem 8926MB
[2022-04-09 01:39:49 large] (main.py 226): INFO Train: [224/300][1200/2502]	eta 0:11:02 lr 0.000078	time 0.5029 (0.5091)	loss 2.1736 (3.0222)	grad_norm 6.2347 (6.5859)	mem 8926MB
[2022-04-09 01:40:39 large] (main.py 226): INFO Train: [224/300][1300/2502]	eta 0:10:11 lr 0.000078	time 0.4889 (0.5087)	loss 3.2177 (3.0207)	grad_norm 6.1148 (6.5929)	mem 8926MB
[2022-04-09 01:41:31 large] (main.py 226): INFO Train: [224/300][1400/2502]	eta 0:09:20 lr 0.000078	time 0.5227 (0.5089)	loss 3.4298 (3.0115)	grad_norm 5.4670 (6.5932)	mem 8926MB
[2022-04-09 01:42:22 large] (main.py 226): INFO Train: [224/300][1500/2502]	eta 0:08:30 lr 0.000078	time 0.5478 (0.5093)	loss 2.9995 (3.0147)	grad_norm 6.0955 (6.5872)	mem 8926MB
[2022-04-09 01:43:12 large] (main.py 226): INFO Train: [224/300][1600/2502]	eta 0:07:38 lr 0.000078	time 0.4892 (0.5084)	loss 3.5186 (3.0167)	grad_norm 5.9252 (6.5994)	mem 8926MB
[2022-04-09 01:44:03 large] (main.py 226): INFO Train: [224/300][1700/2502]	eta 0:06:47 lr 0.000078	time 0.5433 (0.5087)	loss 3.0759 (3.0220)	grad_norm 6.2999 (6.6028)	mem 8926MB
[2022-04-09 01:44:53 large] (main.py 226): INFO Train: [224/300][1800/2502]	eta 0:05:56 lr 0.000078	time 0.4899 (0.5084)	loss 3.1947 (3.0183)	grad_norm 5.6642 (6.5942)	mem 8926MB
[2022-04-09 01:45:44 large] (main.py 226): INFO Train: [224/300][1900/2502]	eta 0:05:05 lr 0.000078	time 0.5229 (0.5082)	loss 2.4834 (3.0192)	grad_norm 5.1606 (6.5887)	mem 8926MB
[2022-04-09 01:46:33 large] (main.py 226): INFO Train: [224/300][2000/2502]	eta 0:04:14 lr 0.000078	time 0.4829 (0.5077)	loss 3.7340 (3.0192)	grad_norm 6.8557 (6.5816)	mem 8926MB
[2022-04-09 01:47:23 large] (main.py 226): INFO Train: [224/300][2100/2502]	eta 0:03:23 lr 0.000078	time 0.4997 (0.5072)	loss 2.8652 (3.0211)	grad_norm 4.8117 (6.5771)	mem 8926MB
[2022-04-09 01:48:15 large] (main.py 226): INFO Train: [224/300][2200/2502]	eta 0:02:33 lr 0.000078	time 0.5241 (0.5078)	loss 3.7751 (3.0231)	grad_norm 9.1930 (6.5830)	mem 8926MB
[2022-04-09 01:49:07 large] (main.py 226): INFO Train: [224/300][2300/2502]	eta 0:01:42 lr 0.000078	time 0.4555 (0.5081)	loss 3.2106 (3.0251)	grad_norm 6.7309 (6.5761)	mem 8926MB
[2022-04-09 01:49:58 large] (main.py 226): INFO Train: [224/300][2400/2502]	eta 0:00:51 lr 0.000078	time 0.5036 (0.5085)	loss 2.3052 (3.0256)	grad_norm 4.4231 (6.6024)	mem 8926MB
[2022-04-09 01:50:47 large] (main.py 226): INFO Train: [224/300][2500/2502]	eta 0:00:01 lr 0.000077	time 0.4721 (0.5075)	loss 2.2015 (3.0290)	grad_norm 5.5850 (6.6127)	mem 8926MB
[2022-04-09 01:50:48 large] (main.py 233): INFO EPOCH 224 training takes 0:21:10
[2022-04-09 01:50:54 large] (main.py 273): INFO Test: [0/98]	Time 6.360 (6.360)	Loss 0.9172 (0.9172)	Acc@1 82.422 (82.422)	Acc@5 95.508 (95.508)	Mem 8926MB
[2022-04-09 01:51:20 large] (main.py 279): INFO  * Acc@1 80.564 Acc@5 95.116
[2022-04-09 01:51:20 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 80.6%
[2022-04-09 01:51:20 large] (utils.py 57): INFO output/large/default/ckpt_epoch_224.pth saving......
[2022-04-09 01:51:21 large] (utils.py 59): INFO output/large/default/ckpt_epoch_224.pth saved !!!
[2022-04-09 01:51:21 large] (main.py 148): INFO Max accuracy: 80.56%
[2022-04-09 01:51:30 large] (main.py 226): INFO Train: [225/300][0/2502]	eta 5:55:50 lr 0.000077	time 8.5335 (8.5335)	loss 2.3492 (2.3492)	grad_norm 7.0826 (7.0826)	mem 8926MB
[2022-04-09 01:52:19 large] (main.py 226): INFO Train: [225/300][100/2502]	eta 0:22:57 lr 0.000077	time 0.4509 (0.5734)	loss 2.7065 (3.0082)	grad_norm 5.6009 (6.4172)	mem 8926MB
[2022-04-09 01:53:09 large] (main.py 226): INFO Train: [225/300][200/2502]	eta 0:20:36 lr 0.000077	time 0.5380 (0.5373)	loss 2.7502 (2.9557)	grad_norm 5.5053 (6.3605)	mem 8926MB
[2022-04-09 01:54:01 large] (main.py 226): INFO Train: [225/300][300/2502]	eta 0:19:27 lr 0.000077	time 0.5931 (0.5302)	loss 2.5754 (2.9735)	grad_norm 19.4297 (6.4362)	mem 8926MB
[2022-04-09 01:54:53 large] (main.py 226): INFO Train: [225/300][400/2502]	eta 0:18:30 lr 0.000077	time 0.4872 (0.5285)	loss 2.9674 (2.9866)	grad_norm 6.2135 (6.4879)	mem 8926MB
[2022-04-09 01:55:45 large] (main.py 226): INFO Train: [225/300][500/2502]	eta 0:17:32 lr 0.000077	time 0.5068 (0.5260)	loss 2.9889 (3.0029)	grad_norm 6.5019 (6.4669)	mem 8926MB
[2022-04-09 01:56:37 large] (main.py 226): INFO Train: [225/300][600/2502]	eta 0:16:38 lr 0.000077	time 0.5347 (0.5251)	loss 2.7855 (3.0141)	grad_norm 7.4186 (6.4472)	mem 8926MB
[2022-04-09 01:57:27 large] (main.py 226): INFO Train: [225/300][700/2502]	eta 0:15:40 lr 0.000077	time 0.4958 (0.5218)	loss 3.6306 (3.0156)	grad_norm 7.6884 (6.4360)	mem 8926MB
[2022-04-09 01:58:16 large] (main.py 226): INFO Train: [225/300][800/2502]	eta 0:14:42 lr 0.000077	time 0.5608 (0.5183)	loss 3.1407 (3.0047)	grad_norm 5.1126 (6.4894)	mem 8926MB
[2022-04-09 01:59:06 large] (main.py 226): INFO Train: [225/300][900/2502]	eta 0:13:46 lr 0.000077	time 0.5054 (0.5159)	loss 3.3439 (3.0013)	grad_norm 5.3796 (6.5106)	mem 8926MB
[2022-04-09 01:59:57 large] (main.py 226): INFO Train: [225/300][1000/2502]	eta 0:12:53 lr 0.000077	time 0.4505 (0.5149)	loss 3.0181 (2.9984)	grad_norm 4.7500 (6.4742)	mem 8926MB
[2022-04-09 02:00:45 large] (main.py 226): INFO Train: [225/300][1100/2502]	eta 0:11:58 lr 0.000077	time 0.4837 (0.5123)	loss 2.3081 (3.0018)	grad_norm 6.7377 (6.5294)	mem 8926MB
[2022-04-09 02:01:36 large] (main.py 226): INFO Train: [225/300][1200/2502]	eta 0:11:06 lr 0.000077	time 0.5149 (0.5121)	loss 2.5250 (3.0026)	grad_norm 6.4974 (6.5221)	mem 8926MB
[2022-04-09 02:02:28 large] (main.py 226): INFO Train: [225/300][1300/2502]	eta 0:10:16 lr 0.000077	time 0.5111 (0.5128)	loss 3.5544 (3.0018)	grad_norm 5.3068 (6.5197)	mem 8926MB
[2022-04-09 02:03:19 large] (main.py 226): INFO Train: [225/300][1400/2502]	eta 0:09:24 lr 0.000076	time 0.4701 (0.5126)	loss 2.8192 (3.0099)	grad_norm 6.7787 (nan)	mem 8926MB
[2022-04-09 02:04:09 large] (main.py 226): INFO Train: [225/300][1500/2502]	eta 0:08:32 lr 0.000076	time 0.4983 (0.5119)	loss 3.2792 (3.0093)	grad_norm 5.8035 (nan)	mem 8926MB
[2022-04-09 02:05:01 large] (main.py 226): INFO Train: [225/300][1600/2502]	eta 0:07:41 lr 0.000076	time 0.5062 (0.5122)	loss 3.5539 (3.0102)	grad_norm 6.0473 (nan)	mem 8926MB
[2022-04-09 02:05:50 large] (main.py 226): INFO Train: [225/300][1700/2502]	eta 0:06:49 lr 0.000076	time 0.4866 (0.5108)	loss 2.9174 (3.0112)	grad_norm 6.9611 (nan)	mem 8926MB
[2022-04-09 02:06:41 large] (main.py 226): INFO Train: [225/300][1800/2502]	eta 0:05:58 lr 0.000076	time 0.5055 (0.5106)	loss 2.8977 (3.0116)	grad_norm 4.8640 (nan)	mem 8926MB
[2022-04-09 02:07:32 large] (main.py 226): INFO Train: [225/300][1900/2502]	eta 0:05:07 lr 0.000076	time 0.5129 (0.5108)	loss 3.1713 (3.0122)	grad_norm 5.8712 (nan)	mem 8926MB
[2022-04-09 02:08:24 large] (main.py 226): INFO Train: [225/300][2000/2502]	eta 0:04:16 lr 0.000076	time 0.5106 (0.5110)	loss 2.8908 (3.0134)	grad_norm 7.0603 (nan)	mem 8926MB
[2022-04-09 02:09:15 large] (main.py 226): INFO Train: [225/300][2100/2502]	eta 0:03:25 lr 0.000076	time 0.4930 (0.5112)	loss 2.9006 (3.0165)	grad_norm 5.4523 (nan)	mem 8926MB
[2022-04-09 02:10:04 large] (main.py 226): INFO Train: [225/300][2200/2502]	eta 0:02:34 lr 0.000076	time 0.5017 (0.5102)	loss 3.2205 (3.0160)	grad_norm 6.0125 (nan)	mem 8926MB
[2022-04-09 02:10:54 large] (main.py 226): INFO Train: [225/300][2300/2502]	eta 0:01:42 lr 0.000076	time 0.4959 (0.5096)	loss 2.6815 (3.0151)	grad_norm 4.5078 (nan)	mem 8926MB
[2022-04-09 02:11:44 large] (main.py 226): INFO Train: [225/300][2400/2502]	eta 0:00:51 lr 0.000076	time 0.5166 (0.5093)	loss 2.9657 (3.0147)	grad_norm 7.0965 (nan)	mem 8926MB
[2022-04-09 02:12:35 large] (main.py 226): INFO Train: [225/300][2500/2502]	eta 0:00:01 lr 0.000076	time 0.4957 (0.5093)	loss 2.7603 (3.0170)	grad_norm 4.8959 (nan)	mem 8926MB
[2022-04-09 02:12:36 large] (main.py 233): INFO EPOCH 225 training takes 0:21:14
[2022-04-09 02:12:42 large] (main.py 273): INFO Test: [0/98]	Time 6.140 (6.140)	Loss 0.9049 (0.9049)	Acc@1 82.031 (82.031)	Acc@5 96.289 (96.289)	Mem 8926MB
[2022-04-09 02:13:08 large] (main.py 279): INFO  * Acc@1 80.564 Acc@5 95.126
[2022-04-09 02:13:08 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 80.6%
[2022-04-09 02:13:08 large] (main.py 148): INFO Max accuracy: 80.56%
[2022-04-09 02:13:15 large] (main.py 226): INFO Train: [226/300][0/2502]	eta 4:59:33 lr 0.000076	time 7.1837 (7.1837)	loss 3.3101 (3.3101)	grad_norm 9.1172 (9.1172)	mem 8926MB
[2022-04-09 02:14:05 large] (main.py 226): INFO Train: [226/300][100/2502]	eta 0:22:38 lr 0.000076	time 0.4734 (0.5654)	loss 3.3633 (2.9257)	grad_norm 6.1051 (6.5286)	mem 8926MB
[2022-04-09 02:14:53 large] (main.py 226): INFO Train: [226/300][200/2502]	eta 0:20:08 lr 0.000076	time 0.5268 (0.5249)	loss 3.1867 (2.9268)	grad_norm 6.4712 (6.7881)	mem 8926MB
[2022-04-09 02:15:43 large] (main.py 226): INFO Train: [226/300][300/2502]	eta 0:18:58 lr 0.000075	time 0.4817 (0.5170)	loss 3.0813 (2.9829)	grad_norm 5.4878 (6.7541)	mem 8926MB
[2022-04-09 02:16:32 large] (main.py 226): INFO Train: [226/300][400/2502]	eta 0:17:52 lr 0.000075	time 0.4995 (0.5104)	loss 3.1061 (3.0047)	grad_norm 6.4752 (6.6611)	mem 8926MB
[2022-04-09 02:17:24 large] (main.py 226): INFO Train: [226/300][500/2502]	eta 0:17:03 lr 0.000075	time 0.5309 (0.5110)	loss 2.7390 (3.0035)	grad_norm 5.0672 (6.5924)	mem 8926MB
[2022-04-09 02:18:16 large] (main.py 226): INFO Train: [226/300][600/2502]	eta 0:16:14 lr 0.000075	time 0.5308 (0.5122)	loss 2.8284 (3.0003)	grad_norm 6.1843 (nan)	mem 8926MB
[2022-04-09 02:19:06 large] (main.py 226): INFO Train: [226/300][700/2502]	eta 0:15:20 lr 0.000075	time 0.4876 (0.5108)	loss 3.8155 (2.9976)	grad_norm 5.6809 (nan)	mem 8926MB
[2022-04-09 02:19:56 large] (main.py 226): INFO Train: [226/300][800/2502]	eta 0:14:26 lr 0.000075	time 0.5232 (0.5094)	loss 3.3870 (3.0005)	grad_norm 5.3137 (nan)	mem 8926MB
[2022-04-09 02:20:46 large] (main.py 226): INFO Train: [226/300][900/2502]	eta 0:13:34 lr 0.000075	time 0.5723 (0.5082)	loss 3.5263 (3.0054)	grad_norm 6.3060 (nan)	mem 8926MB
[2022-04-09 02:21:37 large] (main.py 226): INFO Train: [226/300][1000/2502]	eta 0:12:43 lr 0.000075	time 0.4920 (0.5085)	loss 3.4335 (3.0088)	grad_norm 7.1714 (nan)	mem 8926MB
[2022-04-09 02:22:28 large] (main.py 226): INFO Train: [226/300][1100/2502]	eta 0:11:53 lr 0.000075	time 0.5017 (0.5091)	loss 3.6976 (3.0091)	grad_norm 6.1859 (nan)	mem 8926MB
[2022-04-09 02:23:20 large] (main.py 226): INFO Train: [226/300][1200/2502]	eta 0:11:03 lr 0.000075	time 0.5418 (0.5096)	loss 2.5936 (3.0048)	grad_norm 5.9710 (nan)	mem 8926MB
[2022-04-09 02:24:11 large] (main.py 226): INFO Train: [226/300][1300/2502]	eta 0:10:12 lr 0.000075	time 0.5002 (0.5099)	loss 2.9514 (3.0001)	grad_norm 6.4036 (nan)	mem 8926MB
[2022-04-09 02:25:02 large] (main.py 226): INFO Train: [226/300][1400/2502]	eta 0:09:21 lr 0.000075	time 0.4807 (0.5099)	loss 1.9109 (3.0019)	grad_norm 6.4515 (nan)	mem 8926MB
[2022-04-09 02:25:51 large] (main.py 226): INFO Train: [226/300][1500/2502]	eta 0:08:29 lr 0.000075	time 0.4984 (0.5083)	loss 3.4898 (3.0042)	grad_norm 8.4434 (nan)	mem 8926MB
[2022-04-09 02:26:40 large] (main.py 226): INFO Train: [226/300][1600/2502]	eta 0:07:37 lr 0.000075	time 0.4506 (0.5073)	loss 2.3053 (3.0012)	grad_norm 5.5383 (nan)	mem 8926MB
[2022-04-09 02:27:29 large] (main.py 226): INFO Train: [226/300][1700/2502]	eta 0:06:45 lr 0.000074	time 0.4790 (0.5061)	loss 2.2125 (3.0037)	grad_norm 5.6941 (nan)	mem 8926MB
[2022-04-09 02:28:19 large] (main.py 226): INFO Train: [226/300][1800/2502]	eta 0:05:55 lr 0.000074	time 0.5098 (0.5061)	loss 2.5148 (3.0006)	grad_norm 6.7201 (nan)	mem 8926MB
[2022-04-09 02:29:09 large] (main.py 226): INFO Train: [226/300][1900/2502]	eta 0:05:04 lr 0.000074	time 0.4787 (0.5054)	loss 3.6349 (3.0044)	grad_norm 6.6186 (nan)	mem 8926MB
[2022-04-09 02:29:58 large] (main.py 226): INFO Train: [226/300][2000/2502]	eta 0:04:13 lr 0.000074	time 0.4943 (0.5047)	loss 3.5238 (3.0052)	grad_norm 5.4629 (nan)	mem 8926MB
[2022-04-09 02:30:47 large] (main.py 226): INFO Train: [226/300][2100/2502]	eta 0:03:22 lr 0.000074	time 0.5031 (0.5042)	loss 3.5842 (3.0023)	grad_norm 6.2458 (nan)	mem 8926MB
[2022-04-09 02:31:37 large] (main.py 226): INFO Train: [226/300][2200/2502]	eta 0:02:32 lr 0.000074	time 0.4928 (0.5040)	loss 3.7370 (3.0042)	grad_norm 9.3299 (nan)	mem 8926MB
[2022-04-09 02:32:28 large] (main.py 226): INFO Train: [226/300][2300/2502]	eta 0:01:41 lr 0.000074	time 0.5181 (0.5044)	loss 3.3923 (3.0077)	grad_norm 6.3281 (nan)	mem 8926MB
[2022-04-09 02:33:20 large] (main.py 226): INFO Train: [226/300][2400/2502]	eta 0:00:51 lr 0.000074	time 0.5556 (0.5049)	loss 3.2923 (3.0090)	grad_norm 4.7527 (nan)	mem 8926MB
[2022-04-09 02:34:11 large] (main.py 226): INFO Train: [226/300][2500/2502]	eta 0:00:01 lr 0.000074	time 0.4989 (0.5051)	loss 3.2748 (3.0112)	grad_norm 9.0288 (nan)	mem 8926MB
[2022-04-09 02:34:12 large] (main.py 233): INFO EPOCH 226 training takes 0:21:04
[2022-04-09 02:34:19 large] (main.py 273): INFO Test: [0/98]	Time 6.993 (6.993)	Loss 1.0298 (1.0298)	Acc@1 78.906 (78.906)	Acc@5 96.094 (96.094)	Mem 8926MB
[2022-04-09 02:34:44 large] (main.py 279): INFO  * Acc@1 80.700 Acc@5 95.270
[2022-04-09 02:34:44 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 80.7%
[2022-04-09 02:34:44 large] (utils.py 57): INFO output/large/default/ckpt_epoch_226.pth saving......
[2022-04-09 02:34:45 large] (utils.py 59): INFO output/large/default/ckpt_epoch_226.pth saved !!!
[2022-04-09 02:34:45 large] (main.py 148): INFO Max accuracy: 80.70%
[2022-04-09 02:34:53 large] (main.py 226): INFO Train: [227/300][0/2502]	eta 5:47:14 lr 0.000074	time 8.3270 (8.3270)	loss 2.8311 (2.8311)	grad_norm 4.1553 (4.1553)	mem 8926MB
[2022-04-09 02:35:43 large] (main.py 226): INFO Train: [227/300][100/2502]	eta 0:23:06 lr 0.000074	time 0.5428 (0.5772)	loss 3.1634 (2.9757)	grad_norm 4.7894 (6.2300)	mem 8926MB
[2022-04-09 02:36:33 large] (main.py 226): INFO Train: [227/300][200/2502]	eta 0:20:35 lr 0.000074	time 0.4840 (0.5366)	loss 2.5784 (3.0145)	grad_norm 6.1611 (6.3012)	mem 8926MB
[2022-04-09 02:37:24 large] (main.py 226): INFO Train: [227/300][300/2502]	eta 0:19:20 lr 0.000074	time 0.5541 (0.5268)	loss 3.4228 (3.0161)	grad_norm 5.9270 (nan)	mem 8926MB
[2022-04-09 02:38:15 large] (main.py 226): INFO Train: [227/300][400/2502]	eta 0:18:22 lr 0.000074	time 0.5806 (0.5244)	loss 3.0961 (3.0164)	grad_norm 6.7319 (nan)	mem 8926MB
[2022-04-09 02:39:07 large] (main.py 226): INFO Train: [227/300][500/2502]	eta 0:17:25 lr 0.000074	time 0.5470 (0.5224)	loss 3.3324 (3.0065)	grad_norm 5.0059 (nan)	mem 8926MB
[2022-04-09 02:39:57 large] (main.py 226): INFO Train: [227/300][600/2502]	eta 0:16:28 lr 0.000073	time 0.4839 (0.5197)	loss 2.8694 (3.0032)	grad_norm 6.1525 (nan)	mem 8926MB
[2022-04-09 02:40:47 large] (main.py 226): INFO Train: [227/300][700/2502]	eta 0:15:29 lr 0.000073	time 0.5860 (0.5159)	loss 3.4435 (2.9974)	grad_norm 4.9165 (nan)	mem 8926MB
[2022-04-09 02:41:36 large] (main.py 226): INFO Train: [227/300][800/2502]	eta 0:14:32 lr 0.000073	time 0.5121 (0.5126)	loss 3.6902 (3.0016)	grad_norm 9.6454 (nan)	mem 8929MB
[2022-04-09 02:42:26 large] (main.py 226): INFO Train: [227/300][900/2502]	eta 0:13:39 lr 0.000073	time 0.5092 (0.5112)	loss 3.2541 (3.0012)	grad_norm 6.2137 (nan)	mem 8929MB
[2022-04-09 02:43:16 large] (main.py 226): INFO Train: [227/300][1000/2502]	eta 0:12:46 lr 0.000073	time 0.5117 (0.5101)	loss 2.9110 (2.9952)	grad_norm 6.6907 (nan)	mem 8929MB
[2022-04-09 02:44:07 large] (main.py 226): INFO Train: [227/300][1100/2502]	eta 0:11:55 lr 0.000073	time 0.4880 (0.5103)	loss 3.4386 (2.9971)	grad_norm 5.4377 (nan)	mem 8929MB
[2022-04-09 02:44:59 large] (main.py 226): INFO Train: [227/300][1200/2502]	eta 0:11:05 lr 0.000073	time 0.5154 (0.5109)	loss 2.0752 (2.9984)	grad_norm 9.3723 (nan)	mem 8929MB
[2022-04-09 02:45:49 large] (main.py 226): INFO Train: [227/300][1300/2502]	eta 0:10:13 lr 0.000073	time 0.4743 (0.5100)	loss 2.8375 (3.0017)	grad_norm 4.1452 (nan)	mem 8929MB
[2022-04-09 02:46:37 large] (main.py 226): INFO Train: [227/300][1400/2502]	eta 0:09:20 lr 0.000073	time 0.4586 (0.5083)	loss 2.0906 (2.9968)	grad_norm 4.8857 (nan)	mem 8929MB
[2022-04-09 02:47:25 large] (main.py 226): INFO Train: [227/300][1500/2502]	eta 0:08:27 lr 0.000073	time 0.4807 (0.5066)	loss 2.6073 (2.9945)	grad_norm 5.1061 (nan)	mem 8929MB
[2022-04-09 02:48:13 large] (main.py 226): INFO Train: [227/300][1600/2502]	eta 0:07:35 lr 0.000073	time 0.4877 (0.5050)	loss 3.6783 (2.9945)	grad_norm 13.6061 (nan)	mem 8929MB
[2022-04-09 02:49:03 large] (main.py 226): INFO Train: [227/300][1700/2502]	eta 0:06:44 lr 0.000073	time 0.4900 (0.5047)	loss 3.1351 (2.9932)	grad_norm 6.6694 (nan)	mem 8929MB
[2022-04-09 02:49:53 large] (main.py 226): INFO Train: [227/300][1800/2502]	eta 0:05:53 lr 0.000073	time 0.5025 (0.5041)	loss 2.1543 (2.9932)	grad_norm 5.1307 (nan)	mem 8929MB
[2022-04-09 02:50:44 large] (main.py 226): INFO Train: [227/300][1900/2502]	eta 0:05:03 lr 0.000073	time 0.5144 (0.5043)	loss 3.4115 (2.9915)	grad_norm 7.0376 (nan)	mem 8929MB
[2022-04-09 02:51:34 large] (main.py 226): INFO Train: [227/300][2000/2502]	eta 0:04:13 lr 0.000072	time 0.4977 (0.5045)	loss 3.0210 (2.9948)	grad_norm 7.0198 (nan)	mem 8929MB
[2022-04-09 02:52:25 large] (main.py 226): INFO Train: [227/300][2100/2502]	eta 0:03:22 lr 0.000072	time 0.5286 (0.5045)	loss 2.2052 (2.9945)	grad_norm 5.3705 (nan)	mem 8929MB
[2022-04-09 02:53:15 large] (main.py 226): INFO Train: [227/300][2200/2502]	eta 0:02:32 lr 0.000072	time 0.4806 (0.5043)	loss 3.2239 (2.9972)	grad_norm 6.4749 (nan)	mem 8929MB
[2022-04-09 02:54:03 large] (main.py 226): INFO Train: [227/300][2300/2502]	eta 0:01:41 lr 0.000072	time 0.4484 (0.5035)	loss 3.3714 (2.9978)	grad_norm 7.3819 (nan)	mem 8929MB
[2022-04-09 02:54:52 large] (main.py 226): INFO Train: [227/300][2400/2502]	eta 0:00:51 lr 0.000072	time 0.4915 (0.5028)	loss 3.3530 (2.9999)	grad_norm 7.1649 (nan)	mem 8929MB
[2022-04-09 02:55:42 large] (main.py 226): INFO Train: [227/300][2500/2502]	eta 0:00:01 lr 0.000072	time 0.4724 (0.5027)	loss 2.5872 (3.0012)	grad_norm 5.7301 (nan)	mem 8929MB
[2022-04-09 02:55:43 large] (main.py 233): INFO EPOCH 227 training takes 0:20:58
[2022-04-09 02:55:49 large] (main.py 273): INFO Test: [0/98]	Time 6.196 (6.196)	Loss 1.0439 (1.0439)	Acc@1 78.516 (78.516)	Acc@5 94.141 (94.141)	Mem 8929MB
[2022-04-09 02:56:15 large] (main.py 279): INFO  * Acc@1 80.676 Acc@5 95.256
[2022-04-09 02:56:15 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 80.7%
[2022-04-09 02:56:15 large] (main.py 148): INFO Max accuracy: 80.70%
[2022-04-09 02:56:22 large] (main.py 226): INFO Train: [228/300][0/2502]	eta 4:43:58 lr 0.000072	time 6.8100 (6.8100)	loss 3.2461 (3.2461)	grad_norm 5.8494 (5.8494)	mem 8929MB
[2022-04-09 02:57:12 large] (main.py 226): INFO Train: [228/300][100/2502]	eta 0:22:25 lr 0.000072	time 0.4932 (0.5602)	loss 2.7432 (2.9156)	grad_norm 5.4454 (6.7426)	mem 8929MB
[2022-04-09 02:58:02 large] (main.py 226): INFO Train: [228/300][200/2502]	eta 0:20:24 lr 0.000072	time 0.5078 (0.5321)	loss 3.5156 (2.9284)	grad_norm 5.4924 (6.6439)	mem 8929MB
[2022-04-09 02:58:51 large] (main.py 226): INFO Train: [228/300][300/2502]	eta 0:19:03 lr 0.000072	time 0.4907 (0.5192)	loss 2.7908 (2.9798)	grad_norm 7.3307 (6.6195)	mem 8929MB
[2022-04-09 02:59:41 large] (main.py 226): INFO Train: [228/300][400/2502]	eta 0:17:59 lr 0.000072	time 0.4906 (0.5136)	loss 2.8656 (2.9990)	grad_norm 8.2724 (6.6281)	mem 8929MB
[2022-04-09 03:00:30 large] (main.py 226): INFO Train: [228/300][500/2502]	eta 0:16:58 lr 0.000072	time 0.4915 (0.5085)	loss 3.2902 (3.0081)	grad_norm 6.1484 (6.6182)	mem 8929MB
[2022-04-09 03:01:21 large] (main.py 226): INFO Train: [228/300][600/2502]	eta 0:16:06 lr 0.000072	time 0.4902 (0.5080)	loss 2.6063 (3.0010)	grad_norm 5.1897 (6.5910)	mem 8929MB
[2022-04-09 03:02:13 large] (main.py 226): INFO Train: [228/300][700/2502]	eta 0:15:18 lr 0.000072	time 0.5270 (0.5100)	loss 2.4737 (3.0116)	grad_norm 5.8853 (6.5835)	mem 8929MB
[2022-04-09 03:03:05 large] (main.py 226): INFO Train: [228/300][800/2502]	eta 0:14:30 lr 0.000072	time 0.5049 (0.5114)	loss 3.4861 (3.0165)	grad_norm 5.1923 (6.5439)	mem 8929MB
[2022-04-09 03:03:56 large] (main.py 226): INFO Train: [228/300][900/2502]	eta 0:13:39 lr 0.000071	time 0.4601 (0.5117)	loss 2.8284 (3.0178)	grad_norm 6.5216 (nan)	mem 8929MB
[2022-04-09 03:04:45 large] (main.py 226): INFO Train: [228/300][1000/2502]	eta 0:12:45 lr 0.000071	time 0.5077 (0.5096)	loss 3.1001 (3.0181)	grad_norm 7.5977 (nan)	mem 8929MB
[2022-04-09 03:05:34 large] (main.py 226): INFO Train: [228/300][1100/2502]	eta 0:11:51 lr 0.000071	time 0.4849 (0.5076)	loss 3.3144 (3.0137)	grad_norm 6.1573 (nan)	mem 8929MB
[2022-04-09 03:06:24 large] (main.py 226): INFO Train: [228/300][1200/2502]	eta 0:11:00 lr 0.000071	time 0.5005 (0.5071)	loss 2.1736 (3.0080)	grad_norm 7.5661 (nan)	mem 8929MB
[2022-04-09 03:07:14 large] (main.py 226): INFO Train: [228/300][1300/2502]	eta 0:10:08 lr 0.000071	time 0.4767 (0.5060)	loss 3.7132 (3.0051)	grad_norm 6.5308 (nan)	mem 8929MB
[2022-04-09 03:08:03 large] (main.py 226): INFO Train: [228/300][1400/2502]	eta 0:09:16 lr 0.000071	time 0.5069 (0.5049)	loss 3.0901 (3.0023)	grad_norm 5.4756 (nan)	mem 8929MB
[2022-04-09 03:08:54 large] (main.py 226): INFO Train: [228/300][1500/2502]	eta 0:08:26 lr 0.000071	time 0.4826 (0.5052)	loss 3.4202 (3.0013)	grad_norm 6.2180 (nan)	mem 8929MB
[2022-04-09 03:09:44 large] (main.py 226): INFO Train: [228/300][1600/2502]	eta 0:07:35 lr 0.000071	time 0.5953 (0.5051)	loss 3.3096 (3.0052)	grad_norm 6.2779 (nan)	mem 8929MB
[2022-04-09 03:10:35 large] (main.py 226): INFO Train: [228/300][1700/2502]	eta 0:06:45 lr 0.000071	time 0.4784 (0.5057)	loss 2.7005 (3.0032)	grad_norm 5.2126 (nan)	mem 8929MB
[2022-04-09 03:11:27 large] (main.py 226): INFO Train: [228/300][1800/2502]	eta 0:05:55 lr 0.000071	time 0.5117 (0.5062)	loss 3.2311 (3.0015)	grad_norm 6.1580 (nan)	mem 8929MB
[2022-04-09 03:12:18 large] (main.py 226): INFO Train: [228/300][1900/2502]	eta 0:05:05 lr 0.000071	time 0.5368 (0.5067)	loss 3.3607 (3.0044)	grad_norm 6.5038 (nan)	mem 8929MB
[2022-04-09 03:13:08 large] (main.py 226): INFO Train: [228/300][2000/2502]	eta 0:04:14 lr 0.000071	time 0.5044 (0.5063)	loss 2.1978 (2.9990)	grad_norm 6.9539 (nan)	mem 8929MB
[2022-04-09 03:13:58 large] (main.py 226): INFO Train: [228/300][2100/2502]	eta 0:03:23 lr 0.000071	time 0.4891 (0.5057)	loss 3.4819 (3.0008)	grad_norm 5.0446 (nan)	mem 8929MB
[2022-04-09 03:14:49 large] (main.py 226): INFO Train: [228/300][2200/2502]	eta 0:02:32 lr 0.000071	time 0.5068 (0.5060)	loss 3.5965 (3.0041)	grad_norm 8.0196 (nan)	mem 8929MB
[2022-04-09 03:15:39 large] (main.py 226): INFO Train: [228/300][2300/2502]	eta 0:01:42 lr 0.000070	time 0.4998 (0.5056)	loss 2.8784 (3.0050)	grad_norm 4.7879 (nan)	mem 8929MB
[2022-04-09 03:16:30 large] (main.py 226): INFO Train: [228/300][2400/2502]	eta 0:00:51 lr 0.000070	time 0.5079 (0.5058)	loss 3.6907 (3.0033)	grad_norm 9.9594 (nan)	mem 8929MB
[2022-04-09 03:17:21 large] (main.py 226): INFO Train: [228/300][2500/2502]	eta 0:00:01 lr 0.000070	time 0.5018 (0.5060)	loss 2.6535 (3.0018)	grad_norm 6.7301 (nan)	mem 8929MB
[2022-04-09 03:17:22 large] (main.py 233): INFO EPOCH 228 training takes 0:21:06
[2022-04-09 03:17:28 large] (main.py 273): INFO Test: [0/98]	Time 6.000 (6.000)	Loss 0.9574 (0.9574)	Acc@1 80.078 (80.078)	Acc@5 95.703 (95.703)	Mem 8929MB
[2022-04-09 03:17:54 large] (main.py 279): INFO  * Acc@1 80.400 Acc@5 95.126
[2022-04-09 03:17:54 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 80.4%
[2022-04-09 03:17:54 large] (main.py 148): INFO Max accuracy: 80.70%
[2022-04-09 03:18:02 large] (main.py 226): INFO Train: [229/300][0/2502]	eta 5:01:15 lr 0.000070	time 7.2246 (7.2246)	loss 3.3793 (3.3793)	grad_norm 5.7274 (5.7274)	mem 8929MB
[2022-04-09 03:18:51 large] (main.py 226): INFO Train: [229/300][100/2502]	eta 0:22:37 lr 0.000070	time 0.4628 (0.5651)	loss 3.3757 (2.9765)	grad_norm 6.6482 (6.8358)	mem 8929MB
[2022-04-09 03:19:40 large] (main.py 226): INFO Train: [229/300][200/2502]	eta 0:20:08 lr 0.000070	time 0.5431 (0.5251)	loss 3.6505 (3.0018)	grad_norm 6.9628 (6.8360)	mem 8929MB
[2022-04-09 03:20:31 large] (main.py 226): INFO Train: [229/300][300/2502]	eta 0:19:03 lr 0.000070	time 0.6223 (0.5193)	loss 3.1885 (3.0213)	grad_norm 6.4842 (6.9025)	mem 8929MB
[2022-04-09 03:21:21 large] (main.py 226): INFO Train: [229/300][400/2502]	eta 0:18:01 lr 0.000070	time 0.5453 (0.5146)	loss 3.2633 (2.9980)	grad_norm 7.6564 (6.9161)	mem 8929MB
[2022-04-09 03:22:10 large] (main.py 226): INFO Train: [229/300][500/2502]	eta 0:17:03 lr 0.000070	time 0.4862 (0.5110)	loss 2.1446 (3.0056)	grad_norm 8.9971 (6.9501)	mem 8929MB
[2022-04-09 03:23:00 large] (main.py 226): INFO Train: [229/300][600/2502]	eta 0:16:07 lr 0.000070	time 0.5103 (0.5089)	loss 2.4072 (3.0136)	grad_norm 5.8650 (6.9258)	mem 8929MB
[2022-04-09 03:23:52 large] (main.py 226): INFO Train: [229/300][700/2502]	eta 0:15:19 lr 0.000070	time 0.5357 (0.5103)	loss 2.5252 (3.0131)	grad_norm 6.5012 (6.8692)	mem 8929MB
[2022-04-09 03:24:44 large] (main.py 226): INFO Train: [229/300][800/2502]	eta 0:14:30 lr 0.000070	time 0.5215 (0.5113)	loss 3.3184 (3.0124)	grad_norm 5.2984 (6.9226)	mem 8929MB
[2022-04-09 03:25:36 large] (main.py 226): INFO Train: [229/300][900/2502]	eta 0:13:40 lr 0.000070	time 0.5265 (0.5120)	loss 2.6021 (3.0175)	grad_norm 4.8133 (6.9144)	mem 8929MB
[2022-04-09 03:26:25 large] (main.py 226): INFO Train: [229/300][1000/2502]	eta 0:12:46 lr 0.000070	time 0.5099 (0.5103)	loss 3.0831 (3.0204)	grad_norm 6.2420 (7.0094)	mem 8929MB
[2022-04-09 03:27:14 large] (main.py 226): INFO Train: [229/300][1100/2502]	eta 0:11:52 lr 0.000070	time 0.5417 (0.5081)	loss 2.7546 (3.0182)	grad_norm 7.0879 (6.9734)	mem 8929MB
[2022-04-09 03:28:02 large] (main.py 226): INFO Train: [229/300][1200/2502]	eta 0:10:58 lr 0.000069	time 0.4476 (0.5059)	loss 2.7013 (3.0205)	grad_norm 5.8885 (6.9739)	mem 8929MB
[2022-04-09 03:28:51 large] (main.py 226): INFO Train: [229/300][1300/2502]	eta 0:10:06 lr 0.000069	time 0.4881 (0.5046)	loss 3.2480 (3.0205)	grad_norm 5.5407 (6.9281)	mem 8929MB
[2022-04-09 03:29:42 large] (main.py 226): INFO Train: [229/300][1400/2502]	eta 0:09:16 lr 0.000069	time 0.5329 (0.5054)	loss 1.8842 (3.0146)	grad_norm 5.5086 (nan)	mem 8929MB
[2022-04-09 03:30:33 large] (main.py 226): INFO Train: [229/300][1500/2502]	eta 0:08:26 lr 0.000069	time 0.4748 (0.5054)	loss 3.2931 (3.0166)	grad_norm 6.6309 (nan)	mem 8929MB
[2022-04-09 03:31:23 large] (main.py 226): INFO Train: [229/300][1600/2502]	eta 0:07:35 lr 0.000069	time 0.5258 (0.5049)	loss 2.0321 (3.0094)	grad_norm 5.6871 (nan)	mem 8929MB
[2022-04-09 03:32:12 large] (main.py 226): INFO Train: [229/300][1700/2502]	eta 0:06:44 lr 0.000069	time 0.4975 (0.5040)	loss 2.5538 (3.0112)	grad_norm 5.6909 (nan)	mem 8929MB
[2022-04-09 03:33:03 large] (main.py 226): INFO Train: [229/300][1800/2502]	eta 0:05:53 lr 0.000069	time 0.5264 (0.5043)	loss 3.4257 (3.0112)	grad_norm 7.2083 (nan)	mem 8929MB
[2022-04-09 03:33:54 large] (main.py 226): INFO Train: [229/300][1900/2502]	eta 0:05:03 lr 0.000069	time 0.5003 (0.5048)	loss 3.3677 (3.0120)	grad_norm 8.1562 (nan)	mem 8929MB
[2022-04-09 03:34:44 large] (main.py 226): INFO Train: [229/300][2000/2502]	eta 0:04:13 lr 0.000069	time 0.5417 (0.5046)	loss 3.2356 (3.0143)	grad_norm 9.0455 (nan)	mem 8929MB
[2022-04-09 03:35:32 large] (main.py 226): INFO Train: [229/300][2100/2502]	eta 0:03:22 lr 0.000069	time 0.5133 (0.5036)	loss 3.0656 (3.0102)	grad_norm 6.3588 (nan)	mem 8929MB
[2022-04-09 03:36:21 large] (main.py 226): INFO Train: [229/300][2200/2502]	eta 0:02:31 lr 0.000069	time 0.4928 (0.5028)	loss 3.2120 (3.0102)	grad_norm 5.6415 (nan)	mem 8929MB
[2022-04-09 03:37:10 large] (main.py 226): INFO Train: [229/300][2300/2502]	eta 0:01:41 lr 0.000069	time 0.4796 (0.5023)	loss 2.2648 (3.0068)	grad_norm 5.1426 (nan)	mem 8929MB
[2022-04-09 03:37:59 large] (main.py 226): INFO Train: [229/300][2400/2502]	eta 0:00:51 lr 0.000069	time 0.4507 (0.5019)	loss 2.8082 (3.0080)	grad_norm 20.8086 (nan)	mem 8929MB
[2022-04-09 03:38:48 large] (main.py 226): INFO Train: [229/300][2500/2502]	eta 0:00:01 lr 0.000069	time 0.4819 (0.5011)	loss 3.4328 (3.0067)	grad_norm 6.6339 (nan)	mem 8929MB
[2022-04-09 03:38:49 large] (main.py 233): INFO EPOCH 229 training takes 0:20:54
[2022-04-09 03:38:54 large] (main.py 273): INFO Test: [0/98]	Time 5.947 (5.947)	Loss 0.9911 (0.9911)	Acc@1 78.320 (78.320)	Acc@5 94.727 (94.727)	Mem 8929MB
[2022-04-09 03:39:21 large] (main.py 279): INFO  * Acc@1 80.764 Acc@5 95.212
[2022-04-09 03:39:21 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 80.8%
[2022-04-09 03:39:21 large] (utils.py 57): INFO output/large/default/ckpt_epoch_229.pth saving......
[2022-04-09 03:39:22 large] (utils.py 59): INFO output/large/default/ckpt_epoch_229.pth saved !!!
[2022-04-09 03:39:22 large] (main.py 148): INFO Max accuracy: 80.76%
[2022-04-09 03:39:30 large] (main.py 226): INFO Train: [230/300][0/2502]	eta 5:31:27 lr 0.000069	time 7.9486 (7.9486)	loss 3.5338 (3.5338)	grad_norm 5.6905 (5.6905)	mem 8929MB
[2022-04-09 03:40:20 large] (main.py 226): INFO Train: [230/300][100/2502]	eta 0:22:52 lr 0.000069	time 0.4745 (0.5713)	loss 3.1373 (2.9976)	grad_norm 5.8623 (6.7262)	mem 8929MB
[2022-04-09 03:41:09 large] (main.py 226): INFO Train: [230/300][200/2502]	eta 0:20:21 lr 0.000068	time 0.4796 (0.5306)	loss 3.2947 (3.0006)	grad_norm 6.3709 (6.9316)	mem 8929MB
[2022-04-09 03:41:58 large] (main.py 226): INFO Train: [230/300][300/2502]	eta 0:18:59 lr 0.000068	time 0.5146 (0.5176)	loss 2.0005 (2.9774)	grad_norm 7.2622 (6.8081)	mem 8929MB
[2022-04-09 03:42:48 large] (main.py 226): INFO Train: [230/300][400/2502]	eta 0:17:57 lr 0.000068	time 0.4742 (0.5128)	loss 2.8684 (2.9805)	grad_norm 5.4545 (6.7744)	mem 8929MB
[2022-04-09 03:43:38 large] (main.py 226): INFO Train: [230/300][500/2502]	eta 0:17:02 lr 0.000068	time 0.4494 (0.5105)	loss 3.3112 (2.9874)	grad_norm 7.4511 (6.7595)	mem 8929MB
[2022-04-09 03:44:28 large] (main.py 226): INFO Train: [230/300][600/2502]	eta 0:16:08 lr 0.000068	time 0.5162 (0.5091)	loss 3.5638 (2.9900)	grad_norm 6.2927 (6.7462)	mem 8929MB
[2022-04-09 03:45:18 large] (main.py 226): INFO Train: [230/300][700/2502]	eta 0:15:14 lr 0.000068	time 0.5368 (0.5075)	loss 3.3911 (2.9865)	grad_norm 6.6179 (6.7454)	mem 8929MB
[2022-04-09 03:46:07 large] (main.py 226): INFO Train: [230/300][800/2502]	eta 0:14:21 lr 0.000068	time 0.5072 (0.5061)	loss 2.3156 (2.9774)	grad_norm 5.1920 (6.7706)	mem 8929MB
[2022-04-09 03:46:59 large] (main.py 226): INFO Train: [230/300][900/2502]	eta 0:13:32 lr 0.000068	time 0.5102 (0.5072)	loss 3.2545 (2.9730)	grad_norm 6.3676 (6.7476)	mem 8929MB
[2022-04-09 03:47:49 large] (main.py 226): INFO Train: [230/300][1000/2502]	eta 0:12:40 lr 0.000068	time 0.5115 (0.5062)	loss 3.2726 (2.9696)	grad_norm 6.7799 (6.7433)	mem 8929MB
[2022-04-09 03:48:38 large] (main.py 226): INFO Train: [230/300][1100/2502]	eta 0:11:47 lr 0.000068	time 0.5585 (0.5047)	loss 3.4871 (2.9630)	grad_norm 6.2649 (6.7707)	mem 8929MB
[2022-04-09 03:49:29 large] (main.py 226): INFO Train: [230/300][1200/2502]	eta 0:10:58 lr 0.000068	time 0.4978 (0.5056)	loss 3.1811 (2.9636)	grad_norm 4.8257 (6.7921)	mem 8929MB
[2022-04-09 03:50:19 large] (main.py 226): INFO Train: [230/300][1300/2502]	eta 0:10:07 lr 0.000068	time 0.4984 (0.5054)	loss 3.3811 (2.9636)	grad_norm 6.2882 (6.7941)	mem 8929MB
[2022-04-09 03:51:10 large] (main.py 226): INFO Train: [230/300][1400/2502]	eta 0:09:16 lr 0.000068	time 0.4764 (0.5052)	loss 3.4999 (2.9654)	grad_norm 14.2708 (6.7874)	mem 8929MB
[2022-04-09 03:51:58 large] (main.py 226): INFO Train: [230/300][1500/2502]	eta 0:08:24 lr 0.000068	time 0.4889 (0.5038)	loss 3.3262 (2.9695)	grad_norm 5.4286 (6.7856)	mem 8929MB
[2022-04-09 03:52:48 large] (main.py 226): INFO Train: [230/300][1600/2502]	eta 0:07:34 lr 0.000067	time 0.4961 (0.5034)	loss 3.3400 (2.9684)	grad_norm 7.2614 (6.7929)	mem 8929MB
[2022-04-09 03:53:39 large] (main.py 226): INFO Train: [230/300][1700/2502]	eta 0:06:44 lr 0.000067	time 0.5126 (0.5041)	loss 2.0822 (2.9718)	grad_norm 5.3506 (nan)	mem 8929MB
[2022-04-09 03:54:29 large] (main.py 226): INFO Train: [230/300][1800/2502]	eta 0:05:53 lr 0.000067	time 0.4850 (0.5036)	loss 3.6526 (2.9744)	grad_norm 5.2471 (nan)	mem 8929MB
[2022-04-09 03:55:20 large] (main.py 226): INFO Train: [230/300][1900/2502]	eta 0:05:03 lr 0.000067	time 0.4780 (0.5039)	loss 3.2314 (2.9767)	grad_norm 4.7689 (nan)	mem 8929MB
[2022-04-09 03:56:08 large] (main.py 226): INFO Train: [230/300][2000/2502]	eta 0:04:12 lr 0.000067	time 0.5130 (0.5030)	loss 3.6100 (2.9763)	grad_norm 5.7766 (nan)	mem 8929MB
[2022-04-09 03:56:58 large] (main.py 226): INFO Train: [230/300][2100/2502]	eta 0:03:22 lr 0.000067	time 0.5321 (0.5029)	loss 3.1683 (2.9764)	grad_norm 5.5992 (nan)	mem 8929MB
[2022-04-09 03:57:48 large] (main.py 226): INFO Train: [230/300][2200/2502]	eta 0:02:31 lr 0.000067	time 0.4874 (0.5026)	loss 2.8305 (2.9764)	grad_norm 6.6071 (nan)	mem 8929MB
[2022-04-09 03:58:39 large] (main.py 226): INFO Train: [230/300][2300/2502]	eta 0:01:41 lr 0.000067	time 0.4548 (0.5028)	loss 3.0633 (2.9818)	grad_norm 7.9872 (nan)	mem 8929MB
[2022-04-09 03:59:27 large] (main.py 226): INFO Train: [230/300][2400/2502]	eta 0:00:51 lr 0.000067	time 0.4831 (0.5020)	loss 2.0621 (2.9787)	grad_norm 6.1176 (nan)	mem 8929MB
[2022-04-09 04:00:16 large] (main.py 226): INFO Train: [230/300][2500/2502]	eta 0:00:01 lr 0.000067	time 0.4951 (0.5015)	loss 3.2366 (2.9823)	grad_norm 7.0448 (nan)	mem 8929MB
[2022-04-09 04:00:17 large] (main.py 233): INFO EPOCH 230 training takes 0:20:55
[2022-04-09 04:00:24 large] (main.py 273): INFO Test: [0/98]	Time 6.380 (6.380)	Loss 1.0592 (1.0592)	Acc@1 80.078 (80.078)	Acc@5 93.945 (93.945)	Mem 8929MB
[2022-04-09 04:00:50 large] (main.py 279): INFO  * Acc@1 80.550 Acc@5 95.212
[2022-04-09 04:00:50 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 80.5%
[2022-04-09 04:00:50 large] (main.py 148): INFO Max accuracy: 80.76%
[2022-04-09 04:00:56 large] (main.py 226): INFO Train: [231/300][0/2502]	eta 4:38:42 lr 0.000067	time 6.6836 (6.6836)	loss 3.4328 (3.4328)	grad_norm 8.3610 (8.3610)	mem 8929MB
[2022-04-09 04:01:47 large] (main.py 226): INFO Train: [231/300][100/2502]	eta 0:22:39 lr 0.000067	time 0.4889 (0.5660)	loss 3.2631 (2.9698)	grad_norm 5.6476 (6.4196)	mem 8929MB
[2022-04-09 04:02:35 large] (main.py 226): INFO Train: [231/300][200/2502]	eta 0:20:06 lr 0.000067	time 0.4771 (0.5243)	loss 3.3608 (2.9655)	grad_norm 7.3105 (6.7285)	mem 8929MB
[2022-04-09 04:03:24 large] (main.py 226): INFO Train: [231/300][300/2502]	eta 0:18:47 lr 0.000067	time 0.5089 (0.5122)	loss 3.2732 (2.9585)	grad_norm 7.8435 (6.5984)	mem 8929MB
[2022-04-09 04:04:15 large] (main.py 226): INFO Train: [231/300][400/2502]	eta 0:17:55 lr 0.000067	time 0.5142 (0.5116)	loss 3.0917 (2.9828)	grad_norm 6.6756 (6.6360)	mem 8929MB
[2022-04-09 04:05:07 large] (main.py 226): INFO Train: [231/300][500/2502]	eta 0:17:08 lr 0.000067	time 0.5189 (0.5138)	loss 3.1020 (2.9776)	grad_norm 8.9098 (6.6725)	mem 8929MB
[2022-04-09 04:05:59 large] (main.py 226): INFO Train: [231/300][600/2502]	eta 0:16:19 lr 0.000066	time 0.5584 (0.5147)	loss 3.4102 (2.9773)	grad_norm 8.3563 (6.6920)	mem 8929MB
[2022-04-09 04:06:48 large] (main.py 226): INFO Train: [231/300][700/2502]	eta 0:15:21 lr 0.000066	time 0.4774 (0.5116)	loss 2.4693 (2.9758)	grad_norm 6.5730 (6.7337)	mem 8929MB
[2022-04-09 04:07:36 large] (main.py 226): INFO Train: [231/300][800/2502]	eta 0:14:24 lr 0.000066	time 0.4904 (0.5078)	loss 2.4584 (2.9756)	grad_norm 7.4277 (6.7279)	mem 8929MB
[2022-04-09 04:08:25 large] (main.py 226): INFO Train: [231/300][900/2502]	eta 0:13:29 lr 0.000066	time 0.4981 (0.5053)	loss 2.5771 (2.9766)	grad_norm 6.6663 (6.7295)	mem 8929MB
[2022-04-09 04:09:16 large] (main.py 226): INFO Train: [231/300][1000/2502]	eta 0:12:39 lr 0.000066	time 0.5210 (0.5058)	loss 3.4450 (2.9819)	grad_norm 6.8916 (6.7771)	mem 8929MB
[2022-04-09 04:10:08 large] (main.py 226): INFO Train: [231/300][1100/2502]	eta 0:11:50 lr 0.000066	time 0.5120 (0.5069)	loss 3.0026 (2.9767)	grad_norm 9.6079 (6.7746)	mem 8929MB
[2022-04-09 04:11:00 large] (main.py 226): INFO Train: [231/300][1200/2502]	eta 0:11:01 lr 0.000066	time 0.5351 (0.5078)	loss 3.3062 (2.9696)	grad_norm 5.5079 (6.8169)	mem 8929MB
[2022-04-09 04:11:50 large] (main.py 226): INFO Train: [231/300][1300/2502]	eta 0:10:10 lr 0.000066	time 0.4561 (0.5075)	loss 3.3079 (2.9671)	grad_norm 8.0026 (6.8154)	mem 8929MB
[2022-04-09 04:12:40 large] (main.py 226): INFO Train: [231/300][1400/2502]	eta 0:09:18 lr 0.000066	time 0.5063 (0.5067)	loss 3.5653 (2.9702)	grad_norm 12.8228 (6.8250)	mem 8929MB
[2022-04-09 04:13:31 large] (main.py 226): INFO Train: [231/300][1500/2502]	eta 0:08:28 lr 0.000066	time 0.5124 (0.5072)	loss 2.6338 (2.9703)	grad_norm 5.3279 (6.8557)	mem 8929MB
[2022-04-09 04:14:23 large] (main.py 226): INFO Train: [231/300][1600/2502]	eta 0:07:37 lr 0.000066	time 0.5009 (0.5077)	loss 3.6361 (2.9739)	grad_norm 9.0188 (6.9345)	mem 8929MB
[2022-04-09 04:15:12 large] (main.py 226): INFO Train: [231/300][1700/2502]	eta 0:06:46 lr 0.000066	time 0.5654 (0.5070)	loss 2.9335 (2.9754)	grad_norm 7.6243 (6.9609)	mem 8929MB
[2022-04-09 04:16:01 large] (main.py 226): INFO Train: [231/300][1800/2502]	eta 0:05:55 lr 0.000066	time 0.4701 (0.5058)	loss 2.5043 (2.9771)	grad_norm 5.7935 (6.9517)	mem 8929MB
[2022-04-09 04:16:49 large] (main.py 226): INFO Train: [231/300][1900/2502]	eta 0:05:03 lr 0.000066	time 0.5054 (0.5047)	loss 3.1613 (2.9756)	grad_norm 5.6985 (6.9405)	mem 8929MB
[2022-04-09 04:17:39 large] (main.py 226): INFO Train: [231/300][2000/2502]	eta 0:04:13 lr 0.000065	time 0.4913 (0.5042)	loss 1.9102 (2.9742)	grad_norm 5.0623 (6.9347)	mem 8929MB
[2022-04-09 04:18:29 large] (main.py 226): INFO Train: [231/300][2100/2502]	eta 0:03:22 lr 0.000065	time 0.4955 (0.5040)	loss 2.9689 (2.9760)	grad_norm 7.4134 (6.9211)	mem 8929MB
[2022-04-09 04:19:18 large] (main.py 226): INFO Train: [231/300][2200/2502]	eta 0:02:32 lr 0.000065	time 0.4629 (0.5036)	loss 1.9405 (2.9765)	grad_norm 9.9262 (6.9572)	mem 8929MB
[2022-04-09 04:20:08 large] (main.py 226): INFO Train: [231/300][2300/2502]	eta 0:01:41 lr 0.000065	time 0.4753 (0.5034)	loss 3.4525 (2.9749)	grad_norm 6.3954 (6.9555)	mem 8929MB
[2022-04-09 04:20:58 large] (main.py 226): INFO Train: [231/300][2400/2502]	eta 0:00:51 lr 0.000065	time 0.4755 (0.5031)	loss 2.8307 (2.9745)	grad_norm 12.3812 (6.9616)	mem 8929MB
[2022-04-09 04:21:46 large] (main.py 226): INFO Train: [231/300][2500/2502]	eta 0:00:01 lr 0.000065	time 0.4564 (0.5022)	loss 2.8124 (2.9760)	grad_norm 6.6701 (6.9708)	mem 8929MB
[2022-04-09 04:21:47 large] (main.py 233): INFO EPOCH 231 training takes 0:20:57
[2022-04-09 04:21:53 large] (main.py 273): INFO Test: [0/98]	Time 5.892 (5.892)	Loss 0.9241 (0.9241)	Acc@1 81.250 (81.250)	Acc@5 95.508 (95.508)	Mem 8929MB
[2022-04-09 04:22:19 large] (main.py 279): INFO  * Acc@1 80.828 Acc@5 95.222
[2022-04-09 04:22:19 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 80.8%
[2022-04-09 04:22:19 large] (utils.py 57): INFO output/large/default/ckpt_epoch_231.pth saving......
[2022-04-09 04:22:20 large] (utils.py 59): INFO output/large/default/ckpt_epoch_231.pth saved !!!
[2022-04-09 04:22:20 large] (main.py 148): INFO Max accuracy: 80.83%
[2022-04-09 04:22:28 large] (main.py 226): INFO Train: [232/300][0/2502]	eta 5:14:53 lr 0.000065	time 7.5515 (7.5515)	loss 3.2268 (3.2268)	grad_norm 4.9463 (4.9463)	mem 8929MB
[2022-04-09 04:23:18 large] (main.py 226): INFO Train: [232/300][100/2502]	eta 0:23:03 lr 0.000065	time 0.5079 (0.5759)	loss 3.4521 (2.9600)	grad_norm 6.8651 (6.9140)	mem 8929MB
[2022-04-09 04:24:10 large] (main.py 226): INFO Train: [232/300][200/2502]	eta 0:21:02 lr 0.000065	time 0.5098 (0.5485)	loss 3.6811 (2.9811)	grad_norm 5.3660 (7.0405)	mem 8929MB
[2022-04-09 04:25:01 large] (main.py 226): INFO Train: [232/300][300/2502]	eta 0:19:39 lr 0.000065	time 0.4976 (0.5356)	loss 3.0132 (2.9713)	grad_norm 6.9188 (6.9812)	mem 8929MB
[2022-04-09 04:25:51 large] (main.py 226): INFO Train: [232/300][400/2502]	eta 0:18:24 lr 0.000065	time 0.4919 (0.5255)	loss 3.4602 (2.9755)	grad_norm 6.5787 (6.9964)	mem 8929MB
[2022-04-09 04:26:42 large] (main.py 226): INFO Train: [232/300][500/2502]	eta 0:17:25 lr 0.000065	time 0.5122 (0.5224)	loss 2.3544 (2.9614)	grad_norm 8.2460 (7.0033)	mem 8929MB
[2022-04-09 04:27:30 large] (main.py 226): INFO Train: [232/300][600/2502]	eta 0:16:22 lr 0.000065	time 0.5806 (0.5164)	loss 3.2783 (2.9482)	grad_norm 7.6094 (6.9987)	mem 8929MB
[2022-04-09 04:28:21 large] (main.py 226): INFO Train: [232/300][700/2502]	eta 0:15:27 lr 0.000065	time 0.4808 (0.5149)	loss 2.0701 (2.9608)	grad_norm 5.3863 (7.0750)	mem 8929MB
[2022-04-09 04:29:11 large] (main.py 226): INFO Train: [232/300][800/2502]	eta 0:14:33 lr 0.000065	time 0.5558 (0.5130)	loss 3.5255 (2.9620)	grad_norm 10.0267 (nan)	mem 8929MB
[2022-04-09 04:30:02 large] (main.py 226): INFO Train: [232/300][900/2502]	eta 0:13:42 lr 0.000065	time 0.4983 (0.5133)	loss 2.9030 (2.9725)	grad_norm 5.7489 (nan)	mem 8929MB
[2022-04-09 04:30:53 large] (main.py 226): INFO Train: [232/300][1000/2502]	eta 0:12:49 lr 0.000064	time 0.4887 (0.5123)	loss 2.9956 (2.9695)	grad_norm 7.1375 (nan)	mem 8929MB
[2022-04-09 04:31:43 large] (main.py 226): INFO Train: [232/300][1100/2502]	eta 0:11:57 lr 0.000064	time 0.5243 (0.5115)	loss 3.2863 (2.9650)	grad_norm 7.3661 (nan)	mem 8929MB
[2022-04-09 04:32:33 large] (main.py 226): INFO Train: [232/300][1200/2502]	eta 0:11:04 lr 0.000064	time 0.5077 (0.5102)	loss 3.2228 (2.9676)	grad_norm 6.0813 (nan)	mem 8929MB
[2022-04-09 04:33:24 large] (main.py 226): INFO Train: [232/300][1300/2502]	eta 0:10:13 lr 0.000064	time 0.5768 (0.5103)	loss 3.2387 (2.9623)	grad_norm 13.6634 (nan)	mem 8929MB
[2022-04-09 04:34:14 large] (main.py 226): INFO Train: [232/300][1400/2502]	eta 0:09:21 lr 0.000064	time 0.4734 (0.5099)	loss 2.4996 (2.9621)	grad_norm 8.6551 (nan)	mem 8929MB
[2022-04-09 04:35:03 large] (main.py 226): INFO Train: [232/300][1500/2502]	eta 0:08:29 lr 0.000064	time 0.4987 (0.5085)	loss 3.1814 (2.9662)	grad_norm 5.9963 (nan)	mem 8929MB
[2022-04-09 04:35:53 large] (main.py 226): INFO Train: [232/300][1600/2502]	eta 0:07:37 lr 0.000064	time 0.4858 (0.5077)	loss 2.6247 (2.9668)	grad_norm 6.2830 (nan)	mem 8929MB
[2022-04-09 04:36:42 large] (main.py 226): INFO Train: [232/300][1700/2502]	eta 0:06:46 lr 0.000064	time 0.4917 (0.5065)	loss 3.3668 (2.9633)	grad_norm 8.1025 (nan)	mem 8929MB
[2022-04-09 04:37:32 large] (main.py 226): INFO Train: [232/300][1800/2502]	eta 0:05:55 lr 0.000064	time 0.4904 (0.5063)	loss 3.4532 (2.9632)	grad_norm 5.0589 (nan)	mem 8929MB
[2022-04-09 04:38:21 large] (main.py 226): INFO Train: [232/300][1900/2502]	eta 0:05:04 lr 0.000064	time 0.4819 (0.5054)	loss 2.7589 (2.9595)	grad_norm 6.8844 (nan)	mem 8929MB
[2022-04-09 04:39:09 large] (main.py 226): INFO Train: [232/300][2000/2502]	eta 0:04:13 lr 0.000064	time 0.4886 (0.5044)	loss 3.1720 (2.9640)	grad_norm 6.2519 (nan)	mem 8929MB
[2022-04-09 04:40:00 large] (main.py 226): INFO Train: [232/300][2100/2502]	eta 0:03:22 lr 0.000064	time 0.5038 (0.5046)	loss 2.1486 (2.9630)	grad_norm 5.5587 (nan)	mem 8929MB
[2022-04-09 04:40:52 large] (main.py 226): INFO Train: [232/300][2200/2502]	eta 0:02:32 lr 0.000064	time 0.5847 (0.5052)	loss 2.5629 (2.9609)	grad_norm 7.6655 (nan)	mem 8929MB
[2022-04-09 04:41:42 large] (main.py 226): INFO Train: [232/300][2300/2502]	eta 0:01:41 lr 0.000064	time 0.5127 (0.5048)	loss 2.8130 (2.9603)	grad_norm 9.9884 (nan)	mem 8929MB
[2022-04-09 04:42:33 large] (main.py 226): INFO Train: [232/300][2400/2502]	eta 0:00:51 lr 0.000064	time 0.5028 (0.5050)	loss 1.8910 (2.9604)	grad_norm 6.1935 (nan)	mem 8929MB
[2022-04-09 04:43:22 large] (main.py 226): INFO Train: [232/300][2500/2502]	eta 0:00:01 lr 0.000063	time 0.5009 (0.5047)	loss 3.3785 (2.9581)	grad_norm 6.0157 (nan)	mem 8929MB
[2022-04-09 04:43:23 large] (main.py 233): INFO EPOCH 232 training takes 0:21:03
[2022-04-09 04:43:30 large] (main.py 273): INFO Test: [0/98]	Time 7.011 (7.011)	Loss 1.0455 (1.0455)	Acc@1 79.102 (79.102)	Acc@5 96.094 (96.094)	Mem 8929MB
[2022-04-09 04:43:56 large] (main.py 279): INFO  * Acc@1 80.594 Acc@5 95.264
[2022-04-09 04:43:56 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 80.6%
[2022-04-09 04:43:56 large] (main.py 148): INFO Max accuracy: 80.83%
[2022-04-09 04:44:02 large] (main.py 226): INFO Train: [233/300][0/2502]	eta 4:29:59 lr 0.000063	time 6.4747 (6.4747)	loss 3.0300 (3.0300)	grad_norm 7.4917 (7.4917)	mem 8929MB
[2022-04-09 04:44:54 large] (main.py 226): INFO Train: [233/300][100/2502]	eta 0:23:04 lr 0.000063	time 0.4754 (0.5764)	loss 3.2182 (2.9674)	grad_norm 7.3813 (6.9321)	mem 8929MB
[2022-04-09 04:45:43 large] (main.py 226): INFO Train: [233/300][200/2502]	eta 0:20:24 lr 0.000063	time 0.5311 (0.5320)	loss 2.8504 (2.9588)	grad_norm 9.8710 (6.9122)	mem 8929MB
[2022-04-09 04:46:31 large] (main.py 226): INFO Train: [233/300][300/2502]	eta 0:18:53 lr 0.000063	time 0.4470 (0.5147)	loss 3.0798 (2.9543)	grad_norm 6.4762 (6.9496)	mem 8929MB
[2022-04-09 04:47:21 large] (main.py 226): INFO Train: [233/300][400/2502]	eta 0:17:55 lr 0.000063	time 0.5213 (0.5115)	loss 2.4880 (2.9636)	grad_norm 6.4910 (6.9249)	mem 8929MB
[2022-04-09 04:48:13 large] (main.py 226): INFO Train: [233/300][500/2502]	eta 0:17:06 lr 0.000063	time 0.5252 (0.5125)	loss 2.9200 (2.9722)	grad_norm 7.5259 (6.9982)	mem 8929MB
[2022-04-09 04:49:03 large] (main.py 226): INFO Train: [233/300][600/2502]	eta 0:16:10 lr 0.000063	time 0.5029 (0.5104)	loss 2.9472 (2.9718)	grad_norm 5.6508 (7.0179)	mem 8929MB
[2022-04-09 04:49:54 large] (main.py 226): INFO Train: [233/300][700/2502]	eta 0:15:20 lr 0.000063	time 0.5692 (0.5106)	loss 2.6803 (2.9708)	grad_norm 5.0408 (6.9518)	mem 8929MB
[2022-04-09 04:50:45 large] (main.py 226): INFO Train: [233/300][800/2502]	eta 0:14:28 lr 0.000063	time 0.4892 (0.5103)	loss 3.5136 (2.9713)	grad_norm 8.6829 (6.9039)	mem 8929MB
[2022-04-09 04:51:34 large] (main.py 226): INFO Train: [233/300][900/2502]	eta 0:13:34 lr 0.000063	time 0.4988 (0.5082)	loss 3.2032 (2.9758)	grad_norm 7.8530 (6.8812)	mem 8929MB
[2022-04-09 04:52:24 large] (main.py 226): INFO Train: [233/300][1000/2502]	eta 0:12:42 lr 0.000063	time 0.4840 (0.5079)	loss 2.8945 (2.9765)	grad_norm 4.6814 (6.8126)	mem 8929MB
[2022-04-09 04:53:14 large] (main.py 226): INFO Train: [233/300][1100/2502]	eta 0:11:50 lr 0.000063	time 0.5307 (0.5070)	loss 3.0886 (2.9800)	grad_norm 5.8886 (6.8261)	mem 8929MB
[2022-04-09 04:54:04 large] (main.py 226): INFO Train: [233/300][1200/2502]	eta 0:10:58 lr 0.000063	time 0.4965 (0.5060)	loss 3.0457 (2.9752)	grad_norm 5.2106 (6.8333)	mem 8929MB
[2022-04-09 04:54:55 large] (main.py 226): INFO Train: [233/300][1300/2502]	eta 0:10:08 lr 0.000063	time 0.4985 (0.5065)	loss 3.3628 (2.9795)	grad_norm 7.6782 (6.8552)	mem 8929MB
[2022-04-09 04:55:46 large] (main.py 226): INFO Train: [233/300][1400/2502]	eta 0:09:18 lr 0.000063	time 0.5315 (0.5070)	loss 1.8187 (2.9779)	grad_norm 5.2023 (6.8340)	mem 8929MB
[2022-04-09 04:56:35 large] (main.py 226): INFO Train: [233/300][1500/2502]	eta 0:08:26 lr 0.000062	time 0.5075 (0.5059)	loss 3.7685 (2.9799)	grad_norm 8.4155 (6.8974)	mem 8929MB
[2022-04-09 04:57:24 large] (main.py 226): INFO Train: [233/300][1600/2502]	eta 0:07:35 lr 0.000062	time 0.4982 (0.5048)	loss 2.1293 (2.9797)	grad_norm 5.6222 (nan)	mem 8929MB
[2022-04-09 04:58:13 large] (main.py 226): INFO Train: [233/300][1700/2502]	eta 0:06:44 lr 0.000062	time 0.4916 (0.5042)	loss 3.0362 (2.9809)	grad_norm 5.7901 (nan)	mem 8929MB
[2022-04-09 04:59:04 large] (main.py 226): INFO Train: [233/300][1800/2502]	eta 0:05:53 lr 0.000062	time 0.5146 (0.5042)	loss 2.1411 (2.9831)	grad_norm 6.4553 (nan)	mem 8929MB
[2022-04-09 04:59:55 large] (main.py 226): INFO Train: [233/300][1900/2502]	eta 0:05:03 lr 0.000062	time 0.5102 (0.5044)	loss 3.0114 (2.9839)	grad_norm 7.3783 (nan)	mem 8929MB
[2022-04-09 05:00:45 large] (main.py 226): INFO Train: [233/300][2000/2502]	eta 0:04:13 lr 0.000062	time 0.4540 (0.5043)	loss 3.0794 (2.9780)	grad_norm 6.6067 (nan)	mem 8929MB
[2022-04-09 05:01:34 large] (main.py 226): INFO Train: [233/300][2100/2502]	eta 0:03:22 lr 0.000062	time 0.4709 (0.5038)	loss 3.0037 (2.9787)	grad_norm 5.7129 (nan)	mem 8929MB
[2022-04-09 05:02:24 large] (main.py 226): INFO Train: [233/300][2200/2502]	eta 0:02:32 lr 0.000062	time 0.5050 (0.5036)	loss 3.5293 (2.9762)	grad_norm 7.7351 (nan)	mem 8929MB
[2022-04-09 05:03:15 large] (main.py 226): INFO Train: [233/300][2300/2502]	eta 0:01:41 lr 0.000062	time 0.6026 (0.5035)	loss 2.9398 (2.9783)	grad_norm 8.4488 (nan)	mem 8929MB
[2022-04-09 05:04:04 large] (main.py 226): INFO Train: [233/300][2400/2502]	eta 0:00:51 lr 0.000062	time 0.4917 (0.5031)	loss 3.0051 (2.9794)	grad_norm 5.9318 (nan)	mem 8929MB
[2022-04-09 05:04:54 large] (main.py 226): INFO Train: [233/300][2500/2502]	eta 0:00:01 lr 0.000062	time 0.4804 (0.5029)	loss 3.5540 (2.9831)	grad_norm 5.6822 (nan)	mem 8929MB
[2022-04-09 05:04:55 large] (main.py 233): INFO EPOCH 233 training takes 0:20:58
[2022-04-09 05:05:00 large] (main.py 273): INFO Test: [0/98]	Time 5.898 (5.898)	Loss 1.0121 (1.0121)	Acc@1 80.469 (80.469)	Acc@5 94.922 (94.922)	Mem 8929MB
[2022-04-09 05:05:27 large] (main.py 279): INFO  * Acc@1 80.562 Acc@5 95.196
[2022-04-09 05:05:27 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 80.6%
[2022-04-09 05:05:27 large] (main.py 148): INFO Max accuracy: 80.83%
[2022-04-09 05:05:34 large] (main.py 226): INFO Train: [234/300][0/2502]	eta 5:10:57 lr 0.000062	time 7.4570 (7.4570)	loss 2.0567 (2.0567)	grad_norm 6.3679 (6.3679)	mem 8929MB
[2022-04-09 05:06:24 large] (main.py 226): INFO Train: [234/300][100/2502]	eta 0:22:42 lr 0.000062	time 0.4839 (0.5671)	loss 3.1673 (2.9825)	grad_norm 6.0734 (6.4860)	mem 8929MB
[2022-04-09 05:07:15 large] (main.py 226): INFO Train: [234/300][200/2502]	eta 0:20:37 lr 0.000062	time 0.5788 (0.5375)	loss 2.4904 (2.9947)	grad_norm 6.7687 (6.6124)	mem 8929MB
[2022-04-09 05:08:07 large] (main.py 226): INFO Train: [234/300][300/2502]	eta 0:19:32 lr 0.000062	time 0.4918 (0.5326)	loss 2.9320 (2.9543)	grad_norm 6.1499 (6.9081)	mem 8929MB
[2022-04-09 05:08:57 large] (main.py 226): INFO Train: [234/300][400/2502]	eta 0:18:22 lr 0.000062	time 0.5031 (0.5243)	loss 2.6129 (2.9534)	grad_norm 6.5480 (6.9731)	mem 8929MB
[2022-04-09 05:09:47 large] (main.py 226): INFO Train: [234/300][500/2502]	eta 0:17:20 lr 0.000061	time 0.4911 (0.5195)	loss 2.8836 (2.9566)	grad_norm 6.9937 (7.0251)	mem 8929MB
[2022-04-09 05:10:36 large] (main.py 226): INFO Train: [234/300][600/2502]	eta 0:16:20 lr 0.000061	time 0.5243 (0.5155)	loss 3.3618 (2.9619)	grad_norm 6.6907 (6.9947)	mem 8929MB
[2022-04-09 05:11:27 large] (main.py 226): INFO Train: [234/300][700/2502]	eta 0:15:26 lr 0.000061	time 0.5507 (0.5144)	loss 2.9802 (2.9624)	grad_norm 6.1335 (7.0860)	mem 8929MB
[2022-04-09 05:12:18 large] (main.py 226): INFO Train: [234/300][800/2502]	eta 0:14:34 lr 0.000061	time 0.5049 (0.5141)	loss 3.1086 (2.9672)	grad_norm 7.0956 (7.0895)	mem 8929MB
[2022-04-09 05:13:10 large] (main.py 226): INFO Train: [234/300][900/2502]	eta 0:13:43 lr 0.000061	time 0.5056 (0.5143)	loss 3.2775 (2.9631)	grad_norm 5.1147 (7.0744)	mem 8929MB
[2022-04-09 05:14:00 large] (main.py 226): INFO Train: [234/300][1000/2502]	eta 0:12:50 lr 0.000061	time 0.4889 (0.5130)	loss 3.4097 (2.9641)	grad_norm 9.4593 (7.0693)	mem 8929MB
[2022-04-09 05:14:49 large] (main.py 226): INFO Train: [234/300][1100/2502]	eta 0:11:56 lr 0.000061	time 0.4930 (0.5111)	loss 2.5540 (2.9614)	grad_norm 7.1118 (nan)	mem 8929MB
[2022-04-09 05:15:38 large] (main.py 226): INFO Train: [234/300][1200/2502]	eta 0:11:03 lr 0.000061	time 0.4763 (0.5095)	loss 3.4636 (2.9659)	grad_norm 6.3537 (nan)	mem 8929MB
[2022-04-09 05:16:29 large] (main.py 226): INFO Train: [234/300][1300/2502]	eta 0:10:12 lr 0.000061	time 0.5202 (0.5094)	loss 2.2343 (2.9642)	grad_norm 12.3847 (nan)	mem 8929MB
[2022-04-09 05:17:21 large] (main.py 226): INFO Train: [234/300][1400/2502]	eta 0:09:21 lr 0.000061	time 0.5835 (0.5096)	loss 2.7638 (2.9598)	grad_norm 6.0508 (nan)	mem 8929MB
[2022-04-09 05:18:10 large] (main.py 226): INFO Train: [234/300][1500/2502]	eta 0:08:29 lr 0.000061	time 0.5436 (0.5087)	loss 3.3191 (2.9628)	grad_norm 7.0318 (nan)	mem 8929MB
[2022-04-09 05:19:01 large] (main.py 226): INFO Train: [234/300][1600/2502]	eta 0:07:38 lr 0.000061	time 0.5149 (0.5088)	loss 2.1817 (2.9576)	grad_norm 8.5247 (nan)	mem 8929MB
[2022-04-09 05:19:52 large] (main.py 226): INFO Train: [234/300][1700/2502]	eta 0:06:48 lr 0.000061	time 0.5038 (0.5090)	loss 3.4016 (2.9552)	grad_norm 5.9122 (nan)	mem 8929MB
[2022-04-09 05:20:42 large] (main.py 226): INFO Train: [234/300][1800/2502]	eta 0:05:56 lr 0.000061	time 0.4536 (0.5081)	loss 3.5013 (2.9584)	grad_norm 6.0831 (nan)	mem 8929MB
[2022-04-09 05:21:32 large] (main.py 226): INFO Train: [234/300][1900/2502]	eta 0:05:05 lr 0.000061	time 0.4880 (0.5077)	loss 3.1119 (2.9611)	grad_norm 7.0527 (nan)	mem 8929MB
[2022-04-09 05:22:22 large] (main.py 226): INFO Train: [234/300][2000/2502]	eta 0:04:14 lr 0.000060	time 0.5112 (0.5074)	loss 2.8445 (2.9592)	grad_norm 7.5454 (nan)	mem 8929MB
[2022-04-09 05:23:13 large] (main.py 226): INFO Train: [234/300][2100/2502]	eta 0:03:24 lr 0.000060	time 0.5144 (0.5076)	loss 3.2105 (2.9606)	grad_norm 6.0122 (nan)	mem 8929MB
[2022-04-09 05:24:04 large] (main.py 226): INFO Train: [234/300][2200/2502]	eta 0:02:33 lr 0.000060	time 0.5011 (0.5079)	loss 3.4874 (2.9619)	grad_norm 6.7635 (nan)	mem 8929MB
[2022-04-09 05:24:56 large] (main.py 226): INFO Train: [234/300][2300/2502]	eta 0:01:42 lr 0.000060	time 0.4980 (0.5081)	loss 3.2728 (2.9642)	grad_norm 6.9695 (nan)	mem 8929MB
[2022-04-09 05:25:45 large] (main.py 226): INFO Train: [234/300][2400/2502]	eta 0:00:51 lr 0.000060	time 0.4843 (0.5076)	loss 3.5989 (2.9687)	grad_norm 6.6917 (nan)	mem 8929MB
[2022-04-09 05:26:34 large] (main.py 226): INFO Train: [234/300][2500/2502]	eta 0:00:01 lr 0.000060	time 0.4974 (0.5069)	loss 2.6270 (2.9690)	grad_norm 6.3790 (nan)	mem 8929MB
[2022-04-09 05:26:35 large] (main.py 233): INFO EPOCH 234 training takes 0:21:08
[2022-04-09 05:26:41 large] (main.py 273): INFO Test: [0/98]	Time 6.015 (6.015)	Loss 1.0914 (1.0914)	Acc@1 77.148 (77.148)	Acc@5 93.945 (93.945)	Mem 8929MB
[2022-04-09 05:27:08 large] (main.py 279): INFO  * Acc@1 80.654 Acc@5 95.188
[2022-04-09 05:27:08 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 80.7%
[2022-04-09 05:27:08 large] (main.py 148): INFO Max accuracy: 80.83%
[2022-04-09 05:27:15 large] (main.py 226): INFO Train: [235/300][0/2502]	eta 5:14:59 lr 0.000060	time 7.5537 (7.5537)	loss 2.5461 (2.5461)	grad_norm 6.6300 (6.6300)	mem 8929MB
[2022-04-09 05:28:05 large] (main.py 226): INFO Train: [235/300][100/2502]	eta 0:22:38 lr 0.000060	time 0.4905 (0.5654)	loss 3.3929 (2.9737)	grad_norm 4.7647 (7.0534)	mem 8929MB
[2022-04-09 05:28:53 large] (main.py 226): INFO Train: [235/300][200/2502]	eta 0:20:13 lr 0.000060	time 0.4628 (0.5270)	loss 3.0053 (2.9664)	grad_norm 4.4650 (6.8714)	mem 8929MB
[2022-04-09 05:29:45 large] (main.py 226): INFO Train: [235/300][300/2502]	eta 0:19:12 lr 0.000060	time 0.5829 (0.5235)	loss 2.1519 (2.9851)	grad_norm 6.6102 (6.9910)	mem 8929MB
[2022-04-09 05:30:37 large] (main.py 226): INFO Train: [235/300][400/2502]	eta 0:18:18 lr 0.000060	time 0.5131 (0.5225)	loss 1.6946 (2.9995)	grad_norm 5.3452 (7.1123)	mem 8929MB
[2022-04-09 05:31:27 large] (main.py 226): INFO Train: [235/300][500/2502]	eta 0:17:17 lr 0.000060	time 0.4913 (0.5182)	loss 2.6794 (2.9937)	grad_norm 7.7142 (7.1160)	mem 8929MB
[2022-04-09 05:32:16 large] (main.py 226): INFO Train: [235/300][600/2502]	eta 0:16:15 lr 0.000060	time 0.4944 (0.5126)	loss 2.9098 (2.9955)	grad_norm 7.1659 (7.1384)	mem 8929MB
[2022-04-09 05:33:04 large] (main.py 226): INFO Train: [235/300][700/2502]	eta 0:15:16 lr 0.000060	time 0.5237 (0.5089)	loss 2.0086 (2.9902)	grad_norm 6.6724 (nan)	mem 8929MB
[2022-04-09 05:33:53 large] (main.py 226): INFO Train: [235/300][800/2502]	eta 0:14:22 lr 0.000060	time 0.4982 (0.5066)	loss 2.4735 (2.9832)	grad_norm 8.1697 (nan)	mem 8929MB
[2022-04-09 05:34:45 large] (main.py 226): INFO Train: [235/300][900/2502]	eta 0:13:33 lr 0.000060	time 0.5049 (0.5077)	loss 2.7533 (2.9864)	grad_norm 8.7173 (nan)	mem 8929MB
[2022-04-09 05:35:33 large] (main.py 226): INFO Train: [235/300][1000/2502]	eta 0:12:38 lr 0.000060	time 0.5129 (0.5053)	loss 2.4844 (2.9899)	grad_norm 6.0098 (nan)	mem 8929MB
[2022-04-09 05:36:23 large] (main.py 226): INFO Train: [235/300][1100/2502]	eta 0:11:47 lr 0.000059	time 0.5304 (0.5043)	loss 3.3037 (2.9859)	grad_norm 5.6655 (nan)	mem 8929MB
[2022-04-09 05:37:12 large] (main.py 226): INFO Train: [235/300][1200/2502]	eta 0:10:54 lr 0.000059	time 0.5901 (0.5030)	loss 3.5373 (2.9810)	grad_norm 8.5350 (nan)	mem 8929MB
[2022-04-09 05:38:02 large] (main.py 226): INFO Train: [235/300][1300/2502]	eta 0:10:05 lr 0.000059	time 0.5185 (0.5034)	loss 3.5678 (2.9860)	grad_norm 6.5164 (nan)	mem 8929MB
[2022-04-09 05:38:54 large] (main.py 226): INFO Train: [235/300][1400/2502]	eta 0:09:15 lr 0.000059	time 0.4923 (0.5043)	loss 3.1534 (2.9768)	grad_norm 6.8717 (nan)	mem 8929MB
[2022-04-09 05:39:44 large] (main.py 226): INFO Train: [235/300][1500/2502]	eta 0:08:24 lr 0.000059	time 0.4988 (0.5038)	loss 2.1968 (2.9741)	grad_norm 7.3219 (nan)	mem 8929MB
[2022-04-09 05:40:35 large] (main.py 226): INFO Train: [235/300][1600/2502]	eta 0:07:34 lr 0.000059	time 0.5584 (0.5043)	loss 3.3337 (2.9729)	grad_norm 6.2166 (nan)	mem 8929MB
[2022-04-09 05:41:25 large] (main.py 226): INFO Train: [235/300][1700/2502]	eta 0:06:44 lr 0.000059	time 0.5137 (0.5040)	loss 3.3551 (2.9764)	grad_norm 9.9952 (nan)	mem 8929MB
[2022-04-09 05:42:14 large] (main.py 226): INFO Train: [235/300][1800/2502]	eta 0:05:53 lr 0.000059	time 0.5089 (0.5034)	loss 3.4050 (2.9785)	grad_norm 6.4787 (nan)	mem 8929MB
[2022-04-09 05:43:05 large] (main.py 226): INFO Train: [235/300][1900/2502]	eta 0:05:03 lr 0.000059	time 0.5064 (0.5037)	loss 3.3976 (2.9778)	grad_norm 5.5457 (nan)	mem 8929MB
[2022-04-09 05:43:55 large] (main.py 226): INFO Train: [235/300][2000/2502]	eta 0:04:12 lr 0.000059	time 0.5065 (0.5034)	loss 3.4327 (2.9797)	grad_norm 4.7813 (nan)	mem 8929MB
[2022-04-09 05:44:44 large] (main.py 226): INFO Train: [235/300][2100/2502]	eta 0:03:22 lr 0.000059	time 0.4897 (0.5027)	loss 3.3048 (2.9776)	grad_norm 6.4851 (nan)	mem 8929MB
[2022-04-09 05:45:34 large] (main.py 226): INFO Train: [235/300][2200/2502]	eta 0:02:31 lr 0.000059	time 0.4481 (0.5026)	loss 2.2895 (2.9761)	grad_norm 8.1137 (nan)	mem 8929MB
[2022-04-09 05:46:24 large] (main.py 226): INFO Train: [235/300][2300/2502]	eta 0:01:41 lr 0.000059	time 0.4927 (0.5024)	loss 2.2637 (2.9780)	grad_norm 17.3635 (nan)	mem 8929MB
[2022-04-09 05:47:15 large] (main.py 226): INFO Train: [235/300][2400/2502]	eta 0:00:51 lr 0.000059	time 0.5261 (0.5027)	loss 3.0739 (2.9738)	grad_norm 5.7435 (nan)	mem 8929MB
[2022-04-09 05:48:06 large] (main.py 226): INFO Train: [235/300][2500/2502]	eta 0:00:01 lr 0.000059	time 0.5048 (0.5030)	loss 3.0081 (2.9754)	grad_norm 8.5518 (nan)	mem 8929MB
[2022-04-09 05:48:07 large] (main.py 233): INFO EPOCH 235 training takes 0:20:59
[2022-04-09 05:48:12 large] (main.py 273): INFO Test: [0/98]	Time 5.567 (5.567)	Loss 1.0901 (1.0901)	Acc@1 77.344 (77.344)	Acc@5 94.727 (94.727)	Mem 8929MB
[2022-04-09 05:48:39 large] (main.py 279): INFO  * Acc@1 80.800 Acc@5 95.266
[2022-04-09 05:48:39 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 80.8%
[2022-04-09 05:48:39 large] (main.py 148): INFO Max accuracy: 80.83%
[2022-04-09 05:48:47 large] (main.py 226): INFO Train: [236/300][0/2502]	eta 5:28:43 lr 0.000059	time 7.8832 (7.8832)	loss 2.9813 (2.9813)	grad_norm 7.2792 (7.2792)	mem 8929MB
[2022-04-09 05:49:37 large] (main.py 226): INFO Train: [236/300][100/2502]	eta 0:23:06 lr 0.000058	time 0.5115 (0.5772)	loss 2.1516 (2.8839)	grad_norm 7.9790 (7.0640)	mem 8929MB
[2022-04-09 05:50:28 large] (main.py 226): INFO Train: [236/300][200/2502]	eta 0:20:53 lr 0.000058	time 0.5240 (0.5446)	loss 2.8853 (2.8844)	grad_norm 6.0803 (7.0951)	mem 8929MB
[2022-04-09 05:51:18 large] (main.py 226): INFO Train: [236/300][300/2502]	eta 0:19:24 lr 0.000058	time 0.4883 (0.5288)	loss 2.9709 (2.9148)	grad_norm 8.0451 (7.1912)	mem 8929MB
[2022-04-09 05:52:08 large] (main.py 226): INFO Train: [236/300][400/2502]	eta 0:18:14 lr 0.000058	time 0.5129 (0.5208)	loss 3.3893 (2.9047)	grad_norm 6.8756 (7.2766)	mem 8929MB
[2022-04-09 05:52:59 large] (main.py 226): INFO Train: [236/300][500/2502]	eta 0:17:19 lr 0.000058	time 0.4713 (0.5192)	loss 3.2816 (2.9103)	grad_norm 6.3158 (7.2231)	mem 8929MB
[2022-04-09 05:53:50 large] (main.py 226): INFO Train: [236/300][600/2502]	eta 0:16:24 lr 0.000058	time 0.5308 (0.5177)	loss 2.3746 (2.9108)	grad_norm 5.8527 (7.2615)	mem 8929MB
[2022-04-09 05:54:40 large] (main.py 226): INFO Train: [236/300][700/2502]	eta 0:15:29 lr 0.000058	time 0.5451 (0.5156)	loss 3.3128 (2.9320)	grad_norm 6.6404 (7.2201)	mem 8929MB
[2022-04-09 05:55:30 large] (main.py 226): INFO Train: [236/300][800/2502]	eta 0:14:34 lr 0.000058	time 0.4932 (0.5137)	loss 3.0081 (2.9419)	grad_norm 6.2620 (7.1717)	mem 8929MB
[2022-04-09 05:56:22 large] (main.py 226): INFO Train: [236/300][900/2502]	eta 0:13:42 lr 0.000058	time 0.5120 (0.5137)	loss 3.1645 (2.9506)	grad_norm 10.7462 (7.1726)	mem 8929MB
[2022-04-09 05:57:13 large] (main.py 226): INFO Train: [236/300][1000/2502]	eta 0:12:51 lr 0.000058	time 0.4877 (0.5137)	loss 3.2274 (2.9482)	grad_norm 6.7165 (7.1901)	mem 8929MB
[2022-04-09 05:58:04 large] (main.py 226): INFO Train: [236/300][1100/2502]	eta 0:11:59 lr 0.000058	time 0.5016 (0.5132)	loss 2.9190 (2.9457)	grad_norm 7.8143 (7.1440)	mem 8929MB
[2022-04-09 05:58:55 large] (main.py 226): INFO Train: [236/300][1200/2502]	eta 0:11:07 lr 0.000058	time 0.5071 (0.5129)	loss 3.3834 (2.9483)	grad_norm 6.2406 (7.1315)	mem 8929MB
[2022-04-09 05:59:46 large] (main.py 226): INFO Train: [236/300][1300/2502]	eta 0:10:16 lr 0.000058	time 0.5029 (0.5126)	loss 3.1907 (2.9496)	grad_norm 5.7242 (7.1369)	mem 8929MB
[2022-04-09 06:00:36 large] (main.py 226): INFO Train: [236/300][1400/2502]	eta 0:09:24 lr 0.000058	time 0.5032 (0.5120)	loss 3.4378 (2.9502)	grad_norm 5.4998 (7.1124)	mem 8929MB
[2022-04-09 06:01:26 large] (main.py 226): INFO Train: [236/300][1500/2502]	eta 0:08:31 lr 0.000058	time 0.5091 (0.5109)	loss 3.3465 (2.9542)	grad_norm 5.9127 (7.1528)	mem 8929MB
[2022-04-09 06:02:15 large] (main.py 226): INFO Train: [236/300][1600/2502]	eta 0:07:39 lr 0.000058	time 0.4669 (0.5095)	loss 2.0303 (2.9549)	grad_norm 5.6993 (7.1503)	mem 8929MB
[2022-04-09 06:03:03 large] (main.py 226): INFO Train: [236/300][1700/2502]	eta 0:06:47 lr 0.000057	time 0.5007 (0.5082)	loss 2.5000 (2.9547)	grad_norm 6.1336 (7.1346)	mem 8929MB
[2022-04-09 06:03:52 large] (main.py 226): INFO Train: [236/300][1800/2502]	eta 0:05:56 lr 0.000057	time 0.5203 (0.5072)	loss 3.3435 (2.9550)	grad_norm 8.1548 (7.1381)	mem 8929MB
[2022-04-09 06:04:42 large] (main.py 226): INFO Train: [236/300][1900/2502]	eta 0:05:04 lr 0.000057	time 0.5103 (0.5064)	loss 2.9571 (2.9588)	grad_norm 8.2238 (7.1753)	mem 8929MB
[2022-04-09 06:05:32 large] (main.py 226): INFO Train: [236/300][2000/2502]	eta 0:04:14 lr 0.000057	time 0.4690 (0.5064)	loss 3.2314 (2.9575)	grad_norm 4.7748 (7.1704)	mem 8929MB
[2022-04-09 06:06:21 large] (main.py 226): INFO Train: [236/300][2100/2502]	eta 0:03:23 lr 0.000057	time 0.4860 (0.5056)	loss 3.3163 (2.9593)	grad_norm 6.5067 (7.1830)	mem 8929MB
[2022-04-09 06:07:12 large] (main.py 226): INFO Train: [236/300][2200/2502]	eta 0:02:32 lr 0.000057	time 0.4749 (0.5056)	loss 3.6258 (2.9593)	grad_norm 6.7299 (7.1742)	mem 8929MB
[2022-04-09 06:08:01 large] (main.py 226): INFO Train: [236/300][2300/2502]	eta 0:01:42 lr 0.000057	time 0.4831 (0.5051)	loss 3.1740 (2.9596)	grad_norm 5.7116 (7.1685)	mem 8929MB
[2022-04-09 06:08:50 large] (main.py 226): INFO Train: [236/300][2400/2502]	eta 0:00:51 lr 0.000057	time 0.4686 (0.5043)	loss 2.1890 (2.9599)	grad_norm 5.6873 (7.2259)	mem 8929MB
[2022-04-09 06:09:39 large] (main.py 226): INFO Train: [236/300][2500/2502]	eta 0:00:01 lr 0.000057	time 0.5050 (0.5039)	loss 1.8764 (2.9597)	grad_norm 8.8891 (7.2339)	mem 8929MB
[2022-04-09 06:09:40 large] (main.py 233): INFO EPOCH 236 training takes 0:21:01
[2022-04-09 06:09:47 large] (main.py 273): INFO Test: [0/98]	Time 6.940 (6.940)	Loss 1.0804 (1.0804)	Acc@1 77.539 (77.539)	Acc@5 94.336 (94.336)	Mem 8929MB
[2022-04-09 06:10:12 large] (main.py 279): INFO  * Acc@1 80.792 Acc@5 95.216
[2022-04-09 06:10:12 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 80.8%
[2022-04-09 06:10:12 large] (main.py 148): INFO Max accuracy: 80.83%
[2022-04-09 06:10:19 large] (main.py 226): INFO Train: [237/300][0/2502]	eta 4:29:09 lr 0.000057	time 6.4545 (6.4545)	loss 3.1869 (3.1869)	grad_norm 6.2242 (6.2242)	mem 8929MB
[2022-04-09 06:11:11 large] (main.py 226): INFO Train: [237/300][100/2502]	eta 0:23:05 lr 0.000057	time 0.5295 (0.5768)	loss 3.5456 (2.8930)	grad_norm 6.6954 (7.1899)	mem 8929MB
[2022-04-09 06:12:02 large] (main.py 226): INFO Train: [237/300][200/2502]	eta 0:20:53 lr 0.000057	time 0.5056 (0.5447)	loss 3.5321 (2.9200)	grad_norm 7.8454 (7.3892)	mem 8929MB
[2022-04-09 06:12:53 large] (main.py 226): INFO Train: [237/300][300/2502]	eta 0:19:36 lr 0.000057	time 0.4816 (0.5345)	loss 2.6389 (2.9342)	grad_norm 5.6677 (7.4602)	mem 8929MB
[2022-04-09 06:13:42 large] (main.py 226): INFO Train: [237/300][400/2502]	eta 0:18:19 lr 0.000057	time 0.5116 (0.5229)	loss 3.2034 (2.9589)	grad_norm 6.5590 (7.4332)	mem 8929MB
[2022-04-09 06:14:32 large] (main.py 226): INFO Train: [237/300][500/2502]	eta 0:17:18 lr 0.000057	time 0.4465 (0.5190)	loss 2.9843 (2.9667)	grad_norm 6.2136 (7.4029)	mem 8929MB
[2022-04-09 06:15:22 large] (main.py 226): INFO Train: [237/300][600/2502]	eta 0:16:20 lr 0.000057	time 0.5352 (0.5154)	loss 3.3761 (2.9641)	grad_norm 16.4743 (7.3970)	mem 8929MB
[2022-04-09 06:16:10 large] (main.py 226): INFO Train: [237/300][700/2502]	eta 0:15:20 lr 0.000056	time 0.4653 (0.5107)	loss 3.2553 (2.9591)	grad_norm 6.0477 (7.4007)	mem 8929MB
[2022-04-09 06:17:00 large] (main.py 226): INFO Train: [237/300][800/2502]	eta 0:14:26 lr 0.000056	time 0.5033 (0.5090)	loss 3.5434 (2.9666)	grad_norm 7.0324 (7.3611)	mem 8929MB
[2022-04-09 06:17:50 large] (main.py 226): INFO Train: [237/300][900/2502]	eta 0:13:33 lr 0.000056	time 0.5589 (0.5081)	loss 3.0814 (2.9592)	grad_norm 5.5312 (7.4829)	mem 8929MB
[2022-04-09 06:18:40 large] (main.py 226): INFO Train: [237/300][1000/2502]	eta 0:12:42 lr 0.000056	time 0.4880 (0.5077)	loss 3.0092 (2.9635)	grad_norm 5.2851 (7.4548)	mem 8929MB
[2022-04-09 06:19:30 large] (main.py 226): INFO Train: [237/300][1100/2502]	eta 0:11:50 lr 0.000056	time 0.5088 (0.5068)	loss 2.9980 (2.9638)	grad_norm 7.8169 (7.4344)	mem 8929MB
[2022-04-09 06:20:21 large] (main.py 226): INFO Train: [237/300][1200/2502]	eta 0:11:00 lr 0.000056	time 0.4675 (0.5072)	loss 2.3441 (2.9688)	grad_norm 6.8109 (nan)	mem 8929MB
[2022-04-09 06:21:12 large] (main.py 226): INFO Train: [237/300][1300/2502]	eta 0:10:09 lr 0.000056	time 0.5207 (0.5068)	loss 2.9672 (2.9638)	grad_norm 7.1724 (nan)	mem 8929MB
[2022-04-09 06:22:03 large] (main.py 226): INFO Train: [237/300][1400/2502]	eta 0:09:19 lr 0.000056	time 0.5097 (0.5075)	loss 3.5029 (2.9666)	grad_norm 7.2569 (nan)	mem 8929MB
[2022-04-09 06:22:52 large] (main.py 226): INFO Train: [237/300][1500/2502]	eta 0:08:27 lr 0.000056	time 0.4748 (0.5062)	loss 3.3815 (2.9675)	grad_norm 5.7368 (nan)	mem 8929MB
[2022-04-09 06:23:41 large] (main.py 226): INFO Train: [237/300][1600/2502]	eta 0:07:35 lr 0.000056	time 0.5499 (0.5052)	loss 3.5414 (2.9700)	grad_norm 6.5670 (nan)	mem 8929MB
[2022-04-09 06:24:30 large] (main.py 226): INFO Train: [237/300][1700/2502]	eta 0:06:44 lr 0.000056	time 0.5923 (0.5043)	loss 3.2858 (2.9662)	grad_norm 6.2063 (nan)	mem 8929MB
[2022-04-09 06:25:21 large] (main.py 226): INFO Train: [237/300][1800/2502]	eta 0:05:54 lr 0.000056	time 0.5360 (0.5047)	loss 3.3521 (2.9624)	grad_norm 6.3768 (nan)	mem 8929MB
[2022-04-09 06:26:11 large] (main.py 226): INFO Train: [237/300][1900/2502]	eta 0:05:03 lr 0.000056	time 0.5459 (0.5042)	loss 2.3425 (2.9603)	grad_norm 5.7802 (nan)	mem 8929MB
[2022-04-09 06:27:01 large] (main.py 226): INFO Train: [237/300][2000/2502]	eta 0:04:13 lr 0.000056	time 0.4782 (0.5041)	loss 1.8766 (2.9603)	grad_norm 5.3633 (nan)	mem 8929MB
[2022-04-09 06:27:50 large] (main.py 226): INFO Train: [237/300][2100/2502]	eta 0:03:22 lr 0.000056	time 0.4783 (0.5037)	loss 3.2993 (2.9573)	grad_norm 8.3278 (nan)	mem 8929MB
[2022-04-09 06:28:39 large] (main.py 226): INFO Train: [237/300][2200/2502]	eta 0:02:31 lr 0.000056	time 0.4859 (0.5030)	loss 3.4207 (2.9595)	grad_norm 8.1271 (nan)	mem 8929MB
[2022-04-09 06:29:30 large] (main.py 226): INFO Train: [237/300][2300/2502]	eta 0:01:41 lr 0.000055	time 0.5566 (0.5032)	loss 3.2361 (2.9593)	grad_norm 6.7344 (nan)	mem 8929MB
[2022-04-09 06:30:21 large] (main.py 226): INFO Train: [237/300][2400/2502]	eta 0:00:51 lr 0.000055	time 0.4847 (0.5036)	loss 2.9302 (2.9600)	grad_norm 10.4139 (nan)	mem 8929MB
[2022-04-09 06:31:11 large] (main.py 226): INFO Train: [237/300][2500/2502]	eta 0:00:01 lr 0.000055	time 0.4643 (0.5032)	loss 3.1336 (2.9647)	grad_norm 8.4540 (nan)	mem 8929MB
[2022-04-09 06:31:12 large] (main.py 233): INFO EPOCH 237 training takes 0:20:59
[2022-04-09 06:31:18 large] (main.py 273): INFO Test: [0/98]	Time 5.862 (5.862)	Loss 0.9198 (0.9198)	Acc@1 81.641 (81.641)	Acc@5 96.289 (96.289)	Mem 8929MB
[2022-04-09 06:31:45 large] (main.py 279): INFO  * Acc@1 80.880 Acc@5 95.338
[2022-04-09 06:31:45 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 80.9%
[2022-04-09 06:31:45 large] (utils.py 57): INFO output/large/default/ckpt_epoch_237.pth saving......
[2022-04-09 06:31:45 large] (utils.py 59): INFO output/large/default/ckpt_epoch_237.pth saved !!!
[2022-04-09 06:31:45 large] (main.py 148): INFO Max accuracy: 80.88%
[2022-04-09 06:31:53 large] (main.py 226): INFO Train: [238/300][0/2502]	eta 5:16:47 lr 0.000055	time 7.5971 (7.5971)	loss 3.0531 (3.0531)	grad_norm 7.2284 (7.2284)	mem 8929MB
[2022-04-09 06:32:42 large] (main.py 226): INFO Train: [238/300][100/2502]	eta 0:22:26 lr 0.000055	time 0.4574 (0.5607)	loss 3.2372 (2.9821)	grad_norm 11.3936 (8.4080)	mem 8929MB
[2022-04-09 06:33:30 large] (main.py 226): INFO Train: [238/300][200/2502]	eta 0:20:01 lr 0.000055	time 0.4709 (0.5219)	loss 3.2917 (2.9794)	grad_norm 11.1665 (8.5587)	mem 8929MB
[2022-04-09 06:34:20 large] (main.py 226): INFO Train: [238/300][300/2502]	eta 0:18:53 lr 0.000055	time 0.4745 (0.5148)	loss 2.0491 (2.9939)	grad_norm 8.2874 (8.2143)	mem 8929MB
[2022-04-09 06:35:10 large] (main.py 226): INFO Train: [238/300][400/2502]	eta 0:17:54 lr 0.000055	time 0.4794 (0.5111)	loss 2.9603 (2.9802)	grad_norm 6.3574 (8.1121)	mem 8929MB
[2022-04-09 06:35:59 large] (main.py 226): INFO Train: [238/300][500/2502]	eta 0:16:55 lr 0.000055	time 0.5020 (0.5073)	loss 2.5340 (2.9732)	grad_norm 8.0779 (7.9779)	mem 8929MB
[2022-04-09 06:36:50 large] (main.py 226): INFO Train: [238/300][600/2502]	eta 0:16:05 lr 0.000055	time 0.4714 (0.5074)	loss 2.6048 (2.9663)	grad_norm 7.8943 (nan)	mem 8929MB
[2022-04-09 06:37:40 large] (main.py 226): INFO Train: [238/300][700/2502]	eta 0:15:12 lr 0.000055	time 0.5008 (0.5063)	loss 2.6850 (2.9659)	grad_norm 7.6912 (nan)	mem 8929MB
[2022-04-09 06:38:31 large] (main.py 226): INFO Train: [238/300][800/2502]	eta 0:14:23 lr 0.000055	time 0.5082 (0.5071)	loss 3.3184 (2.9589)	grad_norm 6.0324 (nan)	mem 8929MB
[2022-04-09 06:39:23 large] (main.py 226): INFO Train: [238/300][900/2502]	eta 0:13:34 lr 0.000055	time 0.5634 (0.5082)	loss 3.3737 (2.9587)	grad_norm 6.7062 (nan)	mem 8929MB
[2022-04-09 06:40:13 large] (main.py 226): INFO Train: [238/300][1000/2502]	eta 0:12:41 lr 0.000055	time 0.4900 (0.5071)	loss 3.1956 (2.9562)	grad_norm 7.0220 (nan)	mem 8929MB
[2022-04-09 06:41:02 large] (main.py 226): INFO Train: [238/300][1100/2502]	eta 0:11:49 lr 0.000055	time 0.4824 (0.5060)	loss 2.4163 (2.9545)	grad_norm 8.3231 (nan)	mem 8929MB
[2022-04-09 06:41:53 large] (main.py 226): INFO Train: [238/300][1200/2502]	eta 0:10:58 lr 0.000055	time 0.4892 (0.5059)	loss 3.3805 (2.9515)	grad_norm 5.8774 (nan)	mem 8929MB
[2022-04-09 06:42:44 large] (main.py 226): INFO Train: [238/300][1300/2502]	eta 0:10:08 lr 0.000055	time 0.5129 (0.5064)	loss 3.3360 (2.9596)	grad_norm 6.9057 (nan)	mem 8929MB
[2022-04-09 06:43:35 large] (main.py 226): INFO Train: [238/300][1400/2502]	eta 0:09:18 lr 0.000054	time 0.5074 (0.5069)	loss 3.4661 (2.9590)	grad_norm 7.8690 (nan)	mem 8929MB
[2022-04-09 06:44:26 large] (main.py 226): INFO Train: [238/300][1500/2502]	eta 0:08:27 lr 0.000054	time 0.4869 (0.5067)	loss 3.2250 (2.9635)	grad_norm 6.9652 (nan)	mem 8929MB
[2022-04-09 06:45:14 large] (main.py 226): INFO Train: [238/300][1600/2502]	eta 0:07:35 lr 0.000054	time 0.4795 (0.5053)	loss 2.9980 (2.9620)	grad_norm 6.4729 (nan)	mem 8929MB
[2022-04-09 06:46:02 large] (main.py 226): INFO Train: [238/300][1700/2502]	eta 0:06:44 lr 0.000054	time 0.4601 (0.5039)	loss 3.4916 (2.9633)	grad_norm 8.8888 (nan)	mem 8929MB
[2022-04-09 06:46:53 large] (main.py 226): INFO Train: [238/300][1800/2502]	eta 0:05:53 lr 0.000054	time 0.5005 (0.5038)	loss 2.9264 (2.9586)	grad_norm 7.0203 (nan)	mem 8929MB
[2022-04-09 06:47:42 large] (main.py 226): INFO Train: [238/300][1900/2502]	eta 0:05:02 lr 0.000054	time 0.5349 (0.5032)	loss 3.1737 (2.9604)	grad_norm 10.8697 (nan)	mem 8929MB
[2022-04-09 06:48:32 large] (main.py 226): INFO Train: [238/300][2000/2502]	eta 0:04:12 lr 0.000054	time 0.4703 (0.5030)	loss 3.0785 (2.9603)	grad_norm 8.0764 (nan)	mem 8929MB
[2022-04-09 06:49:23 large] (main.py 226): INFO Train: [238/300][2100/2502]	eta 0:03:22 lr 0.000054	time 0.5120 (0.5033)	loss 2.2178 (2.9578)	grad_norm 6.4086 (nan)	mem 8929MB
[2022-04-09 06:50:14 large] (main.py 226): INFO Train: [238/300][2200/2502]	eta 0:02:32 lr 0.000054	time 0.5132 (0.5035)	loss 3.1371 (2.9566)	grad_norm 9.8217 (nan)	mem 8929MB
[2022-04-09 06:51:03 large] (main.py 226): INFO Train: [238/300][2300/2502]	eta 0:01:41 lr 0.000054	time 0.5067 (0.5029)	loss 2.8949 (2.9576)	grad_norm 7.5715 (nan)	mem 8929MB
[2022-04-09 06:51:52 large] (main.py 226): INFO Train: [238/300][2400/2502]	eta 0:00:51 lr 0.000054	time 0.5035 (0.5026)	loss 2.3932 (2.9539)	grad_norm 8.9239 (nan)	mem 8929MB
[2022-04-09 06:52:43 large] (main.py 226): INFO Train: [238/300][2500/2502]	eta 0:00:01 lr 0.000054	time 0.4904 (0.5029)	loss 2.7146 (2.9532)	grad_norm 6.6958 (nan)	mem 8929MB
[2022-04-09 06:52:44 large] (main.py 233): INFO EPOCH 238 training takes 0:20:58
[2022-04-09 06:52:50 large] (main.py 273): INFO Test: [0/98]	Time 6.167 (6.167)	Loss 1.0559 (1.0559)	Acc@1 77.930 (77.930)	Acc@5 95.312 (95.312)	Mem 8929MB
[2022-04-09 06:53:16 large] (main.py 279): INFO  * Acc@1 80.646 Acc@5 95.172
[2022-04-09 06:53:16 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 80.6%
[2022-04-09 06:53:16 large] (main.py 148): INFO Max accuracy: 80.88%
[2022-04-09 06:53:23 large] (main.py 226): INFO Train: [239/300][0/2502]	eta 4:43:19 lr 0.000054	time 6.7944 (6.7944)	loss 2.9395 (2.9395)	grad_norm 6.4194 (6.4194)	mem 8929MB
[2022-04-09 06:54:14 large] (main.py 226): INFO Train: [239/300][100/2502]	eta 0:22:55 lr 0.000054	time 0.5188 (0.5726)	loss 4.0152 (2.9791)	grad_norm 9.8844 (6.8694)	mem 8929MB
[2022-04-09 06:55:04 large] (main.py 226): INFO Train: [239/300][200/2502]	eta 0:20:35 lr 0.000054	time 0.4838 (0.5368)	loss 3.2861 (2.9744)	grad_norm 10.4782 (6.8662)	mem 8929MB
[2022-04-09 06:55:54 large] (main.py 226): INFO Train: [239/300][300/2502]	eta 0:19:14 lr 0.000054	time 0.4479 (0.5245)	loss 2.8613 (2.9446)	grad_norm 7.7349 (7.0349)	mem 8929MB
[2022-04-09 06:56:43 large] (main.py 226): INFO Train: [239/300][400/2502]	eta 0:18:03 lr 0.000054	time 0.4891 (0.5154)	loss 3.4672 (2.9430)	grad_norm 6.6357 (7.2190)	mem 8929MB
[2022-04-09 06:57:33 large] (main.py 226): INFO Train: [239/300][500/2502]	eta 0:17:05 lr 0.000053	time 0.4642 (0.5120)	loss 3.2631 (2.9477)	grad_norm 8.1394 (7.3149)	mem 8929MB
[2022-04-09 06:58:22 large] (main.py 226): INFO Train: [239/300][600/2502]	eta 0:16:08 lr 0.000053	time 0.5503 (0.5090)	loss 2.6269 (2.9395)	grad_norm 8.0123 (7.3223)	mem 8929MB
[2022-04-09 06:59:12 large] (main.py 226): INFO Train: [239/300][700/2502]	eta 0:15:13 lr 0.000053	time 0.5427 (0.5069)	loss 3.1671 (2.9370)	grad_norm 6.5121 (7.2745)	mem 8929MB
[2022-04-09 07:00:03 large] (main.py 226): INFO Train: [239/300][800/2502]	eta 0:14:24 lr 0.000053	time 0.4818 (0.5079)	loss 2.6255 (2.9325)	grad_norm 6.2094 (7.1989)	mem 8929MB
[2022-04-09 07:00:53 large] (main.py 226): INFO Train: [239/300][900/2502]	eta 0:13:32 lr 0.000053	time 0.5313 (0.5073)	loss 3.3727 (2.9330)	grad_norm 7.3031 (7.2348)	mem 8929MB
[2022-04-09 07:01:43 large] (main.py 226): INFO Train: [239/300][1000/2502]	eta 0:12:40 lr 0.000053	time 0.5609 (0.5066)	loss 3.4138 (2.9361)	grad_norm 7.3129 (7.2560)	mem 8929MB
[2022-04-09 07:02:35 large] (main.py 226): INFO Train: [239/300][1100/2502]	eta 0:11:51 lr 0.000053	time 0.5245 (0.5073)	loss 3.1241 (2.9357)	grad_norm 6.3608 (7.2485)	mem 8929MB
[2022-04-09 07:03:24 large] (main.py 226): INFO Train: [239/300][1200/2502]	eta 0:10:59 lr 0.000053	time 0.5042 (0.5064)	loss 3.3911 (2.9373)	grad_norm 5.4370 (7.2622)	mem 8929MB
[2022-04-09 07:04:14 large] (main.py 226): INFO Train: [239/300][1300/2502]	eta 0:10:07 lr 0.000053	time 0.5447 (0.5057)	loss 1.8408 (2.9377)	grad_norm 6.9154 (7.3109)	mem 8929MB
[2022-04-09 07:05:05 large] (main.py 226): INFO Train: [239/300][1400/2502]	eta 0:09:17 lr 0.000053	time 0.5382 (0.5059)	loss 2.8524 (2.9369)	grad_norm 7.1411 (7.4253)	mem 8929MB
[2022-04-09 07:05:56 large] (main.py 226): INFO Train: [239/300][1500/2502]	eta 0:08:27 lr 0.000053	time 0.4746 (0.5061)	loss 3.3052 (2.9388)	grad_norm 4.3180 (7.4497)	mem 8929MB
[2022-04-09 07:06:44 large] (main.py 226): INFO Train: [239/300][1600/2502]	eta 0:07:35 lr 0.000053	time 0.4698 (0.5047)	loss 3.3531 (2.9421)	grad_norm 7.8415 (7.4733)	mem 8929MB
[2022-04-09 07:07:33 large] (main.py 226): INFO Train: [239/300][1700/2502]	eta 0:06:44 lr 0.000053	time 0.4848 (0.5040)	loss 3.1935 (2.9445)	grad_norm 4.6089 (7.4290)	mem 8929MB
[2022-04-09 07:08:24 large] (main.py 226): INFO Train: [239/300][1800/2502]	eta 0:05:53 lr 0.000053	time 0.5259 (0.5042)	loss 3.1143 (2.9432)	grad_norm 11.1611 (7.4708)	mem 8929MB
[2022-04-09 07:09:16 large] (main.py 226): INFO Train: [239/300][1900/2502]	eta 0:05:03 lr 0.000053	time 0.5152 (0.5047)	loss 2.0860 (2.9476)	grad_norm 6.2716 (7.4912)	mem 8929MB
[2022-04-09 07:10:07 large] (main.py 226): INFO Train: [239/300][2000/2502]	eta 0:04:13 lr 0.000053	time 0.5121 (0.5050)	loss 3.1740 (2.9446)	grad_norm 6.7447 (7.4815)	mem 8929MB
[2022-04-09 07:10:57 large] (main.py 226): INFO Train: [239/300][2100/2502]	eta 0:03:22 lr 0.000053	time 0.4712 (0.5049)	loss 1.8295 (2.9469)	grad_norm 6.9376 (7.4854)	mem 8929MB
[2022-04-09 07:11:46 large] (main.py 226): INFO Train: [239/300][2200/2502]	eta 0:02:32 lr 0.000052	time 0.5009 (0.5042)	loss 3.5471 (2.9513)	grad_norm 7.3457 (7.4769)	mem 8929MB
[2022-04-09 07:12:35 large] (main.py 226): INFO Train: [239/300][2300/2502]	eta 0:01:41 lr 0.000052	time 0.4744 (0.5038)	loss 2.9832 (2.9537)	grad_norm 6.5380 (7.4777)	mem 8929MB
[2022-04-09 07:13:26 large] (main.py 226): INFO Train: [239/300][2400/2502]	eta 0:00:51 lr 0.000052	time 0.4996 (0.5039)	loss 3.0046 (2.9515)	grad_norm 8.8287 (7.4764)	mem 8929MB
[2022-04-09 07:14:17 large] (main.py 226): INFO Train: [239/300][2500/2502]	eta 0:00:01 lr 0.000052	time 0.5287 (0.5042)	loss 3.3175 (2.9530)	grad_norm 127.6388 (7.5192)	mem 8929MB
[2022-04-09 07:14:18 large] (main.py 233): INFO EPOCH 239 training takes 0:21:02
[2022-04-09 07:14:24 large] (main.py 273): INFO Test: [0/98]	Time 6.193 (6.193)	Loss 1.0420 (1.0420)	Acc@1 80.664 (80.664)	Acc@5 93.750 (93.750)	Mem 8929MB
[2022-04-09 07:14:50 large] (main.py 279): INFO  * Acc@1 80.886 Acc@5 95.254
[2022-04-09 07:14:50 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 80.9%
[2022-04-09 07:14:50 large] (utils.py 57): INFO output/large/default/ckpt_epoch_239.pth saving......
[2022-04-09 07:14:51 large] (utils.py 59): INFO output/large/default/ckpt_epoch_239.pth saved !!!
[2022-04-09 07:14:51 large] (main.py 148): INFO Max accuracy: 80.89%
[2022-04-09 07:15:00 large] (main.py 226): INFO Train: [240/300][0/2502]	eta 6:00:47 lr 0.000052	time 8.6519 (8.6519)	loss 3.2483 (3.2483)	grad_norm 9.8128 (9.8128)	mem 8929MB
[2022-04-09 07:15:48 large] (main.py 226): INFO Train: [240/300][100/2502]	eta 0:22:39 lr 0.000052	time 0.4579 (0.5658)	loss 2.5222 (2.9607)	grad_norm 8.5522 (8.1448)	mem 8929MB
[2022-04-09 07:16:37 large] (main.py 226): INFO Train: [240/300][200/2502]	eta 0:20:10 lr 0.000052	time 0.5015 (0.5257)	loss 3.3719 (2.9850)	grad_norm 14.0185 (7.6275)	mem 8929MB
[2022-04-09 07:17:28 large] (main.py 226): INFO Train: [240/300][300/2502]	eta 0:19:08 lr 0.000052	time 0.5105 (0.5214)	loss 3.3552 (2.9909)	grad_norm 6.0283 (7.5519)	mem 8929MB
[2022-04-09 07:18:18 large] (main.py 226): INFO Train: [240/300][400/2502]	eta 0:18:04 lr 0.000052	time 0.5078 (0.5157)	loss 2.9355 (2.9753)	grad_norm 10.3422 (7.6886)	mem 8929MB
[2022-04-09 07:19:09 large] (main.py 226): INFO Train: [240/300][500/2502]	eta 0:17:11 lr 0.000052	time 0.5393 (0.5151)	loss 3.7745 (2.9731)	grad_norm 11.5168 (7.5458)	mem 8929MB
[2022-04-09 07:19:59 large] (main.py 226): INFO Train: [240/300][600/2502]	eta 0:16:15 lr 0.000052	time 0.5170 (0.5129)	loss 2.8884 (2.9763)	grad_norm 9.5353 (7.5648)	mem 8929MB
[2022-04-09 07:20:50 large] (main.py 226): INFO Train: [240/300][700/2502]	eta 0:15:22 lr 0.000052	time 0.5085 (0.5121)	loss 3.2742 (2.9622)	grad_norm 5.0316 (7.9442)	mem 8929MB
[2022-04-09 07:21:42 large] (main.py 226): INFO Train: [240/300][800/2502]	eta 0:14:32 lr 0.000052	time 0.5089 (0.5125)	loss 3.3948 (2.9679)	grad_norm 7.0407 (7.8786)	mem 8929MB
[2022-04-09 07:22:31 large] (main.py 226): INFO Train: [240/300][900/2502]	eta 0:13:38 lr 0.000052	time 0.4739 (0.5108)	loss 2.7705 (2.9669)	grad_norm 7.8985 (7.8038)	mem 8929MB
[2022-04-09 07:23:20 large] (main.py 226): INFO Train: [240/300][1000/2502]	eta 0:12:44 lr 0.000052	time 0.5136 (0.5088)	loss 3.0722 (2.9723)	grad_norm 7.7696 (7.7796)	mem 8929MB
[2022-04-09 07:24:10 large] (main.py 226): INFO Train: [240/300][1100/2502]	eta 0:11:51 lr 0.000052	time 0.4803 (0.5074)	loss 3.1064 (2.9656)	grad_norm 6.9822 (7.7281)	mem 8929MB
[2022-04-09 07:24:59 large] (main.py 226): INFO Train: [240/300][1200/2502]	eta 0:10:59 lr 0.000052	time 0.5062 (0.5064)	loss 3.2103 (2.9706)	grad_norm 8.3378 (7.7612)	mem 8929MB
[2022-04-09 07:25:51 large] (main.py 226): INFO Train: [240/300][1300/2502]	eta 0:10:09 lr 0.000051	time 0.5120 (0.5069)	loss 3.7385 (2.9745)	grad_norm 7.4692 (7.7583)	mem 8929MB
[2022-04-09 07:26:40 large] (main.py 226): INFO Train: [240/300][1400/2502]	eta 0:09:17 lr 0.000051	time 0.5001 (0.5061)	loss 3.0237 (2.9723)	grad_norm 7.8673 (7.7353)	mem 8929MB
[2022-04-09 07:27:30 large] (main.py 226): INFO Train: [240/300][1500/2502]	eta 0:08:26 lr 0.000051	time 0.4914 (0.5056)	loss 2.9468 (2.9655)	grad_norm 6.3320 (7.6987)	mem 8929MB
[2022-04-09 07:28:19 large] (main.py 226): INFO Train: [240/300][1600/2502]	eta 0:07:35 lr 0.000051	time 0.4911 (0.5047)	loss 2.1017 (2.9648)	grad_norm 7.9211 (7.6920)	mem 8929MB
[2022-04-09 07:29:10 large] (main.py 226): INFO Train: [240/300][1700/2502]	eta 0:06:44 lr 0.000051	time 0.4968 (0.5049)	loss 2.6186 (2.9610)	grad_norm 7.7060 (7.6603)	mem 8929MB
[2022-04-09 07:29:58 large] (main.py 226): INFO Train: [240/300][1800/2502]	eta 0:05:53 lr 0.000051	time 0.4892 (0.5038)	loss 2.4480 (2.9582)	grad_norm 6.7488 (7.6616)	mem 8929MB
[2022-04-09 07:30:49 large] (main.py 226): INFO Train: [240/300][1900/2502]	eta 0:05:03 lr 0.000051	time 0.5137 (0.5039)	loss 3.4952 (2.9579)	grad_norm 8.0035 (7.6586)	mem 8929MB
[2022-04-09 07:31:38 large] (main.py 226): INFO Train: [240/300][2000/2502]	eta 0:04:12 lr 0.000051	time 0.4768 (0.5034)	loss 3.3078 (2.9591)	grad_norm 10.7262 (7.6411)	mem 8929MB
[2022-04-09 07:32:27 large] (main.py 226): INFO Train: [240/300][2100/2502]	eta 0:03:22 lr 0.000051	time 0.5266 (0.5025)	loss 3.1737 (2.9574)	grad_norm 9.1471 (7.6483)	mem 8929MB
[2022-04-09 07:33:16 large] (main.py 226): INFO Train: [240/300][2200/2502]	eta 0:02:31 lr 0.000051	time 0.4970 (0.5021)	loss 2.9105 (2.9549)	grad_norm 5.1398 (7.6431)	mem 8929MB
[2022-04-09 07:34:05 large] (main.py 226): INFO Train: [240/300][2300/2502]	eta 0:01:41 lr 0.000051	time 0.5094 (0.5015)	loss 3.3641 (2.9557)	grad_norm 6.6528 (7.6343)	mem 8929MB
[2022-04-09 07:34:54 large] (main.py 226): INFO Train: [240/300][2400/2502]	eta 0:00:51 lr 0.000051	time 0.5102 (0.5011)	loss 2.3287 (2.9569)	grad_norm 6.0712 (7.6240)	mem 8929MB
[2022-04-09 07:35:45 large] (main.py 226): INFO Train: [240/300][2500/2502]	eta 0:00:01 lr 0.000051	time 0.4958 (0.5014)	loss 3.7477 (2.9601)	grad_norm 47.2271 (7.6707)	mem 8929MB
[2022-04-09 07:35:46 large] (main.py 233): INFO EPOCH 240 training takes 0:20:55
[2022-04-09 07:35:52 large] (main.py 273): INFO Test: [0/98]	Time 6.065 (6.065)	Loss 0.9079 (0.9079)	Acc@1 83.984 (83.984)	Acc@5 95.312 (95.312)	Mem 8929MB
[2022-04-09 07:36:18 large] (main.py 279): INFO  * Acc@1 80.896 Acc@5 95.282
[2022-04-09 07:36:18 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 80.9%
[2022-04-09 07:36:18 large] (utils.py 57): INFO output/large/default/ckpt_epoch_240.pth saving......
[2022-04-09 07:36:19 large] (utils.py 59): INFO output/large/default/ckpt_epoch_240.pth saved !!!
[2022-04-09 07:36:19 large] (main.py 148): INFO Max accuracy: 80.90%
[2022-04-09 07:36:27 large] (main.py 226): INFO Train: [241/300][0/2502]	eta 5:36:33 lr 0.000051	time 8.0708 (8.0708)	loss 3.5155 (3.5155)	grad_norm 7.7799 (7.7799)	mem 8929MB
[2022-04-09 07:37:16 large] (main.py 226): INFO Train: [241/300][100/2502]	eta 0:22:41 lr 0.000051	time 0.5095 (0.5667)	loss 2.2044 (2.8431)	grad_norm 7.3016 (8.9155)	mem 8929MB
[2022-04-09 07:38:08 large] (main.py 226): INFO Train: [241/300][200/2502]	eta 0:20:42 lr 0.000051	time 0.6162 (0.5398)	loss 2.1661 (2.8933)	grad_norm 7.8824 (8.1382)	mem 8929MB
[2022-04-09 07:38:59 large] (main.py 226): INFO Train: [241/300][300/2502]	eta 0:19:30 lr 0.000051	time 0.5264 (0.5314)	loss 2.7125 (2.9122)	grad_norm 11.0736 (8.0518)	mem 8929MB
[2022-04-09 07:39:48 large] (main.py 226): INFO Train: [241/300][400/2502]	eta 0:18:14 lr 0.000051	time 0.4808 (0.5206)	loss 3.4728 (2.9327)	grad_norm 7.5378 (nan)	mem 8929MB
[2022-04-09 07:40:38 large] (main.py 226): INFO Train: [241/300][500/2502]	eta 0:17:13 lr 0.000050	time 0.5494 (0.5162)	loss 3.3722 (2.9270)	grad_norm 5.7043 (nan)	mem 8929MB
[2022-04-09 07:41:29 large] (main.py 226): INFO Train: [241/300][600/2502]	eta 0:16:20 lr 0.000050	time 0.5163 (0.5155)	loss 3.3418 (2.9451)	grad_norm 5.9679 (nan)	mem 8929MB
[2022-04-09 07:42:19 large] (main.py 226): INFO Train: [241/300][700/2502]	eta 0:15:24 lr 0.000050	time 0.4895 (0.5129)	loss 3.2982 (2.9370)	grad_norm 5.5854 (nan)	mem 8929MB
[2022-04-09 07:43:08 large] (main.py 226): INFO Train: [241/300][800/2502]	eta 0:14:29 lr 0.000050	time 0.5144 (0.5109)	loss 2.0190 (2.9358)	grad_norm 6.7941 (nan)	mem 8929MB
[2022-04-09 07:43:59 large] (main.py 226): INFO Train: [241/300][900/2502]	eta 0:13:37 lr 0.000050	time 0.4777 (0.5100)	loss 3.0012 (2.9339)	grad_norm 6.3679 (nan)	mem 8929MB
[2022-04-09 07:44:48 large] (main.py 226): INFO Train: [241/300][1000/2502]	eta 0:12:43 lr 0.000050	time 0.4952 (0.5085)	loss 3.0548 (2.9344)	grad_norm 6.7026 (nan)	mem 8929MB
[2022-04-09 07:45:37 large] (main.py 226): INFO Train: [241/300][1100/2502]	eta 0:11:50 lr 0.000050	time 0.4776 (0.5071)	loss 2.1850 (2.9336)	grad_norm 4.9940 (nan)	mem 8929MB
[2022-04-09 07:46:28 large] (main.py 226): INFO Train: [241/300][1200/2502]	eta 0:10:59 lr 0.000050	time 0.5126 (0.5068)	loss 2.4311 (2.9423)	grad_norm 13.1103 (nan)	mem 8929MB
[2022-04-09 07:47:16 large] (main.py 226): INFO Train: [241/300][1300/2502]	eta 0:10:07 lr 0.000050	time 0.4986 (0.5052)	loss 2.6919 (2.9363)	grad_norm 9.8505 (nan)	mem 8929MB
[2022-04-09 07:48:07 large] (main.py 226): INFO Train: [241/300][1400/2502]	eta 0:09:16 lr 0.000050	time 0.4884 (0.5054)	loss 2.9360 (2.9395)	grad_norm 7.0810 (nan)	mem 8929MB
[2022-04-09 07:48:57 large] (main.py 226): INFO Train: [241/300][1500/2502]	eta 0:08:25 lr 0.000050	time 0.5065 (0.5047)	loss 3.4886 (2.9417)	grad_norm 6.5417 (nan)	mem 8929MB
[2022-04-09 07:49:48 large] (main.py 226): INFO Train: [241/300][1600/2502]	eta 0:07:35 lr 0.000050	time 0.4892 (0.5054)	loss 3.4102 (2.9408)	grad_norm 5.6191 (nan)	mem 8929MB
[2022-04-09 07:50:40 large] (main.py 226): INFO Train: [241/300][1700/2502]	eta 0:06:45 lr 0.000050	time 0.5138 (0.5059)	loss 3.3424 (2.9415)	grad_norm 8.9863 (nan)	mem 8929MB
[2022-04-09 07:51:29 large] (main.py 226): INFO Train: [241/300][1800/2502]	eta 0:05:54 lr 0.000050	time 0.4968 (0.5054)	loss 3.2927 (2.9441)	grad_norm 12.4493 (nan)	mem 8929MB
[2022-04-09 07:52:20 large] (main.py 226): INFO Train: [241/300][1900/2502]	eta 0:05:04 lr 0.000050	time 0.4915 (0.5057)	loss 2.6119 (2.9419)	grad_norm 4.9012 (nan)	mem 8929MB
[2022-04-09 07:53:10 large] (main.py 226): INFO Train: [241/300][2000/2502]	eta 0:04:13 lr 0.000050	time 0.4736 (0.5053)	loss 2.4974 (2.9396)	grad_norm 6.1050 (nan)	mem 8929MB
[2022-04-09 07:53:59 large] (main.py 226): INFO Train: [241/300][2100/2502]	eta 0:03:22 lr 0.000050	time 0.5208 (0.5047)	loss 3.1650 (2.9400)	grad_norm 7.7247 (nan)	mem 8929MB
[2022-04-09 07:54:51 large] (main.py 226): INFO Train: [241/300][2200/2502]	eta 0:02:32 lr 0.000049	time 0.5042 (0.5050)	loss 3.5499 (2.9372)	grad_norm 8.1792 (nan)	mem 8929MB
[2022-04-09 07:55:42 large] (main.py 226): INFO Train: [241/300][2300/2502]	eta 0:01:42 lr 0.000049	time 0.6154 (0.5052)	loss 2.7356 (2.9374)	grad_norm 7.6854 (nan)	mem 8929MB
[2022-04-09 07:56:30 large] (main.py 226): INFO Train: [241/300][2400/2502]	eta 0:00:51 lr 0.000049	time 0.4837 (0.5044)	loss 3.0505 (2.9384)	grad_norm 7.1089 (nan)	mem 8929MB
[2022-04-09 07:57:19 large] (main.py 226): INFO Train: [241/300][2500/2502]	eta 0:00:01 lr 0.000049	time 0.4801 (0.5036)	loss 3.3065 (2.9398)	grad_norm 9.6634 (nan)	mem 8929MB
[2022-04-09 07:57:20 large] (main.py 233): INFO EPOCH 241 training takes 0:21:00
[2022-04-09 07:57:26 large] (main.py 273): INFO Test: [0/98]	Time 6.098 (6.098)	Loss 1.0015 (1.0015)	Acc@1 80.469 (80.469)	Acc@5 96.094 (96.094)	Mem 8929MB
[2022-04-09 07:57:52 large] (main.py 279): INFO  * Acc@1 80.896 Acc@5 95.226
[2022-04-09 07:57:52 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 80.9%
[2022-04-09 07:57:52 large] (utils.py 57): INFO output/large/default/ckpt_epoch_241.pth saving......
[2022-04-09 07:57:53 large] (utils.py 59): INFO output/large/default/ckpt_epoch_241.pth saved !!!
[2022-04-09 07:57:53 large] (main.py 148): INFO Max accuracy: 80.90%
[2022-04-09 07:58:01 large] (main.py 226): INFO Train: [242/300][0/2502]	eta 5:53:14 lr 0.000049	time 8.4711 (8.4711)	loss 2.9007 (2.9007)	grad_norm 9.9737 (9.9737)	mem 8929MB
[2022-04-09 07:58:50 large] (main.py 226): INFO Train: [242/300][100/2502]	eta 0:22:44 lr 0.000049	time 0.4788 (0.5681)	loss 2.1528 (2.8906)	grad_norm 7.6150 (7.2544)	mem 8929MB
[2022-04-09 07:59:39 large] (main.py 226): INFO Train: [242/300][200/2502]	eta 0:20:23 lr 0.000049	time 0.5297 (0.5315)	loss 3.0337 (2.8813)	grad_norm 6.5825 (7.3631)	mem 8929MB
[2022-04-09 08:00:29 large] (main.py 226): INFO Train: [242/300][300/2502]	eta 0:19:05 lr 0.000049	time 0.5280 (0.5203)	loss 3.4385 (2.9274)	grad_norm 6.4576 (7.4200)	mem 8929MB
[2022-04-09 08:01:21 large] (main.py 226): INFO Train: [242/300][400/2502]	eta 0:18:15 lr 0.000049	time 0.5198 (0.5209)	loss 3.2942 (2.9269)	grad_norm 6.8493 (7.6676)	mem 8929MB
[2022-04-09 08:02:11 large] (main.py 226): INFO Train: [242/300][500/2502]	eta 0:17:11 lr 0.000049	time 0.5628 (0.5151)	loss 3.3791 (2.9107)	grad_norm 6.0155 (7.6513)	mem 8929MB
[2022-04-09 08:03:01 large] (main.py 226): INFO Train: [242/300][600/2502]	eta 0:16:16 lr 0.000049	time 0.4853 (0.5135)	loss 2.6607 (2.9221)	grad_norm 15.8758 (7.6735)	mem 8929MB
[2022-04-09 08:03:51 large] (main.py 226): INFO Train: [242/300][700/2502]	eta 0:15:21 lr 0.000049	time 0.5532 (0.5111)	loss 2.1266 (2.9262)	grad_norm 7.2873 (7.6254)	mem 8929MB
[2022-04-09 08:04:41 large] (main.py 226): INFO Train: [242/300][800/2502]	eta 0:14:26 lr 0.000049	time 0.5403 (0.5093)	loss 2.2137 (2.9316)	grad_norm 5.9992 (7.5927)	mem 8929MB
[2022-04-09 08:05:32 large] (main.py 226): INFO Train: [242/300][900/2502]	eta 0:13:36 lr 0.000049	time 0.5168 (0.5100)	loss 3.3231 (2.9353)	grad_norm 6.7050 (7.5964)	mem 8929MB
[2022-04-09 08:06:23 large] (main.py 226): INFO Train: [242/300][1000/2502]	eta 0:12:45 lr 0.000049	time 0.4831 (0.5094)	loss 3.3636 (2.9303)	grad_norm 9.7982 (7.6307)	mem 8929MB
[2022-04-09 08:07:11 large] (main.py 226): INFO Train: [242/300][1100/2502]	eta 0:11:51 lr 0.000049	time 0.5049 (0.5073)	loss 3.2991 (2.9339)	grad_norm 6.7407 (7.6486)	mem 8929MB
[2022-04-09 08:08:02 large] (main.py 226): INFO Train: [242/300][1200/2502]	eta 0:11:00 lr 0.000049	time 0.4923 (0.5072)	loss 2.8389 (2.9361)	grad_norm 8.1734 (7.6823)	mem 8929MB
[2022-04-09 08:08:51 large] (main.py 226): INFO Train: [242/300][1300/2502]	eta 0:10:07 lr 0.000049	time 0.5101 (0.5058)	loss 2.9768 (2.9353)	grad_norm 5.8940 (7.6541)	mem 8929MB
[2022-04-09 08:09:39 large] (main.py 226): INFO Train: [242/300][1400/2502]	eta 0:09:15 lr 0.000048	time 0.5450 (0.5045)	loss 3.3189 (2.9407)	grad_norm 5.8631 (7.6597)	mem 8929MB
[2022-04-09 08:10:29 large] (main.py 226): INFO Train: [242/300][1500/2502]	eta 0:08:24 lr 0.000048	time 0.4960 (0.5039)	loss 3.1095 (2.9461)	grad_norm 8.5878 (inf)	mem 8929MB
[2022-04-09 08:11:20 large] (main.py 226): INFO Train: [242/300][1600/2502]	eta 0:07:35 lr 0.000048	time 0.5294 (0.5046)	loss 3.5200 (2.9454)	grad_norm 9.6062 (inf)	mem 8929MB
[2022-04-09 08:12:12 large] (main.py 226): INFO Train: [242/300][1700/2502]	eta 0:06:45 lr 0.000048	time 0.5197 (0.5053)	loss 2.4211 (2.9465)	grad_norm 5.4558 (inf)	mem 8929MB
[2022-04-09 08:13:04 large] (main.py 226): INFO Train: [242/300][1800/2502]	eta 0:05:55 lr 0.000048	time 0.5072 (0.5060)	loss 3.1527 (2.9504)	grad_norm 10.9328 (inf)	mem 8929MB
[2022-04-09 08:13:55 large] (main.py 226): INFO Train: [242/300][1900/2502]	eta 0:05:04 lr 0.000048	time 0.5359 (0.5063)	loss 3.2004 (2.9507)	grad_norm 7.9026 (inf)	mem 8929MB
[2022-04-09 08:14:45 large] (main.py 226): INFO Train: [242/300][2000/2502]	eta 0:04:14 lr 0.000048	time 0.4560 (0.5060)	loss 3.1456 (2.9511)	grad_norm 5.2198 (inf)	mem 8929MB
[2022-04-09 08:15:35 large] (main.py 226): INFO Train: [242/300][2100/2502]	eta 0:03:23 lr 0.000048	time 0.4740 (0.5057)	loss 3.5716 (2.9536)	grad_norm 7.0946 (inf)	mem 8929MB
[2022-04-09 08:16:24 large] (main.py 226): INFO Train: [242/300][2200/2502]	eta 0:02:32 lr 0.000048	time 0.4886 (0.5051)	loss 2.9716 (2.9511)	grad_norm 7.8054 (inf)	mem 8929MB
[2022-04-09 08:17:14 large] (main.py 226): INFO Train: [242/300][2300/2502]	eta 0:01:41 lr 0.000048	time 0.5153 (0.5046)	loss 3.0518 (2.9496)	grad_norm 7.9170 (inf)	mem 8929MB
[2022-04-09 08:18:05 large] (main.py 226): INFO Train: [242/300][2400/2502]	eta 0:00:51 lr 0.000048	time 0.5236 (0.5049)	loss 2.3822 (2.9482)	grad_norm 5.7630 (inf)	mem 8929MB
[2022-04-09 08:18:56 large] (main.py 226): INFO Train: [242/300][2500/2502]	eta 0:00:01 lr 0.000048	time 0.5031 (0.5051)	loss 3.1373 (2.9493)	grad_norm 7.7723 (inf)	mem 8929MB
[2022-04-09 08:18:57 large] (main.py 233): INFO EPOCH 242 training takes 0:21:04
[2022-04-09 08:19:03 large] (main.py 273): INFO Test: [0/98]	Time 6.074 (6.074)	Loss 1.0748 (1.0748)	Acc@1 77.734 (77.734)	Acc@5 94.141 (94.141)	Mem 8929MB
[2022-04-09 08:19:29 large] (main.py 279): INFO  * Acc@1 80.970 Acc@5 95.258
[2022-04-09 08:19:29 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.0%
[2022-04-09 08:19:29 large] (utils.py 57): INFO output/large/default/ckpt_epoch_242.pth saving......
[2022-04-09 08:19:30 large] (utils.py 59): INFO output/large/default/ckpt_epoch_242.pth saved !!!
[2022-04-09 08:19:30 large] (main.py 148): INFO Max accuracy: 80.97%
[2022-04-09 08:19:38 large] (main.py 226): INFO Train: [243/300][0/2502]	eta 5:34:51 lr 0.000048	time 8.0303 (8.0303)	loss 3.0024 (3.0024)	grad_norm 5.9468 (5.9468)	mem 8929MB
[2022-04-09 08:20:27 large] (main.py 226): INFO Train: [243/300][100/2502]	eta 0:22:33 lr 0.000048	time 0.4711 (0.5633)	loss 3.1994 (2.8599)	grad_norm 8.0890 (7.9189)	mem 8929MB
[2022-04-09 08:21:16 large] (main.py 226): INFO Train: [243/300][200/2502]	eta 0:20:13 lr 0.000048	time 0.4962 (0.5270)	loss 3.2030 (2.9598)	grad_norm 8.6404 (8.1862)	mem 8929MB
[2022-04-09 08:22:06 large] (main.py 226): INFO Train: [243/300][300/2502]	eta 0:18:59 lr 0.000048	time 0.4889 (0.5173)	loss 3.0316 (2.9496)	grad_norm 6.7812 (8.1291)	mem 8929MB
[2022-04-09 08:22:55 large] (main.py 226): INFO Train: [243/300][400/2502]	eta 0:17:56 lr 0.000048	time 0.5115 (0.5122)	loss 1.9989 (2.9498)	grad_norm 6.1875 (8.0748)	mem 8929MB
[2022-04-09 08:23:44 large] (main.py 226): INFO Train: [243/300][500/2502]	eta 0:16:56 lr 0.000048	time 0.4864 (0.5078)	loss 3.3966 (2.9423)	grad_norm 8.4107 (8.1181)	mem 8929MB
[2022-04-09 08:24:36 large] (main.py 226): INFO Train: [243/300][600/2502]	eta 0:16:07 lr 0.000047	time 0.5291 (0.5088)	loss 3.2097 (2.9441)	grad_norm 11.8011 (8.0710)	mem 8929MB
[2022-04-09 08:25:26 large] (main.py 226): INFO Train: [243/300][700/2502]	eta 0:15:14 lr 0.000047	time 0.5144 (0.5073)	loss 3.6191 (2.9451)	grad_norm 8.0195 (8.0657)	mem 8929MB
[2022-04-09 08:26:17 large] (main.py 226): INFO Train: [243/300][800/2502]	eta 0:14:24 lr 0.000047	time 0.4869 (0.5078)	loss 3.3519 (2.9445)	grad_norm 7.2546 (8.0116)	mem 8929MB
[2022-04-09 08:27:05 large] (main.py 226): INFO Train: [243/300][900/2502]	eta 0:13:29 lr 0.000047	time 0.5268 (0.5056)	loss 3.2207 (2.9407)	grad_norm 5.8481 (7.9336)	mem 8929MB
[2022-04-09 08:27:55 large] (main.py 226): INFO Train: [243/300][1000/2502]	eta 0:12:38 lr 0.000047	time 0.4889 (0.5049)	loss 3.0397 (2.9300)	grad_norm 6.5018 (7.9433)	mem 8929MB
[2022-04-09 08:28:45 large] (main.py 226): INFO Train: [243/300][1100/2502]	eta 0:11:47 lr 0.000047	time 0.5205 (0.5045)	loss 3.1513 (2.9306)	grad_norm 10.4404 (7.9404)	mem 8929MB
[2022-04-09 08:29:34 large] (main.py 226): INFO Train: [243/300][1200/2502]	eta 0:10:55 lr 0.000047	time 0.5049 (0.5032)	loss 3.0979 (2.9312)	grad_norm 7.0585 (7.9209)	mem 8929MB
[2022-04-09 08:30:25 large] (main.py 226): INFO Train: [243/300][1300/2502]	eta 0:10:05 lr 0.000047	time 0.5526 (0.5034)	loss 3.1598 (2.9337)	grad_norm 6.3719 (7.9011)	mem 8929MB
[2022-04-09 08:31:16 large] (main.py 226): INFO Train: [243/300][1400/2502]	eta 0:09:15 lr 0.000047	time 0.5750 (0.5041)	loss 3.4171 (2.9349)	grad_norm 6.7367 (7.8560)	mem 8929MB
[2022-04-09 08:32:06 large] (main.py 226): INFO Train: [243/300][1500/2502]	eta 0:08:24 lr 0.000047	time 0.4900 (0.5040)	loss 2.8272 (2.9341)	grad_norm 8.1850 (7.8679)	mem 8929MB
[2022-04-09 08:32:56 large] (main.py 226): INFO Train: [243/300][1600/2502]	eta 0:07:33 lr 0.000047	time 0.5049 (0.5033)	loss 3.6422 (2.9319)	grad_norm 7.6348 (7.8822)	mem 8929MB
[2022-04-09 08:33:46 large] (main.py 226): INFO Train: [243/300][1700/2502]	eta 0:06:43 lr 0.000047	time 0.4788 (0.5031)	loss 3.3865 (2.9300)	grad_norm 6.1486 (7.8795)	mem 8929MB
[2022-04-09 08:34:35 large] (main.py 226): INFO Train: [243/300][1800/2502]	eta 0:05:52 lr 0.000047	time 0.4842 (0.5027)	loss 3.6615 (2.9268)	grad_norm 8.7886 (7.8889)	mem 8929MB
[2022-04-09 08:35:25 large] (main.py 226): INFO Train: [243/300][1900/2502]	eta 0:05:02 lr 0.000047	time 0.6072 (0.5025)	loss 3.0683 (2.9298)	grad_norm 6.9018 (7.8752)	mem 8929MB
[2022-04-09 08:36:17 large] (main.py 226): INFO Train: [243/300][2000/2502]	eta 0:04:12 lr 0.000047	time 0.4859 (0.5032)	loss 2.1120 (2.9268)	grad_norm 4.3014 (7.9488)	mem 8929MB
[2022-04-09 08:37:08 large] (main.py 226): INFO Train: [243/300][2100/2502]	eta 0:03:22 lr 0.000047	time 0.5065 (0.5037)	loss 3.1200 (2.9248)	grad_norm 4.9073 (7.9263)	mem 8929MB
[2022-04-09 08:37:59 large] (main.py 226): INFO Train: [243/300][2200/2502]	eta 0:02:32 lr 0.000047	time 0.4682 (0.5037)	loss 1.8209 (2.9276)	grad_norm 6.3798 (7.9118)	mem 8929MB
[2022-04-09 08:38:47 large] (main.py 226): INFO Train: [243/300][2300/2502]	eta 0:01:41 lr 0.000046	time 0.5370 (0.5028)	loss 3.4981 (2.9309)	grad_norm 7.9165 (7.9072)	mem 8929MB
[2022-04-09 08:39:37 large] (main.py 226): INFO Train: [243/300][2400/2502]	eta 0:00:51 lr 0.000046	time 0.5049 (0.5029)	loss 3.3556 (2.9329)	grad_norm 7.0304 (7.8845)	mem 8929MB
[2022-04-09 08:40:29 large] (main.py 226): INFO Train: [243/300][2500/2502]	eta 0:00:01 lr 0.000046	time 0.4933 (0.5032)	loss 3.3360 (2.9321)	grad_norm 7.8657 (7.9063)	mem 8929MB
[2022-04-09 08:40:30 large] (main.py 233): INFO EPOCH 243 training takes 0:20:59
[2022-04-09 08:40:36 large] (main.py 273): INFO Test: [0/98]	Time 6.627 (6.627)	Loss 0.9803 (0.9803)	Acc@1 81.055 (81.055)	Acc@5 95.312 (95.312)	Mem 8929MB
[2022-04-09 08:41:02 large] (main.py 279): INFO  * Acc@1 80.928 Acc@5 95.310
[2022-04-09 08:41:02 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 80.9%
[2022-04-09 08:41:02 large] (main.py 148): INFO Max accuracy: 80.97%
[2022-04-09 08:41:09 large] (main.py 226): INFO Train: [244/300][0/2502]	eta 4:58:00 lr 0.000046	time 7.1464 (7.1464)	loss 3.4403 (3.4403)	grad_norm 7.5505 (7.5505)	mem 8929MB
[2022-04-09 08:42:00 large] (main.py 226): INFO Train: [244/300][100/2502]	eta 0:23:07 lr 0.000046	time 0.4982 (0.5777)	loss 2.1162 (2.9533)	grad_norm 9.2673 (7.6826)	mem 8929MB
[2022-04-09 08:42:50 large] (main.py 226): INFO Train: [244/300][200/2502]	eta 0:20:36 lr 0.000046	time 0.5136 (0.5371)	loss 2.7523 (2.9775)	grad_norm 6.9887 (7.8595)	mem 8929MB
[2022-04-09 08:43:40 large] (main.py 226): INFO Train: [244/300][300/2502]	eta 0:19:14 lr 0.000046	time 0.4771 (0.5242)	loss 2.1650 (2.9616)	grad_norm 8.1486 (7.8589)	mem 8929MB
[2022-04-09 08:44:32 large] (main.py 226): INFO Train: [244/300][400/2502]	eta 0:18:19 lr 0.000046	time 0.5602 (0.5232)	loss 2.0792 (2.9233)	grad_norm 5.5614 (8.0281)	mem 8929MB
[2022-04-09 08:45:24 large] (main.py 226): INFO Train: [244/300][500/2502]	eta 0:17:26 lr 0.000046	time 0.5099 (0.5229)	loss 3.2219 (2.9177)	grad_norm 6.4629 (8.0158)	mem 8929MB
[2022-04-09 08:46:14 large] (main.py 226): INFO Train: [244/300][600/2502]	eta 0:16:27 lr 0.000046	time 0.5820 (0.5190)	loss 2.7638 (2.8985)	grad_norm 9.4466 (nan)	mem 8929MB
[2022-04-09 08:47:05 large] (main.py 226): INFO Train: [244/300][700/2502]	eta 0:15:33 lr 0.000046	time 0.4846 (0.5180)	loss 2.7787 (2.9092)	grad_norm 79.4310 (nan)	mem 8929MB
[2022-04-09 08:47:55 large] (main.py 226): INFO Train: [244/300][800/2502]	eta 0:14:38 lr 0.000046	time 0.4570 (0.5159)	loss 2.5420 (2.9076)	grad_norm 8.3006 (nan)	mem 8929MB
[2022-04-09 08:48:45 large] (main.py 226): INFO Train: [244/300][900/2502]	eta 0:13:43 lr 0.000046	time 0.4919 (0.5141)	loss 2.2392 (2.9198)	grad_norm 9.4742 (nan)	mem 8929MB
[2022-04-09 08:49:35 large] (main.py 226): INFO Train: [244/300][1000/2502]	eta 0:12:49 lr 0.000046	time 0.5004 (0.5126)	loss 3.4612 (2.9251)	grad_norm 7.1421 (nan)	mem 8929MB
[2022-04-09 08:50:24 large] (main.py 226): INFO Train: [244/300][1100/2502]	eta 0:11:56 lr 0.000046	time 0.4916 (0.5108)	loss 2.9587 (2.9288)	grad_norm 7.9938 (nan)	mem 8929MB
[2022-04-09 08:51:14 large] (main.py 226): INFO Train: [244/300][1200/2502]	eta 0:11:04 lr 0.000046	time 0.5174 (0.5101)	loss 3.4159 (2.9283)	grad_norm 7.4737 (nan)	mem 8929MB
[2022-04-09 08:52:06 large] (main.py 226): INFO Train: [244/300][1300/2502]	eta 0:10:13 lr 0.000046	time 0.5474 (0.5105)	loss 2.7285 (2.9310)	grad_norm 7.6827 (nan)	mem 8929MB
[2022-04-09 08:52:58 large] (main.py 226): INFO Train: [244/300][1400/2502]	eta 0:09:23 lr 0.000046	time 0.5534 (0.5110)	loss 3.1158 (2.9325)	grad_norm 6.6841 (nan)	mem 8929MB
[2022-04-09 08:53:47 large] (main.py 226): INFO Train: [244/300][1500/2502]	eta 0:08:31 lr 0.000045	time 0.4975 (0.5100)	loss 3.3388 (2.9333)	grad_norm 7.1935 (nan)	mem 8929MB
[2022-04-09 08:54:37 large] (main.py 226): INFO Train: [244/300][1600/2502]	eta 0:07:39 lr 0.000045	time 0.4911 (0.5091)	loss 2.8356 (2.9282)	grad_norm 5.7679 (nan)	mem 8929MB
[2022-04-09 08:55:27 large] (main.py 226): INFO Train: [244/300][1700/2502]	eta 0:06:47 lr 0.000045	time 0.5024 (0.5085)	loss 3.5581 (2.9328)	grad_norm 10.7879 (nan)	mem 8929MB
[2022-04-09 08:56:17 large] (main.py 226): INFO Train: [244/300][1800/2502]	eta 0:05:56 lr 0.000045	time 0.4923 (0.5084)	loss 2.5747 (2.9315)	grad_norm 6.9997 (nan)	mem 8929MB
[2022-04-09 08:57:08 large] (main.py 226): INFO Train: [244/300][1900/2502]	eta 0:05:05 lr 0.000045	time 0.5029 (0.5082)	loss 3.0212 (2.9335)	grad_norm 7.4033 (nan)	mem 8929MB
[2022-04-09 08:58:00 large] (main.py 226): INFO Train: [244/300][2000/2502]	eta 0:04:15 lr 0.000045	time 0.4883 (0.5086)	loss 3.1168 (2.9305)	grad_norm 9.6810 (nan)	mem 8929MB
[2022-04-09 08:58:49 large] (main.py 226): INFO Train: [244/300][2100/2502]	eta 0:03:24 lr 0.000045	time 0.4743 (0.5081)	loss 2.9481 (2.9259)	grad_norm 10.4982 (nan)	mem 8929MB
[2022-04-09 08:59:39 large] (main.py 226): INFO Train: [244/300][2200/2502]	eta 0:02:33 lr 0.000045	time 0.5054 (0.5075)	loss 1.8448 (2.9263)	grad_norm 6.4442 (nan)	mem 8929MB
[2022-04-09 09:00:29 large] (main.py 226): INFO Train: [244/300][2300/2502]	eta 0:01:42 lr 0.000045	time 0.4837 (0.5071)	loss 2.2217 (2.9245)	grad_norm 9.3083 (nan)	mem 8929MB
[2022-04-09 09:01:18 large] (main.py 226): INFO Train: [244/300][2400/2502]	eta 0:00:51 lr 0.000045	time 0.4940 (0.5065)	loss 3.5120 (2.9255)	grad_norm 7.9347 (nan)	mem 8929MB
[2022-04-09 09:02:09 large] (main.py 226): INFO Train: [244/300][2500/2502]	eta 0:00:01 lr 0.000045	time 0.4959 (0.5067)	loss 3.5812 (2.9274)	grad_norm 22.7972 (nan)	mem 8929MB
[2022-04-09 09:02:10 large] (main.py 233): INFO EPOCH 244 training takes 0:21:08
[2022-04-09 09:02:16 large] (main.py 273): INFO Test: [0/98]	Time 6.327 (6.327)	Loss 0.9191 (0.9191)	Acc@1 83.398 (83.398)	Acc@5 95.898 (95.898)	Mem 8929MB
[2022-04-09 09:02:42 large] (main.py 279): INFO  * Acc@1 80.954 Acc@5 95.252
[2022-04-09 09:02:42 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.0%
[2022-04-09 09:02:42 large] (main.py 148): INFO Max accuracy: 80.97%
[2022-04-09 09:02:50 large] (main.py 226): INFO Train: [245/300][0/2502]	eta 5:02:26 lr 0.000045	time 7.2528 (7.2528)	loss 3.8677 (3.8677)	grad_norm 9.5939 (9.5939)	mem 8929MB
[2022-04-09 09:03:40 large] (main.py 226): INFO Train: [245/300][100/2502]	eta 0:22:40 lr 0.000045	time 0.5180 (0.5665)	loss 2.4987 (2.9633)	grad_norm 5.9770 (7.6116)	mem 8929MB
[2022-04-09 09:04:28 large] (main.py 226): INFO Train: [245/300][200/2502]	eta 0:20:13 lr 0.000045	time 0.5721 (0.5273)	loss 3.0191 (2.9435)	grad_norm 7.0463 (7.7343)	mem 8929MB
[2022-04-09 09:05:18 large] (main.py 226): INFO Train: [245/300][300/2502]	eta 0:18:59 lr 0.000045	time 0.5259 (0.5174)	loss 3.1508 (2.9290)	grad_norm 7.9666 (7.7826)	mem 8929MB
[2022-04-09 09:06:08 large] (main.py 226): INFO Train: [245/300][400/2502]	eta 0:17:59 lr 0.000045	time 0.4561 (0.5136)	loss 2.8950 (2.9356)	grad_norm 5.5031 (7.7556)	mem 8929MB
[2022-04-09 09:06:59 large] (main.py 226): INFO Train: [245/300][500/2502]	eta 0:17:03 lr 0.000045	time 0.5043 (0.5115)	loss 2.6966 (2.9395)	grad_norm 6.8449 (7.8510)	mem 8929MB
[2022-04-09 09:07:51 large] (main.py 226): INFO Train: [245/300][600/2502]	eta 0:16:16 lr 0.000045	time 0.5109 (0.5135)	loss 2.1539 (2.9374)	grad_norm 7.5109 (7.8797)	mem 8929MB
[2022-04-09 09:08:43 large] (main.py 226): INFO Train: [245/300][700/2502]	eta 0:15:27 lr 0.000045	time 0.5255 (0.5147)	loss 2.6842 (2.9414)	grad_norm 7.7580 (7.8553)	mem 8929MB
[2022-04-09 09:09:35 large] (main.py 226): INFO Train: [245/300][800/2502]	eta 0:14:36 lr 0.000044	time 0.4954 (0.5151)	loss 3.2981 (2.9307)	grad_norm 9.2158 (7.8535)	mem 8929MB
[2022-04-09 09:10:25 large] (main.py 226): INFO Train: [245/300][900/2502]	eta 0:13:42 lr 0.000044	time 0.4902 (0.5132)	loss 2.5751 (2.9382)	grad_norm 5.8649 (7.8373)	mem 8929MB
[2022-04-09 09:11:16 large] (main.py 226): INFO Train: [245/300][1000/2502]	eta 0:12:50 lr 0.000044	time 0.5960 (0.5132)	loss 2.6514 (2.9342)	grad_norm 6.7917 (7.9621)	mem 8929MB
[2022-04-09 09:12:06 large] (main.py 226): INFO Train: [245/300][1100/2502]	eta 0:11:57 lr 0.000044	time 0.4703 (0.5121)	loss 3.1543 (2.9328)	grad_norm 7.0797 (7.9774)	mem 8929MB
[2022-04-09 09:12:58 large] (main.py 226): INFO Train: [245/300][1200/2502]	eta 0:11:06 lr 0.000044	time 0.5272 (0.5123)	loss 3.1128 (2.9362)	grad_norm 5.7871 (7.9301)	mem 8929MB
[2022-04-09 09:13:47 large] (main.py 226): INFO Train: [245/300][1300/2502]	eta 0:10:14 lr 0.000044	time 0.5120 (0.5111)	loss 2.9504 (2.9404)	grad_norm 12.5595 (7.9542)	mem 8929MB
[2022-04-09 09:14:37 large] (main.py 226): INFO Train: [245/300][1400/2502]	eta 0:09:22 lr 0.000044	time 0.4901 (0.5100)	loss 3.4252 (2.9317)	grad_norm 5.9929 (7.9568)	mem 8929MB
[2022-04-09 09:15:28 large] (main.py 226): INFO Train: [245/300][1500/2502]	eta 0:08:31 lr 0.000044	time 0.5261 (0.5104)	loss 3.1610 (2.9266)	grad_norm 6.8163 (7.9664)	mem 8929MB
[2022-04-09 09:16:18 large] (main.py 226): INFO Train: [245/300][1600/2502]	eta 0:07:39 lr 0.000044	time 0.4931 (0.5098)	loss 3.5032 (2.9203)	grad_norm 6.5091 (7.9639)	mem 8929MB
[2022-04-09 09:17:08 large] (main.py 226): INFO Train: [245/300][1700/2502]	eta 0:06:48 lr 0.000044	time 0.5139 (0.5090)	loss 2.5320 (2.9175)	grad_norm 6.9739 (7.9380)	mem 8929MB
[2022-04-09 09:17:58 large] (main.py 226): INFO Train: [245/300][1800/2502]	eta 0:05:57 lr 0.000044	time 0.5477 (0.5086)	loss 2.4452 (2.9162)	grad_norm 6.6210 (7.9897)	mem 8929MB
[2022-04-09 09:18:49 large] (main.py 226): INFO Train: [245/300][1900/2502]	eta 0:05:06 lr 0.000044	time 0.5132 (0.5085)	loss 3.1221 (2.9196)	grad_norm 11.4189 (8.0349)	mem 8929MB
[2022-04-09 09:19:39 large] (main.py 226): INFO Train: [245/300][2000/2502]	eta 0:04:14 lr 0.000044	time 0.5234 (0.5080)	loss 3.1271 (2.9204)	grad_norm 6.5391 (8.0611)	mem 8929MB
[2022-04-09 09:20:30 large] (main.py 226): INFO Train: [245/300][2100/2502]	eta 0:03:24 lr 0.000044	time 0.5124 (0.5084)	loss 3.4119 (2.9222)	grad_norm 10.7635 (8.0698)	mem 8929MB
[2022-04-09 09:21:22 large] (main.py 226): INFO Train: [245/300][2200/2502]	eta 0:02:33 lr 0.000044	time 0.4763 (0.5088)	loss 2.4428 (2.9231)	grad_norm 5.6747 (8.0378)	mem 8929MB
[2022-04-09 09:22:12 large] (main.py 226): INFO Train: [245/300][2300/2502]	eta 0:01:42 lr 0.000044	time 0.5587 (0.5084)	loss 3.2415 (2.9279)	grad_norm 7.4315 (8.0360)	mem 8929MB
[2022-04-09 09:23:02 large] (main.py 226): INFO Train: [245/300][2400/2502]	eta 0:00:51 lr 0.000044	time 0.5030 (0.5080)	loss 2.8100 (2.9321)	grad_norm 11.5106 (8.0355)	mem 8929MB
[2022-04-09 09:23:53 large] (main.py 226): INFO Train: [245/300][2500/2502]	eta 0:00:01 lr 0.000044	time 0.4904 (0.5081)	loss 3.1000 (2.9337)	grad_norm 6.5397 (8.0309)	mem 8929MB
[2022-04-09 09:23:54 large] (main.py 233): INFO EPOCH 245 training takes 0:21:11
[2022-04-09 09:24:01 large] (main.py 273): INFO Test: [0/98]	Time 6.871 (6.871)	Loss 0.9624 (0.9624)	Acc@1 82.422 (82.422)	Acc@5 95.703 (95.703)	Mem 8929MB
[2022-04-09 09:24:26 large] (main.py 279): INFO  * Acc@1 80.966 Acc@5 95.364
[2022-04-09 09:24:26 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.0%
[2022-04-09 09:24:26 large] (main.py 148): INFO Max accuracy: 80.97%
[2022-04-09 09:24:33 large] (main.py 226): INFO Train: [246/300][0/2502]	eta 4:37:27 lr 0.000044	time 6.6536 (6.6536)	loss 2.2206 (2.2206)	grad_norm 5.9233 (5.9233)	mem 8929MB
[2022-04-09 09:25:23 large] (main.py 226): INFO Train: [246/300][100/2502]	eta 0:22:37 lr 0.000043	time 0.4997 (0.5653)	loss 3.3813 (2.8991)	grad_norm 11.9091 (7.6837)	mem 8929MB
[2022-04-09 09:26:14 large] (main.py 226): INFO Train: [246/300][200/2502]	eta 0:20:30 lr 0.000043	time 0.4814 (0.5346)	loss 2.9754 (2.8846)	grad_norm 6.3110 (7.6661)	mem 8929MB
[2022-04-09 09:27:03 large] (main.py 226): INFO Train: [246/300][300/2502]	eta 0:19:06 lr 0.000043	time 0.4812 (0.5206)	loss 2.9722 (2.9085)	grad_norm 6.9997 (7.8166)	mem 8929MB
[2022-04-09 09:27:52 large] (main.py 226): INFO Train: [246/300][400/2502]	eta 0:18:00 lr 0.000043	time 0.4946 (0.5138)	loss 3.2637 (2.8913)	grad_norm 6.6104 (7.8629)	mem 8929MB
[2022-04-09 09:28:42 large] (main.py 226): INFO Train: [246/300][500/2502]	eta 0:17:02 lr 0.000043	time 0.4844 (0.5107)	loss 2.9675 (2.8941)	grad_norm 6.1674 (7.7711)	mem 8929MB
[2022-04-09 09:29:34 large] (main.py 226): INFO Train: [246/300][600/2502]	eta 0:16:13 lr 0.000043	time 0.5049 (0.5121)	loss 3.0804 (2.8866)	grad_norm 7.5030 (7.7632)	mem 8929MB
[2022-04-09 09:30:26 large] (main.py 226): INFO Train: [246/300][700/2502]	eta 0:15:25 lr 0.000043	time 0.5297 (0.5135)	loss 2.5910 (2.8856)	grad_norm 8.0991 (7.7678)	mem 8929MB
[2022-04-09 09:31:15 large] (main.py 226): INFO Train: [246/300][800/2502]	eta 0:14:28 lr 0.000043	time 0.5107 (0.5105)	loss 3.0670 (2.8876)	grad_norm 6.6049 (7.7127)	mem 8929MB
[2022-04-09 09:32:04 large] (main.py 226): INFO Train: [246/300][900/2502]	eta 0:13:34 lr 0.000043	time 0.4891 (0.5082)	loss 2.7790 (2.8992)	grad_norm 6.3635 (7.7150)	mem 8929MB
[2022-04-09 09:32:53 large] (main.py 226): INFO Train: [246/300][1000/2502]	eta 0:12:40 lr 0.000043	time 0.4709 (0.5061)	loss 2.7251 (2.9073)	grad_norm 7.2152 (7.6978)	mem 8929MB
[2022-04-09 09:33:42 large] (main.py 226): INFO Train: [246/300][1100/2502]	eta 0:11:48 lr 0.000043	time 0.4828 (0.5051)	loss 3.2826 (2.9068)	grad_norm 7.5270 (7.7057)	mem 8929MB
[2022-04-09 09:34:32 large] (main.py 226): INFO Train: [246/300][1200/2502]	eta 0:10:56 lr 0.000043	time 0.4984 (0.5041)	loss 1.5977 (2.9045)	grad_norm 6.6066 (7.7084)	mem 8929MB
[2022-04-09 09:35:23 large] (main.py 226): INFO Train: [246/300][1300/2502]	eta 0:10:06 lr 0.000043	time 0.5293 (0.5049)	loss 2.8089 (2.9077)	grad_norm 9.5333 (7.7143)	mem 8929MB
[2022-04-09 09:36:13 large] (main.py 226): INFO Train: [246/300][1400/2502]	eta 0:09:16 lr 0.000043	time 0.5020 (0.5047)	loss 2.1610 (2.9087)	grad_norm 6.7091 (7.7240)	mem 8929MB
[2022-04-09 09:37:05 large] (main.py 226): INFO Train: [246/300][1500/2502]	eta 0:08:26 lr 0.000043	time 0.5115 (0.5057)	loss 2.9814 (2.9123)	grad_norm 7.2319 (7.7215)	mem 8929MB
[2022-04-09 09:37:56 large] (main.py 226): INFO Train: [246/300][1600/2502]	eta 0:07:35 lr 0.000043	time 0.4832 (0.5055)	loss 2.1285 (2.9113)	grad_norm 14.6189 (7.7052)	mem 8929MB
[2022-04-09 09:38:45 large] (main.py 226): INFO Train: [246/300][1700/2502]	eta 0:06:44 lr 0.000043	time 0.4923 (0.5045)	loss 2.6443 (2.9056)	grad_norm 8.0020 (7.7343)	mem 8929MB
[2022-04-09 09:39:34 large] (main.py 226): INFO Train: [246/300][1800/2502]	eta 0:05:53 lr 0.000043	time 0.4527 (0.5038)	loss 3.2354 (2.9050)	grad_norm 7.4079 (7.7570)	mem 8929MB
[2022-04-09 09:40:23 large] (main.py 226): INFO Train: [246/300][1900/2502]	eta 0:05:02 lr 0.000042	time 0.4978 (0.5031)	loss 2.2826 (2.9029)	grad_norm 7.6764 (7.7636)	mem 8929MB
[2022-04-09 09:41:13 large] (main.py 226): INFO Train: [246/300][2000/2502]	eta 0:04:12 lr 0.000042	time 0.5821 (0.5032)	loss 1.7877 (2.9011)	grad_norm 5.8803 (7.7452)	mem 8929MB
[2022-04-09 09:42:02 large] (main.py 226): INFO Train: [246/300][2100/2502]	eta 0:03:21 lr 0.000042	time 0.4805 (0.5023)	loss 2.7734 (2.9006)	grad_norm 8.8012 (7.7682)	mem 8929MB
[2022-04-09 09:42:51 large] (main.py 226): INFO Train: [246/300][2200/2502]	eta 0:02:31 lr 0.000042	time 0.4837 (0.5020)	loss 3.1397 (2.9017)	grad_norm 8.8510 (7.7973)	mem 8929MB
[2022-04-09 09:43:43 large] (main.py 226): INFO Train: [246/300][2300/2502]	eta 0:01:41 lr 0.000042	time 0.5555 (0.5025)	loss 2.0407 (2.8972)	grad_norm 5.6534 (7.7931)	mem 8929MB
[2022-04-09 09:44:35 large] (main.py 226): INFO Train: [246/300][2400/2502]	eta 0:00:51 lr 0.000042	time 0.5216 (0.5032)	loss 2.2559 (2.9002)	grad_norm 8.1394 (nan)	mem 8929MB
[2022-04-09 09:45:24 large] (main.py 226): INFO Train: [246/300][2500/2502]	eta 0:00:01 lr 0.000042	time 0.5067 (0.5029)	loss 3.4817 (2.9025)	grad_norm 8.2262 (nan)	mem 8929MB
[2022-04-09 09:45:25 large] (main.py 233): INFO EPOCH 246 training takes 0:20:58
[2022-04-09 09:45:32 large] (main.py 273): INFO Test: [0/98]	Time 6.784 (6.784)	Loss 1.0522 (1.0522)	Acc@1 78.711 (78.711)	Acc@5 94.727 (94.727)	Mem 8929MB
[2022-04-09 09:45:58 large] (main.py 279): INFO  * Acc@1 81.126 Acc@5 95.406
[2022-04-09 09:45:58 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.1%
[2022-04-09 09:45:58 large] (utils.py 57): INFO output/large/default/ckpt_epoch_246.pth saving......
[2022-04-09 09:45:59 large] (utils.py 59): INFO output/large/default/ckpt_epoch_246.pth saved !!!
[2022-04-09 09:45:59 large] (main.py 148): INFO Max accuracy: 81.13%
[2022-04-09 09:46:06 large] (main.py 226): INFO Train: [247/300][0/2502]	eta 5:18:11 lr 0.000042	time 7.6305 (7.6305)	loss 3.1322 (3.1322)	grad_norm 8.3266 (8.3266)	mem 8929MB
[2022-04-09 09:46:56 large] (main.py 226): INFO Train: [247/300][100/2502]	eta 0:22:42 lr 0.000042	time 0.4990 (0.5671)	loss 3.4423 (2.9024)	grad_norm 7.2524 (8.3364)	mem 8929MB
[2022-04-09 09:47:46 large] (main.py 226): INFO Train: [247/300][200/2502]	eta 0:20:26 lr 0.000042	time 0.5229 (0.5329)	loss 2.9581 (2.8652)	grad_norm 8.3860 (7.9635)	mem 8929MB
[2022-04-09 09:48:36 large] (main.py 226): INFO Train: [247/300][300/2502]	eta 0:19:10 lr 0.000042	time 0.5468 (0.5223)	loss 3.0464 (2.8679)	grad_norm 8.9144 (8.0267)	mem 8929MB
[2022-04-09 09:49:28 large] (main.py 226): INFO Train: [247/300][400/2502]	eta 0:18:15 lr 0.000042	time 0.4960 (0.5212)	loss 3.3551 (2.8893)	grad_norm 7.9732 (7.9126)	mem 8929MB
[2022-04-09 09:50:20 large] (main.py 226): INFO Train: [247/300][500/2502]	eta 0:17:22 lr 0.000042	time 0.5398 (0.5209)	loss 2.4286 (2.8875)	grad_norm 11.0581 (7.9728)	mem 8929MB
[2022-04-09 09:51:10 large] (main.py 226): INFO Train: [247/300][600/2502]	eta 0:16:26 lr 0.000042	time 0.4968 (0.5185)	loss 2.4835 (2.8998)	grad_norm 8.4635 (7.9460)	mem 8929MB
[2022-04-09 09:52:00 large] (main.py 226): INFO Train: [247/300][700/2502]	eta 0:15:28 lr 0.000042	time 0.5240 (0.5150)	loss 3.1368 (2.8860)	grad_norm 5.6852 (7.9319)	mem 8929MB
[2022-04-09 09:52:52 large] (main.py 226): INFO Train: [247/300][800/2502]	eta 0:14:37 lr 0.000042	time 0.5055 (0.5156)	loss 3.4214 (2.8864)	grad_norm 7.5057 (7.9660)	mem 8929MB
[2022-04-09 09:53:44 large] (main.py 226): INFO Train: [247/300][900/2502]	eta 0:13:46 lr 0.000042	time 0.5041 (0.5160)	loss 3.5379 (2.8813)	grad_norm 6.1404 (7.9410)	mem 8929MB
[2022-04-09 09:54:35 large] (main.py 226): INFO Train: [247/300][1000/2502]	eta 0:12:55 lr 0.000042	time 0.4975 (0.5163)	loss 3.1084 (2.8826)	grad_norm 7.4713 (7.9010)	mem 8929MB
[2022-04-09 09:55:25 large] (main.py 226): INFO Train: [247/300][1100/2502]	eta 0:12:01 lr 0.000042	time 0.4795 (0.5145)	loss 2.8209 (2.8840)	grad_norm 5.3224 (7.8920)	mem 8929MB
[2022-04-09 09:56:14 large] (main.py 226): INFO Train: [247/300][1200/2502]	eta 0:11:07 lr 0.000041	time 0.4624 (0.5124)	loss 3.7655 (2.8882)	grad_norm 15.4921 (7.9083)	mem 8929MB
[2022-04-09 09:57:04 large] (main.py 226): INFO Train: [247/300][1300/2502]	eta 0:10:14 lr 0.000041	time 0.4853 (0.5111)	loss 1.6459 (2.8850)	grad_norm 6.5481 (7.9306)	mem 8929MB
[2022-04-09 09:57:55 large] (main.py 226): INFO Train: [247/300][1400/2502]	eta 0:09:23 lr 0.000041	time 0.5176 (0.5113)	loss 3.1811 (2.8911)	grad_norm 6.5679 (7.9484)	mem 8929MB
[2022-04-09 09:58:47 large] (main.py 226): INFO Train: [247/300][1500/2502]	eta 0:08:32 lr 0.000041	time 0.5006 (0.5116)	loss 2.9176 (2.8930)	grad_norm 10.9648 (7.9912)	mem 8929MB
[2022-04-09 09:59:38 large] (main.py 226): INFO Train: [247/300][1600/2502]	eta 0:07:41 lr 0.000041	time 0.4931 (0.5119)	loss 2.8243 (2.8966)	grad_norm 6.0623 (7.9796)	mem 8929MB
[2022-04-09 10:00:28 large] (main.py 226): INFO Train: [247/300][1700/2502]	eta 0:06:49 lr 0.000041	time 0.4912 (0.5110)	loss 3.2235 (2.8980)	grad_norm 7.0284 (7.9703)	mem 8929MB
[2022-04-09 10:01:17 large] (main.py 226): INFO Train: [247/300][1800/2502]	eta 0:05:57 lr 0.000041	time 0.4992 (0.5098)	loss 3.3839 (2.8999)	grad_norm 6.2505 (7.9828)	mem 8929MB
[2022-04-09 10:02:08 large] (main.py 226): INFO Train: [247/300][1900/2502]	eta 0:05:07 lr 0.000041	time 0.5054 (0.5101)	loss 2.7427 (2.8998)	grad_norm 6.5550 (7.9961)	mem 8929MB
[2022-04-09 10:03:00 large] (main.py 226): INFO Train: [247/300][2000/2502]	eta 0:04:16 lr 0.000041	time 0.5035 (0.5107)	loss 2.9558 (2.8993)	grad_norm 6.6955 (8.0168)	mem 8929MB
[2022-04-09 10:03:52 large] (main.py 226): INFO Train: [247/300][2100/2502]	eta 0:03:25 lr 0.000041	time 0.5299 (0.5110)	loss 2.9674 (2.9010)	grad_norm 6.4461 (8.0623)	mem 8929MB
[2022-04-09 10:04:44 large] (main.py 226): INFO Train: [247/300][2200/2502]	eta 0:02:34 lr 0.000041	time 0.5104 (0.5111)	loss 3.0576 (2.8988)	grad_norm 6.7045 (8.0521)	mem 8929MB
[2022-04-09 10:05:33 large] (main.py 226): INFO Train: [247/300][2300/2502]	eta 0:01:43 lr 0.000041	time 0.5177 (0.5105)	loss 3.0288 (2.8963)	grad_norm 10.8125 (8.0728)	mem 8929MB
[2022-04-09 10:06:22 large] (main.py 226): INFO Train: [247/300][2400/2502]	eta 0:00:51 lr 0.000041	time 0.4621 (0.5094)	loss 3.2920 (2.8963)	grad_norm 6.2682 (8.0926)	mem 8929MB
[2022-04-09 10:07:11 large] (main.py 226): INFO Train: [247/300][2500/2502]	eta 0:00:01 lr 0.000041	time 0.4809 (0.5086)	loss 1.6785 (2.8995)	grad_norm 6.1329 (8.1065)	mem 8929MB
[2022-04-09 10:07:11 large] (main.py 233): INFO EPOCH 247 training takes 0:21:12
[2022-04-09 10:07:18 large] (main.py 273): INFO Test: [0/98]	Time 6.111 (6.111)	Loss 0.9169 (0.9169)	Acc@1 82.422 (82.422)	Acc@5 96.094 (96.094)	Mem 8929MB
[2022-04-09 10:07:44 large] (main.py 279): INFO  * Acc@1 81.072 Acc@5 95.464
[2022-04-09 10:07:44 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.1%
[2022-04-09 10:07:44 large] (main.py 148): INFO Max accuracy: 81.13%
[2022-04-09 10:07:51 large] (main.py 226): INFO Train: [248/300][0/2502]	eta 5:16:47 lr 0.000041	time 7.5968 (7.5968)	loss 3.3603 (3.3603)	grad_norm 8.9599 (8.9599)	mem 8929MB
[2022-04-09 10:08:42 large] (main.py 226): INFO Train: [248/300][100/2502]	eta 0:22:56 lr 0.000041	time 0.4479 (0.5732)	loss 1.6803 (2.8304)	grad_norm 5.9985 (8.1292)	mem 8929MB
[2022-04-09 10:09:31 large] (main.py 226): INFO Train: [248/300][200/2502]	eta 0:20:30 lr 0.000041	time 0.5011 (0.5347)	loss 1.8504 (2.8462)	grad_norm 7.7349 (8.4088)	mem 8929MB
[2022-04-09 10:10:21 large] (main.py 226): INFO Train: [248/300][300/2502]	eta 0:19:09 lr 0.000041	time 0.5399 (0.5221)	loss 2.4699 (2.8521)	grad_norm 8.3688 (8.3790)	mem 8929MB
[2022-04-09 10:11:14 large] (main.py 226): INFO Train: [248/300][400/2502]	eta 0:18:19 lr 0.000041	time 0.4957 (0.5230)	loss 3.5700 (2.8614)	grad_norm 7.0485 (8.3140)	mem 8929MB
[2022-04-09 10:12:07 large] (main.py 226): INFO Train: [248/300][500/2502]	eta 0:17:31 lr 0.000041	time 0.5550 (0.5252)	loss 2.3139 (2.8737)	grad_norm 6.1829 (8.2418)	mem 8929MB
[2022-04-09 10:12:57 large] (main.py 226): INFO Train: [248/300][600/2502]	eta 0:16:30 lr 0.000040	time 0.4802 (0.5210)	loss 3.2364 (2.8749)	grad_norm 10.1750 (8.2048)	mem 8929MB
[2022-04-09 10:13:48 large] (main.py 226): INFO Train: [248/300][700/2502]	eta 0:15:35 lr 0.000040	time 0.5133 (0.5190)	loss 1.8944 (2.8748)	grad_norm 7.7563 (nan)	mem 8929MB
[2022-04-09 10:14:39 large] (main.py 226): INFO Train: [248/300][800/2502]	eta 0:14:42 lr 0.000040	time 0.4931 (0.5185)	loss 3.1524 (2.8761)	grad_norm 9.0450 (nan)	mem 8929MB
[2022-04-09 10:15:28 large] (main.py 226): INFO Train: [248/300][900/2502]	eta 0:13:45 lr 0.000040	time 0.4781 (0.5150)	loss 2.5374 (2.8798)	grad_norm 10.5506 (nan)	mem 8929MB
[2022-04-09 10:16:18 large] (main.py 226): INFO Train: [248/300][1000/2502]	eta 0:12:51 lr 0.000040	time 0.4648 (0.5137)	loss 3.1922 (2.8824)	grad_norm 8.0543 (nan)	mem 8929MB
[2022-04-09 10:17:07 large] (main.py 226): INFO Train: [248/300][1100/2502]	eta 0:11:56 lr 0.000040	time 0.4711 (0.5113)	loss 1.8232 (2.8843)	grad_norm 10.6147 (nan)	mem 8929MB
[2022-04-09 10:17:57 large] (main.py 226): INFO Train: [248/300][1200/2502]	eta 0:11:05 lr 0.000040	time 0.5298 (0.5108)	loss 3.5819 (2.8865)	grad_norm 9.8949 (nan)	mem 8929MB
[2022-04-09 10:18:48 large] (main.py 226): INFO Train: [248/300][1300/2502]	eta 0:10:13 lr 0.000040	time 0.5619 (0.5101)	loss 3.0721 (2.8846)	grad_norm 5.3954 (nan)	mem 8929MB
[2022-04-09 10:19:40 large] (main.py 226): INFO Train: [248/300][1400/2502]	eta 0:09:23 lr 0.000040	time 0.5200 (0.5111)	loss 3.3620 (2.8831)	grad_norm 7.2910 (nan)	mem 8929MB
[2022-04-09 10:20:32 large] (main.py 226): INFO Train: [248/300][1500/2502]	eta 0:08:33 lr 0.000040	time 0.5252 (0.5121)	loss 3.2068 (2.8859)	grad_norm 6.7452 (nan)	mem 8929MB
[2022-04-09 10:21:24 large] (main.py 226): INFO Train: [248/300][1600/2502]	eta 0:07:42 lr 0.000040	time 0.4695 (0.5125)	loss 3.4071 (2.8835)	grad_norm 9.0170 (nan)	mem 8929MB
[2022-04-09 10:22:17 large] (main.py 226): INFO Train: [248/300][1700/2502]	eta 0:06:51 lr 0.000040	time 0.5637 (0.5130)	loss 2.7879 (2.8851)	grad_norm 7.1202 (nan)	mem 8929MB
[2022-04-09 10:23:08 large] (main.py 226): INFO Train: [248/300][1800/2502]	eta 0:06:00 lr 0.000040	time 0.4468 (0.5129)	loss 3.1547 (2.8844)	grad_norm 7.0655 (nan)	mem 8929MB
[2022-04-09 10:23:57 large] (main.py 226): INFO Train: [248/300][1900/2502]	eta 0:05:08 lr 0.000040	time 0.5012 (0.5119)	loss 3.4128 (2.8871)	grad_norm 12.5478 (nan)	mem 8929MB
[2022-04-09 10:24:47 large] (main.py 226): INFO Train: [248/300][2000/2502]	eta 0:04:16 lr 0.000040	time 0.5556 (0.5113)	loss 3.2299 (2.8880)	grad_norm 9.0775 (nan)	mem 8929MB
[2022-04-09 10:25:36 large] (main.py 226): INFO Train: [248/300][2100/2502]	eta 0:03:25 lr 0.000040	time 0.5009 (0.5102)	loss 3.3414 (2.8908)	grad_norm 6.0974 (nan)	mem 8929MB
[2022-04-09 10:26:27 large] (main.py 226): INFO Train: [248/300][2200/2502]	eta 0:02:34 lr 0.000040	time 0.5447 (0.5103)	loss 3.0798 (2.8903)	grad_norm 6.4595 (nan)	mem 8929MB
[2022-04-09 10:27:18 large] (main.py 226): INFO Train: [248/300][2300/2502]	eta 0:01:43 lr 0.000040	time 0.4840 (0.5104)	loss 2.3698 (2.8885)	grad_norm 7.3130 (nan)	mem 8929MB
[2022-04-09 10:28:07 large] (main.py 226): INFO Train: [248/300][2400/2502]	eta 0:00:51 lr 0.000040	time 0.5161 (0.5096)	loss 3.6311 (2.8863)	grad_norm 6.6829 (nan)	mem 8929MB
[2022-04-09 10:28:57 large] (main.py 226): INFO Train: [248/300][2500/2502]	eta 0:00:01 lr 0.000039	time 0.4954 (0.5090)	loss 3.4406 (2.8880)	grad_norm 8.8594 (nan)	mem 8929MB
[2022-04-09 10:28:58 large] (main.py 233): INFO EPOCH 248 training takes 0:21:13
[2022-04-09 10:29:04 large] (main.py 273): INFO Test: [0/98]	Time 6.175 (6.175)	Loss 0.8987 (0.8987)	Acc@1 82.422 (82.422)	Acc@5 96.680 (96.680)	Mem 8929MB
[2022-04-09 10:29:30 large] (main.py 279): INFO  * Acc@1 81.082 Acc@5 95.400
[2022-04-09 10:29:30 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.1%
[2022-04-09 10:29:30 large] (main.py 148): INFO Max accuracy: 81.13%
[2022-04-09 10:29:37 large] (main.py 226): INFO Train: [249/300][0/2502]	eta 4:39:28 lr 0.000039	time 6.7019 (6.7019)	loss 2.7397 (2.7397)	grad_norm 7.4716 (7.4716)	mem 8929MB
[2022-04-09 10:30:28 large] (main.py 226): INFO Train: [249/300][100/2502]	eta 0:22:45 lr 0.000039	time 0.4939 (0.5684)	loss 1.8374 (2.9334)	grad_norm 10.0154 (9.0401)	mem 8929MB
[2022-04-09 10:31:20 large] (main.py 226): INFO Train: [249/300][200/2502]	eta 0:20:54 lr 0.000039	time 0.5160 (0.5450)	loss 3.1375 (2.8853)	grad_norm 16.3445 (8.9489)	mem 8929MB
[2022-04-09 10:32:09 large] (main.py 226): INFO Train: [249/300][300/2502]	eta 0:19:22 lr 0.000039	time 0.4795 (0.5278)	loss 3.0887 (2.8703)	grad_norm 8.0081 (8.7496)	mem 8929MB
[2022-04-09 10:32:58 large] (main.py 226): INFO Train: [249/300][400/2502]	eta 0:18:07 lr 0.000039	time 0.4798 (0.5174)	loss 3.3918 (2.8863)	grad_norm 10.6607 (8.6064)	mem 8929MB
[2022-04-09 10:33:48 large] (main.py 226): INFO Train: [249/300][500/2502]	eta 0:17:10 lr 0.000039	time 0.4893 (0.5145)	loss 3.0860 (2.8837)	grad_norm 8.6850 (8.4750)	mem 8929MB
[2022-04-09 10:34:40 large] (main.py 226): INFO Train: [249/300][600/2502]	eta 0:16:19 lr 0.000039	time 0.5423 (0.5148)	loss 3.5530 (2.8948)	grad_norm 10.7445 (8.4269)	mem 8929MB
[2022-04-09 10:35:30 large] (main.py 226): INFO Train: [249/300][700/2502]	eta 0:15:25 lr 0.000039	time 0.5056 (0.5135)	loss 3.5043 (2.8960)	grad_norm 7.9219 (8.4396)	mem 8929MB
[2022-04-09 10:36:20 large] (main.py 226): INFO Train: [249/300][800/2502]	eta 0:14:31 lr 0.000039	time 0.5206 (0.5118)	loss 3.5293 (2.8915)	grad_norm 4.7876 (8.3788)	mem 8929MB
[2022-04-09 10:37:10 large] (main.py 226): INFO Train: [249/300][900/2502]	eta 0:13:37 lr 0.000039	time 0.5130 (0.5104)	loss 2.5318 (2.8951)	grad_norm 7.8346 (8.4442)	mem 8929MB
[2022-04-09 10:38:02 large] (main.py 226): INFO Train: [249/300][1000/2502]	eta 0:12:47 lr 0.000039	time 0.4656 (0.5112)	loss 1.7438 (2.8999)	grad_norm 8.4626 (8.4466)	mem 8929MB
[2022-04-09 10:38:53 large] (main.py 226): INFO Train: [249/300][1100/2502]	eta 0:11:55 lr 0.000039	time 0.5423 (0.5107)	loss 3.5443 (2.9008)	grad_norm 15.9506 (8.4498)	mem 8929MB
[2022-04-09 10:39:45 large] (main.py 226): INFO Train: [249/300][1200/2502]	eta 0:11:06 lr 0.000039	time 0.5701 (0.5116)	loss 3.0964 (2.9025)	grad_norm 6.8827 (8.4213)	mem 8929MB
[2022-04-09 10:40:35 large] (main.py 226): INFO Train: [249/300][1300/2502]	eta 0:10:14 lr 0.000039	time 0.5000 (0.5112)	loss 3.5451 (2.8997)	grad_norm 6.6343 (8.4563)	mem 8929MB
[2022-04-09 10:41:25 large] (main.py 226): INFO Train: [249/300][1400/2502]	eta 0:09:22 lr 0.000039	time 0.5059 (0.5101)	loss 3.0517 (2.9032)	grad_norm 8.5611 (8.4441)	mem 8929MB
[2022-04-09 10:42:15 large] (main.py 226): INFO Train: [249/300][1500/2502]	eta 0:08:30 lr 0.000039	time 0.5197 (0.5095)	loss 3.0459 (2.9068)	grad_norm 7.6690 (8.4324)	mem 8929MB
[2022-04-09 10:43:07 large] (main.py 226): INFO Train: [249/300][1600/2502]	eta 0:07:40 lr 0.000039	time 0.5142 (0.5102)	loss 2.3678 (2.9066)	grad_norm 6.0513 (8.4371)	mem 8929MB
[2022-04-09 10:43:59 large] (main.py 226): INFO Train: [249/300][1700/2502]	eta 0:06:49 lr 0.000039	time 0.5153 (0.5107)	loss 3.1744 (2.9083)	grad_norm 9.3890 (8.4381)	mem 8929MB
[2022-04-09 10:44:49 large] (main.py 226): INFO Train: [249/300][1800/2502]	eta 0:05:58 lr 0.000039	time 0.5138 (0.5101)	loss 2.3126 (2.9055)	grad_norm 6.9263 (8.4746)	mem 8929MB
[2022-04-09 10:45:41 large] (main.py 226): INFO Train: [249/300][1900/2502]	eta 0:05:07 lr 0.000038	time 0.5110 (0.5104)	loss 3.4088 (2.9069)	grad_norm 6.0686 (8.4379)	mem 8929MB
[2022-04-09 10:46:32 large] (main.py 226): INFO Train: [249/300][2000/2502]	eta 0:04:16 lr 0.000038	time 0.5040 (0.5106)	loss 3.3718 (2.9037)	grad_norm 8.7604 (8.4426)	mem 8929MB
[2022-04-09 10:47:21 large] (main.py 226): INFO Train: [249/300][2100/2502]	eta 0:03:24 lr 0.000038	time 0.5836 (0.5096)	loss 3.1982 (2.9016)	grad_norm 7.5277 (8.4331)	mem 8929MB
[2022-04-09 10:48:10 large] (main.py 226): INFO Train: [249/300][2200/2502]	eta 0:02:33 lr 0.000038	time 0.5275 (0.5087)	loss 3.6433 (2.9008)	grad_norm 6.7357 (8.4124)	mem 8929MB
[2022-04-09 10:49:00 large] (main.py 226): INFO Train: [249/300][2300/2502]	eta 0:01:42 lr 0.000038	time 0.5219 (0.5082)	loss 2.4680 (2.9004)	grad_norm 5.6881 (8.4093)	mem 8929MB
[2022-04-09 10:49:51 large] (main.py 226): INFO Train: [249/300][2400/2502]	eta 0:00:51 lr 0.000038	time 0.4938 (0.5082)	loss 2.6161 (2.9022)	grad_norm 7.4063 (8.3971)	mem 8929MB
[2022-04-09 10:50:41 large] (main.py 226): INFO Train: [249/300][2500/2502]	eta 0:00:01 lr 0.000038	time 0.5032 (0.5079)	loss 2.5343 (2.8994)	grad_norm 7.8808 (8.3738)	mem 8929MB
[2022-04-09 10:50:42 large] (main.py 233): INFO EPOCH 249 training takes 0:21:11
[2022-04-09 10:50:49 large] (main.py 273): INFO Test: [0/98]	Time 7.449 (7.449)	Loss 1.1215 (1.1215)	Acc@1 75.781 (75.781)	Acc@5 93.555 (93.555)	Mem 8929MB
[2022-04-09 10:51:14 large] (main.py 279): INFO  * Acc@1 81.232 Acc@5 95.424
[2022-04-09 10:51:14 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.2%
[2022-04-09 10:51:14 large] (utils.py 57): INFO output/large/default/ckpt_epoch_249.pth saving......
[2022-04-09 10:51:15 large] (utils.py 59): INFO output/large/default/ckpt_epoch_249.pth saved !!!
[2022-04-09 10:51:15 large] (main.py 148): INFO Max accuracy: 81.23%
[2022-04-09 10:51:23 large] (main.py 226): INFO Train: [250/300][0/2502]	eta 5:16:49 lr 0.000038	time 7.5979 (7.5979)	loss 3.0880 (3.0880)	grad_norm 7.6823 (7.6823)	mem 8929MB
[2022-04-09 10:52:14 large] (main.py 226): INFO Train: [250/300][100/2502]	eta 0:23:09 lr 0.000038	time 0.5422 (0.5787)	loss 2.0800 (2.9140)	grad_norm 5.9584 (7.9245)	mem 8929MB
[2022-04-09 10:53:04 large] (main.py 226): INFO Train: [250/300][200/2502]	eta 0:20:44 lr 0.000038	time 0.5028 (0.5405)	loss 2.4710 (2.8832)	grad_norm 8.3484 (nan)	mem 8929MB
[2022-04-09 10:53:54 large] (main.py 226): INFO Train: [250/300][300/2502]	eta 0:19:20 lr 0.000038	time 0.5285 (0.5271)	loss 3.1805 (2.8744)	grad_norm 6.8157 (nan)	mem 8929MB
[2022-04-09 10:54:46 large] (main.py 226): INFO Train: [250/300][400/2502]	eta 0:18:25 lr 0.000038	time 0.5298 (0.5257)	loss 2.2962 (2.8666)	grad_norm 7.1664 (nan)	mem 8929MB
[2022-04-09 10:55:38 large] (main.py 226): INFO Train: [250/300][500/2502]	eta 0:17:31 lr 0.000038	time 0.4985 (0.5253)	loss 3.2714 (2.8434)	grad_norm 9.6516 (nan)	mem 8929MB
[2022-04-09 10:56:31 large] (main.py 226): INFO Train: [250/300][600/2502]	eta 0:16:38 lr 0.000038	time 0.5048 (0.5249)	loss 2.0640 (2.8546)	grad_norm 10.7735 (nan)	mem 8929MB
[2022-04-09 10:57:23 large] (main.py 226): INFO Train: [250/300][700/2502]	eta 0:15:44 lr 0.000038	time 0.5567 (0.5242)	loss 2.4688 (2.8633)	grad_norm 7.7472 (nan)	mem 8929MB
[2022-04-09 10:58:14 large] (main.py 226): INFO Train: [250/300][800/2502]	eta 0:14:50 lr 0.000038	time 0.5897 (0.5234)	loss 2.4624 (2.8659)	grad_norm 8.2864 (nan)	mem 8929MB
[2022-04-09 10:59:05 large] (main.py 226): INFO Train: [250/300][900/2502]	eta 0:13:55 lr 0.000038	time 0.4883 (0.5217)	loss 3.0291 (2.8719)	grad_norm 5.9591 (nan)	mem 8929MB
[2022-04-09 10:59:54 large] (main.py 226): INFO Train: [250/300][1000/2502]	eta 0:12:58 lr 0.000038	time 0.4640 (0.5185)	loss 2.9681 (2.8706)	grad_norm 8.1318 (nan)	mem 8929MB
[2022-04-09 11:00:43 large] (main.py 226): INFO Train: [250/300][1100/2502]	eta 0:12:03 lr 0.000038	time 0.4875 (0.5159)	loss 3.0472 (2.8765)	grad_norm 6.4128 (nan)	mem 8929MB
[2022-04-09 11:01:34 large] (main.py 226): INFO Train: [250/300][1200/2502]	eta 0:11:10 lr 0.000038	time 0.6121 (0.5152)	loss 3.1307 (2.8706)	grad_norm 6.4592 (nan)	mem 8929MB
[2022-04-09 11:02:24 large] (main.py 226): INFO Train: [250/300][1300/2502]	eta 0:10:17 lr 0.000037	time 0.5314 (0.5141)	loss 3.2703 (2.8701)	grad_norm 6.2991 (nan)	mem 8929MB
[2022-04-09 11:03:15 large] (main.py 226): INFO Train: [250/300][1400/2502]	eta 0:09:26 lr 0.000037	time 0.5705 (0.5142)	loss 2.8807 (2.8779)	grad_norm 7.6588 (nan)	mem 8929MB
[2022-04-09 11:04:08 large] (main.py 226): INFO Train: [250/300][1500/2502]	eta 0:08:35 lr 0.000037	time 0.5032 (0.5149)	loss 3.3084 (2.8808)	grad_norm 6.6069 (nan)	mem 8929MB
[2022-04-09 11:04:56 large] (main.py 226): INFO Train: [250/300][1600/2502]	eta 0:07:42 lr 0.000037	time 0.5050 (0.5129)	loss 2.9967 (2.8808)	grad_norm 5.6171 (nan)	mem 8929MB
[2022-04-09 11:05:45 large] (main.py 226): INFO Train: [250/300][1700/2502]	eta 0:06:50 lr 0.000037	time 0.4752 (0.5115)	loss 3.5258 (2.8845)	grad_norm 13.7076 (nan)	mem 8929MB
[2022-04-09 11:06:34 large] (main.py 226): INFO Train: [250/300][1800/2502]	eta 0:05:58 lr 0.000037	time 0.5348 (0.5102)	loss 3.3132 (2.8873)	grad_norm 8.4148 (nan)	mem 8929MB
[2022-04-09 11:07:25 large] (main.py 226): INFO Train: [250/300][1900/2502]	eta 0:05:07 lr 0.000037	time 0.4650 (0.5102)	loss 3.3698 (2.8873)	grad_norm 7.7997 (nan)	mem 8929MB
[2022-04-09 11:08:17 large] (main.py 226): INFO Train: [250/300][2000/2502]	eta 0:04:16 lr 0.000037	time 0.5097 (0.5108)	loss 2.2328 (2.8871)	grad_norm 7.3325 (nan)	mem 8929MB
[2022-04-09 11:09:08 large] (main.py 226): INFO Train: [250/300][2100/2502]	eta 0:03:25 lr 0.000037	time 0.4644 (0.5106)	loss 2.7078 (2.8896)	grad_norm 5.9329 (nan)	mem 8929MB
[2022-04-09 11:09:57 large] (main.py 226): INFO Train: [250/300][2200/2502]	eta 0:02:34 lr 0.000037	time 0.5181 (0.5100)	loss 3.1919 (2.8927)	grad_norm 6.5911 (nan)	mem 8929MB
[2022-04-09 11:10:46 large] (main.py 226): INFO Train: [250/300][2300/2502]	eta 0:01:42 lr 0.000037	time 0.5115 (0.5090)	loss 2.9184 (2.8964)	grad_norm 7.0228 (nan)	mem 8929MB
[2022-04-09 11:11:35 large] (main.py 226): INFO Train: [250/300][2400/2502]	eta 0:00:51 lr 0.000037	time 0.4738 (0.5082)	loss 2.0589 (2.8967)	grad_norm 27.2003 (nan)	mem 8929MB
[2022-04-09 11:12:24 large] (main.py 226): INFO Train: [250/300][2500/2502]	eta 0:00:01 lr 0.000037	time 0.4851 (0.5074)	loss 3.2131 (2.8991)	grad_norm 5.8513 (nan)	mem 8929MB
[2022-04-09 11:12:25 large] (main.py 233): INFO EPOCH 250 training takes 0:21:10
[2022-04-09 11:12:32 large] (main.py 273): INFO Test: [0/98]	Time 7.018 (7.018)	Loss 1.0033 (1.0033)	Acc@1 82.422 (82.422)	Acc@5 94.531 (94.531)	Mem 8929MB
[2022-04-09 11:12:58 large] (main.py 279): INFO  * Acc@1 81.158 Acc@5 95.438
[2022-04-09 11:12:58 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.2%
[2022-04-09 11:12:58 large] (main.py 148): INFO Max accuracy: 81.23%
[2022-04-09 11:13:05 large] (main.py 226): INFO Train: [251/300][0/2502]	eta 4:57:09 lr 0.000037	time 7.1259 (7.1259)	loss 3.4052 (3.4052)	grad_norm 6.7269 (6.7269)	mem 8929MB
[2022-04-09 11:13:56 large] (main.py 226): INFO Train: [251/300][100/2502]	eta 0:23:11 lr 0.000037	time 0.5806 (0.5794)	loss 3.3719 (2.9119)	grad_norm 11.0273 (7.6753)	mem 8929MB
[2022-04-09 11:14:46 large] (main.py 226): INFO Train: [251/300][200/2502]	eta 0:20:44 lr 0.000037	time 0.4899 (0.5406)	loss 1.9644 (2.9066)	grad_norm 9.7136 (8.1199)	mem 8929MB
[2022-04-09 11:15:37 large] (main.py 226): INFO Train: [251/300][300/2502]	eta 0:19:23 lr 0.000037	time 0.5816 (0.5282)	loss 2.1096 (2.9101)	grad_norm 6.9245 (8.2088)	mem 8929MB
[2022-04-09 11:16:29 large] (main.py 226): INFO Train: [251/300][400/2502]	eta 0:18:28 lr 0.000037	time 0.5609 (0.5274)	loss 3.1088 (2.9034)	grad_norm 9.9391 (8.2077)	mem 8929MB
[2022-04-09 11:17:22 large] (main.py 226): INFO Train: [251/300][500/2502]	eta 0:17:35 lr 0.000037	time 0.5142 (0.5274)	loss 3.1524 (2.8986)	grad_norm 10.3242 (8.1929)	mem 8929MB
[2022-04-09 11:18:12 large] (main.py 226): INFO Train: [251/300][600/2502]	eta 0:16:35 lr 0.000037	time 0.5352 (0.5236)	loss 2.8329 (2.8852)	grad_norm 9.2483 (8.1836)	mem 8929MB
[2022-04-09 11:19:04 large] (main.py 226): INFO Train: [251/300][700/2502]	eta 0:15:42 lr 0.000037	time 0.5691 (0.5231)	loss 2.5036 (2.8899)	grad_norm 17.1412 (8.4486)	mem 8929MB
[2022-04-09 11:19:56 large] (main.py 226): INFO Train: [251/300][800/2502]	eta 0:14:49 lr 0.000036	time 0.5002 (0.5225)	loss 3.1744 (2.8866)	grad_norm 17.3162 (8.4959)	mem 8929MB
[2022-04-09 11:20:48 large] (main.py 226): INFO Train: [251/300][900/2502]	eta 0:13:57 lr 0.000036	time 0.5020 (0.5226)	loss 2.8360 (2.9001)	grad_norm 11.5572 (8.5869)	mem 8929MB
[2022-04-09 11:21:41 large] (main.py 226): INFO Train: [251/300][1000/2502]	eta 0:13:04 lr 0.000036	time 0.5254 (0.5225)	loss 3.1654 (2.9015)	grad_norm 7.2207 (8.5733)	mem 8929MB
[2022-04-09 11:22:30 large] (main.py 226): INFO Train: [251/300][1100/2502]	eta 0:12:09 lr 0.000036	time 0.4808 (0.5203)	loss 3.3980 (2.8977)	grad_norm 7.9233 (8.6140)	mem 8929MB
[2022-04-09 11:23:20 large] (main.py 226): INFO Train: [251/300][1200/2502]	eta 0:11:14 lr 0.000036	time 0.5029 (0.5182)	loss 3.6330 (2.9031)	grad_norm 8.2059 (8.5722)	mem 8929MB
[2022-04-09 11:24:12 large] (main.py 226): INFO Train: [251/300][1300/2502]	eta 0:10:22 lr 0.000036	time 0.5674 (0.5181)	loss 3.6034 (2.8956)	grad_norm 6.6896 (8.5181)	mem 8929MB
[2022-04-09 11:25:04 large] (main.py 226): INFO Train: [251/300][1400/2502]	eta 0:09:31 lr 0.000036	time 0.5374 (0.5183)	loss 3.4753 (2.8956)	grad_norm 6.4479 (8.5085)	mem 8929MB
[2022-04-09 11:25:56 large] (main.py 226): INFO Train: [251/300][1500/2502]	eta 0:08:39 lr 0.000036	time 0.5122 (0.5184)	loss 3.3797 (2.8963)	grad_norm 6.6463 (8.5871)	mem 8929MB
[2022-04-09 11:26:47 large] (main.py 226): INFO Train: [251/300][1600/2502]	eta 0:07:47 lr 0.000036	time 0.4887 (0.5180)	loss 1.9650 (2.8946)	grad_norm 6.1312 (8.5774)	mem 8929MB
[2022-04-09 11:27:38 large] (main.py 226): INFO Train: [251/300][1700/2502]	eta 0:06:54 lr 0.000036	time 0.6086 (0.5175)	loss 2.3912 (2.8943)	grad_norm 8.9411 (8.7078)	mem 8929MB
[2022-04-09 11:28:28 large] (main.py 226): INFO Train: [251/300][1800/2502]	eta 0:06:02 lr 0.000036	time 0.5243 (0.5164)	loss 3.4474 (2.8924)	grad_norm 7.0360 (8.6926)	mem 8929MB
[2022-04-09 11:29:20 large] (main.py 226): INFO Train: [251/300][1900/2502]	eta 0:05:10 lr 0.000036	time 0.5106 (0.5165)	loss 3.5884 (2.8951)	grad_norm 10.4742 (8.7490)	mem 8929MB
[2022-04-09 11:30:12 large] (main.py 226): INFO Train: [251/300][2000/2502]	eta 0:04:19 lr 0.000036	time 0.5224 (0.5168)	loss 3.0725 (2.8940)	grad_norm 11.4671 (8.7342)	mem 8929MB
[2022-04-09 11:31:01 large] (main.py 226): INFO Train: [251/300][2100/2502]	eta 0:03:27 lr 0.000036	time 0.5031 (0.5156)	loss 2.6573 (2.8936)	grad_norm 7.6842 (8.7181)	mem 8929MB
[2022-04-09 11:31:52 large] (main.py 226): INFO Train: [251/300][2200/2502]	eta 0:02:35 lr 0.000036	time 0.5271 (0.5156)	loss 2.6822 (2.8911)	grad_norm 10.0130 (8.7416)	mem 8929MB
[2022-04-09 11:32:45 large] (main.py 226): INFO Train: [251/300][2300/2502]	eta 0:01:44 lr 0.000036	time 0.5278 (0.5160)	loss 2.7632 (2.8912)	grad_norm 12.6579 (8.7169)	mem 8929MB
[2022-04-09 11:33:36 large] (main.py 226): INFO Train: [251/300][2400/2502]	eta 0:00:52 lr 0.000036	time 0.4857 (0.5156)	loss 3.3888 (2.8896)	grad_norm 7.2875 (8.6922)	mem 8929MB
[2022-04-09 11:34:25 large] (main.py 226): INFO Train: [251/300][2500/2502]	eta 0:00:01 lr 0.000036	time 0.4846 (0.5148)	loss 3.3536 (2.8884)	grad_norm 17.9012 (8.6949)	mem 8929MB
[2022-04-09 11:34:26 large] (main.py 233): INFO EPOCH 251 training takes 0:21:28
[2022-04-09 11:34:32 large] (main.py 273): INFO Test: [0/98]	Time 6.062 (6.062)	Loss 1.0503 (1.0503)	Acc@1 79.492 (79.492)	Acc@5 95.312 (95.312)	Mem 8929MB
[2022-04-09 11:34:58 large] (main.py 279): INFO  * Acc@1 81.110 Acc@5 95.446
[2022-04-09 11:34:58 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.1%
[2022-04-09 11:34:58 large] (main.py 148): INFO Max accuracy: 81.23%
[2022-04-09 11:35:05 large] (main.py 226): INFO Train: [252/300][0/2502]	eta 4:41:09 lr 0.000036	time 6.7426 (6.7426)	loss 2.7619 (2.7619)	grad_norm 5.6385 (5.6385)	mem 8929MB
[2022-04-09 11:35:55 large] (main.py 226): INFO Train: [252/300][100/2502]	eta 0:22:39 lr 0.000036	time 0.5683 (0.5661)	loss 3.6230 (2.8584)	grad_norm 13.5849 (8.9528)	mem 8929MB
[2022-04-09 11:36:45 large] (main.py 226): INFO Train: [252/300][200/2502]	eta 0:20:19 lr 0.000036	time 0.4917 (0.5297)	loss 2.8428 (2.9039)	grad_norm 6.9618 (8.6530)	mem 8929MB
[2022-04-09 11:37:37 large] (main.py 226): INFO Train: [252/300][300/2502]	eta 0:19:20 lr 0.000035	time 0.5107 (0.5270)	loss 2.8998 (2.8767)	grad_norm 6.8388 (8.7695)	mem 8929MB
[2022-04-09 11:38:26 large] (main.py 226): INFO Train: [252/300][400/2502]	eta 0:18:10 lr 0.000035	time 0.4875 (0.5190)	loss 3.3900 (2.8745)	grad_norm 7.3524 (8.5835)	mem 8929MB
[2022-04-09 11:39:16 large] (main.py 226): INFO Train: [252/300][500/2502]	eta 0:17:10 lr 0.000035	time 0.4908 (0.5147)	loss 2.9127 (2.8646)	grad_norm 15.0606 (8.6058)	mem 8929MB
[2022-04-09 11:40:09 large] (main.py 226): INFO Train: [252/300][600/2502]	eta 0:16:22 lr 0.000035	time 0.5402 (0.5165)	loss 2.1568 (2.8663)	grad_norm 7.7580 (inf)	mem 8929MB
[2022-04-09 11:41:01 large] (main.py 226): INFO Train: [252/300][700/2502]	eta 0:15:33 lr 0.000035	time 0.5266 (0.5180)	loss 3.1357 (2.8778)	grad_norm 6.5826 (inf)	mem 8929MB
[2022-04-09 11:41:54 large] (main.py 226): INFO Train: [252/300][800/2502]	eta 0:14:42 lr 0.000035	time 0.5052 (0.5186)	loss 3.7000 (2.8789)	grad_norm 8.6450 (inf)	mem 8929MB
[2022-04-09 11:42:46 large] (main.py 226): INFO Train: [252/300][900/2502]	eta 0:13:52 lr 0.000035	time 0.5369 (0.5194)	loss 2.2863 (2.8688)	grad_norm 7.3327 (inf)	mem 8929MB
[2022-04-09 11:43:35 large] (main.py 226): INFO Train: [252/300][1000/2502]	eta 0:12:55 lr 0.000035	time 0.4691 (0.5164)	loss 3.4921 (2.8629)	grad_norm 6.7984 (inf)	mem 8929MB
[2022-04-09 11:44:25 large] (main.py 226): INFO Train: [252/300][1100/2502]	eta 0:12:02 lr 0.000035	time 0.5723 (0.5151)	loss 3.3942 (2.8660)	grad_norm 7.2176 (nan)	mem 8929MB
[2022-04-09 11:45:17 large] (main.py 226): INFO Train: [252/300][1200/2502]	eta 0:11:10 lr 0.000035	time 0.4798 (0.5150)	loss 2.3156 (2.8693)	grad_norm 7.2014 (nan)	mem 8929MB
[2022-04-09 11:46:05 large] (main.py 226): INFO Train: [252/300][1300/2502]	eta 0:10:16 lr 0.000035	time 0.4910 (0.5128)	loss 3.4241 (2.8730)	grad_norm 6.4016 (nan)	mem 8929MB
[2022-04-09 11:46:57 large] (main.py 226): INFO Train: [252/300][1400/2502]	eta 0:09:25 lr 0.000035	time 0.5347 (0.5130)	loss 3.4195 (2.8717)	grad_norm 8.6303 (nan)	mem 8929MB
[2022-04-09 11:47:50 large] (main.py 226): INFO Train: [252/300][1500/2502]	eta 0:08:34 lr 0.000035	time 0.6122 (0.5139)	loss 2.9851 (2.8723)	grad_norm 8.5389 (nan)	mem 8929MB
[2022-04-09 11:48:42 large] (main.py 226): INFO Train: [252/300][1600/2502]	eta 0:07:44 lr 0.000035	time 0.5281 (0.5144)	loss 2.8368 (2.8769)	grad_norm 6.0158 (nan)	mem 8929MB
[2022-04-09 11:49:32 large] (main.py 226): INFO Train: [252/300][1700/2502]	eta 0:06:52 lr 0.000035	time 0.5008 (0.5138)	loss 3.1431 (2.8749)	grad_norm 8.5794 (nan)	mem 8929MB
[2022-04-09 11:50:24 large] (main.py 226): INFO Train: [252/300][1800/2502]	eta 0:06:00 lr 0.000035	time 0.6199 (0.5140)	loss 2.3268 (2.8728)	grad_norm 6.0092 (nan)	mem 8929MB
[2022-04-09 11:51:15 large] (main.py 226): INFO Train: [252/300][1900/2502]	eta 0:05:09 lr 0.000035	time 0.4947 (0.5135)	loss 3.6648 (2.8736)	grad_norm 8.6069 (nan)	mem 8929MB
[2022-04-09 11:52:04 large] (main.py 226): INFO Train: [252/300][2000/2502]	eta 0:04:17 lr 0.000035	time 0.5158 (0.5124)	loss 2.6782 (2.8791)	grad_norm 7.4983 (nan)	mem 8929MB
[2022-04-09 11:52:54 large] (main.py 226): INFO Train: [252/300][2100/2502]	eta 0:03:25 lr 0.000035	time 0.4881 (0.5118)	loss 2.9777 (2.8794)	grad_norm 6.2226 (nan)	mem 8929MB
[2022-04-09 11:53:43 large] (main.py 226): INFO Train: [252/300][2200/2502]	eta 0:02:34 lr 0.000035	time 0.5010 (0.5112)	loss 3.2971 (2.8804)	grad_norm 9.3902 (nan)	mem 8929MB
[2022-04-09 11:54:34 large] (main.py 226): INFO Train: [252/300][2300/2502]	eta 0:01:43 lr 0.000034	time 0.4886 (0.5111)	loss 3.0012 (2.8830)	grad_norm 12.4945 (nan)	mem 8929MB
[2022-04-09 11:55:23 large] (main.py 226): INFO Train: [252/300][2400/2502]	eta 0:00:52 lr 0.000034	time 0.4590 (0.5102)	loss 1.8183 (2.8813)	grad_norm 6.5650 (nan)	mem 8929MB
[2022-04-09 11:56:14 large] (main.py 226): INFO Train: [252/300][2500/2502]	eta 0:00:01 lr 0.000034	time 0.5037 (0.5100)	loss 3.5226 (2.8791)	grad_norm 10.0838 (nan)	mem 8929MB
[2022-04-09 11:56:15 large] (main.py 233): INFO EPOCH 252 training takes 0:21:16
[2022-04-09 11:56:21 large] (main.py 273): INFO Test: [0/98]	Time 6.520 (6.520)	Loss 1.0633 (1.0633)	Acc@1 78.711 (78.711)	Acc@5 94.727 (94.727)	Mem 8929MB
[2022-04-09 11:56:47 large] (main.py 279): INFO  * Acc@1 81.126 Acc@5 95.418
[2022-04-09 11:56:47 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.1%
[2022-04-09 11:56:47 large] (main.py 148): INFO Max accuracy: 81.23%
[2022-04-09 11:56:54 large] (main.py 226): INFO Train: [253/300][0/2502]	eta 4:57:13 lr 0.000034	time 7.1275 (7.1275)	loss 3.2026 (3.2026)	grad_norm 7.2268 (7.2268)	mem 8929MB
[2022-04-09 11:57:46 large] (main.py 226): INFO Train: [253/300][100/2502]	eta 0:23:21 lr 0.000034	time 0.4448 (0.5834)	loss 3.2721 (2.9128)	grad_norm 7.3455 (7.7987)	mem 8929MB
[2022-04-09 11:58:35 large] (main.py 226): INFO Train: [253/300][200/2502]	eta 0:20:35 lr 0.000034	time 0.5082 (0.5366)	loss 3.0655 (2.8917)	grad_norm 7.7094 (8.1498)	mem 8929MB
[2022-04-09 11:59:27 large] (main.py 226): INFO Train: [253/300][300/2502]	eta 0:19:31 lr 0.000034	time 0.5311 (0.5319)	loss 3.2954 (2.8758)	grad_norm 9.5695 (8.1929)	mem 8929MB
[2022-04-09 12:00:20 large] (main.py 226): INFO Train: [253/300][400/2502]	eta 0:18:33 lr 0.000034	time 0.5116 (0.5300)	loss 3.2097 (2.8615)	grad_norm 7.2542 (8.2378)	mem 8929MB
[2022-04-09 12:01:12 large] (main.py 226): INFO Train: [253/300][500/2502]	eta 0:17:39 lr 0.000034	time 0.5690 (0.5291)	loss 3.1417 (2.8779)	grad_norm 7.1065 (8.3829)	mem 8929MB
[2022-04-09 12:02:04 large] (main.py 226): INFO Train: [253/300][600/2502]	eta 0:16:42 lr 0.000034	time 0.5038 (0.5273)	loss 3.1534 (2.8731)	grad_norm 7.2084 (8.3104)	mem 8929MB
[2022-04-09 12:02:57 large] (main.py 226): INFO Train: [253/300][700/2502]	eta 0:15:49 lr 0.000034	time 0.4985 (0.5270)	loss 3.1477 (2.8786)	grad_norm 9.5190 (8.3540)	mem 8929MB
[2022-04-09 12:03:47 large] (main.py 226): INFO Train: [253/300][800/2502]	eta 0:14:52 lr 0.000034	time 0.4905 (0.5241)	loss 3.2385 (2.8780)	grad_norm 8.0281 (8.3570)	mem 8929MB
[2022-04-09 12:04:38 large] (main.py 226): INFO Train: [253/300][900/2502]	eta 0:13:56 lr 0.000034	time 0.4982 (0.5223)	loss 3.1152 (2.8874)	grad_norm 7.5187 (8.4332)	mem 8929MB
[2022-04-09 12:05:27 large] (main.py 226): INFO Train: [253/300][1000/2502]	eta 0:13:00 lr 0.000034	time 0.4838 (0.5194)	loss 3.0891 (2.8881)	grad_norm 8.1899 (8.5181)	mem 8929MB
[2022-04-09 12:06:18 large] (main.py 226): INFO Train: [253/300][1100/2502]	eta 0:12:06 lr 0.000034	time 0.4886 (0.5180)	loss 2.8502 (2.8882)	grad_norm 7.8449 (8.4896)	mem 8929MB
[2022-04-09 12:07:07 large] (main.py 226): INFO Train: [253/300][1200/2502]	eta 0:11:11 lr 0.000034	time 0.4939 (0.5160)	loss 2.3670 (2.8858)	grad_norm 6.4473 (8.5848)	mem 8929MB
[2022-04-09 12:07:58 large] (main.py 226): INFO Train: [253/300][1300/2502]	eta 0:10:20 lr 0.000034	time 0.5264 (0.5158)	loss 3.5157 (2.8916)	grad_norm 8.5971 (8.5487)	mem 8929MB
[2022-04-09 12:08:49 large] (main.py 226): INFO Train: [253/300][1400/2502]	eta 0:09:27 lr 0.000034	time 0.5026 (0.5152)	loss 3.1906 (2.8893)	grad_norm 6.4814 (8.6155)	mem 8929MB
[2022-04-09 12:09:39 large] (main.py 226): INFO Train: [253/300][1500/2502]	eta 0:08:35 lr 0.000034	time 0.4893 (0.5142)	loss 2.9598 (2.8926)	grad_norm 11.5243 (8.5928)	mem 8929MB
[2022-04-09 12:10:30 large] (main.py 226): INFO Train: [253/300][1600/2502]	eta 0:07:43 lr 0.000034	time 0.4862 (0.5137)	loss 3.2452 (2.8907)	grad_norm 6.1219 (8.5639)	mem 8929MB
[2022-04-09 12:11:19 large] (main.py 226): INFO Train: [253/300][1700/2502]	eta 0:06:50 lr 0.000034	time 0.4905 (0.5124)	loss 2.0701 (2.8880)	grad_norm 7.6168 (8.5332)	mem 8929MB
[2022-04-09 12:12:09 large] (main.py 226): INFO Train: [253/300][1800/2502]	eta 0:05:59 lr 0.000034	time 0.5106 (0.5115)	loss 3.1191 (2.8883)	grad_norm 5.2244 (8.5515)	mem 8929MB
[2022-04-09 12:13:01 large] (main.py 226): INFO Train: [253/300][1900/2502]	eta 0:05:08 lr 0.000033	time 0.5037 (0.5120)	loss 2.9146 (2.8904)	grad_norm 7.1578 (8.5969)	mem 8929MB
[2022-04-09 12:13:53 large] (main.py 226): INFO Train: [253/300][2000/2502]	eta 0:04:17 lr 0.000033	time 0.5159 (0.5126)	loss 3.4380 (2.8901)	grad_norm 7.1329 (8.5949)	mem 8929MB
[2022-04-09 12:14:46 large] (main.py 226): INFO Train: [253/300][2100/2502]	eta 0:03:26 lr 0.000033	time 0.5191 (0.5132)	loss 3.1094 (2.8875)	grad_norm 7.0810 (8.6037)	mem 8929MB
[2022-04-09 12:15:38 large] (main.py 226): INFO Train: [253/300][2200/2502]	eta 0:02:35 lr 0.000033	time 0.5217 (0.5135)	loss 1.7869 (2.8893)	grad_norm 7.7765 (8.5883)	mem 8929MB
[2022-04-09 12:16:29 large] (main.py 226): INFO Train: [253/300][2300/2502]	eta 0:01:43 lr 0.000033	time 0.5124 (0.5137)	loss 3.1034 (2.8880)	grad_norm 7.0124 (8.5706)	mem 8929MB
[2022-04-09 12:17:21 large] (main.py 226): INFO Train: [253/300][2400/2502]	eta 0:00:52 lr 0.000033	time 0.5650 (0.5139)	loss 3.3091 (2.8869)	grad_norm 9.3522 (nan)	mem 8929MB
[2022-04-09 12:18:13 large] (main.py 226): INFO Train: [253/300][2500/2502]	eta 0:00:01 lr 0.000033	time 0.5011 (0.5141)	loss 3.2285 (2.8850)	grad_norm 7.5211 (nan)	mem 8929MB
[2022-04-09 12:18:14 large] (main.py 233): INFO EPOCH 253 training takes 0:21:26
[2022-04-09 12:18:20 large] (main.py 273): INFO Test: [0/98]	Time 6.170 (6.170)	Loss 0.9152 (0.9152)	Acc@1 82.031 (82.031)	Acc@5 94.922 (94.922)	Mem 8929MB
[2022-04-09 12:18:46 large] (main.py 279): INFO  * Acc@1 81.352 Acc@5 95.434
[2022-04-09 12:18:46 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.4%
[2022-04-09 12:18:46 large] (utils.py 57): INFO output/large/default/ckpt_epoch_253.pth saving......
[2022-04-09 12:18:47 large] (utils.py 59): INFO output/large/default/ckpt_epoch_253.pth saved !!!
[2022-04-09 12:18:47 large] (main.py 148): INFO Max accuracy: 81.35%
[2022-04-09 12:18:54 large] (main.py 226): INFO Train: [254/300][0/2502]	eta 5:23:13 lr 0.000033	time 7.7514 (7.7514)	loss 2.2829 (2.2829)	grad_norm 6.1542 (6.1542)	mem 8929MB
[2022-04-09 12:19:44 large] (main.py 226): INFO Train: [254/300][100/2502]	eta 0:22:41 lr 0.000033	time 0.5669 (0.5669)	loss 3.5247 (2.9534)	grad_norm 8.2521 (8.1010)	mem 8929MB
[2022-04-09 12:20:35 large] (main.py 226): INFO Train: [254/300][200/2502]	eta 0:20:43 lr 0.000033	time 0.5129 (0.5402)	loss 2.6798 (2.9240)	grad_norm 6.4388 (8.3463)	mem 8929MB
[2022-04-09 12:21:27 large] (main.py 226): INFO Train: [254/300][300/2502]	eta 0:19:36 lr 0.000033	time 0.5042 (0.5341)	loss 3.3654 (2.8789)	grad_norm 5.7224 (8.4166)	mem 8929MB
[2022-04-09 12:22:18 large] (main.py 226): INFO Train: [254/300][400/2502]	eta 0:18:29 lr 0.000033	time 0.4851 (0.5278)	loss 2.5921 (2.8732)	grad_norm 7.0248 (8.4999)	mem 8929MB
[2022-04-09 12:23:08 large] (main.py 226): INFO Train: [254/300][500/2502]	eta 0:17:24 lr 0.000033	time 0.5122 (0.5218)	loss 3.0374 (2.8725)	grad_norm 9.9799 (8.5516)	mem 8929MB
[2022-04-09 12:23:58 large] (main.py 226): INFO Train: [254/300][600/2502]	eta 0:16:26 lr 0.000033	time 0.4609 (0.5187)	loss 2.9767 (2.8808)	grad_norm 7.4567 (8.5699)	mem 8929MB
[2022-04-09 12:24:47 large] (main.py 226): INFO Train: [254/300][700/2502]	eta 0:15:25 lr 0.000033	time 0.4885 (0.5136)	loss 2.4167 (2.8873)	grad_norm 12.2584 (8.6202)	mem 8929MB
[2022-04-09 12:25:39 large] (main.py 226): INFO Train: [254/300][800/2502]	eta 0:14:35 lr 0.000033	time 0.5423 (0.5145)	loss 2.0224 (2.8831)	grad_norm 11.1630 (8.6515)	mem 8929MB
[2022-04-09 12:26:32 large] (main.py 226): INFO Train: [254/300][900/2502]	eta 0:13:46 lr 0.000033	time 0.5036 (0.5159)	loss 3.2384 (2.8840)	grad_norm 7.6877 (8.8942)	mem 8929MB
[2022-04-09 12:27:24 large] (main.py 226): INFO Train: [254/300][1000/2502]	eta 0:12:56 lr 0.000033	time 0.5009 (0.5170)	loss 2.8633 (2.8863)	grad_norm 6.8389 (8.9190)	mem 8929MB
[2022-04-09 12:28:15 large] (main.py 226): INFO Train: [254/300][1100/2502]	eta 0:12:03 lr 0.000033	time 0.5242 (0.5161)	loss 3.4311 (2.8888)	grad_norm 8.5039 (8.9639)	mem 8929MB
[2022-04-09 12:29:04 large] (main.py 226): INFO Train: [254/300][1200/2502]	eta 0:11:09 lr 0.000033	time 0.4950 (0.5142)	loss 3.3216 (2.8889)	grad_norm 6.9850 (8.9089)	mem 8929MB
[2022-04-09 12:29:56 large] (main.py 226): INFO Train: [254/300][1300/2502]	eta 0:10:18 lr 0.000033	time 0.5056 (0.5145)	loss 2.8657 (2.8902)	grad_norm 5.5366 (8.8616)	mem 8929MB
[2022-04-09 12:30:46 large] (main.py 226): INFO Train: [254/300][1400/2502]	eta 0:09:25 lr 0.000032	time 0.5509 (0.5135)	loss 3.0668 (2.8858)	grad_norm 7.9204 (8.8693)	mem 8929MB
[2022-04-09 12:31:36 large] (main.py 226): INFO Train: [254/300][1500/2502]	eta 0:08:33 lr 0.000032	time 0.5799 (0.5128)	loss 1.9359 (2.8861)	grad_norm 8.8507 (8.8429)	mem 8929MB
[2022-04-09 12:32:28 large] (main.py 226): INFO Train: [254/300][1600/2502]	eta 0:07:42 lr 0.000032	time 0.4970 (0.5128)	loss 2.9597 (2.8899)	grad_norm 6.3310 (8.7903)	mem 8929MB
[2022-04-09 12:33:20 large] (main.py 226): INFO Train: [254/300][1700/2502]	eta 0:06:51 lr 0.000032	time 0.5141 (0.5132)	loss 3.4309 (2.8840)	grad_norm 8.7154 (nan)	mem 8929MB
[2022-04-09 12:34:12 large] (main.py 226): INFO Train: [254/300][1800/2502]	eta 0:06:00 lr 0.000032	time 0.6052 (0.5135)	loss 3.2626 (2.8821)	grad_norm 7.3442 (nan)	mem 8929MB
[2022-04-09 12:35:02 large] (main.py 226): INFO Train: [254/300][1900/2502]	eta 0:05:08 lr 0.000032	time 0.5057 (0.5133)	loss 3.4969 (2.8815)	grad_norm 9.3453 (nan)	mem 8929MB
[2022-04-09 12:35:52 large] (main.py 226): INFO Train: [254/300][2000/2502]	eta 0:04:17 lr 0.000032	time 0.5188 (0.5125)	loss 3.3046 (2.8844)	grad_norm 9.5395 (nan)	mem 8929MB
[2022-04-09 12:36:43 large] (main.py 226): INFO Train: [254/300][2100/2502]	eta 0:03:25 lr 0.000032	time 0.4738 (0.5120)	loss 3.0564 (2.8838)	grad_norm 6.7091 (nan)	mem 8929MB
[2022-04-09 12:37:32 large] (main.py 226): INFO Train: [254/300][2200/2502]	eta 0:02:34 lr 0.000032	time 0.5067 (0.5114)	loss 2.2059 (2.8838)	grad_norm 7.1099 (nan)	mem 8929MB
[2022-04-09 12:38:24 large] (main.py 226): INFO Train: [254/300][2300/2502]	eta 0:01:43 lr 0.000032	time 0.5791 (0.5117)	loss 3.1807 (2.8844)	grad_norm 7.8858 (nan)	mem 8929MB
[2022-04-09 12:39:17 large] (main.py 226): INFO Train: [254/300][2400/2502]	eta 0:00:52 lr 0.000032	time 0.5248 (0.5123)	loss 2.8134 (2.8858)	grad_norm 9.3014 (nan)	mem 8929MB
[2022-04-09 12:40:08 large] (main.py 226): INFO Train: [254/300][2500/2502]	eta 0:00:01 lr 0.000032	time 0.4960 (0.5124)	loss 2.2243 (2.8834)	grad_norm 8.0681 (nan)	mem 8929MB
[2022-04-09 12:40:09 large] (main.py 233): INFO EPOCH 254 training takes 0:21:22
[2022-04-09 12:40:15 large] (main.py 273): INFO Test: [0/98]	Time 6.002 (6.002)	Loss 0.8843 (0.8843)	Acc@1 82.617 (82.617)	Acc@5 96.094 (96.094)	Mem 8929MB
[2022-04-09 12:40:42 large] (main.py 279): INFO  * Acc@1 81.396 Acc@5 95.504
[2022-04-09 12:40:42 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.4%
[2022-04-09 12:40:42 large] (utils.py 57): INFO output/large/default/ckpt_epoch_254.pth saving......
[2022-04-09 12:40:42 large] (utils.py 59): INFO output/large/default/ckpt_epoch_254.pth saved !!!
[2022-04-09 12:40:42 large] (main.py 148): INFO Max accuracy: 81.40%
[2022-04-09 12:40:50 large] (main.py 226): INFO Train: [255/300][0/2502]	eta 5:17:00 lr 0.000032	time 7.6021 (7.6021)	loss 3.5961 (3.5961)	grad_norm 5.8307 (5.8307)	mem 8929MB
[2022-04-09 12:41:40 large] (main.py 226): INFO Train: [255/300][100/2502]	eta 0:22:39 lr 0.000032	time 0.5335 (0.5662)	loss 3.4813 (2.8923)	grad_norm 8.9768 (8.9608)	mem 8929MB
[2022-04-09 12:42:30 large] (main.py 226): INFO Train: [255/300][200/2502]	eta 0:20:33 lr 0.000032	time 0.4651 (0.5358)	loss 3.1913 (2.8720)	grad_norm 8.6515 (8.8313)	mem 8929MB
[2022-04-09 12:43:20 large] (main.py 226): INFO Train: [255/300][300/2502]	eta 0:19:10 lr 0.000032	time 0.4993 (0.5225)	loss 2.2068 (2.8623)	grad_norm 6.7890 (8.5829)	mem 8929MB
[2022-04-09 12:44:09 large] (main.py 226): INFO Train: [255/300][400/2502]	eta 0:18:03 lr 0.000032	time 0.4573 (0.5155)	loss 3.3229 (2.8684)	grad_norm 7.4926 (8.7972)	mem 8929MB
[2022-04-09 12:44:59 large] (main.py 226): INFO Train: [255/300][500/2502]	eta 0:17:05 lr 0.000032	time 0.4798 (0.5123)	loss 2.1687 (2.8523)	grad_norm 8.2282 (8.9067)	mem 8929MB
[2022-04-09 12:45:50 large] (main.py 226): INFO Train: [255/300][600/2502]	eta 0:16:14 lr 0.000032	time 0.5282 (0.5123)	loss 3.2907 (2.8522)	grad_norm 8.1118 (8.7727)	mem 8929MB
[2022-04-09 12:46:43 large] (main.py 226): INFO Train: [255/300][700/2502]	eta 0:15:27 lr 0.000032	time 0.5188 (0.5145)	loss 1.9482 (2.8490)	grad_norm 7.1639 (8.6999)	mem 8929MB
[2022-04-09 12:47:34 large] (main.py 226): INFO Train: [255/300][800/2502]	eta 0:14:35 lr 0.000032	time 0.4865 (0.5144)	loss 2.9636 (2.8406)	grad_norm 8.8233 (8.6390)	mem 8929MB
[2022-04-09 12:48:25 large] (main.py 226): INFO Train: [255/300][900/2502]	eta 0:13:42 lr 0.000032	time 0.5098 (0.5134)	loss 3.2912 (2.8456)	grad_norm 7.3156 (8.5749)	mem 8929MB
[2022-04-09 12:49:18 large] (main.py 226): INFO Train: [255/300][1000/2502]	eta 0:12:53 lr 0.000032	time 0.5042 (0.5147)	loss 3.3500 (2.8478)	grad_norm 7.5421 (8.5421)	mem 8929MB
[2022-04-09 12:50:07 large] (main.py 226): INFO Train: [255/300][1100/2502]	eta 0:11:58 lr 0.000031	time 0.4735 (0.5125)	loss 3.2036 (2.8369)	grad_norm 7.4223 (8.5043)	mem 8929MB
[2022-04-09 12:50:56 large] (main.py 226): INFO Train: [255/300][1200/2502]	eta 0:11:05 lr 0.000031	time 0.5425 (0.5108)	loss 3.1971 (2.8397)	grad_norm 8.5872 (8.4826)	mem 8929MB
[2022-04-09 12:51:48 large] (main.py 226): INFO Train: [255/300][1300/2502]	eta 0:10:14 lr 0.000031	time 0.5426 (0.5114)	loss 2.4117 (2.8299)	grad_norm 8.0711 (8.4655)	mem 8929MB
[2022-04-09 12:52:38 large] (main.py 226): INFO Train: [255/300][1400/2502]	eta 0:09:23 lr 0.000031	time 0.5001 (0.5109)	loss 2.8167 (2.8288)	grad_norm 6.3455 (8.4443)	mem 8929MB
[2022-04-09 12:53:31 large] (main.py 226): INFO Train: [255/300][1500/2502]	eta 0:08:33 lr 0.000031	time 0.5277 (0.5121)	loss 2.5136 (2.8342)	grad_norm 9.6498 (8.4482)	mem 8929MB
[2022-04-09 12:54:23 large] (main.py 226): INFO Train: [255/300][1600/2502]	eta 0:07:42 lr 0.000031	time 0.5096 (0.5126)	loss 3.4756 (2.8358)	grad_norm 7.6554 (8.4497)	mem 8929MB
[2022-04-09 12:55:16 large] (main.py 226): INFO Train: [255/300][1700/2502]	eta 0:06:51 lr 0.000031	time 0.5022 (0.5133)	loss 2.8854 (2.8421)	grad_norm 7.4483 (8.4254)	mem 8929MB
[2022-04-09 12:56:05 large] (main.py 226): INFO Train: [255/300][1800/2502]	eta 0:05:59 lr 0.000031	time 0.4624 (0.5123)	loss 3.2931 (2.8424)	grad_norm 13.0750 (8.4204)	mem 8929MB
[2022-04-09 12:56:56 large] (main.py 226): INFO Train: [255/300][1900/2502]	eta 0:05:08 lr 0.000031	time 0.5146 (0.5120)	loss 3.1966 (2.8430)	grad_norm 7.6158 (8.4051)	mem 8929MB
[2022-04-09 12:57:48 large] (main.py 226): INFO Train: [255/300][2000/2502]	eta 0:04:17 lr 0.000031	time 0.5545 (0.5124)	loss 2.6706 (2.8455)	grad_norm 16.3111 (8.4711)	mem 8929MB
[2022-04-09 12:58:40 large] (main.py 226): INFO Train: [255/300][2100/2502]	eta 0:03:26 lr 0.000031	time 0.4823 (0.5129)	loss 3.4059 (2.8476)	grad_norm 7.5539 (8.4407)	mem 8929MB
[2022-04-09 12:59:32 large] (main.py 226): INFO Train: [255/300][2200/2502]	eta 0:02:34 lr 0.000031	time 0.4897 (0.5130)	loss 2.7662 (2.8489)	grad_norm 8.2968 (8.4392)	mem 8929MB
[2022-04-09 13:00:21 large] (main.py 226): INFO Train: [255/300][2300/2502]	eta 0:01:43 lr 0.000031	time 0.5075 (0.5120)	loss 2.9583 (2.8516)	grad_norm 7.6344 (8.4323)	mem 8929MB
[2022-04-09 13:01:10 large] (main.py 226): INFO Train: [255/300][2400/2502]	eta 0:00:52 lr 0.000031	time 0.5264 (0.5111)	loss 3.3878 (2.8527)	grad_norm 9.0101 (8.4606)	mem 8929MB
[2022-04-09 13:01:58 large] (main.py 226): INFO Train: [255/300][2500/2502]	eta 0:00:01 lr 0.000031	time 0.4704 (0.5101)	loss 3.3397 (2.8531)	grad_norm 8.0750 (8.4490)	mem 8929MB
[2022-04-09 13:01:59 large] (main.py 233): INFO EPOCH 255 training takes 0:21:16
[2022-04-09 13:02:05 large] (main.py 273): INFO Test: [0/98]	Time 6.187 (6.187)	Loss 0.8660 (0.8660)	Acc@1 85.352 (85.352)	Acc@5 96.680 (96.680)	Mem 8929MB
[2022-04-09 13:02:31 large] (main.py 279): INFO  * Acc@1 81.302 Acc@5 95.504
[2022-04-09 13:02:31 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.3%
[2022-04-09 13:02:31 large] (main.py 148): INFO Max accuracy: 81.40%
[2022-04-09 13:02:38 large] (main.py 226): INFO Train: [256/300][0/2502]	eta 4:46:45 lr 0.000031	time 6.8768 (6.8768)	loss 2.4516 (2.4516)	grad_norm 7.8228 (7.8228)	mem 8929MB
[2022-04-09 13:03:30 large] (main.py 226): INFO Train: [256/300][100/2502]	eta 0:23:11 lr 0.000031	time 0.5098 (0.5793)	loss 2.3291 (2.7935)	grad_norm 5.7031 (8.8720)	mem 8929MB
[2022-04-09 13:04:21 large] (main.py 226): INFO Train: [256/300][200/2502]	eta 0:20:52 lr 0.000031	time 0.4890 (0.5440)	loss 2.5913 (2.8148)	grad_norm 6.5835 (9.0839)	mem 8929MB
[2022-04-09 13:05:09 large] (main.py 226): INFO Train: [256/300][300/2502]	eta 0:19:15 lr 0.000031	time 0.4918 (0.5250)	loss 2.9386 (2.8163)	grad_norm 9.2491 (9.0325)	mem 8929MB
[2022-04-09 13:05:58 large] (main.py 226): INFO Train: [256/300][400/2502]	eta 0:18:05 lr 0.000031	time 0.4998 (0.5164)	loss 2.8523 (2.8378)	grad_norm 6.2058 (8.9824)	mem 8929MB
[2022-04-09 13:06:50 large] (main.py 226): INFO Train: [256/300][500/2502]	eta 0:17:13 lr 0.000031	time 0.5763 (0.5161)	loss 3.3817 (2.8511)	grad_norm 8.0823 (8.8064)	mem 8929MB
[2022-04-09 13:07:44 large] (main.py 226): INFO Train: [256/300][600/2502]	eta 0:16:28 lr 0.000031	time 0.6021 (0.5195)	loss 2.3017 (2.8592)	grad_norm 9.6493 (8.7335)	mem 8929MB
[2022-04-09 13:08:33 large] (main.py 226): INFO Train: [256/300][700/2502]	eta 0:15:29 lr 0.000030	time 0.4621 (0.5156)	loss 3.1915 (2.8654)	grad_norm 5.2948 (8.6693)	mem 8929MB
[2022-04-09 13:09:25 large] (main.py 226): INFO Train: [256/300][800/2502]	eta 0:14:39 lr 0.000030	time 0.5121 (0.5165)	loss 3.0909 (2.8674)	grad_norm 6.2053 (8.6287)	mem 8929MB
[2022-04-09 13:10:17 large] (main.py 226): INFO Train: [256/300][900/2502]	eta 0:13:47 lr 0.000030	time 0.4908 (0.5165)	loss 2.8747 (2.8662)	grad_norm 6.8345 (8.5719)	mem 8929MB
[2022-04-09 13:11:06 large] (main.py 226): INFO Train: [256/300][1000/2502]	eta 0:12:52 lr 0.000030	time 0.5281 (0.5145)	loss 2.1106 (2.8640)	grad_norm 7.1860 (8.5627)	mem 8929MB
[2022-04-09 13:11:58 large] (main.py 226): INFO Train: [256/300][1100/2502]	eta 0:12:01 lr 0.000030	time 0.4811 (0.5147)	loss 3.3694 (2.8691)	grad_norm 8.7993 (8.5542)	mem 8929MB
[2022-04-09 13:12:48 large] (main.py 226): INFO Train: [256/300][1200/2502]	eta 0:11:08 lr 0.000030	time 0.5255 (0.5138)	loss 3.3787 (2.8765)	grad_norm 6.5958 (8.5335)	mem 8929MB
[2022-04-09 13:13:41 large] (main.py 226): INFO Train: [256/300][1300/2502]	eta 0:10:18 lr 0.000030	time 0.4733 (0.5145)	loss 3.1933 (2.8766)	grad_norm 8.2189 (8.5203)	mem 8929MB
[2022-04-09 13:14:32 large] (main.py 226): INFO Train: [256/300][1400/2502]	eta 0:09:26 lr 0.000030	time 0.5177 (0.5143)	loss 2.3730 (2.8785)	grad_norm 6.4266 (8.4901)	mem 8929MB
[2022-04-09 13:15:24 large] (main.py 226): INFO Train: [256/300][1500/2502]	eta 0:08:35 lr 0.000030	time 0.5206 (0.5149)	loss 3.1084 (2.8800)	grad_norm 7.2517 (8.5566)	mem 8929MB
[2022-04-09 13:16:17 large] (main.py 226): INFO Train: [256/300][1600/2502]	eta 0:07:45 lr 0.000030	time 0.5152 (0.5155)	loss 1.7929 (2.8782)	grad_norm 8.3128 (8.5657)	mem 8929MB
[2022-04-09 13:17:05 large] (main.py 226): INFO Train: [256/300][1700/2502]	eta 0:06:51 lr 0.000030	time 0.4813 (0.5137)	loss 3.1994 (2.8783)	grad_norm 9.6953 (8.5513)	mem 8929MB
[2022-04-09 13:17:55 large] (main.py 226): INFO Train: [256/300][1800/2502]	eta 0:05:59 lr 0.000030	time 0.5725 (0.5126)	loss 3.4254 (2.8783)	grad_norm 7.8829 (8.5406)	mem 8929MB
[2022-04-09 13:18:47 large] (main.py 226): INFO Train: [256/300][1900/2502]	eta 0:05:08 lr 0.000030	time 0.5659 (0.5132)	loss 3.4806 (2.8792)	grad_norm 8.1792 (8.5632)	mem 8929MB
[2022-04-09 13:19:40 large] (main.py 226): INFO Train: [256/300][2000/2502]	eta 0:04:17 lr 0.000030	time 0.5702 (0.5139)	loss 3.2093 (2.8767)	grad_norm 9.4090 (8.5407)	mem 8929MB
[2022-04-09 13:20:32 large] (main.py 226): INFO Train: [256/300][2100/2502]	eta 0:03:26 lr 0.000030	time 0.5115 (0.5142)	loss 3.1387 (2.8790)	grad_norm 7.8044 (8.5523)	mem 8929MB
[2022-04-09 13:21:24 large] (main.py 226): INFO Train: [256/300][2200/2502]	eta 0:02:35 lr 0.000030	time 0.5238 (0.5145)	loss 1.9558 (2.8795)	grad_norm 9.0216 (8.5869)	mem 8929MB
[2022-04-09 13:22:15 large] (main.py 226): INFO Train: [256/300][2300/2502]	eta 0:01:43 lr 0.000030	time 0.4590 (0.5146)	loss 2.7884 (2.8778)	grad_norm 7.4967 (8.5600)	mem 8929MB
[2022-04-09 13:23:05 large] (main.py 226): INFO Train: [256/300][2400/2502]	eta 0:00:52 lr 0.000030	time 0.4899 (0.5136)	loss 2.6582 (2.8766)	grad_norm 9.8434 (8.5590)	mem 8929MB
[2022-04-09 13:23:54 large] (main.py 226): INFO Train: [256/300][2500/2502]	eta 0:00:01 lr 0.000030	time 0.4974 (0.5129)	loss 3.3409 (2.8760)	grad_norm 7.0973 (8.5494)	mem 8929MB
[2022-04-09 13:23:55 large] (main.py 233): INFO EPOCH 256 training takes 0:21:23
[2022-04-09 13:24:02 large] (main.py 273): INFO Test: [0/98]	Time 6.455 (6.455)	Loss 1.0291 (1.0291)	Acc@1 78.906 (78.906)	Acc@5 95.898 (95.898)	Mem 8929MB
[2022-04-09 13:24:28 large] (main.py 279): INFO  * Acc@1 81.452 Acc@5 95.520
[2022-04-09 13:24:28 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.5%
[2022-04-09 13:24:28 large] (utils.py 57): INFO output/large/default/ckpt_epoch_256.pth saving......
[2022-04-09 13:24:29 large] (utils.py 59): INFO output/large/default/ckpt_epoch_256.pth saved !!!
[2022-04-09 13:24:29 large] (main.py 148): INFO Max accuracy: 81.45%
[2022-04-09 13:24:36 large] (main.py 226): INFO Train: [257/300][0/2502]	eta 5:15:25 lr 0.000030	time 7.5642 (7.5642)	loss 3.2337 (3.2337)	grad_norm 5.9517 (5.9517)	mem 8929MB
[2022-04-09 13:25:26 large] (main.py 226): INFO Train: [257/300][100/2502]	eta 0:22:43 lr 0.000030	time 0.4875 (0.5675)	loss 2.1390 (2.9818)	grad_norm 6.5885 (7.8927)	mem 8929MB
[2022-04-09 13:26:17 large] (main.py 226): INFO Train: [257/300][200/2502]	eta 0:20:46 lr 0.000030	time 0.5970 (0.5415)	loss 3.0020 (2.9419)	grad_norm 6.2447 (8.0486)	mem 8929MB
[2022-04-09 13:27:10 large] (main.py 226): INFO Train: [257/300][300/2502]	eta 0:19:43 lr 0.000030	time 0.5356 (0.5375)	loss 2.1195 (2.9080)	grad_norm 6.1586 (8.0584)	mem 8929MB
[2022-04-09 13:28:02 large] (main.py 226): INFO Train: [257/300][400/2502]	eta 0:18:38 lr 0.000029	time 0.4881 (0.5320)	loss 3.2845 (2.8968)	grad_norm 7.6496 (nan)	mem 8929MB
[2022-04-09 13:28:54 large] (main.py 226): INFO Train: [257/300][500/2502]	eta 0:17:39 lr 0.000029	time 0.4894 (0.5291)	loss 2.5903 (2.8935)	grad_norm 5.5374 (nan)	mem 8929MB
[2022-04-09 13:29:46 large] (main.py 226): INFO Train: [257/300][600/2502]	eta 0:16:45 lr 0.000029	time 0.5272 (0.5289)	loss 3.5650 (2.8906)	grad_norm 8.2763 (nan)	mem 8929MB
[2022-04-09 13:30:39 large] (main.py 226): INFO Train: [257/300][700/2502]	eta 0:15:51 lr 0.000029	time 0.5910 (0.5281)	loss 3.2602 (2.8857)	grad_norm 6.8704 (nan)	mem 8929MB
[2022-04-09 13:31:31 large] (main.py 226): INFO Train: [257/300][800/2502]	eta 0:14:57 lr 0.000029	time 0.4935 (0.5271)	loss 2.8326 (2.8922)	grad_norm 7.6922 (nan)	mem 8929MB
[2022-04-09 13:32:22 large] (main.py 226): INFO Train: [257/300][900/2502]	eta 0:14:02 lr 0.000029	time 0.5035 (0.5259)	loss 3.0894 (2.8939)	grad_norm 7.3847 (nan)	mem 8929MB
[2022-04-09 13:33:12 large] (main.py 226): INFO Train: [257/300][1000/2502]	eta 0:13:05 lr 0.000029	time 0.4962 (0.5229)	loss 1.8788 (2.8872)	grad_norm 32.8223 (nan)	mem 8929MB
[2022-04-09 13:34:04 large] (main.py 226): INFO Train: [257/300][1100/2502]	eta 0:12:12 lr 0.000029	time 0.5008 (0.5226)	loss 3.1014 (2.8871)	grad_norm 7.0986 (nan)	mem 8929MB
[2022-04-09 13:34:57 large] (main.py 226): INFO Train: [257/300][1200/2502]	eta 0:11:21 lr 0.000029	time 0.5011 (0.5231)	loss 2.6228 (2.8887)	grad_norm 8.0239 (nan)	mem 8929MB
[2022-04-09 13:35:49 large] (main.py 226): INFO Train: [257/300][1300/2502]	eta 0:10:28 lr 0.000029	time 0.5170 (0.5231)	loss 2.8841 (2.8934)	grad_norm 5.9086 (nan)	mem 8929MB
[2022-04-09 13:36:41 large] (main.py 226): INFO Train: [257/300][1400/2502]	eta 0:09:36 lr 0.000029	time 0.5413 (0.5229)	loss 2.1936 (2.8925)	grad_norm 5.4548 (nan)	mem 8929MB
[2022-04-09 13:37:33 large] (main.py 226): INFO Train: [257/300][1500/2502]	eta 0:08:43 lr 0.000029	time 0.5289 (0.5228)	loss 1.8908 (2.8950)	grad_norm 5.6612 (nan)	mem 8929MB
[2022-04-09 13:38:25 large] (main.py 226): INFO Train: [257/300][1600/2502]	eta 0:07:51 lr 0.000029	time 0.5410 (0.5226)	loss 2.9479 (2.8948)	grad_norm 5.9643 (nan)	mem 8929MB
[2022-04-09 13:39:16 large] (main.py 226): INFO Train: [257/300][1700/2502]	eta 0:06:58 lr 0.000029	time 0.5380 (0.5217)	loss 3.0599 (2.8948)	grad_norm 7.6467 (nan)	mem 8929MB
[2022-04-09 13:40:08 large] (main.py 226): INFO Train: [257/300][1800/2502]	eta 0:06:06 lr 0.000029	time 0.5637 (0.5215)	loss 3.0179 (2.8940)	grad_norm 7.8423 (nan)	mem 8929MB
[2022-04-09 13:41:00 large] (main.py 226): INFO Train: [257/300][1900/2502]	eta 0:05:13 lr 0.000029	time 0.5048 (0.5214)	loss 3.2984 (2.8951)	grad_norm 6.0489 (nan)	mem 8929MB
[2022-04-09 13:41:48 large] (main.py 226): INFO Train: [257/300][2000/2502]	eta 0:04:20 lr 0.000029	time 0.4667 (0.5197)	loss 3.4581 (2.8969)	grad_norm 5.5128 (nan)	mem 8929MB
[2022-04-09 13:42:37 large] (main.py 226): INFO Train: [257/300][2100/2502]	eta 0:03:28 lr 0.000029	time 0.4880 (0.5181)	loss 2.6759 (2.8952)	grad_norm 8.0108 (nan)	mem 8929MB
[2022-04-09 13:43:28 large] (main.py 226): INFO Train: [257/300][2200/2502]	eta 0:02:36 lr 0.000029	time 0.5319 (0.5179)	loss 3.3325 (2.8913)	grad_norm 8.2881 (nan)	mem 8929MB
[2022-04-09 13:44:18 large] (main.py 226): INFO Train: [257/300][2300/2502]	eta 0:01:44 lr 0.000029	time 0.5042 (0.5171)	loss 2.0893 (2.8908)	grad_norm 7.5247 (nan)	mem 8929MB
[2022-04-09 13:45:09 large] (main.py 226): INFO Train: [257/300][2400/2502]	eta 0:00:52 lr 0.000029	time 0.5331 (0.5168)	loss 3.4241 (2.8874)	grad_norm 6.9492 (nan)	mem 8929MB
[2022-04-09 13:46:02 large] (main.py 226): INFO Train: [257/300][2500/2502]	eta 0:00:01 lr 0.000029	time 0.5022 (0.5170)	loss 2.0831 (2.8860)	grad_norm 7.8977 (nan)	mem 8929MB
[2022-04-09 13:46:03 large] (main.py 233): INFO EPOCH 257 training takes 0:21:34
[2022-04-09 13:46:09 large] (main.py 273): INFO Test: [0/98]	Time 6.012 (6.012)	Loss 0.9867 (0.9867)	Acc@1 80.273 (80.273)	Acc@5 94.531 (94.531)	Mem 8929MB
[2022-04-09 13:46:35 large] (main.py 279): INFO  * Acc@1 81.564 Acc@5 95.526
[2022-04-09 13:46:35 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.6%
[2022-04-09 13:46:35 large] (utils.py 57): INFO output/large/default/ckpt_epoch_257.pth saving......
[2022-04-09 13:46:36 large] (utils.py 59): INFO output/large/default/ckpt_epoch_257.pth saved !!!
[2022-04-09 13:46:36 large] (main.py 148): INFO Max accuracy: 81.56%
[2022-04-09 13:46:43 large] (main.py 226): INFO Train: [258/300][0/2502]	eta 4:57:09 lr 0.000029	time 7.1261 (7.1261)	loss 3.3211 (3.3211)	grad_norm 7.5015 (7.5015)	mem 8929MB
[2022-04-09 13:47:34 large] (main.py 226): INFO Train: [258/300][100/2502]	eta 0:22:55 lr 0.000029	time 0.5138 (0.5728)	loss 3.0769 (2.8951)	grad_norm 10.2351 (8.6365)	mem 8929MB
[2022-04-09 13:48:24 large] (main.py 226): INFO Train: [258/300][200/2502]	eta 0:20:44 lr 0.000028	time 0.5507 (0.5405)	loss 3.0075 (2.8404)	grad_norm 6.5987 (8.6011)	mem 8929MB
[2022-04-09 13:49:14 large] (main.py 226): INFO Train: [258/300][300/2502]	eta 0:19:20 lr 0.000028	time 0.5688 (0.5272)	loss 3.1219 (2.8482)	grad_norm 6.7304 (8.6294)	mem 8929MB
[2022-04-09 13:50:08 large] (main.py 226): INFO Train: [258/300][400/2502]	eta 0:18:30 lr 0.000028	time 0.5347 (0.5284)	loss 2.3955 (2.8566)	grad_norm 8.3787 (8.6097)	mem 8929MB
[2022-04-09 13:51:01 large] (main.py 226): INFO Train: [258/300][500/2502]	eta 0:17:38 lr 0.000028	time 0.4980 (0.5286)	loss 3.0648 (2.8540)	grad_norm 11.2970 (8.7223)	mem 8929MB
[2022-04-09 13:51:54 large] (main.py 226): INFO Train: [258/300][600/2502]	eta 0:16:45 lr 0.000028	time 0.4969 (0.5289)	loss 2.9675 (2.8541)	grad_norm 7.7478 (8.6833)	mem 8929MB
[2022-04-09 13:52:46 large] (main.py 226): INFO Train: [258/300][700/2502]	eta 0:15:51 lr 0.000028	time 0.5730 (0.5280)	loss 3.1668 (2.8574)	grad_norm 7.8724 (8.7654)	mem 8929MB
[2022-04-09 13:53:38 large] (main.py 226): INFO Train: [258/300][800/2502]	eta 0:14:57 lr 0.000028	time 0.5031 (0.5276)	loss 2.2776 (2.8552)	grad_norm 9.0075 (8.7030)	mem 8929MB
[2022-04-09 13:54:31 large] (main.py 226): INFO Train: [258/300][900/2502]	eta 0:14:04 lr 0.000028	time 0.5470 (0.5273)	loss 2.9797 (2.8501)	grad_norm 8.4184 (8.6320)	mem 8929MB
[2022-04-09 13:55:21 large] (main.py 226): INFO Train: [258/300][1000/2502]	eta 0:13:07 lr 0.000028	time 0.4717 (0.5244)	loss 3.1224 (2.8560)	grad_norm 6.7028 (8.5950)	mem 8929MB
[2022-04-09 13:56:10 large] (main.py 226): INFO Train: [258/300][1100/2502]	eta 0:12:10 lr 0.000028	time 0.4942 (0.5212)	loss 3.3346 (2.8555)	grad_norm 10.1952 (8.6106)	mem 8929MB
[2022-04-09 13:57:01 large] (main.py 226): INFO Train: [258/300][1200/2502]	eta 0:11:18 lr 0.000028	time 0.6217 (0.5210)	loss 3.1155 (2.8637)	grad_norm 8.9173 (8.6230)	mem 8929MB
[2022-04-09 13:57:51 large] (main.py 226): INFO Train: [258/300][1300/2502]	eta 0:10:24 lr 0.000028	time 0.5054 (0.5193)	loss 3.0486 (2.8653)	grad_norm 7.3000 (8.6352)	mem 8929MB
[2022-04-09 13:58:41 large] (main.py 226): INFO Train: [258/300][1400/2502]	eta 0:09:30 lr 0.000028	time 0.4951 (0.5177)	loss 2.4860 (2.8691)	grad_norm 7.6455 (8.6382)	mem 8929MB
[2022-04-09 13:59:31 large] (main.py 226): INFO Train: [258/300][1500/2502]	eta 0:08:37 lr 0.000028	time 0.5095 (0.5166)	loss 2.1935 (2.8768)	grad_norm 8.1146 (nan)	mem 8929MB
[2022-04-09 14:00:21 large] (main.py 226): INFO Train: [258/300][1600/2502]	eta 0:07:45 lr 0.000028	time 0.5126 (0.5157)	loss 3.0897 (2.8728)	grad_norm 15.4810 (nan)	mem 8929MB
[2022-04-09 14:01:14 large] (main.py 226): INFO Train: [258/300][1700/2502]	eta 0:06:54 lr 0.000028	time 0.5084 (0.5165)	loss 2.8222 (2.8715)	grad_norm 21.5787 (nan)	mem 8929MB
[2022-04-09 14:02:07 large] (main.py 226): INFO Train: [258/300][1800/2502]	eta 0:06:03 lr 0.000028	time 0.5126 (0.5172)	loss 1.9450 (2.8743)	grad_norm 6.4917 (nan)	mem 8929MB
[2022-04-09 14:03:00 large] (main.py 226): INFO Train: [258/300][1900/2502]	eta 0:05:11 lr 0.000028	time 0.5159 (0.5176)	loss 2.7896 (2.8750)	grad_norm 8.1900 (nan)	mem 8929MB
[2022-04-09 14:03:52 large] (main.py 226): INFO Train: [258/300][2000/2502]	eta 0:04:20 lr 0.000028	time 0.5276 (0.5181)	loss 3.1682 (2.8719)	grad_norm 8.0974 (nan)	mem 8929MB
[2022-04-09 14:04:45 large] (main.py 226): INFO Train: [258/300][2100/2502]	eta 0:03:28 lr 0.000028	time 0.6278 (0.5184)	loss 2.8894 (2.8729)	grad_norm 16.6636 (nan)	mem 8929MB
[2022-04-09 14:05:38 large] (main.py 226): INFO Train: [258/300][2200/2502]	eta 0:02:36 lr 0.000028	time 0.5549 (0.5188)	loss 2.7061 (2.8723)	grad_norm 6.6439 (nan)	mem 8929MB
[2022-04-09 14:06:30 large] (main.py 226): INFO Train: [258/300][2300/2502]	eta 0:01:44 lr 0.000028	time 0.4841 (0.5190)	loss 2.9313 (2.8702)	grad_norm 11.3724 (nan)	mem 8929MB
[2022-04-09 14:07:22 large] (main.py 226): INFO Train: [258/300][2400/2502]	eta 0:00:52 lr 0.000028	time 0.4845 (0.5192)	loss 3.2418 (2.8703)	grad_norm 7.7798 (nan)	mem 8929MB
[2022-04-09 14:08:14 large] (main.py 226): INFO Train: [258/300][2500/2502]	eta 0:00:01 lr 0.000027	time 0.4929 (0.5190)	loss 2.2582 (2.8676)	grad_norm 8.3440 (nan)	mem 8929MB
[2022-04-09 14:08:15 large] (main.py 233): INFO EPOCH 258 training takes 0:21:39
[2022-04-09 14:08:21 large] (main.py 273): INFO Test: [0/98]	Time 6.633 (6.633)	Loss 0.8732 (0.8732)	Acc@1 84.570 (84.570)	Acc@5 95.703 (95.703)	Mem 8929MB
[2022-04-09 14:08:47 large] (main.py 279): INFO  * Acc@1 81.496 Acc@5 95.590
[2022-04-09 14:08:47 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.5%
[2022-04-09 14:08:47 large] (main.py 148): INFO Max accuracy: 81.56%
[2022-04-09 14:08:54 large] (main.py 226): INFO Train: [259/300][0/2502]	eta 4:36:51 lr 0.000027	time 6.6395 (6.6395)	loss 3.2335 (3.2335)	grad_norm 8.9675 (8.9675)	mem 8929MB
[2022-04-09 14:09:44 large] (main.py 226): INFO Train: [259/300][100/2502]	eta 0:22:36 lr 0.000027	time 0.4734 (0.5647)	loss 3.2003 (2.9211)	grad_norm 6.9337 (8.6765)	mem 8929MB
[2022-04-09 14:10:33 large] (main.py 226): INFO Train: [259/300][200/2502]	eta 0:20:16 lr 0.000027	time 0.5064 (0.5286)	loss 2.3205 (2.8465)	grad_norm 10.2441 (8.5792)	mem 8929MB
[2022-04-09 14:11:26 large] (main.py 226): INFO Train: [259/300][300/2502]	eta 0:19:21 lr 0.000027	time 0.5345 (0.5273)	loss 2.7138 (2.8387)	grad_norm 7.2423 (8.5939)	mem 8929MB
[2022-04-09 14:12:19 large] (main.py 226): INFO Train: [259/300][400/2502]	eta 0:18:30 lr 0.000027	time 0.5100 (0.5282)	loss 3.3206 (2.8562)	grad_norm 7.5700 (8.5511)	mem 8929MB
[2022-04-09 14:13:11 large] (main.py 226): INFO Train: [259/300][500/2502]	eta 0:17:33 lr 0.000027	time 0.4863 (0.5262)	loss 2.6330 (2.8444)	grad_norm 9.0075 (8.4669)	mem 8929MB
[2022-04-09 14:14:00 large] (main.py 226): INFO Train: [259/300][600/2502]	eta 0:16:31 lr 0.000027	time 0.4790 (0.5211)	loss 2.9387 (2.8376)	grad_norm 7.6607 (8.4576)	mem 8929MB
[2022-04-09 14:14:51 large] (main.py 226): INFO Train: [259/300][700/2502]	eta 0:15:36 lr 0.000027	time 0.4457 (0.5195)	loss 2.1177 (2.8289)	grad_norm 8.7885 (8.5324)	mem 8929MB
[2022-04-09 14:15:45 large] (main.py 226): INFO Train: [259/300][800/2502]	eta 0:14:48 lr 0.000027	time 0.5108 (0.5218)	loss 2.3828 (2.8352)	grad_norm 7.4196 (8.6201)	mem 8929MB
[2022-04-09 14:16:38 large] (main.py 226): INFO Train: [259/300][900/2502]	eta 0:13:57 lr 0.000027	time 0.5389 (0.5228)	loss 2.9781 (2.8524)	grad_norm 6.9733 (8.7212)	mem 8929MB
[2022-04-09 14:17:31 large] (main.py 226): INFO Train: [259/300][1000/2502]	eta 0:13:06 lr 0.000027	time 0.5210 (0.5234)	loss 1.8511 (2.8518)	grad_norm 9.0372 (8.6877)	mem 8929MB
[2022-04-09 14:18:23 large] (main.py 226): INFO Train: [259/300][1100/2502]	eta 0:12:14 lr 0.000027	time 0.5155 (0.5235)	loss 2.7712 (2.8521)	grad_norm 8.1468 (nan)	mem 8929MB
[2022-04-09 14:19:16 large] (main.py 226): INFO Train: [259/300][1200/2502]	eta 0:11:21 lr 0.000027	time 0.5189 (0.5237)	loss 3.0901 (2.8409)	grad_norm 7.5912 (nan)	mem 8929MB
[2022-04-09 14:20:09 large] (main.py 226): INFO Train: [259/300][1300/2502]	eta 0:10:29 lr 0.000027	time 0.5133 (0.5240)	loss 3.2410 (2.8391)	grad_norm 9.0376 (nan)	mem 8929MB
[2022-04-09 14:21:01 large] (main.py 226): INFO Train: [259/300][1400/2502]	eta 0:09:37 lr 0.000027	time 0.4934 (0.5240)	loss 3.0889 (2.8426)	grad_norm 6.1240 (nan)	mem 8929MB
[2022-04-09 14:21:50 large] (main.py 226): INFO Train: [259/300][1500/2502]	eta 0:08:42 lr 0.000027	time 0.5728 (0.5218)	loss 2.5540 (2.8427)	grad_norm 8.0528 (nan)	mem 8929MB
[2022-04-09 14:22:40 large] (main.py 226): INFO Train: [259/300][1600/2502]	eta 0:07:49 lr 0.000027	time 0.4482 (0.5204)	loss 2.0646 (2.8422)	grad_norm 8.8989 (nan)	mem 8929MB
[2022-04-09 14:23:29 large] (main.py 226): INFO Train: [259/300][1700/2502]	eta 0:06:55 lr 0.000027	time 0.5551 (0.5184)	loss 2.4681 (2.8463)	grad_norm 6.7243 (nan)	mem 8929MB
[2022-04-09 14:24:20 large] (main.py 226): INFO Train: [259/300][1800/2502]	eta 0:06:03 lr 0.000027	time 0.5338 (0.5181)	loss 2.3356 (2.8493)	grad_norm 9.0415 (nan)	mem 8929MB
[2022-04-09 14:25:13 large] (main.py 226): INFO Train: [259/300][1900/2502]	eta 0:05:12 lr 0.000027	time 0.5133 (0.5185)	loss 3.4386 (2.8529)	grad_norm 10.3485 (nan)	mem 8929MB
[2022-04-09 14:26:05 large] (main.py 226): INFO Train: [259/300][2000/2502]	eta 0:04:20 lr 0.000027	time 0.5165 (0.5190)	loss 2.8255 (2.8537)	grad_norm 6.5724 (nan)	mem 8929MB
[2022-04-09 14:26:58 large] (main.py 226): INFO Train: [259/300][2100/2502]	eta 0:03:28 lr 0.000027	time 0.5153 (0.5194)	loss 2.9376 (2.8521)	grad_norm 6.3748 (nan)	mem 8929MB
[2022-04-09 14:27:50 large] (main.py 226): INFO Train: [259/300][2200/2502]	eta 0:02:36 lr 0.000027	time 0.4889 (0.5194)	loss 3.0196 (2.8511)	grad_norm 6.3051 (nan)	mem 8929MB
[2022-04-09 14:28:41 large] (main.py 226): INFO Train: [259/300][2300/2502]	eta 0:01:44 lr 0.000026	time 0.5920 (0.5190)	loss 2.7752 (2.8547)	grad_norm 7.7272 (nan)	mem 8929MB
[2022-04-09 14:29:33 large] (main.py 226): INFO Train: [259/300][2400/2502]	eta 0:00:52 lr 0.000026	time 0.5439 (0.5191)	loss 2.5924 (2.8555)	grad_norm 9.2153 (nan)	mem 8929MB
[2022-04-09 14:30:23 large] (main.py 226): INFO Train: [259/300][2500/2502]	eta 0:00:01 lr 0.000026	time 0.5383 (0.5184)	loss 2.9047 (2.8548)	grad_norm 9.1213 (nan)	mem 8929MB
[2022-04-09 14:30:24 large] (main.py 233): INFO EPOCH 259 training takes 0:21:37
[2022-04-09 14:30:31 large] (main.py 273): INFO Test: [0/98]	Time 6.086 (6.086)	Loss 1.0261 (1.0261)	Acc@1 81.641 (81.641)	Acc@5 94.531 (94.531)	Mem 8929MB
[2022-04-09 14:30:56 large] (main.py 279): INFO  * Acc@1 81.416 Acc@5 95.560
[2022-04-09 14:30:56 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.4%
[2022-04-09 14:30:56 large] (main.py 148): INFO Max accuracy: 81.56%
[2022-04-09 14:31:03 large] (main.py 226): INFO Train: [260/300][0/2502]	eta 4:51:25 lr 0.000026	time 6.9888 (6.9888)	loss 2.3332 (2.3332)	grad_norm 7.9304 (7.9304)	mem 8929MB
[2022-04-09 14:31:55 large] (main.py 226): INFO Train: [260/300][100/2502]	eta 0:23:02 lr 0.000026	time 0.5497 (0.5754)	loss 3.1877 (2.8570)	grad_norm 5.7731 (8.5851)	mem 8929MB
[2022-04-09 14:32:47 large] (main.py 226): INFO Train: [260/300][200/2502]	eta 0:21:06 lr 0.000026	time 0.5981 (0.5502)	loss 2.3085 (2.8671)	grad_norm 8.3034 (8.5403)	mem 8929MB
[2022-04-09 14:33:38 large] (main.py 226): INFO Train: [260/300][300/2502]	eta 0:19:40 lr 0.000026	time 0.5424 (0.5360)	loss 2.8661 (2.8588)	grad_norm 9.9327 (8.5009)	mem 8929MB
[2022-04-09 14:34:28 large] (main.py 226): INFO Train: [260/300][400/2502]	eta 0:18:29 lr 0.000026	time 0.5295 (0.5276)	loss 3.4784 (2.8526)	grad_norm 11.5678 (8.5832)	mem 8929MB
[2022-04-09 14:35:20 large] (main.py 226): INFO Train: [260/300][500/2502]	eta 0:17:34 lr 0.000026	time 0.6134 (0.5267)	loss 3.0222 (2.8492)	grad_norm 6.8862 (8.5633)	mem 8929MB
[2022-04-09 14:36:13 large] (main.py 226): INFO Train: [260/300][600/2502]	eta 0:16:41 lr 0.000026	time 0.5605 (0.5267)	loss 3.0042 (2.8461)	grad_norm 7.2301 (8.5161)	mem 8929MB
[2022-04-09 14:37:06 large] (main.py 226): INFO Train: [260/300][700/2502]	eta 0:15:49 lr 0.000026	time 0.5244 (0.5272)	loss 3.2037 (2.8459)	grad_norm 6.5998 (8.4946)	mem 8929MB
[2022-04-09 14:37:59 large] (main.py 226): INFO Train: [260/300][800/2502]	eta 0:14:57 lr 0.000026	time 0.5112 (0.5274)	loss 3.1243 (2.8486)	grad_norm 7.6049 (8.6446)	mem 8929MB
[2022-04-09 14:38:52 large] (main.py 226): INFO Train: [260/300][900/2502]	eta 0:14:05 lr 0.000026	time 0.5304 (0.5275)	loss 2.0154 (2.8589)	grad_norm 7.2796 (8.6125)	mem 8929MB
[2022-04-09 14:39:44 large] (main.py 226): INFO Train: [260/300][1000/2502]	eta 0:13:11 lr 0.000026	time 0.5515 (0.5270)	loss 3.5724 (2.8538)	grad_norm 6.9834 (8.8337)	mem 8929MB
[2022-04-09 14:40:35 large] (main.py 226): INFO Train: [260/300][1100/2502]	eta 0:12:17 lr 0.000026	time 0.4841 (0.5258)	loss 3.6434 (2.8496)	grad_norm 11.4959 (8.8345)	mem 8929MB
[2022-04-09 14:41:27 large] (main.py 226): INFO Train: [260/300][1200/2502]	eta 0:11:23 lr 0.000026	time 0.5364 (0.5247)	loss 2.9904 (2.8503)	grad_norm 9.0755 (8.8151)	mem 8929MB
[2022-04-09 14:42:19 large] (main.py 226): INFO Train: [260/300][1300/2502]	eta 0:10:30 lr 0.000026	time 0.5658 (0.5248)	loss 3.6704 (2.8455)	grad_norm 9.8173 (8.7973)	mem 8929MB
[2022-04-09 14:43:12 large] (main.py 226): INFO Train: [260/300][1400/2502]	eta 0:09:38 lr 0.000026	time 0.5737 (0.5249)	loss 2.5414 (2.8465)	grad_norm 6.8185 (8.8285)	mem 8929MB
[2022-04-09 14:44:04 large] (main.py 226): INFO Train: [260/300][1500/2502]	eta 0:08:45 lr 0.000026	time 0.4996 (0.5245)	loss 3.4450 (2.8458)	grad_norm 31.5688 (8.8449)	mem 8929MB
[2022-04-09 14:44:57 large] (main.py 226): INFO Train: [260/300][1600/2502]	eta 0:07:53 lr 0.000026	time 0.5068 (0.5247)	loss 3.2653 (2.8444)	grad_norm 9.1454 (8.8188)	mem 8929MB
[2022-04-09 14:45:49 large] (main.py 226): INFO Train: [260/300][1700/2502]	eta 0:07:00 lr 0.000026	time 0.4783 (0.5246)	loss 2.4408 (2.8458)	grad_norm 9.8445 (8.8044)	mem 8929MB
[2022-04-09 14:46:42 large] (main.py 226): INFO Train: [260/300][1800/2502]	eta 0:06:08 lr 0.000026	time 0.5718 (0.5248)	loss 3.1126 (2.8494)	grad_norm 6.5057 (nan)	mem 8929MB
[2022-04-09 14:47:34 large] (main.py 226): INFO Train: [260/300][1900/2502]	eta 0:05:15 lr 0.000026	time 0.5600 (0.5248)	loss 2.0641 (2.8496)	grad_norm 6.5767 (nan)	mem 8929MB
[2022-04-09 14:48:27 large] (main.py 226): INFO Train: [260/300][2000/2502]	eta 0:04:23 lr 0.000026	time 0.5343 (0.5248)	loss 3.1203 (2.8526)	grad_norm 10.3534 (nan)	mem 8929MB
[2022-04-09 14:49:16 large] (main.py 226): INFO Train: [260/300][2100/2502]	eta 0:03:30 lr 0.000026	time 0.4813 (0.5235)	loss 3.3134 (2.8544)	grad_norm 7.4746 (nan)	mem 8929MB
[2022-04-09 14:50:07 large] (main.py 226): INFO Train: [260/300][2200/2502]	eta 0:02:37 lr 0.000025	time 0.5123 (0.5226)	loss 2.7655 (2.8545)	grad_norm 9.0489 (nan)	mem 8929MB
[2022-04-09 14:50:59 large] (main.py 226): INFO Train: [260/300][2300/2502]	eta 0:01:45 lr 0.000025	time 0.5739 (0.5227)	loss 1.8685 (2.8537)	grad_norm 6.6555 (nan)	mem 8929MB
[2022-04-09 14:51:52 large] (main.py 226): INFO Train: [260/300][2400/2502]	eta 0:00:53 lr 0.000025	time 0.5098 (0.5228)	loss 2.9046 (2.8551)	grad_norm 5.6437 (nan)	mem 8929MB
[2022-04-09 14:52:44 large] (main.py 226): INFO Train: [260/300][2500/2502]	eta 0:00:01 lr 0.000025	time 0.5056 (0.5228)	loss 3.1600 (2.8558)	grad_norm 6.8564 (nan)	mem 8929MB
[2022-04-09 14:52:45 large] (main.py 233): INFO EPOCH 260 training takes 0:21:48
[2022-04-09 14:52:51 large] (main.py 273): INFO Test: [0/98]	Time 6.514 (6.514)	Loss 1.0176 (1.0176)	Acc@1 80.273 (80.273)	Acc@5 94.531 (94.531)	Mem 8929MB
[2022-04-09 14:53:17 large] (main.py 279): INFO  * Acc@1 81.482 Acc@5 95.516
[2022-04-09 14:53:17 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.5%
[2022-04-09 14:53:17 large] (main.py 148): INFO Max accuracy: 81.56%
[2022-04-09 14:53:25 large] (main.py 226): INFO Train: [261/300][0/2502]	eta 5:14:53 lr 0.000025	time 7.5512 (7.5512)	loss 2.1354 (2.1354)	grad_norm 6.4319 (6.4319)	mem 8929MB
[2022-04-09 14:54:15 large] (main.py 226): INFO Train: [261/300][100/2502]	eta 0:22:57 lr 0.000025	time 0.4845 (0.5733)	loss 2.8285 (2.7581)	grad_norm 6.1692 (8.3869)	mem 8929MB
[2022-04-09 14:55:09 large] (main.py 226): INFO Train: [261/300][200/2502]	eta 0:21:14 lr 0.000025	time 0.5537 (0.5536)	loss 2.5714 (2.7731)	grad_norm 9.4699 (8.6851)	mem 8929MB
[2022-04-09 14:56:01 large] (main.py 226): INFO Train: [261/300][300/2502]	eta 0:19:58 lr 0.000025	time 0.5218 (0.5442)	loss 3.2312 (2.7973)	grad_norm 6.4949 (8.8154)	mem 8929MB
[2022-04-09 14:56:52 large] (main.py 226): INFO Train: [261/300][400/2502]	eta 0:18:44 lr 0.000025	time 0.5043 (0.5348)	loss 3.2945 (2.8005)	grad_norm 7.4471 (8.9148)	mem 8929MB
[2022-04-09 14:57:45 large] (main.py 226): INFO Train: [261/300][500/2502]	eta 0:17:51 lr 0.000025	time 0.4939 (0.5350)	loss 3.0673 (2.8091)	grad_norm 8.1904 (8.8980)	mem 8929MB
[2022-04-09 14:58:37 large] (main.py 226): INFO Train: [261/300][600/2502]	eta 0:16:50 lr 0.000025	time 0.4647 (0.5312)	loss 2.7423 (2.8174)	grad_norm 8.9851 (8.8444)	mem 8929MB
[2022-04-09 14:59:26 large] (main.py 226): INFO Train: [261/300][700/2502]	eta 0:15:46 lr 0.000025	time 0.5310 (0.5253)	loss 3.4935 (2.8137)	grad_norm 8.2146 (8.7079)	mem 8929MB
[2022-04-09 15:00:15 large] (main.py 226): INFO Train: [261/300][800/2502]	eta 0:14:47 lr 0.000025	time 0.5281 (0.5217)	loss 3.4652 (2.8227)	grad_norm 9.8074 (8.6218)	mem 8929MB
[2022-04-09 15:01:06 large] (main.py 226): INFO Train: [261/300][900/2502]	eta 0:13:53 lr 0.000025	time 0.5117 (0.5202)	loss 3.5838 (2.8245)	grad_norm 6.7070 (8.5673)	mem 8929MB
[2022-04-09 15:01:59 large] (main.py 226): INFO Train: [261/300][1000/2502]	eta 0:13:03 lr 0.000025	time 0.5622 (0.5215)	loss 2.9832 (2.8322)	grad_norm 7.0852 (8.5355)	mem 8929MB
[2022-04-09 15:02:50 large] (main.py 226): INFO Train: [261/300][1100/2502]	eta 0:12:09 lr 0.000025	time 0.5932 (0.5205)	loss 3.4705 (2.8338)	grad_norm 6.8905 (8.5076)	mem 8929MB
[2022-04-09 15:03:43 large] (main.py 226): INFO Train: [261/300][1200/2502]	eta 0:11:18 lr 0.000025	time 0.5678 (0.5213)	loss 3.1699 (2.8303)	grad_norm 10.4443 (8.4591)	mem 8929MB
[2022-04-09 15:04:37 large] (main.py 226): INFO Train: [261/300][1300/2502]	eta 0:10:27 lr 0.000025	time 0.5267 (0.5222)	loss 1.6206 (2.8314)	grad_norm 9.2469 (8.4552)	mem 8929MB
[2022-04-09 15:05:29 large] (main.py 226): INFO Train: [261/300][1400/2502]	eta 0:09:35 lr 0.000025	time 0.5286 (0.5222)	loss 3.0537 (2.8322)	grad_norm 7.3816 (8.4721)	mem 8929MB
[2022-04-09 15:06:22 large] (main.py 226): INFO Train: [261/300][1500/2502]	eta 0:08:43 lr 0.000025	time 0.5158 (0.5228)	loss 3.1982 (2.8394)	grad_norm 8.2200 (8.5029)	mem 8929MB
[2022-04-09 15:07:14 large] (main.py 226): INFO Train: [261/300][1600/2502]	eta 0:07:51 lr 0.000025	time 0.4970 (0.5229)	loss 2.6015 (2.8394)	grad_norm 7.9712 (8.5186)	mem 8929MB
[2022-04-09 15:08:04 large] (main.py 226): INFO Train: [261/300][1700/2502]	eta 0:06:58 lr 0.000025	time 0.4917 (0.5215)	loss 3.2757 (2.8383)	grad_norm 7.8116 (8.5068)	mem 8929MB
[2022-04-09 15:08:57 large] (main.py 226): INFO Train: [261/300][1800/2502]	eta 0:06:06 lr 0.000025	time 0.5297 (0.5218)	loss 3.1613 (2.8377)	grad_norm 7.6694 (8.5523)	mem 8929MB
[2022-04-09 15:09:50 large] (main.py 226): INFO Train: [261/300][1900/2502]	eta 0:05:14 lr 0.000025	time 0.4691 (0.5220)	loss 3.2298 (2.8413)	grad_norm 7.6996 (8.5447)	mem 8929MB
[2022-04-09 15:10:40 large] (main.py 226): INFO Train: [261/300][2000/2502]	eta 0:04:21 lr 0.000025	time 0.5531 (0.5212)	loss 2.1547 (2.8406)	grad_norm 5.5376 (8.5310)	mem 8929MB
[2022-04-09 15:11:33 large] (main.py 226): INFO Train: [261/300][2100/2502]	eta 0:03:29 lr 0.000025	time 0.5598 (0.5215)	loss 3.2646 (2.8446)	grad_norm 9.7467 (8.6167)	mem 8929MB
[2022-04-09 15:12:26 large] (main.py 226): INFO Train: [261/300][2200/2502]	eta 0:02:37 lr 0.000024	time 0.5875 (0.5219)	loss 3.0531 (2.8475)	grad_norm 7.5397 (8.6289)	mem 8929MB
[2022-04-09 15:13:19 large] (main.py 226): INFO Train: [261/300][2300/2502]	eta 0:01:45 lr 0.000024	time 0.5360 (0.5221)	loss 3.0062 (2.8486)	grad_norm 6.5445 (8.6125)	mem 8929MB
[2022-04-09 15:14:11 large] (main.py 226): INFO Train: [261/300][2400/2502]	eta 0:00:53 lr 0.000024	time 0.5129 (0.5223)	loss 2.9870 (2.8459)	grad_norm 9.3020 (8.6051)	mem 8929MB
[2022-04-09 15:15:04 large] (main.py 226): INFO Train: [261/300][2500/2502]	eta 0:00:01 lr 0.000024	time 0.5044 (0.5223)	loss 3.3960 (2.8486)	grad_norm 158.6221 (8.6700)	mem 8929MB
[2022-04-09 15:15:05 large] (main.py 233): INFO EPOCH 261 training takes 0:21:47
[2022-04-09 15:15:12 large] (main.py 273): INFO Test: [0/98]	Time 6.827 (6.827)	Loss 0.9881 (0.9881)	Acc@1 81.445 (81.445)	Acc@5 94.727 (94.727)	Mem 8929MB
[2022-04-09 15:15:37 large] (main.py 279): INFO  * Acc@1 81.498 Acc@5 95.536
[2022-04-09 15:15:37 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.5%
[2022-04-09 15:15:37 large] (main.py 148): INFO Max accuracy: 81.56%
[2022-04-09 15:15:44 large] (main.py 226): INFO Train: [262/300][0/2502]	eta 4:26:40 lr 0.000024	time 6.3953 (6.3953)	loss 2.6784 (2.6784)	grad_norm 6.1203 (6.1203)	mem 8929MB
[2022-04-09 15:16:34 large] (main.py 226): INFO Train: [262/300][100/2502]	eta 0:22:36 lr 0.000024	time 0.4627 (0.5648)	loss 2.6592 (2.8286)	grad_norm 7.3663 (8.5712)	mem 8929MB
[2022-04-09 15:17:24 large] (main.py 226): INFO Train: [262/300][200/2502]	eta 0:20:17 lr 0.000024	time 0.4955 (0.5289)	loss 3.2298 (2.8456)	grad_norm 25.5413 (9.4807)	mem 8929MB
[2022-04-09 15:18:16 large] (main.py 226): INFO Train: [262/300][300/2502]	eta 0:19:20 lr 0.000024	time 0.5524 (0.5270)	loss 1.7581 (2.8486)	grad_norm 8.3008 (9.2669)	mem 8929MB
[2022-04-09 15:19:10 large] (main.py 226): INFO Train: [262/300][400/2502]	eta 0:18:33 lr 0.000024	time 0.5796 (0.5297)	loss 3.4342 (2.8690)	grad_norm 10.8403 (9.1616)	mem 8929MB
[2022-04-09 15:20:03 large] (main.py 226): INFO Train: [262/300][500/2502]	eta 0:17:43 lr 0.000024	time 0.5479 (0.5312)	loss 2.6978 (2.8777)	grad_norm 9.2776 (9.1952)	mem 8929MB
[2022-04-09 15:20:56 large] (main.py 226): INFO Train: [262/300][600/2502]	eta 0:16:50 lr 0.000024	time 0.5295 (0.5312)	loss 2.9773 (2.8692)	grad_norm 11.9674 (9.0114)	mem 8929MB
[2022-04-09 15:21:51 large] (main.py 226): INFO Train: [262/300][700/2502]	eta 0:15:59 lr 0.000024	time 0.5349 (0.5327)	loss 1.6696 (2.8574)	grad_norm 6.4589 (8.9574)	mem 8929MB
[2022-04-09 15:22:43 large] (main.py 226): INFO Train: [262/300][800/2502]	eta 0:15:05 lr 0.000024	time 0.5258 (0.5320)	loss 2.4332 (2.8538)	grad_norm 7.6211 (8.9951)	mem 8929MB
[2022-04-09 15:23:37 large] (main.py 226): INFO Train: [262/300][900/2502]	eta 0:14:12 lr 0.000024	time 0.5682 (0.5323)	loss 2.9448 (2.8532)	grad_norm 7.9299 (8.9431)	mem 8929MB
[2022-04-09 15:24:29 large] (main.py 226): INFO Train: [262/300][1000/2502]	eta 0:13:18 lr 0.000024	time 0.5114 (0.5317)	loss 2.7743 (2.8484)	grad_norm 7.5504 (8.9809)	mem 8929MB
[2022-04-09 15:25:21 large] (main.py 226): INFO Train: [262/300][1100/2502]	eta 0:12:22 lr 0.000024	time 0.4988 (0.5298)	loss 1.9219 (2.8487)	grad_norm 6.9536 (8.9873)	mem 8929MB
[2022-04-09 15:26:11 large] (main.py 226): INFO Train: [262/300][1200/2502]	eta 0:11:26 lr 0.000024	time 0.5491 (0.5274)	loss 2.7423 (2.8473)	grad_norm 7.3756 (8.9603)	mem 8929MB
[2022-04-09 15:27:03 large] (main.py 226): INFO Train: [262/300][1300/2502]	eta 0:10:33 lr 0.000024	time 0.5211 (0.5272)	loss 2.0231 (2.8466)	grad_norm 10.8433 (8.9879)	mem 8929MB
[2022-04-09 15:27:56 large] (main.py 226): INFO Train: [262/300][1400/2502]	eta 0:09:40 lr 0.000024	time 0.4614 (0.5271)	loss 2.6763 (2.8500)	grad_norm 6.1016 (9.0065)	mem 8929MB
[2022-04-09 15:28:49 large] (main.py 226): INFO Train: [262/300][1500/2502]	eta 0:08:48 lr 0.000024	time 0.5000 (0.5273)	loss 3.0368 (2.8474)	grad_norm 6.3550 (9.0050)	mem 8929MB
[2022-04-09 15:29:40 large] (main.py 226): INFO Train: [262/300][1600/2502]	eta 0:07:54 lr 0.000024	time 0.4881 (0.5264)	loss 3.2731 (2.8490)	grad_norm 7.1614 (8.9994)	mem 8929MB
[2022-04-09 15:30:30 large] (main.py 226): INFO Train: [262/300][1700/2502]	eta 0:07:00 lr 0.000024	time 0.4939 (0.5246)	loss 2.7682 (2.8480)	grad_norm 9.6388 (9.0151)	mem 8929MB
[2022-04-09 15:31:22 large] (main.py 226): INFO Train: [262/300][1800/2502]	eta 0:06:08 lr 0.000024	time 0.5302 (0.5248)	loss 2.2109 (2.8498)	grad_norm 9.0084 (9.0012)	mem 8929MB
[2022-04-09 15:32:15 large] (main.py 226): INFO Train: [262/300][1900/2502]	eta 0:05:15 lr 0.000024	time 0.5356 (0.5249)	loss 2.5307 (2.8494)	grad_norm 7.5003 (8.9577)	mem 8929MB
[2022-04-09 15:33:08 large] (main.py 226): INFO Train: [262/300][2000/2502]	eta 0:04:23 lr 0.000024	time 0.5296 (0.5253)	loss 2.9631 (2.8470)	grad_norm 10.4870 (8.9794)	mem 8929MB
[2022-04-09 15:33:58 large] (main.py 226): INFO Train: [262/300][2100/2502]	eta 0:03:30 lr 0.000024	time 0.4665 (0.5238)	loss 2.9549 (2.8444)	grad_norm 6.3326 (8.9866)	mem 8929MB
[2022-04-09 15:34:48 large] (main.py 226): INFO Train: [262/300][2200/2502]	eta 0:02:37 lr 0.000023	time 0.4926 (0.5229)	loss 3.1915 (2.8443)	grad_norm 7.0501 (8.9699)	mem 8929MB
[2022-04-09 15:35:39 large] (main.py 226): INFO Train: [262/300][2300/2502]	eta 0:01:45 lr 0.000023	time 0.5130 (0.5222)	loss 2.9930 (2.8423)	grad_norm 7.1030 (8.9872)	mem 8929MB
[2022-04-09 15:36:32 large] (main.py 226): INFO Train: [262/300][2400/2502]	eta 0:00:53 lr 0.000023	time 0.5247 (0.5225)	loss 1.9563 (2.8429)	grad_norm 11.4356 (8.9923)	mem 8929MB
[2022-04-09 15:37:24 large] (main.py 226): INFO Train: [262/300][2500/2502]	eta 0:00:01 lr 0.000023	time 0.5018 (0.5227)	loss 3.0435 (2.8405)	grad_norm 13.5570 (9.0313)	mem 8929MB
[2022-04-09 15:37:25 large] (main.py 233): INFO EPOCH 262 training takes 0:21:48
[2022-04-09 15:37:32 large] (main.py 273): INFO Test: [0/98]	Time 6.247 (6.247)	Loss 1.0506 (1.0506)	Acc@1 81.055 (81.055)	Acc@5 95.703 (95.703)	Mem 8929MB
[2022-04-09 15:37:58 large] (main.py 279): INFO  * Acc@1 81.580 Acc@5 95.500
[2022-04-09 15:37:58 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.6%
[2022-04-09 15:37:58 large] (utils.py 57): INFO output/large/default/ckpt_epoch_262.pth saving......
[2022-04-09 15:37:59 large] (utils.py 59): INFO output/large/default/ckpt_epoch_262.pth saved !!!
[2022-04-09 15:37:59 large] (main.py 148): INFO Max accuracy: 81.58%
[2022-04-09 15:38:07 large] (main.py 226): INFO Train: [263/300][0/2502]	eta 5:35:41 lr 0.000023	time 8.0502 (8.0502)	loss 2.9890 (2.9890)	grad_norm 6.4179 (6.4179)	mem 8929MB
[2022-04-09 15:38:57 large] (main.py 226): INFO Train: [263/300][100/2502]	eta 0:23:15 lr 0.000023	time 0.4989 (0.5809)	loss 3.3081 (2.8840)	grad_norm 12.0750 (8.8549)	mem 8929MB
[2022-04-09 15:39:51 large] (main.py 226): INFO Train: [263/300][200/2502]	eta 0:21:22 lr 0.000023	time 0.5506 (0.5570)	loss 3.3530 (2.8441)	grad_norm 9.1338 (8.9278)	mem 8929MB
[2022-04-09 15:40:44 large] (main.py 226): INFO Train: [263/300][300/2502]	eta 0:20:07 lr 0.000023	time 0.4969 (0.5482)	loss 2.6978 (2.8483)	grad_norm 8.2580 (nan)	mem 8929MB
[2022-04-09 15:41:36 large] (main.py 226): INFO Train: [263/300][400/2502]	eta 0:18:58 lr 0.000023	time 0.4849 (0.5415)	loss 2.4492 (2.8651)	grad_norm 7.8356 (nan)	mem 8929MB
[2022-04-09 15:42:26 large] (main.py 226): INFO Train: [263/300][500/2502]	eta 0:17:46 lr 0.000023	time 0.4986 (0.5327)	loss 2.7219 (2.8756)	grad_norm 8.4599 (nan)	mem 8929MB
[2022-04-09 15:43:15 large] (main.py 226): INFO Train: [263/300][600/2502]	eta 0:16:41 lr 0.000023	time 0.5383 (0.5266)	loss 2.4540 (2.8632)	grad_norm 7.8571 (nan)	mem 8929MB
[2022-04-09 15:44:06 large] (main.py 226): INFO Train: [263/300][700/2502]	eta 0:15:43 lr 0.000023	time 0.5335 (0.5237)	loss 2.1656 (2.8526)	grad_norm 7.8225 (nan)	mem 8929MB
[2022-04-09 15:44:59 large] (main.py 226): INFO Train: [263/300][800/2502]	eta 0:14:53 lr 0.000023	time 0.5182 (0.5250)	loss 1.9084 (2.8490)	grad_norm 14.6452 (nan)	mem 8929MB
[2022-04-09 15:45:54 large] (main.py 226): INFO Train: [263/300][900/2502]	eta 0:14:05 lr 0.000023	time 0.5717 (0.5277)	loss 2.6250 (2.8393)	grad_norm 7.3967 (nan)	mem 8929MB
[2022-04-09 15:46:48 large] (main.py 226): INFO Train: [263/300][1000/2502]	eta 0:13:13 lr 0.000023	time 0.5282 (0.5284)	loss 3.0234 (2.8421)	grad_norm 7.8879 (nan)	mem 8929MB
[2022-04-09 15:47:41 large] (main.py 226): INFO Train: [263/300][1100/2502]	eta 0:12:21 lr 0.000023	time 0.5152 (0.5289)	loss 2.5765 (2.8403)	grad_norm 7.4993 (nan)	mem 8929MB
[2022-04-09 15:48:34 large] (main.py 226): INFO Train: [263/300][1200/2502]	eta 0:11:29 lr 0.000023	time 0.5210 (0.5292)	loss 2.0623 (2.8362)	grad_norm 6.0841 (nan)	mem 8929MB
[2022-04-09 15:49:27 large] (main.py 226): INFO Train: [263/300][1300/2502]	eta 0:10:35 lr 0.000023	time 0.5673 (0.5290)	loss 2.5758 (2.8355)	grad_norm 8.4682 (nan)	mem 8929MB
[2022-04-09 15:50:20 large] (main.py 226): INFO Train: [263/300][1400/2502]	eta 0:09:42 lr 0.000023	time 0.5320 (0.5289)	loss 3.2698 (2.8351)	grad_norm 8.2818 (nan)	mem 8929MB
[2022-04-09 15:51:12 large] (main.py 226): INFO Train: [263/300][1500/2502]	eta 0:08:49 lr 0.000023	time 0.5290 (0.5287)	loss 2.3213 (2.8427)	grad_norm 6.9430 (nan)	mem 8929MB
[2022-04-09 15:52:04 large] (main.py 226): INFO Train: [263/300][1600/2502]	eta 0:07:56 lr 0.000023	time 0.4979 (0.5281)	loss 2.4004 (2.8373)	grad_norm 6.6474 (nan)	mem 8929MB
[2022-04-09 15:52:55 large] (main.py 226): INFO Train: [263/300][1700/2502]	eta 0:07:02 lr 0.000023	time 0.5187 (0.5271)	loss 2.8125 (2.8371)	grad_norm 6.7498 (nan)	mem 8929MB
[2022-04-09 15:53:46 large] (main.py 226): INFO Train: [263/300][1800/2502]	eta 0:06:09 lr 0.000023	time 0.5165 (0.5258)	loss 3.1502 (2.8386)	grad_norm 8.5588 (nan)	mem 8929MB
[2022-04-09 15:54:38 large] (main.py 226): INFO Train: [263/300][1900/2502]	eta 0:05:16 lr 0.000023	time 0.5198 (0.5259)	loss 3.1686 (2.8439)	grad_norm 10.1562 (nan)	mem 8929MB
[2022-04-09 15:55:31 large] (main.py 226): INFO Train: [263/300][2000/2502]	eta 0:04:24 lr 0.000023	time 0.5145 (0.5261)	loss 3.1565 (2.8433)	grad_norm 7.4135 (nan)	mem 8929MB
[2022-04-09 15:56:25 large] (main.py 226): INFO Train: [263/300][2100/2502]	eta 0:03:31 lr 0.000023	time 0.4605 (0.5265)	loss 1.9489 (2.8406)	grad_norm 9.4016 (nan)	mem 8929MB
[2022-04-09 15:57:18 large] (main.py 226): INFO Train: [263/300][2200/2502]	eta 0:02:39 lr 0.000022	time 0.5083 (0.5266)	loss 2.7735 (2.8401)	grad_norm 5.6228 (nan)	mem 8929MB
[2022-04-09 15:58:11 large] (main.py 226): INFO Train: [263/300][2300/2502]	eta 0:01:46 lr 0.000022	time 0.5708 (0.5269)	loss 3.2545 (2.8402)	grad_norm 9.6041 (nan)	mem 8929MB
[2022-04-09 15:59:04 large] (main.py 226): INFO Train: [263/300][2400/2502]	eta 0:00:53 lr 0.000022	time 0.5235 (0.5269)	loss 1.9761 (2.8399)	grad_norm 13.1299 (nan)	mem 8929MB
[2022-04-09 15:59:56 large] (main.py 226): INFO Train: [263/300][2500/2502]	eta 0:00:01 lr 0.000022	time 0.5330 (0.5267)	loss 3.0510 (2.8395)	grad_norm 6.1596 (nan)	mem 8929MB
[2022-04-09 15:59:57 large] (main.py 233): INFO EPOCH 263 training takes 0:21:58
[2022-04-09 16:00:03 large] (main.py 273): INFO Test: [0/98]	Time 5.571 (5.571)	Loss 1.0506 (1.0506)	Acc@1 79.297 (79.297)	Acc@5 94.922 (94.922)	Mem 8929MB
[2022-04-09 16:00:30 large] (main.py 279): INFO  * Acc@1 81.556 Acc@5 95.542
[2022-04-09 16:00:30 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.6%
[2022-04-09 16:00:30 large] (main.py 148): INFO Max accuracy: 81.58%
[2022-04-09 16:00:37 large] (main.py 226): INFO Train: [264/300][0/2502]	eta 4:58:14 lr 0.000022	time 7.1523 (7.1523)	loss 1.7476 (1.7476)	grad_norm 7.6788 (7.6788)	mem 8929MB
[2022-04-09 16:01:28 large] (main.py 226): INFO Train: [264/300][100/2502]	eta 0:23:14 lr 0.000022	time 0.5309 (0.5805)	loss 3.4235 (2.8343)	grad_norm 10.2708 (8.6112)	mem 8929MB
[2022-04-09 16:02:20 large] (main.py 226): INFO Train: [264/300][200/2502]	eta 0:20:58 lr 0.000022	time 0.4901 (0.5466)	loss 2.9721 (2.8542)	grad_norm 7.4566 (8.5931)	mem 8929MB
[2022-04-09 16:03:12 large] (main.py 226): INFO Train: [264/300][300/2502]	eta 0:19:47 lr 0.000022	time 0.5062 (0.5395)	loss 3.1161 (2.8499)	grad_norm 7.3159 (8.7310)	mem 8929MB
[2022-04-09 16:04:06 large] (main.py 226): INFO Train: [264/300][400/2502]	eta 0:18:54 lr 0.000022	time 0.5051 (0.5398)	loss 2.7004 (2.8460)	grad_norm 6.6912 (8.9745)	mem 8929MB
[2022-04-09 16:04:59 large] (main.py 226): INFO Train: [264/300][500/2502]	eta 0:17:57 lr 0.000022	time 0.5317 (0.5383)	loss 1.8691 (2.8454)	grad_norm 9.1255 (9.0265)	mem 8929MB
[2022-04-09 16:05:53 large] (main.py 226): INFO Train: [264/300][600/2502]	eta 0:17:03 lr 0.000022	time 0.5055 (0.5379)	loss 3.0768 (2.8285)	grad_norm 7.2001 (nan)	mem 8929MB
[2022-04-09 16:06:44 large] (main.py 226): INFO Train: [264/300][700/2502]	eta 0:16:01 lr 0.000022	time 0.5269 (0.5334)	loss 2.4730 (2.8312)	grad_norm 8.8956 (nan)	mem 8929MB
[2022-04-09 16:07:37 large] (main.py 226): INFO Train: [264/300][800/2502]	eta 0:15:07 lr 0.000022	time 0.4772 (0.5335)	loss 2.7002 (2.8439)	grad_norm 19.8513 (nan)	mem 8929MB
[2022-04-09 16:08:27 large] (main.py 226): INFO Train: [264/300][900/2502]	eta 0:14:07 lr 0.000022	time 0.4762 (0.5292)	loss 3.2839 (2.8515)	grad_norm 6.9879 (nan)	mem 8929MB
[2022-04-09 16:09:17 large] (main.py 226): INFO Train: [264/300][1000/2502]	eta 0:13:10 lr 0.000022	time 0.5620 (0.5266)	loss 1.9372 (2.8429)	grad_norm 9.2702 (nan)	mem 8929MB
[2022-04-09 16:10:07 large] (main.py 226): INFO Train: [264/300][1100/2502]	eta 0:12:15 lr 0.000022	time 0.5122 (0.5244)	loss 3.1425 (2.8502)	grad_norm 7.1405 (nan)	mem 8929MB
[2022-04-09 16:10:59 large] (main.py 226): INFO Train: [264/300][1200/2502]	eta 0:11:22 lr 0.000022	time 0.5244 (0.5239)	loss 3.3589 (2.8484)	grad_norm 10.7548 (nan)	mem 8929MB
[2022-04-09 16:11:49 large] (main.py 226): INFO Train: [264/300][1300/2502]	eta 0:10:27 lr 0.000022	time 0.5095 (0.5222)	loss 3.1782 (2.8493)	grad_norm 7.4787 (nan)	mem 8929MB
[2022-04-09 16:12:40 large] (main.py 226): INFO Train: [264/300][1400/2502]	eta 0:09:34 lr 0.000022	time 0.5034 (0.5211)	loss 3.1884 (2.8500)	grad_norm 7.9967 (nan)	mem 8929MB
[2022-04-09 16:13:33 large] (main.py 226): INFO Train: [264/300][1500/2502]	eta 0:08:43 lr 0.000022	time 0.5341 (0.5221)	loss 3.3490 (2.8478)	grad_norm 9.8105 (nan)	mem 8929MB
[2022-04-09 16:14:27 large] (main.py 226): INFO Train: [264/300][1600/2502]	eta 0:07:51 lr 0.000022	time 0.5029 (0.5229)	loss 2.1532 (2.8441)	grad_norm 7.1151 (nan)	mem 8929MB
[2022-04-09 16:15:16 large] (main.py 226): INFO Train: [264/300][1700/2502]	eta 0:06:57 lr 0.000022	time 0.4865 (0.5208)	loss 1.7601 (2.8423)	grad_norm 11.6548 (nan)	mem 8929MB
[2022-04-09 16:16:08 large] (main.py 226): INFO Train: [264/300][1800/2502]	eta 0:06:05 lr 0.000022	time 0.5260 (0.5209)	loss 2.2920 (2.8418)	grad_norm 8.2518 (nan)	mem 8929MB
[2022-04-09 16:17:02 large] (main.py 226): INFO Train: [264/300][1900/2502]	eta 0:05:14 lr 0.000022	time 0.5068 (0.5219)	loss 2.7672 (2.8428)	grad_norm 8.9392 (nan)	mem 8929MB
[2022-04-09 16:17:56 large] (main.py 226): INFO Train: [264/300][2000/2502]	eta 0:04:22 lr 0.000022	time 0.5201 (0.5227)	loss 3.4798 (2.8405)	grad_norm 9.9894 (nan)	mem 8929MB
[2022-04-09 16:18:49 large] (main.py 226): INFO Train: [264/300][2100/2502]	eta 0:03:30 lr 0.000022	time 0.5206 (0.5234)	loss 2.2133 (2.8391)	grad_norm 7.2059 (nan)	mem 8929MB
[2022-04-09 16:19:43 large] (main.py 226): INFO Train: [264/300][2200/2502]	eta 0:02:38 lr 0.000022	time 0.6289 (0.5240)	loss 2.8767 (2.8367)	grad_norm 9.3181 (nan)	mem 8929MB
[2022-04-09 16:20:37 large] (main.py 226): INFO Train: [264/300][2300/2502]	eta 0:01:45 lr 0.000022	time 0.4995 (0.5247)	loss 1.8296 (2.8361)	grad_norm 7.2545 (nan)	mem 8929MB
[2022-04-09 16:21:28 large] (main.py 226): INFO Train: [264/300][2400/2502]	eta 0:00:53 lr 0.000021	time 0.4853 (0.5240)	loss 3.0109 (2.8359)	grad_norm 7.8774 (nan)	mem 8929MB
[2022-04-09 16:22:17 large] (main.py 226): INFO Train: [264/300][2500/2502]	eta 0:00:01 lr 0.000021	time 0.4803 (0.5226)	loss 2.2099 (2.8346)	grad_norm 7.8899 (nan)	mem 8929MB
[2022-04-09 16:22:18 large] (main.py 233): INFO EPOCH 264 training takes 0:21:47
[2022-04-09 16:22:24 large] (main.py 273): INFO Test: [0/98]	Time 6.247 (6.247)	Loss 1.0748 (1.0748)	Acc@1 79.492 (79.492)	Acc@5 94.727 (94.727)	Mem 8929MB
[2022-04-09 16:22:50 large] (main.py 279): INFO  * Acc@1 81.514 Acc@5 95.518
[2022-04-09 16:22:50 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.5%
[2022-04-09 16:22:50 large] (main.py 148): INFO Max accuracy: 81.58%
[2022-04-09 16:22:57 large] (main.py 226): INFO Train: [265/300][0/2502]	eta 4:40:04 lr 0.000021	time 6.7166 (6.7166)	loss 3.0364 (3.0364)	grad_norm 6.8694 (6.8694)	mem 8929MB
[2022-04-09 16:23:50 large] (main.py 226): INFO Train: [265/300][100/2502]	eta 0:23:41 lr 0.000021	time 0.4752 (0.5919)	loss 2.2372 (2.8368)	grad_norm 8.0703 (8.7541)	mem 8929MB
[2022-04-09 16:24:39 large] (main.py 226): INFO Train: [265/300][200/2502]	eta 0:20:52 lr 0.000021	time 0.5266 (0.5442)	loss 2.3916 (2.8195)	grad_norm 11.0112 (8.9883)	mem 8929MB
[2022-04-09 16:25:30 large] (main.py 226): INFO Train: [265/300][300/2502]	eta 0:19:28 lr 0.000021	time 0.5481 (0.5304)	loss 3.1178 (2.8126)	grad_norm 7.7516 (9.0512)	mem 8929MB
[2022-04-09 16:26:23 large] (main.py 226): INFO Train: [265/300][400/2502]	eta 0:18:36 lr 0.000021	time 0.5377 (0.5312)	loss 3.0687 (2.8288)	grad_norm 7.8610 (9.3082)	mem 8929MB
[2022-04-09 16:27:18 large] (main.py 226): INFO Train: [265/300][500/2502]	eta 0:17:50 lr 0.000021	time 0.5782 (0.5346)	loss 1.9946 (2.8278)	grad_norm 9.2241 (9.2187)	mem 8929MB
[2022-04-09 16:28:10 large] (main.py 226): INFO Train: [265/300][600/2502]	eta 0:16:51 lr 0.000021	time 0.4689 (0.5320)	loss 2.6578 (2.8363)	grad_norm 5.2058 (9.1040)	mem 8929MB
[2022-04-09 16:29:02 large] (main.py 226): INFO Train: [265/300][700/2502]	eta 0:15:55 lr 0.000021	time 0.5372 (0.5305)	loss 3.2183 (2.8417)	grad_norm 6.6734 (9.1452)	mem 8929MB
[2022-04-09 16:29:55 large] (main.py 226): INFO Train: [265/300][800/2502]	eta 0:15:04 lr 0.000021	time 0.5530 (0.5312)	loss 2.3098 (2.8439)	grad_norm 7.5125 (9.2133)	mem 8929MB
[2022-04-09 16:30:49 large] (main.py 226): INFO Train: [265/300][900/2502]	eta 0:14:12 lr 0.000021	time 0.5151 (0.5321)	loss 3.1980 (2.8471)	grad_norm 15.8491 (9.2410)	mem 8929MB
[2022-04-09 16:31:43 large] (main.py 226): INFO Train: [265/300][1000/2502]	eta 0:13:19 lr 0.000021	time 0.5100 (0.5322)	loss 2.8468 (2.8384)	grad_norm 7.7588 (9.2739)	mem 8929MB
[2022-04-09 16:32:35 large] (main.py 226): INFO Train: [265/300][1100/2502]	eta 0:12:25 lr 0.000021	time 0.5317 (0.5316)	loss 3.0975 (2.8393)	grad_norm 7.5673 (9.2548)	mem 8929MB
[2022-04-09 16:33:25 large] (main.py 226): INFO Train: [265/300][1200/2502]	eta 0:11:28 lr 0.000021	time 0.5040 (0.5288)	loss 3.6041 (2.8381)	grad_norm 10.2727 (9.2684)	mem 8929MB
[2022-04-09 16:34:14 large] (main.py 226): INFO Train: [265/300][1300/2502]	eta 0:10:31 lr 0.000021	time 0.4742 (0.5255)	loss 2.9856 (2.8498)	grad_norm 9.5925 (9.2625)	mem 8929MB
[2022-04-09 16:35:03 large] (main.py 226): INFO Train: [265/300][1400/2502]	eta 0:09:36 lr 0.000021	time 0.4724 (0.5230)	loss 3.3074 (2.8546)	grad_norm 12.6239 (9.2338)	mem 8929MB
[2022-04-09 16:35:54 large] (main.py 226): INFO Train: [265/300][1500/2502]	eta 0:08:43 lr 0.000021	time 0.6013 (0.5226)	loss 3.0399 (2.8581)	grad_norm 9.5987 (nan)	mem 8929MB
[2022-04-09 16:36:49 large] (main.py 226): INFO Train: [265/300][1600/2502]	eta 0:07:52 lr 0.000021	time 0.5487 (0.5239)	loss 2.7722 (2.8530)	grad_norm 8.3037 (nan)	mem 8929MB
[2022-04-09 16:37:42 large] (main.py 226): INFO Train: [265/300][1700/2502]	eta 0:07:00 lr 0.000021	time 0.5371 (0.5247)	loss 3.0248 (2.8524)	grad_norm 9.0051 (nan)	mem 8929MB
[2022-04-09 16:38:37 large] (main.py 226): INFO Train: [265/300][1800/2502]	eta 0:06:09 lr 0.000021	time 0.5105 (0.5258)	loss 1.9014 (2.8553)	grad_norm 7.3243 (nan)	mem 8929MB
[2022-04-09 16:39:28 large] (main.py 226): INFO Train: [265/300][1900/2502]	eta 0:05:15 lr 0.000021	time 0.5007 (0.5249)	loss 3.1908 (2.8521)	grad_norm 11.7218 (nan)	mem 8929MB
[2022-04-09 16:40:20 large] (main.py 226): INFO Train: [265/300][2000/2502]	eta 0:04:23 lr 0.000021	time 0.4854 (0.5249)	loss 2.9379 (2.8494)	grad_norm 7.6316 (nan)	mem 8929MB
[2022-04-09 16:41:13 large] (main.py 226): INFO Train: [265/300][2100/2502]	eta 0:03:31 lr 0.000021	time 0.5201 (0.5250)	loss 2.0160 (2.8481)	grad_norm 34.1802 (nan)	mem 8929MB
[2022-04-09 16:42:06 large] (main.py 226): INFO Train: [265/300][2200/2502]	eta 0:02:38 lr 0.000021	time 0.6283 (0.5253)	loss 2.8487 (2.8450)	grad_norm 6.3059 (nan)	mem 8929MB
[2022-04-09 16:42:58 large] (main.py 226): INFO Train: [265/300][2300/2502]	eta 0:01:46 lr 0.000021	time 0.4769 (0.5252)	loss 2.3259 (2.8443)	grad_norm 8.7368 (nan)	mem 8929MB
[2022-04-09 16:43:50 large] (main.py 226): INFO Train: [265/300][2400/2502]	eta 0:00:53 lr 0.000021	time 0.4972 (0.5247)	loss 3.1088 (2.8454)	grad_norm 7.1352 (nan)	mem 8929MB
[2022-04-09 16:44:42 large] (main.py 226): INFO Train: [265/300][2500/2502]	eta 0:00:01 lr 0.000021	time 0.5063 (0.5247)	loss 2.3302 (2.8446)	grad_norm 8.4675 (nan)	mem 8929MB
[2022-04-09 16:44:43 large] (main.py 233): INFO EPOCH 265 training takes 0:21:53
[2022-04-09 16:44:50 large] (main.py 273): INFO Test: [0/98]	Time 6.545 (6.545)	Loss 1.0227 (1.0227)	Acc@1 80.078 (80.078)	Acc@5 95.898 (95.898)	Mem 8929MB
[2022-04-09 16:45:16 large] (main.py 279): INFO  * Acc@1 81.626 Acc@5 95.584
[2022-04-09 16:45:16 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.6%
[2022-04-09 16:45:16 large] (utils.py 57): INFO output/large/default/ckpt_epoch_265.pth saving......
[2022-04-09 16:45:17 large] (utils.py 59): INFO output/large/default/ckpt_epoch_265.pth saved !!!
[2022-04-09 16:45:17 large] (main.py 148): INFO Max accuracy: 81.63%
[2022-04-09 16:45:25 large] (main.py 226): INFO Train: [266/300][0/2502]	eta 5:40:44 lr 0.000021	time 8.1713 (8.1713)	loss 1.9491 (1.9491)	grad_norm 16.8067 (16.8067)	mem 8929MB
[2022-04-09 16:46:15 large] (main.py 226): INFO Train: [266/300][100/2502]	eta 0:23:15 lr 0.000020	time 0.5464 (0.5810)	loss 3.1697 (2.8420)	grad_norm 7.7796 (9.8844)	mem 8929MB
[2022-04-09 16:47:09 large] (main.py 226): INFO Train: [266/300][200/2502]	eta 0:21:22 lr 0.000020	time 0.5121 (0.5572)	loss 2.5096 (2.8328)	grad_norm 9.7797 (10.0421)	mem 8929MB
[2022-04-09 16:48:03 large] (main.py 226): INFO Train: [266/300][300/2502]	eta 0:20:17 lr 0.000020	time 0.5217 (0.5531)	loss 3.4793 (2.8351)	grad_norm 10.6482 (10.3329)	mem 8929MB
[2022-04-09 16:48:57 large] (main.py 226): INFO Train: [266/300][400/2502]	eta 0:19:12 lr 0.000020	time 0.4905 (0.5483)	loss 3.0887 (2.8651)	grad_norm 7.0230 (10.2388)	mem 8929MB
[2022-04-09 16:49:50 large] (main.py 226): INFO Train: [266/300][500/2502]	eta 0:18:12 lr 0.000020	time 0.5027 (0.5455)	loss 2.9985 (2.8555)	grad_norm 7.4401 (10.0095)	mem 8929MB
[2022-04-09 16:50:43 large] (main.py 226): INFO Train: [266/300][600/2502]	eta 0:17:13 lr 0.000020	time 0.5236 (0.5433)	loss 3.0469 (2.8553)	grad_norm 8.8316 (9.8078)	mem 8929MB
[2022-04-09 16:51:37 large] (main.py 226): INFO Train: [266/300][700/2502]	eta 0:16:17 lr 0.000020	time 0.5173 (0.5425)	loss 2.9308 (2.8545)	grad_norm 10.4387 (9.8095)	mem 8929MB
[2022-04-09 16:52:28 large] (main.py 226): INFO Train: [266/300][800/2502]	eta 0:15:16 lr 0.000020	time 0.5986 (0.5383)	loss 1.9875 (2.8390)	grad_norm 12.4900 (9.7399)	mem 8929MB
[2022-04-09 16:53:21 large] (main.py 226): INFO Train: [266/300][900/2502]	eta 0:14:20 lr 0.000020	time 0.5233 (0.5370)	loss 3.0323 (2.8358)	grad_norm 8.7094 (9.7559)	mem 8929MB
[2022-04-09 16:54:14 large] (main.py 226): INFO Train: [266/300][1000/2502]	eta 0:13:26 lr 0.000020	time 0.5932 (0.5368)	loss 3.1624 (2.8409)	grad_norm 8.6703 (9.7362)	mem 8929MB
[2022-04-09 16:55:07 large] (main.py 226): INFO Train: [266/300][1100/2502]	eta 0:12:31 lr 0.000020	time 0.5397 (0.5360)	loss 3.0253 (2.8470)	grad_norm 5.5523 (9.7328)	mem 8929MB
[2022-04-09 16:56:00 large] (main.py 226): INFO Train: [266/300][1200/2502]	eta 0:11:37 lr 0.000020	time 0.4901 (0.5353)	loss 2.9266 (2.8468)	grad_norm 7.2429 (9.6487)	mem 8929MB
[2022-04-09 16:56:49 large] (main.py 226): INFO Train: [266/300][1300/2502]	eta 0:10:39 lr 0.000020	time 0.5410 (0.5317)	loss 2.4939 (2.8426)	grad_norm 7.4975 (9.6601)	mem 8929MB
[2022-04-09 16:57:37 large] (main.py 226): INFO Train: [266/300][1400/2502]	eta 0:09:42 lr 0.000020	time 0.4833 (0.5283)	loss 3.1529 (2.8471)	grad_norm 5.8017 (9.5836)	mem 8929MB
[2022-04-09 16:58:29 large] (main.py 226): INFO Train: [266/300][1500/2502]	eta 0:08:48 lr 0.000020	time 0.5604 (0.5277)	loss 3.4512 (2.8512)	grad_norm 12.3393 (9.6514)	mem 8929MB
[2022-04-09 16:59:23 large] (main.py 226): INFO Train: [266/300][1600/2502]	eta 0:07:56 lr 0.000020	time 0.5203 (0.5285)	loss 2.4996 (2.8480)	grad_norm 10.7977 (9.6253)	mem 8929MB
[2022-04-09 17:00:17 large] (main.py 226): INFO Train: [266/300][1700/2502]	eta 0:07:04 lr 0.000020	time 0.5176 (0.5295)	loss 2.7057 (2.8428)	grad_norm 10.5135 (9.6347)	mem 8929MB
[2022-04-09 17:01:11 large] (main.py 226): INFO Train: [266/300][1800/2502]	eta 0:06:11 lr 0.000020	time 0.5096 (0.5299)	loss 3.3205 (2.8423)	grad_norm 13.0979 (9.5775)	mem 8929MB
[2022-04-09 17:02:05 large] (main.py 226): INFO Train: [266/300][1900/2502]	eta 0:05:19 lr 0.000020	time 0.6382 (0.5305)	loss 3.2471 (2.8415)	grad_norm 9.7232 (9.5405)	mem 8929MB
[2022-04-09 17:02:59 large] (main.py 226): INFO Train: [266/300][2000/2502]	eta 0:04:26 lr 0.000020	time 0.5061 (0.5309)	loss 2.3954 (2.8439)	grad_norm 8.5874 (9.5647)	mem 8929MB
[2022-04-09 17:03:54 large] (main.py 226): INFO Train: [266/300][2100/2502]	eta 0:03:33 lr 0.000020	time 0.5464 (0.5316)	loss 2.9387 (2.8438)	grad_norm 8.0635 (9.5258)	mem 8929MB
[2022-04-09 17:04:45 large] (main.py 226): INFO Train: [266/300][2200/2502]	eta 0:02:40 lr 0.000020	time 0.4945 (0.5309)	loss 2.9831 (2.8402)	grad_norm 8.0503 (9.5296)	mem 8929MB
[2022-04-09 17:05:35 large] (main.py 226): INFO Train: [266/300][2300/2502]	eta 0:01:46 lr 0.000020	time 0.5111 (0.5295)	loss 3.1401 (2.8422)	grad_norm 7.7642 (9.4938)	mem 8929MB
[2022-04-09 17:06:28 large] (main.py 226): INFO Train: [266/300][2400/2502]	eta 0:00:54 lr 0.000020	time 0.5471 (0.5296)	loss 2.4380 (2.8366)	grad_norm 9.4260 (9.4566)	mem 8929MB
[2022-04-09 17:07:22 large] (main.py 226): INFO Train: [266/300][2500/2502]	eta 0:00:01 lr 0.000020	time 0.5355 (0.5299)	loss 2.8817 (2.8370)	grad_norm 7.1205 (9.4655)	mem 8929MB
[2022-04-09 17:07:23 large] (main.py 233): INFO EPOCH 266 training takes 0:22:06
[2022-04-09 17:07:30 large] (main.py 273): INFO Test: [0/98]	Time 6.415 (6.415)	Loss 1.0294 (1.0294)	Acc@1 79.297 (79.297)	Acc@5 94.922 (94.922)	Mem 8929MB
[2022-04-09 17:07:56 large] (main.py 279): INFO  * Acc@1 81.640 Acc@5 95.524
[2022-04-09 17:07:56 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.6%
[2022-04-09 17:07:56 large] (utils.py 57): INFO output/large/default/ckpt_epoch_266.pth saving......
[2022-04-09 17:07:57 large] (utils.py 59): INFO output/large/default/ckpt_epoch_266.pth saved !!!
[2022-04-09 17:07:57 large] (main.py 148): INFO Max accuracy: 81.64%
[2022-04-09 17:08:04 large] (main.py 226): INFO Train: [267/300][0/2502]	eta 5:17:14 lr 0.000020	time 7.6079 (7.6079)	loss 2.0018 (2.0018)	grad_norm 10.8562 (10.8562)	mem 8929MB
[2022-04-09 17:08:56 large] (main.py 226): INFO Train: [267/300][100/2502]	eta 0:23:38 lr 0.000020	time 0.4958 (0.5905)	loss 1.8489 (2.8146)	grad_norm 12.8605 (9.7899)	mem 8929MB
[2022-04-09 17:09:50 large] (main.py 226): INFO Train: [267/300][200/2502]	eta 0:21:37 lr 0.000020	time 0.5543 (0.5636)	loss 2.3216 (2.8213)	grad_norm 7.6679 (9.3226)	mem 8929MB
[2022-04-09 17:10:44 large] (main.py 226): INFO Train: [267/300][300/2502]	eta 0:20:25 lr 0.000020	time 0.6357 (0.5564)	loss 2.7254 (2.8478)	grad_norm 6.8663 (9.5855)	mem 8929MB
[2022-04-09 17:11:38 large] (main.py 226): INFO Train: [267/300][400/2502]	eta 0:19:21 lr 0.000019	time 0.5432 (0.5524)	loss 2.9817 (2.8583)	grad_norm 8.3301 (9.4456)	mem 8929MB
[2022-04-09 17:12:27 large] (main.py 226): INFO Train: [267/300][500/2502]	eta 0:18:00 lr 0.000019	time 0.4890 (0.5400)	loss 2.5584 (2.8574)	grad_norm 6.6202 (9.2942)	mem 8929MB
[2022-04-09 17:13:16 large] (main.py 226): INFO Train: [267/300][600/2502]	eta 0:16:51 lr 0.000019	time 0.5056 (0.5318)	loss 2.8052 (2.8598)	grad_norm 7.5236 (9.2561)	mem 8929MB
[2022-04-09 17:14:10 large] (main.py 226): INFO Train: [267/300][700/2502]	eta 0:15:59 lr 0.000019	time 0.5204 (0.5325)	loss 3.2096 (2.8577)	grad_norm 9.2060 (9.3269)	mem 8929MB
[2022-04-09 17:15:04 large] (main.py 226): INFO Train: [267/300][800/2502]	eta 0:15:08 lr 0.000019	time 0.6071 (0.5340)	loss 3.3052 (2.8526)	grad_norm 9.1548 (nan)	mem 8929MB
[2022-04-09 17:15:58 large] (main.py 226): INFO Train: [267/300][900/2502]	eta 0:14:16 lr 0.000019	time 0.5897 (0.5347)	loss 3.2906 (2.8495)	grad_norm 7.6641 (nan)	mem 8929MB
[2022-04-09 17:16:53 large] (main.py 226): INFO Train: [267/300][1000/2502]	eta 0:13:24 lr 0.000019	time 0.5316 (0.5356)	loss 1.8586 (2.8408)	grad_norm 7.4028 (nan)	mem 8929MB
[2022-04-09 17:17:48 large] (main.py 226): INFO Train: [267/300][1100/2502]	eta 0:12:32 lr 0.000019	time 0.5049 (0.5369)	loss 2.6639 (2.8395)	grad_norm 7.9170 (nan)	mem 8929MB
[2022-04-09 17:18:40 large] (main.py 226): INFO Train: [267/300][1200/2502]	eta 0:11:37 lr 0.000019	time 0.4719 (0.5355)	loss 2.7397 (2.8434)	grad_norm 16.0873 (nan)	mem 8929MB
[2022-04-09 17:19:30 large] (main.py 226): INFO Train: [267/300][1300/2502]	eta 0:10:40 lr 0.000019	time 0.4993 (0.5327)	loss 1.8699 (2.8412)	grad_norm 6.8319 (nan)	mem 8929MB
[2022-04-09 17:20:18 large] (main.py 226): INFO Train: [267/300][1400/2502]	eta 0:09:43 lr 0.000019	time 0.4963 (0.5293)	loss 3.4356 (2.8407)	grad_norm 8.4906 (nan)	mem 8929MB
[2022-04-09 17:21:10 large] (main.py 226): INFO Train: [267/300][1500/2502]	eta 0:08:49 lr 0.000019	time 0.5830 (0.5287)	loss 2.9778 (2.8402)	grad_norm 12.7786 (nan)	mem 8929MB
[2022-04-09 17:22:05 large] (main.py 226): INFO Train: [267/300][1600/2502]	eta 0:07:57 lr 0.000019	time 0.5722 (0.5298)	loss 3.1804 (2.8403)	grad_norm 6.6207 (nan)	mem 8929MB
[2022-04-09 17:23:00 large] (main.py 226): INFO Train: [267/300][1700/2502]	eta 0:07:05 lr 0.000019	time 0.6104 (0.5312)	loss 2.9158 (2.8403)	grad_norm 6.5440 (nan)	mem 8929MB
[2022-04-09 17:23:56 large] (main.py 226): INFO Train: [267/300][1800/2502]	eta 0:06:13 lr 0.000019	time 0.4630 (0.5325)	loss 3.1978 (2.8408)	grad_norm 7.8594 (nan)	mem 8929MB
[2022-04-09 17:24:49 large] (main.py 226): INFO Train: [267/300][1900/2502]	eta 0:05:20 lr 0.000019	time 0.5377 (0.5324)	loss 2.6601 (2.8412)	grad_norm 8.1242 (nan)	mem 8929MB
[2022-04-09 17:25:43 large] (main.py 226): INFO Train: [267/300][2000/2502]	eta 0:04:27 lr 0.000019	time 0.5096 (0.5328)	loss 1.7156 (2.8427)	grad_norm 7.7741 (nan)	mem 8929MB
[2022-04-09 17:26:36 large] (main.py 226): INFO Train: [267/300][2100/2502]	eta 0:03:34 lr 0.000019	time 0.4819 (0.5329)	loss 2.7238 (2.8461)	grad_norm 7.4859 (nan)	mem 8929MB
[2022-04-09 17:27:27 large] (main.py 226): INFO Train: [267/300][2200/2502]	eta 0:02:40 lr 0.000019	time 0.5769 (0.5318)	loss 2.0538 (2.8432)	grad_norm 5.8681 (nan)	mem 8929MB
[2022-04-09 17:28:21 large] (main.py 226): INFO Train: [267/300][2300/2502]	eta 0:01:47 lr 0.000019	time 0.5277 (0.5322)	loss 2.9516 (2.8432)	grad_norm 9.8542 (nan)	mem 8929MB
[2022-04-09 17:29:15 large] (main.py 226): INFO Train: [267/300][2400/2502]	eta 0:00:54 lr 0.000019	time 0.5623 (0.5322)	loss 2.8324 (2.8417)	grad_norm 11.3620 (nan)	mem 8929MB
[2022-04-09 17:30:05 large] (main.py 226): INFO Train: [267/300][2500/2502]	eta 0:00:01 lr 0.000019	time 0.4934 (0.5312)	loss 2.0022 (2.8432)	grad_norm 6.4552 (nan)	mem 8929MB
[2022-04-09 17:30:06 large] (main.py 233): INFO EPOCH 267 training takes 0:22:09
[2022-04-09 17:30:13 large] (main.py 273): INFO Test: [0/98]	Time 6.608 (6.608)	Loss 0.9427 (0.9427)	Acc@1 81.250 (81.250)	Acc@5 94.727 (94.727)	Mem 8929MB
[2022-04-09 17:30:39 large] (main.py 279): INFO  * Acc@1 81.444 Acc@5 95.512
[2022-04-09 17:30:39 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.4%
[2022-04-09 17:30:39 large] (main.py 148): INFO Max accuracy: 81.64%
[2022-04-09 17:30:46 large] (main.py 226): INFO Train: [268/300][0/2502]	eta 4:47:11 lr 0.000019	time 6.8869 (6.8869)	loss 2.0981 (2.0981)	grad_norm 7.2864 (7.2864)	mem 8929MB
[2022-04-09 17:31:39 large] (main.py 226): INFO Train: [268/300][100/2502]	eta 0:23:40 lr 0.000019	time 0.5339 (0.5915)	loss 1.8106 (2.8465)	grad_norm 11.2778 (9.8375)	mem 8929MB
[2022-04-09 17:32:33 large] (main.py 226): INFO Train: [268/300][200/2502]	eta 0:21:42 lr 0.000019	time 0.5263 (0.5658)	loss 2.7452 (2.8381)	grad_norm 6.6246 (9.6536)	mem 8929MB
[2022-04-09 17:33:27 large] (main.py 226): INFO Train: [268/300][300/2502]	eta 0:20:28 lr 0.000019	time 0.5376 (0.5580)	loss 3.3103 (2.8353)	grad_norm 7.3172 (9.5038)	mem 8929MB
[2022-04-09 17:34:21 large] (main.py 226): INFO Train: [268/300][400/2502]	eta 0:19:21 lr 0.000019	time 0.4856 (0.5528)	loss 3.2958 (2.8525)	grad_norm 9.6848 (9.5896)	mem 8929MB
[2022-04-09 17:35:12 large] (main.py 226): INFO Train: [268/300][500/2502]	eta 0:18:10 lr 0.000019	time 0.5100 (0.5447)	loss 2.3912 (2.8365)	grad_norm 7.4075 (9.6951)	mem 8929MB
[2022-04-09 17:36:06 large] (main.py 226): INFO Train: [268/300][600/2502]	eta 0:17:13 lr 0.000019	time 0.5345 (0.5436)	loss 2.9880 (2.8343)	grad_norm 8.2746 (9.5974)	mem 8929MB
[2022-04-09 17:37:00 large] (main.py 226): INFO Train: [268/300][700/2502]	eta 0:16:20 lr 0.000019	time 0.4967 (0.5443)	loss 3.1764 (2.8294)	grad_norm 9.7228 (9.5722)	mem 8929MB
[2022-04-09 17:37:54 large] (main.py 226): INFO Train: [268/300][800/2502]	eta 0:15:23 lr 0.000018	time 0.5174 (0.5427)	loss 3.5040 (2.8350)	grad_norm 7.0826 (9.6973)	mem 8929MB
[2022-04-09 17:38:44 large] (main.py 226): INFO Train: [268/300][900/2502]	eta 0:14:21 lr 0.000018	time 0.4993 (0.5379)	loss 3.1340 (2.8351)	grad_norm 9.0026 (9.7228)	mem 8929MB
[2022-04-09 17:39:36 large] (main.py 226): INFO Train: [268/300][1000/2502]	eta 0:13:26 lr 0.000018	time 0.5886 (0.5371)	loss 1.9300 (2.8253)	grad_norm 9.7510 (9.6946)	mem 8929MB
[2022-04-09 17:40:29 large] (main.py 226): INFO Train: [268/300][1100/2502]	eta 0:12:31 lr 0.000018	time 0.4909 (0.5362)	loss 3.2610 (2.8210)	grad_norm 7.4905 (9.6436)	mem 8929MB
[2022-04-09 17:41:22 large] (main.py 226): INFO Train: [268/300][1200/2502]	eta 0:11:37 lr 0.000018	time 0.6261 (0.5354)	loss 3.3080 (2.8149)	grad_norm 8.7900 (9.5755)	mem 8929MB
[2022-04-09 17:42:16 large] (main.py 226): INFO Train: [268/300][1300/2502]	eta 0:10:43 lr 0.000018	time 0.5300 (0.5357)	loss 3.2135 (2.8220)	grad_norm 9.2589 (9.6418)	mem 8929MB
[2022-04-09 17:43:10 large] (main.py 226): INFO Train: [268/300][1400/2502]	eta 0:09:51 lr 0.000018	time 0.5166 (0.5363)	loss 3.1812 (2.8230)	grad_norm 7.7992 (9.6074)	mem 8929MB
[2022-04-09 17:43:59 large] (main.py 226): INFO Train: [268/300][1500/2502]	eta 0:08:54 lr 0.000018	time 0.4732 (0.5331)	loss 3.5310 (2.8294)	grad_norm 7.7703 (9.6856)	mem 8929MB
[2022-04-09 17:44:49 large] (main.py 226): INFO Train: [268/300][1600/2502]	eta 0:07:59 lr 0.000018	time 0.4868 (0.5312)	loss 3.0394 (2.8291)	grad_norm 11.2903 (9.6787)	mem 8929MB
[2022-04-09 17:45:41 large] (main.py 226): INFO Train: [268/300][1700/2502]	eta 0:07:05 lr 0.000018	time 0.5807 (0.5303)	loss 2.6309 (2.8316)	grad_norm 7.0787 (9.6727)	mem 8929MB
[2022-04-09 17:46:36 large] (main.py 226): INFO Train: [268/300][1800/2502]	eta 0:06:13 lr 0.000018	time 0.5719 (0.5315)	loss 3.2902 (2.8311)	grad_norm 11.7908 (9.6800)	mem 8929MB
[2022-04-09 17:47:30 large] (main.py 226): INFO Train: [268/300][1900/2502]	eta 0:05:20 lr 0.000018	time 0.5222 (0.5319)	loss 2.9038 (2.8305)	grad_norm 6.8108 (9.6718)	mem 8929MB
[2022-04-09 17:48:23 large] (main.py 226): INFO Train: [268/300][2000/2502]	eta 0:04:26 lr 0.000018	time 0.4932 (0.5316)	loss 2.9262 (2.8287)	grad_norm 11.5832 (9.6920)	mem 8929MB
[2022-04-09 17:49:14 large] (main.py 226): INFO Train: [268/300][2100/2502]	eta 0:03:33 lr 0.000018	time 0.5038 (0.5305)	loss 3.2884 (2.8262)	grad_norm 10.3155 (9.6750)	mem 8929MB
[2022-04-09 17:50:09 large] (main.py 226): INFO Train: [268/300][2200/2502]	eta 0:02:40 lr 0.000018	time 0.5566 (0.5315)	loss 3.1332 (2.8220)	grad_norm 8.0010 (9.6996)	mem 8929MB
[2022-04-09 17:51:03 large] (main.py 226): INFO Train: [268/300][2300/2502]	eta 0:01:47 lr 0.000018	time 0.5098 (0.5322)	loss 3.1449 (2.8252)	grad_norm 7.5160 (9.6599)	mem 8929MB
[2022-04-09 17:51:57 large] (main.py 226): INFO Train: [268/300][2400/2502]	eta 0:00:54 lr 0.000018	time 0.4933 (0.5323)	loss 1.6941 (2.8256)	grad_norm 8.6921 (9.6661)	mem 8929MB
[2022-04-09 17:52:51 large] (main.py 226): INFO Train: [268/300][2500/2502]	eta 0:00:01 lr 0.000018	time 0.5107 (0.5325)	loss 3.3489 (2.8266)	grad_norm 8.5151 (9.6715)	mem 8929MB
[2022-04-09 17:52:52 large] (main.py 233): INFO EPOCH 268 training takes 0:22:12
[2022-04-09 17:52:58 large] (main.py 273): INFO Test: [0/98]	Time 6.086 (6.086)	Loss 0.9576 (0.9576)	Acc@1 84.375 (84.375)	Acc@5 95.312 (95.312)	Mem 8929MB
[2022-04-09 17:53:24 large] (main.py 279): INFO  * Acc@1 81.656 Acc@5 95.560
[2022-04-09 17:53:24 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.7%
[2022-04-09 17:53:24 large] (utils.py 57): INFO output/large/default/ckpt_epoch_268.pth saving......
[2022-04-09 17:53:25 large] (utils.py 59): INFO output/large/default/ckpt_epoch_268.pth saved !!!
[2022-04-09 17:53:25 large] (main.py 148): INFO Max accuracy: 81.66%
[2022-04-09 17:53:32 large] (main.py 226): INFO Train: [269/300][0/2502]	eta 5:15:14 lr 0.000018	time 7.5598 (7.5598)	loss 2.1626 (2.1626)	grad_norm 10.3071 (10.3071)	mem 8929MB
[2022-04-09 17:54:22 large] (main.py 226): INFO Train: [269/300][100/2502]	eta 0:22:50 lr 0.000018	time 0.4781 (0.5704)	loss 2.8541 (2.8252)	grad_norm 9.1450 (inf)	mem 8929MB
[2022-04-09 17:55:12 large] (main.py 226): INFO Train: [269/300][200/2502]	eta 0:20:24 lr 0.000018	time 0.4999 (0.5318)	loss 2.7604 (2.8651)	grad_norm 8.2916 (nan)	mem 8929MB
[2022-04-09 17:56:04 large] (main.py 226): INFO Train: [269/300][300/2502]	eta 0:19:26 lr 0.000018	time 0.5480 (0.5297)	loss 2.6705 (2.8522)	grad_norm 6.8098 (nan)	mem 8929MB
[2022-04-09 17:56:59 large] (main.py 226): INFO Train: [269/300][400/2502]	eta 0:18:42 lr 0.000018	time 0.5316 (0.5339)	loss 3.4159 (2.8552)	grad_norm 9.2277 (nan)	mem 8929MB
[2022-04-09 17:57:54 large] (main.py 226): INFO Train: [269/300][500/2502]	eta 0:17:57 lr 0.000018	time 0.5904 (0.5381)	loss 2.3640 (2.8488)	grad_norm 9.6953 (nan)	mem 8929MB
[2022-04-09 17:58:48 large] (main.py 226): INFO Train: [269/300][600/2502]	eta 0:17:03 lr 0.000018	time 0.5326 (0.5380)	loss 3.0578 (2.8352)	grad_norm 6.9661 (nan)	mem 8929MB
[2022-04-09 17:59:42 large] (main.py 226): INFO Train: [269/300][700/2502]	eta 0:16:10 lr 0.000018	time 0.5173 (0.5386)	loss 2.0078 (2.8397)	grad_norm 10.4718 (nan)	mem 8929MB
[2022-04-09 18:00:36 large] (main.py 226): INFO Train: [269/300][800/2502]	eta 0:15:16 lr 0.000018	time 0.5272 (0.5386)	loss 3.7189 (2.8442)	grad_norm 9.4923 (nan)	mem 8929MB
[2022-04-09 18:01:31 large] (main.py 226): INFO Train: [269/300][900/2502]	eta 0:14:24 lr 0.000018	time 0.5550 (0.5394)	loss 3.0203 (2.8440)	grad_norm 8.2258 (nan)	mem 8929MB
[2022-04-09 18:02:24 large] (main.py 226): INFO Train: [269/300][1000/2502]	eta 0:13:29 lr 0.000018	time 0.5250 (0.5388)	loss 2.0618 (2.8363)	grad_norm 8.7974 (nan)	mem 8929MB
[2022-04-09 18:03:18 large] (main.py 226): INFO Train: [269/300][1100/2502]	eta 0:12:34 lr 0.000018	time 0.5122 (0.5384)	loss 2.0831 (2.8301)	grad_norm 8.8624 (nan)	mem 8929MB
[2022-04-09 18:04:09 large] (main.py 226): INFO Train: [269/300][1200/2502]	eta 0:11:38 lr 0.000018	time 0.6480 (0.5362)	loss 3.1845 (2.8316)	grad_norm 9.9841 (nan)	mem 8929MB
[2022-04-09 18:05:02 large] (main.py 226): INFO Train: [269/300][1300/2502]	eta 0:10:43 lr 0.000018	time 0.5874 (0.5357)	loss 1.9931 (2.8300)	grad_norm 9.2705 (nan)	mem 8929MB
[2022-04-09 18:05:55 large] (main.py 226): INFO Train: [269/300][1400/2502]	eta 0:09:49 lr 0.000017	time 0.5198 (0.5354)	loss 2.9162 (2.8324)	grad_norm 6.2715 (nan)	mem 8929MB
[2022-04-09 18:06:46 large] (main.py 226): INFO Train: [269/300][1500/2502]	eta 0:08:54 lr 0.000017	time 0.5102 (0.5338)	loss 2.4439 (2.8358)	grad_norm 7.7688 (nan)	mem 8929MB
[2022-04-09 18:07:40 large] (main.py 226): INFO Train: [269/300][1600/2502]	eta 0:08:01 lr 0.000017	time 0.5406 (0.5340)	loss 2.6685 (2.8330)	grad_norm 8.1818 (nan)	mem 8929MB
[2022-04-09 18:08:33 large] (main.py 226): INFO Train: [269/300][1700/2502]	eta 0:07:08 lr 0.000017	time 0.5300 (0.5338)	loss 2.6145 (2.8271)	grad_norm 10.5840 (nan)	mem 8929MB
[2022-04-09 18:09:27 large] (main.py 226): INFO Train: [269/300][1800/2502]	eta 0:06:15 lr 0.000017	time 0.5142 (0.5342)	loss 3.1706 (2.8258)	grad_norm 11.0568 (nan)	mem 8929MB
[2022-04-09 18:10:19 large] (main.py 226): INFO Train: [269/300][1900/2502]	eta 0:05:21 lr 0.000017	time 0.4492 (0.5334)	loss 3.2758 (2.8215)	grad_norm 7.0640 (nan)	mem 8929MB
[2022-04-09 18:11:09 large] (main.py 226): INFO Train: [269/300][2000/2502]	eta 0:04:27 lr 0.000017	time 0.5126 (0.5319)	loss 2.8209 (2.8194)	grad_norm 24.6498 (nan)	mem 8929MB
[2022-04-09 18:12:03 large] (main.py 226): INFO Train: [269/300][2100/2502]	eta 0:03:34 lr 0.000017	time 0.5848 (0.5324)	loss 3.1888 (2.8220)	grad_norm 7.9161 (nan)	mem 8929MB
[2022-04-09 18:12:57 large] (main.py 226): INFO Train: [269/300][2200/2502]	eta 0:02:40 lr 0.000017	time 0.4781 (0.5325)	loss 2.6647 (2.8223)	grad_norm 8.0958 (nan)	mem 8929MB
[2022-04-09 18:13:48 large] (main.py 226): INFO Train: [269/300][2300/2502]	eta 0:01:47 lr 0.000017	time 0.5210 (0.5317)	loss 2.7957 (2.8194)	grad_norm 7.9539 (nan)	mem 8929MB
[2022-04-09 18:14:43 large] (main.py 226): INFO Train: [269/300][2400/2502]	eta 0:00:54 lr 0.000017	time 0.5351 (0.5324)	loss 3.1165 (2.8193)	grad_norm 9.1153 (nan)	mem 8929MB
[2022-04-09 18:15:36 large] (main.py 226): INFO Train: [269/300][2500/2502]	eta 0:00:01 lr 0.000017	time 0.5101 (0.5323)	loss 2.8765 (2.8212)	grad_norm 7.6273 (nan)	mem 8929MB
[2022-04-09 18:15:37 large] (main.py 233): INFO EPOCH 269 training takes 0:22:12
[2022-04-09 18:15:44 large] (main.py 273): INFO Test: [0/98]	Time 6.602 (6.602)	Loss 0.9296 (0.9296)	Acc@1 81.445 (81.445)	Acc@5 96.094 (96.094)	Mem 8929MB
[2022-04-09 18:16:09 large] (main.py 279): INFO  * Acc@1 81.648 Acc@5 95.564
[2022-04-09 18:16:09 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.6%
[2022-04-09 18:16:09 large] (main.py 148): INFO Max accuracy: 81.66%
[2022-04-09 18:16:16 large] (main.py 226): INFO Train: [270/300][0/2502]	eta 5:04:23 lr 0.000017	time 7.2996 (7.2996)	loss 2.6391 (2.6391)	grad_norm 19.3699 (19.3699)	mem 8929MB
[2022-04-09 18:17:08 large] (main.py 226): INFO Train: [270/300][100/2502]	eta 0:23:20 lr 0.000017	time 0.5060 (0.5829)	loss 3.1842 (2.7995)	grad_norm 10.5830 (10.6941)	mem 8929MB
[2022-04-09 18:18:01 large] (main.py 226): INFO Train: [270/300][200/2502]	eta 0:21:24 lr 0.000017	time 0.5235 (0.5581)	loss 2.1692 (2.8432)	grad_norm 13.7419 (10.1658)	mem 8929MB
[2022-04-09 18:18:56 large] (main.py 226): INFO Train: [270/300][300/2502]	eta 0:20:19 lr 0.000017	time 0.5306 (0.5539)	loss 2.8506 (2.8133)	grad_norm 7.8176 (nan)	mem 8929MB
[2022-04-09 18:19:50 large] (main.py 226): INFO Train: [270/300][400/2502]	eta 0:19:19 lr 0.000017	time 0.6127 (0.5514)	loss 2.6638 (2.8123)	grad_norm 8.8179 (nan)	mem 8929MB
[2022-04-09 18:20:42 large] (main.py 226): INFO Train: [270/300][500/2502]	eta 0:18:08 lr 0.000017	time 0.5212 (0.5438)	loss 3.3932 (2.8197)	grad_norm 9.9715 (nan)	mem 8929MB
[2022-04-09 18:21:35 large] (main.py 226): INFO Train: [270/300][600/2502]	eta 0:17:10 lr 0.000017	time 0.5745 (0.5418)	loss 3.0327 (2.8123)	grad_norm 8.1787 (nan)	mem 8929MB
[2022-04-09 18:22:24 large] (main.py 226): INFO Train: [270/300][700/2502]	eta 0:16:04 lr 0.000017	time 0.5013 (0.5352)	loss 3.1943 (2.8208)	grad_norm 7.8217 (nan)	mem 8929MB
[2022-04-09 18:23:15 large] (main.py 226): INFO Train: [270/300][800/2502]	eta 0:15:04 lr 0.000017	time 0.5234 (0.5315)	loss 2.7094 (2.8135)	grad_norm 8.1779 (nan)	mem 8929MB
[2022-04-09 18:24:09 large] (main.py 226): INFO Train: [270/300][900/2502]	eta 0:14:13 lr 0.000017	time 0.6217 (0.5329)	loss 1.9261 (2.8130)	grad_norm 11.3520 (nan)	mem 8929MB
[2022-04-09 18:25:03 large] (main.py 226): INFO Train: [270/300][1000/2502]	eta 0:13:20 lr 0.000017	time 0.5306 (0.5329)	loss 3.3485 (2.8143)	grad_norm 9.2734 (nan)	mem 8929MB
[2022-04-09 18:25:57 large] (main.py 226): INFO Train: [270/300][1100/2502]	eta 0:12:28 lr 0.000017	time 0.5290 (0.5340)	loss 3.2372 (2.8189)	grad_norm 8.5562 (nan)	mem 8929MB
[2022-04-09 18:26:49 large] (main.py 226): INFO Train: [270/300][1200/2502]	eta 0:11:33 lr 0.000017	time 0.4781 (0.5326)	loss 1.6858 (2.8145)	grad_norm 9.1722 (nan)	mem 8929MB
[2022-04-09 18:27:42 large] (main.py 226): INFO Train: [270/300][1300/2502]	eta 0:10:39 lr 0.000017	time 0.5178 (0.5322)	loss 2.9248 (2.8091)	grad_norm 10.3461 (nan)	mem 8929MB
[2022-04-09 18:28:36 large] (main.py 226): INFO Train: [270/300][1400/2502]	eta 0:09:47 lr 0.000017	time 0.5433 (0.5328)	loss 2.6823 (2.8087)	grad_norm 7.7728 (nan)	mem 8929MB
[2022-04-09 18:29:30 large] (main.py 226): INFO Train: [270/300][1500/2502]	eta 0:08:54 lr 0.000017	time 0.5543 (0.5337)	loss 2.6740 (2.8079)	grad_norm 7.6971 (nan)	mem 8929MB
[2022-04-09 18:30:21 large] (main.py 226): INFO Train: [270/300][1600/2502]	eta 0:08:00 lr 0.000017	time 0.5052 (0.5323)	loss 3.2042 (2.8165)	grad_norm 9.0866 (nan)	mem 8929MB
[2022-04-09 18:31:13 large] (main.py 226): INFO Train: [270/300][1700/2502]	eta 0:07:06 lr 0.000017	time 0.5112 (0.5313)	loss 2.0234 (2.8150)	grad_norm 7.4251 (nan)	mem 8929MB
[2022-04-09 18:32:05 large] (main.py 226): INFO Train: [270/300][1800/2502]	eta 0:06:12 lr 0.000017	time 0.5026 (0.5309)	loss 3.2255 (2.8180)	grad_norm 10.2310 (nan)	mem 8929MB
[2022-04-09 18:32:55 large] (main.py 226): INFO Train: [270/300][1900/2502]	eta 0:05:18 lr 0.000017	time 0.4599 (0.5289)	loss 1.7917 (2.8169)	grad_norm 11.3545 (nan)	mem 8929MB
[2022-04-09 18:33:45 large] (main.py 226): INFO Train: [270/300][2000/2502]	eta 0:04:24 lr 0.000016	time 0.5790 (0.5276)	loss 3.0598 (2.8186)	grad_norm 6.4245 (nan)	mem 8929MB
[2022-04-09 18:34:39 large] (main.py 226): INFO Train: [270/300][2100/2502]	eta 0:03:32 lr 0.000016	time 0.5356 (0.5283)	loss 3.3561 (2.8206)	grad_norm 7.9826 (nan)	mem 8929MB
[2022-04-09 18:35:34 large] (main.py 226): INFO Train: [270/300][2200/2502]	eta 0:02:39 lr 0.000016	time 0.5895 (0.5293)	loss 2.8033 (2.8160)	grad_norm 8.8920 (nan)	mem 8929MB
[2022-04-09 18:36:30 large] (main.py 226): INFO Train: [270/300][2300/2502]	eta 0:01:47 lr 0.000016	time 0.5368 (0.5306)	loss 2.5415 (2.8137)	grad_norm 17.6848 (nan)	mem 8929MB
[2022-04-09 18:37:25 large] (main.py 226): INFO Train: [270/300][2400/2502]	eta 0:00:54 lr 0.000016	time 0.5569 (0.5315)	loss 1.9679 (2.8158)	grad_norm 13.2305 (nan)	mem 8929MB
[2022-04-09 18:38:19 large] (main.py 226): INFO Train: [270/300][2500/2502]	eta 0:00:01 lr 0.000016	time 0.5182 (0.5316)	loss 2.8521 (2.8156)	grad_norm 6.6935 (nan)	mem 8929MB
[2022-04-09 18:38:20 large] (main.py 233): INFO EPOCH 270 training takes 0:22:10
[2022-04-09 18:38:27 large] (main.py 273): INFO Test: [0/98]	Time 6.807 (6.807)	Loss 0.9283 (0.9283)	Acc@1 82.031 (82.031)	Acc@5 97.266 (97.266)	Mem 8929MB
[2022-04-09 18:38:52 large] (main.py 279): INFO  * Acc@1 81.736 Acc@5 95.630
[2022-04-09 18:38:52 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.7%
[2022-04-09 18:38:52 large] (utils.py 57): INFO output/large/default/ckpt_epoch_270.pth saving......
[2022-04-09 18:38:53 large] (utils.py 59): INFO output/large/default/ckpt_epoch_270.pth saved !!!
[2022-04-09 18:38:53 large] (main.py 148): INFO Max accuracy: 81.74%
[2022-04-09 18:39:01 large] (main.py 226): INFO Train: [271/300][0/2502]	eta 5:44:30 lr 0.000016	time 8.2617 (8.2617)	loss 1.9415 (1.9415)	grad_norm 9.6006 (9.6006)	mem 8929MB
[2022-04-09 18:39:51 large] (main.py 226): INFO Train: [271/300][100/2502]	eta 0:23:10 lr 0.000016	time 0.4763 (0.5789)	loss 3.3917 (2.8538)	grad_norm 13.6299 (8.8456)	mem 8929MB
[2022-04-09 18:40:45 large] (main.py 226): INFO Train: [271/300][200/2502]	eta 0:21:27 lr 0.000016	time 0.5169 (0.5594)	loss 3.0278 (2.8045)	grad_norm 6.8643 (9.8526)	mem 8929MB
[2022-04-09 18:41:38 large] (main.py 226): INFO Train: [271/300][300/2502]	eta 0:20:09 lr 0.000016	time 0.4822 (0.5492)	loss 1.7442 (2.8055)	grad_norm 10.0494 (9.5994)	mem 8929MB
[2022-04-09 18:42:31 large] (main.py 226): INFO Train: [271/300][400/2502]	eta 0:19:03 lr 0.000016	time 0.5448 (0.5438)	loss 3.1385 (2.8122)	grad_norm 7.5105 (9.6296)	mem 8929MB
[2022-04-09 18:43:25 large] (main.py 226): INFO Train: [271/300][500/2502]	eta 0:18:06 lr 0.000016	time 0.4923 (0.5427)	loss 3.3258 (2.8092)	grad_norm 9.1653 (9.6193)	mem 8929MB
[2022-04-09 18:44:14 large] (main.py 226): INFO Train: [271/300][600/2502]	eta 0:16:57 lr 0.000016	time 0.4977 (0.5350)	loss 3.1626 (2.8108)	grad_norm 8.6708 (9.5746)	mem 8929MB
[2022-04-09 18:45:05 large] (main.py 226): INFO Train: [271/300][700/2502]	eta 0:15:57 lr 0.000016	time 0.5305 (0.5315)	loss 2.3240 (2.8067)	grad_norm 7.0078 (9.4890)	mem 8929MB
[2022-04-09 18:45:56 large] (main.py 226): INFO Train: [271/300][800/2502]	eta 0:14:58 lr 0.000016	time 0.4762 (0.5282)	loss 2.5662 (2.8113)	grad_norm 8.4622 (9.4367)	mem 8929MB
[2022-04-09 18:46:48 large] (main.py 226): INFO Train: [271/300][900/2502]	eta 0:14:05 lr 0.000016	time 0.5754 (0.5275)	loss 3.2730 (2.8263)	grad_norm 10.9842 (9.4384)	mem 8929MB
[2022-04-09 18:47:41 large] (main.py 226): INFO Train: [271/300][1000/2502]	eta 0:13:12 lr 0.000016	time 0.5858 (0.5274)	loss 2.7641 (2.8252)	grad_norm 8.1043 (9.4971)	mem 8929MB
[2022-04-09 18:48:32 large] (main.py 226): INFO Train: [271/300][1100/2502]	eta 0:12:17 lr 0.000016	time 0.5128 (0.5258)	loss 3.0297 (2.8229)	grad_norm 7.1835 (9.5461)	mem 8929MB
[2022-04-09 18:49:27 large] (main.py 226): INFO Train: [271/300][1200/2502]	eta 0:11:26 lr 0.000016	time 0.5015 (0.5276)	loss 2.1751 (2.8260)	grad_norm 7.4409 (9.6000)	mem 8929MB
[2022-04-09 18:50:22 large] (main.py 226): INFO Train: [271/300][1300/2502]	eta 0:10:36 lr 0.000016	time 0.5794 (0.5299)	loss 2.9378 (2.8282)	grad_norm 10.6919 (9.5951)	mem 8929MB
[2022-04-09 18:51:17 large] (main.py 226): INFO Train: [271/300][1400/2502]	eta 0:09:45 lr 0.000016	time 0.4893 (0.5312)	loss 3.0957 (2.8272)	grad_norm 8.9232 (9.6600)	mem 8929MB
[2022-04-09 18:52:06 large] (main.py 226): INFO Train: [271/300][1500/2502]	eta 0:08:49 lr 0.000016	time 0.4854 (0.5283)	loss 2.8611 (2.8250)	grad_norm 7.1024 (9.6548)	mem 8929MB
[2022-04-09 18:52:57 large] (main.py 226): INFO Train: [271/300][1600/2502]	eta 0:07:55 lr 0.000016	time 0.4878 (0.5270)	loss 2.5735 (2.8187)	grad_norm 7.1385 (9.6663)	mem 8929MB
[2022-04-09 18:53:47 large] (main.py 226): INFO Train: [271/300][1700/2502]	eta 0:07:01 lr 0.000016	time 0.5281 (0.5257)	loss 3.4789 (2.8169)	grad_norm 9.9610 (9.7026)	mem 8929MB
[2022-04-09 18:54:38 large] (main.py 226): INFO Train: [271/300][1800/2502]	eta 0:06:08 lr 0.000016	time 0.5359 (0.5249)	loss 3.3705 (2.8149)	grad_norm 8.9221 (9.6838)	mem 8929MB
[2022-04-09 18:55:33 large] (main.py 226): INFO Train: [271/300][1900/2502]	eta 0:05:16 lr 0.000016	time 0.5336 (0.5264)	loss 3.2323 (2.8133)	grad_norm 8.9917 (9.6842)	mem 8929MB
[2022-04-09 18:56:28 large] (main.py 226): INFO Train: [271/300][2000/2502]	eta 0:04:24 lr 0.000016	time 0.5704 (0.5271)	loss 2.9960 (2.8157)	grad_norm 7.3590 (9.6432)	mem 8929MB
[2022-04-09 18:57:20 large] (main.py 226): INFO Train: [271/300][2100/2502]	eta 0:03:31 lr 0.000016	time 0.5155 (0.5269)	loss 3.0212 (2.8152)	grad_norm 8.6326 (9.6663)	mem 8929MB
[2022-04-09 18:58:10 large] (main.py 226): INFO Train: [271/300][2200/2502]	eta 0:02:38 lr 0.000016	time 0.4949 (0.5259)	loss 1.6945 (2.8146)	grad_norm 9.8505 (9.6778)	mem 8929MB
[2022-04-09 18:59:05 large] (main.py 226): INFO Train: [271/300][2300/2502]	eta 0:01:46 lr 0.000016	time 0.5309 (0.5267)	loss 2.9990 (2.8153)	grad_norm 8.6192 (9.6566)	mem 8929MB
[2022-04-09 18:59:59 large] (main.py 226): INFO Train: [271/300][2400/2502]	eta 0:00:53 lr 0.000016	time 0.5565 (0.5272)	loss 1.7736 (2.8116)	grad_norm 7.4278 (9.6404)	mem 8929MB
[2022-04-09 19:00:53 large] (main.py 226): INFO Train: [271/300][2500/2502]	eta 0:00:01 lr 0.000016	time 0.5077 (0.5278)	loss 3.3535 (2.8121)	grad_norm 10.1504 (9.6354)	mem 8929MB
[2022-04-09 19:00:54 large] (main.py 233): INFO EPOCH 271 training takes 0:22:00
[2022-04-09 19:01:00 large] (main.py 273): INFO Test: [0/98]	Time 6.501 (6.501)	Loss 0.9040 (0.9040)	Acc@1 82.617 (82.617)	Acc@5 96.680 (96.680)	Mem 8929MB
[2022-04-09 19:01:26 large] (main.py 279): INFO  * Acc@1 81.780 Acc@5 95.610
[2022-04-09 19:01:26 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.8%
[2022-04-09 19:01:26 large] (utils.py 57): INFO output/large/default/ckpt_epoch_271.pth saving......
[2022-04-09 19:01:27 large] (utils.py 59): INFO output/large/default/ckpt_epoch_271.pth saved !!!
[2022-04-09 19:01:27 large] (main.py 148): INFO Max accuracy: 81.78%
[2022-04-09 19:01:34 large] (main.py 226): INFO Train: [272/300][0/2502]	eta 5:16:10 lr 0.000016	time 7.5822 (7.5822)	loss 2.7595 (2.7595)	grad_norm 9.5784 (9.5784)	mem 8929MB
[2022-04-09 19:02:24 large] (main.py 226): INFO Train: [272/300][100/2502]	eta 0:22:37 lr 0.000016	time 0.4879 (0.5653)	loss 3.0904 (2.8753)	grad_norm 9.2495 (8.9057)	mem 8929MB
[2022-04-09 19:03:15 large] (main.py 226): INFO Train: [272/300][200/2502]	eta 0:20:38 lr 0.000016	time 0.4941 (0.5379)	loss 3.0053 (2.8123)	grad_norm 8.3023 (9.0500)	mem 8929MB
[2022-04-09 19:04:04 large] (main.py 226): INFO Train: [272/300][300/2502]	eta 0:19:11 lr 0.000015	time 0.4527 (0.5229)	loss 2.9165 (2.8113)	grad_norm 8.3320 (9.2313)	mem 8929MB
[2022-04-09 19:04:55 large] (main.py 226): INFO Train: [272/300][400/2502]	eta 0:18:12 lr 0.000015	time 0.5432 (0.5198)	loss 2.8976 (2.8067)	grad_norm 9.7992 (9.2137)	mem 8929MB
[2022-04-09 19:05:51 large] (main.py 226): INFO Train: [272/300][500/2502]	eta 0:17:37 lr 0.000015	time 0.6846 (0.5282)	loss 2.7870 (2.8053)	grad_norm 6.7469 (9.3326)	mem 8929MB
[2022-04-09 19:06:46 large] (main.py 226): INFO Train: [272/300][600/2502]	eta 0:16:51 lr 0.000015	time 0.5458 (0.5316)	loss 3.1149 (2.8196)	grad_norm 9.1073 (9.2963)	mem 8929MB
[2022-04-09 19:07:41 large] (main.py 226): INFO Train: [272/300][700/2502]	eta 0:16:01 lr 0.000015	time 0.5764 (0.5338)	loss 2.9449 (2.8039)	grad_norm 6.1724 (9.3035)	mem 8929MB
[2022-04-09 19:08:36 large] (main.py 226): INFO Train: [272/300][800/2502]	eta 0:15:11 lr 0.000015	time 0.5961 (0.5357)	loss 3.4434 (2.8093)	grad_norm 8.1456 (9.2752)	mem 8929MB
[2022-04-09 19:09:30 large] (main.py 226): INFO Train: [272/300][900/2502]	eta 0:14:19 lr 0.000015	time 0.5257 (0.5367)	loss 3.1363 (2.7955)	grad_norm 9.2724 (9.3336)	mem 8929MB
[2022-04-09 19:10:24 large] (main.py 226): INFO Train: [272/300][1000/2502]	eta 0:13:26 lr 0.000015	time 0.5283 (0.5369)	loss 1.8252 (2.8016)	grad_norm 8.1202 (9.3472)	mem 8929MB
[2022-04-09 19:11:18 large] (main.py 226): INFO Train: [272/300][1100/2502]	eta 0:12:32 lr 0.000015	time 0.5093 (0.5368)	loss 3.0091 (2.7958)	grad_norm 9.6764 (nan)	mem 8929MB
[2022-04-09 19:12:11 large] (main.py 226): INFO Train: [272/300][1200/2502]	eta 0:11:38 lr 0.000015	time 0.5123 (0.5367)	loss 1.7762 (2.7953)	grad_norm 8.6232 (nan)	mem 8929MB
[2022-04-09 19:13:02 large] (main.py 226): INFO Train: [272/300][1300/2502]	eta 0:10:42 lr 0.000015	time 0.5145 (0.5343)	loss 2.3455 (2.7923)	grad_norm 10.9312 (nan)	mem 8929MB
[2022-04-09 19:13:56 large] (main.py 226): INFO Train: [272/300][1400/2502]	eta 0:09:49 lr 0.000015	time 0.4763 (0.5349)	loss 3.2170 (2.7948)	grad_norm 8.8352 (nan)	mem 8929MB
[2022-04-09 19:14:46 large] (main.py 226): INFO Train: [272/300][1500/2502]	eta 0:08:53 lr 0.000015	time 0.5909 (0.5323)	loss 2.8179 (2.7966)	grad_norm 6.5591 (nan)	mem 8929MB
[2022-04-09 19:15:39 large] (main.py 226): INFO Train: [272/300][1600/2502]	eta 0:08:00 lr 0.000015	time 0.5642 (0.5325)	loss 3.5317 (2.7988)	grad_norm 8.4301 (nan)	mem 8929MB
[2022-04-09 19:16:33 large] (main.py 226): INFO Train: [272/300][1700/2502]	eta 0:07:07 lr 0.000015	time 0.5120 (0.5330)	loss 2.0099 (2.7951)	grad_norm 7.9810 (nan)	mem 8929MB
[2022-04-09 19:17:27 large] (main.py 226): INFO Train: [272/300][1800/2502]	eta 0:06:14 lr 0.000015	time 0.5287 (0.5333)	loss 2.4854 (2.7977)	grad_norm 7.9430 (nan)	mem 8929MB
[2022-04-09 19:18:22 large] (main.py 226): INFO Train: [272/300][1900/2502]	eta 0:05:21 lr 0.000015	time 0.6213 (0.5341)	loss 3.3409 (2.7965)	grad_norm 8.0716 (nan)	mem 8929MB
[2022-04-09 19:19:12 large] (main.py 226): INFO Train: [272/300][2000/2502]	eta 0:04:27 lr 0.000015	time 0.5097 (0.5324)	loss 3.1065 (2.8006)	grad_norm 8.4233 (nan)	mem 8929MB
[2022-04-09 19:20:02 large] (main.py 226): INFO Train: [272/300][2100/2502]	eta 0:03:33 lr 0.000015	time 0.5056 (0.5307)	loss 2.9855 (2.8002)	grad_norm 9.6641 (nan)	mem 8929MB
[2022-04-09 19:20:55 large] (main.py 226): INFO Train: [272/300][2200/2502]	eta 0:02:40 lr 0.000015	time 0.5827 (0.5310)	loss 3.2036 (2.8002)	grad_norm 8.1906 (nan)	mem 8929MB
[2022-04-09 19:21:47 large] (main.py 226): INFO Train: [272/300][2300/2502]	eta 0:01:47 lr 0.000015	time 0.4929 (0.5302)	loss 3.1189 (2.8044)	grad_norm 13.1286 (nan)	mem 8929MB
[2022-04-09 19:22:38 large] (main.py 226): INFO Train: [272/300][2400/2502]	eta 0:00:53 lr 0.000015	time 0.5270 (0.5294)	loss 3.3087 (2.8033)	grad_norm 7.5492 (nan)	mem 8929MB
[2022-04-09 19:23:31 large] (main.py 226): INFO Train: [272/300][2500/2502]	eta 0:00:01 lr 0.000015	time 0.5175 (0.5297)	loss 2.0688 (2.8031)	grad_norm 8.0519 (nan)	mem 8929MB
[2022-04-09 19:23:32 large] (main.py 233): INFO EPOCH 272 training takes 0:22:05
[2022-04-09 19:23:38 large] (main.py 273): INFO Test: [0/98]	Time 5.797 (5.797)	Loss 0.9110 (0.9110)	Acc@1 83.789 (83.789)	Acc@5 94.922 (94.922)	Mem 8929MB
[2022-04-09 19:24:05 large] (main.py 279): INFO  * Acc@1 81.722 Acc@5 95.534
[2022-04-09 19:24:05 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.7%
[2022-04-09 19:24:05 large] (main.py 148): INFO Max accuracy: 81.78%
[2022-04-09 19:24:12 large] (main.py 226): INFO Train: [273/300][0/2502]	eta 4:59:37 lr 0.000015	time 7.1854 (7.1854)	loss 2.7741 (2.7741)	grad_norm 7.6197 (7.6197)	mem 8929MB
[2022-04-09 19:25:05 large] (main.py 226): INFO Train: [273/300][100/2502]	eta 0:23:47 lr 0.000015	time 0.5400 (0.5941)	loss 1.8933 (2.7787)	grad_norm 16.8106 (9.7053)	mem 8929MB
[2022-04-09 19:25:59 large] (main.py 226): INFO Train: [273/300][200/2502]	eta 0:21:47 lr 0.000015	time 0.5339 (0.5679)	loss 2.0520 (2.7681)	grad_norm 8.5283 (9.5438)	mem 8929MB
[2022-04-09 19:26:53 large] (main.py 226): INFO Train: [273/300][300/2502]	eta 0:20:28 lr 0.000015	time 0.4701 (0.5581)	loss 3.1236 (2.7441)	grad_norm 7.6127 (9.7166)	mem 8929MB
[2022-04-09 19:27:42 large] (main.py 226): INFO Train: [273/300][400/2502]	eta 0:19:01 lr 0.000015	time 0.5145 (0.5432)	loss 2.7423 (2.7527)	grad_norm 9.2139 (9.9061)	mem 8929MB
[2022-04-09 19:28:36 large] (main.py 226): INFO Train: [273/300][500/2502]	eta 0:18:06 lr 0.000015	time 0.5634 (0.5425)	loss 3.2584 (2.7794)	grad_norm 10.6782 (9.7099)	mem 8929MB
[2022-04-09 19:29:31 large] (main.py 226): INFO Train: [273/300][600/2502]	eta 0:17:13 lr 0.000015	time 0.5500 (0.5432)	loss 3.2223 (2.7864)	grad_norm 8.6571 (9.6733)	mem 8929MB
[2022-04-09 19:30:21 large] (main.py 226): INFO Train: [273/300][700/2502]	eta 0:16:08 lr 0.000015	time 0.6040 (0.5374)	loss 3.4220 (2.8011)	grad_norm 11.2944 (9.6392)	mem 8929MB
[2022-04-09 19:31:12 large] (main.py 226): INFO Train: [273/300][800/2502]	eta 0:15:07 lr 0.000015	time 0.5695 (0.5331)	loss 3.2735 (2.8020)	grad_norm 8.6836 (9.6218)	mem 8929MB
[2022-04-09 19:32:06 large] (main.py 226): INFO Train: [273/300][900/2502]	eta 0:14:15 lr 0.000015	time 0.5094 (0.5339)	loss 2.1944 (2.7936)	grad_norm 8.8796 (nan)	mem 8929MB
[2022-04-09 19:32:58 large] (main.py 226): INFO Train: [273/300][1000/2502]	eta 0:13:19 lr 0.000015	time 0.5102 (0.5325)	loss 2.2467 (2.7983)	grad_norm 6.0064 (nan)	mem 8929MB
[2022-04-09 19:33:49 large] (main.py 226): INFO Train: [273/300][1100/2502]	eta 0:12:24 lr 0.000015	time 0.5686 (0.5309)	loss 2.2937 (2.8030)	grad_norm 18.2262 (nan)	mem 8929MB
[2022-04-09 19:34:42 large] (main.py 226): INFO Train: [273/300][1200/2502]	eta 0:11:31 lr 0.000014	time 0.4955 (0.5310)	loss 3.0466 (2.8075)	grad_norm 7.8448 (nan)	mem 8929MB
[2022-04-09 19:35:34 large] (main.py 226): INFO Train: [273/300][1300/2502]	eta 0:10:37 lr 0.000014	time 0.4916 (0.5300)	loss 2.5905 (2.8026)	grad_norm 7.2865 (nan)	mem 8929MB
[2022-04-09 19:36:28 large] (main.py 226): INFO Train: [273/300][1400/2502]	eta 0:09:45 lr 0.000014	time 0.6169 (0.5309)	loss 3.5510 (2.8048)	grad_norm 9.3881 (nan)	mem 8929MB
[2022-04-09 19:37:22 large] (main.py 226): INFO Train: [273/300][1500/2502]	eta 0:08:52 lr 0.000014	time 0.5072 (0.5315)	loss 1.8965 (2.8070)	grad_norm 9.6201 (nan)	mem 8929MB
[2022-04-09 19:38:17 large] (main.py 226): INFO Train: [273/300][1600/2502]	eta 0:08:00 lr 0.000014	time 0.4549 (0.5324)	loss 3.0875 (2.8091)	grad_norm 7.8080 (nan)	mem 8929MB
[2022-04-09 19:39:12 large] (main.py 226): INFO Train: [273/300][1700/2502]	eta 0:07:07 lr 0.000014	time 0.5890 (0.5332)	loss 1.9747 (2.8065)	grad_norm 10.2440 (nan)	mem 8929MB
[2022-04-09 19:40:05 large] (main.py 226): INFO Train: [273/300][1800/2502]	eta 0:06:14 lr 0.000014	time 0.5913 (0.5331)	loss 1.6888 (2.8040)	grad_norm 8.3434 (nan)	mem 8929MB
[2022-04-09 19:40:57 large] (main.py 226): INFO Train: [273/300][1900/2502]	eta 0:05:20 lr 0.000014	time 0.4917 (0.5325)	loss 2.6472 (2.8047)	grad_norm 9.4770 (nan)	mem 8929MB
[2022-04-09 19:41:49 large] (main.py 226): INFO Train: [273/300][2000/2502]	eta 0:04:26 lr 0.000014	time 0.5326 (0.5318)	loss 3.0091 (2.8071)	grad_norm 42.8148 (nan)	mem 8929MB
[2022-04-09 19:42:42 large] (main.py 226): INFO Train: [273/300][2100/2502]	eta 0:03:33 lr 0.000014	time 0.5159 (0.5317)	loss 2.9851 (2.8050)	grad_norm 6.9399 (nan)	mem 8929MB
[2022-04-09 19:43:35 large] (main.py 226): INFO Train: [273/300][2200/2502]	eta 0:02:40 lr 0.000014	time 0.5158 (0.5316)	loss 3.0886 (2.8017)	grad_norm 8.1408 (nan)	mem 8929MB
[2022-04-09 19:44:28 large] (main.py 226): INFO Train: [273/300][2300/2502]	eta 0:01:47 lr 0.000014	time 0.4941 (0.5315)	loss 2.5634 (2.8040)	grad_norm 5.3506 (nan)	mem 8929MB
[2022-04-09 19:45:21 large] (main.py 226): INFO Train: [273/300][2400/2502]	eta 0:00:54 lr 0.000014	time 0.5289 (0.5315)	loss 3.1283 (2.8049)	grad_norm 6.9722 (nan)	mem 8929MB
[2022-04-09 19:46:14 large] (main.py 226): INFO Train: [273/300][2500/2502]	eta 0:00:01 lr 0.000014	time 0.5085 (0.5314)	loss 3.2526 (2.8065)	grad_norm 6.8481 (nan)	mem 8929MB
[2022-04-09 19:46:15 large] (main.py 233): INFO EPOCH 273 training takes 0:22:10
[2022-04-09 19:46:22 large] (main.py 273): INFO Test: [0/98]	Time 7.041 (7.041)	Loss 0.9300 (0.9300)	Acc@1 84.375 (84.375)	Acc@5 95.703 (95.703)	Mem 8929MB
[2022-04-09 19:46:47 large] (main.py 279): INFO  * Acc@1 81.670 Acc@5 95.624
[2022-04-09 19:46:47 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.7%
[2022-04-09 19:46:47 large] (main.py 148): INFO Max accuracy: 81.78%
[2022-04-09 19:46:54 large] (main.py 226): INFO Train: [274/300][0/2502]	eta 5:03:39 lr 0.000014	time 7.2819 (7.2819)	loss 3.0375 (3.0375)	grad_norm 8.1815 (8.1815)	mem 8929MB
[2022-04-09 19:47:45 large] (main.py 226): INFO Train: [274/300][100/2502]	eta 0:23:01 lr 0.000014	time 0.4801 (0.5750)	loss 2.8926 (2.8646)	grad_norm 7.2799 (9.9108)	mem 8929MB
[2022-04-09 19:48:35 large] (main.py 226): INFO Train: [274/300][200/2502]	eta 0:20:41 lr 0.000014	time 0.4998 (0.5392)	loss 3.3637 (2.8312)	grad_norm 7.8530 (9.9951)	mem 8929MB
[2022-04-09 19:49:25 large] (main.py 226): INFO Train: [274/300][300/2502]	eta 0:19:13 lr 0.000014	time 0.4898 (0.5238)	loss 2.6384 (2.8071)	grad_norm 14.9025 (9.7698)	mem 8929MB
[2022-04-09 19:50:17 large] (main.py 226): INFO Train: [274/300][400/2502]	eta 0:18:22 lr 0.000014	time 0.5829 (0.5244)	loss 2.7237 (2.8096)	grad_norm 7.1980 (9.7592)	mem 8929MB
[2022-04-09 19:51:11 large] (main.py 226): INFO Train: [274/300][500/2502]	eta 0:17:36 lr 0.000014	time 0.5191 (0.5278)	loss 2.9037 (2.8019)	grad_norm 8.3096 (9.7152)	mem 8929MB
[2022-04-09 19:52:05 large] (main.py 226): INFO Train: [274/300][600/2502]	eta 0:16:48 lr 0.000014	time 0.5303 (0.5302)	loss 2.5850 (2.8133)	grad_norm 34.4732 (9.8962)	mem 8929MB
[2022-04-09 19:53:00 large] (main.py 226): INFO Train: [274/300][700/2502]	eta 0:15:58 lr 0.000014	time 0.5957 (0.5321)	loss 2.5453 (2.8079)	grad_norm 7.1387 (9.9114)	mem 8929MB
[2022-04-09 19:53:53 large] (main.py 226): INFO Train: [274/300][800/2502]	eta 0:15:05 lr 0.000014	time 0.5214 (0.5321)	loss 2.2521 (2.8029)	grad_norm 11.6824 (9.8861)	mem 8929MB
[2022-04-09 19:54:46 large] (main.py 226): INFO Train: [274/300][900/2502]	eta 0:14:12 lr 0.000014	time 0.5056 (0.5323)	loss 2.5209 (2.7966)	grad_norm 10.8236 (9.9043)	mem 8929MB
[2022-04-09 19:55:39 large] (main.py 226): INFO Train: [274/300][1000/2502]	eta 0:13:18 lr 0.000014	time 0.5284 (0.5319)	loss 2.6211 (2.7954)	grad_norm 7.6601 (9.8472)	mem 8929MB
[2022-04-09 19:56:29 large] (main.py 226): INFO Train: [274/300][1100/2502]	eta 0:12:21 lr 0.000014	time 0.5189 (0.5286)	loss 3.1327 (2.7961)	grad_norm 14.3731 (9.8580)	mem 8929MB
[2022-04-09 19:57:21 large] (main.py 226): INFO Train: [274/300][1200/2502]	eta 0:11:27 lr 0.000014	time 0.5270 (0.5283)	loss 2.7809 (2.8024)	grad_norm 9.7101 (9.8804)	mem 8929MB
[2022-04-09 19:58:14 large] (main.py 226): INFO Train: [274/300][1300/2502]	eta 0:10:35 lr 0.000014	time 0.5582 (0.5283)	loss 3.0261 (2.8043)	grad_norm 8.9930 (9.8576)	mem 8929MB
[2022-04-09 19:59:07 large] (main.py 226): INFO Train: [274/300][1400/2502]	eta 0:09:42 lr 0.000014	time 0.5067 (0.5284)	loss 2.7297 (2.8027)	grad_norm 7.3304 (9.8955)	mem 8929MB
[2022-04-09 20:00:01 large] (main.py 226): INFO Train: [274/300][1500/2502]	eta 0:08:50 lr 0.000014	time 0.6087 (0.5290)	loss 2.2005 (2.8020)	grad_norm 7.3763 (9.8800)	mem 8929MB
[2022-04-09 20:00:53 large] (main.py 226): INFO Train: [274/300][1600/2502]	eta 0:07:56 lr 0.000014	time 0.5117 (0.5288)	loss 3.4224 (2.8013)	grad_norm 19.5544 (9.8753)	mem 8929MB
[2022-04-09 20:01:47 large] (main.py 226): INFO Train: [274/300][1700/2502]	eta 0:07:04 lr 0.000014	time 0.5200 (0.5293)	loss 1.9416 (2.8039)	grad_norm 11.5347 (9.9128)	mem 8929MB
[2022-04-09 20:02:39 large] (main.py 226): INFO Train: [274/300][1800/2502]	eta 0:06:11 lr 0.000014	time 0.4955 (0.5289)	loss 2.8506 (2.7984)	grad_norm 9.3163 (9.9012)	mem 8929MB
[2022-04-09 20:03:30 large] (main.py 226): INFO Train: [274/300][1900/2502]	eta 0:05:17 lr 0.000014	time 0.4974 (0.5277)	loss 2.2134 (2.7983)	grad_norm 11.3546 (10.0057)	mem 8929MB
[2022-04-09 20:04:20 large] (main.py 226): INFO Train: [274/300][2000/2502]	eta 0:04:24 lr 0.000014	time 0.5022 (0.5264)	loss 2.7910 (2.8011)	grad_norm 8.7529 (10.0195)	mem 8929MB
[2022-04-09 20:05:13 large] (main.py 226): INFO Train: [274/300][2100/2502]	eta 0:03:31 lr 0.000014	time 0.5142 (0.5266)	loss 2.7259 (2.8030)	grad_norm 6.4544 (10.0015)	mem 8929MB
[2022-04-09 20:06:07 large] (main.py 226): INFO Train: [274/300][2200/2502]	eta 0:02:39 lr 0.000014	time 0.5164 (0.5271)	loss 2.9938 (2.8042)	grad_norm 14.3454 (9.9719)	mem 8929MB
[2022-04-09 20:07:01 large] (main.py 226): INFO Train: [274/300][2300/2502]	eta 0:01:46 lr 0.000013	time 0.5151 (0.5275)	loss 2.8701 (2.8001)	grad_norm 7.9264 (9.9923)	mem 8929MB
[2022-04-09 20:07:51 large] (main.py 226): INFO Train: [274/300][2400/2502]	eta 0:00:53 lr 0.000013	time 0.4957 (0.5267)	loss 3.1238 (2.7964)	grad_norm 10.1025 (10.1397)	mem 8929MB
[2022-04-09 20:08:41 large] (main.py 226): INFO Train: [274/300][2500/2502]	eta 0:00:01 lr 0.000013	time 0.5069 (0.5256)	loss 2.5745 (2.7956)	grad_norm 8.0838 (10.1250)	mem 8929MB
[2022-04-09 20:08:42 large] (main.py 233): INFO EPOCH 274 training takes 0:21:55
[2022-04-09 20:08:49 large] (main.py 273): INFO Test: [0/98]	Time 6.486 (6.486)	Loss 0.8299 (0.8299)	Acc@1 83.984 (83.984)	Acc@5 95.898 (95.898)	Mem 8929MB
[2022-04-09 20:09:15 large] (main.py 279): INFO  * Acc@1 81.782 Acc@5 95.584
[2022-04-09 20:09:15 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.8%
[2022-04-09 20:09:15 large] (utils.py 57): INFO output/large/default/ckpt_epoch_274.pth saving......
[2022-04-09 20:09:15 large] (utils.py 59): INFO output/large/default/ckpt_epoch_274.pth saved !!!
[2022-04-09 20:09:15 large] (main.py 148): INFO Max accuracy: 81.78%
[2022-04-09 20:09:23 large] (main.py 226): INFO Train: [275/300][0/2502]	eta 5:20:06 lr 0.000013	time 7.6766 (7.6766)	loss 2.6117 (2.6117)	grad_norm 7.7694 (7.7694)	mem 8929MB
[2022-04-09 20:10:13 large] (main.py 226): INFO Train: [275/300][100/2502]	eta 0:22:36 lr 0.000013	time 0.5171 (0.5649)	loss 2.8916 (2.7986)	grad_norm 7.6392 (9.9384)	mem 8929MB
[2022-04-09 20:11:02 large] (main.py 226): INFO Train: [275/300][200/2502]	eta 0:20:16 lr 0.000013	time 0.4860 (0.5285)	loss 2.5559 (2.7932)	grad_norm 6.5262 (9.8791)	mem 8929MB
[2022-04-09 20:11:52 large] (main.py 226): INFO Train: [275/300][300/2502]	eta 0:19:02 lr 0.000013	time 0.5594 (0.5187)	loss 2.8193 (2.7883)	grad_norm 10.6044 (9.9332)	mem 8929MB
[2022-04-09 20:12:45 large] (main.py 226): INFO Train: [275/300][400/2502]	eta 0:18:19 lr 0.000013	time 0.5840 (0.5229)	loss 2.7304 (2.7905)	grad_norm 8.7357 (10.0637)	mem 8929MB
[2022-04-09 20:13:40 large] (main.py 226): INFO Train: [275/300][500/2502]	eta 0:17:36 lr 0.000013	time 0.5298 (0.5277)	loss 3.1893 (2.7911)	grad_norm 8.6229 (nan)	mem 8929MB
[2022-04-09 20:14:35 large] (main.py 226): INFO Train: [275/300][600/2502]	eta 0:16:50 lr 0.000013	time 0.5349 (0.5314)	loss 2.7039 (2.7902)	grad_norm 6.7157 (nan)	mem 8929MB
[2022-04-09 20:15:29 large] (main.py 226): INFO Train: [275/300][700/2502]	eta 0:15:59 lr 0.000013	time 0.4966 (0.5322)	loss 2.6153 (2.7990)	grad_norm 7.8909 (nan)	mem 8929MB
[2022-04-09 20:16:22 large] (main.py 226): INFO Train: [275/300][800/2502]	eta 0:15:06 lr 0.000013	time 0.5521 (0.5323)	loss 3.1024 (2.8054)	grad_norm 17.2201 (nan)	mem 8929MB
[2022-04-09 20:17:14 large] (main.py 226): INFO Train: [275/300][900/2502]	eta 0:14:10 lr 0.000013	time 0.5016 (0.5309)	loss 3.0486 (2.8045)	grad_norm 6.5172 (nan)	mem 8929MB
[2022-04-09 20:18:05 large] (main.py 226): INFO Train: [275/300][1000/2502]	eta 0:13:14 lr 0.000013	time 0.4512 (0.5290)	loss 2.1815 (2.8049)	grad_norm 12.2428 (nan)	mem 8929MB
[2022-04-09 20:18:56 large] (main.py 226): INFO Train: [275/300][1100/2502]	eta 0:12:18 lr 0.000013	time 0.5112 (0.5270)	loss 3.0573 (2.8015)	grad_norm 9.9853 (nan)	mem 8929MB
[2022-04-09 20:19:49 large] (main.py 226): INFO Train: [275/300][1200/2502]	eta 0:11:26 lr 0.000013	time 0.5120 (0.5273)	loss 2.9458 (2.8056)	grad_norm 9.8975 (nan)	mem 8929MB
[2022-04-09 20:20:42 large] (main.py 226): INFO Train: [275/300][1300/2502]	eta 0:10:34 lr 0.000013	time 0.5653 (0.5275)	loss 2.8666 (2.8093)	grad_norm 8.3836 (nan)	mem 8929MB
[2022-04-09 20:21:35 large] (main.py 226): INFO Train: [275/300][1400/2502]	eta 0:09:41 lr 0.000013	time 0.5344 (0.5276)	loss 3.0945 (2.8146)	grad_norm 14.1189 (nan)	mem 8929MB
[2022-04-09 20:22:27 large] (main.py 226): INFO Train: [275/300][1500/2502]	eta 0:08:48 lr 0.000013	time 0.5593 (0.5276)	loss 2.7218 (2.8160)	grad_norm 10.0303 (nan)	mem 8929MB
[2022-04-09 20:23:21 large] (main.py 226): INFO Train: [275/300][1600/2502]	eta 0:07:56 lr 0.000013	time 0.4985 (0.5282)	loss 3.1243 (2.8107)	grad_norm 9.3614 (nan)	mem 8929MB
[2022-04-09 20:24:13 large] (main.py 226): INFO Train: [275/300][1700/2502]	eta 0:07:03 lr 0.000013	time 0.5567 (0.5278)	loss 3.0635 (2.8156)	grad_norm 13.3404 (nan)	mem 8929MB
[2022-04-09 20:25:06 large] (main.py 226): INFO Train: [275/300][1800/2502]	eta 0:06:10 lr 0.000013	time 0.5166 (0.5279)	loss 3.1385 (2.8165)	grad_norm 8.0433 (nan)	mem 8929MB
[2022-04-09 20:25:59 large] (main.py 226): INFO Train: [275/300][1900/2502]	eta 0:05:17 lr 0.000013	time 0.5287 (0.5277)	loss 2.3070 (2.8132)	grad_norm 7.3261 (nan)	mem 8929MB
[2022-04-09 20:26:51 large] (main.py 226): INFO Train: [275/300][2000/2502]	eta 0:04:24 lr 0.000013	time 0.5343 (0.5277)	loss 3.0706 (2.8132)	grad_norm 19.8381 (nan)	mem 8929MB
[2022-04-09 20:27:44 large] (main.py 226): INFO Train: [275/300][2100/2502]	eta 0:03:32 lr 0.000013	time 0.5127 (0.5277)	loss 2.8386 (2.8149)	grad_norm 8.9643 (nan)	mem 8929MB
[2022-04-09 20:28:36 large] (main.py 226): INFO Train: [275/300][2200/2502]	eta 0:02:39 lr 0.000013	time 0.4921 (0.5274)	loss 2.9599 (2.8175)	grad_norm 8.7101 (nan)	mem 8929MB
[2022-04-09 20:29:30 large] (main.py 226): INFO Train: [275/300][2300/2502]	eta 0:01:46 lr 0.000013	time 0.5074 (0.5277)	loss 3.3955 (2.8143)	grad_norm 11.9639 (nan)	mem 8929MB
[2022-04-09 20:30:21 large] (main.py 226): INFO Train: [275/300][2400/2502]	eta 0:00:53 lr 0.000013	time 0.4875 (0.5272)	loss 2.8861 (2.8126)	grad_norm 8.0144 (nan)	mem 8929MB
[2022-04-09 20:31:13 large] (main.py 226): INFO Train: [275/300][2500/2502]	eta 0:00:01 lr 0.000013	time 0.5096 (0.5267)	loss 3.0949 (2.8128)	grad_norm 9.2755 (nan)	mem 8929MB
[2022-04-09 20:31:14 large] (main.py 233): INFO EPOCH 275 training takes 0:21:58
[2022-04-09 20:31:20 large] (main.py 273): INFO Test: [0/98]	Time 6.094 (6.094)	Loss 0.9767 (0.9767)	Acc@1 81.055 (81.055)	Acc@5 95.312 (95.312)	Mem 8929MB
[2022-04-09 20:31:46 large] (main.py 279): INFO  * Acc@1 81.724 Acc@5 95.602
[2022-04-09 20:31:46 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.7%
[2022-04-09 20:31:46 large] (main.py 148): INFO Max accuracy: 81.78%
[2022-04-09 20:31:53 large] (main.py 226): INFO Train: [276/300][0/2502]	eta 5:15:45 lr 0.000013	time 7.5722 (7.5722)	loss 3.3058 (3.3058)	grad_norm 8.7260 (8.7260)	mem 8929MB
[2022-04-09 20:32:44 large] (main.py 226): INFO Train: [276/300][100/2502]	eta 0:23:07 lr 0.000013	time 0.4802 (0.5776)	loss 3.3799 (2.8950)	grad_norm 10.1039 (9.9410)	mem 8929MB
[2022-04-09 20:33:33 large] (main.py 226): INFO Train: [276/300][200/2502]	eta 0:20:32 lr 0.000013	time 0.5230 (0.5355)	loss 2.9448 (2.8313)	grad_norm 8.1661 (9.7526)	mem 8929MB
[2022-04-09 20:34:27 large] (main.py 226): INFO Train: [276/300][300/2502]	eta 0:19:37 lr 0.000013	time 0.5313 (0.5346)	loss 2.9615 (2.8211)	grad_norm 8.6075 (9.9229)	mem 8929MB
[2022-04-09 20:35:20 large] (main.py 226): INFO Train: [276/300][400/2502]	eta 0:18:44 lr 0.000013	time 0.5720 (0.5350)	loss 3.4074 (2.8053)	grad_norm 9.8837 (9.8953)	mem 8929MB
[2022-04-09 20:36:14 large] (main.py 226): INFO Train: [276/300][500/2502]	eta 0:17:50 lr 0.000013	time 0.5443 (0.5349)	loss 2.9917 (2.8171)	grad_norm 9.1031 (10.0236)	mem 8929MB
[2022-04-09 20:37:07 large] (main.py 226): INFO Train: [276/300][600/2502]	eta 0:16:57 lr 0.000013	time 0.5143 (0.5351)	loss 3.2120 (2.8235)	grad_norm 8.3152 (9.9410)	mem 8929MB
[2022-04-09 20:38:01 large] (main.py 226): INFO Train: [276/300][700/2502]	eta 0:16:04 lr 0.000013	time 0.5856 (0.5354)	loss 3.0516 (2.8204)	grad_norm 9.8954 (9.8529)	mem 8929MB
[2022-04-09 20:38:55 large] (main.py 226): INFO Train: [276/300][800/2502]	eta 0:15:11 lr 0.000013	time 0.5060 (0.5354)	loss 3.2315 (2.8114)	grad_norm 11.2673 (9.9078)	mem 8929MB
[2022-04-09 20:39:47 large] (main.py 226): INFO Train: [276/300][900/2502]	eta 0:14:16 lr 0.000013	time 0.5190 (0.5345)	loss 2.8131 (2.8016)	grad_norm 9.3415 (10.0181)	mem 8929MB
[2022-04-09 20:40:41 large] (main.py 226): INFO Train: [276/300][1000/2502]	eta 0:13:23 lr 0.000013	time 0.5929 (0.5347)	loss 3.1206 (2.7951)	grad_norm 20.4276 (10.0745)	mem 8929MB
[2022-04-09 20:41:34 large] (main.py 226): INFO Train: [276/300][1100/2502]	eta 0:12:29 lr 0.000012	time 0.5268 (0.5342)	loss 2.9359 (2.7956)	grad_norm 9.0475 (10.0856)	mem 8929MB
[2022-04-09 20:42:26 large] (main.py 226): INFO Train: [276/300][1200/2502]	eta 0:11:34 lr 0.000012	time 0.5065 (0.5335)	loss 2.7948 (2.7983)	grad_norm 8.8944 (10.0198)	mem 8929MB
[2022-04-09 20:43:19 large] (main.py 226): INFO Train: [276/300][1300/2502]	eta 0:10:40 lr 0.000012	time 0.4729 (0.5330)	loss 3.0056 (2.8000)	grad_norm 9.9394 (9.9886)	mem 8929MB
[2022-04-09 20:44:07 large] (main.py 226): INFO Train: [276/300][1400/2502]	eta 0:09:43 lr 0.000012	time 0.4733 (0.5295)	loss 3.1368 (2.8035)	grad_norm 9.3777 (10.0205)	mem 8929MB
[2022-04-09 20:44:57 large] (main.py 226): INFO Train: [276/300][1500/2502]	eta 0:08:48 lr 0.000012	time 0.4864 (0.5271)	loss 1.9517 (2.8065)	grad_norm 16.9866 (10.0595)	mem 8929MB
[2022-04-09 20:45:48 large] (main.py 226): INFO Train: [276/300][1600/2502]	eta 0:07:54 lr 0.000012	time 0.5180 (0.5260)	loss 3.1415 (2.8005)	grad_norm 7.7730 (10.0904)	mem 8929MB
[2022-04-09 20:46:41 large] (main.py 226): INFO Train: [276/300][1700/2502]	eta 0:07:02 lr 0.000012	time 0.5394 (0.5263)	loss 2.8066 (2.8015)	grad_norm 12.5796 (nan)	mem 8929MB
[2022-04-09 20:47:34 large] (main.py 226): INFO Train: [276/300][1800/2502]	eta 0:06:09 lr 0.000012	time 0.4652 (0.5268)	loss 1.9629 (2.7998)	grad_norm 8.4644 (nan)	mem 8929MB
[2022-04-09 20:48:27 large] (main.py 226): INFO Train: [276/300][1900/2502]	eta 0:05:17 lr 0.000012	time 0.5344 (0.5269)	loss 2.7469 (2.8026)	grad_norm 9.8112 (nan)	mem 8929MB
[2022-04-09 20:49:21 large] (main.py 226): INFO Train: [276/300][2000/2502]	eta 0:04:24 lr 0.000012	time 0.5224 (0.5273)	loss 2.0247 (2.8040)	grad_norm 8.1814 (nan)	mem 8929MB
[2022-04-09 20:50:14 large] (main.py 226): INFO Train: [276/300][2100/2502]	eta 0:03:32 lr 0.000012	time 0.5641 (0.5274)	loss 3.0976 (2.8044)	grad_norm 7.0121 (nan)	mem 8929MB
[2022-04-09 20:51:05 large] (main.py 226): INFO Train: [276/300][2200/2502]	eta 0:02:39 lr 0.000012	time 0.5528 (0.5269)	loss 2.2223 (2.8082)	grad_norm 6.8563 (nan)	mem 8929MB
[2022-04-09 20:51:57 large] (main.py 226): INFO Train: [276/300][2300/2502]	eta 0:01:46 lr 0.000012	time 0.4886 (0.5263)	loss 3.5054 (2.8076)	grad_norm 9.5511 (nan)	mem 8929MB
[2022-04-09 20:52:49 large] (main.py 226): INFO Train: [276/300][2400/2502]	eta 0:00:53 lr 0.000012	time 0.5332 (0.5263)	loss 3.5780 (2.8088)	grad_norm 8.2111 (nan)	mem 8929MB
[2022-04-09 20:53:42 large] (main.py 226): INFO Train: [276/300][2500/2502]	eta 0:00:01 lr 0.000012	time 0.5081 (0.5262)	loss 3.3238 (2.8103)	grad_norm 9.8326 (nan)	mem 8929MB
[2022-04-09 20:53:43 large] (main.py 233): INFO EPOCH 276 training takes 0:21:57
[2022-04-09 20:53:50 large] (main.py 273): INFO Test: [0/98]	Time 7.092 (7.092)	Loss 1.0243 (1.0243)	Acc@1 82.031 (82.031)	Acc@5 94.336 (94.336)	Mem 8929MB
[2022-04-09 20:54:15 large] (main.py 279): INFO  * Acc@1 81.706 Acc@5 95.634
[2022-04-09 20:54:15 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.7%
[2022-04-09 20:54:15 large] (main.py 148): INFO Max accuracy: 81.78%
[2022-04-09 20:54:22 large] (main.py 226): INFO Train: [277/300][0/2502]	eta 5:07:37 lr 0.000012	time 7.3769 (7.3769)	loss 2.0132 (2.0132)	grad_norm 16.1318 (16.1318)	mem 8929MB
[2022-04-09 20:55:13 large] (main.py 226): INFO Train: [277/300][100/2502]	eta 0:22:53 lr 0.000012	time 0.5327 (0.5719)	loss 2.9655 (2.8576)	grad_norm 9.8513 (9.7158)	mem 8929MB
[2022-04-09 20:56:06 large] (main.py 226): INFO Train: [277/300][200/2502]	eta 0:21:05 lr 0.000012	time 0.5973 (0.5496)	loss 3.0172 (2.8287)	grad_norm 14.0782 (9.6753)	mem 8929MB
[2022-04-09 20:56:58 large] (main.py 226): INFO Train: [277/300][300/2502]	eta 0:19:54 lr 0.000012	time 0.4956 (0.5425)	loss 1.9255 (2.8315)	grad_norm 8.8301 (9.8631)	mem 8929MB
[2022-04-09 20:57:49 large] (main.py 226): INFO Train: [277/300][400/2502]	eta 0:18:41 lr 0.000012	time 0.5679 (0.5335)	loss 2.4639 (2.8476)	grad_norm 7.7131 (9.7674)	mem 8929MB
[2022-04-09 20:58:43 large] (main.py 226): INFO Train: [277/300][500/2502]	eta 0:17:49 lr 0.000012	time 0.6101 (0.5341)	loss 3.0590 (2.8392)	grad_norm 7.9197 (9.7313)	mem 8929MB
[2022-04-09 20:59:33 large] (main.py 226): INFO Train: [277/300][600/2502]	eta 0:16:47 lr 0.000012	time 0.5129 (0.5295)	loss 2.1362 (2.8489)	grad_norm 9.3225 (9.8284)	mem 8929MB
[2022-04-09 21:00:26 large] (main.py 226): INFO Train: [277/300][700/2502]	eta 0:15:53 lr 0.000012	time 0.5284 (0.5291)	loss 3.2820 (2.8428)	grad_norm 8.5015 (9.8612)	mem 8929MB
[2022-04-09 21:01:19 large] (main.py 226): INFO Train: [277/300][800/2502]	eta 0:15:01 lr 0.000012	time 0.5008 (0.5298)	loss 2.8382 (2.8438)	grad_norm 8.2331 (9.9638)	mem 8929MB
[2022-04-09 21:02:08 large] (main.py 226): INFO Train: [277/300][900/2502]	eta 0:14:01 lr 0.000012	time 0.4938 (0.5251)	loss 2.4586 (2.8369)	grad_norm 8.3249 (9.9432)	mem 8929MB
[2022-04-09 21:02:59 large] (main.py 226): INFO Train: [277/300][1000/2502]	eta 0:13:06 lr 0.000012	time 0.5043 (0.5238)	loss 2.3570 (2.8343)	grad_norm 8.9595 (10.0532)	mem 8929MB
[2022-04-09 21:03:52 large] (main.py 226): INFO Train: [277/300][1100/2502]	eta 0:12:15 lr 0.000012	time 0.5183 (0.5243)	loss 2.3334 (2.8367)	grad_norm 11.1739 (10.0121)	mem 8929MB
[2022-04-09 21:04:45 large] (main.py 226): INFO Train: [277/300][1200/2502]	eta 0:11:23 lr 0.000012	time 0.5279 (0.5249)	loss 2.6960 (2.8347)	grad_norm 9.6456 (10.0346)	mem 8929MB
[2022-04-09 21:05:38 large] (main.py 226): INFO Train: [277/300][1300/2502]	eta 0:10:30 lr 0.000012	time 0.5858 (0.5247)	loss 2.1392 (2.8347)	grad_norm 12.5362 (10.0543)	mem 8929MB
[2022-04-09 21:06:28 large] (main.py 226): INFO Train: [277/300][1400/2502]	eta 0:09:36 lr 0.000012	time 0.5143 (0.5232)	loss 2.2461 (2.8366)	grad_norm 7.2761 (10.1401)	mem 8929MB
[2022-04-09 21:07:18 large] (main.py 226): INFO Train: [277/300][1500/2502]	eta 0:08:42 lr 0.000012	time 0.4742 (0.5215)	loss 3.5854 (2.8296)	grad_norm 12.1577 (10.1550)	mem 8929MB
[2022-04-09 21:08:07 large] (main.py 226): INFO Train: [277/300][1600/2502]	eta 0:07:48 lr 0.000012	time 0.5048 (0.5194)	loss 2.5233 (2.8287)	grad_norm 9.7533 (10.1293)	mem 8929MB
[2022-04-09 21:08:56 large] (main.py 226): INFO Train: [277/300][1700/2502]	eta 0:06:55 lr 0.000012	time 0.4976 (0.5180)	loss 3.2140 (2.8295)	grad_norm 7.3450 (10.1097)	mem 8929MB
[2022-04-09 21:09:49 large] (main.py 226): INFO Train: [277/300][1800/2502]	eta 0:06:03 lr 0.000012	time 0.5131 (0.5185)	loss 2.0430 (2.8287)	grad_norm 11.9009 (10.0558)	mem 8929MB
[2022-04-09 21:10:41 large] (main.py 226): INFO Train: [277/300][1900/2502]	eta 0:05:12 lr 0.000012	time 0.4877 (0.5186)	loss 2.9205 (2.8259)	grad_norm 10.5844 (10.0549)	mem 8929MB
[2022-04-09 21:11:30 large] (main.py 226): INFO Train: [277/300][2000/2502]	eta 0:04:19 lr 0.000012	time 0.5028 (0.5173)	loss 2.3359 (2.8236)	grad_norm 10.6871 (10.0592)	mem 8929MB
[2022-04-09 21:12:22 large] (main.py 226): INFO Train: [277/300][2100/2502]	eta 0:03:28 lr 0.000012	time 0.5539 (0.5174)	loss 3.0812 (2.8227)	grad_norm 8.3111 (10.0455)	mem 8929MB
[2022-04-09 21:13:16 large] (main.py 226): INFO Train: [277/300][2200/2502]	eta 0:02:36 lr 0.000012	time 0.5535 (0.5183)	loss 3.3396 (2.8189)	grad_norm 12.0291 (10.0189)	mem 8929MB
[2022-04-09 21:14:06 large] (main.py 226): INFO Train: [277/300][2300/2502]	eta 0:01:44 lr 0.000012	time 0.5093 (0.5177)	loss 2.5540 (2.8173)	grad_norm 11.9124 (10.0632)	mem 8929MB
[2022-04-09 21:14:59 large] (main.py 226): INFO Train: [277/300][2400/2502]	eta 0:00:52 lr 0.000012	time 0.5120 (0.5180)	loss 2.1579 (2.8171)	grad_norm 8.8154 (10.0750)	mem 8929MB
[2022-04-09 21:15:51 large] (main.py 226): INFO Train: [277/300][2500/2502]	eta 0:00:01 lr 0.000012	time 0.4755 (0.5182)	loss 2.3435 (2.8176)	grad_norm 8.4335 (10.1140)	mem 8929MB
[2022-04-09 21:15:52 large] (main.py 233): INFO EPOCH 277 training takes 0:21:36
[2022-04-09 21:15:59 large] (main.py 273): INFO Test: [0/98]	Time 6.810 (6.810)	Loss 0.9244 (0.9244)	Acc@1 83.594 (83.594)	Acc@5 95.703 (95.703)	Mem 8929MB
[2022-04-09 21:16:24 large] (main.py 279): INFO  * Acc@1 81.816 Acc@5 95.666
[2022-04-09 21:16:24 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.8%
[2022-04-09 21:16:24 large] (utils.py 57): INFO output/large/default/ckpt_epoch_277.pth saving......
[2022-04-09 21:16:25 large] (utils.py 59): INFO output/large/default/ckpt_epoch_277.pth saved !!!
[2022-04-09 21:16:25 large] (main.py 148): INFO Max accuracy: 81.82%
[2022-04-09 21:16:33 large] (main.py 226): INFO Train: [278/300][0/2502]	eta 5:09:49 lr 0.000012	time 7.4298 (7.4298)	loss 2.9693 (2.9693)	grad_norm 7.3916 (7.3916)	mem 8929MB
[2022-04-09 21:17:23 large] (main.py 226): INFO Train: [278/300][100/2502]	eta 0:22:54 lr 0.000012	time 0.5205 (0.5721)	loss 2.1499 (2.7900)	grad_norm 10.9583 (9.9352)	mem 8929MB
[2022-04-09 21:18:16 large] (main.py 226): INFO Train: [278/300][200/2502]	eta 0:21:05 lr 0.000011	time 0.5117 (0.5497)	loss 3.2043 (2.8051)	grad_norm 9.5808 (10.0636)	mem 8929MB
[2022-04-09 21:19:09 large] (main.py 226): INFO Train: [278/300][300/2502]	eta 0:19:55 lr 0.000011	time 0.4887 (0.5428)	loss 1.6975 (2.8095)	grad_norm 10.6165 (10.1780)	mem 8929MB
[2022-04-09 21:20:02 large] (main.py 226): INFO Train: [278/300][400/2502]	eta 0:18:55 lr 0.000011	time 0.5560 (0.5403)	loss 3.2195 (2.8015)	grad_norm 15.1630 (10.2504)	mem 8929MB
[2022-04-09 21:20:52 large] (main.py 226): INFO Train: [278/300][500/2502]	eta 0:17:47 lr 0.000011	time 0.5486 (0.5331)	loss 1.6991 (2.7833)	grad_norm 7.6102 (10.0414)	mem 8929MB
[2022-04-09 21:21:43 large] (main.py 226): INFO Train: [278/300][600/2502]	eta 0:16:44 lr 0.000011	time 0.5150 (0.5281)	loss 2.7092 (2.7802)	grad_norm 11.7495 (10.0855)	mem 8929MB
[2022-04-09 21:22:31 large] (main.py 226): INFO Train: [278/300][700/2502]	eta 0:15:41 lr 0.000011	time 0.4991 (0.5224)	loss 3.0002 (2.7877)	grad_norm 8.4306 (10.0496)	mem 8929MB
[2022-04-09 21:23:23 large] (main.py 226): INFO Train: [278/300][800/2502]	eta 0:14:47 lr 0.000011	time 0.6069 (0.5216)	loss 2.8593 (2.7786)	grad_norm 13.8605 (10.0125)	mem 8929MB
[2022-04-09 21:24:16 large] (main.py 226): INFO Train: [278/300][900/2502]	eta 0:13:57 lr 0.000011	time 0.5018 (0.5225)	loss 2.7648 (2.7849)	grad_norm 9.9190 (9.9836)	mem 8929MB
[2022-04-09 21:25:09 large] (main.py 226): INFO Train: [278/300][1000/2502]	eta 0:13:05 lr 0.000011	time 0.5483 (0.5231)	loss 2.8267 (2.7821)	grad_norm 9.6000 (10.0366)	mem 8929MB
[2022-04-09 21:26:02 large] (main.py 226): INFO Train: [278/300][1100/2502]	eta 0:12:13 lr 0.000011	time 0.5289 (0.5235)	loss 3.1911 (2.7898)	grad_norm 8.8300 (10.0408)	mem 8929MB
[2022-04-09 21:26:55 large] (main.py 226): INFO Train: [278/300][1200/2502]	eta 0:11:22 lr 0.000011	time 0.5222 (0.5243)	loss 3.1323 (2.7942)	grad_norm 8.7756 (10.0640)	mem 8929MB
[2022-04-09 21:27:47 large] (main.py 226): INFO Train: [278/300][1300/2502]	eta 0:10:30 lr 0.000011	time 0.5218 (0.5242)	loss 2.3667 (2.7964)	grad_norm 8.2334 (9.9744)	mem 8929MB
[2022-04-09 21:28:40 large] (main.py 226): INFO Train: [278/300][1400/2502]	eta 0:09:38 lr 0.000011	time 0.5041 (0.5247)	loss 1.8943 (2.7912)	grad_norm 9.0480 (9.9568)	mem 8929MB
[2022-04-09 21:29:33 large] (main.py 226): INFO Train: [278/300][1500/2502]	eta 0:08:45 lr 0.000011	time 0.5014 (0.5246)	loss 2.6125 (2.7947)	grad_norm 8.8117 (9.9548)	mem 8929MB
[2022-04-09 21:30:23 large] (main.py 226): INFO Train: [278/300][1600/2502]	eta 0:07:52 lr 0.000011	time 0.4907 (0.5234)	loss 1.7818 (2.7941)	grad_norm 7.0378 (9.9603)	mem 8929MB
[2022-04-09 21:31:15 large] (main.py 226): INFO Train: [278/300][1700/2502]	eta 0:06:59 lr 0.000011	time 0.5343 (0.5233)	loss 2.9625 (2.7984)	grad_norm 8.5734 (9.9272)	mem 8929MB
[2022-04-09 21:32:07 large] (main.py 226): INFO Train: [278/300][1800/2502]	eta 0:06:07 lr 0.000011	time 0.5114 (0.5232)	loss 2.2616 (2.7966)	grad_norm 7.8462 (9.9013)	mem 8929MB
[2022-04-09 21:32:59 large] (main.py 226): INFO Train: [278/300][1900/2502]	eta 0:05:14 lr 0.000011	time 0.4994 (0.5226)	loss 3.2176 (2.7963)	grad_norm 6.5693 (9.8766)	mem 8929MB
[2022-04-09 21:33:50 large] (main.py 226): INFO Train: [278/300][2000/2502]	eta 0:04:22 lr 0.000011	time 0.5227 (0.5222)	loss 3.0892 (2.7924)	grad_norm 7.7816 (9.8552)	mem 8929MB
[2022-04-09 21:34:42 large] (main.py 226): INFO Train: [278/300][2100/2502]	eta 0:03:29 lr 0.000011	time 0.5181 (0.5221)	loss 3.1458 (2.7947)	grad_norm 10.4724 (9.8293)	mem 8929MB
[2022-04-09 21:35:34 large] (main.py 226): INFO Train: [278/300][2200/2502]	eta 0:02:37 lr 0.000011	time 0.4595 (0.5221)	loss 2.9512 (2.7941)	grad_norm 6.9121 (9.8323)	mem 8929MB
[2022-04-09 21:36:24 large] (main.py 226): INFO Train: [278/300][2300/2502]	eta 0:01:45 lr 0.000011	time 0.4885 (0.5209)	loss 3.1571 (2.7955)	grad_norm 9.7796 (9.8572)	mem 8929MB
[2022-04-09 21:37:16 large] (main.py 226): INFO Train: [278/300][2400/2502]	eta 0:00:53 lr 0.000011	time 0.4937 (0.5208)	loss 2.6700 (2.7959)	grad_norm 8.3326 (9.8370)	mem 8929MB
[2022-04-09 21:38:06 large] (main.py 226): INFO Train: [278/300][2500/2502]	eta 0:00:01 lr 0.000011	time 0.4817 (0.5201)	loss 2.8566 (2.7967)	grad_norm 7.9639 (9.8478)	mem 8929MB
[2022-04-09 21:38:07 large] (main.py 233): INFO EPOCH 278 training takes 0:21:41
[2022-04-09 21:38:14 large] (main.py 273): INFO Test: [0/98]	Time 6.448 (6.448)	Loss 0.9160 (0.9160)	Acc@1 82.422 (82.422)	Acc@5 96.875 (96.875)	Mem 8929MB
[2022-04-09 21:38:40 large] (main.py 279): INFO  * Acc@1 81.706 Acc@5 95.622
[2022-04-09 21:38:40 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.7%
[2022-04-09 21:38:40 large] (main.py 148): INFO Max accuracy: 81.82%
[2022-04-09 21:38:47 large] (main.py 226): INFO Train: [279/300][0/2502]	eta 5:05:19 lr 0.000011	time 7.3219 (7.3219)	loss 3.4289 (3.4289)	grad_norm 7.5231 (7.5231)	mem 8929MB
[2022-04-09 21:39:38 large] (main.py 226): INFO Train: [279/300][100/2502]	eta 0:23:15 lr 0.000011	time 0.4948 (0.5808)	loss 2.6933 (2.7805)	grad_norm 6.8200 (9.5509)	mem 8929MB
[2022-04-09 21:40:31 large] (main.py 226): INFO Train: [279/300][200/2502]	eta 0:21:11 lr 0.000011	time 0.5226 (0.5524)	loss 2.0657 (2.7845)	grad_norm 9.4536 (9.9550)	mem 8929MB
[2022-04-09 21:41:22 large] (main.py 226): INFO Train: [279/300][300/2502]	eta 0:19:49 lr 0.000011	time 0.4859 (0.5402)	loss 2.0345 (2.7704)	grad_norm 7.9974 (nan)	mem 8929MB
[2022-04-09 21:42:12 large] (main.py 226): INFO Train: [279/300][400/2502]	eta 0:18:33 lr 0.000011	time 0.5095 (0.5299)	loss 2.6853 (2.7746)	grad_norm 8.3098 (nan)	mem 8929MB
[2022-04-09 21:43:05 large] (main.py 226): INFO Train: [279/300][500/2502]	eta 0:17:40 lr 0.000011	time 0.5613 (0.5297)	loss 3.0155 (2.7863)	grad_norm 9.6808 (nan)	mem 8929MB
[2022-04-09 21:43:58 large] (main.py 226): INFO Train: [279/300][600/2502]	eta 0:16:47 lr 0.000011	time 0.5541 (0.5296)	loss 3.2284 (2.7901)	grad_norm 9.8344 (nan)	mem 8929MB
[2022-04-09 21:44:51 large] (main.py 226): INFO Train: [279/300][700/2502]	eta 0:15:55 lr 0.000011	time 0.5384 (0.5303)	loss 3.4398 (2.7884)	grad_norm 11.1932 (nan)	mem 8929MB
[2022-04-09 21:45:43 large] (main.py 226): INFO Train: [279/300][800/2502]	eta 0:15:00 lr 0.000011	time 0.5234 (0.5292)	loss 2.1674 (2.7817)	grad_norm 7.1807 (nan)	mem 8929MB
[2022-04-09 21:46:35 large] (main.py 226): INFO Train: [279/300][900/2502]	eta 0:14:06 lr 0.000011	time 0.4811 (0.5281)	loss 3.0619 (2.7766)	grad_norm 19.8292 (nan)	mem 8929MB
[2022-04-09 21:47:25 large] (main.py 226): INFO Train: [279/300][1000/2502]	eta 0:13:08 lr 0.000011	time 0.4565 (0.5247)	loss 3.1032 (2.7778)	grad_norm 10.2007 (nan)	mem 8929MB
[2022-04-09 21:48:16 large] (main.py 226): INFO Train: [279/300][1100/2502]	eta 0:12:13 lr 0.000011	time 0.5379 (0.5232)	loss 1.9324 (2.7786)	grad_norm 10.5348 (nan)	mem 8929MB
[2022-04-09 21:49:07 large] (main.py 226): INFO Train: [279/300][1200/2502]	eta 0:11:20 lr 0.000011	time 0.5086 (0.5225)	loss 3.0163 (2.7823)	grad_norm 8.1003 (nan)	mem 8929MB
[2022-04-09 21:49:56 large] (main.py 226): INFO Train: [279/300][1300/2502]	eta 0:10:25 lr 0.000011	time 0.4962 (0.5201)	loss 2.8514 (2.7860)	grad_norm 7.0234 (nan)	mem 8929MB
[2022-04-09 21:50:48 large] (main.py 226): INFO Train: [279/300][1400/2502]	eta 0:09:33 lr 0.000011	time 0.5683 (0.5201)	loss 2.4526 (2.7884)	grad_norm 9.3515 (nan)	mem 8929MB
[2022-04-09 21:51:38 large] (main.py 226): INFO Train: [279/300][1500/2502]	eta 0:08:39 lr 0.000011	time 0.5206 (0.5184)	loss 2.7975 (2.7855)	grad_norm 7.7581 (nan)	mem 8929MB
[2022-04-09 21:52:29 large] (main.py 226): INFO Train: [279/300][1600/2502]	eta 0:07:47 lr 0.000011	time 0.4911 (0.5178)	loss 3.1743 (2.7867)	grad_norm 9.0470 (nan)	mem 8929MB
[2022-04-09 21:53:21 large] (main.py 226): INFO Train: [279/300][1700/2502]	eta 0:06:55 lr 0.000011	time 0.5596 (0.5184)	loss 1.7303 (2.7851)	grad_norm 5.7099 (nan)	mem 8929MB
[2022-04-09 21:54:14 large] (main.py 226): INFO Train: [279/300][1800/2502]	eta 0:06:04 lr 0.000011	time 0.4750 (0.5190)	loss 1.8767 (2.7843)	grad_norm 7.5585 (nan)	mem 8929MB
[2022-04-09 21:55:07 large] (main.py 226): INFO Train: [279/300][1900/2502]	eta 0:05:12 lr 0.000011	time 0.5863 (0.5193)	loss 2.9440 (2.7829)	grad_norm 7.1581 (nan)	mem 8929MB
[2022-04-09 21:55:59 large] (main.py 226): INFO Train: [279/300][2000/2502]	eta 0:04:20 lr 0.000011	time 0.5094 (0.5195)	loss 2.4384 (2.7848)	grad_norm 10.7133 (nan)	mem 8929MB
[2022-04-09 21:56:51 large] (main.py 226): INFO Train: [279/300][2100/2502]	eta 0:03:28 lr 0.000010	time 0.5033 (0.5197)	loss 3.3006 (2.7851)	grad_norm 10.8072 (nan)	mem 8929MB
[2022-04-09 21:57:43 large] (main.py 226): INFO Train: [279/300][2200/2502]	eta 0:02:36 lr 0.000010	time 0.5738 (0.5197)	loss 3.1325 (2.7856)	grad_norm 9.0534 (nan)	mem 8929MB
[2022-04-09 21:58:35 large] (main.py 226): INFO Train: [279/300][2300/2502]	eta 0:01:44 lr 0.000010	time 0.5091 (0.5198)	loss 2.5235 (2.7890)	grad_norm 8.2272 (nan)	mem 8929MB
[2022-04-09 21:59:28 large] (main.py 226): INFO Train: [279/300][2400/2502]	eta 0:00:53 lr 0.000010	time 0.5324 (0.5198)	loss 3.2217 (2.7887)	grad_norm 7.0526 (nan)	mem 8929MB
[2022-04-09 22:00:16 large] (main.py 226): INFO Train: [279/300][2500/2502]	eta 0:00:01 lr 0.000010	time 0.4747 (0.5183)	loss 2.2851 (2.7884)	grad_norm 60.5996 (nan)	mem 8929MB
[2022-04-09 22:00:17 large] (main.py 233): INFO EPOCH 279 training takes 0:21:37
[2022-04-09 22:00:23 large] (main.py 273): INFO Test: [0/98]	Time 6.659 (6.659)	Loss 1.0222 (1.0222)	Acc@1 81.250 (81.250)	Acc@5 95.312 (95.312)	Mem 8929MB
[2022-04-09 22:00:49 large] (main.py 279): INFO  * Acc@1 81.904 Acc@5 95.570
[2022-04-09 22:00:49 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.9%
[2022-04-09 22:00:49 large] (utils.py 57): INFO output/large/default/ckpt_epoch_279.pth saving......
[2022-04-09 22:00:50 large] (utils.py 59): INFO output/large/default/ckpt_epoch_279.pth saved !!!
[2022-04-09 22:00:50 large] (main.py 148): INFO Max accuracy: 81.90%
[2022-04-09 22:00:58 large] (main.py 226): INFO Train: [280/300][0/2502]	eta 5:27:01 lr 0.000010	time 7.8424 (7.8424)	loss 3.3672 (3.3672)	grad_norm 9.6847 (9.6847)	mem 8929MB
[2022-04-09 22:01:48 large] (main.py 226): INFO Train: [280/300][100/2502]	eta 0:23:01 lr 0.000010	time 0.5228 (0.5753)	loss 2.0106 (2.7227)	grad_norm 13.9237 (9.6869)	mem 8929MB
[2022-04-09 22:02:37 large] (main.py 226): INFO Train: [280/300][200/2502]	eta 0:20:29 lr 0.000010	time 0.4887 (0.5342)	loss 3.1364 (2.7651)	grad_norm 9.6932 (9.8975)	mem 8929MB
[2022-04-09 22:03:27 large] (main.py 226): INFO Train: [280/300][300/2502]	eta 0:19:05 lr 0.000010	time 0.4839 (0.5201)	loss 3.1235 (2.7876)	grad_norm 8.4580 (9.6568)	mem 8929MB
[2022-04-09 22:04:18 large] (main.py 226): INFO Train: [280/300][400/2502]	eta 0:18:10 lr 0.000010	time 0.5034 (0.5190)	loss 3.0769 (2.8088)	grad_norm 8.2884 (9.7144)	mem 8929MB
[2022-04-09 22:05:11 large] (main.py 226): INFO Train: [280/300][500/2502]	eta 0:17:21 lr 0.000010	time 0.4655 (0.5203)	loss 2.8607 (2.7929)	grad_norm 8.5203 (9.7490)	mem 8929MB
[2022-04-09 22:06:00 large] (main.py 226): INFO Train: [280/300][600/2502]	eta 0:16:21 lr 0.000010	time 0.4835 (0.5160)	loss 3.1014 (2.7902)	grad_norm 8.2049 (9.7577)	mem 8929MB
[2022-04-09 22:06:52 large] (main.py 226): INFO Train: [280/300][700/2502]	eta 0:15:30 lr 0.000010	time 0.5563 (0.5163)	loss 3.1736 (2.8052)	grad_norm 12.2059 (9.7208)	mem 8929MB
[2022-04-09 22:07:45 large] (main.py 226): INFO Train: [280/300][800/2502]	eta 0:14:41 lr 0.000010	time 0.5346 (0.5177)	loss 2.0869 (2.7986)	grad_norm 8.0692 (9.6767)	mem 8929MB
[2022-04-09 22:08:35 large] (main.py 226): INFO Train: [280/300][900/2502]	eta 0:13:47 lr 0.000010	time 0.5018 (0.5165)	loss 3.0057 (2.8041)	grad_norm 7.8405 (nan)	mem 8929MB
[2022-04-09 22:09:26 large] (main.py 226): INFO Train: [280/300][1000/2502]	eta 0:12:53 lr 0.000010	time 0.5150 (0.5152)	loss 2.9215 (2.8011)	grad_norm 7.8510 (nan)	mem 8929MB
[2022-04-09 22:10:19 large] (main.py 226): INFO Train: [280/300][1100/2502]	eta 0:12:03 lr 0.000010	time 0.5121 (0.5163)	loss 2.9092 (2.7971)	grad_norm 10.8642 (nan)	mem 8929MB
[2022-04-09 22:11:11 large] (main.py 226): INFO Train: [280/300][1200/2502]	eta 0:11:13 lr 0.000010	time 0.5218 (0.5174)	loss 2.5854 (2.7951)	grad_norm 8.9157 (nan)	mem 8929MB
[2022-04-09 22:12:03 large] (main.py 226): INFO Train: [280/300][1300/2502]	eta 0:10:21 lr 0.000010	time 0.5336 (0.5171)	loss 3.1041 (2.7889)	grad_norm 9.9842 (nan)	mem 8929MB
[2022-04-09 22:12:53 large] (main.py 226): INFO Train: [280/300][1400/2502]	eta 0:09:28 lr 0.000010	time 0.4802 (0.5162)	loss 2.6197 (2.7866)	grad_norm 11.0184 (nan)	mem 8929MB
[2022-04-09 22:13:42 large] (main.py 226): INFO Train: [280/300][1500/2502]	eta 0:08:35 lr 0.000010	time 0.4902 (0.5145)	loss 2.1358 (2.7841)	grad_norm 7.5394 (nan)	mem 8929MB
[2022-04-09 22:14:32 large] (main.py 226): INFO Train: [280/300][1600/2502]	eta 0:07:43 lr 0.000010	time 0.4906 (0.5134)	loss 2.4337 (2.7842)	grad_norm 6.6837 (nan)	mem 8929MB
[2022-04-09 22:15:24 large] (main.py 226): INFO Train: [280/300][1700/2502]	eta 0:06:51 lr 0.000010	time 0.6279 (0.5136)	loss 3.3003 (2.7885)	grad_norm 7.9821 (nan)	mem 8929MB
[2022-04-09 22:16:14 large] (main.py 226): INFO Train: [280/300][1800/2502]	eta 0:06:00 lr 0.000010	time 0.5050 (0.5129)	loss 2.4611 (2.7867)	grad_norm 14.0956 (nan)	mem 8929MB
[2022-04-09 22:17:06 large] (main.py 226): INFO Train: [280/300][1900/2502]	eta 0:05:09 lr 0.000010	time 0.5035 (0.5133)	loss 2.8494 (2.7860)	grad_norm 9.7356 (nan)	mem 8929MB
[2022-04-09 22:17:55 large] (main.py 226): INFO Train: [280/300][2000/2502]	eta 0:04:17 lr 0.000010	time 0.4873 (0.5124)	loss 3.0830 (2.7880)	grad_norm 7.9982 (nan)	mem 8929MB
[2022-04-09 22:18:45 large] (main.py 226): INFO Train: [280/300][2100/2502]	eta 0:03:25 lr 0.000010	time 0.4895 (0.5114)	loss 2.2964 (2.7894)	grad_norm 10.4739 (nan)	mem 8929MB
[2022-04-09 22:19:34 large] (main.py 226): INFO Train: [280/300][2200/2502]	eta 0:02:34 lr 0.000010	time 0.4773 (0.5106)	loss 3.2326 (2.7870)	grad_norm 7.8886 (nan)	mem 8929MB
[2022-04-09 22:20:23 large] (main.py 226): INFO Train: [280/300][2300/2502]	eta 0:01:42 lr 0.000010	time 0.4913 (0.5099)	loss 3.4500 (2.7870)	grad_norm 7.9890 (nan)	mem 8929MB
[2022-04-09 22:21:15 large] (main.py 226): INFO Train: [280/300][2400/2502]	eta 0:00:52 lr 0.000010	time 0.4931 (0.5103)	loss 2.1829 (2.7841)	grad_norm 8.9682 (nan)	mem 8929MB
[2022-04-09 22:22:05 large] (main.py 226): INFO Train: [280/300][2500/2502]	eta 0:00:01 lr 0.000010	time 0.5116 (0.5098)	loss 3.4185 (2.7833)	grad_norm 12.4580 (nan)	mem 8929MB
[2022-04-09 22:22:06 large] (main.py 233): INFO EPOCH 280 training takes 0:21:16
[2022-04-09 22:22:13 large] (main.py 273): INFO Test: [0/98]	Time 6.411 (6.411)	Loss 0.9376 (0.9376)	Acc@1 81.445 (81.445)	Acc@5 96.289 (96.289)	Mem 8929MB
[2022-04-09 22:22:38 large] (main.py 279): INFO  * Acc@1 81.874 Acc@5 95.628
[2022-04-09 22:22:38 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.9%
[2022-04-09 22:22:38 large] (main.py 148): INFO Max accuracy: 81.90%
[2022-04-09 22:22:45 large] (main.py 226): INFO Train: [281/300][0/2502]	eta 4:47:11 lr 0.000010	time 6.8872 (6.8872)	loss 1.9151 (1.9151)	grad_norm 6.2844 (6.2844)	mem 8929MB
[2022-04-09 22:23:36 large] (main.py 226): INFO Train: [281/300][100/2502]	eta 0:22:51 lr 0.000010	time 0.4724 (0.5712)	loss 1.7832 (2.7562)	grad_norm 8.5978 (11.5390)	mem 8929MB
[2022-04-09 22:24:24 large] (main.py 226): INFO Train: [281/300][200/2502]	eta 0:20:15 lr 0.000010	time 0.4879 (0.5281)	loss 2.9712 (2.8027)	grad_norm 26.6481 (11.3341)	mem 8929MB
[2022-04-09 22:25:14 large] (main.py 226): INFO Train: [281/300][300/2502]	eta 0:19:03 lr 0.000010	time 0.4951 (0.5192)	loss 2.0057 (2.7748)	grad_norm 11.0654 (10.8001)	mem 8929MB
[2022-04-09 22:26:07 large] (main.py 226): INFO Train: [281/300][400/2502]	eta 0:18:13 lr 0.000010	time 0.5437 (0.5201)	loss 3.3261 (2.7496)	grad_norm 14.8591 (10.8531)	mem 8929MB
[2022-04-09 22:27:00 large] (main.py 226): INFO Train: [281/300][500/2502]	eta 0:17:26 lr 0.000010	time 0.5166 (0.5228)	loss 3.1559 (2.7468)	grad_norm 7.9680 (10.5942)	mem 8929MB
[2022-04-09 22:27:53 large] (main.py 226): INFO Train: [281/300][600/2502]	eta 0:16:35 lr 0.000010	time 0.5567 (0.5235)	loss 2.5149 (2.7531)	grad_norm 15.4659 (10.4875)	mem 8929MB
[2022-04-09 22:28:43 large] (main.py 226): INFO Train: [281/300][700/2502]	eta 0:15:38 lr 0.000010	time 0.4872 (0.5206)	loss 2.6847 (2.7592)	grad_norm 9.0331 (10.5274)	mem 8929MB
[2022-04-09 22:29:33 large] (main.py 226): INFO Train: [281/300][800/2502]	eta 0:14:41 lr 0.000010	time 0.4928 (0.5179)	loss 2.8922 (2.7613)	grad_norm 8.2778 (10.3573)	mem 8929MB
[2022-04-09 22:30:23 large] (main.py 226): INFO Train: [281/300][900/2502]	eta 0:13:45 lr 0.000010	time 0.5028 (0.5156)	loss 3.2157 (2.7607)	grad_norm 13.5582 (10.1830)	mem 8929MB
[2022-04-09 22:31:14 large] (main.py 226): INFO Train: [281/300][1000/2502]	eta 0:12:53 lr 0.000010	time 0.5045 (0.5151)	loss 3.1818 (2.7612)	grad_norm 8.8829 (10.1708)	mem 8929MB
[2022-04-09 22:32:07 large] (main.py 226): INFO Train: [281/300][1100/2502]	eta 0:12:03 lr 0.000010	time 0.5291 (0.5163)	loss 2.2615 (2.7607)	grad_norm 11.9628 (10.1234)	mem 8929MB
[2022-04-09 22:32:59 large] (main.py 226): INFO Train: [281/300][1200/2502]	eta 0:11:13 lr 0.000010	time 0.5153 (0.5170)	loss 2.7296 (2.7620)	grad_norm 9.2128 (10.0804)	mem 8929MB
[2022-04-09 22:33:51 large] (main.py 226): INFO Train: [281/300][1300/2502]	eta 0:10:21 lr 0.000010	time 0.4873 (0.5173)	loss 2.5432 (2.7606)	grad_norm 10.4097 (10.0019)	mem 8929MB
[2022-04-09 22:34:41 large] (main.py 226): INFO Train: [281/300][1400/2502]	eta 0:09:28 lr 0.000010	time 0.4940 (0.5162)	loss 3.3281 (2.7627)	grad_norm 7.9344 (nan)	mem 8929MB
[2022-04-09 22:35:30 large] (main.py 226): INFO Train: [281/300][1500/2502]	eta 0:08:35 lr 0.000010	time 0.4999 (0.5142)	loss 1.8140 (2.7636)	grad_norm 8.5437 (nan)	mem 8929MB
[2022-04-09 22:36:20 large] (main.py 226): INFO Train: [281/300][1600/2502]	eta 0:07:42 lr 0.000010	time 0.5105 (0.5131)	loss 2.9721 (2.7647)	grad_norm 6.5755 (nan)	mem 8929MB
[2022-04-09 22:37:12 large] (main.py 226): INFO Train: [281/300][1700/2502]	eta 0:06:51 lr 0.000010	time 0.5600 (0.5137)	loss 3.2308 (2.7666)	grad_norm 6.1795 (nan)	mem 8929MB
[2022-04-09 22:38:05 large] (main.py 226): INFO Train: [281/300][1800/2502]	eta 0:06:01 lr 0.000010	time 0.5113 (0.5145)	loss 2.1032 (2.7620)	grad_norm 9.7667 (nan)	mem 8929MB
[2022-04-09 22:38:57 large] (main.py 226): INFO Train: [281/300][1900/2502]	eta 0:05:09 lr 0.000010	time 0.4587 (0.5146)	loss 3.1391 (2.7664)	grad_norm 9.3629 (nan)	mem 8929MB
[2022-04-09 22:39:45 large] (main.py 226): INFO Train: [281/300][2000/2502]	eta 0:04:17 lr 0.000009	time 0.4829 (0.5132)	loss 3.2952 (2.7665)	grad_norm 8.5360 (nan)	mem 8929MB
[2022-04-09 22:40:36 large] (main.py 226): INFO Train: [281/300][2100/2502]	eta 0:03:26 lr 0.000009	time 0.5260 (0.5131)	loss 2.4517 (2.7686)	grad_norm 9.1512 (nan)	mem 8929MB
[2022-04-09 22:41:26 large] (main.py 226): INFO Train: [281/300][2200/2502]	eta 0:02:34 lr 0.000009	time 0.5077 (0.5124)	loss 3.0493 (2.7687)	grad_norm 9.7876 (nan)	mem 8929MB
[2022-04-09 22:42:18 large] (main.py 226): INFO Train: [281/300][2300/2502]	eta 0:01:43 lr 0.000009	time 0.5113 (0.5127)	loss 3.0899 (2.7687)	grad_norm 9.5242 (nan)	mem 8929MB
[2022-04-09 22:43:10 large] (main.py 226): INFO Train: [281/300][2400/2502]	eta 0:00:52 lr 0.000009	time 0.5365 (0.5131)	loss 3.0579 (2.7713)	grad_norm 7.4295 (nan)	mem 8929MB
[2022-04-09 22:44:00 large] (main.py 226): INFO Train: [281/300][2500/2502]	eta 0:00:01 lr 0.000009	time 0.4701 (0.5125)	loss 2.2816 (2.7744)	grad_norm 18.0202 (nan)	mem 8929MB
[2022-04-09 22:44:01 large] (main.py 233): INFO EPOCH 281 training takes 0:21:22
[2022-04-09 22:44:09 large] (main.py 273): INFO Test: [0/98]	Time 7.673 (7.673)	Loss 0.9055 (0.9055)	Acc@1 82.617 (82.617)	Acc@5 95.703 (95.703)	Mem 8929MB
[2022-04-09 22:44:33 large] (main.py 279): INFO  * Acc@1 81.792 Acc@5 95.630
[2022-04-09 22:44:33 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.8%
[2022-04-09 22:44:33 large] (main.py 148): INFO Max accuracy: 81.90%
[2022-04-09 22:44:41 large] (main.py 226): INFO Train: [282/300][0/2502]	eta 5:35:44 lr 0.000009	time 8.0513 (8.0513)	loss 3.4226 (3.4226)	grad_norm 12.6196 (12.6196)	mem 8929MB
[2022-04-09 22:45:31 large] (main.py 226): INFO Train: [282/300][100/2502]	eta 0:22:52 lr 0.000009	time 0.4493 (0.5715)	loss 3.5287 (2.8382)	grad_norm 11.3009 (9.9221)	mem 8929MB
[2022-04-09 22:46:22 large] (main.py 226): INFO Train: [282/300][200/2502]	eta 0:20:46 lr 0.000009	time 0.5622 (0.5413)	loss 2.8494 (2.8087)	grad_norm 11.0841 (9.6810)	mem 8929MB
[2022-04-09 22:47:15 large] (main.py 226): INFO Train: [282/300][300/2502]	eta 0:19:43 lr 0.000009	time 0.5301 (0.5377)	loss 3.0743 (2.8221)	grad_norm 8.0644 (9.8515)	mem 8929MB
[2022-04-09 22:48:07 large] (main.py 226): INFO Train: [282/300][400/2502]	eta 0:18:38 lr 0.000009	time 0.5046 (0.5323)	loss 3.2928 (2.8013)	grad_norm 11.0515 (9.8153)	mem 8929MB
[2022-04-09 22:48:56 large] (main.py 226): INFO Train: [282/300][500/2502]	eta 0:17:28 lr 0.000009	time 0.4910 (0.5240)	loss 2.6810 (2.7972)	grad_norm 7.1687 (9.9299)	mem 8929MB
[2022-04-09 22:49:46 large] (main.py 226): INFO Train: [282/300][600/2502]	eta 0:16:30 lr 0.000009	time 0.5240 (0.5206)	loss 2.9355 (2.8082)	grad_norm 8.4745 (9.9421)	mem 8929MB
[2022-04-09 22:50:39 large] (main.py 226): INFO Train: [282/300][700/2502]	eta 0:15:39 lr 0.000009	time 0.5349 (0.5214)	loss 3.4350 (2.7941)	grad_norm 8.6305 (10.1266)	mem 8929MB
[2022-04-09 22:51:31 large] (main.py 226): INFO Train: [282/300][800/2502]	eta 0:14:48 lr 0.000009	time 0.5120 (0.5220)	loss 2.5313 (2.7963)	grad_norm 8.8590 (10.2753)	mem 8929MB
[2022-04-09 22:52:22 large] (main.py 226): INFO Train: [282/300][900/2502]	eta 0:13:52 lr 0.000009	time 0.5755 (0.5199)	loss 3.4281 (2.8044)	grad_norm 8.9878 (10.2928)	mem 8929MB
[2022-04-09 22:53:12 large] (main.py 226): INFO Train: [282/300][1000/2502]	eta 0:12:58 lr 0.000009	time 0.5141 (0.5181)	loss 2.5789 (2.8043)	grad_norm 8.5971 (10.4202)	mem 8929MB
[2022-04-09 22:54:02 large] (main.py 226): INFO Train: [282/300][1100/2502]	eta 0:12:03 lr 0.000009	time 0.4864 (0.5163)	loss 2.1327 (2.8010)	grad_norm 13.6746 (10.3675)	mem 8929MB
[2022-04-09 22:54:50 large] (main.py 226): INFO Train: [282/300][1200/2502]	eta 0:11:08 lr 0.000009	time 0.4918 (0.5138)	loss 2.9673 (2.8015)	grad_norm 9.1179 (10.2993)	mem 8929MB
[2022-04-09 22:55:41 large] (main.py 226): INFO Train: [282/300][1300/2502]	eta 0:10:16 lr 0.000009	time 0.4960 (0.5129)	loss 2.9257 (2.8054)	grad_norm 11.4664 (10.3077)	mem 8929MB
[2022-04-09 22:56:32 large] (main.py 226): INFO Train: [282/300][1400/2502]	eta 0:09:25 lr 0.000009	time 0.5780 (0.5133)	loss 2.0880 (2.8014)	grad_norm 9.3510 (10.3884)	mem 8929MB
[2022-04-09 22:57:25 large] (main.py 226): INFO Train: [282/300][1500/2502]	eta 0:08:35 lr 0.000009	time 0.4999 (0.5141)	loss 2.7164 (2.7968)	grad_norm 10.2868 (10.3981)	mem 8929MB
[2022-04-09 22:58:16 large] (main.py 226): INFO Train: [282/300][1600/2502]	eta 0:07:43 lr 0.000009	time 0.4539 (0.5140)	loss 3.1167 (2.7986)	grad_norm 10.0119 (10.4141)	mem 8929MB
[2022-04-09 22:59:06 large] (main.py 226): INFO Train: [282/300][1700/2502]	eta 0:06:51 lr 0.000009	time 0.4938 (0.5129)	loss 3.1710 (2.8016)	grad_norm 8.2891 (10.4378)	mem 8929MB
[2022-04-09 22:59:58 large] (main.py 226): INFO Train: [282/300][1800/2502]	eta 0:06:00 lr 0.000009	time 0.4998 (0.5134)	loss 1.9211 (2.8007)	grad_norm 8.3611 (10.3979)	mem 8929MB
[2022-04-09 23:00:47 large] (main.py 226): INFO Train: [282/300][1900/2502]	eta 0:05:08 lr 0.000009	time 0.4676 (0.5122)	loss 2.5987 (2.8003)	grad_norm 6.7116 (10.3847)	mem 8929MB
[2022-04-09 23:01:37 large] (main.py 226): INFO Train: [282/300][2000/2502]	eta 0:04:16 lr 0.000009	time 0.4767 (0.5116)	loss 3.4500 (2.8005)	grad_norm 12.6435 (10.3772)	mem 8929MB
[2022-04-09 23:02:29 large] (main.py 226): INFO Train: [282/300][2100/2502]	eta 0:03:25 lr 0.000009	time 0.5561 (0.5118)	loss 2.5169 (2.7978)	grad_norm 10.3404 (10.3475)	mem 8929MB
[2022-04-09 23:03:21 large] (main.py 226): INFO Train: [282/300][2200/2502]	eta 0:02:34 lr 0.000009	time 0.5269 (0.5124)	loss 3.0813 (2.7983)	grad_norm 8.2069 (10.3340)	mem 8929MB
[2022-04-09 23:04:14 large] (main.py 226): INFO Train: [282/300][2300/2502]	eta 0:01:43 lr 0.000009	time 0.5118 (0.5130)	loss 3.0101 (2.7994)	grad_norm 7.6525 (10.3585)	mem 8929MB
[2022-04-09 23:05:06 large] (main.py 226): INFO Train: [282/300][2400/2502]	eta 0:00:52 lr 0.000009	time 0.5416 (0.5135)	loss 2.9853 (2.7976)	grad_norm 11.4095 (10.3247)	mem 8929MB
[2022-04-09 23:05:58 large] (main.py 226): INFO Train: [282/300][2500/2502]	eta 0:00:01 lr 0.000009	time 0.5042 (0.5139)	loss 1.7512 (2.7956)	grad_norm 9.9777 (10.3070)	mem 8929MB
[2022-04-09 23:05:59 large] (main.py 233): INFO EPOCH 282 training takes 0:21:26
[2022-04-09 23:06:07 large] (main.py 273): INFO Test: [0/98]	Time 7.314 (7.314)	Loss 0.9692 (0.9692)	Acc@1 82.812 (82.812)	Acc@5 95.312 (95.312)	Mem 8929MB
[2022-04-09 23:06:32 large] (main.py 279): INFO  * Acc@1 81.804 Acc@5 95.654
[2022-04-09 23:06:32 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.8%
[2022-04-09 23:06:32 large] (main.py 148): INFO Max accuracy: 81.90%
[2022-04-09 23:06:39 large] (main.py 226): INFO Train: [283/300][0/2502]	eta 5:10:42 lr 0.000009	time 7.4511 (7.4511)	loss 2.7924 (2.7924)	grad_norm 6.5840 (6.5840)	mem 8929MB
[2022-04-09 23:07:30 large] (main.py 226): INFO Train: [283/300][100/2502]	eta 0:23:04 lr 0.000009	time 0.5022 (0.5766)	loss 2.9729 (2.7932)	grad_norm 11.0745 (10.3104)	mem 8929MB
[2022-04-09 23:08:20 large] (main.py 226): INFO Train: [283/300][200/2502]	eta 0:20:38 lr 0.000009	time 0.4629 (0.5380)	loss 2.6661 (2.7639)	grad_norm 7.8339 (10.7080)	mem 8929MB
[2022-04-09 23:09:10 large] (main.py 226): INFO Train: [283/300][300/2502]	eta 0:19:19 lr 0.000009	time 0.5120 (0.5268)	loss 3.0431 (2.7583)	grad_norm 8.1849 (10.5366)	mem 8929MB
[2022-04-09 23:10:04 large] (main.py 226): INFO Train: [283/300][400/2502]	eta 0:18:29 lr 0.000009	time 0.5933 (0.5280)	loss 3.3615 (2.7640)	grad_norm 7.8487 (10.4522)	mem 8929MB
[2022-04-09 23:10:54 large] (main.py 226): INFO Train: [283/300][500/2502]	eta 0:17:29 lr 0.000009	time 0.4892 (0.5241)	loss 2.7430 (2.7682)	grad_norm 14.4562 (10.3877)	mem 8929MB
[2022-04-09 23:11:46 large] (main.py 226): INFO Train: [283/300][600/2502]	eta 0:16:34 lr 0.000009	time 0.5218 (0.5230)	loss 2.5510 (2.7468)	grad_norm 5.7730 (10.3103)	mem 8929MB
[2022-04-09 23:12:39 large] (main.py 226): INFO Train: [283/300][700/2502]	eta 0:15:44 lr 0.000009	time 0.5963 (0.5240)	loss 2.7358 (2.7491)	grad_norm 7.5420 (10.2544)	mem 8929MB
[2022-04-09 23:13:29 large] (main.py 226): INFO Train: [283/300][800/2502]	eta 0:14:46 lr 0.000009	time 0.4903 (0.5208)	loss 2.6776 (2.7480)	grad_norm 8.9526 (10.2483)	mem 8929MB
[2022-04-09 23:14:19 large] (main.py 226): INFO Train: [283/300][900/2502]	eta 0:13:50 lr 0.000009	time 0.5470 (0.5184)	loss 2.7386 (2.7519)	grad_norm 7.3059 (10.1645)	mem 8929MB
[2022-04-09 23:15:09 large] (main.py 226): INFO Train: [283/300][1000/2502]	eta 0:12:56 lr 0.000009	time 0.5030 (0.5169)	loss 2.5140 (2.7561)	grad_norm 14.7493 (10.1479)	mem 8929MB
[2022-04-09 23:15:59 large] (main.py 226): INFO Train: [283/300][1100/2502]	eta 0:12:02 lr 0.000009	time 0.4997 (0.5152)	loss 3.1085 (2.7678)	grad_norm 9.3589 (10.2278)	mem 8929MB
[2022-04-09 23:16:49 large] (main.py 226): INFO Train: [283/300][1200/2502]	eta 0:11:08 lr 0.000009	time 0.5048 (0.5136)	loss 3.0886 (2.7667)	grad_norm 15.3806 (10.1963)	mem 8929MB
[2022-04-09 23:17:41 large] (main.py 226): INFO Train: [283/300][1300/2502]	eta 0:10:18 lr 0.000009	time 0.5090 (0.5145)	loss 3.2016 (2.7681)	grad_norm 7.1753 (10.2226)	mem 8929MB
[2022-04-09 23:18:35 large] (main.py 226): INFO Train: [283/300][1400/2502]	eta 0:09:28 lr 0.000009	time 0.5174 (0.5160)	loss 3.2118 (2.7701)	grad_norm 9.6199 (10.2239)	mem 8929MB
[2022-04-09 23:19:26 large] (main.py 226): INFO Train: [283/300][1500/2502]	eta 0:08:37 lr 0.000009	time 0.5890 (0.5160)	loss 3.0359 (2.7708)	grad_norm 9.9450 (10.1857)	mem 8929MB
[2022-04-09 23:20:17 large] (main.py 226): INFO Train: [283/300][1600/2502]	eta 0:07:44 lr 0.000009	time 0.5216 (0.5153)	loss 3.1903 (2.7727)	grad_norm 8.5078 (10.2375)	mem 8929MB
[2022-04-09 23:21:07 large] (main.py 226): INFO Train: [283/300][1700/2502]	eta 0:06:52 lr 0.000009	time 0.4979 (0.5145)	loss 2.8697 (2.7716)	grad_norm 9.0852 (10.2280)	mem 8929MB
[2022-04-09 23:21:57 large] (main.py 226): INFO Train: [283/300][1800/2502]	eta 0:06:00 lr 0.000009	time 0.5064 (0.5138)	loss 2.8886 (2.7771)	grad_norm 20.8169 (inf)	mem 8929MB
[2022-04-09 23:22:48 large] (main.py 226): INFO Train: [283/300][1900/2502]	eta 0:05:08 lr 0.000009	time 0.4596 (0.5133)	loss 2.9906 (2.7778)	grad_norm 7.5762 (inf)	mem 8929MB
[2022-04-09 23:23:37 large] (main.py 226): INFO Train: [283/300][2000/2502]	eta 0:04:17 lr 0.000009	time 0.5132 (0.5121)	loss 2.9278 (2.7757)	grad_norm 11.0234 (inf)	mem 8929MB
[2022-04-09 23:24:29 large] (main.py 226): INFO Train: [283/300][2100/2502]	eta 0:03:26 lr 0.000009	time 0.4858 (0.5125)	loss 3.1106 (2.7731)	grad_norm 7.4489 (inf)	mem 8929MB
[2022-04-09 23:25:21 large] (main.py 226): INFO Train: [283/300][2200/2502]	eta 0:02:34 lr 0.000009	time 0.5216 (0.5130)	loss 2.9843 (2.7722)	grad_norm 7.2424 (inf)	mem 8929MB
[2022-04-09 23:26:13 large] (main.py 226): INFO Train: [283/300][2300/2502]	eta 0:01:43 lr 0.000009	time 0.5110 (0.5134)	loss 3.4370 (2.7696)	grad_norm 7.2813 (inf)	mem 8929MB
[2022-04-09 23:27:03 large] (main.py 226): INFO Train: [283/300][2400/2502]	eta 0:00:52 lr 0.000008	time 0.4916 (0.5130)	loss 2.8429 (2.7653)	grad_norm 10.3588 (inf)	mem 8929MB
[2022-04-09 23:27:54 large] (main.py 226): INFO Train: [283/300][2500/2502]	eta 0:00:01 lr 0.000008	time 0.4713 (0.5125)	loss 3.0827 (2.7677)	grad_norm 11.4310 (inf)	mem 8929MB
[2022-04-09 23:27:55 large] (main.py 233): INFO EPOCH 283 training takes 0:21:22
[2022-04-09 23:28:01 large] (main.py 273): INFO Test: [0/98]	Time 6.205 (6.205)	Loss 0.8312 (0.8312)	Acc@1 85.156 (85.156)	Acc@5 95.898 (95.898)	Mem 8929MB
[2022-04-09 23:28:27 large] (main.py 279): INFO  * Acc@1 81.844 Acc@5 95.622
[2022-04-09 23:28:27 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.8%
[2022-04-09 23:28:27 large] (main.py 148): INFO Max accuracy: 81.90%
[2022-04-09 23:28:34 large] (main.py 226): INFO Train: [284/300][0/2502]	eta 4:41:30 lr 0.000008	time 6.7509 (6.7509)	loss 2.9287 (2.9287)	grad_norm 6.5488 (6.5488)	mem 8929MB
[2022-04-09 23:29:26 large] (main.py 226): INFO Train: [284/300][100/2502]	eta 0:23:17 lr 0.000008	time 0.5080 (0.5817)	loss 1.9013 (2.7978)	grad_norm 10.3638 (9.9293)	mem 8929MB
[2022-04-09 23:30:15 large] (main.py 226): INFO Train: [284/300][200/2502]	eta 0:20:31 lr 0.000008	time 0.4853 (0.5351)	loss 2.8739 (2.8038)	grad_norm 18.9432 (9.9974)	mem 8929MB
[2022-04-09 23:31:05 large] (main.py 226): INFO Train: [284/300][300/2502]	eta 0:19:13 lr 0.000008	time 0.4622 (0.5240)	loss 2.9644 (2.7829)	grad_norm 8.8043 (10.0832)	mem 8929MB
[2022-04-09 23:31:57 large] (main.py 226): INFO Train: [284/300][400/2502]	eta 0:18:17 lr 0.000008	time 0.5214 (0.5222)	loss 2.8972 (2.7852)	grad_norm 9.7952 (10.1986)	mem 8929MB
[2022-04-09 23:32:49 large] (main.py 226): INFO Train: [284/300][500/2502]	eta 0:17:27 lr 0.000008	time 0.5012 (0.5234)	loss 2.5189 (2.7846)	grad_norm 10.7064 (10.1636)	mem 8929MB
[2022-04-09 23:33:41 large] (main.py 226): INFO Train: [284/300][600/2502]	eta 0:16:34 lr 0.000008	time 0.5194 (0.5229)	loss 3.2521 (2.7873)	grad_norm 13.3844 (10.0841)	mem 8929MB
[2022-04-09 23:34:34 large] (main.py 226): INFO Train: [284/300][700/2502]	eta 0:15:41 lr 0.000008	time 0.5312 (0.5227)	loss 3.0678 (2.7870)	grad_norm 13.0943 (10.2247)	mem 8929MB
[2022-04-09 23:35:24 large] (main.py 226): INFO Train: [284/300][800/2502]	eta 0:14:45 lr 0.000008	time 0.5068 (0.5201)	loss 3.0618 (2.7896)	grad_norm 7.9697 (10.2378)	mem 8929MB
[2022-04-09 23:36:13 large] (main.py 226): INFO Train: [284/300][900/2502]	eta 0:13:48 lr 0.000008	time 0.4710 (0.5172)	loss 3.1459 (2.7930)	grad_norm 8.0110 (10.2350)	mem 8929MB
[2022-04-09 23:37:04 large] (main.py 226): INFO Train: [284/300][1000/2502]	eta 0:12:56 lr 0.000008	time 0.4864 (0.5167)	loss 2.7736 (2.7873)	grad_norm 13.1196 (10.2209)	mem 8929MB
[2022-04-09 23:37:53 large] (main.py 226): INFO Train: [284/300][1100/2502]	eta 0:12:00 lr 0.000008	time 0.4816 (0.5137)	loss 1.9292 (2.7856)	grad_norm 7.2224 (10.2217)	mem 8929MB
[2022-04-09 23:38:43 large] (main.py 226): INFO Train: [284/300][1200/2502]	eta 0:11:08 lr 0.000008	time 0.5064 (0.5131)	loss 3.2563 (2.7883)	grad_norm 8.3337 (10.1659)	mem 8929MB
[2022-04-09 23:39:34 large] (main.py 226): INFO Train: [284/300][1300/2502]	eta 0:10:16 lr 0.000008	time 0.4842 (0.5127)	loss 2.9665 (2.7887)	grad_norm 6.5904 (10.1336)	mem 8929MB
[2022-04-09 23:40:24 large] (main.py 226): INFO Train: [284/300][1400/2502]	eta 0:09:23 lr 0.000008	time 0.4896 (0.5115)	loss 3.2975 (2.7895)	grad_norm 11.4721 (10.1031)	mem 8929MB
[2022-04-09 23:41:16 large] (main.py 226): INFO Train: [284/300][1500/2502]	eta 0:08:32 lr 0.000008	time 0.4843 (0.5120)	loss 2.6471 (2.7902)	grad_norm 9.3257 (10.1647)	mem 8929MB
[2022-04-09 23:42:06 large] (main.py 226): INFO Train: [284/300][1600/2502]	eta 0:07:41 lr 0.000008	time 0.5379 (0.5117)	loss 3.1316 (2.7877)	grad_norm 12.3104 (10.1492)	mem 8929MB
[2022-04-09 23:42:56 large] (main.py 226): INFO Train: [284/300][1700/2502]	eta 0:06:49 lr 0.000008	time 0.4942 (0.5110)	loss 3.1901 (2.7874)	grad_norm 12.4409 (10.1607)	mem 8929MB
[2022-04-09 23:43:48 large] (main.py 226): INFO Train: [284/300][1800/2502]	eta 0:05:59 lr 0.000008	time 0.5226 (0.5115)	loss 2.8209 (2.7836)	grad_norm 8.1997 (10.1653)	mem 8929MB
[2022-04-09 23:44:41 large] (main.py 226): INFO Train: [284/300][1900/2502]	eta 0:05:08 lr 0.000008	time 0.5136 (0.5122)	loss 1.9919 (2.7821)	grad_norm 12.8924 (10.2200)	mem 8929MB
[2022-04-09 23:45:31 large] (main.py 226): INFO Train: [284/300][2000/2502]	eta 0:04:16 lr 0.000008	time 0.4876 (0.5115)	loss 3.5991 (2.7842)	grad_norm 8.6892 (nan)	mem 8929MB
[2022-04-09 23:46:23 large] (main.py 226): INFO Train: [284/300][2100/2502]	eta 0:03:25 lr 0.000008	time 0.5067 (0.5119)	loss 3.2936 (2.7838)	grad_norm 7.3147 (nan)	mem 8929MB
[2022-04-09 23:47:14 large] (main.py 226): INFO Train: [284/300][2200/2502]	eta 0:02:34 lr 0.000008	time 0.5169 (0.5120)	loss 3.0999 (2.7868)	grad_norm 6.4882 (nan)	mem 8929MB
[2022-04-09 23:48:06 large] (main.py 226): INFO Train: [284/300][2300/2502]	eta 0:01:43 lr 0.000008	time 0.5168 (0.5123)	loss 1.9753 (2.7847)	grad_norm 10.7643 (nan)	mem 8929MB
[2022-04-09 23:48:56 large] (main.py 226): INFO Train: [284/300][2400/2502]	eta 0:00:52 lr 0.000008	time 0.4971 (0.5118)	loss 1.6172 (2.7846)	grad_norm 7.8590 (nan)	mem 8929MB
[2022-04-09 23:49:46 large] (main.py 226): INFO Train: [284/300][2500/2502]	eta 0:00:01 lr 0.000008	time 0.5260 (0.5114)	loss 3.2388 (2.7833)	grad_norm 7.7764 (nan)	mem 8929MB
[2022-04-09 23:49:47 large] (main.py 233): INFO EPOCH 284 training takes 0:21:19
[2022-04-09 23:49:54 large] (main.py 273): INFO Test: [0/98]	Time 6.403 (6.403)	Loss 1.1050 (1.1050)	Acc@1 80.078 (80.078)	Acc@5 94.141 (94.141)	Mem 8929MB
[2022-04-09 23:50:19 large] (main.py 279): INFO  * Acc@1 81.842 Acc@5 95.566
[2022-04-09 23:50:19 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.8%
[2022-04-09 23:50:19 large] (main.py 148): INFO Max accuracy: 81.90%
[2022-04-09 23:50:26 large] (main.py 226): INFO Train: [285/300][0/2502]	eta 4:50:44 lr 0.000008	time 6.9721 (6.9721)	loss 3.2616 (3.2616)	grad_norm 7.1409 (7.1409)	mem 8929MB
[2022-04-09 23:51:18 large] (main.py 226): INFO Train: [285/300][100/2502]	eta 0:23:10 lr 0.000008	time 0.5179 (0.5790)	loss 3.1653 (2.8084)	grad_norm 9.3275 (10.2590)	mem 8929MB
[2022-04-09 23:52:10 large] (main.py 226): INFO Train: [285/300][200/2502]	eta 0:21:07 lr 0.000008	time 0.4953 (0.5508)	loss 2.7565 (2.8197)	grad_norm 7.3237 (10.4055)	mem 8929MB
[2022-04-09 23:53:02 large] (main.py 226): INFO Train: [285/300][300/2502]	eta 0:19:53 lr 0.000008	time 0.5191 (0.5420)	loss 2.5890 (2.8086)	grad_norm 9.6763 (10.3746)	mem 8929MB
[2022-04-09 23:53:55 large] (main.py 226): INFO Train: [285/300][400/2502]	eta 0:18:49 lr 0.000008	time 0.4991 (0.5372)	loss 1.6354 (2.8032)	grad_norm 7.5679 (nan)	mem 8929MB
[2022-04-09 23:54:47 large] (main.py 226): INFO Train: [285/300][500/2502]	eta 0:17:49 lr 0.000008	time 0.5351 (0.5340)	loss 2.7737 (2.7894)	grad_norm 12.7643 (nan)	mem 8929MB
[2022-04-09 23:55:39 large] (main.py 226): INFO Train: [285/300][600/2502]	eta 0:16:51 lr 0.000008	time 0.5108 (0.5318)	loss 2.7108 (2.7810)	grad_norm 7.2845 (nan)	mem 8929MB
[2022-04-09 23:56:31 large] (main.py 226): INFO Train: [285/300][700/2502]	eta 0:15:55 lr 0.000008	time 0.4944 (0.5305)	loss 3.2516 (2.7903)	grad_norm 8.8172 (nan)	mem 8929MB
[2022-04-09 23:57:21 large] (main.py 226): INFO Train: [285/300][800/2502]	eta 0:14:55 lr 0.000008	time 0.4970 (0.5259)	loss 2.4674 (2.7886)	grad_norm 8.6315 (nan)	mem 8929MB
[2022-04-09 23:58:09 large] (main.py 226): INFO Train: [285/300][900/2502]	eta 0:13:55 lr 0.000008	time 0.5016 (0.5217)	loss 2.4567 (2.7902)	grad_norm 6.5760 (nan)	mem 8929MB
[2022-04-09 23:59:01 large] (main.py 226): INFO Train: [285/300][1000/2502]	eta 0:13:03 lr 0.000008	time 0.5046 (0.5216)	loss 2.1738 (2.7898)	grad_norm 7.8078 (nan)	mem 8929MB
[2022-04-09 23:59:52 large] (main.py 226): INFO Train: [285/300][1100/2502]	eta 0:12:09 lr 0.000008	time 0.4811 (0.5201)	loss 2.0608 (2.7805)	grad_norm 10.1587 (nan)	mem 8929MB
[2022-04-10 00:00:42 large] (main.py 226): INFO Train: [285/300][1200/2502]	eta 0:11:14 lr 0.000008	time 0.5890 (0.5181)	loss 3.1636 (2.7828)	grad_norm 9.9443 (nan)	mem 8929MB
[2022-04-10 00:01:32 large] (main.py 226): INFO Train: [285/300][1300/2502]	eta 0:10:21 lr 0.000008	time 0.4502 (0.5170)	loss 2.9809 (2.7875)	grad_norm 9.6674 (nan)	mem 8929MB
[2022-04-10 00:02:20 large] (main.py 226): INFO Train: [285/300][1400/2502]	eta 0:09:27 lr 0.000008	time 0.4867 (0.5147)	loss 3.1461 (2.7818)	grad_norm 8.4554 (nan)	mem 8929MB
[2022-04-10 00:03:11 large] (main.py 226): INFO Train: [285/300][1500/2502]	eta 0:08:35 lr 0.000008	time 0.4902 (0.5142)	loss 2.4644 (2.7864)	grad_norm 9.5810 (nan)	mem 8929MB
[2022-04-10 00:04:02 large] (main.py 226): INFO Train: [285/300][1600/2502]	eta 0:07:43 lr 0.000008	time 0.5201 (0.5137)	loss 2.4059 (2.7853)	grad_norm 7.8908 (nan)	mem 8929MB
[2022-04-10 00:04:54 large] (main.py 226): INFO Train: [285/300][1700/2502]	eta 0:06:52 lr 0.000008	time 0.5197 (0.5143)	loss 3.0956 (2.7831)	grad_norm 5.9740 (nan)	mem 8929MB
[2022-04-10 00:05:46 large] (main.py 226): INFO Train: [285/300][1800/2502]	eta 0:06:01 lr 0.000008	time 0.4743 (0.5145)	loss 1.9947 (2.7840)	grad_norm 6.9054 (nan)	mem 8929MB
[2022-04-10 00:06:35 large] (main.py 226): INFO Train: [285/300][1900/2502]	eta 0:05:08 lr 0.000008	time 0.4855 (0.5130)	loss 1.8859 (2.7879)	grad_norm 8.7626 (nan)	mem 8929MB
[2022-04-10 00:07:24 large] (main.py 226): INFO Train: [285/300][2000/2502]	eta 0:04:17 lr 0.000008	time 0.4845 (0.5123)	loss 2.3374 (2.7882)	grad_norm 8.6185 (nan)	mem 8929MB
[2022-04-10 00:08:14 large] (main.py 226): INFO Train: [285/300][2100/2502]	eta 0:03:25 lr 0.000008	time 0.5086 (0.5114)	loss 2.9492 (2.7823)	grad_norm 6.8532 (nan)	mem 8929MB
[2022-04-10 00:09:06 large] (main.py 226): INFO Train: [285/300][2200/2502]	eta 0:02:34 lr 0.000008	time 0.5157 (0.5118)	loss 2.8175 (2.7815)	grad_norm 7.9954 (nan)	mem 8929MB
[2022-04-10 00:09:58 large] (main.py 226): INFO Train: [285/300][2300/2502]	eta 0:01:43 lr 0.000008	time 0.5066 (0.5125)	loss 2.7783 (2.7815)	grad_norm 10.8177 (nan)	mem 8929MB
[2022-04-10 00:10:51 large] (main.py 226): INFO Train: [285/300][2400/2502]	eta 0:00:52 lr 0.000008	time 0.5659 (0.5130)	loss 2.8668 (2.7802)	grad_norm 7.3907 (nan)	mem 8929MB
[2022-04-10 00:11:43 large] (main.py 226): INFO Train: [285/300][2500/2502]	eta 0:00:01 lr 0.000008	time 0.4959 (0.5132)	loss 2.9933 (2.7793)	grad_norm 8.9245 (nan)	mem 8929MB
[2022-04-10 00:11:44 large] (main.py 233): INFO EPOCH 285 training takes 0:21:24
[2022-04-10 00:11:50 large] (main.py 273): INFO Test: [0/98]	Time 5.980 (5.980)	Loss 0.8424 (0.8424)	Acc@1 85.938 (85.938)	Acc@5 95.703 (95.703)	Mem 8929MB
[2022-04-10 00:12:16 large] (main.py 279): INFO  * Acc@1 81.866 Acc@5 95.644
[2022-04-10 00:12:16 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.9%
[2022-04-10 00:12:16 large] (main.py 148): INFO Max accuracy: 81.90%
[2022-04-10 00:12:24 large] (main.py 226): INFO Train: [286/300][0/2502]	eta 5:18:46 lr 0.000008	time 7.6443 (7.6443)	loss 3.1097 (3.1097)	grad_norm 8.1443 (8.1443)	mem 8929MB
[2022-04-10 00:13:14 large] (main.py 226): INFO Train: [286/300][100/2502]	eta 0:22:54 lr 0.000008	time 0.5150 (0.5724)	loss 2.8272 (2.7098)	grad_norm 6.8976 (10.4179)	mem 8929MB
[2022-04-10 00:14:04 large] (main.py 226): INFO Train: [286/300][200/2502]	eta 0:20:37 lr 0.000008	time 0.5080 (0.5377)	loss 3.2407 (2.7112)	grad_norm 9.2147 (10.3253)	mem 8929MB
[2022-04-10 00:14:55 large] (main.py 226): INFO Train: [286/300][300/2502]	eta 0:19:25 lr 0.000008	time 0.5123 (0.5294)	loss 2.0124 (2.7389)	grad_norm 7.7931 (10.4681)	mem 8929MB
[2022-04-10 00:15:48 large] (main.py 226): INFO Train: [286/300][400/2502]	eta 0:18:31 lr 0.000008	time 0.5099 (0.5286)	loss 3.1841 (2.7306)	grad_norm 7.0743 (10.3798)	mem 8929MB
[2022-04-10 00:16:39 large] (main.py 226): INFO Train: [286/300][500/2502]	eta 0:17:30 lr 0.000008	time 0.5420 (0.5246)	loss 1.9814 (2.7300)	grad_norm 10.7610 (10.3792)	mem 8929MB
[2022-04-10 00:17:28 large] (main.py 226): INFO Train: [286/300][600/2502]	eta 0:16:27 lr 0.000008	time 0.4887 (0.5193)	loss 3.2157 (2.7331)	grad_norm 9.0667 (10.2863)	mem 8929MB
[2022-04-10 00:18:19 large] (main.py 226): INFO Train: [286/300][700/2502]	eta 0:15:32 lr 0.000008	time 0.5503 (0.5175)	loss 2.9388 (2.7322)	grad_norm 7.6336 (10.6222)	mem 8929MB
[2022-04-10 00:19:10 large] (main.py 226): INFO Train: [286/300][800/2502]	eta 0:14:39 lr 0.000008	time 0.5644 (0.5166)	loss 3.3727 (2.7307)	grad_norm 11.5210 (10.5546)	mem 8929MB
[2022-04-10 00:20:00 large] (main.py 226): INFO Train: [286/300][900/2502]	eta 0:13:45 lr 0.000008	time 0.4882 (0.5152)	loss 2.0856 (2.7398)	grad_norm 10.5104 (10.6523)	mem 8929MB
[2022-04-10 00:20:49 large] (main.py 226): INFO Train: [286/300][1000/2502]	eta 0:12:50 lr 0.000008	time 0.4866 (0.5127)	loss 3.0516 (2.7425)	grad_norm 6.8252 (10.6506)	mem 8929MB
[2022-04-10 00:21:40 large] (main.py 226): INFO Train: [286/300][1100/2502]	eta 0:11:58 lr 0.000007	time 0.5451 (0.5123)	loss 2.5895 (2.7390)	grad_norm 14.1534 (10.7560)	mem 8929MB
[2022-04-10 00:22:33 large] (main.py 226): INFO Train: [286/300][1200/2502]	eta 0:11:08 lr 0.000007	time 0.5450 (0.5135)	loss 2.9902 (2.7411)	grad_norm 8.6998 (10.7052)	mem 8929MB
[2022-04-10 00:23:23 large] (main.py 226): INFO Train: [286/300][1300/2502]	eta 0:10:16 lr 0.000007	time 0.5218 (0.5126)	loss 2.4510 (2.7410)	grad_norm 9.2179 (10.7030)	mem 8929MB
[2022-04-10 00:24:15 large] (main.py 226): INFO Train: [286/300][1400/2502]	eta 0:09:25 lr 0.000007	time 0.4986 (0.5131)	loss 2.2608 (2.7446)	grad_norm 11.8521 (10.6800)	mem 8929MB
[2022-04-10 00:25:07 large] (main.py 226): INFO Train: [286/300][1500/2502]	eta 0:08:34 lr 0.000007	time 0.4941 (0.5136)	loss 2.7881 (2.7477)	grad_norm 7.6247 (10.6690)	mem 8929MB
[2022-04-10 00:25:59 large] (main.py 226): INFO Train: [286/300][1600/2502]	eta 0:07:43 lr 0.000007	time 0.5277 (0.5141)	loss 3.4893 (2.7492)	grad_norm 8.6570 (10.6776)	mem 8929MB
[2022-04-10 00:26:50 large] (main.py 226): INFO Train: [286/300][1700/2502]	eta 0:06:51 lr 0.000007	time 0.4870 (0.5136)	loss 3.0533 (2.7566)	grad_norm 7.5698 (10.6202)	mem 8929MB
[2022-04-10 00:27:39 large] (main.py 226): INFO Train: [286/300][1800/2502]	eta 0:05:59 lr 0.000007	time 0.5106 (0.5128)	loss 2.6263 (2.7564)	grad_norm 8.7947 (10.6109)	mem 8929MB
[2022-04-10 00:28:32 large] (main.py 226): INFO Train: [286/300][1900/2502]	eta 0:05:09 lr 0.000007	time 0.5079 (0.5135)	loss 3.2742 (2.7633)	grad_norm 12.5995 (10.6443)	mem 8929MB
[2022-04-10 00:29:22 large] (main.py 226): INFO Train: [286/300][2000/2502]	eta 0:04:17 lr 0.000007	time 0.4931 (0.5130)	loss 3.6098 (2.7641)	grad_norm 8.4088 (inf)	mem 8929MB
[2022-04-10 00:30:13 large] (main.py 226): INFO Train: [286/300][2100/2502]	eta 0:03:26 lr 0.000007	time 0.4931 (0.5126)	loss 2.8588 (2.7625)	grad_norm 10.0910 (inf)	mem 8929MB
[2022-04-10 00:31:04 large] (main.py 226): INFO Train: [286/300][2200/2502]	eta 0:02:34 lr 0.000007	time 0.4811 (0.5124)	loss 1.8138 (2.7617)	grad_norm 40.6992 (inf)	mem 8929MB
[2022-04-10 00:31:56 large] (main.py 226): INFO Train: [286/300][2300/2502]	eta 0:01:43 lr 0.000007	time 0.5075 (0.5127)	loss 2.1953 (2.7649)	grad_norm 7.2287 (inf)	mem 8929MB
[2022-04-10 00:32:47 large] (main.py 226): INFO Train: [286/300][2400/2502]	eta 0:00:52 lr 0.000007	time 0.5101 (0.5129)	loss 3.4393 (2.7656)	grad_norm 8.6318 (inf)	mem 8929MB
[2022-04-10 00:33:39 large] (main.py 226): INFO Train: [286/300][2500/2502]	eta 0:00:01 lr 0.000007	time 0.4971 (0.5130)	loss 3.0571 (2.7648)	grad_norm 8.8469 (inf)	mem 8929MB
[2022-04-10 00:33:40 large] (main.py 233): INFO EPOCH 286 training takes 0:21:23
[2022-04-10 00:33:46 large] (main.py 273): INFO Test: [0/98]	Time 6.524 (6.524)	Loss 1.0482 (1.0482)	Acc@1 79.688 (79.688)	Acc@5 95.312 (95.312)	Mem 8929MB
[2022-04-10 00:34:12 large] (main.py 279): INFO  * Acc@1 81.886 Acc@5 95.626
[2022-04-10 00:34:12 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.9%
[2022-04-10 00:34:12 large] (main.py 148): INFO Max accuracy: 81.90%
[2022-04-10 00:34:19 large] (main.py 226): INFO Train: [287/300][0/2502]	eta 4:52:33 lr 0.000007	time 7.0157 (7.0157)	loss 2.7667 (2.7667)	grad_norm 9.8901 (9.8901)	mem 8929MB
[2022-04-10 00:35:11 large] (main.py 226): INFO Train: [287/300][100/2502]	eta 0:23:22 lr 0.000007	time 0.4793 (0.5841)	loss 3.0075 (2.8496)	grad_norm 7.6209 (10.1632)	mem 8929MB
[2022-04-10 00:36:02 large] (main.py 226): INFO Train: [287/300][200/2502]	eta 0:21:05 lr 0.000007	time 0.4780 (0.5498)	loss 2.6639 (2.7417)	grad_norm 7.0216 (10.7872)	mem 8929MB
[2022-04-10 00:36:51 large] (main.py 226): INFO Train: [287/300][300/2502]	eta 0:19:25 lr 0.000007	time 0.5105 (0.5292)	loss 3.0713 (2.7688)	grad_norm 8.2539 (10.4855)	mem 8929MB
[2022-04-10 00:37:42 large] (main.py 226): INFO Train: [287/300][400/2502]	eta 0:18:19 lr 0.000007	time 0.4789 (0.5231)	loss 2.6263 (2.7762)	grad_norm 7.0215 (10.4765)	mem 8929MB
[2022-04-10 00:38:31 large] (main.py 226): INFO Train: [287/300][500/2502]	eta 0:17:16 lr 0.000007	time 0.4795 (0.5180)	loss 2.8091 (2.7864)	grad_norm 27.3216 (10.5760)	mem 8929MB
[2022-04-10 00:39:24 large] (main.py 226): INFO Train: [287/300][600/2502]	eta 0:16:27 lr 0.000007	time 0.5783 (0.5192)	loss 3.5477 (2.7879)	grad_norm 9.6105 (10.7195)	mem 8929MB
[2022-04-10 00:40:16 large] (main.py 226): INFO Train: [287/300][700/2502]	eta 0:15:35 lr 0.000007	time 0.5049 (0.5193)	loss 2.6135 (2.7858)	grad_norm 10.1233 (10.7356)	mem 8929MB
[2022-04-10 00:41:08 large] (main.py 226): INFO Train: [287/300][800/2502]	eta 0:14:44 lr 0.000007	time 0.5283 (0.5197)	loss 2.3966 (2.7740)	grad_norm 7.0184 (10.6705)	mem 8929MB
[2022-04-10 00:42:00 large] (main.py 226): INFO Train: [287/300][900/2502]	eta 0:13:52 lr 0.000007	time 0.5582 (0.5199)	loss 3.3198 (2.7820)	grad_norm 10.7927 (10.7450)	mem 8929MB
[2022-04-10 00:42:51 large] (main.py 226): INFO Train: [287/300][1000/2502]	eta 0:12:58 lr 0.000007	time 0.4875 (0.5183)	loss 3.0538 (2.7841)	grad_norm 15.4024 (10.8797)	mem 8929MB
[2022-04-10 00:43:41 large] (main.py 226): INFO Train: [287/300][1100/2502]	eta 0:12:04 lr 0.000007	time 0.5144 (0.5167)	loss 2.9339 (2.7811)	grad_norm 9.3202 (10.9686)	mem 8929MB
[2022-04-10 00:44:30 large] (main.py 226): INFO Train: [287/300][1200/2502]	eta 0:11:09 lr 0.000007	time 0.5058 (0.5144)	loss 3.2348 (2.7780)	grad_norm 9.7374 (10.9949)	mem 8929MB
[2022-04-10 00:45:20 large] (main.py 226): INFO Train: [287/300][1300/2502]	eta 0:10:17 lr 0.000007	time 0.5139 (0.5138)	loss 3.0501 (2.7681)	grad_norm 9.2192 (10.9247)	mem 8929MB
[2022-04-10 00:46:12 large] (main.py 226): INFO Train: [287/300][1400/2502]	eta 0:09:26 lr 0.000007	time 0.5001 (0.5142)	loss 2.3502 (2.7667)	grad_norm 11.4769 (10.9257)	mem 8929MB
[2022-04-10 00:47:04 large] (main.py 226): INFO Train: [287/300][1500/2502]	eta 0:08:35 lr 0.000007	time 0.5203 (0.5145)	loss 2.0975 (2.7648)	grad_norm 9.8438 (10.8546)	mem 8929MB
[2022-04-10 00:47:56 large] (main.py 226): INFO Train: [287/300][1600/2502]	eta 0:07:44 lr 0.000007	time 0.5139 (0.5148)	loss 2.9958 (2.7573)	grad_norm 21.6931 (10.8671)	mem 8929MB
[2022-04-10 00:48:48 large] (main.py 226): INFO Train: [287/300][1700/2502]	eta 0:06:53 lr 0.000007	time 0.4946 (0.5150)	loss 2.6448 (2.7581)	grad_norm 8.0655 (10.8315)	mem 8929MB
[2022-04-10 00:49:38 large] (main.py 226): INFO Train: [287/300][1800/2502]	eta 0:06:00 lr 0.000007	time 0.5132 (0.5141)	loss 3.0236 (2.7582)	grad_norm 8.7700 (10.7724)	mem 8929MB
[2022-04-10 00:50:28 large] (main.py 226): INFO Train: [287/300][1900/2502]	eta 0:05:09 lr 0.000007	time 0.5012 (0.5135)	loss 2.5550 (2.7596)	grad_norm 9.7081 (nan)	mem 8929MB
[2022-04-10 00:51:17 large] (main.py 226): INFO Train: [287/300][2000/2502]	eta 0:04:17 lr 0.000007	time 0.5834 (0.5123)	loss 3.1162 (2.7616)	grad_norm 5.6977 (nan)	mem 8929MB
[2022-04-10 00:52:09 large] (main.py 226): INFO Train: [287/300][2100/2502]	eta 0:03:26 lr 0.000007	time 0.5314 (0.5125)	loss 3.0634 (2.7616)	grad_norm 8.3773 (nan)	mem 8929MB
[2022-04-10 00:53:01 large] (main.py 226): INFO Train: [287/300][2200/2502]	eta 0:02:34 lr 0.000007	time 0.5381 (0.5128)	loss 3.1266 (2.7615)	grad_norm 13.4583 (nan)	mem 8929MB
[2022-04-10 00:53:53 large] (main.py 226): INFO Train: [287/300][2300/2502]	eta 0:01:43 lr 0.000007	time 0.5365 (0.5131)	loss 2.9203 (2.7627)	grad_norm 12.1893 (nan)	mem 8929MB
[2022-04-10 00:54:43 large] (main.py 226): INFO Train: [287/300][2400/2502]	eta 0:00:52 lr 0.000007	time 0.5078 (0.5126)	loss 2.4056 (2.7639)	grad_norm 7.8130 (nan)	mem 8929MB
[2022-04-10 00:55:32 large] (main.py 226): INFO Train: [287/300][2500/2502]	eta 0:00:01 lr 0.000007	time 0.4949 (0.5117)	loss 2.0762 (2.7646)	grad_norm 18.7293 (nan)	mem 8929MB
[2022-04-10 00:55:33 large] (main.py 233): INFO EPOCH 287 training takes 0:21:20
[2022-04-10 00:55:39 large] (main.py 273): INFO Test: [0/98]	Time 6.111 (6.111)	Loss 0.9322 (0.9322)	Acc@1 80.273 (80.273)	Acc@5 96.875 (96.875)	Mem 8929MB
[2022-04-10 00:56:05 large] (main.py 279): INFO  * Acc@1 81.832 Acc@5 95.612
[2022-04-10 00:56:05 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.8%
[2022-04-10 00:56:05 large] (main.py 148): INFO Max accuracy: 81.90%
[2022-04-10 00:56:13 large] (main.py 226): INFO Train: [288/300][0/2502]	eta 5:14:33 lr 0.000007	time 7.5433 (7.5433)	loss 3.0432 (3.0432)	grad_norm 6.3673 (6.3673)	mem 8929MB
[2022-04-10 00:57:04 large] (main.py 226): INFO Train: [288/300][100/2502]	eta 0:23:17 lr 0.000007	time 0.5161 (0.5817)	loss 2.4210 (2.7406)	grad_norm 9.8193 (11.3769)	mem 8929MB
[2022-04-10 00:57:55 large] (main.py 226): INFO Train: [288/300][200/2502]	eta 0:20:56 lr 0.000007	time 0.4680 (0.5458)	loss 3.3800 (2.7709)	grad_norm 11.5354 (10.9447)	mem 8929MB
[2022-04-10 00:58:46 large] (main.py 226): INFO Train: [288/300][300/2502]	eta 0:19:36 lr 0.000007	time 0.4895 (0.5341)	loss 3.0931 (2.7613)	grad_norm 7.0651 (10.6544)	mem 8929MB
[2022-04-10 00:59:38 large] (main.py 226): INFO Train: [288/300][400/2502]	eta 0:18:35 lr 0.000007	time 0.5132 (0.5309)	loss 2.7504 (2.7654)	grad_norm 12.7027 (10.5120)	mem 8929MB
[2022-04-10 01:00:29 large] (main.py 226): INFO Train: [288/300][500/2502]	eta 0:17:35 lr 0.000007	time 0.4993 (0.5274)	loss 2.8877 (2.7697)	grad_norm 9.2662 (10.5829)	mem 8929MB
[2022-04-10 01:01:20 large] (main.py 226): INFO Train: [288/300][600/2502]	eta 0:16:36 lr 0.000007	time 0.4744 (0.5242)	loss 2.9550 (2.7590)	grad_norm 6.3795 (10.7592)	mem 8929MB
[2022-04-10 01:02:12 large] (main.py 226): INFO Train: [288/300][700/2502]	eta 0:15:44 lr 0.000007	time 0.5434 (0.5241)	loss 3.0951 (2.7654)	grad_norm 9.4031 (10.6711)	mem 8929MB
[2022-04-10 01:03:04 large] (main.py 226): INFO Train: [288/300][800/2502]	eta 0:14:51 lr 0.000007	time 0.5073 (0.5236)	loss 3.5960 (2.7751)	grad_norm 9.2870 (10.6218)	mem 8929MB
[2022-04-10 01:03:56 large] (main.py 226): INFO Train: [288/300][900/2502]	eta 0:13:57 lr 0.000007	time 0.5067 (0.5231)	loss 2.6257 (2.7883)	grad_norm 17.2690 (10.5556)	mem 8929MB
[2022-04-10 01:04:48 large] (main.py 226): INFO Train: [288/300][1000/2502]	eta 0:13:04 lr 0.000007	time 0.5398 (0.5226)	loss 2.3438 (2.7861)	grad_norm 13.6507 (10.5572)	mem 8929MB
[2022-04-10 01:05:40 large] (main.py 226): INFO Train: [288/300][1100/2502]	eta 0:12:12 lr 0.000007	time 0.5328 (0.5223)	loss 3.1103 (2.7859)	grad_norm 9.2405 (10.5729)	mem 8929MB
[2022-04-10 01:06:32 large] (main.py 226): INFO Train: [288/300][1200/2502]	eta 0:11:19 lr 0.000007	time 0.5198 (0.5219)	loss 3.2586 (2.7858)	grad_norm 8.8791 (10.6427)	mem 8929MB
[2022-04-10 01:07:22 large] (main.py 226): INFO Train: [288/300][1300/2502]	eta 0:10:25 lr 0.000007	time 0.4940 (0.5206)	loss 1.9542 (2.7841)	grad_norm 8.9608 (10.6514)	mem 8929MB
[2022-04-10 01:08:12 large] (main.py 226): INFO Train: [288/300][1400/2502]	eta 0:09:32 lr 0.000007	time 0.4854 (0.5191)	loss 2.7280 (2.7859)	grad_norm 9.0339 (10.6326)	mem 8929MB
[2022-04-10 01:09:03 large] (main.py 226): INFO Train: [288/300][1500/2502]	eta 0:08:39 lr 0.000007	time 0.5161 (0.5183)	loss 2.6921 (2.7849)	grad_norm 11.1285 (10.5885)	mem 8929MB
[2022-04-10 01:09:55 large] (main.py 226): INFO Train: [288/300][1600/2502]	eta 0:07:47 lr 0.000007	time 0.5387 (0.5181)	loss 2.5725 (2.7835)	grad_norm 8.3888 (10.6043)	mem 8929MB
[2022-04-10 01:10:46 large] (main.py 226): INFO Train: [288/300][1700/2502]	eta 0:06:55 lr 0.000007	time 0.5360 (0.5180)	loss 2.8515 (2.7815)	grad_norm 7.8230 (10.6120)	mem 8929MB
[2022-04-10 01:11:37 large] (main.py 226): INFO Train: [288/300][1800/2502]	eta 0:06:03 lr 0.000007	time 0.5096 (0.5172)	loss 2.5446 (2.7794)	grad_norm 9.4316 (10.6315)	mem 8929MB
[2022-04-10 01:12:28 large] (main.py 226): INFO Train: [288/300][1900/2502]	eta 0:05:11 lr 0.000007	time 0.4837 (0.5168)	loss 2.9520 (2.7798)	grad_norm 7.3802 (10.6216)	mem 8929MB
[2022-04-10 01:13:19 large] (main.py 226): INFO Train: [288/300][2000/2502]	eta 0:04:19 lr 0.000007	time 0.5227 (0.5168)	loss 3.0233 (2.7798)	grad_norm 6.6763 (10.6629)	mem 8929MB
[2022-04-10 01:14:10 large] (main.py 226): INFO Train: [288/300][2100/2502]	eta 0:03:27 lr 0.000007	time 0.4892 (0.5165)	loss 1.9876 (2.7830)	grad_norm 13.1934 (10.6928)	mem 8929MB
[2022-04-10 01:15:00 large] (main.py 226): INFO Train: [288/300][2200/2502]	eta 0:02:35 lr 0.000007	time 0.4856 (0.5155)	loss 2.9618 (2.7805)	grad_norm 13.5772 (10.6716)	mem 8929MB
[2022-04-10 01:15:50 large] (main.py 226): INFO Train: [288/300][2300/2502]	eta 0:01:44 lr 0.000007	time 0.4846 (0.5151)	loss 3.1827 (2.7815)	grad_norm 8.6349 (10.6703)	mem 8929MB
[2022-04-10 01:16:41 large] (main.py 226): INFO Train: [288/300][2400/2502]	eta 0:00:52 lr 0.000007	time 0.4988 (0.5148)	loss 3.2284 (2.7793)	grad_norm 8.9010 (10.8263)	mem 8929MB
[2022-04-10 01:17:32 large] (main.py 226): INFO Train: [288/300][2500/2502]	eta 0:00:01 lr 0.000007	time 0.4956 (0.5147)	loss 1.8840 (2.7773)	grad_norm 11.4359 (10.8786)	mem 8929MB
[2022-04-10 01:17:33 large] (main.py 233): INFO EPOCH 288 training takes 0:21:28
[2022-04-10 01:17:41 large] (main.py 273): INFO Test: [0/98]	Time 7.087 (7.087)	Loss 0.9197 (0.9197)	Acc@1 82.812 (82.812)	Acc@5 93.945 (93.945)	Mem 8929MB
[2022-04-10 01:18:06 large] (main.py 279): INFO  * Acc@1 81.882 Acc@5 95.694
[2022-04-10 01:18:06 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.9%
[2022-04-10 01:18:06 large] (main.py 148): INFO Max accuracy: 81.90%
[2022-04-10 01:18:14 large] (main.py 226): INFO Train: [289/300][0/2502]	eta 5:20:42 lr 0.000007	time 7.6910 (7.6910)	loss 3.5267 (3.5267)	grad_norm 14.8628 (14.8628)	mem 8929MB
[2022-04-10 01:19:05 large] (main.py 226): INFO Train: [289/300][100/2502]	eta 0:23:19 lr 0.000007	time 0.4820 (0.5825)	loss 3.0135 (2.8395)	grad_norm 7.4835 (10.5818)	mem 8929MB
[2022-04-10 01:19:56 large] (main.py 226): INFO Train: [289/300][200/2502]	eta 0:20:51 lr 0.000007	time 0.5023 (0.5435)	loss 1.9767 (2.7855)	grad_norm 6.9205 (11.3584)	mem 8929MB
[2022-04-10 01:20:48 large] (main.py 226): INFO Train: [289/300][300/2502]	eta 0:19:42 lr 0.000007	time 0.5342 (0.5370)	loss 3.2603 (2.8129)	grad_norm 9.2697 (11.0780)	mem 8929MB
[2022-04-10 01:21:39 large] (main.py 226): INFO Train: [289/300][400/2502]	eta 0:18:36 lr 0.000007	time 0.4950 (0.5311)	loss 3.6090 (2.7984)	grad_norm 9.4948 (11.0756)	mem 8929MB
[2022-04-10 01:22:29 large] (main.py 226): INFO Train: [289/300][500/2502]	eta 0:17:28 lr 0.000007	time 0.5199 (0.5235)	loss 2.8025 (2.7992)	grad_norm 6.6599 (10.8397)	mem 8929MB
[2022-04-10 01:23:20 large] (main.py 226): INFO Train: [289/300][600/2502]	eta 0:16:33 lr 0.000007	time 0.5131 (0.5224)	loss 2.8479 (2.7975)	grad_norm 7.7151 (10.7638)	mem 8929MB
[2022-04-10 01:24:12 large] (main.py 226): INFO Train: [289/300][700/2502]	eta 0:15:40 lr 0.000007	time 0.5122 (0.5222)	loss 2.9416 (2.8032)	grad_norm 11.4604 (10.7229)	mem 8929MB
[2022-04-10 01:25:04 large] (main.py 226): INFO Train: [289/300][800/2502]	eta 0:14:48 lr 0.000007	time 0.5263 (0.5220)	loss 3.1016 (2.7904)	grad_norm 13.5286 (10.6972)	mem 8929MB
[2022-04-10 01:25:56 large] (main.py 226): INFO Train: [289/300][900/2502]	eta 0:13:54 lr 0.000007	time 0.4934 (0.5207)	loss 1.7379 (2.7912)	grad_norm 10.4759 (10.7193)	mem 8929MB
[2022-04-10 01:26:46 large] (main.py 226): INFO Train: [289/300][1000/2502]	eta 0:13:00 lr 0.000007	time 0.5399 (0.5194)	loss 2.0988 (2.7963)	grad_norm 8.6867 (10.6943)	mem 8929MB
[2022-04-10 01:27:36 large] (main.py 226): INFO Train: [289/300][1100/2502]	eta 0:12:05 lr 0.000007	time 0.5309 (0.5178)	loss 3.1186 (2.8002)	grad_norm 9.8419 (10.7111)	mem 8929MB
[2022-04-10 01:28:26 large] (main.py 226): INFO Train: [289/300][1200/2502]	eta 0:11:12 lr 0.000007	time 0.5259 (0.5161)	loss 3.1372 (2.7980)	grad_norm 9.7796 (10.7125)	mem 8929MB
[2022-04-10 01:29:16 large] (main.py 226): INFO Train: [289/300][1300/2502]	eta 0:10:18 lr 0.000006	time 0.5202 (0.5145)	loss 1.7238 (2.7891)	grad_norm 7.8905 (10.8336)	mem 8929MB
[2022-04-10 01:30:07 large] (main.py 226): INFO Train: [289/300][1400/2502]	eta 0:09:26 lr 0.000006	time 0.5098 (0.5143)	loss 2.3407 (2.7828)	grad_norm 13.2673 (10.8899)	mem 8929MB
[2022-04-10 01:30:56 large] (main.py 226): INFO Train: [289/300][1500/2502]	eta 0:08:33 lr 0.000006	time 0.4762 (0.5127)	loss 3.1284 (2.7845)	grad_norm 7.7959 (10.8771)	mem 8929MB
[2022-04-10 01:31:47 large] (main.py 226): INFO Train: [289/300][1600/2502]	eta 0:07:42 lr 0.000006	time 0.4847 (0.5128)	loss 2.7987 (2.7847)	grad_norm 7.9757 (nan)	mem 8929MB
[2022-04-10 01:32:37 large] (main.py 226): INFO Train: [289/300][1700/2502]	eta 0:06:50 lr 0.000006	time 0.5052 (0.5121)	loss 2.4860 (2.7769)	grad_norm 9.0266 (nan)	mem 8929MB
[2022-04-10 01:33:28 large] (main.py 226): INFO Train: [289/300][1800/2502]	eta 0:05:59 lr 0.000006	time 0.4903 (0.5115)	loss 2.9765 (2.7807)	grad_norm 8.8103 (nan)	mem 8929MB
[2022-04-10 01:34:18 large] (main.py 226): INFO Train: [289/300][1900/2502]	eta 0:05:07 lr 0.000006	time 0.4933 (0.5110)	loss 3.0699 (2.7807)	grad_norm 13.9832 (nan)	mem 8929MB
[2022-04-10 01:35:09 large] (main.py 226): INFO Train: [289/300][2000/2502]	eta 0:04:16 lr 0.000006	time 0.5287 (0.5109)	loss 3.0360 (2.7791)	grad_norm 19.9227 (nan)	mem 8929MB
[2022-04-10 01:35:59 large] (main.py 226): INFO Train: [289/300][2100/2502]	eta 0:03:25 lr 0.000006	time 0.5165 (0.5105)	loss 2.8248 (2.7736)	grad_norm 10.7953 (nan)	mem 8929MB
[2022-04-10 01:36:50 large] (main.py 226): INFO Train: [289/300][2200/2502]	eta 0:02:34 lr 0.000006	time 0.5218 (0.5106)	loss 2.9690 (2.7723)	grad_norm 9.4909 (nan)	mem 8929MB
[2022-04-10 01:37:41 large] (main.py 226): INFO Train: [289/300][2300/2502]	eta 0:01:43 lr 0.000006	time 0.4858 (0.5104)	loss 2.8486 (2.7728)	grad_norm 8.8936 (nan)	mem 8929MB
[2022-04-10 01:38:29 large] (main.py 226): INFO Train: [289/300][2400/2502]	eta 0:00:51 lr 0.000006	time 0.5071 (0.5094)	loss 2.9356 (2.7739)	grad_norm 12.7435 (nan)	mem 8929MB
[2022-04-10 01:39:18 large] (main.py 226): INFO Train: [289/300][2500/2502]	eta 0:00:01 lr 0.000006	time 0.4850 (0.5085)	loss 1.7764 (2.7760)	grad_norm 9.6097 (nan)	mem 8929MB
[2022-04-10 01:39:19 large] (main.py 233): INFO EPOCH 289 training takes 0:21:12
[2022-04-10 01:39:26 large] (main.py 273): INFO Test: [0/98]	Time 6.330 (6.330)	Loss 1.0112 (1.0112)	Acc@1 80.078 (80.078)	Acc@5 96.094 (96.094)	Mem 8929MB
[2022-04-10 01:39:51 large] (main.py 279): INFO  * Acc@1 81.860 Acc@5 95.658
[2022-04-10 01:39:51 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.9%
[2022-04-10 01:39:51 large] (main.py 148): INFO Max accuracy: 81.90%
[2022-04-10 01:40:00 large] (main.py 226): INFO Train: [290/300][0/2502]	eta 5:55:11 lr 0.000006	time 8.5179 (8.5179)	loss 3.1576 (3.1576)	grad_norm 10.6243 (10.6243)	mem 8929MB
[2022-04-10 01:40:50 large] (main.py 226): INFO Train: [290/300][100/2502]	eta 0:23:09 lr 0.000006	time 0.4950 (0.5784)	loss 2.4680 (2.6859)	grad_norm 13.0954 (11.6141)	mem 8929MB
[2022-04-10 01:41:42 large] (main.py 226): INFO Train: [290/300][200/2502]	eta 0:21:06 lr 0.000006	time 0.5372 (0.5500)	loss 3.2860 (2.7164)	grad_norm 7.0889 (11.6372)	mem 8929MB
[2022-04-10 01:42:35 large] (main.py 226): INFO Train: [290/300][300/2502]	eta 0:19:55 lr 0.000006	time 0.6052 (0.5429)	loss 2.8775 (2.7047)	grad_norm 19.7645 (11.4531)	mem 8929MB
[2022-04-10 01:43:27 large] (main.py 226): INFO Train: [290/300][400/2502]	eta 0:18:49 lr 0.000006	time 0.5113 (0.5372)	loss 2.9594 (2.7149)	grad_norm 8.0272 (11.2736)	mem 8929MB
[2022-04-10 01:44:19 large] (main.py 226): INFO Train: [290/300][500/2502]	eta 0:17:48 lr 0.000006	time 0.5112 (0.5337)	loss 3.2448 (2.7211)	grad_norm 9.7035 (11.1666)	mem 8929MB
[2022-04-10 01:45:08 large] (main.py 226): INFO Train: [290/300][600/2502]	eta 0:16:42 lr 0.000006	time 0.4874 (0.5270)	loss 2.7959 (2.7407)	grad_norm 8.3683 (11.1686)	mem 8929MB
[2022-04-10 01:45:59 large] (main.py 226): INFO Train: [290/300][700/2502]	eta 0:15:45 lr 0.000006	time 0.4513 (0.5245)	loss 3.0640 (2.7366)	grad_norm 12.6994 (11.0096)	mem 8929MB
[2022-04-10 01:46:49 large] (main.py 226): INFO Train: [290/300][800/2502]	eta 0:14:47 lr 0.000006	time 0.5033 (0.5214)	loss 2.5525 (2.7435)	grad_norm 8.7809 (10.9279)	mem 8929MB
[2022-04-10 01:47:39 large] (main.py 226): INFO Train: [290/300][900/2502]	eta 0:13:51 lr 0.000006	time 0.5713 (0.5189)	loss 3.2337 (2.7407)	grad_norm 10.8413 (10.8380)	mem 8929MB
[2022-04-10 01:48:29 large] (main.py 226): INFO Train: [290/300][1000/2502]	eta 0:12:56 lr 0.000006	time 0.4976 (0.5172)	loss 3.0170 (2.7489)	grad_norm 12.2812 (10.7668)	mem 8929MB
[2022-04-10 01:49:20 large] (main.py 226): INFO Train: [290/300][1100/2502]	eta 0:12:04 lr 0.000006	time 0.4848 (0.5169)	loss 2.8988 (2.7509)	grad_norm 8.3437 (10.6458)	mem 8929MB
[2022-04-10 01:50:10 large] (main.py 226): INFO Train: [290/300][1200/2502]	eta 0:11:10 lr 0.000006	time 0.4856 (0.5148)	loss 3.2297 (2.7513)	grad_norm 9.7431 (10.5597)	mem 8929MB
[2022-04-10 01:50:59 large] (main.py 226): INFO Train: [290/300][1300/2502]	eta 0:10:17 lr 0.000006	time 0.4928 (0.5135)	loss 2.7108 (2.7560)	grad_norm 9.3729 (10.5714)	mem 8929MB
[2022-04-10 01:51:50 large] (main.py 226): INFO Train: [290/300][1400/2502]	eta 0:09:24 lr 0.000006	time 0.5666 (0.5126)	loss 2.9165 (2.7616)	grad_norm 7.9751 (10.5284)	mem 8929MB
[2022-04-10 01:52:39 large] (main.py 226): INFO Train: [290/300][1500/2502]	eta 0:08:32 lr 0.000006	time 0.4891 (0.5113)	loss 2.2985 (2.7624)	grad_norm 13.3995 (10.5547)	mem 8929MB
[2022-04-10 01:53:30 large] (main.py 226): INFO Train: [290/300][1600/2502]	eta 0:07:41 lr 0.000006	time 0.5196 (0.5112)	loss 2.6059 (2.7596)	grad_norm 14.9870 (10.5578)	mem 8929MB
[2022-04-10 01:54:22 large] (main.py 226): INFO Train: [290/300][1700/2502]	eta 0:06:50 lr 0.000006	time 0.4883 (0.5118)	loss 2.8251 (2.7643)	grad_norm 9.3656 (10.5945)	mem 8929MB
[2022-04-10 01:55:12 large] (main.py 226): INFO Train: [290/300][1800/2502]	eta 0:05:58 lr 0.000006	time 0.4474 (0.5112)	loss 2.5146 (2.7668)	grad_norm 7.2593 (10.6017)	mem 8929MB
[2022-04-10 01:56:02 large] (main.py 226): INFO Train: [290/300][1900/2502]	eta 0:05:07 lr 0.000006	time 0.4949 (0.5105)	loss 3.1176 (2.7661)	grad_norm 8.3905 (10.6021)	mem 8929MB
[2022-04-10 01:56:51 large] (main.py 226): INFO Train: [290/300][2000/2502]	eta 0:04:15 lr 0.000006	time 0.4875 (0.5095)	loss 2.8525 (2.7655)	grad_norm 9.6032 (10.6469)	mem 8929MB
[2022-04-10 01:57:39 large] (main.py 226): INFO Train: [290/300][2100/2502]	eta 0:03:24 lr 0.000006	time 0.4866 (0.5084)	loss 2.5698 (2.7673)	grad_norm 28.3997 (10.6736)	mem 8929MB
[2022-04-10 01:58:30 large] (main.py 226): INFO Train: [290/300][2200/2502]	eta 0:02:33 lr 0.000006	time 0.4751 (0.5080)	loss 3.3658 (2.7643)	grad_norm 11.5416 (10.7227)	mem 8929MB
[2022-04-10 01:59:19 large] (main.py 226): INFO Train: [290/300][2300/2502]	eta 0:01:42 lr 0.000006	time 0.5129 (0.5074)	loss 3.1151 (2.7611)	grad_norm 10.6904 (10.7158)	mem 8929MB
[2022-04-10 02:00:10 large] (main.py 226): INFO Train: [290/300][2400/2502]	eta 0:00:51 lr 0.000006	time 0.5371 (0.5077)	loss 3.0244 (2.7605)	grad_norm 8.8815 (10.7010)	mem 8929MB
[2022-04-10 02:01:02 large] (main.py 226): INFO Train: [290/300][2500/2502]	eta 0:00:01 lr 0.000006	time 0.5083 (0.5079)	loss 3.1211 (2.7636)	grad_norm 8.8867 (10.6884)	mem 8929MB
[2022-04-10 02:01:03 large] (main.py 233): INFO EPOCH 290 training takes 0:21:11
[2022-04-10 02:01:08 large] (main.py 273): INFO Test: [0/98]	Time 5.610 (5.610)	Loss 1.0140 (1.0140)	Acc@1 82.031 (82.031)	Acc@5 95.312 (95.312)	Mem 8929MB
[2022-04-10 02:01:35 large] (main.py 279): INFO  * Acc@1 81.898 Acc@5 95.620
[2022-04-10 02:01:35 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.9%
[2022-04-10 02:01:35 large] (main.py 148): INFO Max accuracy: 81.90%
[2022-04-10 02:01:43 large] (main.py 226): INFO Train: [291/300][0/2502]	eta 5:05:25 lr 0.000006	time 7.3241 (7.3241)	loss 2.7720 (2.7720)	grad_norm 6.5070 (6.5070)	mem 8929MB
[2022-04-10 02:02:34 large] (main.py 226): INFO Train: [291/300][100/2502]	eta 0:23:24 lr 0.000006	time 0.5129 (0.5847)	loss 2.5331 (2.8297)	grad_norm 9.8782 (10.7772)	mem 8929MB
[2022-04-10 02:03:25 large] (main.py 226): INFO Train: [291/300][200/2502]	eta 0:21:00 lr 0.000006	time 0.4856 (0.5477)	loss 3.2936 (2.7784)	grad_norm 14.7353 (10.9689)	mem 8929MB
[2022-04-10 02:04:14 large] (main.py 226): INFO Train: [291/300][300/2502]	eta 0:19:23 lr 0.000006	time 0.4666 (0.5283)	loss 1.7227 (2.7749)	grad_norm 12.6916 (10.7082)	mem 8929MB
[2022-04-10 02:05:03 large] (main.py 226): INFO Train: [291/300][400/2502]	eta 0:18:09 lr 0.000006	time 0.5148 (0.5184)	loss 2.5170 (2.7681)	grad_norm 11.5532 (10.8587)	mem 8929MB
[2022-04-10 02:05:52 large] (main.py 226): INFO Train: [291/300][500/2502]	eta 0:17:04 lr 0.000006	time 0.4566 (0.5117)	loss 2.9568 (2.7647)	grad_norm 10.4506 (10.7621)	mem 8929MB
[2022-04-10 02:06:42 large] (main.py 226): INFO Train: [291/300][600/2502]	eta 0:16:12 lr 0.000006	time 0.5003 (0.5112)	loss 3.2338 (2.7653)	grad_norm 8.5491 (nan)	mem 8929MB
[2022-04-10 02:07:33 large] (main.py 226): INFO Train: [291/300][700/2502]	eta 0:15:20 lr 0.000006	time 0.4755 (0.5110)	loss 2.9419 (2.7736)	grad_norm 8.9544 (nan)	mem 8929MB
[2022-04-10 02:08:22 large] (main.py 226): INFO Train: [291/300][800/2502]	eta 0:14:24 lr 0.000006	time 0.4879 (0.5081)	loss 3.2321 (2.7691)	grad_norm 11.0635 (nan)	mem 8929MB
[2022-04-10 02:09:12 large] (main.py 226): INFO Train: [291/300][900/2502]	eta 0:13:32 lr 0.000006	time 0.5325 (0.5074)	loss 1.8414 (2.7575)	grad_norm 9.8536 (nan)	mem 8929MB
[2022-04-10 02:10:04 large] (main.py 226): INFO Train: [291/300][1000/2502]	eta 0:12:44 lr 0.000006	time 0.4910 (0.5087)	loss 3.1312 (2.7625)	grad_norm 13.9125 (nan)	mem 8929MB
[2022-04-10 02:10:54 large] (main.py 226): INFO Train: [291/300][1100/2502]	eta 0:11:51 lr 0.000006	time 0.4677 (0.5072)	loss 2.8307 (2.7608)	grad_norm 8.5297 (nan)	mem 8929MB
[2022-04-10 02:11:43 large] (main.py 226): INFO Train: [291/300][1200/2502]	eta 0:10:58 lr 0.000006	time 0.5064 (0.5059)	loss 3.0296 (2.7576)	grad_norm 6.4870 (nan)	mem 8929MB
[2022-04-10 02:12:32 large] (main.py 226): INFO Train: [291/300][1300/2502]	eta 0:10:06 lr 0.000006	time 0.5035 (0.5048)	loss 3.2062 (2.7643)	grad_norm 10.4633 (nan)	mem 8929MB
[2022-04-10 02:13:23 large] (main.py 226): INFO Train: [291/300][1400/2502]	eta 0:09:17 lr 0.000006	time 0.5391 (0.5055)	loss 2.9188 (2.7707)	grad_norm 10.0233 (nan)	mem 8929MB
[2022-04-10 02:14:16 large] (main.py 226): INFO Train: [291/300][1500/2502]	eta 0:08:27 lr 0.000006	time 0.4726 (0.5067)	loss 2.9129 (2.7729)	grad_norm 12.0587 (nan)	mem 8929MB
[2022-04-10 02:15:05 large] (main.py 226): INFO Train: [291/300][1600/2502]	eta 0:07:36 lr 0.000006	time 0.4942 (0.5057)	loss 2.6819 (2.7739)	grad_norm 11.5553 (nan)	mem 8929MB
[2022-04-10 02:15:55 large] (main.py 226): INFO Train: [291/300][1700/2502]	eta 0:06:45 lr 0.000006	time 0.5137 (0.5053)	loss 2.8650 (2.7776)	grad_norm 15.7424 (nan)	mem 8929MB
[2022-04-10 02:16:46 large] (main.py 226): INFO Train: [291/300][1800/2502]	eta 0:05:54 lr 0.000006	time 0.4732 (0.5056)	loss 2.1289 (2.7813)	grad_norm 8.9173 (nan)	mem 8929MB
[2022-04-10 02:17:36 large] (main.py 226): INFO Train: [291/300][1900/2502]	eta 0:05:04 lr 0.000006	time 0.5535 (0.5055)	loss 3.5906 (2.7778)	grad_norm 8.3228 (nan)	mem 8929MB
[2022-04-10 02:18:25 large] (main.py 226): INFO Train: [291/300][2000/2502]	eta 0:04:13 lr 0.000006	time 0.5311 (0.5047)	loss 2.5804 (2.7788)	grad_norm 9.7618 (nan)	mem 8929MB
[2022-04-10 02:19:17 large] (main.py 226): INFO Train: [291/300][2100/2502]	eta 0:03:23 lr 0.000006	time 0.5130 (0.5051)	loss 3.2683 (2.7781)	grad_norm 7.9882 (nan)	mem 8929MB
[2022-04-10 02:20:09 large] (main.py 226): INFO Train: [291/300][2200/2502]	eta 0:02:32 lr 0.000006	time 0.5723 (0.5060)	loss 3.0144 (2.7772)	grad_norm 8.5724 (nan)	mem 8929MB
[2022-04-10 02:21:00 large] (main.py 226): INFO Train: [291/300][2300/2502]	eta 0:01:42 lr 0.000006	time 0.4985 (0.5061)	loss 2.9449 (2.7817)	grad_norm 18.4480 (nan)	mem 8929MB
[2022-04-10 02:21:49 large] (main.py 226): INFO Train: [291/300][2400/2502]	eta 0:00:51 lr 0.000006	time 0.5188 (0.5055)	loss 3.1796 (2.7830)	grad_norm 9.6789 (nan)	mem 8929MB
[2022-04-10 02:22:39 large] (main.py 226): INFO Train: [291/300][2500/2502]	eta 0:00:01 lr 0.000006	time 0.4943 (0.5052)	loss 3.0844 (2.7862)	grad_norm 9.8696 (nan)	mem 8929MB
[2022-04-10 02:22:40 large] (main.py 233): INFO EPOCH 291 training takes 0:21:04
[2022-04-10 02:22:46 large] (main.py 273): INFO Test: [0/98]	Time 6.666 (6.666)	Loss 1.1247 (1.1247)	Acc@1 78.711 (78.711)	Acc@5 95.312 (95.312)	Mem 8929MB
[2022-04-10 02:23:12 large] (main.py 279): INFO  * Acc@1 81.902 Acc@5 95.644
[2022-04-10 02:23:12 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.9%
[2022-04-10 02:23:12 large] (main.py 148): INFO Max accuracy: 81.90%
[2022-04-10 02:23:19 large] (main.py 226): INFO Train: [292/300][0/2502]	eta 4:56:00 lr 0.000006	time 7.0985 (7.0985)	loss 2.9272 (2.9272)	grad_norm 7.8152 (7.8152)	mem 8929MB
[2022-04-10 02:24:10 large] (main.py 226): INFO Train: [292/300][100/2502]	eta 0:23:04 lr 0.000006	time 0.5454 (0.5766)	loss 3.1075 (2.8811)	grad_norm 17.8685 (10.9826)	mem 8929MB
[2022-04-10 02:24:59 large] (main.py 226): INFO Train: [292/300][200/2502]	eta 0:20:28 lr 0.000006	time 0.4876 (0.5336)	loss 2.3940 (2.8082)	grad_norm 13.2134 (10.6749)	mem 8929MB
[2022-04-10 02:25:48 large] (main.py 226): INFO Train: [292/300][300/2502]	eta 0:19:01 lr 0.000006	time 0.4810 (0.5182)	loss 2.9782 (2.7821)	grad_norm 6.4230 (10.4663)	mem 8929MB
[2022-04-10 02:26:38 large] (main.py 226): INFO Train: [292/300][400/2502]	eta 0:18:00 lr 0.000006	time 0.4986 (0.5138)	loss 2.4131 (2.7847)	grad_norm 16.6306 (10.3365)	mem 8929MB
[2022-04-10 02:27:30 large] (main.py 226): INFO Train: [292/300][500/2502]	eta 0:17:12 lr 0.000006	time 0.5325 (0.5157)	loss 2.9246 (2.7693)	grad_norm 10.8020 (10.1848)	mem 8929MB
[2022-04-10 02:28:22 large] (main.py 226): INFO Train: [292/300][600/2502]	eta 0:16:23 lr 0.000006	time 0.5491 (0.5169)	loss 3.1334 (2.7756)	grad_norm 10.0147 (10.2815)	mem 8929MB
[2022-04-10 02:29:14 large] (main.py 226): INFO Train: [292/300][700/2502]	eta 0:15:31 lr 0.000006	time 0.5084 (0.5170)	loss 2.9891 (2.7754)	grad_norm 9.7398 (10.5747)	mem 8929MB
[2022-04-10 02:30:06 large] (main.py 226): INFO Train: [292/300][800/2502]	eta 0:14:40 lr 0.000006	time 0.5019 (0.5172)	loss 2.1364 (2.7790)	grad_norm 6.9005 (10.5747)	mem 8929MB
[2022-04-10 02:30:55 large] (main.py 226): INFO Train: [292/300][900/2502]	eta 0:13:43 lr 0.000006	time 0.4875 (0.5143)	loss 3.0004 (2.7834)	grad_norm 7.3009 (10.6285)	mem 8929MB
[2022-04-10 02:31:44 large] (main.py 226): INFO Train: [292/300][1000/2502]	eta 0:12:48 lr 0.000006	time 0.4795 (0.5118)	loss 3.2410 (2.7802)	grad_norm 15.5899 (nan)	mem 8929MB
[2022-04-10 02:32:34 large] (main.py 226): INFO Train: [292/300][1100/2502]	eta 0:11:56 lr 0.000006	time 0.5449 (0.5110)	loss 3.0450 (2.7809)	grad_norm 8.3374 (nan)	mem 8929MB
[2022-04-10 02:33:26 large] (main.py 226): INFO Train: [292/300][1200/2502]	eta 0:11:05 lr 0.000006	time 0.5048 (0.5114)	loss 2.9334 (2.7766)	grad_norm 8.3819 (nan)	mem 8929MB
[2022-04-10 02:34:18 large] (main.py 226): INFO Train: [292/300][1300/2502]	eta 0:10:15 lr 0.000006	time 0.4509 (0.5120)	loss 3.2222 (2.7758)	grad_norm 19.4093 (nan)	mem 8929MB
[2022-04-10 02:35:09 large] (main.py 226): INFO Train: [292/300][1400/2502]	eta 0:09:24 lr 0.000006	time 0.4797 (0.5120)	loss 2.0052 (2.7716)	grad_norm 9.7109 (nan)	mem 8929MB
[2022-04-10 02:35:57 large] (main.py 226): INFO Train: [292/300][1500/2502]	eta 0:08:31 lr 0.000006	time 0.4673 (0.5101)	loss 3.0285 (2.7743)	grad_norm 10.9632 (nan)	mem 8929MB
[2022-04-10 02:36:46 large] (main.py 226): INFO Train: [292/300][1600/2502]	eta 0:07:38 lr 0.000006	time 0.4662 (0.5088)	loss 2.8551 (2.7750)	grad_norm 8.4168 (nan)	mem 8929MB
[2022-04-10 02:37:36 large] (main.py 226): INFO Train: [292/300][1700/2502]	eta 0:06:47 lr 0.000006	time 0.5387 (0.5080)	loss 2.0342 (2.7719)	grad_norm 12.5964 (nan)	mem 8929MB
[2022-04-10 02:38:26 large] (main.py 226): INFO Train: [292/300][1800/2502]	eta 0:05:56 lr 0.000006	time 0.5243 (0.5074)	loss 3.1428 (2.7727)	grad_norm 12.0311 (nan)	mem 8929MB
[2022-04-10 02:39:15 large] (main.py 226): INFO Train: [292/300][1900/2502]	eta 0:05:05 lr 0.000006	time 0.5062 (0.5068)	loss 1.9598 (2.7743)	grad_norm 9.6746 (nan)	mem 8929MB
[2022-04-10 02:40:07 large] (main.py 226): INFO Train: [292/300][2000/2502]	eta 0:04:14 lr 0.000006	time 0.4970 (0.5074)	loss 1.9327 (2.7717)	grad_norm 7.3550 (nan)	mem 8929MB
[2022-04-10 02:40:59 large] (main.py 226): INFO Train: [292/300][2100/2502]	eta 0:03:24 lr 0.000006	time 0.5295 (0.5080)	loss 2.7433 (2.7731)	grad_norm 9.9681 (nan)	mem 8929MB
[2022-04-10 02:41:51 large] (main.py 226): INFO Train: [292/300][2200/2502]	eta 0:02:33 lr 0.000006	time 0.5207 (0.5085)	loss 2.7548 (2.7710)	grad_norm 13.4852 (nan)	mem 8929MB
[2022-04-10 02:42:41 large] (main.py 226): INFO Train: [292/300][2300/2502]	eta 0:01:42 lr 0.000006	time 0.5090 (0.5082)	loss 3.3537 (2.7735)	grad_norm 14.9901 (nan)	mem 8929MB
[2022-04-10 02:43:31 large] (main.py 226): INFO Train: [292/300][2400/2502]	eta 0:00:51 lr 0.000006	time 0.5002 (0.5077)	loss 3.0656 (2.7733)	grad_norm 10.2863 (nan)	mem 8929MB
[2022-04-10 02:44:22 large] (main.py 226): INFO Train: [292/300][2500/2502]	eta 0:00:01 lr 0.000006	time 0.4996 (0.5077)	loss 2.6746 (2.7708)	grad_norm 7.3484 (nan)	mem 8929MB
[2022-04-10 02:44:23 large] (main.py 233): INFO EPOCH 292 training takes 0:21:10
[2022-04-10 02:44:29 large] (main.py 273): INFO Test: [0/98]	Time 5.874 (5.874)	Loss 0.9230 (0.9230)	Acc@1 83.789 (83.789)	Acc@5 96.875 (96.875)	Mem 8929MB
[2022-04-10 02:44:55 large] (main.py 279): INFO  * Acc@1 81.888 Acc@5 95.638
[2022-04-10 02:44:55 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.9%
[2022-04-10 02:44:55 large] (main.py 148): INFO Max accuracy: 81.90%
[2022-04-10 02:45:03 large] (main.py 226): INFO Train: [293/300][0/2502]	eta 5:42:37 lr 0.000006	time 8.2164 (8.2164)	loss 3.3850 (3.3850)	grad_norm 9.3179 (9.3179)	mem 8929MB
[2022-04-10 02:45:54 large] (main.py 226): INFO Train: [293/300][100/2502]	eta 0:23:32 lr 0.000006	time 0.4670 (0.5882)	loss 2.4908 (2.8197)	grad_norm 10.5119 (11.4345)	mem 8929MB
[2022-04-10 02:46:44 large] (main.py 226): INFO Train: [293/300][200/2502]	eta 0:20:45 lr 0.000006	time 0.5163 (0.5411)	loss 3.1326 (2.7844)	grad_norm 9.5087 (11.1813)	mem 8929MB
[2022-04-10 02:47:32 large] (main.py 226): INFO Train: [293/300][300/2502]	eta 0:19:09 lr 0.000006	time 0.4502 (0.5220)	loss 3.2483 (2.7629)	grad_norm 8.9514 (11.2672)	mem 8929MB
[2022-04-10 02:48:23 large] (main.py 226): INFO Train: [293/300][400/2502]	eta 0:18:08 lr 0.000006	time 0.5390 (0.5177)	loss 3.2273 (2.7625)	grad_norm 17.4431 (11.4120)	mem 8929MB
[2022-04-10 02:49:15 large] (main.py 226): INFO Train: [293/300][500/2502]	eta 0:17:17 lr 0.000006	time 0.5217 (0.5182)	loss 2.2525 (2.7615)	grad_norm 8.9690 (11.2321)	mem 8929MB
[2022-04-10 02:50:05 large] (main.py 226): INFO Train: [293/300][600/2502]	eta 0:16:20 lr 0.000006	time 0.4880 (0.5155)	loss 3.1427 (2.7580)	grad_norm 74.6296 (11.1916)	mem 8929MB
[2022-04-10 02:50:56 large] (main.py 226): INFO Train: [293/300][700/2502]	eta 0:15:27 lr 0.000006	time 0.4875 (0.5146)	loss 3.2445 (2.7571)	grad_norm 7.5580 (11.2261)	mem 8929MB
[2022-04-10 02:51:47 large] (main.py 226): INFO Train: [293/300][800/2502]	eta 0:14:35 lr 0.000006	time 0.5386 (0.5142)	loss 2.7308 (2.7584)	grad_norm 8.0707 (11.2425)	mem 8929MB
[2022-04-10 02:52:38 large] (main.py 226): INFO Train: [293/300][900/2502]	eta 0:13:42 lr 0.000006	time 0.4937 (0.5133)	loss 2.6904 (2.7544)	grad_norm 9.1180 (11.0881)	mem 8929MB
[2022-04-10 02:53:28 large] (main.py 226): INFO Train: [293/300][1000/2502]	eta 0:12:50 lr 0.000006	time 0.5120 (0.5129)	loss 3.3181 (2.7567)	grad_norm 11.8620 (11.0714)	mem 8929MB
[2022-04-10 02:54:19 large] (main.py 226): INFO Train: [293/300][1100/2502]	eta 0:11:57 lr 0.000006	time 0.5282 (0.5119)	loss 2.7144 (2.7612)	grad_norm 8.6504 (nan)	mem 8929MB
[2022-04-10 02:55:10 large] (main.py 226): INFO Train: [293/300][1200/2502]	eta 0:11:06 lr 0.000006	time 0.5293 (0.5122)	loss 3.0750 (2.7624)	grad_norm 8.8629 (nan)	mem 8929MB
[2022-04-10 02:56:02 large] (main.py 226): INFO Train: [293/300][1300/2502]	eta 0:10:16 lr 0.000006	time 0.4903 (0.5128)	loss 2.7434 (2.7655)	grad_norm 10.5046 (nan)	mem 8929MB
[2022-04-10 02:56:52 large] (main.py 226): INFO Train: [293/300][1400/2502]	eta 0:09:23 lr 0.000006	time 0.5138 (0.5118)	loss 3.1282 (2.7565)	grad_norm 6.9632 (nan)	mem 8929MB
[2022-04-10 02:57:43 large] (main.py 226): INFO Train: [293/300][1500/2502]	eta 0:08:32 lr 0.000006	time 0.4714 (0.5114)	loss 2.9747 (2.7600)	grad_norm 9.5818 (nan)	mem 8929MB
[2022-04-10 02:58:34 large] (main.py 226): INFO Train: [293/300][1600/2502]	eta 0:07:41 lr 0.000006	time 0.5033 (0.5114)	loss 3.2298 (2.7617)	grad_norm 9.0105 (nan)	mem 8929MB
[2022-04-10 02:59:23 large] (main.py 226): INFO Train: [293/300][1700/2502]	eta 0:06:49 lr 0.000006	time 0.4924 (0.5105)	loss 2.6771 (2.7649)	grad_norm 8.6039 (nan)	mem 8929MB
[2022-04-10 03:00:12 large] (main.py 226): INFO Train: [293/300][1800/2502]	eta 0:05:57 lr 0.000006	time 0.4604 (0.5093)	loss 2.7062 (2.7616)	grad_norm 10.4748 (nan)	mem 8929MB
[2022-04-10 03:01:03 large] (main.py 226): INFO Train: [293/300][1900/2502]	eta 0:05:06 lr 0.000006	time 0.5022 (0.5092)	loss 3.1021 (2.7641)	grad_norm 8.7107 (nan)	mem 8929MB
[2022-04-10 03:01:55 large] (main.py 226): INFO Train: [293/300][2000/2502]	eta 0:04:15 lr 0.000006	time 0.5253 (0.5097)	loss 2.8973 (2.7613)	grad_norm 8.3847 (nan)	mem 8929MB
[2022-04-10 03:02:47 large] (main.py 226): INFO Train: [293/300][2100/2502]	eta 0:03:25 lr 0.000006	time 0.5360 (0.5101)	loss 3.1306 (2.7611)	grad_norm 11.1514 (nan)	mem 8929MB
[2022-04-10 03:03:38 large] (main.py 226): INFO Train: [293/300][2200/2502]	eta 0:02:34 lr 0.000006	time 0.4805 (0.5104)	loss 3.0337 (2.7624)	grad_norm 10.5398 (nan)	mem 8929MB
[2022-04-10 03:04:29 large] (main.py 226): INFO Train: [293/300][2300/2502]	eta 0:01:43 lr 0.000006	time 0.5209 (0.5102)	loss 2.8350 (2.7605)	grad_norm 7.9500 (nan)	mem 8929MB
[2022-04-10 03:05:20 large] (main.py 226): INFO Train: [293/300][2400/2502]	eta 0:00:52 lr 0.000005	time 0.5791 (0.5103)	loss 2.4433 (2.7596)	grad_norm 7.6062 (nan)	mem 8929MB
[2022-04-10 03:06:11 large] (main.py 226): INFO Train: [293/300][2500/2502]	eta 0:00:01 lr 0.000005	time 0.5089 (0.5103)	loss 2.9606 (2.7617)	grad_norm 6.2970 (nan)	mem 8929MB
[2022-04-10 03:06:12 large] (main.py 233): INFO EPOCH 293 training takes 0:21:17
[2022-04-10 03:06:20 large] (main.py 273): INFO Test: [0/98]	Time 7.633 (7.633)	Loss 0.9696 (0.9696)	Acc@1 80.664 (80.664)	Acc@5 94.727 (94.727)	Mem 8929MB
[2022-04-10 03:06:45 large] (main.py 279): INFO  * Acc@1 81.942 Acc@5 95.622
[2022-04-10 03:06:45 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.9%
[2022-04-10 03:06:45 large] (utils.py 57): INFO output/large/default/ckpt_epoch_293.pth saving......
[2022-04-10 03:06:46 large] (utils.py 59): INFO output/large/default/ckpt_epoch_293.pth saved !!!
[2022-04-10 03:06:46 large] (main.py 148): INFO Max accuracy: 81.94%
[2022-04-10 03:06:54 large] (main.py 226): INFO Train: [294/300][0/2502]	eta 5:49:42 lr 0.000005	time 8.3863 (8.3863)	loss 2.9698 (2.9698)	grad_norm 9.0111 (9.0111)	mem 8929MB
[2022-04-10 03:07:44 large] (main.py 226): INFO Train: [294/300][100/2502]	eta 0:22:57 lr 0.000005	time 0.5615 (0.5737)	loss 3.0552 (2.8429)	grad_norm 10.3362 (10.6262)	mem 8929MB
[2022-04-10 03:08:34 large] (main.py 226): INFO Train: [294/300][200/2502]	eta 0:20:39 lr 0.000005	time 0.4798 (0.5384)	loss 2.8066 (2.8082)	grad_norm 11.4687 (10.6835)	mem 8929MB
[2022-04-10 03:09:25 large] (main.py 226): INFO Train: [294/300][300/2502]	eta 0:19:23 lr 0.000005	time 0.5363 (0.5286)	loss 3.0857 (2.7990)	grad_norm 9.1612 (10.7502)	mem 8929MB
[2022-04-10 03:10:14 large] (main.py 226): INFO Train: [294/300][400/2502]	eta 0:18:12 lr 0.000005	time 0.4748 (0.5198)	loss 2.9518 (2.8036)	grad_norm 9.6915 (11.0198)	mem 8929MB
[2022-04-10 03:11:03 large] (main.py 226): INFO Train: [294/300][500/2502]	eta 0:17:07 lr 0.000005	time 0.5004 (0.5130)	loss 2.9463 (2.7779)	grad_norm 8.9127 (10.9668)	mem 8929MB
[2022-04-10 03:11:55 large] (main.py 226): INFO Train: [294/300][600/2502]	eta 0:16:17 lr 0.000005	time 0.5147 (0.5141)	loss 1.9584 (2.7775)	grad_norm 9.4390 (10.9119)	mem 8929MB
[2022-04-10 03:12:47 large] (main.py 226): INFO Train: [294/300][700/2502]	eta 0:15:29 lr 0.000005	time 0.5310 (0.5156)	loss 2.6715 (2.7725)	grad_norm 8.0961 (nan)	mem 8929MB
[2022-04-10 03:13:39 large] (main.py 226): INFO Train: [294/300][800/2502]	eta 0:14:38 lr 0.000005	time 0.5078 (0.5161)	loss 2.9872 (2.7815)	grad_norm 7.9800 (nan)	mem 8929MB
[2022-04-10 03:14:31 large] (main.py 226): INFO Train: [294/300][900/2502]	eta 0:13:47 lr 0.000005	time 0.4532 (0.5162)	loss 2.8480 (2.7828)	grad_norm 17.1530 (nan)	mem 8929MB
[2022-04-10 03:15:23 large] (main.py 226): INFO Train: [294/300][1000/2502]	eta 0:12:56 lr 0.000005	time 0.5202 (0.5168)	loss 2.8940 (2.7867)	grad_norm 12.6377 (nan)	mem 8929MB
[2022-04-10 03:16:15 large] (main.py 226): INFO Train: [294/300][1100/2502]	eta 0:12:04 lr 0.000005	time 0.5047 (0.5167)	loss 3.0252 (2.7871)	grad_norm 10.5620 (nan)	mem 8929MB
[2022-04-10 03:17:07 large] (main.py 226): INFO Train: [294/300][1200/2502]	eta 0:11:12 lr 0.000005	time 0.5314 (0.5169)	loss 2.7035 (2.7832)	grad_norm 7.2201 (nan)	mem 8929MB
[2022-04-10 03:17:55 large] (main.py 226): INFO Train: [294/300][1300/2502]	eta 0:10:18 lr 0.000005	time 0.4823 (0.5147)	loss 3.2104 (2.7789)	grad_norm 13.7088 (nan)	mem 8929MB
[2022-04-10 03:18:45 large] (main.py 226): INFO Train: [294/300][1400/2502]	eta 0:09:25 lr 0.000005	time 0.5120 (0.5131)	loss 3.0702 (2.7806)	grad_norm 9.4664 (nan)	mem 8929MB
[2022-04-10 03:19:35 large] (main.py 226): INFO Train: [294/300][1500/2502]	eta 0:08:33 lr 0.000005	time 0.5300 (0.5126)	loss 2.7894 (2.7863)	grad_norm 12.8986 (nan)	mem 8929MB
[2022-04-10 03:20:26 large] (main.py 226): INFO Train: [294/300][1600/2502]	eta 0:07:42 lr 0.000005	time 0.5441 (0.5123)	loss 2.9872 (2.7875)	grad_norm 12.8305 (nan)	mem 8929MB
[2022-04-10 03:21:17 large] (main.py 226): INFO Train: [294/300][1700/2502]	eta 0:06:50 lr 0.000005	time 0.4642 (0.5119)	loss 3.2816 (2.7869)	grad_norm 8.8285 (nan)	mem 8929MB
[2022-04-10 03:22:05 large] (main.py 226): INFO Train: [294/300][1800/2502]	eta 0:05:58 lr 0.000005	time 0.5607 (0.5105)	loss 2.2162 (2.7849)	grad_norm 12.2170 (nan)	mem 8929MB
[2022-04-10 03:22:54 large] (main.py 226): INFO Train: [294/300][1900/2502]	eta 0:05:06 lr 0.000005	time 0.4520 (0.5095)	loss 3.1073 (2.7852)	grad_norm 11.8605 (nan)	mem 8929MB
[2022-04-10 03:23:44 large] (main.py 226): INFO Train: [294/300][2000/2502]	eta 0:04:15 lr 0.000005	time 0.5264 (0.5090)	loss 3.0401 (2.7849)	grad_norm 8.2624 (nan)	mem 8929MB
[2022-04-10 03:24:37 large] (main.py 226): INFO Train: [294/300][2100/2502]	eta 0:03:24 lr 0.000005	time 0.5954 (0.5097)	loss 2.9860 (2.7850)	grad_norm 9.2912 (nan)	mem 8929MB
[2022-04-10 03:25:29 large] (main.py 226): INFO Train: [294/300][2200/2502]	eta 0:02:34 lr 0.000005	time 0.5901 (0.5101)	loss 2.8655 (2.7817)	grad_norm 33.8973 (nan)	mem 8929MB
[2022-04-10 03:26:19 large] (main.py 226): INFO Train: [294/300][2300/2502]	eta 0:01:42 lr 0.000005	time 0.4899 (0.5098)	loss 2.9214 (2.7782)	grad_norm 9.7920 (nan)	mem 8929MB
[2022-04-10 03:27:10 large] (main.py 226): INFO Train: [294/300][2400/2502]	eta 0:00:51 lr 0.000005	time 0.5296 (0.5097)	loss 3.1543 (2.7797)	grad_norm 9.6564 (nan)	mem 8929MB
[2022-04-10 03:27:59 large] (main.py 226): INFO Train: [294/300][2500/2502]	eta 0:00:01 lr 0.000005	time 0.4995 (0.5092)	loss 3.8008 (2.7805)	grad_norm 7.7464 (nan)	mem 8929MB
[2022-04-10 03:28:00 large] (main.py 233): INFO EPOCH 294 training takes 0:21:14
[2022-04-10 03:28:06 large] (main.py 273): INFO Test: [0/98]	Time 6.020 (6.020)	Loss 0.9526 (0.9526)	Acc@1 83.203 (83.203)	Acc@5 96.289 (96.289)	Mem 8929MB
[2022-04-10 03:28:33 large] (main.py 279): INFO  * Acc@1 81.926 Acc@5 95.562
[2022-04-10 03:28:33 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.9%
[2022-04-10 03:28:33 large] (main.py 148): INFO Max accuracy: 81.94%
[2022-04-10 03:28:39 large] (main.py 226): INFO Train: [295/300][0/2502]	eta 4:34:39 lr 0.000005	time 6.5866 (6.5866)	loss 1.9206 (1.9206)	grad_norm 6.4188 (6.4188)	mem 8929MB
[2022-04-10 03:29:30 large] (main.py 226): INFO Train: [295/300][100/2502]	eta 0:22:47 lr 0.000005	time 0.4768 (0.5693)	loss 3.0847 (2.8034)	grad_norm 9.0070 (10.4604)	mem 8929MB
[2022-04-10 03:30:20 large] (main.py 226): INFO Train: [295/300][200/2502]	eta 0:20:34 lr 0.000005	time 0.4800 (0.5363)	loss 3.3317 (2.7679)	grad_norm 10.5612 (13.0632)	mem 8929MB
[2022-04-10 03:31:10 large] (main.py 226): INFO Train: [295/300][300/2502]	eta 0:19:08 lr 0.000005	time 0.5208 (0.5216)	loss 2.5102 (2.7789)	grad_norm 7.0659 (12.0763)	mem 8929MB
[2022-04-10 03:32:00 large] (main.py 226): INFO Train: [295/300][400/2502]	eta 0:18:04 lr 0.000005	time 0.4890 (0.5160)	loss 3.4494 (2.7765)	grad_norm 9.0379 (11.6749)	mem 8929MB
[2022-04-10 03:32:49 large] (main.py 226): INFO Train: [295/300][500/2502]	eta 0:17:03 lr 0.000005	time 0.4762 (0.5112)	loss 2.3953 (2.7838)	grad_norm 10.0808 (11.2899)	mem 8929MB
[2022-04-10 03:33:38 large] (main.py 226): INFO Train: [295/300][600/2502]	eta 0:16:06 lr 0.000005	time 0.4533 (0.5080)	loss 2.6217 (2.7726)	grad_norm 12.5925 (11.2036)	mem 8929MB
[2022-04-10 03:34:27 large] (main.py 226): INFO Train: [295/300][700/2502]	eta 0:15:11 lr 0.000005	time 0.4917 (0.5057)	loss 2.1967 (2.7732)	grad_norm 7.8196 (11.1559)	mem 8929MB
[2022-04-10 03:35:17 large] (main.py 226): INFO Train: [295/300][800/2502]	eta 0:14:18 lr 0.000005	time 0.4477 (0.5044)	loss 2.0226 (2.7693)	grad_norm 7.9073 (10.9754)	mem 8929MB
[2022-04-10 03:36:06 large] (main.py 226): INFO Train: [295/300][900/2502]	eta 0:13:26 lr 0.000005	time 0.5698 (0.5031)	loss 3.1515 (2.7777)	grad_norm 8.7170 (10.9331)	mem 8929MB
[2022-04-10 03:36:55 large] (main.py 226): INFO Train: [295/300][1000/2502]	eta 0:12:33 lr 0.000005	time 0.4991 (0.5015)	loss 3.1437 (2.7743)	grad_norm 8.1935 (11.0372)	mem 8929MB
[2022-04-10 03:37:46 large] (main.py 226): INFO Train: [295/300][1100/2502]	eta 0:11:45 lr 0.000005	time 0.5306 (0.5030)	loss 2.9102 (2.7682)	grad_norm 9.1399 (11.0153)	mem 8929MB
[2022-04-10 03:38:39 large] (main.py 226): INFO Train: [295/300][1200/2502]	eta 0:10:57 lr 0.000005	time 0.5144 (0.5048)	loss 2.6467 (2.7666)	grad_norm 11.2241 (11.0057)	mem 8929MB
[2022-04-10 03:39:31 large] (main.py 226): INFO Train: [295/300][1300/2502]	eta 0:10:08 lr 0.000005	time 0.5045 (0.5060)	loss 3.1470 (2.7628)	grad_norm 6.1513 (10.9561)	mem 8929MB
[2022-04-10 03:40:23 large] (main.py 226): INFO Train: [295/300][1400/2502]	eta 0:09:18 lr 0.000005	time 0.5045 (0.5070)	loss 1.8580 (2.7673)	grad_norm 9.5292 (10.9280)	mem 8929MB
[2022-04-10 03:41:15 large] (main.py 226): INFO Train: [295/300][1500/2502]	eta 0:08:28 lr 0.000005	time 0.5341 (0.5077)	loss 3.1416 (2.7711)	grad_norm 9.0920 (10.9041)	mem 8929MB
[2022-04-10 03:42:05 large] (main.py 226): INFO Train: [295/300][1600/2502]	eta 0:07:37 lr 0.000005	time 0.5069 (0.5071)	loss 3.0101 (2.7694)	grad_norm 12.1371 (10.9008)	mem 8929MB
[2022-04-10 03:42:55 large] (main.py 226): INFO Train: [295/300][1700/2502]	eta 0:06:46 lr 0.000005	time 0.4902 (0.5067)	loss 2.6322 (2.7735)	grad_norm 10.3254 (10.8890)	mem 8929MB
[2022-04-10 03:43:45 large] (main.py 226): INFO Train: [295/300][1800/2502]	eta 0:05:55 lr 0.000005	time 0.4663 (0.5066)	loss 3.0546 (2.7719)	grad_norm 8.2513 (10.8312)	mem 8929MB
[2022-04-10 03:44:33 large] (main.py 226): INFO Train: [295/300][1900/2502]	eta 0:05:04 lr 0.000005	time 0.5095 (0.5054)	loss 3.0114 (2.7726)	grad_norm 7.6009 (10.8208)	mem 8929MB
[2022-04-10 03:45:24 large] (main.py 226): INFO Train: [295/300][2000/2502]	eta 0:04:13 lr 0.000005	time 0.6283 (0.5056)	loss 2.8029 (2.7725)	grad_norm 8.5148 (10.8517)	mem 8929MB
[2022-04-10 03:46:16 large] (main.py 226): INFO Train: [295/300][2100/2502]	eta 0:03:23 lr 0.000005	time 0.5273 (0.5062)	loss 3.0807 (2.7719)	grad_norm 9.3124 (nan)	mem 8929MB
[2022-04-10 03:47:08 large] (main.py 226): INFO Train: [295/300][2200/2502]	eta 0:02:33 lr 0.000005	time 0.5050 (0.5068)	loss 2.4708 (2.7762)	grad_norm 10.5410 (nan)	mem 8929MB
[2022-04-10 03:47:59 large] (main.py 226): INFO Train: [295/300][2300/2502]	eta 0:01:42 lr 0.000005	time 0.4883 (0.5069)	loss 3.1845 (2.7744)	grad_norm 11.5773 (nan)	mem 8929MB
[2022-04-10 03:48:48 large] (main.py 226): INFO Train: [295/300][2400/2502]	eta 0:00:51 lr 0.000005	time 0.4923 (0.5061)	loss 2.6191 (2.7724)	grad_norm 11.2211 (nan)	mem 8929MB
[2022-04-10 03:49:38 large] (main.py 226): INFO Train: [295/300][2500/2502]	eta 0:00:01 lr 0.000005	time 0.5051 (0.5059)	loss 3.1374 (2.7747)	grad_norm 7.5693 (nan)	mem 8929MB
[2022-04-10 03:49:39 large] (main.py 233): INFO EPOCH 295 training takes 0:21:06
[2022-04-10 03:49:45 large] (main.py 273): INFO Test: [0/98]	Time 6.005 (6.005)	Loss 0.9910 (0.9910)	Acc@1 81.250 (81.250)	Acc@5 95.312 (95.312)	Mem 8929MB
[2022-04-10 03:50:11 large] (main.py 279): INFO  * Acc@1 81.932 Acc@5 95.620
[2022-04-10 03:50:11 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.9%
[2022-04-10 03:50:11 large] (main.py 148): INFO Max accuracy: 81.94%
[2022-04-10 03:50:18 large] (main.py 226): INFO Train: [296/300][0/2502]	eta 5:04:22 lr 0.000005	time 7.2991 (7.2991)	loss 2.9631 (2.9631)	grad_norm 8.9086 (8.9086)	mem 8929MB
[2022-04-10 03:51:10 large] (main.py 226): INFO Train: [296/300][100/2502]	eta 0:23:17 lr 0.000005	time 0.5104 (0.5820)	loss 3.1721 (2.7413)	grad_norm 6.7986 (10.6938)	mem 8929MB
[2022-04-10 03:51:58 large] (main.py 226): INFO Train: [296/300][200/2502]	eta 0:20:26 lr 0.000005	time 0.4663 (0.5327)	loss 3.2071 (2.7469)	grad_norm 9.6064 (10.6914)	mem 8929MB
[2022-04-10 03:52:47 large] (main.py 226): INFO Train: [296/300][300/2502]	eta 0:19:03 lr 0.000005	time 0.5378 (0.5192)	loss 3.0118 (2.7489)	grad_norm 7.8269 (10.5417)	mem 8929MB
[2022-04-10 03:53:37 large] (main.py 226): INFO Train: [296/300][400/2502]	eta 0:18:01 lr 0.000005	time 0.4689 (0.5143)	loss 3.1565 (2.7417)	grad_norm 10.0657 (10.4044)	mem 8929MB
[2022-04-10 03:54:30 large] (main.py 226): INFO Train: [296/300][500/2502]	eta 0:17:13 lr 0.000005	time 0.5292 (0.5162)	loss 2.7631 (2.7577)	grad_norm 8.8979 (10.3925)	mem 8929MB
[2022-04-10 03:55:20 large] (main.py 226): INFO Train: [296/300][600/2502]	eta 0:16:18 lr 0.000005	time 0.5457 (0.5145)	loss 2.9578 (2.7680)	grad_norm 8.9856 (10.3607)	mem 8929MB
[2022-04-10 03:56:10 large] (main.py 226): INFO Train: [296/300][700/2502]	eta 0:15:23 lr 0.000005	time 0.5246 (0.5125)	loss 3.2357 (2.7703)	grad_norm 8.2013 (10.7734)	mem 8929MB
[2022-04-10 03:56:59 large] (main.py 226): INFO Train: [296/300][800/2502]	eta 0:14:27 lr 0.000005	time 0.4771 (0.5096)	loss 3.0498 (2.7737)	grad_norm 11.6685 (10.7380)	mem 8929MB
[2022-04-10 03:57:48 large] (main.py 226): INFO Train: [296/300][900/2502]	eta 0:13:33 lr 0.000005	time 0.4774 (0.5077)	loss 2.0391 (2.7676)	grad_norm 26.6361 (11.1492)	mem 8929MB
[2022-04-10 03:58:37 large] (main.py 226): INFO Train: [296/300][1000/2502]	eta 0:12:39 lr 0.000005	time 0.4835 (0.5056)	loss 3.1504 (2.7658)	grad_norm 10.5020 (11.1882)	mem 8929MB
[2022-04-10 03:59:29 large] (main.py 226): INFO Train: [296/300][1100/2502]	eta 0:11:49 lr 0.000005	time 0.4871 (0.5064)	loss 1.5678 (2.7611)	grad_norm 9.4286 (11.2237)	mem 8929MB
[2022-04-10 04:00:21 large] (main.py 226): INFO Train: [296/300][1200/2502]	eta 0:11:01 lr 0.000005	time 0.5113 (0.5080)	loss 3.0435 (2.7518)	grad_norm 8.4621 (11.1845)	mem 8929MB
[2022-04-10 04:01:10 large] (main.py 226): INFO Train: [296/300][1300/2502]	eta 0:10:09 lr 0.000005	time 0.4753 (0.5067)	loss 3.3172 (2.7549)	grad_norm 8.1583 (11.2112)	mem 8929MB
[2022-04-10 04:02:00 large] (main.py 226): INFO Train: [296/300][1400/2502]	eta 0:09:17 lr 0.000005	time 0.5214 (0.5058)	loss 1.6704 (2.7565)	grad_norm 15.0365 (11.1686)	mem 8929MB
[2022-04-10 04:02:51 large] (main.py 226): INFO Train: [296/300][1500/2502]	eta 0:08:27 lr 0.000005	time 0.5051 (0.5063)	loss 3.2873 (2.7575)	grad_norm 10.0127 (11.1345)	mem 8929MB
[2022-04-10 04:03:43 large] (main.py 226): INFO Train: [296/300][1600/2502]	eta 0:07:37 lr 0.000005	time 0.5293 (0.5072)	loss 2.7908 (2.7600)	grad_norm 11.8404 (11.1226)	mem 8929MB
[2022-04-10 04:04:35 large] (main.py 226): INFO Train: [296/300][1700/2502]	eta 0:06:47 lr 0.000005	time 0.5073 (0.5080)	loss 2.7322 (2.7612)	grad_norm 7.7316 (11.1023)	mem 8929MB
[2022-04-10 04:05:25 large] (main.py 226): INFO Train: [296/300][1800/2502]	eta 0:05:56 lr 0.000005	time 0.4766 (0.5076)	loss 3.2625 (2.7652)	grad_norm 8.0805 (11.0973)	mem 8929MB
[2022-04-10 04:06:15 large] (main.py 226): INFO Train: [296/300][1900/2502]	eta 0:05:05 lr 0.000005	time 0.5099 (0.5069)	loss 2.9805 (2.7646)	grad_norm 7.1238 (nan)	mem 8929MB
[2022-04-10 04:07:06 large] (main.py 226): INFO Train: [296/300][2000/2502]	eta 0:04:14 lr 0.000005	time 0.4482 (0.5072)	loss 2.8730 (2.7620)	grad_norm 10.0221 (nan)	mem 8929MB
[2022-04-10 04:07:58 large] (main.py 226): INFO Train: [296/300][2100/2502]	eta 0:03:24 lr 0.000005	time 0.5342 (0.5079)	loss 3.0764 (2.7629)	grad_norm 7.8774 (nan)	mem 8929MB
[2022-04-10 04:08:49 large] (main.py 226): INFO Train: [296/300][2200/2502]	eta 0:02:33 lr 0.000005	time 0.5151 (0.5080)	loss 3.0527 (2.7651)	grad_norm 9.7793 (nan)	mem 8929MB
[2022-04-10 04:09:38 large] (main.py 226): INFO Train: [296/300][2300/2502]	eta 0:01:42 lr 0.000005	time 0.4981 (0.5072)	loss 2.8608 (2.7685)	grad_norm 9.6342 (nan)	mem 8929MB
[2022-04-10 04:10:28 large] (main.py 226): INFO Train: [296/300][2400/2502]	eta 0:00:51 lr 0.000005	time 0.5455 (0.5070)	loss 3.3578 (2.7675)	grad_norm 36.1851 (nan)	mem 8929MB
[2022-04-10 04:11:19 large] (main.py 226): INFO Train: [296/300][2500/2502]	eta 0:00:01 lr 0.000005	time 0.4959 (0.5070)	loss 2.5058 (2.7614)	grad_norm 10.7315 (nan)	mem 8929MB
[2022-04-10 04:11:20 large] (main.py 233): INFO EPOCH 296 training takes 0:21:08
[2022-04-10 04:11:27 large] (main.py 273): INFO Test: [0/98]	Time 6.680 (6.680)	Loss 0.9485 (0.9485)	Acc@1 80.078 (80.078)	Acc@5 96.094 (96.094)	Mem 8929MB
[2022-04-10 04:11:52 large] (main.py 279): INFO  * Acc@1 81.872 Acc@5 95.626
[2022-04-10 04:11:52 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.9%
[2022-04-10 04:11:52 large] (main.py 148): INFO Max accuracy: 81.94%
[2022-04-10 04:11:59 large] (main.py 226): INFO Train: [297/300][0/2502]	eta 4:54:00 lr 0.000005	time 7.0504 (7.0504)	loss 2.4983 (2.4983)	grad_norm 11.1220 (11.1220)	mem 8929MB
[2022-04-10 04:12:50 large] (main.py 226): INFO Train: [297/300][100/2502]	eta 0:23:00 lr 0.000005	time 0.5037 (0.5747)	loss 2.5101 (2.8279)	grad_norm 11.3522 (11.1596)	mem 8929MB
[2022-04-10 04:13:40 large] (main.py 226): INFO Train: [297/300][200/2502]	eta 0:20:36 lr 0.000005	time 0.4596 (0.5373)	loss 1.9906 (2.7967)	grad_norm 10.4525 (10.8022)	mem 8929MB
[2022-04-10 04:14:32 large] (main.py 226): INFO Train: [297/300][300/2502]	eta 0:19:26 lr 0.000005	time 0.5260 (0.5296)	loss 2.8945 (2.7890)	grad_norm 9.2138 (10.8944)	mem 8929MB
[2022-04-10 04:15:23 large] (main.py 226): INFO Train: [297/300][400/2502]	eta 0:18:26 lr 0.000005	time 0.5124 (0.5263)	loss 2.7226 (2.7730)	grad_norm 8.5020 (10.9804)	mem 8929MB
[2022-04-10 04:16:14 large] (main.py 226): INFO Train: [297/300][500/2502]	eta 0:17:24 lr 0.000005	time 0.5133 (0.5217)	loss 2.4416 (2.7726)	grad_norm 9.3659 (10.9852)	mem 8929MB
[2022-04-10 04:17:05 large] (main.py 226): INFO Train: [297/300][600/2502]	eta 0:16:30 lr 0.000005	time 0.5365 (0.5210)	loss 2.9919 (2.7671)	grad_norm 7.6194 (10.9001)	mem 8929MB
[2022-04-10 04:17:55 large] (main.py 226): INFO Train: [297/300][700/2502]	eta 0:15:32 lr 0.000005	time 0.5021 (0.5173)	loss 2.7116 (2.7603)	grad_norm 11.9944 (11.1010)	mem 8929MB
[2022-04-10 04:18:47 large] (main.py 226): INFO Train: [297/300][800/2502]	eta 0:14:40 lr 0.000005	time 0.5162 (0.5171)	loss 2.3919 (2.7556)	grad_norm 10.8594 (11.1894)	mem 8929MB
[2022-04-10 04:19:38 large] (main.py 226): INFO Train: [297/300][900/2502]	eta 0:13:47 lr 0.000005	time 0.4836 (0.5163)	loss 2.9085 (2.7597)	grad_norm 10.7735 (11.1530)	mem 8929MB
[2022-04-10 04:20:26 large] (main.py 226): INFO Train: [297/300][1000/2502]	eta 0:12:50 lr 0.000005	time 0.4627 (0.5130)	loss 2.9758 (2.7640)	grad_norm 10.9264 (11.0903)	mem 8929MB
[2022-04-10 04:21:16 large] (main.py 226): INFO Train: [297/300][1100/2502]	eta 0:11:57 lr 0.000005	time 0.5140 (0.5116)	loss 3.1786 (2.7613)	grad_norm 11.8334 (11.0227)	mem 8929MB
[2022-04-10 04:22:08 large] (main.py 226): INFO Train: [297/300][1200/2502]	eta 0:11:07 lr 0.000005	time 0.5046 (0.5125)	loss 3.1470 (2.7648)	grad_norm 8.1090 (10.9979)	mem 8929MB
[2022-04-10 04:22:59 large] (main.py 226): INFO Train: [297/300][1300/2502]	eta 0:10:15 lr 0.000005	time 0.5046 (0.5125)	loss 3.0110 (2.7695)	grad_norm 10.2714 (10.9763)	mem 8929MB
[2022-04-10 04:23:48 large] (main.py 226): INFO Train: [297/300][1400/2502]	eta 0:09:23 lr 0.000005	time 0.4850 (0.5110)	loss 1.9295 (2.7665)	grad_norm 9.8990 (10.9611)	mem 8929MB
[2022-04-10 04:24:39 large] (main.py 226): INFO Train: [297/300][1500/2502]	eta 0:08:31 lr 0.000005	time 0.5177 (0.5109)	loss 2.3069 (2.7614)	grad_norm 7.8032 (10.9277)	mem 8929MB
[2022-04-10 04:25:31 large] (main.py 226): INFO Train: [297/300][1600/2502]	eta 0:07:41 lr 0.000005	time 0.4862 (0.5112)	loss 2.9529 (2.7621)	grad_norm 10.2434 (10.9080)	mem 8929MB
[2022-04-10 04:26:21 large] (main.py 226): INFO Train: [297/300][1700/2502]	eta 0:06:49 lr 0.000005	time 0.5928 (0.5106)	loss 3.1293 (2.7617)	grad_norm 8.7996 (10.9511)	mem 8929MB
[2022-04-10 04:27:12 large] (main.py 226): INFO Train: [297/300][1800/2502]	eta 0:05:58 lr 0.000005	time 0.5130 (0.5108)	loss 2.3851 (2.7601)	grad_norm 5.9555 (10.9163)	mem 8929MB
[2022-04-10 04:28:04 large] (main.py 226): INFO Train: [297/300][1900/2502]	eta 0:05:07 lr 0.000005	time 0.5087 (0.5111)	loss 2.8335 (2.7623)	grad_norm 6.8345 (10.9402)	mem 8929MB
[2022-04-10 04:28:53 large] (main.py 226): INFO Train: [297/300][2000/2502]	eta 0:04:16 lr 0.000005	time 0.4969 (0.5101)	loss 2.7433 (2.7651)	grad_norm 8.3577 (10.9816)	mem 8929MB
[2022-04-10 04:29:44 large] (main.py 226): INFO Train: [297/300][2100/2502]	eta 0:03:25 lr 0.000005	time 0.5135 (0.5101)	loss 3.3707 (2.7614)	grad_norm 10.2844 (10.9523)	mem 8929MB
[2022-04-10 04:30:35 large] (main.py 226): INFO Train: [297/300][2200/2502]	eta 0:02:34 lr 0.000005	time 0.5040 (0.5102)	loss 2.1915 (2.7609)	grad_norm 9.5005 (10.9162)	mem 8929MB
[2022-04-10 04:31:24 large] (main.py 226): INFO Train: [297/300][2300/2502]	eta 0:01:42 lr 0.000005	time 0.4897 (0.5093)	loss 2.9421 (2.7627)	grad_norm 11.5793 (10.8818)	mem 8929MB
[2022-04-10 04:32:15 large] (main.py 226): INFO Train: [297/300][2400/2502]	eta 0:00:51 lr 0.000005	time 0.5033 (0.5092)	loss 2.2703 (2.7609)	grad_norm 11.7639 (10.9020)	mem 8929MB
[2022-04-10 04:33:06 large] (main.py 226): INFO Train: [297/300][2500/2502]	eta 0:00:01 lr 0.000005	time 0.5088 (0.5094)	loss 3.0617 (2.7622)	grad_norm 9.3483 (10.9717)	mem 8929MB
[2022-04-10 04:33:07 large] (main.py 233): INFO EPOCH 297 training takes 0:21:14
[2022-04-10 04:33:13 large] (main.py 273): INFO Test: [0/98]	Time 5.919 (5.919)	Loss 0.8730 (0.8730)	Acc@1 83.984 (83.984)	Acc@5 96.094 (96.094)	Mem 8929MB
[2022-04-10 04:33:40 large] (main.py 279): INFO  * Acc@1 81.962 Acc@5 95.680
[2022-04-10 04:33:40 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 82.0%
[2022-04-10 04:33:40 large] (utils.py 57): INFO output/large/default/ckpt_epoch_297.pth saving......
[2022-04-10 04:33:40 large] (utils.py 59): INFO output/large/default/ckpt_epoch_297.pth saved !!!
[2022-04-10 04:33:40 large] (main.py 148): INFO Max accuracy: 81.96%
[2022-04-10 04:33:48 large] (main.py 226): INFO Train: [298/300][0/2502]	eta 5:26:51 lr 0.000005	time 7.8385 (7.8385)	loss 3.0382 (3.0382)	grad_norm 8.5313 (8.5313)	mem 8929MB
[2022-04-10 04:34:37 large] (main.py 226): INFO Train: [298/300][100/2502]	eta 0:22:33 lr 0.000005	time 0.4899 (0.5637)	loss 2.8311 (2.7608)	grad_norm 8.5108 (10.8979)	mem 8929MB
[2022-04-10 04:35:28 large] (main.py 226): INFO Train: [298/300][200/2502]	eta 0:20:35 lr 0.000005	time 0.4910 (0.5366)	loss 3.1438 (2.7278)	grad_norm 9.2985 (10.9958)	mem 8929MB
[2022-04-10 04:36:20 large] (main.py 226): INFO Train: [298/300][300/2502]	eta 0:19:30 lr 0.000005	time 0.4991 (0.5315)	loss 2.4642 (2.7354)	grad_norm 11.6459 (11.2053)	mem 8929MB
[2022-04-10 04:37:12 large] (main.py 226): INFO Train: [298/300][400/2502]	eta 0:18:30 lr 0.000005	time 0.5595 (0.5283)	loss 2.0398 (2.7608)	grad_norm 7.6155 (11.0494)	mem 8929MB
[2022-04-10 04:38:02 large] (main.py 226): INFO Train: [298/300][500/2502]	eta 0:17:25 lr 0.000005	time 0.4852 (0.5223)	loss 2.0111 (2.7842)	grad_norm 15.6265 (11.4702)	mem 8929MB
[2022-04-10 04:38:54 large] (main.py 226): INFO Train: [298/300][600/2502]	eta 0:16:30 lr 0.000005	time 0.5098 (0.5209)	loss 3.5095 (2.7599)	grad_norm 12.3650 (11.4336)	mem 8929MB
[2022-04-10 04:39:43 large] (main.py 226): INFO Train: [298/300][700/2502]	eta 0:15:31 lr 0.000005	time 0.4855 (0.5169)	loss 1.8826 (2.7499)	grad_norm 9.8275 (11.2928)	mem 8929MB
[2022-04-10 04:40:32 large] (main.py 226): INFO Train: [298/300][800/2502]	eta 0:14:35 lr 0.000005	time 0.4917 (0.5143)	loss 2.9896 (2.7488)	grad_norm 11.8450 (11.2332)	mem 8929MB
[2022-04-10 04:41:21 large] (main.py 226): INFO Train: [298/300][900/2502]	eta 0:13:38 lr 0.000005	time 0.4791 (0.5110)	loss 2.9418 (2.7501)	grad_norm 8.0117 (11.2041)	mem 8929MB
[2022-04-10 04:42:11 large] (main.py 226): INFO Train: [298/300][1000/2502]	eta 0:12:46 lr 0.000005	time 0.5764 (0.5105)	loss 3.0064 (2.7568)	grad_norm 8.1098 (11.2064)	mem 8929MB
[2022-04-10 04:43:03 large] (main.py 226): INFO Train: [298/300][1100/2502]	eta 0:11:56 lr 0.000005	time 0.5036 (0.5111)	loss 2.2631 (2.7518)	grad_norm 16.1424 (11.1997)	mem 8929MB
[2022-04-10 04:43:55 large] (main.py 226): INFO Train: [298/300][1200/2502]	eta 0:11:06 lr 0.000005	time 0.4857 (0.5118)	loss 3.0709 (2.7553)	grad_norm 7.6866 (11.2230)	mem 8929MB
[2022-04-10 04:44:44 large] (main.py 226): INFO Train: [298/300][1300/2502]	eta 0:10:13 lr 0.000005	time 0.5400 (0.5103)	loss 2.9012 (2.7568)	grad_norm 10.6457 (11.2507)	mem 8929MB
[2022-04-10 04:45:34 large] (main.py 226): INFO Train: [298/300][1400/2502]	eta 0:09:21 lr 0.000005	time 0.5300 (0.5094)	loss 2.1825 (2.7588)	grad_norm 15.1344 (11.2162)	mem 8929MB
[2022-04-10 04:46:24 large] (main.py 226): INFO Train: [298/300][1500/2502]	eta 0:08:29 lr 0.000005	time 0.5370 (0.5085)	loss 1.8456 (2.7591)	grad_norm 12.8932 (11.2139)	mem 8929MB
[2022-04-10 04:47:15 large] (main.py 226): INFO Train: [298/300][1600/2502]	eta 0:07:39 lr 0.000005	time 0.5125 (0.5090)	loss 2.7120 (2.7618)	grad_norm 8.3573 (11.3014)	mem 8929MB
[2022-04-10 04:48:05 large] (main.py 226): INFO Train: [298/300][1700/2502]	eta 0:06:47 lr 0.000005	time 0.5035 (0.5083)	loss 2.6058 (2.7602)	grad_norm 8.6394 (11.2629)	mem 8929MB
[2022-04-10 04:48:55 large] (main.py 226): INFO Train: [298/300][1800/2502]	eta 0:05:56 lr 0.000005	time 0.5463 (0.5079)	loss 2.9400 (2.7617)	grad_norm 10.1154 (11.2301)	mem 8929MB
[2022-04-10 04:49:46 large] (main.py 226): INFO Train: [298/300][1900/2502]	eta 0:05:05 lr 0.000005	time 0.4957 (0.5078)	loss 1.5831 (2.7629)	grad_norm 7.8846 (11.1952)	mem 8929MB
[2022-04-10 04:50:37 large] (main.py 226): INFO Train: [298/300][2000/2502]	eta 0:04:14 lr 0.000005	time 0.5186 (0.5079)	loss 2.8964 (2.7645)	grad_norm 10.5415 (11.1874)	mem 8929MB
[2022-04-10 04:51:28 large] (main.py 226): INFO Train: [298/300][2100/2502]	eta 0:03:24 lr 0.000005	time 0.5870 (0.5082)	loss 2.2498 (2.7698)	grad_norm 7.1275 (11.1517)	mem 8929MB
[2022-04-10 04:52:20 large] (main.py 226): INFO Train: [298/300][2200/2502]	eta 0:02:33 lr 0.000005	time 0.5272 (0.5086)	loss 2.6516 (2.7719)	grad_norm 12.1592 (11.1460)	mem 8929MB
[2022-04-10 04:53:10 large] (main.py 226): INFO Train: [298/300][2300/2502]	eta 0:01:42 lr 0.000005	time 0.5190 (0.5081)	loss 3.2510 (2.7716)	grad_norm 10.6218 (11.1583)	mem 8929MB
[2022-04-10 04:53:59 large] (main.py 226): INFO Train: [298/300][2400/2502]	eta 0:00:51 lr 0.000005	time 0.4686 (0.5077)	loss 3.1909 (2.7696)	grad_norm 10.3479 (11.1666)	mem 8929MB
[2022-04-10 04:54:48 large] (main.py 226): INFO Train: [298/300][2500/2502]	eta 0:00:01 lr 0.000005	time 0.4792 (0.5067)	loss 2.6646 (2.7678)	grad_norm 7.1596 (11.1337)	mem 8929MB
[2022-04-10 04:54:49 large] (main.py 233): INFO EPOCH 298 training takes 0:21:08
[2022-04-10 04:54:55 large] (main.py 273): INFO Test: [0/98]	Time 6.298 (6.298)	Loss 0.9208 (0.9208)	Acc@1 83.398 (83.398)	Acc@5 94.531 (94.531)	Mem 8929MB
[2022-04-10 04:55:21 large] (main.py 279): INFO  * Acc@1 81.942 Acc@5 95.606
[2022-04-10 04:55:21 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 81.9%
[2022-04-10 04:55:21 large] (main.py 148): INFO Max accuracy: 81.96%
[2022-04-10 04:55:29 large] (main.py 226): INFO Train: [299/300][0/2502]	eta 5:02:55 lr 0.000005	time 7.2645 (7.2645)	loss 1.8911 (1.8911)	grad_norm 61.2104 (61.2104)	mem 8929MB
[2022-04-10 04:56:19 large] (main.py 226): INFO Train: [299/300][100/2502]	eta 0:22:43 lr 0.000005	time 0.4861 (0.5678)	loss 2.4712 (2.7308)	grad_norm 14.0671 (11.9043)	mem 8929MB
[2022-04-10 04:57:11 large] (main.py 226): INFO Train: [299/300][200/2502]	eta 0:20:50 lr 0.000005	time 0.5169 (0.5433)	loss 3.0500 (2.7570)	grad_norm 25.3737 (11.3016)	mem 8929MB
[2022-04-10 04:58:03 large] (main.py 226): INFO Train: [299/300][300/2502]	eta 0:19:43 lr 0.000005	time 0.4870 (0.5374)	loss 2.2772 (2.7507)	grad_norm 8.8396 (11.3034)	mem 8929MB
[2022-04-10 04:58:52 large] (main.py 226): INFO Train: [299/300][400/2502]	eta 0:18:25 lr 0.000005	time 0.4996 (0.5257)	loss 2.7653 (2.7680)	grad_norm 8.6971 (11.3475)	mem 8929MB
[2022-04-10 04:59:42 large] (main.py 226): INFO Train: [299/300][500/2502]	eta 0:17:20 lr 0.000005	time 0.4869 (0.5198)	loss 3.2396 (2.7795)	grad_norm 11.2900 (11.2947)	mem 8929MB
[2022-04-10 05:00:32 large] (main.py 226): INFO Train: [299/300][600/2502]	eta 0:16:21 lr 0.000005	time 0.4812 (0.5161)	loss 2.8552 (2.7856)	grad_norm 23.2694 (11.3397)	mem 8929MB
[2022-04-10 05:01:23 large] (main.py 226): INFO Train: [299/300][700/2502]	eta 0:15:28 lr 0.000005	time 0.4918 (0.5153)	loss 2.9784 (2.7784)	grad_norm 6.9004 (11.3082)	mem 8929MB
[2022-04-10 05:02:14 large] (main.py 226): INFO Train: [299/300][800/2502]	eta 0:14:36 lr 0.000005	time 0.5292 (0.5148)	loss 2.8204 (2.7722)	grad_norm 13.5294 (11.2001)	mem 8929MB
[2022-04-10 05:03:04 large] (main.py 226): INFO Train: [299/300][900/2502]	eta 0:13:42 lr 0.000005	time 0.4917 (0.5134)	loss 3.1332 (2.7729)	grad_norm 7.1346 (11.1833)	mem 8929MB
[2022-04-10 05:03:54 large] (main.py 226): INFO Train: [299/300][1000/2502]	eta 0:12:49 lr 0.000005	time 0.4814 (0.5123)	loss 3.1739 (2.7718)	grad_norm 9.7362 (nan)	mem 8929MB
[2022-04-10 05:04:45 large] (main.py 226): INFO Train: [299/300][1100/2502]	eta 0:11:57 lr 0.000005	time 0.5602 (0.5120)	loss 2.9928 (2.7824)	grad_norm 11.7920 (nan)	mem 8929MB
[2022-04-10 05:05:36 large] (main.py 226): INFO Train: [299/300][1200/2502]	eta 0:11:05 lr 0.000005	time 0.4907 (0.5114)	loss 3.4794 (2.7754)	grad_norm 10.5787 (nan)	mem 8929MB
[2022-04-10 05:06:25 large] (main.py 226): INFO Train: [299/300][1300/2502]	eta 0:10:13 lr 0.000005	time 0.4745 (0.5104)	loss 2.6278 (2.7718)	grad_norm 8.1089 (nan)	mem 8929MB
[2022-04-10 05:07:15 large] (main.py 226): INFO Train: [299/300][1400/2502]	eta 0:09:21 lr 0.000005	time 0.4963 (0.5093)	loss 2.9235 (2.7639)	grad_norm 11.0889 (nan)	mem 8929MB
[2022-04-10 05:08:05 large] (main.py 226): INFO Train: [299/300][1500/2502]	eta 0:08:29 lr 0.000005	time 0.4508 (0.5087)	loss 1.5846 (2.7657)	grad_norm 7.9038 (nan)	mem 8929MB
[2022-04-10 05:08:57 large] (main.py 226): INFO Train: [299/300][1600/2502]	eta 0:07:39 lr 0.000005	time 0.5434 (0.5096)	loss 3.2604 (2.7634)	grad_norm 9.2699 (nan)	mem 8929MB
[2022-04-10 05:09:49 large] (main.py 226): INFO Train: [299/300][1700/2502]	eta 0:06:49 lr 0.000005	time 0.4759 (0.5100)	loss 2.6993 (2.7592)	grad_norm 11.0093 (nan)	mem 8929MB
[2022-04-10 05:10:38 large] (main.py 226): INFO Train: [299/300][1800/2502]	eta 0:05:57 lr 0.000005	time 0.4596 (0.5089)	loss 3.1039 (2.7617)	grad_norm 8.1696 (nan)	mem 8929MB
[2022-04-10 05:11:27 large] (main.py 226): INFO Train: [299/300][1900/2502]	eta 0:05:05 lr 0.000005	time 0.5851 (0.5080)	loss 2.8745 (2.7631)	grad_norm 7.0268 (nan)	mem 8929MB
[2022-04-10 05:12:18 large] (main.py 226): INFO Train: [299/300][2000/2502]	eta 0:04:15 lr 0.000005	time 0.5158 (0.5082)	loss 2.6862 (2.7649)	grad_norm 22.9219 (nan)	mem 8929MB
[2022-04-10 05:13:08 large] (main.py 226): INFO Train: [299/300][2100/2502]	eta 0:03:24 lr 0.000005	time 0.4788 (0.5078)	loss 2.9507 (2.7661)	grad_norm 7.1430 (nan)	mem 8929MB
[2022-04-10 05:13:57 large] (main.py 226): INFO Train: [299/300][2200/2502]	eta 0:02:33 lr 0.000005	time 0.5126 (0.5069)	loss 2.2091 (2.7682)	grad_norm 8.4142 (nan)	mem 8929MB
[2022-04-10 05:14:46 large] (main.py 226): INFO Train: [299/300][2300/2502]	eta 0:01:42 lr 0.000005	time 0.5114 (0.5060)	loss 3.2061 (2.7657)	grad_norm 9.7081 (nan)	mem 8929MB
[2022-04-10 05:15:38 large] (main.py 226): INFO Train: [299/300][2400/2502]	eta 0:00:51 lr 0.000005	time 0.5087 (0.5066)	loss 2.7297 (2.7665)	grad_norm 18.1794 (nan)	mem 8929MB
[2022-04-10 05:16:29 large] (main.py 226): INFO Train: [299/300][2500/2502]	eta 0:00:01 lr 0.000005	time 0.4955 (0.5068)	loss 3.3946 (2.7647)	grad_norm 11.1242 (nan)	mem 8929MB
[2022-04-10 05:16:30 large] (main.py 233): INFO EPOCH 299 training takes 0:21:08
[2022-04-10 05:16:30 large] (utils.py 57): INFO output/large/default/ckpt_epoch_299.pth saving......
[2022-04-10 05:16:31 large] (utils.py 59): INFO output/large/default/ckpt_epoch_299.pth saved !!!
[2022-04-10 05:16:38 large] (main.py 273): INFO Test: [0/98]	Time 6.924 (6.924)	Loss 0.9650 (0.9650)	Acc@1 81.445 (81.445)	Acc@5 95.703 (95.703)	Mem 8929MB
[2022-04-10 05:17:02 large] (main.py 279): INFO  * Acc@1 81.984 Acc@5 95.626
[2022-04-10 05:17:02 large] (main.py 144): INFO Accuracy of the network on the 50000 test images: 82.0%
[2022-04-10 05:17:02 large] (utils.py 57): INFO output/large/default/ckpt_epoch_299.pth saving......
[2022-04-10 05:17:03 large] (utils.py 59): INFO output/large/default/ckpt_epoch_299.pth saved !!!
[2022-04-10 05:17:03 large] (main.py 148): INFO Max accuracy: 81.98%
[2022-04-10 05:17:03 large] (main.py 152): INFO Training time 1 day, 21:48:52
