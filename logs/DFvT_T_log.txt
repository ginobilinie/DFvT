[2022-04-17 20:16:34 tiny] (main.py 347): INFO Full config saved to output/tiny/default/config.json
[2022-04-17 20:16:34 tiny] (main.py 350): INFO AMP_OPT_LEVEL: O1
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 256
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: ../../Data/raw-data/imagenet-data/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 16
  PIN_MEMORY: true
  ZIP_MODE: false
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DFvT:
    APE: false
    DEPTHS:
    - 1
    - 1
    - 2
    - 1
    EMBED_DIM: 48
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    SIZE: tiny
    WINDOW_SIZE: 7
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: tiny
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: DFvT
OUTPUT: output/tiny/default
PRINT_FREQ: 100
SAVE_FREQ: 1000
SEED: 0
TAG: default
TEST:
  CROP: true
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: true
  BASE_LR: 0.001
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MIN_LR: 1.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.0e-06
  WEIGHT_DECAY: 0.05

[2022-04-17 20:16:38 tiny] (main.py 80): INFO Creating model:DFvT/tiny
[2022-04-17 20:16:38 tiny] (main.py 85): INFO DFvT(
  (patch_embed): PatchEmbed(
    (proj1): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (proj2): Conv2d(24, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (silu): SiLU(inplace=True)
    (norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (norm1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=48, input_resolution=(28, 28), depth=1
      (blocks): ModuleList(
        (0): TransformerBlock(
          dim=48, input_resolution=(28, 28), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (select): DANE(
            (fc_spatial): Sequential(
              (0): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=48, out_features=1, bias=False)
            )
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc_channel): Sequential(
              (0): Linear(in_features=48, out_features=3, bias=False)
              (1): SiLU(inplace=True)
              (2): LayerNorm((3,), eps=1e-05, elementwise_affine=True)
              (3): Linear(in_features=3, out_features=48, bias=False)
            )
            (sigmoid): Sigmoid()
          )
          (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=48, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=48, out_features=144, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=48, out_features=48, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=48, out_features=192, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=192, out_features=48, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(28, 28), dim=48
        (reduction): Linear(in_features=48, out_features=96, bias=False)
        (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=1
      (blocks): ModuleList(
        (0): TransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (select): DANE(
            (fc_spatial): Sequential(
              (0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=96, out_features=1, bias=False)
            )
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc_channel): Sequential(
              (0): Linear(in_features=96, out_features=6, bias=False)
              (1): SiLU(inplace=True)
              (2): LayerNorm((6,), eps=1e-05, elementwise_affine=True)
              (3): Linear(in_features=6, out_features=96, bias=False)
            )
            (sigmoid): Sigmoid()
          )
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=96, out_features=192, bias=False)
        (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0): TransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=12, window_size=7, shift_size=0, mlp_ratio=4.0
          (select): DANE(
            (fc_spatial): Sequential(
              (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=192, out_features=1, bias=False)
            )
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc_channel): Sequential(
              (0): Linear(in_features=192, out_features=12, bias=False)
              (1): SiLU(inplace=True)
              (2): LayerNorm((12,), eps=1e-05, elementwise_affine=True)
              (3): Linear(in_features=12, out_features=192, bias=False)
            )
            (sigmoid): Sigmoid()
          )
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=12
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): TransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=12, window_size=7, shift_size=0, mlp_ratio=4.0
          (select): DANE(
            (fc_spatial): Sequential(
              (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=192, out_features=1, bias=False)
            )
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc_channel): Sequential(
              (0): Linear(in_features=192, out_features=12, bias=False)
              (1): SiLU(inplace=True)
              (2): LayerNorm((12,), eps=1e-05, elementwise_affine=True)
              (3): Linear(in_features=12, out_features=192, bias=False)
            )
            (sigmoid): Sigmoid()
          )
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=12
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(7, 7), dim=192
        (reduction): Linear(in_features=192, out_features=384, bias=False)
        (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
      )
    )
    (3): BasicLayer(
      dim=384, input_resolution=(7, 7), depth=1
      (blocks): ModuleList(
        (0): TransformerBlock(
          dim=384, input_resolution=(7, 7), num_heads=24, window_size=7, shift_size=0, mlp_ratio=4.0
          (select): DANE(
            (fc_spatial): Sequential(
              (0): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=384, out_features=1, bias=False)
            )
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc_channel): Sequential(
              (0): Linear(in_features=384, out_features=24, bias=False)
              (1): SiLU(inplace=True)
              (2): LayerNorm((24,), eps=1e-05, elementwise_affine=True)
              (3): Linear(in_features=24, out_features=384, bias=False)
            )
            (sigmoid): Sigmoid()
          )
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=384, window_size=(7, 7), num_heads=24
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (convlayers): ModuleList(
    (0): ConvBlock(
      (conv1x1_1): Sequential(
        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): SiLU(inplace=True)
        (6): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (7): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (8): SiLU(inplace=True)
      )
      (conv1): Sequential(
        (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)
        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
      (conv1x1_2): Sequential(
        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
    )
    (1): ConvBlock(
      (conv1x1_1): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): SiLU(inplace=True)
        (6): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (8): SiLU(inplace=True)
      )
      (conv1): Sequential(
        (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
      (conv1x1_2): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
    )
    (2): ConvBlock(
      (conv1x1_1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): SiLU(inplace=True)
        (6): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (7): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (8): SiLU(inplace=True)
      )
      (conv1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
      (conv1x1_2): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
    )
    (3): ConvBlock(
      (conv1x1_1): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): SiLU(inplace=True)
        (6): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (7): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (8): SiLU(inplace=True)
      )
      (conv1): Sequential(
        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
      (conv1x1_2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
    )
  )
  (multiresolution_conv): ModuleList(
    (0): Sequential(
      (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Sequential(
      (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
      (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): Sequential(
      (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
      (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (head): Linear(in_features=384, out_features=1000, bias=True)
)
[2022-04-17 20:16:38 tiny] (main.py 94): INFO number of params: 3967627
[2022-04-17 20:16:38 tiny] (main.py 97): INFO number of GFLOPs: 0.27142848
[2022-04-17 20:16:38 tiny] (main.py 121): INFO no checkpoint found in output/tiny/default, ignoring auto resume
[2022-04-17 20:16:38 tiny] (main.py 134): INFO Start training
[2022-04-17 20:16:55 tiny] (main.py 226): INFO Train: [0/300][0/1251]	eta 6:06:10 lr 0.000001	time 17.5621 (17.5621)	loss 6.9055 (6.9055)	grad_norm 0.5900 (0.5900)	mem 5274MB
[2022-04-17 20:17:53 tiny] (main.py 226): INFO Train: [0/300][100/1251]	eta 0:14:12 lr 0.000005	time 0.5815 (0.7403)	loss 6.9000 (6.9121)	grad_norm 0.5180 (0.5428)	mem 5325MB
[2022-04-17 20:18:50 tiny] (main.py 226): INFO Train: [0/300][200/1251]	eta 0:11:33 lr 0.000009	time 0.6317 (0.6602)	loss 6.9112 (6.9108)	grad_norm 0.5777 (0.5433)	mem 5325MB
[2022-04-17 20:19:49 tiny] (main.py 226): INFO Train: [0/300][300/1251]	eta 0:10:04 lr 0.000013	time 0.7134 (0.6359)	loss 6.9061 (6.9096)	grad_norm 0.5502 (0.5446)	mem 5325MB
[2022-04-17 20:20:47 tiny] (main.py 226): INFO Train: [0/300][400/1251]	eta 0:08:49 lr 0.000017	time 0.6402 (0.6219)	loss 6.9103 (6.9078)	grad_norm 0.5036 (0.5419)	mem 5325MB
[2022-04-17 20:21:47 tiny] (main.py 226): INFO Train: [0/300][500/1251]	eta 0:07:43 lr 0.000021	time 0.7410 (0.6166)	loss 6.8848 (6.9040)	grad_norm 0.5547 (0.5413)	mem 5325MB
[2022-04-17 20:22:45 tiny] (main.py 226): INFO Train: [0/300][600/1251]	eta 0:06:37 lr 0.000025	time 0.5362 (0.6110)	loss 6.8088 (6.8978)	grad_norm 0.6428 (0.5457)	mem 5325MB
[2022-04-17 20:23:44 tiny] (main.py 226): INFO Train: [0/300][700/1251]	eta 0:05:34 lr 0.000029	time 0.6609 (0.6073)	loss 6.8763 (6.8896)	grad_norm 0.6930 (0.5599)	mem 5325MB
[2022-04-17 20:24:43 tiny] (main.py 226): INFO Train: [0/300][800/1251]	eta 0:04:33 lr 0.000033	time 0.7209 (0.6055)	loss 6.8176 (6.8803)	grad_norm 0.8362 (0.5920)	mem 5325MB
[2022-04-17 20:25:41 tiny] (main.py 226): INFO Train: [0/300][900/1251]	eta 0:03:31 lr 0.000037	time 0.5426 (0.6029)	loss 6.8249 (6.8672)	grad_norm 1.0325 (0.6385)	mem 5325MB
[2022-04-17 20:26:39 tiny] (main.py 226): INFO Train: [0/300][1000/1251]	eta 0:02:30 lr 0.000041	time 0.7790 (0.6008)	loss 6.6934 (6.8550)	grad_norm 1.1047 (0.6944)	mem 5325MB
[2022-04-17 20:27:38 tiny] (main.py 226): INFO Train: [0/300][1100/1251]	eta 0:01:30 lr 0.000045	time 0.7118 (0.6001)	loss 6.7669 (6.8420)	grad_norm 1.0887 (0.7488)	mem 5325MB
[2022-04-17 20:28:37 tiny] (main.py 226): INFO Train: [0/300][1200/1251]	eta 0:00:30 lr 0.000049	time 0.5044 (0.5990)	loss 6.6537 (6.8301)	grad_norm 1.0266 (0.7975)	mem 5325MB
[2022-04-17 20:28:59 tiny] (main.py 233): INFO EPOCH 0 training takes 0:12:21
[2022-04-17 20:28:59 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_0.pth saving......
[2022-04-17 20:28:59 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_0.pth saved !!!
[2022-04-17 20:29:10 tiny] (main.py 273): INFO Test: [0/49]	Time 11.442 (11.442)	Loss 6.2794 (6.2794)	Acc@1 2.148 (2.148)	Acc@5 6.445 (6.445)	Mem 5325MB
[2022-04-17 20:29:30 tiny] (main.py 279): INFO  * Acc@1 1.892 Acc@5 6.608
[2022-04-17 20:29:30 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 1.9%
[2022-04-17 20:29:30 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_0.pth saving......
[2022-04-17 20:29:30 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_0.pth saved !!!
[2022-04-17 20:29:30 tiny] (main.py 148): INFO Max accuracy: 1.89%
[2022-04-17 20:29:42 tiny] (main.py 226): INFO Train: [1/300][0/1251]	eta 4:07:51 lr 0.000051	time 11.8873 (11.8873)	loss 6.6916 (6.6916)	grad_norm 1.2652 (1.2652)	mem 5326MB
[2022-04-17 20:30:44 tiny] (main.py 226): INFO Train: [1/300][100/1251]	eta 0:13:54 lr 0.000055	time 0.7148 (0.7254)	loss 6.7026 (6.6697)	grad_norm 1.6777 (1.4377)	mem 5328MB
[2022-04-17 20:31:42 tiny] (main.py 226): INFO Train: [1/300][200/1251]	eta 0:11:29 lr 0.000059	time 0.5580 (0.6565)	loss 6.7227 (6.6576)	grad_norm 1.2522 (1.4447)	mem 5328MB
[2022-04-17 20:32:41 tiny] (main.py 226): INFO Train: [1/300][300/1251]	eta 0:10:03 lr 0.000063	time 0.7440 (0.6345)	loss 6.5022 (6.6416)	grad_norm 1.6154 (1.4430)	mem 5328MB
[2022-04-17 20:33:39 tiny] (main.py 226): INFO Train: [1/300][400/1251]	eta 0:08:48 lr 0.000067	time 0.5291 (0.6207)	loss 6.4266 (6.6314)	grad_norm 1.5886 (1.4615)	mem 5328MB
[2022-04-17 20:34:38 tiny] (main.py 226): INFO Train: [1/300][500/1251]	eta 0:07:41 lr 0.000071	time 0.5930 (0.6144)	loss 6.6162 (6.6210)	grad_norm 1.8432 (1.4900)	mem 5328MB
[2022-04-17 20:35:37 tiny] (main.py 226): INFO Train: [1/300][600/1251]	eta 0:06:37 lr 0.000075	time 0.6965 (0.6102)	loss 6.4549 (6.6113)	grad_norm 1.6551 (1.5075)	mem 5328MB
[2022-04-17 20:36:36 tiny] (main.py 226): INFO Train: [1/300][700/1251]	eta 0:05:34 lr 0.000079	time 0.5868 (0.6067)	loss 6.6291 (6.5991)	grad_norm 1.7486 (1.5474)	mem 5328MB
[2022-04-17 20:37:34 tiny] (main.py 226): INFO Train: [1/300][800/1251]	eta 0:04:32 lr 0.000083	time 0.7801 (0.6041)	loss 6.6008 (6.5890)	grad_norm 1.5046 (1.5750)	mem 5328MB
[2022-04-17 20:38:33 tiny] (main.py 226): INFO Train: [1/300][900/1251]	eta 0:03:31 lr 0.000087	time 0.6138 (0.6027)	loss 6.5791 (6.5802)	grad_norm 1.9858 (1.5908)	mem 5328MB
[2022-04-17 20:39:32 tiny] (main.py 226): INFO Train: [1/300][1000/1251]	eta 0:02:30 lr 0.000091	time 0.5578 (0.6014)	loss 6.6452 (6.5694)	grad_norm 1.8598 (1.6076)	mem 5328MB
[2022-04-17 20:40:31 tiny] (main.py 226): INFO Train: [1/300][1100/1251]	eta 0:01:30 lr 0.000095	time 0.4909 (0.5999)	loss 6.4123 (6.5608)	grad_norm 2.1692 (1.6251)	mem 5328MB
[2022-04-17 20:41:30 tiny] (main.py 226): INFO Train: [1/300][1200/1251]	eta 0:00:30 lr 0.000099	time 0.4336 (0.5988)	loss 6.5852 (6.5514)	grad_norm 1.9926 (1.6422)	mem 5328MB
[2022-04-17 20:41:52 tiny] (main.py 233): INFO EPOCH 1 training takes 0:12:21
[2022-04-17 20:42:03 tiny] (main.py 273): INFO Test: [0/49]	Time 11.172 (11.172)	Loss 5.6606 (5.6606)	Acc@1 5.273 (5.273)	Acc@5 16.406 (16.406)	Mem 5328MB
[2022-04-17 20:42:23 tiny] (main.py 279): INFO  * Acc@1 5.206 Acc@5 15.602
[2022-04-17 20:42:23 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 5.2%
[2022-04-17 20:42:23 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_1.pth saving......
[2022-04-17 20:42:23 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_1.pth saved !!!
[2022-04-17 20:42:23 tiny] (main.py 148): INFO Max accuracy: 5.21%
[2022-04-17 20:42:36 tiny] (main.py 226): INFO Train: [2/300][0/1251]	eta 4:22:01 lr 0.000101	time 12.5674 (12.5674)	loss 6.3098 (6.3098)	grad_norm 1.6470 (1.6470)	mem 5328MB
[2022-04-17 20:43:37 tiny] (main.py 226): INFO Train: [2/300][100/1251]	eta 0:13:57 lr 0.000105	time 0.5241 (0.7276)	loss 6.3912 (6.4493)	grad_norm 2.1385 (1.8514)	mem 5328MB
[2022-04-17 20:44:35 tiny] (main.py 226): INFO Train: [2/300][200/1251]	eta 0:11:31 lr 0.000109	time 0.5511 (0.6575)	loss 6.5304 (6.4364)	grad_norm 1.8884 (1.8364)	mem 5328MB
[2022-04-17 20:45:34 tiny] (main.py 226): INFO Train: [2/300][300/1251]	eta 0:10:02 lr 0.000113	time 0.5862 (0.6332)	loss 6.4902 (6.4146)	grad_norm 1.8753 (1.8599)	mem 5328MB
[2022-04-17 20:46:32 tiny] (main.py 226): INFO Train: [2/300][400/1251]	eta 0:08:47 lr 0.000117	time 0.7000 (0.6197)	loss 6.0721 (6.3923)	grad_norm 1.7290 (1.8633)	mem 5328MB
[2022-04-17 20:47:30 tiny] (main.py 226): INFO Train: [2/300][500/1251]	eta 0:07:40 lr 0.000121	time 0.6136 (0.6136)	loss 6.5502 (6.3838)	grad_norm 1.6053 (1.8629)	mem 5328MB
[2022-04-17 20:48:29 tiny] (main.py 226): INFO Train: [2/300][600/1251]	eta 0:06:36 lr 0.000125	time 0.4965 (0.6089)	loss 6.2185 (6.3706)	grad_norm 1.7846 (1.8735)	mem 5328MB
[2022-04-17 20:49:28 tiny] (main.py 226): INFO Train: [2/300][700/1251]	eta 0:05:34 lr 0.000129	time 0.6544 (0.6063)	loss 6.3629 (6.3618)	grad_norm 1.7703 (1.8866)	mem 5328MB
[2022-04-17 20:50:27 tiny] (main.py 226): INFO Train: [2/300][800/1251]	eta 0:04:32 lr 0.000133	time 0.4929 (0.6038)	loss 6.4012 (6.3559)	grad_norm 1.9163 (1.8886)	mem 5328MB
[2022-04-17 20:51:26 tiny] (main.py 226): INFO Train: [2/300][900/1251]	eta 0:03:31 lr 0.000137	time 0.4522 (0.6025)	loss 6.4197 (6.3456)	grad_norm 1.8279 (1.8949)	mem 5328MB
[2022-04-17 20:52:25 tiny] (main.py 226): INFO Train: [2/300][1000/1251]	eta 0:02:30 lr 0.000141	time 0.6165 (0.6011)	loss 6.4281 (6.3335)	grad_norm 1.8835 (1.9022)	mem 5328MB
[2022-04-17 20:53:24 tiny] (main.py 226): INFO Train: [2/300][1100/1251]	eta 0:01:30 lr 0.000145	time 0.5340 (0.6003)	loss 5.7992 (6.3239)	grad_norm 2.5192 (1.9144)	mem 5328MB
[2022-04-17 20:54:23 tiny] (main.py 226): INFO Train: [2/300][1200/1251]	eta 0:00:30 lr 0.000149	time 0.6169 (0.5994)	loss 6.2738 (6.3185)	grad_norm 1.9290 (1.9179)	mem 5328MB
[2022-04-17 20:54:44 tiny] (main.py 233): INFO EPOCH 2 training takes 0:12:21
[2022-04-17 20:54:56 tiny] (main.py 273): INFO Test: [0/49]	Time 11.541 (11.541)	Loss 5.1832 (5.1832)	Acc@1 8.398 (8.398)	Acc@5 23.926 (23.926)	Mem 5328MB
[2022-04-17 20:55:16 tiny] (main.py 279): INFO  * Acc@1 10.294 Acc@5 26.324
[2022-04-17 20:55:16 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 10.3%
[2022-04-17 20:55:16 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_2.pth saving......
[2022-04-17 20:55:16 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_2.pth saved !!!
[2022-04-17 20:55:16 tiny] (main.py 148): INFO Max accuracy: 10.29%
[2022-04-17 20:55:27 tiny] (main.py 226): INFO Train: [3/300][0/1251]	eta 4:01:24 lr 0.000151	time 11.5783 (11.5783)	loss 6.0053 (6.0053)	grad_norm 1.9388 (1.9388)	mem 5328MB
[2022-04-17 20:56:29 tiny] (main.py 226): INFO Train: [3/300][100/1251]	eta 0:13:55 lr 0.000155	time 0.4274 (0.7260)	loss 6.0735 (6.1938)	grad_norm 1.8987 (1.9349)	mem 5328MB
[2022-04-17 20:57:28 tiny] (main.py 226): INFO Train: [3/300][200/1251]	eta 0:11:29 lr 0.000159	time 0.4962 (0.6556)	loss 6.3756 (6.1596)	grad_norm 2.1346 (1.9572)	mem 5328MB
[2022-04-17 20:58:26 tiny] (main.py 226): INFO Train: [3/300][300/1251]	eta 0:10:01 lr 0.000163	time 0.6251 (0.6325)	loss 5.9194 (6.1700)	grad_norm 1.9886 (1.9775)	mem 5328MB
[2022-04-17 20:59:25 tiny] (main.py 226): INFO Train: [3/300][400/1251]	eta 0:08:48 lr 0.000167	time 0.5547 (0.6210)	loss 5.8404 (6.1467)	grad_norm 1.9703 (1.9881)	mem 5328MB
[2022-04-17 21:00:24 tiny] (main.py 226): INFO Train: [3/300][500/1251]	eta 0:07:41 lr 0.000171	time 0.6066 (0.6149)	loss 6.4155 (6.1458)	grad_norm 1.8394 (1.9822)	mem 5328MB
[2022-04-17 21:01:23 tiny] (main.py 226): INFO Train: [3/300][600/1251]	eta 0:06:37 lr 0.000175	time 0.7155 (0.6103)	loss 6.1074 (6.1321)	grad_norm 1.8971 (1.9937)	mem 5328MB
[2022-04-17 21:02:21 tiny] (main.py 226): INFO Train: [3/300][700/1251]	eta 0:05:34 lr 0.000179	time 0.6508 (0.6072)	loss 5.8603 (6.1282)	grad_norm 1.8526 (1.9919)	mem 5328MB
[2022-04-17 21:03:20 tiny] (main.py 226): INFO Train: [3/300][800/1251]	eta 0:04:32 lr 0.000183	time 0.4366 (0.6045)	loss 6.0848 (6.1241)	grad_norm 2.1036 (inf)	mem 5328MB
[2022-04-17 21:04:18 tiny] (main.py 226): INFO Train: [3/300][900/1251]	eta 0:03:31 lr 0.000187	time 0.6444 (0.6022)	loss 6.2197 (6.1199)	grad_norm 1.8491 (inf)	mem 5328MB
[2022-04-17 21:05:17 tiny] (main.py 226): INFO Train: [3/300][1000/1251]	eta 0:02:30 lr 0.000191	time 0.4509 (0.6004)	loss 6.2925 (6.1159)	grad_norm 1.7944 (inf)	mem 5328MB
[2022-04-17 21:06:16 tiny] (main.py 226): INFO Train: [3/300][1100/1251]	eta 0:01:30 lr 0.000195	time 0.4149 (0.5998)	loss 6.4525 (6.1062)	grad_norm 2.0274 (inf)	mem 5328MB
[2022-04-17 21:07:15 tiny] (main.py 226): INFO Train: [3/300][1200/1251]	eta 0:00:30 lr 0.000199	time 0.5849 (0.5991)	loss 6.1786 (6.0951)	grad_norm 1.8367 (inf)	mem 5328MB
[2022-04-17 21:07:37 tiny] (main.py 233): INFO EPOCH 3 training takes 0:12:21
[2022-04-17 21:07:50 tiny] (main.py 273): INFO Test: [0/49]	Time 12.594 (12.594)	Loss 4.4932 (4.4932)	Acc@1 15.527 (15.527)	Acc@5 38.965 (38.965)	Mem 5328MB
[2022-04-17 21:08:08 tiny] (main.py 279): INFO  * Acc@1 16.188 Acc@5 36.854
[2022-04-17 21:08:08 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 16.2%
[2022-04-17 21:08:08 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_3.pth saving......
[2022-04-17 21:08:08 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_3.pth saved !!!
[2022-04-17 21:08:08 tiny] (main.py 148): INFO Max accuracy: 16.19%
[2022-04-17 21:08:20 tiny] (main.py 226): INFO Train: [4/300][0/1251]	eta 4:13:25 lr 0.000201	time 12.1545 (12.1545)	loss 6.3372 (6.3372)	grad_norm 2.5726 (2.5726)	mem 5328MB
[2022-04-17 21:09:21 tiny] (main.py 226): INFO Train: [4/300][100/1251]	eta 0:13:51 lr 0.000205	time 0.7974 (0.7226)	loss 6.5103 (5.9446)	grad_norm 2.5717 (2.0287)	mem 5328MB
[2022-04-17 21:10:20 tiny] (main.py 226): INFO Train: [4/300][200/1251]	eta 0:11:29 lr 0.000209	time 0.5438 (0.6561)	loss 6.1050 (5.9592)	grad_norm 1.9494 (2.0683)	mem 5328MB
[2022-04-17 21:11:19 tiny] (main.py 226): INFO Train: [4/300][300/1251]	eta 0:10:01 lr 0.000213	time 0.3967 (0.6325)	loss 5.7075 (5.9718)	grad_norm 2.0051 (2.0622)	mem 5328MB
[2022-04-17 21:12:17 tiny] (main.py 226): INFO Train: [4/300][400/1251]	eta 0:08:47 lr 0.000217	time 0.6023 (0.6201)	loss 6.3612 (5.9547)	grad_norm 2.0628 (2.0681)	mem 5328MB
[2022-04-17 21:13:16 tiny] (main.py 226): INFO Train: [4/300][500/1251]	eta 0:07:40 lr 0.000221	time 0.8995 (0.6134)	loss 6.2294 (5.9476)	grad_norm 2.1543 (2.0667)	mem 5328MB
[2022-04-17 21:14:15 tiny] (main.py 226): INFO Train: [4/300][600/1251]	eta 0:06:36 lr 0.000225	time 0.6879 (0.6095)	loss 5.5332 (5.9352)	grad_norm 2.1698 (2.0743)	mem 5328MB
[2022-04-17 21:15:13 tiny] (main.py 226): INFO Train: [4/300][700/1251]	eta 0:05:34 lr 0.000229	time 0.6989 (0.6062)	loss 5.6514 (5.9304)	grad_norm 2.4543 (2.0795)	mem 5328MB
[2022-04-17 21:16:12 tiny] (main.py 226): INFO Train: [4/300][800/1251]	eta 0:04:32 lr 0.000233	time 0.5116 (0.6033)	loss 6.3061 (5.9174)	grad_norm 2.0323 (2.0835)	mem 5328MB
[2022-04-17 21:17:11 tiny] (main.py 226): INFO Train: [4/300][900/1251]	eta 0:03:31 lr 0.000237	time 0.5377 (0.6020)	loss 6.2570 (5.9160)	grad_norm 2.3822 (2.0827)	mem 5328MB
[2022-04-17 21:18:10 tiny] (main.py 226): INFO Train: [4/300][1000/1251]	eta 0:02:30 lr 0.000241	time 0.7712 (0.6010)	loss 6.0955 (5.9111)	grad_norm 1.8388 (2.0840)	mem 5328MB
[2022-04-17 21:19:09 tiny] (main.py 226): INFO Train: [4/300][1100/1251]	eta 0:01:30 lr 0.000245	time 0.8443 (0.5997)	loss 5.4467 (5.9023)	grad_norm 2.2097 (2.0877)	mem 5328MB
[2022-04-17 21:20:08 tiny] (main.py 226): INFO Train: [4/300][1200/1251]	eta 0:00:30 lr 0.000249	time 0.5227 (0.5989)	loss 5.3825 (5.8942)	grad_norm 2.1537 (2.0928)	mem 5328MB
[2022-04-17 21:20:29 tiny] (main.py 233): INFO EPOCH 4 training takes 0:12:21
[2022-04-17 21:20:40 tiny] (main.py 273): INFO Test: [0/49]	Time 10.717 (10.717)	Loss 4.0040 (4.0040)	Acc@1 25.098 (25.098)	Acc@5 46.777 (46.777)	Mem 5328MB
[2022-04-17 21:21:01 tiny] (main.py 279): INFO  * Acc@1 22.908 Acc@5 46.038
[2022-04-17 21:21:01 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 22.9%
[2022-04-17 21:21:01 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_4.pth saving......
[2022-04-17 21:21:01 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_4.pth saved !!!
[2022-04-17 21:21:01 tiny] (main.py 148): INFO Max accuracy: 22.91%
[2022-04-17 21:21:13 tiny] (main.py 226): INFO Train: [5/300][0/1251]	eta 4:10:55 lr 0.000251	time 12.0352 (12.0352)	loss 6.0400 (6.0400)	grad_norm 1.8412 (1.8412)	mem 5328MB
[2022-04-17 21:22:14 tiny] (main.py 226): INFO Train: [5/300][100/1251]	eta 0:13:52 lr 0.000255	time 0.4927 (0.7236)	loss 5.6414 (5.8528)	grad_norm 2.5478 (2.0582)	mem 5328MB
[2022-04-17 21:23:13 tiny] (main.py 226): INFO Train: [5/300][200/1251]	eta 0:11:29 lr 0.000259	time 0.4983 (0.6560)	loss 4.8729 (5.8070)	grad_norm 2.1409 (2.0686)	mem 5328MB
[2022-04-17 21:24:11 tiny] (main.py 226): INFO Train: [5/300][300/1251]	eta 0:10:00 lr 0.000263	time 0.5744 (0.6318)	loss 5.3741 (5.7820)	grad_norm 1.9021 (inf)	mem 5329MB
[2022-04-17 21:25:10 tiny] (main.py 226): INFO Train: [5/300][400/1251]	eta 0:08:47 lr 0.000267	time 0.7253 (0.6201)	loss 5.9111 (5.7704)	grad_norm 1.8086 (inf)	mem 5329MB
[2022-04-17 21:26:08 tiny] (main.py 226): INFO Train: [5/300][500/1251]	eta 0:07:40 lr 0.000271	time 0.5350 (0.6128)	loss 6.0784 (5.7584)	grad_norm 1.7208 (inf)	mem 5329MB
[2022-04-17 21:27:07 tiny] (main.py 226): INFO Train: [5/300][600/1251]	eta 0:06:36 lr 0.000275	time 0.6353 (0.6091)	loss 5.4297 (5.7447)	grad_norm 1.8700 (inf)	mem 5329MB
[2022-04-17 21:28:06 tiny] (main.py 226): INFO Train: [5/300][700/1251]	eta 0:05:33 lr 0.000279	time 0.5151 (0.6057)	loss 5.5305 (5.7265)	grad_norm 2.0022 (inf)	mem 5329MB
[2022-04-17 21:29:05 tiny] (main.py 226): INFO Train: [5/300][800/1251]	eta 0:04:32 lr 0.000283	time 0.5966 (0.6042)	loss 5.8646 (5.7134)	grad_norm 1.9033 (inf)	mem 5329MB
[2022-04-17 21:30:04 tiny] (main.py 226): INFO Train: [5/300][900/1251]	eta 0:03:31 lr 0.000287	time 0.4345 (0.6023)	loss 6.1501 (5.7115)	grad_norm 2.4959 (inf)	mem 5329MB
[2022-04-17 21:31:03 tiny] (main.py 226): INFO Train: [5/300][1000/1251]	eta 0:02:30 lr 0.000291	time 0.5970 (0.6010)	loss 5.8586 (5.7072)	grad_norm 1.9229 (inf)	mem 5329MB
[2022-04-17 21:32:01 tiny] (main.py 226): INFO Train: [5/300][1100/1251]	eta 0:01:30 lr 0.000295	time 0.5979 (0.6000)	loss 5.9777 (5.7006)	grad_norm 2.1401 (inf)	mem 5329MB
[2022-04-17 21:33:00 tiny] (main.py 226): INFO Train: [5/300][1200/1251]	eta 0:00:30 lr 0.000299	time 0.6280 (0.5991)	loss 6.0553 (5.6906)	grad_norm 1.8905 (inf)	mem 5329MB
[2022-04-17 21:33:22 tiny] (main.py 233): INFO EPOCH 5 training takes 0:12:21
[2022-04-17 21:33:34 tiny] (main.py 273): INFO Test: [0/49]	Time 11.675 (11.675)	Loss 3.6058 (3.6058)	Acc@1 29.980 (29.980)	Acc@5 53.809 (53.809)	Mem 5329MB
[2022-04-17 21:33:54 tiny] (main.py 279): INFO  * Acc@1 27.892 Acc@5 53.004
[2022-04-17 21:33:54 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 27.9%
[2022-04-17 21:33:54 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_5.pth saving......
[2022-04-17 21:33:54 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_5.pth saved !!!
[2022-04-17 21:33:54 tiny] (main.py 148): INFO Max accuracy: 27.89%
[2022-04-17 21:34:05 tiny] (main.py 226): INFO Train: [6/300][0/1251]	eta 4:02:23 lr 0.000301	time 11.6254 (11.6254)	loss 5.0241 (5.0241)	grad_norm 2.1449 (2.1449)	mem 5329MB
[2022-04-17 21:35:07 tiny] (main.py 226): INFO Train: [6/300][100/1251]	eta 0:13:58 lr 0.000305	time 0.7411 (0.7284)	loss 6.0281 (5.5565)	grad_norm 2.1478 (2.1186)	mem 5329MB
[2022-04-17 21:36:05 tiny] (main.py 226): INFO Train: [6/300][200/1251]	eta 0:11:27 lr 0.000309	time 0.6408 (0.6545)	loss 5.4923 (5.5879)	grad_norm 2.0221 (2.1268)	mem 5329MB
[2022-04-17 21:37:04 tiny] (main.py 226): INFO Train: [6/300][300/1251]	eta 0:10:01 lr 0.000313	time 0.6214 (0.6330)	loss 5.6397 (5.5597)	grad_norm 1.9395 (2.1385)	mem 5329MB
[2022-04-17 21:38:03 tiny] (main.py 226): INFO Train: [6/300][400/1251]	eta 0:08:48 lr 0.000317	time 0.5085 (0.6212)	loss 5.8685 (5.5694)	grad_norm 2.1296 (2.1212)	mem 5329MB
[2022-04-17 21:39:02 tiny] (main.py 226): INFO Train: [6/300][500/1251]	eta 0:07:41 lr 0.000321	time 0.5188 (0.6142)	loss 5.7283 (5.5566)	grad_norm 1.7979 (2.1105)	mem 5329MB
[2022-04-17 21:40:00 tiny] (main.py 226): INFO Train: [6/300][600/1251]	eta 0:06:37 lr 0.000325	time 0.5778 (0.6100)	loss 5.9076 (5.5477)	grad_norm 2.0976 (2.1045)	mem 5329MB
[2022-04-17 21:40:59 tiny] (main.py 226): INFO Train: [6/300][700/1251]	eta 0:05:34 lr 0.000329	time 0.6958 (0.6070)	loss 5.8698 (5.5421)	grad_norm 1.7573 (2.1070)	mem 5329MB
[2022-04-17 21:41:58 tiny] (main.py 226): INFO Train: [6/300][800/1251]	eta 0:04:32 lr 0.000333	time 0.9596 (0.6047)	loss 4.7292 (5.5356)	grad_norm 2.4077 (2.1032)	mem 5329MB
[2022-04-17 21:42:57 tiny] (main.py 226): INFO Train: [6/300][900/1251]	eta 0:03:31 lr 0.000337	time 0.5936 (0.6033)	loss 5.2836 (5.5346)	grad_norm 1.8763 (2.1004)	mem 5329MB
[2022-04-17 21:43:56 tiny] (main.py 226): INFO Train: [6/300][1000/1251]	eta 0:02:31 lr 0.000341	time 0.6996 (0.6018)	loss 6.1092 (5.5320)	grad_norm 2.1046 (2.0956)	mem 5329MB
[2022-04-17 21:44:55 tiny] (main.py 226): INFO Train: [6/300][1100/1251]	eta 0:01:30 lr 0.000345	time 0.7096 (0.6002)	loss 5.6858 (5.5321)	grad_norm 1.9646 (inf)	mem 5329MB
[2022-04-17 21:45:53 tiny] (main.py 226): INFO Train: [6/300][1200/1251]	eta 0:00:30 lr 0.000349	time 0.4873 (0.5992)	loss 5.1516 (5.5245)	grad_norm 1.7590 (inf)	mem 5329MB
[2022-04-17 21:46:15 tiny] (main.py 233): INFO EPOCH 6 training takes 0:12:21
[2022-04-17 21:46:27 tiny] (main.py 273): INFO Test: [0/49]	Time 11.688 (11.688)	Loss 3.4149 (3.4149)	Acc@1 30.859 (30.859)	Acc@5 58.203 (58.203)	Mem 5329MB
[2022-04-17 21:46:46 tiny] (main.py 279): INFO  * Acc@1 32.256 Acc@5 58.146
[2022-04-17 21:46:46 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 32.3%
[2022-04-17 21:46:46 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_6.pth saving......
[2022-04-17 21:46:46 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_6.pth saved !!!
[2022-04-17 21:46:46 tiny] (main.py 148): INFO Max accuracy: 32.26%
[2022-04-17 21:46:58 tiny] (main.py 226): INFO Train: [7/300][0/1251]	eta 4:16:29 lr 0.000351	time 12.3018 (12.3018)	loss 5.8304 (5.8304)	grad_norm 2.0215 (2.0215)	mem 5329MB
[2022-04-17 21:48:00 tiny] (main.py 226): INFO Train: [7/300][100/1251]	eta 0:13:57 lr 0.000355	time 0.5033 (0.7278)	loss 5.0137 (5.4843)	grad_norm 2.1594 (2.0816)	mem 5329MB
[2022-04-17 21:48:58 tiny] (main.py 226): INFO Train: [7/300][200/1251]	eta 0:11:29 lr 0.000359	time 0.6655 (0.6565)	loss 5.8512 (5.4581)	grad_norm 1.8969 (2.0738)	mem 5329MB
[2022-04-17 21:49:56 tiny] (main.py 226): INFO Train: [7/300][300/1251]	eta 0:10:00 lr 0.000363	time 0.5112 (0.6318)	loss 5.0317 (5.4378)	grad_norm 1.9400 (2.0950)	mem 5329MB
[2022-04-17 21:50:55 tiny] (main.py 226): INFO Train: [7/300][400/1251]	eta 0:08:48 lr 0.000367	time 0.5262 (0.6208)	loss 5.1424 (5.4259)	grad_norm 1.7671 (2.0816)	mem 5329MB
[2022-04-17 21:51:54 tiny] (main.py 226): INFO Train: [7/300][500/1251]	eta 0:07:41 lr 0.000371	time 0.6316 (0.6140)	loss 5.3689 (5.4182)	grad_norm 2.5149 (2.0878)	mem 5329MB
[2022-04-17 21:52:53 tiny] (main.py 226): INFO Train: [7/300][600/1251]	eta 0:06:36 lr 0.000375	time 0.5363 (0.6096)	loss 5.1479 (5.4092)	grad_norm 1.6509 (2.0818)	mem 5329MB
[2022-04-17 21:53:52 tiny] (main.py 226): INFO Train: [7/300][700/1251]	eta 0:05:34 lr 0.000379	time 0.5906 (0.6068)	loss 5.3416 (5.4193)	grad_norm 1.8738 (2.0704)	mem 5329MB
[2022-04-17 21:54:50 tiny] (main.py 226): INFO Train: [7/300][800/1251]	eta 0:04:32 lr 0.000383	time 0.5132 (0.6043)	loss 5.9473 (5.4148)	grad_norm 2.0137 (2.0756)	mem 5329MB
[2022-04-17 21:55:49 tiny] (main.py 226): INFO Train: [7/300][900/1251]	eta 0:03:31 lr 0.000387	time 0.4971 (0.6026)	loss 4.6920 (5.4044)	grad_norm 1.8505 (2.0713)	mem 5329MB
[2022-04-17 21:56:48 tiny] (main.py 226): INFO Train: [7/300][1000/1251]	eta 0:02:30 lr 0.000391	time 0.6907 (0.6014)	loss 5.9403 (5.4087)	grad_norm 1.7776 (2.0642)	mem 5329MB
[2022-04-17 21:57:47 tiny] (main.py 226): INFO Train: [7/300][1100/1251]	eta 0:01:30 lr 0.000395	time 0.6361 (0.6004)	loss 5.7053 (5.4007)	grad_norm 1.8137 (2.0582)	mem 5329MB
[2022-04-17 21:58:46 tiny] (main.py 226): INFO Train: [7/300][1200/1251]	eta 0:00:30 lr 0.000399	time 0.5012 (0.5990)	loss 4.1414 (5.3952)	grad_norm 1.9229 (2.0556)	mem 5329MB
[2022-04-17 21:59:08 tiny] (main.py 233): INFO EPOCH 7 training takes 0:12:21
[2022-04-17 21:59:19 tiny] (main.py 273): INFO Test: [0/49]	Time 11.788 (11.788)	Loss 3.0869 (3.0869)	Acc@1 37.402 (37.402)	Acc@5 62.109 (62.109)	Mem 5329MB
[2022-04-17 21:59:39 tiny] (main.py 279): INFO  * Acc@1 36.192 Acc@5 62.410
[2022-04-17 21:59:39 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 36.2%
[2022-04-17 21:59:39 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_7.pth saving......
[2022-04-17 21:59:39 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_7.pth saved !!!
[2022-04-17 21:59:39 tiny] (main.py 148): INFO Max accuracy: 36.19%
[2022-04-17 21:59:51 tiny] (main.py 226): INFO Train: [8/300][0/1251]	eta 4:02:19 lr 0.000401	time 11.6226 (11.6226)	loss 5.5563 (5.5563)	grad_norm 2.4550 (2.4550)	mem 5329MB
[2022-04-17 22:00:53 tiny] (main.py 226): INFO Train: [8/300][100/1251]	eta 0:14:00 lr 0.000405	time 0.5859 (0.7298)	loss 4.8167 (5.4121)	grad_norm 2.0545 (2.0614)	mem 5329MB
[2022-04-17 22:01:51 tiny] (main.py 226): INFO Train: [8/300][200/1251]	eta 0:11:31 lr 0.000409	time 0.7842 (0.6581)	loss 4.7689 (5.3763)	grad_norm 1.8013 (2.0394)	mem 5329MB
[2022-04-17 22:02:50 tiny] (main.py 226): INFO Train: [8/300][300/1251]	eta 0:10:02 lr 0.000413	time 0.6198 (0.6339)	loss 4.5840 (5.3723)	grad_norm 1.9844 (inf)	mem 5329MB
[2022-04-17 22:03:48 tiny] (main.py 226): INFO Train: [8/300][400/1251]	eta 0:08:48 lr 0.000417	time 0.6385 (0.6215)	loss 5.6971 (5.3389)	grad_norm 1.8704 (inf)	mem 5329MB
[2022-04-17 22:04:46 tiny] (main.py 226): INFO Train: [8/300][500/1251]	eta 0:07:40 lr 0.000421	time 0.5376 (0.6136)	loss 5.2450 (5.3264)	grad_norm 1.7994 (inf)	mem 5329MB
[2022-04-17 22:05:46 tiny] (main.py 226): INFO Train: [8/300][600/1251]	eta 0:06:37 lr 0.000425	time 0.5957 (0.6102)	loss 5.6851 (5.3044)	grad_norm 2.0050 (inf)	mem 5329MB
[2022-04-17 22:06:45 tiny] (main.py 226): INFO Train: [8/300][700/1251]	eta 0:05:34 lr 0.000429	time 0.5879 (0.6072)	loss 4.6379 (5.3023)	grad_norm 1.9280 (inf)	mem 5329MB
[2022-04-17 22:07:43 tiny] (main.py 226): INFO Train: [8/300][800/1251]	eta 0:04:32 lr 0.000433	time 0.3878 (0.6043)	loss 5.6055 (5.2927)	grad_norm 1.9000 (inf)	mem 5329MB
[2022-04-17 22:08:42 tiny] (main.py 226): INFO Train: [8/300][900/1251]	eta 0:03:31 lr 0.000437	time 0.5078 (0.6030)	loss 5.1919 (5.2913)	grad_norm 2.0454 (inf)	mem 5329MB
[2022-04-17 22:09:41 tiny] (main.py 226): INFO Train: [8/300][1000/1251]	eta 0:02:31 lr 0.000441	time 0.6318 (0.6017)	loss 5.5704 (5.2884)	grad_norm 2.2909 (inf)	mem 5329MB
[2022-04-17 22:10:40 tiny] (main.py 226): INFO Train: [8/300][1100/1251]	eta 0:01:30 lr 0.000445	time 0.5012 (0.6007)	loss 5.6443 (5.2870)	grad_norm 2.0864 (inf)	mem 5329MB
[2022-04-17 22:11:39 tiny] (main.py 226): INFO Train: [8/300][1200/1251]	eta 0:00:30 lr 0.000449	time 0.4485 (0.5993)	loss 4.6475 (5.2828)	grad_norm 1.9645 (inf)	mem 5329MB
[2022-04-17 22:12:01 tiny] (main.py 233): INFO EPOCH 8 training takes 0:12:21
[2022-04-17 22:12:13 tiny] (main.py 273): INFO Test: [0/49]	Time 11.852 (11.852)	Loss 2.9466 (2.9466)	Acc@1 40.527 (40.527)	Acc@5 65.332 (65.332)	Mem 5329MB
[2022-04-17 22:12:32 tiny] (main.py 279): INFO  * Acc@1 39.784 Acc@5 65.624
[2022-04-17 22:12:32 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 39.8%
[2022-04-17 22:12:32 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_8.pth saving......
[2022-04-17 22:12:32 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_8.pth saved !!!
[2022-04-17 22:12:32 tiny] (main.py 148): INFO Max accuracy: 39.78%
[2022-04-17 22:12:44 tiny] (main.py 226): INFO Train: [9/300][0/1251]	eta 4:11:29 lr 0.000451	time 12.0618 (12.0618)	loss 4.4412 (4.4412)	grad_norm 2.4769 (2.4769)	mem 5329MB
[2022-04-17 22:13:45 tiny] (main.py 226): INFO Train: [9/300][100/1251]	eta 0:13:55 lr 0.000455	time 0.4424 (0.7257)	loss 5.6823 (5.2555)	grad_norm 1.6645 (1.9605)	mem 5329MB
[2022-04-17 22:14:44 tiny] (main.py 226): INFO Train: [9/300][200/1251]	eta 0:11:29 lr 0.000459	time 0.6633 (0.6557)	loss 5.3017 (5.2440)	grad_norm 1.9489 (1.9941)	mem 5329MB
[2022-04-17 22:15:43 tiny] (main.py 226): INFO Train: [9/300][300/1251]	eta 0:10:01 lr 0.000463	time 0.7557 (0.6326)	loss 4.4247 (5.2636)	grad_norm 2.2080 (2.0178)	mem 5329MB
[2022-04-17 22:16:41 tiny] (main.py 226): INFO Train: [9/300][400/1251]	eta 0:08:48 lr 0.000467	time 0.6354 (0.6210)	loss 4.4234 (5.2309)	grad_norm 1.7798 (2.0134)	mem 5329MB
[2022-04-17 22:17:40 tiny] (main.py 226): INFO Train: [9/300][500/1251]	eta 0:07:41 lr 0.000471	time 0.6046 (0.6142)	loss 5.6255 (5.2119)	grad_norm 2.2883 (2.0282)	mem 5329MB
[2022-04-17 22:18:39 tiny] (main.py 226): INFO Train: [9/300][600/1251]	eta 0:06:36 lr 0.000475	time 0.5256 (0.6095)	loss 4.5215 (5.2085)	grad_norm 2.0860 (2.0338)	mem 5329MB
[2022-04-17 22:19:38 tiny] (main.py 226): INFO Train: [9/300][700/1251]	eta 0:05:34 lr 0.000478	time 0.5469 (0.6068)	loss 5.6841 (5.2045)	grad_norm 2.2446 (2.0343)	mem 5329MB
[2022-04-17 22:20:36 tiny] (main.py 226): INFO Train: [9/300][800/1251]	eta 0:04:32 lr 0.000482	time 0.6447 (0.6046)	loss 4.3011 (5.2032)	grad_norm 1.9391 (2.0370)	mem 5329MB
[2022-04-17 22:21:35 tiny] (main.py 226): INFO Train: [9/300][900/1251]	eta 0:03:31 lr 0.000486	time 0.5169 (0.6029)	loss 5.8198 (5.1902)	grad_norm 1.9460 (2.0488)	mem 5329MB
[2022-04-17 22:22:34 tiny] (main.py 226): INFO Train: [9/300][1000/1251]	eta 0:02:30 lr 0.000490	time 0.4466 (0.6014)	loss 5.6175 (5.1788)	grad_norm 1.9275 (2.0448)	mem 5329MB
[2022-04-17 22:23:33 tiny] (main.py 226): INFO Train: [9/300][1100/1251]	eta 0:01:30 lr 0.000494	time 0.8416 (0.6001)	loss 5.0668 (5.1766)	grad_norm 1.9969 (inf)	mem 5329MB
[2022-04-17 22:24:32 tiny] (main.py 226): INFO Train: [9/300][1200/1251]	eta 0:00:30 lr 0.000498	time 0.6839 (0.5992)	loss 4.3611 (5.1620)	grad_norm 1.9666 (inf)	mem 5329MB
[2022-04-17 22:24:54 tiny] (main.py 233): INFO EPOCH 9 training takes 0:12:21
[2022-04-17 22:25:06 tiny] (main.py 273): INFO Test: [0/49]	Time 12.218 (12.218)	Loss 2.9231 (2.9231)	Acc@1 41.699 (41.699)	Acc@5 65.918 (65.918)	Mem 5329MB
[2022-04-17 22:25:25 tiny] (main.py 279): INFO  * Acc@1 42.284 Acc@5 68.554
[2022-04-17 22:25:25 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 42.3%
[2022-04-17 22:25:25 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_9.pth saving......
[2022-04-17 22:25:25 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_9.pth saved !!!
[2022-04-17 22:25:25 tiny] (main.py 148): INFO Max accuracy: 42.28%
[2022-04-17 22:25:37 tiny] (main.py 226): INFO Train: [10/300][0/1251]	eta 4:16:29 lr 0.000501	time 12.3018 (12.3018)	loss 5.6837 (5.6837)	grad_norm 2.0860 (2.0860)	mem 5329MB
[2022-04-17 22:26:39 tiny] (main.py 226): INFO Train: [10/300][100/1251]	eta 0:13:59 lr 0.000504	time 0.5435 (0.7293)	loss 4.8828 (5.1726)	grad_norm 2.8636 (2.1197)	mem 5329MB
[2022-04-17 22:27:37 tiny] (main.py 226): INFO Train: [10/300][200/1251]	eta 0:11:31 lr 0.000508	time 0.5480 (0.6576)	loss 5.3691 (5.1847)	grad_norm 1.8552 (2.1131)	mem 5329MB
[2022-04-17 22:28:36 tiny] (main.py 226): INFO Train: [10/300][300/1251]	eta 0:10:01 lr 0.000512	time 0.7244 (0.6326)	loss 5.5451 (5.1583)	grad_norm 1.7644 (2.1419)	mem 5329MB
[2022-04-17 22:29:35 tiny] (main.py 226): INFO Train: [10/300][400/1251]	eta 0:08:49 lr 0.000516	time 0.5051 (0.6219)	loss 4.0501 (5.1677)	grad_norm 2.2161 (2.1291)	mem 5329MB
[2022-04-17 22:30:33 tiny] (main.py 226): INFO Train: [10/300][500/1251]	eta 0:07:41 lr 0.000520	time 0.5488 (0.6142)	loss 5.5487 (5.1520)	grad_norm 2.0709 (2.1379)	mem 5329MB
[2022-04-17 22:31:32 tiny] (main.py 226): INFO Train: [10/300][600/1251]	eta 0:06:37 lr 0.000524	time 0.6985 (0.6103)	loss 5.2039 (5.1542)	grad_norm 2.6250 (2.1369)	mem 5329MB
[2022-04-17 22:32:31 tiny] (main.py 226): INFO Train: [10/300][700/1251]	eta 0:05:34 lr 0.000528	time 0.4870 (0.6072)	loss 5.7405 (5.1503)	grad_norm 1.7939 (2.1310)	mem 5329MB
[2022-04-17 22:33:29 tiny] (main.py 226): INFO Train: [10/300][800/1251]	eta 0:04:32 lr 0.000532	time 0.5500 (0.6045)	loss 3.5932 (5.1332)	grad_norm 2.7865 (2.1250)	mem 5329MB
[2022-04-17 22:34:29 tiny] (main.py 226): INFO Train: [10/300][900/1251]	eta 0:03:31 lr 0.000536	time 0.6161 (0.6031)	loss 3.8731 (5.1227)	grad_norm 2.5682 (2.1333)	mem 5329MB
[2022-04-17 22:35:27 tiny] (main.py 226): INFO Train: [10/300][1000/1251]	eta 0:02:30 lr 0.000540	time 0.7045 (0.6009)	loss 5.7443 (5.1256)	grad_norm 2.4216 (2.1281)	mem 5329MB
[2022-04-17 22:36:26 tiny] (main.py 226): INFO Train: [10/300][1100/1251]	eta 0:01:30 lr 0.000544	time 0.5378 (0.5999)	loss 5.4664 (5.1074)	grad_norm 2.0967 (2.1327)	mem 5329MB
[2022-04-17 22:37:25 tiny] (main.py 226): INFO Train: [10/300][1200/1251]	eta 0:00:30 lr 0.000548	time 0.5648 (0.5991)	loss 5.8013 (5.0977)	grad_norm 2.0299 (2.1388)	mem 5329MB
[2022-04-17 22:37:47 tiny] (main.py 233): INFO EPOCH 10 training takes 0:12:21
[2022-04-17 22:37:59 tiny] (main.py 273): INFO Test: [0/49]	Time 12.115 (12.115)	Loss 2.8219 (2.8219)	Acc@1 43.359 (43.359)	Acc@5 67.285 (67.285)	Mem 5329MB
[2022-04-17 22:38:18 tiny] (main.py 279): INFO  * Acc@1 44.054 Acc@5 69.846
[2022-04-17 22:38:18 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 44.1%
[2022-04-17 22:38:18 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_10.pth saving......
[2022-04-17 22:38:18 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_10.pth saved !!!
[2022-04-17 22:38:18 tiny] (main.py 148): INFO Max accuracy: 44.05%
[2022-04-17 22:38:31 tiny] (main.py 226): INFO Train: [11/300][0/1251]	eta 4:19:54 lr 0.000550	time 12.4656 (12.4656)	loss 5.4626 (5.4626)	grad_norm 2.9254 (2.9254)	mem 5329MB
[2022-04-17 22:39:31 tiny] (main.py 226): INFO Train: [11/300][100/1251]	eta 0:13:54 lr 0.000554	time 0.4868 (0.7252)	loss 4.9525 (5.0424)	grad_norm 1.9177 (2.2268)	mem 5329MB
[2022-04-17 22:40:30 tiny] (main.py 226): INFO Train: [11/300][200/1251]	eta 0:11:31 lr 0.000558	time 0.6363 (0.6581)	loss 4.3671 (5.0071)	grad_norm 2.3200 (2.1563)	mem 5329MB
[2022-04-17 22:41:28 tiny] (main.py 226): INFO Train: [11/300][300/1251]	eta 0:10:01 lr 0.000562	time 0.5025 (0.6322)	loss 5.6360 (5.0360)	grad_norm 1.9933 (2.1551)	mem 5329MB
[2022-04-17 22:42:27 tiny] (main.py 226): INFO Train: [11/300][400/1251]	eta 0:08:48 lr 0.000566	time 0.5332 (0.6212)	loss 5.3696 (5.0587)	grad_norm 1.5238 (2.1453)	mem 5329MB
[2022-04-17 22:43:26 tiny] (main.py 226): INFO Train: [11/300][500/1251]	eta 0:07:41 lr 0.000570	time 0.4740 (0.6142)	loss 5.5171 (5.0479)	grad_norm 2.5179 (2.1444)	mem 5329MB
[2022-04-17 22:44:24 tiny] (main.py 226): INFO Train: [11/300][600/1251]	eta 0:06:36 lr 0.000574	time 0.5811 (0.6095)	loss 5.6586 (5.0415)	grad_norm 2.1546 (inf)	mem 5329MB
[2022-04-17 22:45:23 tiny] (main.py 226): INFO Train: [11/300][700/1251]	eta 0:05:34 lr 0.000578	time 0.6655 (0.6068)	loss 5.5408 (5.0549)	grad_norm 1.7859 (inf)	mem 5329MB
[2022-04-17 22:46:22 tiny] (main.py 226): INFO Train: [11/300][800/1251]	eta 0:04:32 lr 0.000582	time 0.6163 (0.6043)	loss 5.2394 (5.0635)	grad_norm 2.0865 (inf)	mem 5329MB
[2022-04-17 22:47:21 tiny] (main.py 226): INFO Train: [11/300][900/1251]	eta 0:03:31 lr 0.000586	time 0.5914 (0.6025)	loss 3.8454 (5.0612)	grad_norm 2.1017 (inf)	mem 5329MB
[2022-04-17 22:48:20 tiny] (main.py 226): INFO Train: [11/300][1000/1251]	eta 0:02:30 lr 0.000590	time 0.5918 (0.6013)	loss 5.5061 (5.0438)	grad_norm 1.9559 (inf)	mem 5329MB
[2022-04-17 22:49:19 tiny] (main.py 226): INFO Train: [11/300][1100/1251]	eta 0:01:30 lr 0.000594	time 0.4292 (0.5999)	loss 5.6126 (5.0395)	grad_norm 2.3308 (inf)	mem 5329MB
[2022-04-17 22:50:17 tiny] (main.py 226): INFO Train: [11/300][1200/1251]	eta 0:00:30 lr 0.000598	time 0.6895 (0.5990)	loss 4.8981 (5.0380)	grad_norm 1.8285 (inf)	mem 5329MB
[2022-04-17 22:50:39 tiny] (main.py 233): INFO EPOCH 11 training takes 0:12:20
[2022-04-17 22:50:51 tiny] (main.py 273): INFO Test: [0/49]	Time 12.412 (12.412)	Loss 2.6137 (2.6137)	Acc@1 45.410 (45.410)	Acc@5 73.438 (73.438)	Mem 5329MB
[2022-04-17 22:51:10 tiny] (main.py 279): INFO  * Acc@1 45.456 Acc@5 71.104
[2022-04-17 22:51:10 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 45.5%
[2022-04-17 22:51:10 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_11.pth saving......
[2022-04-17 22:51:10 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_11.pth saved !!!
[2022-04-17 22:51:10 tiny] (main.py 148): INFO Max accuracy: 45.46%
[2022-04-17 22:51:22 tiny] (main.py 226): INFO Train: [12/300][0/1251]	eta 4:05:24 lr 0.000600	time 11.7702 (11.7702)	loss 5.8010 (5.8010)	grad_norm 2.4734 (2.4734)	mem 5329MB
[2022-04-17 22:52:24 tiny] (main.py 226): INFO Train: [12/300][100/1251]	eta 0:14:01 lr 0.000604	time 0.5602 (0.7308)	loss 4.7591 (4.9159)	grad_norm 1.8346 (2.1981)	mem 5329MB
[2022-04-17 22:53:22 tiny] (main.py 226): INFO Train: [12/300][200/1251]	eta 0:11:30 lr 0.000608	time 0.8329 (0.6568)	loss 5.3416 (4.9673)	grad_norm 1.6269 (2.2074)	mem 5329MB
[2022-04-17 22:54:21 tiny] (main.py 226): INFO Train: [12/300][300/1251]	eta 0:10:03 lr 0.000612	time 0.6186 (0.6342)	loss 5.4346 (4.9868)	grad_norm 1.7381 (2.2153)	mem 5329MB
[2022-04-17 22:55:20 tiny] (main.py 226): INFO Train: [12/300][400/1251]	eta 0:08:49 lr 0.000616	time 0.6064 (0.6221)	loss 5.1716 (4.9713)	grad_norm 1.9245 (2.2134)	mem 5329MB
[2022-04-17 22:56:19 tiny] (main.py 226): INFO Train: [12/300][500/1251]	eta 0:07:42 lr 0.000620	time 0.4785 (0.6155)	loss 5.6619 (4.9691)	grad_norm 2.9610 (2.2130)	mem 5329MB
[2022-04-17 22:57:17 tiny] (main.py 226): INFO Train: [12/300][600/1251]	eta 0:06:37 lr 0.000624	time 0.6379 (0.6105)	loss 5.2427 (4.9764)	grad_norm 1.6493 (2.2185)	mem 5329MB
[2022-04-17 22:58:15 tiny] (main.py 226): INFO Train: [12/300][700/1251]	eta 0:05:34 lr 0.000628	time 0.4017 (0.6064)	loss 5.1534 (4.9763)	grad_norm 3.0753 (2.2226)	mem 5329MB
[2022-04-17 22:59:15 tiny] (main.py 226): INFO Train: [12/300][800/1251]	eta 0:04:32 lr 0.000632	time 0.5492 (0.6047)	loss 4.3904 (4.9709)	grad_norm 2.5836 (2.2405)	mem 5329MB
[2022-04-17 23:00:13 tiny] (main.py 226): INFO Train: [12/300][900/1251]	eta 0:03:31 lr 0.000636	time 0.7522 (0.6028)	loss 5.3027 (4.9796)	grad_norm 3.4960 (2.2530)	mem 5329MB
[2022-04-17 23:01:12 tiny] (main.py 226): INFO Train: [12/300][1000/1251]	eta 0:02:31 lr 0.000640	time 0.5369 (0.6017)	loss 5.0303 (4.9637)	grad_norm 1.5980 (2.2546)	mem 5329MB
[2022-04-17 23:02:11 tiny] (main.py 226): INFO Train: [12/300][1100/1251]	eta 0:01:30 lr 0.000644	time 0.6667 (0.6005)	loss 4.7437 (4.9603)	grad_norm 3.4477 (2.2642)	mem 5329MB
[2022-04-17 23:03:10 tiny] (main.py 226): INFO Train: [12/300][1200/1251]	eta 0:00:30 lr 0.000648	time 0.7449 (0.5993)	loss 4.2217 (4.9626)	grad_norm 2.1442 (2.2686)	mem 5329MB
[2022-04-17 23:03:32 tiny] (main.py 233): INFO EPOCH 12 training takes 0:12:21
[2022-04-17 23:03:44 tiny] (main.py 273): INFO Test: [0/49]	Time 11.762 (11.762)	Loss 2.4786 (2.4786)	Acc@1 49.805 (49.805)	Acc@5 74.121 (74.121)	Mem 5329MB
[2022-04-17 23:04:03 tiny] (main.py 279): INFO  * Acc@1 47.324 Acc@5 72.828
[2022-04-17 23:04:03 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 47.3%
[2022-04-17 23:04:03 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_12.pth saving......
[2022-04-17 23:04:03 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_12.pth saved !!!
[2022-04-17 23:04:03 tiny] (main.py 148): INFO Max accuracy: 47.32%
[2022-04-17 23:04:14 tiny] (main.py 226): INFO Train: [13/300][0/1251]	eta 3:57:27 lr 0.000650	time 11.3892 (11.3892)	loss 4.0276 (4.0276)	grad_norm 2.8338 (2.8338)	mem 5329MB
[2022-04-17 23:05:16 tiny] (main.py 226): INFO Train: [13/300][100/1251]	eta 0:13:55 lr 0.000654	time 0.5988 (0.7260)	loss 4.1642 (4.8475)	grad_norm 2.6112 (inf)	mem 5329MB
[2022-04-17 23:06:15 tiny] (main.py 226): INFO Train: [13/300][200/1251]	eta 0:11:30 lr 0.000658	time 0.5942 (0.6573)	loss 4.3360 (4.8610)	grad_norm 1.7772 (inf)	mem 5329MB
[2022-04-17 23:07:13 tiny] (main.py 226): INFO Train: [13/300][300/1251]	eta 0:10:01 lr 0.000662	time 0.6168 (0.6325)	loss 5.2481 (4.8730)	grad_norm 1.9526 (inf)	mem 5329MB
[2022-04-17 23:08:12 tiny] (main.py 226): INFO Train: [13/300][400/1251]	eta 0:08:48 lr 0.000666	time 0.5094 (0.6216)	loss 5.3706 (4.8854)	grad_norm 2.0295 (inf)	mem 5329MB
[2022-04-17 23:09:11 tiny] (main.py 226): INFO Train: [13/300][500/1251]	eta 0:07:41 lr 0.000670	time 0.5442 (0.6140)	loss 5.5978 (4.9010)	grad_norm 1.5067 (inf)	mem 5329MB
[2022-04-17 23:10:09 tiny] (main.py 226): INFO Train: [13/300][600/1251]	eta 0:06:36 lr 0.000674	time 0.5592 (0.6089)	loss 5.7211 (4.9002)	grad_norm 2.1534 (inf)	mem 5329MB
[2022-04-17 23:11:08 tiny] (main.py 226): INFO Train: [13/300][700/1251]	eta 0:05:34 lr 0.000678	time 0.6834 (0.6064)	loss 5.7658 (4.9008)	grad_norm 1.7429 (inf)	mem 5329MB
[2022-04-17 23:12:07 tiny] (main.py 226): INFO Train: [13/300][800/1251]	eta 0:04:32 lr 0.000682	time 0.3812 (0.6039)	loss 4.6389 (4.8907)	grad_norm 2.1370 (inf)	mem 5329MB
[2022-04-17 23:13:06 tiny] (main.py 226): INFO Train: [13/300][900/1251]	eta 0:03:31 lr 0.000686	time 0.4920 (0.6023)	loss 4.1954 (4.8978)	grad_norm 2.5861 (inf)	mem 5329MB
[2022-04-17 23:14:05 tiny] (main.py 226): INFO Train: [13/300][1000/1251]	eta 0:02:30 lr 0.000690	time 0.4985 (0.6010)	loss 4.8761 (4.8940)	grad_norm 2.2455 (inf)	mem 5329MB
[2022-04-17 23:15:03 tiny] (main.py 226): INFO Train: [13/300][1100/1251]	eta 0:01:30 lr 0.000694	time 0.6446 (0.5998)	loss 5.3573 (4.8951)	grad_norm 3.0335 (inf)	mem 5329MB
[2022-04-17 23:16:02 tiny] (main.py 226): INFO Train: [13/300][1200/1251]	eta 0:00:30 lr 0.000698	time 0.6143 (0.5989)	loss 4.7923 (4.8914)	grad_norm 3.3391 (inf)	mem 5329MB
[2022-04-17 23:16:24 tiny] (main.py 233): INFO EPOCH 13 training takes 0:12:21
[2022-04-17 23:16:37 tiny] (main.py 273): INFO Test: [0/49]	Time 12.474 (12.474)	Loss 2.4006 (2.4006)	Acc@1 49.023 (49.023)	Acc@5 75.195 (75.195)	Mem 5329MB
[2022-04-17 23:16:55 tiny] (main.py 279): INFO  * Acc@1 48.154 Acc@5 73.426
[2022-04-17 23:16:55 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 48.2%
[2022-04-17 23:16:55 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_13.pth saving......
[2022-04-17 23:16:55 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_13.pth saved !!!
[2022-04-17 23:16:55 tiny] (main.py 148): INFO Max accuracy: 48.15%
[2022-04-17 23:17:07 tiny] (main.py 226): INFO Train: [14/300][0/1251]	eta 4:03:30 lr 0.000700	time 11.6792 (11.6792)	loss 5.2007 (5.2007)	grad_norm 2.6508 (2.6508)	mem 5329MB
[2022-04-17 23:18:09 tiny] (main.py 226): INFO Train: [14/300][100/1251]	eta 0:13:59 lr 0.000704	time 0.6434 (0.7290)	loss 4.6235 (4.8922)	grad_norm 4.5697 (2.4560)	mem 5329MB
[2022-04-17 23:19:07 tiny] (main.py 226): INFO Train: [14/300][200/1251]	eta 0:11:29 lr 0.000708	time 0.6269 (0.6559)	loss 5.3088 (4.8609)	grad_norm 3.0668 (2.4640)	mem 5329MB
[2022-04-17 23:20:06 tiny] (main.py 226): INFO Train: [14/300][300/1251]	eta 0:10:02 lr 0.000712	time 0.7399 (0.6338)	loss 4.5160 (4.8637)	grad_norm 2.9485 (2.4187)	mem 5329MB
[2022-04-17 23:21:04 tiny] (main.py 226): INFO Train: [14/300][400/1251]	eta 0:08:48 lr 0.000716	time 0.6320 (0.6208)	loss 4.8687 (4.8567)	grad_norm 2.2431 (2.4115)	mem 5329MB
[2022-04-17 23:22:03 tiny] (main.py 226): INFO Train: [14/300][500/1251]	eta 0:07:40 lr 0.000720	time 0.4841 (0.6137)	loss 5.6252 (4.8489)	grad_norm 3.5990 (2.4160)	mem 5329MB
[2022-04-17 23:23:02 tiny] (main.py 226): INFO Train: [14/300][600/1251]	eta 0:06:36 lr 0.000724	time 0.4419 (0.6096)	loss 5.0471 (4.8614)	grad_norm 1.5134 (2.4058)	mem 5329MB
[2022-04-17 23:24:01 tiny] (main.py 226): INFO Train: [14/300][700/1251]	eta 0:05:34 lr 0.000728	time 0.4600 (0.6066)	loss 4.8399 (4.8632)	grad_norm 4.3761 (2.3954)	mem 5329MB
[2022-04-17 23:24:59 tiny] (main.py 226): INFO Train: [14/300][800/1251]	eta 0:04:32 lr 0.000732	time 0.6101 (0.6040)	loss 3.6768 (4.8786)	grad_norm 1.6636 (inf)	mem 5329MB
[2022-04-17 23:25:58 tiny] (main.py 226): INFO Train: [14/300][900/1251]	eta 0:03:31 lr 0.000736	time 0.6265 (0.6023)	loss 4.2023 (4.8794)	grad_norm 2.9311 (inf)	mem 5329MB
[2022-04-17 23:26:56 tiny] (main.py 226): INFO Train: [14/300][1000/1251]	eta 0:02:30 lr 0.000740	time 0.5843 (0.6004)	loss 4.5032 (4.8729)	grad_norm 1.7359 (inf)	mem 5329MB
[2022-04-17 23:27:55 tiny] (main.py 226): INFO Train: [14/300][1100/1251]	eta 0:01:30 lr 0.000744	time 0.5015 (0.5994)	loss 5.2936 (4.8678)	grad_norm 2.6759 (inf)	mem 5329MB
[2022-04-17 23:28:54 tiny] (main.py 226): INFO Train: [14/300][1200/1251]	eta 0:00:30 lr 0.000748	time 0.6158 (0.5986)	loss 4.6604 (4.8607)	grad_norm 2.1185 (inf)	mem 5329MB
[2022-04-17 23:29:16 tiny] (main.py 233): INFO EPOCH 14 training takes 0:12:20
[2022-04-17 23:29:27 tiny] (main.py 273): INFO Test: [0/49]	Time 10.980 (10.980)	Loss 2.5385 (2.5385)	Acc@1 47.754 (47.754)	Acc@5 73.242 (73.242)	Mem 5329MB
[2022-04-17 23:29:47 tiny] (main.py 279): INFO  * Acc@1 48.474 Acc@5 74.094
[2022-04-17 23:29:47 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 48.5%
[2022-04-17 23:29:47 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_14.pth saving......
[2022-04-17 23:29:47 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_14.pth saved !!!
[2022-04-17 23:29:47 tiny] (main.py 148): INFO Max accuracy: 48.47%
[2022-04-17 23:29:59 tiny] (main.py 226): INFO Train: [15/300][0/1251]	eta 4:06:57 lr 0.000750	time 11.8449 (11.8449)	loss 5.1570 (5.1570)	grad_norm 2.5163 (2.5163)	mem 5329MB
[2022-04-17 23:31:00 tiny] (main.py 226): INFO Train: [15/300][100/1251]	eta 0:13:52 lr 0.000754	time 0.6290 (0.7230)	loss 5.4416 (4.8421)	grad_norm 2.2612 (2.2722)	mem 5329MB
[2022-04-17 23:31:59 tiny] (main.py 226): INFO Train: [15/300][200/1251]	eta 0:11:30 lr 0.000758	time 0.6497 (0.6567)	loss 5.4247 (4.8199)	grad_norm 2.5847 (2.3586)	mem 5329MB
[2022-04-17 23:32:57 tiny] (main.py 226): INFO Train: [15/300][300/1251]	eta 0:10:00 lr 0.000762	time 0.5976 (0.6319)	loss 5.2837 (4.8226)	grad_norm 2.2807 (2.4284)	mem 5329MB
[2022-04-17 23:33:56 tiny] (main.py 226): INFO Train: [15/300][400/1251]	eta 0:08:47 lr 0.000766	time 0.4628 (0.6204)	loss 4.0887 (4.8253)	grad_norm 1.6705 (2.4209)	mem 5329MB
[2022-04-17 23:34:55 tiny] (main.py 226): INFO Train: [15/300][500/1251]	eta 0:07:40 lr 0.000770	time 0.4572 (0.6138)	loss 4.2613 (4.8417)	grad_norm 2.3028 (2.4418)	mem 5329MB
[2022-04-17 23:35:54 tiny] (main.py 226): INFO Train: [15/300][600/1251]	eta 0:06:37 lr 0.000774	time 0.7224 (0.6102)	loss 4.3668 (4.8336)	grad_norm 1.8159 (2.4562)	mem 5329MB
[2022-04-17 23:36:53 tiny] (main.py 226): INFO Train: [15/300][700/1251]	eta 0:05:34 lr 0.000778	time 0.4812 (0.6068)	loss 5.3026 (4.8364)	grad_norm 2.1055 (2.4377)	mem 5329MB
[2022-04-17 23:37:52 tiny] (main.py 226): INFO Train: [15/300][800/1251]	eta 0:04:32 lr 0.000782	time 0.4496 (0.6047)	loss 4.8390 (4.8379)	grad_norm 2.5730 (2.4353)	mem 5329MB
[2022-04-17 23:38:50 tiny] (main.py 226): INFO Train: [15/300][900/1251]	eta 0:03:31 lr 0.000786	time 0.6307 (0.6028)	loss 4.5421 (4.8320)	grad_norm 3.7298 (2.4473)	mem 5329MB
[2022-04-17 23:39:49 tiny] (main.py 226): INFO Train: [15/300][1000/1251]	eta 0:02:30 lr 0.000790	time 0.5595 (0.6015)	loss 5.3944 (4.8340)	grad_norm 3.4360 (2.4377)	mem 5329MB
[2022-04-17 23:40:48 tiny] (main.py 226): INFO Train: [15/300][1100/1251]	eta 0:01:30 lr 0.000794	time 0.6056 (0.6001)	loss 5.2064 (4.8248)	grad_norm 2.1903 (2.4453)	mem 5329MB
[2022-04-17 23:41:47 tiny] (main.py 226): INFO Train: [15/300][1200/1251]	eta 0:00:30 lr 0.000798	time 0.5474 (0.5992)	loss 5.6335 (4.8281)	grad_norm 1.5823 (2.4417)	mem 5329MB
[2022-04-17 23:42:09 tiny] (main.py 233): INFO EPOCH 15 training takes 0:12:21
[2022-04-17 23:42:21 tiny] (main.py 273): INFO Test: [0/49]	Time 11.675 (11.675)	Loss 2.3880 (2.3880)	Acc@1 47.754 (47.754)	Acc@5 76.562 (76.562)	Mem 5329MB
[2022-04-17 23:42:40 tiny] (main.py 279): INFO  * Acc@1 49.986 Acc@5 75.462
[2022-04-17 23:42:40 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 50.0%
[2022-04-17 23:42:40 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_15.pth saving......
[2022-04-17 23:42:40 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_15.pth saved !!!
[2022-04-17 23:42:40 tiny] (main.py 148): INFO Max accuracy: 49.99%
[2022-04-17 23:42:53 tiny] (main.py 226): INFO Train: [16/300][0/1251]	eta 4:18:51 lr 0.000800	time 12.4153 (12.4153)	loss 4.8269 (4.8269)	grad_norm 2.5712 (2.5712)	mem 5329MB
[2022-04-17 23:43:53 tiny] (main.py 226): INFO Train: [16/300][100/1251]	eta 0:13:54 lr 0.000804	time 0.4343 (0.7252)	loss 4.9123 (4.8709)	grad_norm 2.4692 (2.5703)	mem 5329MB
[2022-04-17 23:44:52 tiny] (main.py 226): INFO Train: [16/300][200/1251]	eta 0:11:29 lr 0.000808	time 0.6794 (0.6559)	loss 5.1896 (4.7925)	grad_norm 1.7194 (2.5074)	mem 5329MB
[2022-04-17 23:45:51 tiny] (main.py 226): INFO Train: [16/300][300/1251]	eta 0:10:01 lr 0.000812	time 0.5155 (0.6329)	loss 4.7259 (4.7954)	grad_norm 3.1721 (2.4785)	mem 5329MB
[2022-04-17 23:46:49 tiny] (main.py 226): INFO Train: [16/300][400/1251]	eta 0:08:48 lr 0.000816	time 0.6005 (0.6209)	loss 5.3440 (4.7866)	grad_norm 3.2368 (2.4898)	mem 5329MB
[2022-04-17 23:47:48 tiny] (main.py 226): INFO Train: [16/300][500/1251]	eta 0:07:41 lr 0.000820	time 0.5428 (0.6141)	loss 5.1003 (4.7976)	grad_norm 1.7323 (2.4669)	mem 5329MB
[2022-04-17 23:48:46 tiny] (main.py 226): INFO Train: [16/300][600/1251]	eta 0:06:36 lr 0.000824	time 0.4498 (0.6094)	loss 5.2364 (4.8150)	grad_norm 3.7375 (2.4989)	mem 5329MB
[2022-04-17 23:49:45 tiny] (main.py 226): INFO Train: [16/300][700/1251]	eta 0:05:33 lr 0.000828	time 0.5357 (0.6059)	loss 5.1080 (4.8134)	grad_norm 1.4036 (2.4741)	mem 5329MB
[2022-04-17 23:50:44 tiny] (main.py 226): INFO Train: [16/300][800/1251]	eta 0:04:32 lr 0.000832	time 0.4703 (0.6039)	loss 5.1682 (4.8112)	grad_norm 2.0472 (2.4565)	mem 5329MB
[2022-04-17 23:51:43 tiny] (main.py 226): INFO Train: [16/300][900/1251]	eta 0:03:31 lr 0.000836	time 0.5487 (0.6026)	loss 5.1088 (4.8067)	grad_norm 1.7829 (2.4408)	mem 5329MB
[2022-04-17 23:52:42 tiny] (main.py 226): INFO Train: [16/300][1000/1251]	eta 0:02:30 lr 0.000840	time 0.3717 (0.6010)	loss 4.9722 (4.7992)	grad_norm 2.2658 (inf)	mem 5329MB
[2022-04-17 23:53:40 tiny] (main.py 226): INFO Train: [16/300][1100/1251]	eta 0:01:30 lr 0.000844	time 0.5550 (0.5995)	loss 5.0404 (4.7890)	grad_norm 1.8850 (inf)	mem 5329MB
[2022-04-17 23:54:39 tiny] (main.py 226): INFO Train: [16/300][1200/1251]	eta 0:00:30 lr 0.000848	time 0.3614 (0.5984)	loss 5.0485 (4.7895)	grad_norm 1.8738 (inf)	mem 5329MB
[2022-04-17 23:55:01 tiny] (main.py 233): INFO EPOCH 16 training takes 0:12:20
[2022-04-17 23:55:12 tiny] (main.py 273): INFO Test: [0/49]	Time 11.693 (11.693)	Loss 2.3479 (2.3479)	Acc@1 51.074 (51.074)	Acc@5 76.465 (76.465)	Mem 5329MB
[2022-04-17 23:55:32 tiny] (main.py 279): INFO  * Acc@1 50.428 Acc@5 75.500
[2022-04-17 23:55:32 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 50.4%
[2022-04-17 23:55:32 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_16.pth saving......
[2022-04-17 23:55:32 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_16.pth saved !!!
[2022-04-17 23:55:32 tiny] (main.py 148): INFO Max accuracy: 50.43%
[2022-04-17 23:55:43 tiny] (main.py 226): INFO Train: [17/300][0/1251]	eta 3:41:00 lr 0.000850	time 10.6002 (10.6002)	loss 4.4921 (4.4921)	grad_norm 1.8890 (1.8890)	mem 5329MB
[2022-04-17 23:56:45 tiny] (main.py 226): INFO Train: [17/300][100/1251]	eta 0:13:55 lr 0.000854	time 0.6921 (0.7258)	loss 4.9291 (4.7507)	grad_norm 3.4516 (2.4406)	mem 5329MB
[2022-04-17 23:57:44 tiny] (main.py 226): INFO Train: [17/300][200/1251]	eta 0:11:30 lr 0.000858	time 0.6374 (0.6573)	loss 5.2902 (4.7067)	grad_norm 2.4974 (2.4333)	mem 5329MB
[2022-04-17 23:58:43 tiny] (main.py 226): INFO Train: [17/300][300/1251]	eta 0:10:02 lr 0.000862	time 0.5358 (0.6337)	loss 4.8752 (4.6915)	grad_norm 2.7936 (2.4514)	mem 5329MB
[2022-04-17 23:59:42 tiny] (main.py 226): INFO Train: [17/300][400/1251]	eta 0:08:49 lr 0.000866	time 0.8588 (0.6224)	loss 5.1250 (4.6907)	grad_norm 2.7458 (2.4191)	mem 5329MB
[2022-04-18 00:00:38 tiny] (main.py 226): INFO Train: [17/300][500/1251]	eta 0:07:38 lr 0.000870	time 0.4774 (0.6107)	loss 4.1520 (4.7190)	grad_norm 2.7983 (2.4166)	mem 5329MB
[2022-04-18 00:01:39 tiny] (main.py 226): INFO Train: [17/300][600/1251]	eta 0:06:37 lr 0.000874	time 0.6502 (0.6105)	loss 5.6136 (4.7272)	grad_norm 1.9529 (2.4186)	mem 5329MB
[2022-04-18 00:02:38 tiny] (main.py 226): INFO Train: [17/300][700/1251]	eta 0:05:35 lr 0.000878	time 0.4941 (0.6080)	loss 5.2820 (4.7304)	grad_norm 2.0495 (2.4169)	mem 5329MB
[2022-04-18 00:03:37 tiny] (main.py 226): INFO Train: [17/300][800/1251]	eta 0:04:33 lr 0.000882	time 0.4895 (0.6056)	loss 5.1535 (4.7382)	grad_norm 3.2792 (2.4223)	mem 5329MB
[2022-04-18 00:04:36 tiny] (main.py 226): INFO Train: [17/300][900/1251]	eta 0:03:31 lr 0.000886	time 0.5776 (0.6039)	loss 4.9039 (4.7323)	grad_norm 3.6453 (2.4429)	mem 5329MB
[2022-04-18 00:05:36 tiny] (main.py 226): INFO Train: [17/300][1000/1251]	eta 0:02:31 lr 0.000890	time 0.8397 (0.6032)	loss 5.0009 (4.7402)	grad_norm 1.9717 (2.4394)	mem 5329MB
[2022-04-18 00:06:35 tiny] (main.py 226): INFO Train: [17/300][1100/1251]	eta 0:01:30 lr 0.000894	time 0.4833 (0.6019)	loss 5.0363 (4.7483)	grad_norm 1.7691 (2.4371)	mem 5329MB
[2022-04-18 00:07:33 tiny] (main.py 226): INFO Train: [17/300][1200/1251]	eta 0:00:30 lr 0.000898	time 0.6197 (0.6006)	loss 5.2360 (4.7574)	grad_norm 2.7824 (2.4296)	mem 5329MB
[2022-04-18 00:07:55 tiny] (main.py 233): INFO EPOCH 17 training takes 0:12:22
[2022-04-18 00:08:06 tiny] (main.py 273): INFO Test: [0/49]	Time 11.427 (11.427)	Loss 2.3120 (2.3120)	Acc@1 53.613 (53.613)	Acc@5 77.344 (77.344)	Mem 5329MB
[2022-04-18 00:08:27 tiny] (main.py 279): INFO  * Acc@1 51.926 Acc@5 77.020
[2022-04-18 00:08:27 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 51.9%
[2022-04-18 00:08:27 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_17.pth saving......
[2022-04-18 00:08:27 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_17.pth saved !!!
[2022-04-18 00:08:27 tiny] (main.py 148): INFO Max accuracy: 51.93%
[2022-04-18 00:08:39 tiny] (main.py 226): INFO Train: [18/300][0/1251]	eta 4:16:01 lr 0.000900	time 12.2793 (12.2793)	loss 4.5562 (4.5562)	grad_norm 1.9032 (1.9032)	mem 5329MB
[2022-04-18 00:09:40 tiny] (main.py 226): INFO Train: [18/300][100/1251]	eta 0:13:55 lr 0.000904	time 0.3565 (0.7255)	loss 4.3012 (4.6511)	grad_norm 2.5559 (2.4139)	mem 5329MB
[2022-04-18 00:10:39 tiny] (main.py 226): INFO Train: [18/300][200/1251]	eta 0:11:31 lr 0.000908	time 0.4833 (0.6575)	loss 5.3559 (4.6762)	grad_norm 3.0176 (2.4145)	mem 5329MB
[2022-04-18 00:11:37 tiny] (main.py 226): INFO Train: [18/300][300/1251]	eta 0:10:01 lr 0.000912	time 0.5765 (0.6320)	loss 4.9399 (4.7075)	grad_norm 2.1256 (2.4165)	mem 5329MB
[2022-04-18 00:12:36 tiny] (main.py 226): INFO Train: [18/300][400/1251]	eta 0:08:48 lr 0.000916	time 0.5984 (0.6208)	loss 5.0727 (4.6979)	grad_norm 1.8223 (2.4185)	mem 5329MB
[2022-04-18 00:13:35 tiny] (main.py 226): INFO Train: [18/300][500/1251]	eta 0:07:41 lr 0.000920	time 0.8603 (0.6139)	loss 4.9006 (4.7037)	grad_norm 2.2031 (2.4098)	mem 5329MB
[2022-04-18 00:14:34 tiny] (main.py 226): INFO Train: [18/300][600/1251]	eta 0:06:37 lr 0.000924	time 0.7296 (0.6104)	loss 5.5991 (4.6909)	grad_norm 3.0684 (2.3896)	mem 5329MB
[2022-04-18 00:15:32 tiny] (main.py 226): INFO Train: [18/300][700/1251]	eta 0:05:34 lr 0.000928	time 0.5708 (0.6066)	loss 5.1620 (4.6906)	grad_norm 3.0572 (2.4163)	mem 5329MB
[2022-04-18 00:16:31 tiny] (main.py 226): INFO Train: [18/300][800/1251]	eta 0:04:32 lr 0.000932	time 0.5954 (0.6043)	loss 4.4133 (4.6996)	grad_norm 2.1215 (2.4018)	mem 5329MB
[2022-04-18 00:17:30 tiny] (main.py 226): INFO Train: [18/300][900/1251]	eta 0:03:31 lr 0.000936	time 0.4241 (0.6022)	loss 5.2985 (4.6906)	grad_norm 3.2961 (2.3912)	mem 5329MB
[2022-04-18 00:18:29 tiny] (main.py 226): INFO Train: [18/300][1000/1251]	eta 0:02:30 lr 0.000940	time 0.5831 (0.6011)	loss 5.2621 (4.6961)	grad_norm 3.1345 (inf)	mem 5329MB
[2022-04-18 00:19:27 tiny] (main.py 226): INFO Train: [18/300][1100/1251]	eta 0:01:30 lr 0.000944	time 0.4230 (0.5996)	loss 5.0793 (4.7053)	grad_norm 1.6918 (inf)	mem 5329MB
[2022-04-18 00:20:26 tiny] (main.py 226): INFO Train: [18/300][1200/1251]	eta 0:00:30 lr 0.000948	time 0.5592 (0.5988)	loss 5.5392 (4.7083)	grad_norm 5.4218 (inf)	mem 5329MB
[2022-04-18 00:20:48 tiny] (main.py 233): INFO EPOCH 18 training takes 0:12:21
[2022-04-18 00:21:01 tiny] (main.py 273): INFO Test: [0/49]	Time 12.556 (12.556)	Loss 2.2585 (2.2585)	Acc@1 54.004 (54.004)	Acc@5 78.027 (78.027)	Mem 5329MB
[2022-04-18 00:21:20 tiny] (main.py 279): INFO  * Acc@1 52.410 Acc@5 77.238
[2022-04-18 00:21:20 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 52.4%
[2022-04-18 00:21:20 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_18.pth saving......
[2022-04-18 00:21:20 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_18.pth saved !!!
[2022-04-18 00:21:20 tiny] (main.py 148): INFO Max accuracy: 52.41%
[2022-04-18 00:21:31 tiny] (main.py 226): INFO Train: [19/300][0/1251]	eta 3:45:13 lr 0.000950	time 10.8020 (10.8020)	loss 4.5596 (4.5596)	grad_norm 2.1156 (2.1156)	mem 5329MB
[2022-04-18 00:22:34 tiny] (main.py 226): INFO Train: [19/300][100/1251]	eta 0:13:53 lr 0.000954	time 0.7560 (0.7245)	loss 4.8032 (4.6417)	grad_norm 2.1019 (2.4241)	mem 5329MB
[2022-04-18 00:23:32 tiny] (main.py 226): INFO Train: [19/300][200/1251]	eta 0:11:29 lr 0.000958	time 0.7206 (0.6564)	loss 3.6424 (4.6808)	grad_norm 2.0966 (2.3991)	mem 5329MB
[2022-04-18 00:24:31 tiny] (main.py 226): INFO Train: [19/300][300/1251]	eta 0:10:00 lr 0.000962	time 0.5027 (0.6316)	loss 4.0320 (4.6776)	grad_norm 1.4596 (2.4160)	mem 5329MB
[2022-04-18 00:25:30 tiny] (main.py 226): INFO Train: [19/300][400/1251]	eta 0:08:48 lr 0.000966	time 0.5712 (0.6212)	loss 3.9303 (4.7035)	grad_norm 2.3768 (2.3701)	mem 5329MB
[2022-04-18 00:26:28 tiny] (main.py 226): INFO Train: [19/300][500/1251]	eta 0:07:40 lr 0.000970	time 0.5014 (0.6138)	loss 4.6865 (4.6997)	grad_norm 1.7912 (2.4225)	mem 5329MB
[2022-04-18 00:27:27 tiny] (main.py 226): INFO Train: [19/300][600/1251]	eta 0:06:37 lr 0.000974	time 0.6001 (0.6101)	loss 4.3607 (4.6996)	grad_norm 3.4051 (2.3954)	mem 5329MB
[2022-04-18 00:28:26 tiny] (main.py 226): INFO Train: [19/300][700/1251]	eta 0:05:34 lr 0.000978	time 0.8442 (0.6067)	loss 5.1722 (4.6851)	grad_norm 3.0795 (2.4006)	mem 5329MB
[2022-04-18 00:29:24 tiny] (main.py 226): INFO Train: [19/300][800/1251]	eta 0:04:32 lr 0.000982	time 0.4867 (0.6040)	loss 4.9765 (4.6922)	grad_norm 1.7251 (2.3888)	mem 5329MB
[2022-04-18 00:30:23 tiny] (main.py 226): INFO Train: [19/300][900/1251]	eta 0:03:31 lr 0.000986	time 0.4790 (0.6024)	loss 4.7451 (4.7001)	grad_norm 2.8583 (2.3917)	mem 5329MB
[2022-04-18 00:31:22 tiny] (main.py 226): INFO Train: [19/300][1000/1251]	eta 0:02:30 lr 0.000990	time 0.6850 (0.6007)	loss 5.0766 (4.7113)	grad_norm 2.3685 (2.3802)	mem 5329MB
[2022-04-18 00:32:21 tiny] (main.py 226): INFO Train: [19/300][1100/1251]	eta 0:01:30 lr 0.000994	time 0.3869 (0.5998)	loss 5.4350 (4.7062)	grad_norm 5.2010 (2.3889)	mem 5329MB
[2022-04-18 00:33:19 tiny] (main.py 226): INFO Train: [19/300][1200/1251]	eta 0:00:30 lr 0.000998	time 0.5221 (0.5984)	loss 5.3287 (4.7057)	grad_norm 2.4870 (2.3973)	mem 5329MB
[2022-04-18 00:33:41 tiny] (main.py 233): INFO EPOCH 19 training takes 0:12:20
[2022-04-18 00:33:53 tiny] (main.py 273): INFO Test: [0/49]	Time 11.835 (11.835)	Loss 2.2675 (2.2675)	Acc@1 52.148 (52.148)	Acc@5 77.344 (77.344)	Mem 5329MB
[2022-04-18 00:34:12 tiny] (main.py 279): INFO  * Acc@1 52.654 Acc@5 77.820
[2022-04-18 00:34:12 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 52.7%
[2022-04-18 00:34:12 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_19.pth saving......
[2022-04-18 00:34:12 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_19.pth saved !!!
[2022-04-18 00:34:12 tiny] (main.py 148): INFO Max accuracy: 52.65%
[2022-04-18 00:34:23 tiny] (main.py 226): INFO Train: [20/300][0/1251]	eta 3:52:21 lr 0.000989	time 11.1444 (11.1444)	loss 4.2147 (4.2147)	grad_norm 2.1973 (2.1973)	mem 5329MB
[2022-04-18 00:35:26 tiny] (main.py 226): INFO Train: [20/300][100/1251]	eta 0:13:59 lr 0.000989	time 0.5321 (0.7291)	loss 4.3911 (4.5787)	grad_norm 2.7867 (2.2447)	mem 5329MB
[2022-04-18 00:36:25 tiny] (main.py 226): INFO Train: [20/300][200/1251]	eta 0:11:31 lr 0.000989	time 0.4937 (0.6580)	loss 4.4884 (4.6382)	grad_norm 1.5957 (2.2717)	mem 5329MB
[2022-04-18 00:37:23 tiny] (main.py 226): INFO Train: [20/300][300/1251]	eta 0:10:02 lr 0.000989	time 0.6506 (0.6336)	loss 3.4658 (4.6577)	grad_norm 2.8170 (2.3785)	mem 5329MB
[2022-04-18 00:38:21 tiny] (main.py 226): INFO Train: [20/300][400/1251]	eta 0:08:48 lr 0.000989	time 0.5037 (0.6211)	loss 5.1252 (4.6526)	grad_norm 2.2362 (2.3765)	mem 5329MB
[2022-04-18 00:39:20 tiny] (main.py 226): INFO Train: [20/300][500/1251]	eta 0:07:41 lr 0.000989	time 0.5839 (0.6143)	loss 4.8497 (4.6420)	grad_norm 2.8004 (2.3856)	mem 5329MB
[2022-04-18 00:40:19 tiny] (main.py 226): INFO Train: [20/300][600/1251]	eta 0:06:37 lr 0.000989	time 0.6138 (0.6102)	loss 4.8452 (4.6384)	grad_norm 1.4510 (2.3691)	mem 5329MB
[2022-04-18 00:41:18 tiny] (main.py 226): INFO Train: [20/300][700/1251]	eta 0:05:34 lr 0.000989	time 0.6661 (0.6069)	loss 5.3242 (4.6355)	grad_norm 5.5121 (2.4019)	mem 5329MB
[2022-04-18 00:42:17 tiny] (main.py 226): INFO Train: [20/300][800/1251]	eta 0:04:32 lr 0.000988	time 0.5722 (0.6052)	loss 4.2382 (4.6348)	grad_norm 2.2225 (2.3784)	mem 5329MB
[2022-04-18 00:43:16 tiny] (main.py 226): INFO Train: [20/300][900/1251]	eta 0:03:31 lr 0.000988	time 0.4793 (0.6030)	loss 5.3199 (4.6304)	grad_norm 1.2890 (2.3814)	mem 5329MB
[2022-04-18 00:44:14 tiny] (main.py 226): INFO Train: [20/300][1000/1251]	eta 0:02:30 lr 0.000988	time 0.5297 (0.6013)	loss 4.9824 (4.6213)	grad_norm 3.0744 (2.3680)	mem 5329MB
[2022-04-18 00:45:13 tiny] (main.py 226): INFO Train: [20/300][1100/1251]	eta 0:01:30 lr 0.000988	time 0.5737 (0.6002)	loss 4.6564 (4.6180)	grad_norm 2.4563 (2.3605)	mem 5329MB
[2022-04-18 00:46:12 tiny] (main.py 226): INFO Train: [20/300][1200/1251]	eta 0:00:30 lr 0.000988	time 0.6502 (0.5990)	loss 4.5683 (4.6191)	grad_norm 3.5923 (2.3450)	mem 5329MB
[2022-04-18 00:46:34 tiny] (main.py 233): INFO EPOCH 20 training takes 0:12:21
[2022-04-18 00:46:46 tiny] (main.py 273): INFO Test: [0/49]	Time 11.650 (11.650)	Loss 2.3153 (2.3153)	Acc@1 52.832 (52.832)	Acc@5 75.781 (75.781)	Mem 5329MB
[2022-04-18 00:47:05 tiny] (main.py 279): INFO  * Acc@1 53.648 Acc@5 78.506
[2022-04-18 00:47:05 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 53.6%
[2022-04-18 00:47:05 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_20.pth saving......
[2022-04-18 00:47:05 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_20.pth saved !!!
[2022-04-18 00:47:05 tiny] (main.py 148): INFO Max accuracy: 53.65%
[2022-04-18 00:47:18 tiny] (main.py 226): INFO Train: [21/300][0/1251]	eta 4:13:11 lr 0.000988	time 12.1432 (12.1432)	loss 4.0913 (4.0913)	grad_norm 2.1744 (2.1744)	mem 5329MB
[2022-04-18 00:48:19 tiny] (main.py 226): INFO Train: [21/300][100/1251]	eta 0:13:58 lr 0.000988	time 0.6073 (0.7283)	loss 4.9492 (4.6962)	grad_norm 3.0731 (2.4643)	mem 5329MB
[2022-04-18 00:49:17 tiny] (main.py 226): INFO Train: [21/300][200/1251]	eta 0:11:29 lr 0.000988	time 0.5623 (0.6562)	loss 4.5401 (4.6884)	grad_norm 1.5298 (2.3826)	mem 5329MB
[2022-04-18 00:50:16 tiny] (main.py 226): INFO Train: [21/300][300/1251]	eta 0:10:02 lr 0.000988	time 0.4890 (0.6333)	loss 4.4542 (4.6758)	grad_norm 2.2398 (2.3535)	mem 5329MB
[2022-04-18 00:51:14 tiny] (main.py 226): INFO Train: [21/300][400/1251]	eta 0:08:48 lr 0.000988	time 0.5248 (0.6210)	loss 4.2272 (4.6577)	grad_norm 2.0167 (2.4109)	mem 5329MB
[2022-04-18 00:52:13 tiny] (main.py 226): INFO Train: [21/300][500/1251]	eta 0:07:40 lr 0.000988	time 0.3948 (0.6138)	loss 5.1180 (4.6579)	grad_norm 2.5600 (2.3983)	mem 5329MB
[2022-04-18 00:53:12 tiny] (main.py 226): INFO Train: [21/300][600/1251]	eta 0:06:36 lr 0.000988	time 0.6253 (0.6098)	loss 5.2462 (4.6660)	grad_norm 2.6421 (inf)	mem 5329MB
[2022-04-18 00:54:11 tiny] (main.py 226): INFO Train: [21/300][700/1251]	eta 0:05:34 lr 0.000987	time 0.7218 (0.6069)	loss 4.0167 (4.6643)	grad_norm 1.6461 (inf)	mem 5329MB
[2022-04-18 00:55:09 tiny] (main.py 226): INFO Train: [21/300][800/1251]	eta 0:04:32 lr 0.000987	time 0.5390 (0.6041)	loss 3.5431 (4.6539)	grad_norm 2.6903 (inf)	mem 5329MB
[2022-04-18 00:56:09 tiny] (main.py 226): INFO Train: [21/300][900/1251]	eta 0:03:31 lr 0.000987	time 0.7799 (0.6028)	loss 4.5358 (4.6648)	grad_norm 3.0205 (inf)	mem 5329MB
[2022-04-18 00:57:07 tiny] (main.py 226): INFO Train: [21/300][1000/1251]	eta 0:02:30 lr 0.000987	time 0.7029 (0.6013)	loss 5.0922 (4.6542)	grad_norm 2.8699 (inf)	mem 5329MB
[2022-04-18 00:58:06 tiny] (main.py 226): INFO Train: [21/300][1100/1251]	eta 0:01:30 lr 0.000987	time 0.4107 (0.6001)	loss 5.3576 (4.6473)	grad_norm 4.0149 (inf)	mem 5329MB
[2022-04-18 00:59:05 tiny] (main.py 226): INFO Train: [21/300][1200/1251]	eta 0:00:30 lr 0.000987	time 0.6022 (0.5992)	loss 4.6362 (4.6442)	grad_norm 2.6287 (inf)	mem 5329MB
[2022-04-18 00:59:27 tiny] (main.py 233): INFO EPOCH 21 training takes 0:12:21
[2022-04-18 00:59:38 tiny] (main.py 273): INFO Test: [0/49]	Time 11.014 (11.014)	Loss 2.2231 (2.2231)	Acc@1 55.078 (55.078)	Acc@5 79.688 (79.688)	Mem 5329MB
[2022-04-18 00:59:58 tiny] (main.py 279): INFO  * Acc@1 54.198 Acc@5 78.638
[2022-04-18 00:59:58 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 54.2%
[2022-04-18 00:59:58 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_21.pth saving......
[2022-04-18 00:59:58 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_21.pth saved !!!
[2022-04-18 00:59:58 tiny] (main.py 148): INFO Max accuracy: 54.20%
[2022-04-18 01:00:10 tiny] (main.py 226): INFO Train: [22/300][0/1251]	eta 4:00:58 lr 0.000987	time 11.5574 (11.5574)	loss 5.4646 (5.4646)	grad_norm 2.4451 (2.4451)	mem 5329MB
[2022-04-18 01:01:12 tiny] (main.py 226): INFO Train: [22/300][100/1251]	eta 0:14:00 lr 0.000987	time 0.7670 (0.7304)	loss 4.8110 (4.5894)	grad_norm 2.9042 (2.2189)	mem 5329MB
[2022-04-18 01:02:10 tiny] (main.py 226): INFO Train: [22/300][200/1251]	eta 0:11:29 lr 0.000987	time 0.5941 (0.6561)	loss 4.6185 (4.5861)	grad_norm 1.2087 (2.2709)	mem 5329MB
[2022-04-18 01:03:09 tiny] (main.py 226): INFO Train: [22/300][300/1251]	eta 0:10:01 lr 0.000987	time 0.5625 (0.6325)	loss 4.5547 (4.5859)	grad_norm 2.0371 (2.2704)	mem 5329MB
[2022-04-18 01:04:08 tiny] (main.py 226): INFO Train: [22/300][400/1251]	eta 0:08:49 lr 0.000987	time 0.5293 (0.6226)	loss 4.8975 (4.5976)	grad_norm 2.4474 (2.2806)	mem 5329MB
[2022-04-18 01:05:07 tiny] (main.py 226): INFO Train: [22/300][500/1251]	eta 0:07:41 lr 0.000986	time 0.5591 (0.6150)	loss 4.8242 (4.5956)	grad_norm 2.8396 (2.2907)	mem 5329MB
[2022-04-18 01:06:05 tiny] (main.py 226): INFO Train: [22/300][600/1251]	eta 0:06:37 lr 0.000986	time 0.6725 (0.6099)	loss 4.5389 (4.5956)	grad_norm 1.8168 (2.2963)	mem 5329MB
[2022-04-18 01:07:04 tiny] (main.py 226): INFO Train: [22/300][700/1251]	eta 0:05:34 lr 0.000986	time 0.8528 (0.6074)	loss 4.9311 (4.5885)	grad_norm 1.3641 (2.3100)	mem 5329MB
[2022-04-18 01:08:03 tiny] (main.py 226): INFO Train: [22/300][800/1251]	eta 0:04:32 lr 0.000986	time 0.5239 (0.6045)	loss 4.9753 (4.5943)	grad_norm 4.0171 (2.3185)	mem 5329MB
[2022-04-18 01:09:01 tiny] (main.py 226): INFO Train: [22/300][900/1251]	eta 0:03:31 lr 0.000986	time 0.4981 (0.6021)	loss 4.8293 (4.5839)	grad_norm 2.6430 (2.3348)	mem 5329MB
[2022-04-18 01:10:00 tiny] (main.py 226): INFO Train: [22/300][1000/1251]	eta 0:02:30 lr 0.000986	time 0.6423 (0.6014)	loss 4.8448 (4.5822)	grad_norm 4.6158 (2.3270)	mem 5329MB
[2022-04-18 01:10:59 tiny] (main.py 226): INFO Train: [22/300][1100/1251]	eta 0:01:30 lr 0.000986	time 0.6337 (0.5998)	loss 5.4091 (4.5904)	grad_norm 2.9472 (2.3291)	mem 5329MB
[2022-04-18 01:11:58 tiny] (main.py 226): INFO Train: [22/300][1200/1251]	eta 0:00:30 lr 0.000986	time 0.7212 (0.5990)	loss 4.6685 (4.5964)	grad_norm 4.3558 (2.3320)	mem 5329MB
[2022-04-18 01:12:20 tiny] (main.py 233): INFO EPOCH 22 training takes 0:12:21
[2022-04-18 01:12:32 tiny] (main.py 273): INFO Test: [0/49]	Time 12.624 (12.624)	Loss 2.2032 (2.2032)	Acc@1 54.492 (54.492)	Acc@5 78.809 (78.809)	Mem 5329MB
[2022-04-18 01:12:51 tiny] (main.py 279): INFO  * Acc@1 54.780 Acc@5 79.288
[2022-04-18 01:12:51 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 54.8%
[2022-04-18 01:12:51 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_22.pth saving......
[2022-04-18 01:12:51 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_22.pth saved !!!
[2022-04-18 01:12:51 tiny] (main.py 148): INFO Max accuracy: 54.78%
[2022-04-18 01:13:03 tiny] (main.py 226): INFO Train: [23/300][0/1251]	eta 4:20:36 lr 0.000986	time 12.4992 (12.4992)	loss 3.4172 (3.4172)	grad_norm 2.0011 (2.0011)	mem 5329MB
[2022-04-18 01:14:05 tiny] (main.py 226): INFO Train: [23/300][100/1251]	eta 0:14:03 lr 0.000986	time 0.5696 (0.7325)	loss 4.3702 (4.5774)	grad_norm 1.8463 (2.3551)	mem 5329MB
[2022-04-18 01:15:03 tiny] (main.py 226): INFO Train: [23/300][200/1251]	eta 0:11:31 lr 0.000986	time 0.5733 (0.6576)	loss 4.6525 (4.5133)	grad_norm 1.5088 (2.3722)	mem 5329MB
[2022-04-18 01:16:02 tiny] (main.py 226): INFO Train: [23/300][300/1251]	eta 0:10:04 lr 0.000985	time 0.6915 (0.6352)	loss 4.1792 (4.5290)	grad_norm 1.6842 (2.3748)	mem 5329MB
[2022-04-18 01:17:01 tiny] (main.py 226): INFO Train: [23/300][400/1251]	eta 0:08:49 lr 0.000985	time 0.7506 (0.6225)	loss 5.0449 (4.5426)	grad_norm 2.8398 (2.3270)	mem 5329MB
[2022-04-18 01:17:59 tiny] (main.py 226): INFO Train: [23/300][500/1251]	eta 0:07:41 lr 0.000985	time 0.4744 (0.6142)	loss 4.6490 (4.5350)	grad_norm 2.9326 (2.3477)	mem 5329MB
[2022-04-18 01:18:58 tiny] (main.py 226): INFO Train: [23/300][600/1251]	eta 0:06:37 lr 0.000985	time 0.5971 (0.6099)	loss 5.4887 (4.5636)	grad_norm 1.5023 (2.3561)	mem 5329MB
[2022-04-18 01:19:56 tiny] (main.py 226): INFO Train: [23/300][700/1251]	eta 0:05:34 lr 0.000985	time 0.8312 (0.6067)	loss 4.7330 (4.5577)	grad_norm 2.3964 (2.3411)	mem 5329MB
[2022-04-18 01:20:55 tiny] (main.py 226): INFO Train: [23/300][800/1251]	eta 0:04:32 lr 0.000985	time 0.6224 (0.6043)	loss 4.8286 (4.5641)	grad_norm 1.8377 (2.3574)	mem 5329MB
[2022-04-18 01:21:54 tiny] (main.py 226): INFO Train: [23/300][900/1251]	eta 0:03:31 lr 0.000985	time 0.6596 (0.6029)	loss 4.6621 (4.5599)	grad_norm 1.8265 (inf)	mem 5329MB
[2022-04-18 01:22:53 tiny] (main.py 226): INFO Train: [23/300][1000/1251]	eta 0:02:30 lr 0.000985	time 0.5590 (0.6014)	loss 3.3611 (4.5593)	grad_norm 1.6764 (inf)	mem 5329MB
[2022-04-18 01:23:52 tiny] (main.py 226): INFO Train: [23/300][1100/1251]	eta 0:01:30 lr 0.000985	time 0.5711 (0.6004)	loss 5.4418 (4.5622)	grad_norm 2.5508 (inf)	mem 5329MB
[2022-04-18 01:24:51 tiny] (main.py 226): INFO Train: [23/300][1200/1251]	eta 0:00:30 lr 0.000985	time 0.8484 (0.5997)	loss 3.6481 (4.5614)	grad_norm 2.6862 (inf)	mem 5329MB
[2022-04-18 01:25:12 tiny] (main.py 233): INFO EPOCH 23 training takes 0:12:21
[2022-04-18 01:25:24 tiny] (main.py 273): INFO Test: [0/49]	Time 11.996 (11.996)	Loss 2.0553 (2.0553)	Acc@1 58.008 (58.008)	Acc@5 80.762 (80.762)	Mem 5329MB
[2022-04-18 01:25:44 tiny] (main.py 279): INFO  * Acc@1 55.744 Acc@5 79.988
[2022-04-18 01:25:44 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 55.7%
[2022-04-18 01:25:44 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_23.pth saving......
[2022-04-18 01:25:44 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_23.pth saved !!!
[2022-04-18 01:25:44 tiny] (main.py 148): INFO Max accuracy: 55.74%
[2022-04-18 01:25:55 tiny] (main.py 226): INFO Train: [24/300][0/1251]	eta 4:00:24 lr 0.000984	time 11.5301 (11.5301)	loss 4.8741 (4.8741)	grad_norm 2.5144 (2.5144)	mem 5329MB
[2022-04-18 01:26:57 tiny] (main.py 226): INFO Train: [24/300][100/1251]	eta 0:13:58 lr 0.000984	time 0.6131 (0.7283)	loss 4.9191 (4.5845)	grad_norm 1.4885 (2.2910)	mem 5329MB
[2022-04-18 01:27:56 tiny] (main.py 226): INFO Train: [24/300][200/1251]	eta 0:11:30 lr 0.000984	time 0.5455 (0.6568)	loss 3.2022 (4.5788)	grad_norm 3.4706 (2.2797)	mem 5329MB
[2022-04-18 01:28:54 tiny] (main.py 226): INFO Train: [24/300][300/1251]	eta 0:10:00 lr 0.000984	time 0.5274 (0.6312)	loss 4.4192 (4.5716)	grad_norm 1.7965 (2.3903)	mem 5329MB
[2022-04-18 01:29:53 tiny] (main.py 226): INFO Train: [24/300][400/1251]	eta 0:08:48 lr 0.000984	time 0.6967 (0.6214)	loss 4.6877 (4.5603)	grad_norm 3.0049 (2.3930)	mem 5329MB
[2022-04-18 01:30:52 tiny] (main.py 226): INFO Train: [24/300][500/1251]	eta 0:07:41 lr 0.000984	time 0.6525 (0.6146)	loss 3.4219 (4.5514)	grad_norm 1.7380 (2.4186)	mem 5329MB
[2022-04-18 01:31:50 tiny] (main.py 226): INFO Train: [24/300][600/1251]	eta 0:06:36 lr 0.000984	time 0.7428 (0.6098)	loss 4.5305 (4.5433)	grad_norm 2.2027 (2.4224)	mem 5329MB
[2022-04-18 01:32:49 tiny] (main.py 226): INFO Train: [24/300][700/1251]	eta 0:05:34 lr 0.000984	time 0.6823 (0.6064)	loss 5.1591 (4.5380)	grad_norm 2.2204 (2.3955)	mem 5329MB
[2022-04-18 01:33:48 tiny] (main.py 226): INFO Train: [24/300][800/1251]	eta 0:04:32 lr 0.000984	time 0.6228 (0.6042)	loss 5.0193 (4.5604)	grad_norm 1.9274 (2.4372)	mem 5329MB
[2022-04-18 01:34:46 tiny] (main.py 226): INFO Train: [24/300][900/1251]	eta 0:03:31 lr 0.000984	time 0.4017 (0.6022)	loss 3.3559 (4.5636)	grad_norm 1.4990 (2.4105)	mem 5329MB
[2022-04-18 01:35:45 tiny] (main.py 226): INFO Train: [24/300][1000/1251]	eta 0:02:30 lr 0.000983	time 0.6721 (0.6007)	loss 5.4882 (4.5554)	grad_norm 1.4759 (2.4019)	mem 5329MB
[2022-04-18 01:36:45 tiny] (main.py 226): INFO Train: [24/300][1100/1251]	eta 0:01:30 lr 0.000983	time 0.6590 (0.6001)	loss 4.8703 (4.5680)	grad_norm 2.3570 (2.3967)	mem 5329MB
[2022-04-18 01:37:44 tiny] (main.py 226): INFO Train: [24/300][1200/1251]	eta 0:00:30 lr 0.000983	time 0.4776 (0.5992)	loss 4.6845 (4.5632)	grad_norm 3.4525 (2.3988)	mem 5329MB
[2022-04-18 01:38:05 tiny] (main.py 233): INFO EPOCH 24 training takes 0:12:21
[2022-04-18 01:38:17 tiny] (main.py 273): INFO Test: [0/49]	Time 12.120 (12.120)	Loss 2.1573 (2.1573)	Acc@1 59.570 (59.570)	Acc@5 80.078 (80.078)	Mem 5329MB
[2022-04-18 01:38:36 tiny] (main.py 279): INFO  * Acc@1 56.004 Acc@5 80.080
[2022-04-18 01:38:36 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 56.0%
[2022-04-18 01:38:36 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_24.pth saving......
[2022-04-18 01:38:36 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_24.pth saved !!!
[2022-04-18 01:38:36 tiny] (main.py 148): INFO Max accuracy: 56.00%
[2022-04-18 01:38:48 tiny] (main.py 226): INFO Train: [25/300][0/1251]	eta 3:56:32 lr 0.000983	time 11.3450 (11.3450)	loss 5.3549 (5.3549)	grad_norm 6.3437 (6.3437)	mem 5329MB
[2022-04-18 01:39:50 tiny] (main.py 226): INFO Train: [25/300][100/1251]	eta 0:13:56 lr 0.000983	time 0.5173 (0.7267)	loss 5.4263 (4.5345)	grad_norm 1.4214 (2.5305)	mem 5329MB
[2022-04-18 01:40:49 tiny] (main.py 226): INFO Train: [25/300][200/1251]	eta 0:11:33 lr 0.000983	time 0.5414 (0.6600)	loss 5.0210 (4.5587)	grad_norm 3.1476 (2.4575)	mem 5329MB
[2022-04-18 01:41:47 tiny] (main.py 226): INFO Train: [25/300][300/1251]	eta 0:10:02 lr 0.000983	time 0.6923 (0.6338)	loss 5.0859 (4.5512)	grad_norm 1.8299 (2.4523)	mem 5329MB
[2022-04-18 01:42:46 tiny] (main.py 226): INFO Train: [25/300][400/1251]	eta 0:08:48 lr 0.000983	time 0.8026 (0.6216)	loss 5.4693 (4.5512)	grad_norm 3.0265 (2.4187)	mem 5329MB
[2022-04-18 01:43:44 tiny] (main.py 226): INFO Train: [25/300][500/1251]	eta 0:07:41 lr 0.000983	time 0.4670 (0.6146)	loss 4.9640 (4.5591)	grad_norm 2.0170 (2.4356)	mem 5329MB
[2022-04-18 01:44:43 tiny] (main.py 226): INFO Train: [25/300][600/1251]	eta 0:06:37 lr 0.000982	time 0.4122 (0.6104)	loss 4.9170 (4.5538)	grad_norm 2.4519 (2.4199)	mem 5329MB
[2022-04-18 01:45:42 tiny] (main.py 226): INFO Train: [25/300][700/1251]	eta 0:05:34 lr 0.000982	time 0.4763 (0.6069)	loss 3.4480 (4.5466)	grad_norm 3.5696 (2.4350)	mem 5329MB
[2022-04-18 01:46:41 tiny] (main.py 226): INFO Train: [25/300][800/1251]	eta 0:04:32 lr 0.000982	time 0.5360 (0.6046)	loss 4.7045 (4.5372)	grad_norm 3.8817 (2.4606)	mem 5329MB
[2022-04-18 01:47:39 tiny] (main.py 226): INFO Train: [25/300][900/1251]	eta 0:03:31 lr 0.000982	time 0.5902 (0.6026)	loss 4.7012 (4.5487)	grad_norm 1.8233 (2.4266)	mem 5329MB
[2022-04-18 01:48:38 tiny] (main.py 226): INFO Train: [25/300][1000/1251]	eta 0:02:30 lr 0.000982	time 0.3929 (0.6012)	loss 3.7615 (4.5502)	grad_norm 2.1759 (2.4322)	mem 5329MB
[2022-04-18 01:49:37 tiny] (main.py 226): INFO Train: [25/300][1100/1251]	eta 0:01:30 lr 0.000982	time 0.5782 (0.6001)	loss 3.8916 (4.5529)	grad_norm 1.8841 (2.4218)	mem 5329MB
[2022-04-18 01:50:36 tiny] (main.py 226): INFO Train: [25/300][1200/1251]	eta 0:00:30 lr 0.000982	time 0.5824 (0.5989)	loss 5.2896 (4.5531)	grad_norm 1.8998 (2.4153)	mem 5329MB
[2022-04-18 01:50:58 tiny] (main.py 233): INFO EPOCH 25 training takes 0:12:21
[2022-04-18 01:51:09 tiny] (main.py 273): INFO Test: [0/49]	Time 11.542 (11.542)	Loss 2.0924 (2.0924)	Acc@1 56.836 (56.836)	Acc@5 81.055 (81.055)	Mem 5329MB
[2022-04-18 01:51:29 tiny] (main.py 279): INFO  * Acc@1 56.504 Acc@5 80.478
[2022-04-18 01:51:29 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 56.5%
[2022-04-18 01:51:29 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_25.pth saving......
[2022-04-18 01:51:29 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_25.pth saved !!!
[2022-04-18 01:51:29 tiny] (main.py 148): INFO Max accuracy: 56.50%
[2022-04-18 01:51:42 tiny] (main.py 226): INFO Train: [26/300][0/1251]	eta 4:18:47 lr 0.000982	time 12.4123 (12.4123)	loss 4.5235 (4.5235)	grad_norm 1.7693 (1.7693)	mem 5329MB
[2022-04-18 01:52:43 tiny] (main.py 226): INFO Train: [26/300][100/1251]	eta 0:13:58 lr 0.000982	time 0.6105 (0.7284)	loss 5.2822 (4.4701)	grad_norm 2.5975 (2.2899)	mem 5329MB
[2022-04-18 01:53:41 tiny] (main.py 226): INFO Train: [26/300][200/1251]	eta 0:11:27 lr 0.000982	time 0.5487 (0.6545)	loss 4.8477 (4.4934)	grad_norm 2.4175 (2.2792)	mem 5329MB
[2022-04-18 01:54:39 tiny] (main.py 226): INFO Train: [26/300][300/1251]	eta 0:10:00 lr 0.000981	time 0.6576 (0.6317)	loss 5.3846 (4.5148)	grad_norm 2.6897 (2.4014)	mem 5329MB
[2022-04-18 01:55:38 tiny] (main.py 226): INFO Train: [26/300][400/1251]	eta 0:08:47 lr 0.000981	time 0.7696 (0.6198)	loss 4.8187 (4.5107)	grad_norm 1.5894 (2.4145)	mem 5329MB
[2022-04-18 01:56:37 tiny] (main.py 226): INFO Train: [26/300][500/1251]	eta 0:07:41 lr 0.000981	time 0.4865 (0.6139)	loss 5.0362 (4.5055)	grad_norm 2.8301 (2.3827)	mem 5329MB
[2022-04-18 01:57:35 tiny] (main.py 226): INFO Train: [26/300][600/1251]	eta 0:06:36 lr 0.000981	time 0.6358 (0.6094)	loss 4.7766 (4.5215)	grad_norm 2.8039 (2.3839)	mem 5329MB
[2022-04-18 01:58:34 tiny] (main.py 226): INFO Train: [26/300][700/1251]	eta 0:05:33 lr 0.000981	time 0.5707 (0.6061)	loss 5.3751 (4.5114)	grad_norm 1.7488 (2.4258)	mem 5329MB
[2022-04-18 01:59:33 tiny] (main.py 226): INFO Train: [26/300][800/1251]	eta 0:04:32 lr 0.000981	time 0.4445 (0.6040)	loss 5.2719 (4.5209)	grad_norm 1.5680 (2.4148)	mem 5329MB
[2022-04-18 02:00:32 tiny] (main.py 226): INFO Train: [26/300][900/1251]	eta 0:03:31 lr 0.000981	time 0.7575 (0.6025)	loss 5.0969 (4.5144)	grad_norm 3.0355 (2.4160)	mem 5329MB
[2022-04-18 02:01:31 tiny] (main.py 226): INFO Train: [26/300][1000/1251]	eta 0:02:30 lr 0.000981	time 0.3731 (0.6010)	loss 4.8950 (4.5220)	grad_norm 2.0032 (2.4030)	mem 5329MB
[2022-04-18 02:02:30 tiny] (main.py 226): INFO Train: [26/300][1100/1251]	eta 0:01:30 lr 0.000981	time 0.5466 (0.6001)	loss 4.7845 (4.5296)	grad_norm 4.1698 (inf)	mem 5329MB
[2022-04-18 02:03:28 tiny] (main.py 226): INFO Train: [26/300][1200/1251]	eta 0:00:30 lr 0.000980	time 0.5224 (0.5989)	loss 4.4511 (4.5155)	grad_norm 1.9008 (inf)	mem 5329MB
[2022-04-18 02:03:51 tiny] (main.py 233): INFO EPOCH 26 training takes 0:12:21
[2022-04-18 02:04:02 tiny] (main.py 273): INFO Test: [0/49]	Time 11.109 (11.109)	Loss 1.9818 (1.9818)	Acc@1 58.691 (58.691)	Acc@5 82.617 (82.617)	Mem 5329MB
[2022-04-18 02:04:22 tiny] (main.py 279): INFO  * Acc@1 57.192 Acc@5 80.874
[2022-04-18 02:04:22 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 57.2%
[2022-04-18 02:04:22 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_26.pth saving......
[2022-04-18 02:04:22 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_26.pth saved !!!
[2022-04-18 02:04:22 tiny] (main.py 148): INFO Max accuracy: 57.19%
[2022-04-18 02:04:33 tiny] (main.py 226): INFO Train: [27/300][0/1251]	eta 3:52:15 lr 0.000980	time 11.1398 (11.1398)	loss 4.8136 (4.8136)	grad_norm 2.2000 (2.2000)	mem 5329MB
[2022-04-18 02:05:36 tiny] (main.py 226): INFO Train: [27/300][100/1251]	eta 0:14:00 lr 0.000980	time 0.5440 (0.7306)	loss 4.8952 (4.5509)	grad_norm 1.8699 (inf)	mem 5329MB
[2022-04-18 02:06:34 tiny] (main.py 226): INFO Train: [27/300][200/1251]	eta 0:11:30 lr 0.000980	time 0.4217 (0.6574)	loss 4.8323 (4.4736)	grad_norm 1.9760 (inf)	mem 5329MB
[2022-04-18 02:07:32 tiny] (main.py 226): INFO Train: [27/300][300/1251]	eta 0:10:01 lr 0.000980	time 0.6802 (0.6320)	loss 4.1745 (4.4720)	grad_norm 2.3111 (inf)	mem 5329MB
[2022-04-18 02:08:31 tiny] (main.py 226): INFO Train: [27/300][400/1251]	eta 0:08:48 lr 0.000980	time 0.5408 (0.6210)	loss 3.9664 (4.4579)	grad_norm 1.5167 (inf)	mem 5329MB
[2022-04-18 02:09:29 tiny] (main.py 226): INFO Train: [27/300][500/1251]	eta 0:07:40 lr 0.000980	time 0.6395 (0.6137)	loss 4.5488 (4.4481)	grad_norm 1.7550 (inf)	mem 5329MB
[2022-04-18 02:10:29 tiny] (main.py 226): INFO Train: [27/300][600/1251]	eta 0:06:37 lr 0.000980	time 0.6158 (0.6101)	loss 4.7511 (4.4639)	grad_norm 1.9032 (inf)	mem 5329MB
[2022-04-18 02:11:27 tiny] (main.py 226): INFO Train: [27/300][700/1251]	eta 0:05:34 lr 0.000980	time 0.5529 (0.6062)	loss 4.0789 (4.4635)	grad_norm 1.9781 (inf)	mem 5329MB
[2022-04-18 02:12:26 tiny] (main.py 226): INFO Train: [27/300][800/1251]	eta 0:04:32 lr 0.000979	time 0.6080 (0.6039)	loss 4.3310 (4.4683)	grad_norm 1.9678 (inf)	mem 5329MB
[2022-04-18 02:13:25 tiny] (main.py 226): INFO Train: [27/300][900/1251]	eta 0:03:31 lr 0.000979	time 0.6001 (0.6023)	loss 3.6523 (4.4575)	grad_norm 1.5871 (inf)	mem 5329MB
[2022-04-18 02:14:23 tiny] (main.py 226): INFO Train: [27/300][1000/1251]	eta 0:02:30 lr 0.000979	time 0.4253 (0.6008)	loss 5.2262 (4.4744)	grad_norm 2.1347 (inf)	mem 5329MB
[2022-04-18 02:15:22 tiny] (main.py 226): INFO Train: [27/300][1100/1251]	eta 0:01:30 lr 0.000979	time 0.7294 (0.5997)	loss 4.0059 (4.4772)	grad_norm 3.0316 (inf)	mem 5329MB
[2022-04-18 02:16:21 tiny] (main.py 226): INFO Train: [27/300][1200/1251]	eta 0:00:30 lr 0.000979	time 0.5475 (0.5991)	loss 3.7477 (4.4804)	grad_norm 4.1750 (inf)	mem 5329MB
[2022-04-18 02:16:43 tiny] (main.py 233): INFO EPOCH 27 training takes 0:12:20
[2022-04-18 02:16:55 tiny] (main.py 273): INFO Test: [0/49]	Time 11.886 (11.886)	Loss 2.1125 (2.1125)	Acc@1 55.664 (55.664)	Acc@5 82.617 (82.617)	Mem 5329MB
[2022-04-18 02:17:14 tiny] (main.py 279): INFO  * Acc@1 57.008 Acc@5 80.960
[2022-04-18 02:17:14 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 57.0%
[2022-04-18 02:17:14 tiny] (main.py 148): INFO Max accuracy: 57.19%
[2022-04-18 02:17:26 tiny] (main.py 226): INFO Train: [28/300][0/1251]	eta 3:59:34 lr 0.000979	time 11.4906 (11.4906)	loss 4.8101 (4.8101)	grad_norm 3.7240 (3.7240)	mem 5329MB
[2022-04-18 02:18:28 tiny] (main.py 226): INFO Train: [28/300][100/1251]	eta 0:14:00 lr 0.000979	time 0.5048 (0.7299)	loss 5.2144 (4.4867)	grad_norm 1.9774 (2.4262)	mem 5329MB
[2022-04-18 02:19:26 tiny] (main.py 226): INFO Train: [28/300][200/1251]	eta 0:11:32 lr 0.000979	time 0.5774 (0.6588)	loss 4.1497 (4.5598)	grad_norm 3.2776 (2.5195)	mem 5329MB
[2022-04-18 02:20:25 tiny] (main.py 226): INFO Train: [28/300][300/1251]	eta 0:10:02 lr 0.000979	time 0.6641 (0.6336)	loss 3.5637 (4.5197)	grad_norm 2.0334 (2.4985)	mem 5329MB
[2022-04-18 02:21:23 tiny] (main.py 226): INFO Train: [28/300][400/1251]	eta 0:08:48 lr 0.000978	time 0.5472 (0.6205)	loss 3.6709 (4.4735)	grad_norm 2.5504 (2.4853)	mem 5329MB
[2022-04-18 02:22:22 tiny] (main.py 226): INFO Train: [28/300][500/1251]	eta 0:07:41 lr 0.000978	time 0.4492 (0.6140)	loss 4.0697 (4.4765)	grad_norm 1.7585 (2.4396)	mem 5329MB
[2022-04-18 02:23:21 tiny] (main.py 226): INFO Train: [28/300][600/1251]	eta 0:06:37 lr 0.000978	time 0.5340 (0.6107)	loss 4.8653 (4.4904)	grad_norm 1.6364 (2.4433)	mem 5329MB
[2022-04-18 02:24:19 tiny] (main.py 226): INFO Train: [28/300][700/1251]	eta 0:05:34 lr 0.000978	time 0.5366 (0.6070)	loss 4.6252 (4.4709)	grad_norm 2.0834 (2.4355)	mem 5329MB
[2022-04-18 02:25:18 tiny] (main.py 226): INFO Train: [28/300][800/1251]	eta 0:04:32 lr 0.000978	time 0.6205 (0.6043)	loss 4.6847 (4.4655)	grad_norm 1.6429 (2.4410)	mem 5329MB
[2022-04-18 02:26:17 tiny] (main.py 226): INFO Train: [28/300][900/1251]	eta 0:03:31 lr 0.000978	time 0.8963 (0.6029)	loss 4.9353 (4.4527)	grad_norm 5.0074 (2.4721)	mem 5329MB
[2022-04-18 02:27:16 tiny] (main.py 226): INFO Train: [28/300][1000/1251]	eta 0:02:30 lr 0.000978	time 0.3933 (0.6010)	loss 4.0640 (4.4439)	grad_norm 1.3892 (2.4569)	mem 5329MB
[2022-04-18 02:28:14 tiny] (main.py 226): INFO Train: [28/300][1100/1251]	eta 0:01:30 lr 0.000978	time 0.5238 (0.5998)	loss 4.6205 (4.4390)	grad_norm 2.3106 (2.4550)	mem 5329MB
[2022-04-18 02:29:13 tiny] (main.py 226): INFO Train: [28/300][1200/1251]	eta 0:00:30 lr 0.000977	time 0.9890 (0.5988)	loss 4.7017 (4.4403)	grad_norm 1.2825 (2.4496)	mem 5329MB
[2022-04-18 02:29:35 tiny] (main.py 233): INFO EPOCH 28 training takes 0:12:21
[2022-04-18 02:29:47 tiny] (main.py 273): INFO Test: [0/49]	Time 11.340 (11.340)	Loss 2.1355 (2.1355)	Acc@1 55.469 (55.469)	Acc@5 80.273 (80.273)	Mem 5329MB
[2022-04-18 02:30:06 tiny] (main.py 279): INFO  * Acc@1 57.466 Acc@5 81.238
[2022-04-18 02:30:06 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 57.5%
[2022-04-18 02:30:06 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_28.pth saving......
[2022-04-18 02:30:06 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_28.pth saved !!!
[2022-04-18 02:30:06 tiny] (main.py 148): INFO Max accuracy: 57.47%
[2022-04-18 02:30:18 tiny] (main.py 226): INFO Train: [29/300][0/1251]	eta 4:03:04 lr 0.000977	time 11.6579 (11.6579)	loss 4.8187 (4.8187)	grad_norm 2.4783 (2.4783)	mem 5329MB
[2022-04-18 02:31:20 tiny] (main.py 226): INFO Train: [29/300][100/1251]	eta 0:13:56 lr 0.000977	time 0.6092 (0.7269)	loss 5.1138 (4.3660)	grad_norm 2.0849 (2.4468)	mem 5329MB
[2022-04-18 02:32:18 tiny] (main.py 226): INFO Train: [29/300][200/1251]	eta 0:11:28 lr 0.000977	time 0.5581 (0.6553)	loss 3.7239 (4.3795)	grad_norm 2.6579 (2.3580)	mem 5329MB
[2022-04-18 02:33:17 tiny] (main.py 226): INFO Train: [29/300][300/1251]	eta 0:10:02 lr 0.000977	time 0.7457 (0.6332)	loss 4.5663 (4.4029)	grad_norm 2.3072 (2.4304)	mem 5329MB
[2022-04-18 02:34:15 tiny] (main.py 226): INFO Train: [29/300][400/1251]	eta 0:08:48 lr 0.000977	time 0.6436 (0.6214)	loss 4.2776 (4.4209)	grad_norm 3.8348 (2.4437)	mem 5329MB
[2022-04-18 02:35:14 tiny] (main.py 226): INFO Train: [29/300][500/1251]	eta 0:07:41 lr 0.000977	time 0.4955 (0.6140)	loss 3.7719 (4.4226)	grad_norm 5.2916 (2.4212)	mem 5329MB
[2022-04-18 02:36:12 tiny] (main.py 226): INFO Train: [29/300][600/1251]	eta 0:06:36 lr 0.000977	time 0.3628 (0.6090)	loss 4.3638 (4.4172)	grad_norm 1.8266 (2.4379)	mem 5329MB
[2022-04-18 02:37:12 tiny] (main.py 226): INFO Train: [29/300][700/1251]	eta 0:05:34 lr 0.000976	time 0.5838 (0.6070)	loss 5.2336 (4.4302)	grad_norm 5.5571 (2.4625)	mem 5329MB
[2022-04-18 02:38:11 tiny] (main.py 226): INFO Train: [29/300][800/1251]	eta 0:04:32 lr 0.000976	time 0.7224 (0.6047)	loss 4.8360 (4.4324)	grad_norm 2.4547 (2.4685)	mem 5329MB
[2022-04-18 02:39:09 tiny] (main.py 226): INFO Train: [29/300][900/1251]	eta 0:03:31 lr 0.000976	time 0.6398 (0.6027)	loss 4.9299 (4.4353)	grad_norm 3.2930 (2.4715)	mem 5329MB
[2022-04-18 02:40:08 tiny] (main.py 226): INFO Train: [29/300][1000/1251]	eta 0:02:30 lr 0.000976	time 0.6833 (0.6013)	loss 5.3207 (4.4303)	grad_norm 2.1519 (2.4733)	mem 5329MB
[2022-04-18 02:41:07 tiny] (main.py 226): INFO Train: [29/300][1100/1251]	eta 0:01:30 lr 0.000976	time 0.6931 (0.5998)	loss 4.0095 (4.4355)	grad_norm 2.4416 (2.4708)	mem 5329MB
[2022-04-18 02:42:06 tiny] (main.py 226): INFO Train: [29/300][1200/1251]	eta 0:00:30 lr 0.000976	time 0.5787 (0.5991)	loss 5.1161 (4.4365)	grad_norm 3.0056 (2.4690)	mem 5329MB
[2022-04-18 02:42:27 tiny] (main.py 233): INFO EPOCH 29 training takes 0:12:21
[2022-04-18 02:42:38 tiny] (main.py 273): INFO Test: [0/49]	Time 10.388 (10.388)	Loss 2.0612 (2.0612)	Acc@1 58.301 (58.301)	Acc@5 81.836 (81.836)	Mem 5329MB
[2022-04-18 02:42:59 tiny] (main.py 279): INFO  * Acc@1 58.188 Acc@5 82.000
[2022-04-18 02:42:59 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 58.2%
[2022-04-18 02:42:59 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_29.pth saving......
[2022-04-18 02:42:59 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_29.pth saved !!!
[2022-04-18 02:42:59 tiny] (main.py 148): INFO Max accuracy: 58.19%
[2022-04-18 02:43:10 tiny] (main.py 226): INFO Train: [30/300][0/1251]	eta 4:03:47 lr 0.000976	time 11.6924 (11.6924)	loss 4.9366 (4.9366)	grad_norm 2.6055 (2.6055)	mem 5329MB
[2022-04-18 02:44:12 tiny] (main.py 226): INFO Train: [30/300][100/1251]	eta 0:13:54 lr 0.000976	time 0.5495 (0.7248)	loss 3.3611 (4.4032)	grad_norm 1.7646 (2.3455)	mem 5329MB
[2022-04-18 02:45:11 tiny] (main.py 226): INFO Train: [30/300][200/1251]	eta 0:11:29 lr 0.000976	time 0.5124 (0.6558)	loss 4.9496 (4.4621)	grad_norm 2.5748 (2.3214)	mem 5329MB
[2022-04-18 02:46:09 tiny] (main.py 226): INFO Train: [30/300][300/1251]	eta 0:10:01 lr 0.000975	time 0.6114 (0.6328)	loss 4.3587 (4.4133)	grad_norm 2.1001 (2.3859)	mem 5329MB
[2022-04-18 02:47:08 tiny] (main.py 226): INFO Train: [30/300][400/1251]	eta 0:08:48 lr 0.000975	time 0.5938 (0.6214)	loss 4.4630 (4.4324)	grad_norm 2.4820 (inf)	mem 5329MB
[2022-04-18 02:48:06 tiny] (main.py 226): INFO Train: [30/300][500/1251]	eta 0:07:40 lr 0.000975	time 0.5018 (0.6138)	loss 3.1456 (4.4137)	grad_norm 2.4822 (inf)	mem 5329MB
[2022-04-18 02:49:05 tiny] (main.py 226): INFO Train: [30/300][600/1251]	eta 0:06:36 lr 0.000975	time 0.5517 (0.6096)	loss 3.2581 (4.4226)	grad_norm 1.8331 (inf)	mem 5329MB
[2022-04-18 02:50:04 tiny] (main.py 226): INFO Train: [30/300][700/1251]	eta 0:05:34 lr 0.000975	time 0.7798 (0.6065)	loss 4.1230 (4.4265)	grad_norm 3.6007 (inf)	mem 5329MB
[2022-04-18 02:51:02 tiny] (main.py 226): INFO Train: [30/300][800/1251]	eta 0:04:32 lr 0.000975	time 0.5532 (0.6038)	loss 4.6641 (4.4271)	grad_norm 2.7813 (inf)	mem 5329MB
[2022-04-18 02:52:02 tiny] (main.py 226): INFO Train: [30/300][900/1251]	eta 0:03:31 lr 0.000975	time 0.7150 (0.6028)	loss 3.7925 (4.4252)	grad_norm 1.9811 (inf)	mem 5329MB
[2022-04-18 02:53:01 tiny] (main.py 226): INFO Train: [30/300][1000/1251]	eta 0:02:31 lr 0.000974	time 0.5316 (0.6017)	loss 4.6493 (4.4243)	grad_norm 2.6094 (inf)	mem 5329MB
[2022-04-18 02:54:00 tiny] (main.py 226): INFO Train: [30/300][1100/1251]	eta 0:01:30 lr 0.000974	time 0.4975 (0.6003)	loss 4.3924 (4.4168)	grad_norm 2.6276 (inf)	mem 5329MB
[2022-04-18 02:54:58 tiny] (main.py 226): INFO Train: [30/300][1200/1251]	eta 0:00:30 lr 0.000974	time 0.5333 (0.5989)	loss 4.9259 (4.4164)	grad_norm 1.4720 (inf)	mem 5329MB
[2022-04-18 02:55:20 tiny] (main.py 233): INFO EPOCH 30 training takes 0:12:21
[2022-04-18 02:55:32 tiny] (main.py 273): INFO Test: [0/49]	Time 11.747 (11.747)	Loss 2.1214 (2.1214)	Acc@1 56.934 (56.934)	Acc@5 80.566 (80.566)	Mem 5329MB
[2022-04-18 02:55:51 tiny] (main.py 279): INFO  * Acc@1 57.998 Acc@5 81.748
[2022-04-18 02:55:51 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 58.0%
[2022-04-18 02:55:51 tiny] (main.py 148): INFO Max accuracy: 58.19%
[2022-04-18 02:56:03 tiny] (main.py 226): INFO Train: [31/300][0/1251]	eta 4:02:52 lr 0.000974	time 11.6485 (11.6485)	loss 3.2760 (3.2760)	grad_norm 3.1469 (3.1469)	mem 5329MB
[2022-04-18 02:57:05 tiny] (main.py 226): INFO Train: [31/300][100/1251]	eta 0:13:57 lr 0.000974	time 0.6718 (0.7279)	loss 4.8215 (4.3094)	grad_norm 2.2756 (2.6405)	mem 5329MB
[2022-04-18 02:58:03 tiny] (main.py 226): INFO Train: [31/300][200/1251]	eta 0:11:30 lr 0.000974	time 0.8427 (0.6565)	loss 4.5159 (4.3851)	grad_norm 2.1368 (2.5822)	mem 5329MB
[2022-04-18 02:59:01 tiny] (main.py 226): INFO Train: [31/300][300/1251]	eta 0:10:01 lr 0.000974	time 0.5442 (0.6320)	loss 4.1487 (4.4056)	grad_norm 4.1687 (2.5904)	mem 5329MB
[2022-04-18 03:00:00 tiny] (main.py 226): INFO Train: [31/300][400/1251]	eta 0:08:48 lr 0.000974	time 0.6110 (0.6214)	loss 4.1779 (4.4139)	grad_norm 4.3645 (2.5727)	mem 5329MB
[2022-04-18 03:00:58 tiny] (main.py 226): INFO Train: [31/300][500/1251]	eta 0:07:40 lr 0.000973	time 0.3906 (0.6130)	loss 3.9438 (4.4140)	grad_norm 2.2919 (2.5591)	mem 5329MB
[2022-04-18 03:01:57 tiny] (main.py 226): INFO Train: [31/300][600/1251]	eta 0:06:36 lr 0.000973	time 0.5986 (0.6089)	loss 4.6511 (4.4058)	grad_norm 2.0209 (2.5543)	mem 5329MB
[2022-04-18 03:02:56 tiny] (main.py 226): INFO Train: [31/300][700/1251]	eta 0:05:33 lr 0.000973	time 0.6266 (0.6061)	loss 5.1243 (4.4182)	grad_norm 1.8487 (2.5677)	mem 5329MB
[2022-04-18 03:03:54 tiny] (main.py 226): INFO Train: [31/300][800/1251]	eta 0:04:32 lr 0.000973	time 0.5269 (0.6035)	loss 4.3745 (4.4209)	grad_norm 2.7929 (2.5681)	mem 5329MB
[2022-04-18 03:04:53 tiny] (main.py 226): INFO Train: [31/300][900/1251]	eta 0:03:31 lr 0.000973	time 0.6553 (0.6021)	loss 4.8426 (4.4280)	grad_norm 2.2895 (2.5642)	mem 5329MB
[2022-04-18 03:05:52 tiny] (main.py 226): INFO Train: [31/300][1000/1251]	eta 0:02:30 lr 0.000973	time 0.5817 (0.6006)	loss 4.6508 (4.4305)	grad_norm 3.2648 (2.5529)	mem 5329MB
[2022-04-18 03:06:51 tiny] (main.py 226): INFO Train: [31/300][1100/1251]	eta 0:01:30 lr 0.000973	time 0.6314 (0.5994)	loss 3.0966 (4.4269)	grad_norm 1.9039 (2.5663)	mem 5329MB
[2022-04-18 03:07:50 tiny] (main.py 226): INFO Train: [31/300][1200/1251]	eta 0:00:30 lr 0.000973	time 0.6005 (0.5987)	loss 4.8246 (4.4241)	grad_norm 2.6281 (2.5533)	mem 5329MB
[2022-04-18 03:08:12 tiny] (main.py 233): INFO EPOCH 31 training takes 0:12:20
[2022-04-18 03:08:24 tiny] (main.py 273): INFO Test: [0/49]	Time 12.610 (12.610)	Loss 1.9581 (1.9581)	Acc@1 59.375 (59.375)	Acc@5 84.961 (84.961)	Mem 5329MB
[2022-04-18 03:08:43 tiny] (main.py 279): INFO  * Acc@1 58.190 Acc@5 81.830
[2022-04-18 03:08:43 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 58.2%
[2022-04-18 03:08:43 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_31.pth saving......
[2022-04-18 03:08:43 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_31.pth saved !!!
[2022-04-18 03:08:43 tiny] (main.py 148): INFO Max accuracy: 58.19%
[2022-04-18 03:08:54 tiny] (main.py 226): INFO Train: [32/300][0/1251]	eta 3:57:36 lr 0.000972	time 11.3964 (11.3964)	loss 4.3073 (4.3073)	grad_norm 1.6662 (1.6662)	mem 5329MB
[2022-04-18 03:09:56 tiny] (main.py 226): INFO Train: [32/300][100/1251]	eta 0:13:54 lr 0.000972	time 0.6738 (0.7253)	loss 4.3883 (4.3698)	grad_norm 1.5744 (2.5160)	mem 5329MB
[2022-04-18 03:10:55 tiny] (main.py 226): INFO Train: [32/300][200/1251]	eta 0:11:30 lr 0.000972	time 0.6334 (0.6569)	loss 4.2766 (4.3953)	grad_norm 3.9633 (2.5838)	mem 5329MB
[2022-04-18 03:11:53 tiny] (main.py 226): INFO Train: [32/300][300/1251]	eta 0:10:02 lr 0.000972	time 0.6198 (0.6331)	loss 4.6040 (4.4303)	grad_norm 1.8982 (2.5922)	mem 5329MB
[2022-04-18 03:12:52 tiny] (main.py 226): INFO Train: [32/300][400/1251]	eta 0:08:48 lr 0.000972	time 0.6046 (0.6215)	loss 3.4617 (4.4114)	grad_norm 1.8027 (2.5199)	mem 5329MB
[2022-04-18 03:13:51 tiny] (main.py 226): INFO Train: [32/300][500/1251]	eta 0:07:41 lr 0.000972	time 0.6062 (0.6143)	loss 4.2807 (4.4384)	grad_norm 2.3171 (2.5265)	mem 5329MB
[2022-04-18 03:14:49 tiny] (main.py 226): INFO Train: [32/300][600/1251]	eta 0:06:36 lr 0.000972	time 0.5423 (0.6091)	loss 3.1363 (4.4175)	grad_norm 2.0923 (2.5240)	mem 5329MB
[2022-04-18 03:15:48 tiny] (main.py 226): INFO Train: [32/300][700/1251]	eta 0:05:33 lr 0.000972	time 0.4635 (0.6061)	loss 4.4097 (4.4159)	grad_norm 1.7299 (2.5417)	mem 5329MB
[2022-04-18 03:16:47 tiny] (main.py 226): INFO Train: [32/300][800/1251]	eta 0:04:32 lr 0.000971	time 0.4850 (0.6045)	loss 4.2254 (4.4011)	grad_norm 1.5626 (2.5304)	mem 5329MB
[2022-04-18 03:17:46 tiny] (main.py 226): INFO Train: [32/300][900/1251]	eta 0:03:31 lr 0.000971	time 0.5991 (0.6024)	loss 4.8952 (4.3967)	grad_norm 2.8393 (2.5250)	mem 5329MB
[2022-04-18 03:18:44 tiny] (main.py 226): INFO Train: [32/300][1000/1251]	eta 0:02:30 lr 0.000971	time 0.5012 (0.6009)	loss 4.4219 (4.3975)	grad_norm 1.6477 (2.5024)	mem 5329MB
[2022-04-18 03:19:43 tiny] (main.py 226): INFO Train: [32/300][1100/1251]	eta 0:01:30 lr 0.000971	time 0.5538 (0.5999)	loss 4.5738 (4.4073)	grad_norm 2.2649 (2.5128)	mem 5329MB
[2022-04-18 03:20:42 tiny] (main.py 226): INFO Train: [32/300][1200/1251]	eta 0:00:30 lr 0.000971	time 0.5866 (0.5990)	loss 5.1290 (4.4098)	grad_norm 2.7139 (2.5220)	mem 5329MB
[2022-04-18 03:21:04 tiny] (main.py 233): INFO EPOCH 32 training takes 0:12:20
[2022-04-18 03:21:16 tiny] (main.py 273): INFO Test: [0/49]	Time 12.140 (12.140)	Loss 2.0684 (2.0684)	Acc@1 57.227 (57.227)	Acc@5 81.641 (81.641)	Mem 5329MB
[2022-04-18 03:21:35 tiny] (main.py 279): INFO  * Acc@1 58.288 Acc@5 82.226
[2022-04-18 03:21:35 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 58.3%
[2022-04-18 03:21:35 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_32.pth saving......
[2022-04-18 03:21:35 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_32.pth saved !!!
[2022-04-18 03:21:35 tiny] (main.py 148): INFO Max accuracy: 58.29%
[2022-04-18 03:21:46 tiny] (main.py 226): INFO Train: [33/300][0/1251]	eta 3:57:00 lr 0.000971	time 11.3671 (11.3671)	loss 4.8237 (4.8237)	grad_norm 1.2613 (1.2613)	mem 5329MB
[2022-04-18 03:22:48 tiny] (main.py 226): INFO Train: [33/300][100/1251]	eta 0:13:57 lr 0.000971	time 0.5541 (0.7277)	loss 4.5025 (4.4052)	grad_norm 1.3477 (2.5411)	mem 5329MB
[2022-04-18 03:23:47 tiny] (main.py 226): INFO Train: [33/300][200/1251]	eta 0:11:29 lr 0.000970	time 0.4555 (0.6563)	loss 3.3670 (4.3652)	grad_norm 2.1186 (2.4418)	mem 5329MB
[2022-04-18 03:24:45 tiny] (main.py 226): INFO Train: [33/300][300/1251]	eta 0:10:01 lr 0.000970	time 0.7291 (0.6324)	loss 4.5853 (4.3772)	grad_norm 2.1864 (2.4659)	mem 5329MB
[2022-04-18 03:25:44 tiny] (main.py 226): INFO Train: [33/300][400/1251]	eta 0:08:48 lr 0.000970	time 0.5711 (0.6207)	loss 3.8427 (4.3608)	grad_norm 5.2545 (2.5181)	mem 5329MB
[2022-04-18 03:26:43 tiny] (main.py 226): INFO Train: [33/300][500/1251]	eta 0:07:41 lr 0.000970	time 0.6194 (0.6145)	loss 4.6960 (4.3484)	grad_norm 3.4418 (2.5263)	mem 5329MB
[2022-04-18 03:27:41 tiny] (main.py 226): INFO Train: [33/300][600/1251]	eta 0:06:36 lr 0.000970	time 0.7615 (0.6097)	loss 3.8655 (4.3421)	grad_norm 2.5647 (2.4901)	mem 5329MB
[2022-04-18 03:28:40 tiny] (main.py 226): INFO Train: [33/300][700/1251]	eta 0:05:34 lr 0.000970	time 0.4826 (0.6064)	loss 5.1657 (4.3604)	grad_norm 2.3115 (inf)	mem 5329MB
[2022-04-18 03:29:39 tiny] (main.py 226): INFO Train: [33/300][800/1251]	eta 0:04:32 lr 0.000970	time 0.6358 (0.6047)	loss 3.6207 (4.3707)	grad_norm 3.0752 (inf)	mem 5329MB
[2022-04-18 03:30:38 tiny] (main.py 226): INFO Train: [33/300][900/1251]	eta 0:03:31 lr 0.000969	time 0.6028 (0.6027)	loss 3.4411 (4.3738)	grad_norm 2.0325 (inf)	mem 5329MB
[2022-04-18 03:31:37 tiny] (main.py 226): INFO Train: [33/300][1000/1251]	eta 0:02:30 lr 0.000969	time 0.4549 (0.6011)	loss 4.6945 (4.3797)	grad_norm 2.0341 (inf)	mem 5329MB
[2022-04-18 03:32:36 tiny] (main.py 226): INFO Train: [33/300][1100/1251]	eta 0:01:30 lr 0.000969	time 0.6162 (0.6001)	loss 4.3279 (4.3814)	grad_norm 2.2266 (inf)	mem 5329MB
[2022-04-18 03:33:35 tiny] (main.py 226): INFO Train: [33/300][1200/1251]	eta 0:00:30 lr 0.000969	time 0.7025 (0.5992)	loss 4.9630 (4.3851)	grad_norm 1.9340 (inf)	mem 5329MB
[2022-04-18 03:33:56 tiny] (main.py 233): INFO EPOCH 33 training takes 0:12:21
[2022-04-18 03:34:10 tiny] (main.py 273): INFO Test: [0/49]	Time 13.637 (13.637)	Loss 1.9669 (1.9669)	Acc@1 59.961 (59.961)	Acc@5 82.324 (82.324)	Mem 5329MB
[2022-04-18 03:34:28 tiny] (main.py 279): INFO  * Acc@1 59.062 Acc@5 82.564
[2022-04-18 03:34:28 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 59.1%
[2022-04-18 03:34:28 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_33.pth saving......
[2022-04-18 03:34:28 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_33.pth saved !!!
[2022-04-18 03:34:28 tiny] (main.py 148): INFO Max accuracy: 59.06%
[2022-04-18 03:34:39 tiny] (main.py 226): INFO Train: [34/300][0/1251]	eta 4:04:34 lr 0.000969	time 11.7299 (11.7299)	loss 4.5154 (4.5154)	grad_norm 2.7289 (2.7289)	mem 5329MB
[2022-04-18 03:35:41 tiny] (main.py 226): INFO Train: [34/300][100/1251]	eta 0:13:57 lr 0.000969	time 0.7533 (0.7277)	loss 4.9974 (4.2906)	grad_norm 3.2361 (2.5621)	mem 5329MB
[2022-04-18 03:36:40 tiny] (main.py 226): INFO Train: [34/300][200/1251]	eta 0:11:31 lr 0.000969	time 0.5187 (0.6576)	loss 4.6410 (4.3189)	grad_norm 3.6262 (2.6478)	mem 5329MB
[2022-04-18 03:37:39 tiny] (main.py 226): INFO Train: [34/300][300/1251]	eta 0:10:03 lr 0.000969	time 0.4671 (0.6348)	loss 4.4808 (4.3341)	grad_norm 1.9633 (2.5534)	mem 5329MB
[2022-04-18 03:38:37 tiny] (main.py 226): INFO Train: [34/300][400/1251]	eta 0:08:49 lr 0.000968	time 0.5001 (0.6223)	loss 3.5668 (4.3389)	grad_norm 2.7258 (2.5883)	mem 5329MB
[2022-04-18 03:39:36 tiny] (main.py 226): INFO Train: [34/300][500/1251]	eta 0:07:42 lr 0.000968	time 0.7218 (0.6154)	loss 4.7139 (4.3357)	grad_norm 2.5679 (2.5727)	mem 5329MB
[2022-04-18 03:40:35 tiny] (main.py 226): INFO Train: [34/300][600/1251]	eta 0:06:37 lr 0.000968	time 0.6291 (0.6104)	loss 3.6865 (4.3486)	grad_norm 4.0624 (2.5643)	mem 5329MB
[2022-04-18 03:41:34 tiny] (main.py 226): INFO Train: [34/300][700/1251]	eta 0:05:34 lr 0.000968	time 0.4829 (0.6074)	loss 4.7200 (4.3621)	grad_norm 3.0030 (2.5646)	mem 5329MB
[2022-04-18 03:42:32 tiny] (main.py 226): INFO Train: [34/300][800/1251]	eta 0:04:32 lr 0.000968	time 0.8666 (0.6052)	loss 4.4775 (4.3747)	grad_norm 4.1057 (2.5657)	mem 5329MB
[2022-04-18 03:43:31 tiny] (main.py 226): INFO Train: [34/300][900/1251]	eta 0:03:31 lr 0.000968	time 0.7077 (0.6029)	loss 4.6088 (4.3792)	grad_norm 2.6569 (2.5743)	mem 5329MB
[2022-04-18 03:44:30 tiny] (main.py 226): INFO Train: [34/300][1000/1251]	eta 0:02:30 lr 0.000967	time 0.8418 (0.6016)	loss 4.8435 (4.3739)	grad_norm 2.3345 (2.5565)	mem 5329MB
[2022-04-18 03:45:28 tiny] (main.py 226): INFO Train: [34/300][1100/1251]	eta 0:01:30 lr 0.000967	time 0.6985 (0.5999)	loss 4.0120 (4.3699)	grad_norm 3.8061 (2.5516)	mem 5329MB
[2022-04-18 03:46:27 tiny] (main.py 226): INFO Train: [34/300][1200/1251]	eta 0:00:30 lr 0.000967	time 0.7234 (0.5992)	loss 5.2158 (4.3726)	grad_norm 1.8068 (2.5657)	mem 5329MB
[2022-04-18 03:46:49 tiny] (main.py 233): INFO EPOCH 34 training takes 0:12:21
[2022-04-18 03:47:01 tiny] (main.py 273): INFO Test: [0/49]	Time 11.618 (11.618)	Loss 1.9871 (1.9871)	Acc@1 60.547 (60.547)	Acc@5 83.301 (83.301)	Mem 5329MB
[2022-04-18 03:47:20 tiny] (main.py 279): INFO  * Acc@1 59.412 Acc@5 82.830
[2022-04-18 03:47:20 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 59.4%
[2022-04-18 03:47:20 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_34.pth saving......
[2022-04-18 03:47:20 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_34.pth saved !!!
[2022-04-18 03:47:20 tiny] (main.py 148): INFO Max accuracy: 59.41%
[2022-04-18 03:47:32 tiny] (main.py 226): INFO Train: [35/300][0/1251]	eta 4:05:44 lr 0.000967	time 11.7863 (11.7863)	loss 4.9090 (4.9090)	grad_norm 2.7715 (2.7715)	mem 5329MB
[2022-04-18 03:48:34 tiny] (main.py 226): INFO Train: [35/300][100/1251]	eta 0:13:58 lr 0.000967	time 0.6287 (0.7283)	loss 3.2818 (4.3233)	grad_norm 4.0509 (2.7345)	mem 5329MB
[2022-04-18 03:49:33 tiny] (main.py 226): INFO Train: [35/300][200/1251]	eta 0:11:31 lr 0.000967	time 0.5092 (0.6576)	loss 3.2123 (4.3572)	grad_norm 2.5573 (2.6552)	mem 5329MB
[2022-04-18 03:50:31 tiny] (main.py 226): INFO Train: [35/300][300/1251]	eta 0:10:03 lr 0.000967	time 0.7135 (0.6342)	loss 4.9182 (4.3823)	grad_norm 4.1894 (2.7171)	mem 5329MB
[2022-04-18 03:51:30 tiny] (main.py 226): INFO Train: [35/300][400/1251]	eta 0:08:49 lr 0.000967	time 0.5219 (0.6223)	loss 5.0254 (4.4091)	grad_norm 3.3970 (2.6806)	mem 5329MB
[2022-04-18 03:52:28 tiny] (main.py 226): INFO Train: [35/300][500/1251]	eta 0:07:41 lr 0.000966	time 0.5665 (0.6143)	loss 4.3419 (4.4097)	grad_norm 2.1938 (2.6581)	mem 5329MB
[2022-04-18 03:53:27 tiny] (main.py 226): INFO Train: [35/300][600/1251]	eta 0:06:37 lr 0.000966	time 0.5850 (0.6102)	loss 3.9878 (4.4130)	grad_norm 1.8774 (2.6579)	mem 5329MB
[2022-04-18 03:54:26 tiny] (main.py 226): INFO Train: [35/300][700/1251]	eta 0:05:34 lr 0.000966	time 0.6293 (0.6076)	loss 4.6539 (4.3960)	grad_norm 3.2260 (2.6547)	mem 5329MB
[2022-04-18 03:55:25 tiny] (main.py 226): INFO Train: [35/300][800/1251]	eta 0:04:32 lr 0.000966	time 0.5701 (0.6051)	loss 5.0458 (4.3888)	grad_norm 2.4566 (2.6349)	mem 5329MB
[2022-04-18 03:56:23 tiny] (main.py 226): INFO Train: [35/300][900/1251]	eta 0:03:31 lr 0.000966	time 0.5255 (0.6027)	loss 3.8257 (4.3899)	grad_norm 4.4784 (2.6242)	mem 5329MB
[2022-04-18 03:57:22 tiny] (main.py 226): INFO Train: [35/300][1000/1251]	eta 0:02:30 lr 0.000966	time 0.6253 (0.6010)	loss 4.1377 (4.3951)	grad_norm 3.2744 (2.6065)	mem 5329MB
[2022-04-18 03:58:21 tiny] (main.py 226): INFO Train: [35/300][1100/1251]	eta 0:01:30 lr 0.000965	time 0.6631 (0.5998)	loss 5.1564 (4.3870)	grad_norm 3.3441 (2.6016)	mem 5329MB
[2022-04-18 03:59:19 tiny] (main.py 226): INFO Train: [35/300][1200/1251]	eta 0:00:30 lr 0.000965	time 0.5844 (0.5987)	loss 3.4290 (4.3858)	grad_norm 4.9194 (2.6160)	mem 5329MB
[2022-04-18 03:59:42 tiny] (main.py 233): INFO EPOCH 35 training takes 0:12:21
[2022-04-18 03:59:54 tiny] (main.py 273): INFO Test: [0/49]	Time 12.168 (12.168)	Loss 1.8843 (1.8843)	Acc@1 60.254 (60.254)	Acc@5 84.473 (84.473)	Mem 5329MB
[2022-04-18 04:00:13 tiny] (main.py 279): INFO  * Acc@1 59.786 Acc@5 83.056
[2022-04-18 04:00:13 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 59.8%
[2022-04-18 04:00:13 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_35.pth saving......
[2022-04-18 04:00:13 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_35.pth saved !!!
[2022-04-18 04:00:13 tiny] (main.py 148): INFO Max accuracy: 59.79%
[2022-04-18 04:00:25 tiny] (main.py 226): INFO Train: [36/300][0/1251]	eta 4:12:17 lr 0.000965	time 12.1003 (12.1003)	loss 4.7115 (4.7115)	grad_norm 2.1913 (2.1913)	mem 5329MB
[2022-04-18 04:01:26 tiny] (main.py 226): INFO Train: [36/300][100/1251]	eta 0:13:56 lr 0.000965	time 0.5335 (0.7271)	loss 4.6004 (4.4379)	grad_norm 2.4464 (2.4435)	mem 5329MB
[2022-04-18 04:02:25 tiny] (main.py 226): INFO Train: [36/300][200/1251]	eta 0:11:30 lr 0.000965	time 0.5282 (0.6566)	loss 5.2823 (4.3956)	grad_norm 2.7704 (2.5760)	mem 5329MB
[2022-04-18 04:03:23 tiny] (main.py 226): INFO Train: [36/300][300/1251]	eta 0:10:01 lr 0.000965	time 0.5613 (0.6330)	loss 4.6811 (4.3972)	grad_norm 1.8568 (2.5877)	mem 5329MB
[2022-04-18 04:04:22 tiny] (main.py 226): INFO Train: [36/300][400/1251]	eta 0:08:49 lr 0.000965	time 0.4276 (0.6219)	loss 5.0764 (4.3821)	grad_norm 2.4448 (2.5978)	mem 5329MB
[2022-04-18 04:05:21 tiny] (main.py 226): INFO Train: [36/300][500/1251]	eta 0:07:41 lr 0.000964	time 0.6145 (0.6145)	loss 4.2121 (4.3590)	grad_norm 1.7301 (2.6308)	mem 5329MB
[2022-04-18 04:06:20 tiny] (main.py 226): INFO Train: [36/300][600/1251]	eta 0:06:37 lr 0.000964	time 0.5789 (0.6107)	loss 4.8517 (4.3553)	grad_norm 2.7339 (2.6171)	mem 5329MB
[2022-04-18 04:07:18 tiny] (main.py 226): INFO Train: [36/300][700/1251]	eta 0:05:34 lr 0.000964	time 0.4988 (0.6069)	loss 4.5122 (4.3583)	grad_norm 2.0947 (2.6165)	mem 5329MB
[2022-04-18 04:08:18 tiny] (main.py 226): INFO Train: [36/300][800/1251]	eta 0:04:32 lr 0.000964	time 0.7613 (0.6052)	loss 3.7823 (4.3549)	grad_norm inf (inf)	mem 5329MB
[2022-04-18 04:09:16 tiny] (main.py 226): INFO Train: [36/300][900/1251]	eta 0:03:31 lr 0.000964	time 0.4670 (0.6032)	loss 3.9906 (4.3411)	grad_norm 2.6866 (inf)	mem 5329MB
[2022-04-18 04:10:15 tiny] (main.py 226): INFO Train: [36/300][1000/1251]	eta 0:02:30 lr 0.000964	time 0.4354 (0.6015)	loss 3.5072 (4.3539)	grad_norm 3.0883 (inf)	mem 5329MB
[2022-04-18 04:11:14 tiny] (main.py 226): INFO Train: [36/300][1100/1251]	eta 0:01:30 lr 0.000964	time 0.6364 (0.6003)	loss 4.1554 (4.3545)	grad_norm 1.5815 (inf)	mem 5329MB
[2022-04-18 04:12:13 tiny] (main.py 226): INFO Train: [36/300][1200/1251]	eta 0:00:30 lr 0.000963	time 0.5636 (0.5993)	loss 4.5165 (4.3635)	grad_norm 2.5849 (inf)	mem 5329MB
[2022-04-18 04:12:34 tiny] (main.py 233): INFO EPOCH 36 training takes 0:12:21
[2022-04-18 04:12:46 tiny] (main.py 273): INFO Test: [0/49]	Time 11.464 (11.464)	Loss 1.9625 (1.9625)	Acc@1 60.352 (60.352)	Acc@5 83.594 (83.594)	Mem 5329MB
[2022-04-18 04:13:05 tiny] (main.py 279): INFO  * Acc@1 60.186 Acc@5 83.250
[2022-04-18 04:13:05 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 60.2%
[2022-04-18 04:13:05 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_36.pth saving......
[2022-04-18 04:13:05 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_36.pth saved !!!
[2022-04-18 04:13:05 tiny] (main.py 148): INFO Max accuracy: 60.19%
[2022-04-18 04:13:17 tiny] (main.py 226): INFO Train: [37/300][0/1251]	eta 4:10:35 lr 0.000963	time 12.0184 (12.0184)	loss 4.5147 (4.5147)	grad_norm 2.0499 (2.0499)	mem 5329MB
[2022-04-18 04:14:19 tiny] (main.py 226): INFO Train: [37/300][100/1251]	eta 0:13:55 lr 0.000963	time 0.3740 (0.7261)	loss 4.9845 (4.4120)	grad_norm 1.4303 (2.9404)	mem 5329MB
[2022-04-18 04:15:17 tiny] (main.py 226): INFO Train: [37/300][200/1251]	eta 0:11:30 lr 0.000963	time 0.6041 (0.6565)	loss 4.5772 (4.3801)	grad_norm 3.3683 (2.6952)	mem 5329MB
[2022-04-18 04:16:16 tiny] (main.py 226): INFO Train: [37/300][300/1251]	eta 0:10:01 lr 0.000963	time 0.4995 (0.6328)	loss 3.2862 (4.3511)	grad_norm 1.5407 (2.6197)	mem 5329MB
[2022-04-18 04:17:14 tiny] (main.py 226): INFO Train: [37/300][400/1251]	eta 0:08:47 lr 0.000963	time 0.5906 (0.6204)	loss 4.4082 (4.3527)	grad_norm 1.6075 (2.6472)	mem 5329MB
[2022-04-18 04:18:12 tiny] (main.py 226): INFO Train: [37/300][500/1251]	eta 0:07:40 lr 0.000963	time 0.4282 (0.6128)	loss 3.6101 (4.3497)	grad_norm 2.2826 (2.6447)	mem 5329MB
[2022-04-18 04:19:11 tiny] (main.py 226): INFO Train: [37/300][600/1251]	eta 0:06:36 lr 0.000962	time 0.5957 (0.6085)	loss 4.9883 (4.3643)	grad_norm 2.5357 (2.6367)	mem 5329MB
[2022-04-18 04:20:10 tiny] (main.py 226): INFO Train: [37/300][700/1251]	eta 0:05:33 lr 0.000962	time 0.4833 (0.6058)	loss 3.1453 (4.3638)	grad_norm 3.6737 (2.6064)	mem 5329MB
[2022-04-18 04:21:09 tiny] (main.py 226): INFO Train: [37/300][800/1251]	eta 0:04:32 lr 0.000962	time 0.5756 (0.6033)	loss 4.0209 (4.3719)	grad_norm 2.3244 (2.6252)	mem 5329MB
[2022-04-18 04:22:08 tiny] (main.py 226): INFO Train: [37/300][900/1251]	eta 0:03:31 lr 0.000962	time 0.7608 (0.6020)	loss 4.3495 (4.3690)	grad_norm 3.0069 (2.6202)	mem 5329MB
[2022-04-18 04:23:07 tiny] (main.py 226): INFO Train: [37/300][1000/1251]	eta 0:02:30 lr 0.000962	time 0.5281 (0.6007)	loss 4.7143 (4.3679)	grad_norm 2.5438 (2.6115)	mem 5329MB
[2022-04-18 04:24:05 tiny] (main.py 226): INFO Train: [37/300][1100/1251]	eta 0:01:30 lr 0.000962	time 0.6824 (0.5995)	loss 5.0019 (4.3662)	grad_norm 3.3036 (2.6157)	mem 5329MB
[2022-04-18 04:25:05 tiny] (main.py 226): INFO Train: [37/300][1200/1251]	eta 0:00:30 lr 0.000961	time 0.6703 (0.5988)	loss 5.0074 (4.3744)	grad_norm 2.4640 (2.6234)	mem 5329MB
[2022-04-18 04:25:26 tiny] (main.py 233): INFO EPOCH 37 training takes 0:12:20
[2022-04-18 04:25:39 tiny] (main.py 273): INFO Test: [0/49]	Time 12.437 (12.437)	Loss 1.9201 (1.9201)	Acc@1 59.961 (59.961)	Acc@5 84.570 (84.570)	Mem 5329MB
[2022-04-18 04:25:57 tiny] (main.py 279): INFO  * Acc@1 59.984 Acc@5 83.310
[2022-04-18 04:25:57 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 60.0%
[2022-04-18 04:25:57 tiny] (main.py 148): INFO Max accuracy: 60.19%
[2022-04-18 04:26:09 tiny] (main.py 226): INFO Train: [38/300][0/1251]	eta 3:59:21 lr 0.000961	time 11.4800 (11.4800)	loss 4.6923 (4.6923)	grad_norm 1.6186 (1.6186)	mem 5329MB
[2022-04-18 04:27:10 tiny] (main.py 226): INFO Train: [38/300][100/1251]	eta 0:13:52 lr 0.000961	time 0.6732 (0.7232)	loss 3.3638 (4.3439)	grad_norm 1.7751 (2.5033)	mem 5329MB
[2022-04-18 04:28:09 tiny] (main.py 226): INFO Train: [38/300][200/1251]	eta 0:11:29 lr 0.000961	time 0.6275 (0.6557)	loss 4.8488 (4.3858)	grad_norm 3.1734 (2.6435)	mem 5329MB
[2022-04-18 04:29:08 tiny] (main.py 226): INFO Train: [38/300][300/1251]	eta 0:10:01 lr 0.000961	time 0.5646 (0.6329)	loss 3.9703 (4.4078)	grad_norm 2.2332 (2.6016)	mem 5329MB
[2022-04-18 04:30:07 tiny] (main.py 226): INFO Train: [38/300][400/1251]	eta 0:08:49 lr 0.000961	time 0.5552 (0.6218)	loss 5.1632 (4.4052)	grad_norm 2.5974 (2.5743)	mem 5329MB
[2022-04-18 04:31:05 tiny] (main.py 226): INFO Train: [38/300][500/1251]	eta 0:07:40 lr 0.000961	time 0.6046 (0.6138)	loss 4.5230 (4.4035)	grad_norm 2.2577 (2.5901)	mem 5329MB
[2022-04-18 04:32:04 tiny] (main.py 226): INFO Train: [38/300][600/1251]	eta 0:06:37 lr 0.000960	time 0.4574 (0.6101)	loss 4.9692 (4.3855)	grad_norm 2.7469 (2.6125)	mem 5329MB
[2022-04-18 04:33:02 tiny] (main.py 226): INFO Train: [38/300][700/1251]	eta 0:05:34 lr 0.000960	time 0.4400 (0.6062)	loss 5.4699 (4.3895)	grad_norm 2.4552 (2.6285)	mem 5329MB
[2022-04-18 04:34:02 tiny] (main.py 226): INFO Train: [38/300][800/1251]	eta 0:04:32 lr 0.000960	time 0.4510 (0.6047)	loss 4.2048 (4.3840)	grad_norm 2.2122 (2.6260)	mem 5329MB
[2022-04-18 04:35:00 tiny] (main.py 226): INFO Train: [38/300][900/1251]	eta 0:03:31 lr 0.000960	time 0.7270 (0.6027)	loss 4.2958 (4.3914)	grad_norm 2.7787 (2.6333)	mem 5329MB
[2022-04-18 04:35:59 tiny] (main.py 226): INFO Train: [38/300][1000/1251]	eta 0:02:30 lr 0.000960	time 0.7371 (0.6011)	loss 5.2303 (4.3881)	grad_norm 2.1226 (2.6299)	mem 5329MB
[2022-04-18 04:36:58 tiny] (main.py 226): INFO Train: [38/300][1100/1251]	eta 0:01:30 lr 0.000960	time 0.5248 (0.6000)	loss 3.2031 (4.3818)	grad_norm 4.1343 (inf)	mem 5329MB
[2022-04-18 04:37:57 tiny] (main.py 226): INFO Train: [38/300][1200/1251]	eta 0:00:30 lr 0.000959	time 0.6565 (0.5990)	loss 3.8300 (4.3743)	grad_norm 2.4208 (inf)	mem 5329MB
[2022-04-18 04:38:18 tiny] (main.py 233): INFO EPOCH 38 training takes 0:12:21
[2022-04-18 04:38:29 tiny] (main.py 273): INFO Test: [0/49]	Time 10.818 (10.818)	Loss 1.9514 (1.9514)	Acc@1 59.277 (59.277)	Acc@5 84.375 (84.375)	Mem 5329MB
[2022-04-18 04:38:49 tiny] (main.py 279): INFO  * Acc@1 59.954 Acc@5 83.096
[2022-04-18 04:38:49 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 60.0%
[2022-04-18 04:38:49 tiny] (main.py 148): INFO Max accuracy: 60.19%
[2022-04-18 04:39:01 tiny] (main.py 226): INFO Train: [39/300][0/1251]	eta 4:03:14 lr 0.000959	time 11.6660 (11.6660)	loss 3.9944 (3.9944)	grad_norm 6.2913 (6.2913)	mem 5329MB
[2022-04-18 04:40:03 tiny] (main.py 226): INFO Train: [39/300][100/1251]	eta 0:13:56 lr 0.000959	time 0.4099 (0.7264)	loss 3.8636 (4.3584)	grad_norm 2.1836 (2.5935)	mem 5329MB
[2022-04-18 04:41:02 tiny] (main.py 226): INFO Train: [39/300][200/1251]	eta 0:11:32 lr 0.000959	time 0.6660 (0.6587)	loss 3.0512 (4.4060)	grad_norm 3.0574 (2.5651)	mem 5329MB
[2022-04-18 04:42:00 tiny] (main.py 226): INFO Train: [39/300][300/1251]	eta 0:10:00 lr 0.000959	time 0.5422 (0.6319)	loss 5.1458 (4.3897)	grad_norm 2.0418 (2.6014)	mem 5329MB
[2022-04-18 04:42:59 tiny] (main.py 226): INFO Train: [39/300][400/1251]	eta 0:08:49 lr 0.000959	time 0.6226 (0.6218)	loss 5.0765 (4.3881)	grad_norm 3.1664 (2.6300)	mem 5329MB
[2022-04-18 04:43:57 tiny] (main.py 226): INFO Train: [39/300][500/1251]	eta 0:07:41 lr 0.000958	time 0.6188 (0.6142)	loss 4.6275 (4.3830)	grad_norm 2.6291 (2.6222)	mem 5329MB
[2022-04-18 04:44:56 tiny] (main.py 226): INFO Train: [39/300][600/1251]	eta 0:06:36 lr 0.000958	time 0.4429 (0.6095)	loss 4.6254 (4.3922)	grad_norm 2.7498 (2.6327)	mem 5329MB
[2022-04-18 04:45:55 tiny] (main.py 226): INFO Train: [39/300][700/1251]	eta 0:05:34 lr 0.000958	time 0.6836 (0.6065)	loss 3.4762 (4.3809)	grad_norm 5.0039 (2.6334)	mem 5329MB
[2022-04-18 04:46:54 tiny] (main.py 226): INFO Train: [39/300][800/1251]	eta 0:04:32 lr 0.000958	time 0.7379 (0.6045)	loss 4.9450 (4.3729)	grad_norm 1.4381 (2.6185)	mem 5329MB
[2022-04-18 04:47:53 tiny] (main.py 226): INFO Train: [39/300][900/1251]	eta 0:03:31 lr 0.000958	time 0.6536 (0.6028)	loss 4.4003 (4.3694)	grad_norm 1.8413 (2.6098)	mem 5329MB
[2022-04-18 04:48:51 tiny] (main.py 226): INFO Train: [39/300][1000/1251]	eta 0:02:30 lr 0.000958	time 0.3644 (0.6013)	loss 4.2199 (4.3604)	grad_norm 1.8132 (2.6163)	mem 5329MB
[2022-04-18 04:49:50 tiny] (main.py 226): INFO Train: [39/300][1100/1251]	eta 0:01:30 lr 0.000957	time 0.6513 (0.6004)	loss 4.4167 (4.3641)	grad_norm 3.2934 (2.6057)	mem 5329MB
[2022-04-18 04:50:49 tiny] (main.py 226): INFO Train: [39/300][1200/1251]	eta 0:00:30 lr 0.000957	time 0.7217 (0.5988)	loss 4.5988 (4.3752)	grad_norm 1.6174 (2.6019)	mem 5329MB
[2022-04-18 04:51:11 tiny] (main.py 233): INFO EPOCH 39 training takes 0:12:21
[2022-04-18 04:51:22 tiny] (main.py 273): INFO Test: [0/49]	Time 11.004 (11.004)	Loss 1.9939 (1.9939)	Acc@1 59.082 (59.082)	Acc@5 81.543 (81.543)	Mem 5329MB
[2022-04-18 04:51:42 tiny] (main.py 279): INFO  * Acc@1 59.536 Acc@5 83.118
[2022-04-18 04:51:42 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 59.5%
[2022-04-18 04:51:42 tiny] (main.py 148): INFO Max accuracy: 60.19%
[2022-04-18 04:51:54 tiny] (main.py 226): INFO Train: [40/300][0/1251]	eta 4:14:35 lr 0.000957	time 12.2107 (12.2107)	loss 3.1102 (3.1102)	grad_norm 2.6218 (2.6218)	mem 5329MB
[2022-04-18 04:52:56 tiny] (main.py 226): INFO Train: [40/300][100/1251]	eta 0:14:02 lr 0.000957	time 0.4842 (0.7318)	loss 4.8135 (4.3062)	grad_norm 1.9911 (2.7739)	mem 5329MB
[2022-04-18 04:53:54 tiny] (main.py 226): INFO Train: [40/300][200/1251]	eta 0:11:33 lr 0.000957	time 0.5968 (0.6600)	loss 3.9999 (4.3090)	grad_norm 2.4613 (2.7117)	mem 5329MB
[2022-04-18 04:54:52 tiny] (main.py 226): INFO Train: [40/300][300/1251]	eta 0:10:01 lr 0.000957	time 0.5690 (0.6330)	loss 4.8281 (4.3164)	grad_norm 3.0396 (2.6445)	mem 5329MB
[2022-04-18 04:55:51 tiny] (main.py 226): INFO Train: [40/300][400/1251]	eta 0:08:48 lr 0.000957	time 0.6416 (0.6214)	loss 5.3273 (4.3642)	grad_norm 3.2042 (2.6647)	mem 5329MB
[2022-04-18 04:56:50 tiny] (main.py 226): INFO Train: [40/300][500/1251]	eta 0:07:41 lr 0.000956	time 0.5538 (0.6149)	loss 5.2867 (4.3692)	grad_norm 3.8281 (2.6909)	mem 5329MB
[2022-04-18 04:57:49 tiny] (main.py 226): INFO Train: [40/300][600/1251]	eta 0:06:37 lr 0.000956	time 0.4781 (0.6105)	loss 4.4200 (4.3599)	grad_norm 1.9331 (2.6708)	mem 5329MB
[2022-04-18 04:58:48 tiny] (main.py 226): INFO Train: [40/300][700/1251]	eta 0:05:34 lr 0.000956	time 0.5246 (0.6077)	loss 4.1235 (4.3717)	grad_norm 3.3115 (2.6354)	mem 5329MB
[2022-04-18 04:59:46 tiny] (main.py 226): INFO Train: [40/300][800/1251]	eta 0:04:32 lr 0.000956	time 0.6087 (0.6049)	loss 3.8331 (4.3556)	grad_norm 4.0215 (2.6354)	mem 5329MB
[2022-04-18 05:00:45 tiny] (main.py 226): INFO Train: [40/300][900/1251]	eta 0:03:31 lr 0.000956	time 0.4814 (0.6030)	loss 4.6712 (4.3704)	grad_norm 1.8830 (2.6793)	mem 5329MB
[2022-04-18 05:01:44 tiny] (main.py 226): INFO Train: [40/300][1000/1251]	eta 0:02:30 lr 0.000956	time 0.7439 (0.6014)	loss 4.3039 (4.3678)	grad_norm 3.3403 (2.6829)	mem 5329MB
[2022-04-18 05:02:43 tiny] (main.py 226): INFO Train: [40/300][1100/1251]	eta 0:01:30 lr 0.000955	time 0.5802 (0.6002)	loss 4.4334 (4.3628)	grad_norm 1.4539 (2.6882)	mem 5329MB
[2022-04-18 05:03:41 tiny] (main.py 226): INFO Train: [40/300][1200/1251]	eta 0:00:30 lr 0.000955	time 0.4680 (0.5991)	loss 4.9888 (4.3533)	grad_norm 2.0105 (2.6805)	mem 5329MB
[2022-04-18 05:04:03 tiny] (main.py 233): INFO EPOCH 40 training takes 0:12:21
[2022-04-18 05:04:16 tiny] (main.py 273): INFO Test: [0/49]	Time 12.564 (12.564)	Loss 1.9092 (1.9092)	Acc@1 61.133 (61.133)	Acc@5 84.570 (84.570)	Mem 5329MB
[2022-04-18 05:04:34 tiny] (main.py 279): INFO  * Acc@1 60.210 Acc@5 83.132
[2022-04-18 05:04:34 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 60.2%
[2022-04-18 05:04:34 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_40.pth saving......
[2022-04-18 05:04:34 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_40.pth saved !!!
[2022-04-18 05:04:34 tiny] (main.py 148): INFO Max accuracy: 60.21%
[2022-04-18 05:04:45 tiny] (main.py 226): INFO Train: [41/300][0/1251]	eta 3:57:27 lr 0.000955	time 11.3888 (11.3888)	loss 4.7066 (4.7066)	grad_norm 2.7767 (2.7767)	mem 5329MB
[2022-04-18 05:05:47 tiny] (main.py 226): INFO Train: [41/300][100/1251]	eta 0:13:54 lr 0.000955	time 0.7392 (0.7246)	loss 4.4075 (4.3517)	grad_norm 1.9676 (2.5332)	mem 5329MB
[2022-04-18 05:06:46 tiny] (main.py 226): INFO Train: [41/300][200/1251]	eta 0:11:29 lr 0.000955	time 0.5286 (0.6561)	loss 4.6186 (4.3318)	grad_norm 2.4563 (2.5631)	mem 5329MB
[2022-04-18 05:07:44 tiny] (main.py 226): INFO Train: [41/300][300/1251]	eta 0:10:00 lr 0.000955	time 0.4800 (0.6318)	loss 5.0159 (4.3509)	grad_norm 1.9029 (2.6802)	mem 5329MB
[2022-04-18 05:08:43 tiny] (main.py 226): INFO Train: [41/300][400/1251]	eta 0:08:47 lr 0.000954	time 0.6225 (0.6201)	loss 5.1073 (4.3618)	grad_norm 2.0308 (2.6380)	mem 5329MB
[2022-04-18 05:09:41 tiny] (main.py 226): INFO Train: [41/300][500/1251]	eta 0:07:40 lr 0.000954	time 0.7415 (0.6135)	loss 3.0805 (4.3365)	grad_norm 1.7342 (2.6648)	mem 5329MB
[2022-04-18 05:10:40 tiny] (main.py 226): INFO Train: [41/300][600/1251]	eta 0:06:36 lr 0.000954	time 0.4898 (0.6095)	loss 4.8671 (4.3345)	grad_norm 1.8419 (2.6137)	mem 5329MB
[2022-04-18 05:11:39 tiny] (main.py 226): INFO Train: [41/300][700/1251]	eta 0:05:34 lr 0.000954	time 0.4745 (0.6062)	loss 3.9817 (4.3450)	grad_norm 2.5106 (2.6040)	mem 5329MB
[2022-04-18 05:12:38 tiny] (main.py 226): INFO Train: [41/300][800/1251]	eta 0:04:32 lr 0.000954	time 0.5131 (0.6043)	loss 3.4711 (4.3418)	grad_norm 3.7802 (2.6027)	mem 5329MB
[2022-04-18 05:13:37 tiny] (main.py 226): INFO Train: [41/300][900/1251]	eta 0:03:31 lr 0.000954	time 0.6756 (0.6023)	loss 4.3051 (4.3563)	grad_norm 2.9370 (2.6092)	mem 5329MB
[2022-04-18 05:14:36 tiny] (main.py 226): INFO Train: [41/300][1000/1251]	eta 0:02:30 lr 0.000953	time 0.6949 (0.6009)	loss 3.7525 (4.3576)	grad_norm 1.6607 (2.6105)	mem 5329MB
[2022-04-18 05:15:35 tiny] (main.py 226): INFO Train: [41/300][1100/1251]	eta 0:01:30 lr 0.000953	time 0.4954 (0.6000)	loss 3.6855 (4.3599)	grad_norm 2.6775 (2.6102)	mem 5329MB
[2022-04-18 05:16:33 tiny] (main.py 226): INFO Train: [41/300][1200/1251]	eta 0:00:30 lr 0.000953	time 0.5370 (0.5989)	loss 3.6011 (4.3604)	grad_norm 3.0451 (2.5941)	mem 5329MB
[2022-04-18 05:16:55 tiny] (main.py 233): INFO EPOCH 41 training takes 0:12:21
[2022-04-18 05:17:08 tiny] (main.py 273): INFO Test: [0/49]	Time 12.512 (12.512)	Loss 1.8013 (1.8013)	Acc@1 61.719 (61.719)	Acc@5 84.082 (84.082)	Mem 5329MB
[2022-04-18 05:17:26 tiny] (main.py 279): INFO  * Acc@1 60.708 Acc@5 83.782
[2022-04-18 05:17:26 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 60.7%
[2022-04-18 05:17:26 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_41.pth saving......
[2022-04-18 05:17:26 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_41.pth saved !!!
[2022-04-18 05:17:26 tiny] (main.py 148): INFO Max accuracy: 60.71%
[2022-04-18 05:17:38 tiny] (main.py 226): INFO Train: [42/300][0/1251]	eta 4:07:24 lr 0.000953	time 11.8665 (11.8665)	loss 4.6306 (4.6306)	grad_norm 2.4407 (2.4407)	mem 5329MB
[2022-04-18 05:18:40 tiny] (main.py 226): INFO Train: [42/300][100/1251]	eta 0:13:57 lr 0.000953	time 0.5057 (0.7276)	loss 4.9692 (4.4008)	grad_norm 2.3760 (inf)	mem 5329MB
[2022-04-18 05:19:39 tiny] (main.py 226): INFO Train: [42/300][200/1251]	eta 0:11:31 lr 0.000953	time 0.8114 (0.6577)	loss 3.0904 (4.3115)	grad_norm 2.9019 (inf)	mem 5329MB
[2022-04-18 05:20:37 tiny] (main.py 226): INFO Train: [42/300][300/1251]	eta 0:10:01 lr 0.000952	time 0.6328 (0.6330)	loss 4.4417 (4.2892)	grad_norm 2.7471 (inf)	mem 5329MB
[2022-04-18 05:21:35 tiny] (main.py 226): INFO Train: [42/300][400/1251]	eta 0:08:47 lr 0.000952	time 0.6378 (0.6202)	loss 4.3197 (4.2908)	grad_norm 2.5134 (inf)	mem 5329MB
[2022-04-18 05:22:34 tiny] (main.py 226): INFO Train: [42/300][500/1251]	eta 0:07:40 lr 0.000952	time 0.7892 (0.6137)	loss 4.2146 (4.2992)	grad_norm 1.9645 (inf)	mem 5329MB
[2022-04-18 05:23:32 tiny] (main.py 226): INFO Train: [42/300][600/1251]	eta 0:06:36 lr 0.000952	time 0.5816 (0.6088)	loss 3.9235 (4.3014)	grad_norm 2.8724 (inf)	mem 5329MB
[2022-04-18 05:24:31 tiny] (main.py 226): INFO Train: [42/300][700/1251]	eta 0:05:34 lr 0.000952	time 0.5461 (0.6063)	loss 3.7208 (4.2950)	grad_norm 2.4672 (inf)	mem 5329MB
[2022-04-18 05:25:31 tiny] (main.py 226): INFO Train: [42/300][800/1251]	eta 0:04:32 lr 0.000951	time 0.8121 (0.6049)	loss 3.7184 (4.2905)	grad_norm 4.7716 (inf)	mem 5329MB
[2022-04-18 05:26:29 tiny] (main.py 226): INFO Train: [42/300][900/1251]	eta 0:03:31 lr 0.000951	time 0.5493 (0.6026)	loss 5.3073 (4.2896)	grad_norm 3.5858 (inf)	mem 5329MB
[2022-04-18 05:27:28 tiny] (main.py 226): INFO Train: [42/300][1000/1251]	eta 0:02:30 lr 0.000951	time 0.5070 (0.6014)	loss 3.6472 (4.2931)	grad_norm 2.4299 (inf)	mem 5329MB
[2022-04-18 05:28:28 tiny] (main.py 226): INFO Train: [42/300][1100/1251]	eta 0:01:30 lr 0.000951	time 0.7857 (0.6007)	loss 4.6013 (4.2948)	grad_norm 2.1893 (inf)	mem 5329MB
[2022-04-18 05:29:26 tiny] (main.py 226): INFO Train: [42/300][1200/1251]	eta 0:00:30 lr 0.000951	time 0.5362 (0.5991)	loss 5.0845 (4.2966)	grad_norm 2.9842 (inf)	mem 5329MB
[2022-04-18 05:29:48 tiny] (main.py 233): INFO EPOCH 42 training takes 0:12:21
[2022-04-18 05:29:58 tiny] (main.py 273): INFO Test: [0/49]	Time 9.605 (9.605)	Loss 1.9800 (1.9800)	Acc@1 60.449 (60.449)	Acc@5 83.008 (83.008)	Mem 5329MB
[2022-04-18 05:30:20 tiny] (main.py 279): INFO  * Acc@1 60.742 Acc@5 83.952
[2022-04-18 05:30:20 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 60.7%
[2022-04-18 05:30:20 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_42.pth saving......
[2022-04-18 05:30:20 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_42.pth saved !!!
[2022-04-18 05:30:20 tiny] (main.py 148): INFO Max accuracy: 60.74%
[2022-04-18 05:30:32 tiny] (main.py 226): INFO Train: [43/300][0/1251]	eta 4:11:20 lr 0.000951	time 12.0548 (12.0548)	loss 4.8361 (4.8361)	grad_norm 2.2530 (2.2530)	mem 5329MB
[2022-04-18 05:31:33 tiny] (main.py 226): INFO Train: [43/300][100/1251]	eta 0:13:57 lr 0.000950	time 0.6507 (0.7275)	loss 4.2589 (4.3825)	grad_norm 3.1731 (2.6500)	mem 5329MB
[2022-04-18 05:32:32 tiny] (main.py 226): INFO Train: [43/300][200/1251]	eta 0:11:28 lr 0.000950	time 0.4239 (0.6552)	loss 4.7158 (4.3351)	grad_norm 2.8578 (2.6469)	mem 5329MB
[2022-04-18 05:33:30 tiny] (main.py 226): INFO Train: [43/300][300/1251]	eta 0:09:59 lr 0.000950	time 0.4939 (0.6306)	loss 4.2898 (4.3594)	grad_norm 2.2395 (2.6832)	mem 5329MB
[2022-04-18 05:34:29 tiny] (main.py 226): INFO Train: [43/300][400/1251]	eta 0:08:48 lr 0.000950	time 0.5214 (0.6206)	loss 3.3959 (4.3260)	grad_norm 2.9588 (2.6233)	mem 5329MB
[2022-04-18 05:35:28 tiny] (main.py 226): INFO Train: [43/300][500/1251]	eta 0:07:41 lr 0.000950	time 0.5171 (0.6150)	loss 4.3179 (4.3378)	grad_norm 2.3828 (2.6279)	mem 5329MB
[2022-04-18 05:36:26 tiny] (main.py 226): INFO Train: [43/300][600/1251]	eta 0:06:36 lr 0.000950	time 0.4766 (0.6095)	loss 4.1781 (4.3258)	grad_norm 1.5437 (2.6279)	mem 5329MB
[2022-04-18 05:37:26 tiny] (main.py 226): INFO Train: [43/300][700/1251]	eta 0:05:34 lr 0.000949	time 0.5860 (0.6076)	loss 5.1565 (4.3109)	grad_norm 2.2088 (2.6375)	mem 5329MB
[2022-04-18 05:38:24 tiny] (main.py 226): INFO Train: [43/300][800/1251]	eta 0:04:32 lr 0.000949	time 0.5633 (0.6045)	loss 5.2476 (4.3230)	grad_norm 2.6321 (2.6294)	mem 5329MB
[2022-04-18 05:39:23 tiny] (main.py 226): INFO Train: [43/300][900/1251]	eta 0:03:31 lr 0.000949	time 0.8001 (0.6029)	loss 4.2288 (4.3173)	grad_norm 2.9825 (2.6426)	mem 5329MB
[2022-04-18 05:40:22 tiny] (main.py 226): INFO Train: [43/300][1000/1251]	eta 0:02:30 lr 0.000949	time 0.7262 (0.6014)	loss 3.5642 (4.3028)	grad_norm 1.7573 (2.6500)	mem 5329MB
[2022-04-18 05:41:21 tiny] (main.py 226): INFO Train: [43/300][1100/1251]	eta 0:01:30 lr 0.000949	time 0.5877 (0.6001)	loss 4.6015 (4.3054)	grad_norm 1.9700 (2.6503)	mem 5329MB
[2022-04-18 05:42:20 tiny] (main.py 226): INFO Train: [43/300][1200/1251]	eta 0:00:30 lr 0.000948	time 0.5135 (0.5995)	loss 3.2686 (4.3053)	grad_norm 2.4162 (2.6600)	mem 5329MB
[2022-04-18 05:42:42 tiny] (main.py 233): INFO EPOCH 43 training takes 0:12:21
[2022-04-18 05:42:54 tiny] (main.py 273): INFO Test: [0/49]	Time 11.975 (11.975)	Loss 1.9255 (1.9255)	Acc@1 60.742 (60.742)	Acc@5 84.082 (84.082)	Mem 5329MB
[2022-04-18 05:43:13 tiny] (main.py 279): INFO  * Acc@1 60.914 Acc@5 84.064
[2022-04-18 05:43:13 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 60.9%
[2022-04-18 05:43:13 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_43.pth saving......
[2022-04-18 05:43:13 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_43.pth saved !!!
[2022-04-18 05:43:13 tiny] (main.py 148): INFO Max accuracy: 60.91%
[2022-04-18 05:43:24 tiny] (main.py 226): INFO Train: [44/300][0/1251]	eta 3:55:09 lr 0.000948	time 11.2786 (11.2786)	loss 4.3527 (4.3527)	grad_norm 4.3613 (4.3613)	mem 5329MB
[2022-04-18 05:44:26 tiny] (main.py 226): INFO Train: [44/300][100/1251]	eta 0:13:54 lr 0.000948	time 0.5497 (0.7254)	loss 4.2579 (4.3348)	grad_norm 1.8120 (2.5045)	mem 5329MB
[2022-04-18 05:45:24 tiny] (main.py 226): INFO Train: [44/300][200/1251]	eta 0:11:28 lr 0.000948	time 0.5402 (0.6548)	loss 3.1875 (4.3076)	grad_norm 1.9056 (2.6241)	mem 5329MB
[2022-04-18 05:46:23 tiny] (main.py 226): INFO Train: [44/300][300/1251]	eta 0:10:00 lr 0.000948	time 0.6493 (0.6319)	loss 4.4289 (4.3019)	grad_norm 3.6110 (2.6100)	mem 5329MB
[2022-04-18 05:47:22 tiny] (main.py 226): INFO Train: [44/300][400/1251]	eta 0:08:48 lr 0.000948	time 0.5658 (0.6210)	loss 4.2894 (4.3190)	grad_norm 3.0532 (2.6527)	mem 5329MB
[2022-04-18 05:48:20 tiny] (main.py 226): INFO Train: [44/300][500/1251]	eta 0:07:40 lr 0.000947	time 0.6294 (0.6133)	loss 3.3083 (4.3234)	grad_norm 1.7164 (2.6490)	mem 5329MB
[2022-04-18 05:49:19 tiny] (main.py 226): INFO Train: [44/300][600/1251]	eta 0:06:36 lr 0.000947	time 0.7001 (0.6092)	loss 4.5809 (4.3351)	grad_norm 2.6307 (2.6176)	mem 5329MB
[2022-04-18 05:50:17 tiny] (main.py 226): INFO Train: [44/300][700/1251]	eta 0:05:33 lr 0.000947	time 0.4282 (0.6060)	loss 3.0222 (4.3193)	grad_norm 4.7176 (2.6239)	mem 5329MB
[2022-04-18 05:51:16 tiny] (main.py 226): INFO Train: [44/300][800/1251]	eta 0:04:32 lr 0.000947	time 0.5963 (0.6039)	loss 3.9788 (4.3107)	grad_norm 3.0734 (2.6416)	mem 5329MB
[2022-04-18 05:52:15 tiny] (main.py 226): INFO Train: [44/300][900/1251]	eta 0:03:31 lr 0.000947	time 0.6519 (0.6022)	loss 3.9815 (4.3102)	grad_norm 2.8517 (2.6691)	mem 5329MB
[2022-04-18 05:53:14 tiny] (main.py 226): INFO Train: [44/300][1000/1251]	eta 0:02:30 lr 0.000947	time 0.5106 (0.6008)	loss 4.6504 (4.3158)	grad_norm 2.3527 (2.6683)	mem 5329MB
[2022-04-18 05:54:13 tiny] (main.py 226): INFO Train: [44/300][1100/1251]	eta 0:01:30 lr 0.000946	time 0.6386 (0.5995)	loss 4.6530 (4.3117)	grad_norm 2.3849 (2.6580)	mem 5329MB
[2022-04-18 05:55:11 tiny] (main.py 226): INFO Train: [44/300][1200/1251]	eta 0:00:30 lr 0.000946	time 0.6564 (0.5985)	loss 4.4115 (4.3099)	grad_norm 2.0444 (2.6639)	mem 5329MB
[2022-04-18 05:55:33 tiny] (main.py 233): INFO EPOCH 44 training takes 0:12:20
[2022-04-18 05:55:43 tiny] (main.py 273): INFO Test: [0/49]	Time 10.136 (10.136)	Loss 1.8863 (1.8863)	Acc@1 60.449 (60.449)	Acc@5 84.082 (84.082)	Mem 5329MB
[2022-04-18 05:56:04 tiny] (main.py 279): INFO  * Acc@1 60.740 Acc@5 83.864
[2022-04-18 05:56:04 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 60.7%
[2022-04-18 05:56:04 tiny] (main.py 148): INFO Max accuracy: 60.91%
[2022-04-18 05:56:16 tiny] (main.py 226): INFO Train: [45/300][0/1251]	eta 4:15:07 lr 0.000946	time 12.2364 (12.2364)	loss 5.1956 (5.1956)	grad_norm 3.4608 (3.4608)	mem 5329MB
[2022-04-18 05:57:18 tiny] (main.py 226): INFO Train: [45/300][100/1251]	eta 0:14:03 lr 0.000946	time 0.7504 (0.7327)	loss 4.2744 (4.4460)	grad_norm 2.6039 (2.6345)	mem 5329MB
[2022-04-18 05:58:16 tiny] (main.py 226): INFO Train: [45/300][200/1251]	eta 0:11:30 lr 0.000946	time 0.6028 (0.6571)	loss 4.7811 (4.3725)	grad_norm 2.7494 (2.6735)	mem 5329MB
[2022-04-18 05:59:15 tiny] (main.py 226): INFO Train: [45/300][300/1251]	eta 0:10:01 lr 0.000945	time 0.4509 (0.6325)	loss 3.7021 (4.3410)	grad_norm 4.4787 (2.6338)	mem 5329MB
[2022-04-18 06:00:13 tiny] (main.py 226): INFO Train: [45/300][400/1251]	eta 0:08:48 lr 0.000945	time 0.7162 (0.6206)	loss 4.5393 (4.3424)	grad_norm 2.9117 (2.6543)	mem 5329MB
[2022-04-18 06:01:11 tiny] (main.py 226): INFO Train: [45/300][500/1251]	eta 0:07:40 lr 0.000945	time 0.5050 (0.6133)	loss 3.3146 (4.3313)	grad_norm 4.6681 (2.7091)	mem 5329MB
[2022-04-18 06:02:11 tiny] (main.py 226): INFO Train: [45/300][600/1251]	eta 0:06:37 lr 0.000945	time 0.8796 (0.6099)	loss 4.4876 (4.3282)	grad_norm 1.5994 (inf)	mem 5329MB
[2022-04-18 06:03:09 tiny] (main.py 226): INFO Train: [45/300][700/1251]	eta 0:05:34 lr 0.000945	time 0.4865 (0.6064)	loss 4.7588 (4.3272)	grad_norm 1.6167 (inf)	mem 5329MB
[2022-04-18 06:04:08 tiny] (main.py 226): INFO Train: [45/300][800/1251]	eta 0:04:32 lr 0.000945	time 0.5262 (0.6043)	loss 4.8379 (4.3190)	grad_norm 2.0532 (inf)	mem 5329MB
[2022-04-18 06:05:07 tiny] (main.py 226): INFO Train: [45/300][900/1251]	eta 0:03:31 lr 0.000944	time 0.5729 (0.6027)	loss 4.2087 (4.3123)	grad_norm 2.2681 (inf)	mem 5329MB
[2022-04-18 06:06:06 tiny] (main.py 226): INFO Train: [45/300][1000/1251]	eta 0:02:30 lr 0.000944	time 0.6436 (0.6011)	loss 4.8771 (4.3055)	grad_norm 2.5237 (inf)	mem 5329MB
[2022-04-18 06:07:05 tiny] (main.py 226): INFO Train: [45/300][1100/1251]	eta 0:01:30 lr 0.000944	time 0.4647 (0.5999)	loss 3.2670 (4.3056)	grad_norm 2.1349 (inf)	mem 5329MB
[2022-04-18 06:08:03 tiny] (main.py 226): INFO Train: [45/300][1200/1251]	eta 0:00:30 lr 0.000944	time 0.6216 (0.5988)	loss 4.9450 (4.2990)	grad_norm 1.8189 (inf)	mem 5329MB
[2022-04-18 06:08:25 tiny] (main.py 233): INFO EPOCH 45 training takes 0:12:21
[2022-04-18 06:08:37 tiny] (main.py 273): INFO Test: [0/49]	Time 11.957 (11.957)	Loss 1.9624 (1.9624)	Acc@1 60.449 (60.449)	Acc@5 83.398 (83.398)	Mem 5329MB
[2022-04-18 06:08:56 tiny] (main.py 279): INFO  * Acc@1 61.686 Acc@5 84.352
[2022-04-18 06:08:56 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 61.7%
[2022-04-18 06:08:56 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_45.pth saving......
[2022-04-18 06:08:56 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_45.pth saved !!!
[2022-04-18 06:08:56 tiny] (main.py 148): INFO Max accuracy: 61.69%
[2022-04-18 06:09:09 tiny] (main.py 226): INFO Train: [46/300][0/1251]	eta 4:11:28 lr 0.000944	time 12.0614 (12.0614)	loss 3.2019 (3.2019)	grad_norm 3.5053 (3.5053)	mem 5329MB
[2022-04-18 06:10:10 tiny] (main.py 226): INFO Train: [46/300][100/1251]	eta 0:13:58 lr 0.000943	time 0.6412 (0.7286)	loss 4.4519 (4.3705)	grad_norm 3.9275 (2.7599)	mem 5329MB
[2022-04-18 06:11:08 tiny] (main.py 226): INFO Train: [46/300][200/1251]	eta 0:11:29 lr 0.000943	time 0.5349 (0.6563)	loss 4.5897 (4.3212)	grad_norm 3.0372 (2.7596)	mem 5329MB
[2022-04-18 06:12:07 tiny] (main.py 226): INFO Train: [46/300][300/1251]	eta 0:10:00 lr 0.000943	time 0.5569 (0.6317)	loss 4.9441 (4.3101)	grad_norm 1.7206 (2.7861)	mem 5329MB
[2022-04-18 06:13:06 tiny] (main.py 226): INFO Train: [46/300][400/1251]	eta 0:08:49 lr 0.000943	time 0.6054 (0.6221)	loss 4.7825 (4.2776)	grad_norm 3.7410 (2.7999)	mem 5329MB
[2022-04-18 06:14:04 tiny] (main.py 226): INFO Train: [46/300][500/1251]	eta 0:07:41 lr 0.000943	time 0.6134 (0.6145)	loss 4.7324 (4.2851)	grad_norm 2.1142 (2.8019)	mem 5329MB
[2022-04-18 06:15:03 tiny] (main.py 226): INFO Train: [46/300][600/1251]	eta 0:06:37 lr 0.000943	time 0.8027 (0.6104)	loss 3.5630 (4.2914)	grad_norm 2.2003 (2.7830)	mem 5329MB
[2022-04-18 06:16:02 tiny] (main.py 226): INFO Train: [46/300][700/1251]	eta 0:05:34 lr 0.000942	time 0.6291 (0.6076)	loss 4.3192 (4.2850)	grad_norm 1.9937 (2.7699)	mem 5329MB
[2022-04-18 06:17:01 tiny] (main.py 226): INFO Train: [46/300][800/1251]	eta 0:04:32 lr 0.000942	time 0.5203 (0.6052)	loss 4.8643 (4.2922)	grad_norm 2.9911 (2.7637)	mem 5329MB
[2022-04-18 06:18:00 tiny] (main.py 226): INFO Train: [46/300][900/1251]	eta 0:03:31 lr 0.000942	time 0.5923 (0.6033)	loss 4.7924 (4.2872)	grad_norm 5.0103 (2.7480)	mem 5329MB
[2022-04-18 06:18:59 tiny] (main.py 226): INFO Train: [46/300][1000/1251]	eta 0:02:31 lr 0.000942	time 0.5129 (0.6017)	loss 3.3803 (4.2870)	grad_norm 2.2736 (2.7567)	mem 5329MB
[2022-04-18 06:19:58 tiny] (main.py 226): INFO Train: [46/300][1100/1251]	eta 0:01:30 lr 0.000942	time 0.7502 (0.6005)	loss 3.1469 (4.2762)	grad_norm 3.3741 (2.7378)	mem 5329MB
[2022-04-18 06:20:56 tiny] (main.py 226): INFO Train: [46/300][1200/1251]	eta 0:00:30 lr 0.000941	time 0.6646 (0.5994)	loss 4.6787 (4.2819)	grad_norm 4.1502 (2.7285)	mem 5329MB
[2022-04-18 06:21:18 tiny] (main.py 233): INFO EPOCH 46 training takes 0:12:21
[2022-04-18 06:21:31 tiny] (main.py 273): INFO Test: [0/49]	Time 12.734 (12.734)	Loss 2.0175 (2.0175)	Acc@1 58.594 (58.594)	Acc@5 82.617 (82.617)	Mem 5329MB
[2022-04-18 06:21:49 tiny] (main.py 279): INFO  * Acc@1 61.202 Acc@5 84.134
[2022-04-18 06:21:49 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 61.2%
[2022-04-18 06:21:49 tiny] (main.py 148): INFO Max accuracy: 61.69%
[2022-04-18 06:22:01 tiny] (main.py 226): INFO Train: [47/300][0/1251]	eta 4:02:40 lr 0.000941	time 11.6390 (11.6390)	loss 4.7125 (4.7125)	grad_norm 1.6861 (1.6861)	mem 5329MB
[2022-04-18 06:23:03 tiny] (main.py 226): INFO Train: [47/300][100/1251]	eta 0:14:01 lr 0.000941	time 0.6880 (0.7308)	loss 4.3211 (4.2738)	grad_norm 1.9176 (inf)	mem 5329MB
[2022-04-18 06:24:02 tiny] (main.py 226): INFO Train: [47/300][200/1251]	eta 0:11:32 lr 0.000941	time 0.5569 (0.6586)	loss 4.6627 (4.2767)	grad_norm 2.8309 (inf)	mem 5329MB
[2022-04-18 06:25:00 tiny] (main.py 226): INFO Train: [47/300][300/1251]	eta 0:10:02 lr 0.000941	time 0.4652 (0.6338)	loss 4.5554 (4.2714)	grad_norm 2.1719 (inf)	mem 5329MB
[2022-04-18 06:25:59 tiny] (main.py 226): INFO Train: [47/300][400/1251]	eta 0:08:49 lr 0.000940	time 0.6335 (0.6222)	loss 4.7827 (4.2732)	grad_norm 2.1748 (inf)	mem 5329MB
[2022-04-18 06:26:57 tiny] (main.py 226): INFO Train: [47/300][500/1251]	eta 0:07:41 lr 0.000940	time 0.6796 (0.6151)	loss 4.1984 (4.2704)	grad_norm 2.5651 (inf)	mem 5329MB
[2022-04-18 06:27:56 tiny] (main.py 226): INFO Train: [47/300][600/1251]	eta 0:06:37 lr 0.000940	time 0.4836 (0.6104)	loss 3.6173 (4.2947)	grad_norm 2.6936 (inf)	mem 5329MB
[2022-04-18 06:28:55 tiny] (main.py 226): INFO Train: [47/300][700/1251]	eta 0:05:34 lr 0.000940	time 0.5152 (0.6070)	loss 4.5554 (4.2909)	grad_norm 2.3172 (inf)	mem 5329MB
[2022-04-18 06:29:53 tiny] (main.py 226): INFO Train: [47/300][800/1251]	eta 0:04:32 lr 0.000940	time 0.3495 (0.6040)	loss 4.7971 (4.3002)	grad_norm 3.3909 (inf)	mem 5329MB
[2022-04-18 06:30:52 tiny] (main.py 226): INFO Train: [47/300][900/1251]	eta 0:03:31 lr 0.000939	time 0.6238 (0.6020)	loss 3.0929 (4.2867)	grad_norm 3.1436 (inf)	mem 5329MB
[2022-04-18 06:31:51 tiny] (main.py 226): INFO Train: [47/300][1000/1251]	eta 0:02:30 lr 0.000939	time 0.5637 (0.6011)	loss 5.0813 (4.2804)	grad_norm 2.1443 (inf)	mem 5329MB
[2022-04-18 06:32:50 tiny] (main.py 226): INFO Train: [47/300][1100/1251]	eta 0:01:30 lr 0.000939	time 0.5168 (0.5999)	loss 4.5303 (4.2841)	grad_norm 1.8188 (inf)	mem 5329MB
[2022-04-18 06:33:49 tiny] (main.py 226): INFO Train: [47/300][1200/1251]	eta 0:00:30 lr 0.000939	time 0.7749 (0.5993)	loss 4.6164 (4.2874)	grad_norm 3.1262 (inf)	mem 5329MB
[2022-04-18 06:34:11 tiny] (main.py 233): INFO EPOCH 47 training takes 0:12:21
[2022-04-18 06:34:21 tiny] (main.py 273): INFO Test: [0/49]	Time 10.463 (10.463)	Loss 1.9622 (1.9622)	Acc@1 62.500 (62.500)	Acc@5 84.082 (84.082)	Mem 5329MB
[2022-04-18 06:34:42 tiny] (main.py 279): INFO  * Acc@1 60.796 Acc@5 83.828
[2022-04-18 06:34:42 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 60.8%
[2022-04-18 06:34:42 tiny] (main.py 148): INFO Max accuracy: 61.69%
[2022-04-18 06:34:53 tiny] (main.py 226): INFO Train: [48/300][0/1251]	eta 3:42:26 lr 0.000939	time 10.6689 (10.6689)	loss 4.6069 (4.6069)	grad_norm 2.0731 (2.0731)	mem 5329MB
[2022-04-18 06:35:56 tiny] (main.py 226): INFO Train: [48/300][100/1251]	eta 0:13:57 lr 0.000939	time 0.5647 (0.7273)	loss 3.4004 (4.3206)	grad_norm 2.6150 (2.7422)	mem 5329MB
[2022-04-18 06:36:54 tiny] (main.py 226): INFO Train: [48/300][200/1251]	eta 0:11:29 lr 0.000938	time 0.7300 (0.6557)	loss 4.5003 (4.3041)	grad_norm 2.1154 (2.7581)	mem 5329MB
[2022-04-18 06:37:52 tiny] (main.py 226): INFO Train: [48/300][300/1251]	eta 0:10:01 lr 0.000938	time 0.8438 (0.6323)	loss 4.7673 (4.2728)	grad_norm 1.6283 (2.7531)	mem 5329MB
[2022-04-18 06:38:51 tiny] (main.py 226): INFO Train: [48/300][400/1251]	eta 0:08:48 lr 0.000938	time 0.7228 (0.6206)	loss 4.6310 (4.2771)	grad_norm 5.7596 (2.7729)	mem 5329MB
[2022-04-18 06:39:50 tiny] (main.py 226): INFO Train: [48/300][500/1251]	eta 0:07:41 lr 0.000938	time 0.6946 (0.6140)	loss 4.5739 (4.2866)	grad_norm 3.7394 (2.7871)	mem 5329MB
[2022-04-18 06:40:48 tiny] (main.py 226): INFO Train: [48/300][600/1251]	eta 0:06:36 lr 0.000938	time 0.3995 (0.6094)	loss 4.6162 (4.2905)	grad_norm 1.7989 (2.7903)	mem 5329MB
[2022-04-18 06:41:47 tiny] (main.py 226): INFO Train: [48/300][700/1251]	eta 0:05:33 lr 0.000937	time 0.4978 (0.6060)	loss 4.4572 (4.2990)	grad_norm 2.0509 (2.7663)	mem 5329MB
[2022-04-18 06:42:46 tiny] (main.py 226): INFO Train: [48/300][800/1251]	eta 0:04:32 lr 0.000937	time 0.4676 (0.6041)	loss 4.4468 (4.3072)	grad_norm 3.1915 (2.7448)	mem 5329MB
[2022-04-18 06:43:45 tiny] (main.py 226): INFO Train: [48/300][900/1251]	eta 0:03:31 lr 0.000937	time 0.5452 (0.6025)	loss 4.5275 (4.2964)	grad_norm 3.1536 (2.7315)	mem 5329MB
[2022-04-18 06:44:44 tiny] (main.py 226): INFO Train: [48/300][1000/1251]	eta 0:02:30 lr 0.000937	time 0.6108 (0.6012)	loss 3.8105 (4.2971)	grad_norm 2.4941 (2.7324)	mem 5329MB
[2022-04-18 06:45:43 tiny] (main.py 226): INFO Train: [48/300][1100/1251]	eta 0:01:30 lr 0.000937	time 0.4636 (0.6000)	loss 4.4343 (4.2934)	grad_norm 1.6139 (2.7285)	mem 5329MB
[2022-04-18 06:46:41 tiny] (main.py 226): INFO Train: [48/300][1200/1251]	eta 0:00:30 lr 0.000936	time 0.5236 (0.5984)	loss 3.6824 (4.2890)	grad_norm 1.9681 (2.7347)	mem 5329MB
[2022-04-18 06:47:03 tiny] (main.py 233): INFO EPOCH 48 training takes 0:12:20
[2022-04-18 06:47:15 tiny] (main.py 273): INFO Test: [0/49]	Time 12.000 (12.000)	Loss 1.9441 (1.9441)	Acc@1 58.789 (58.789)	Acc@5 82.227 (82.227)	Mem 5329MB
[2022-04-18 06:47:34 tiny] (main.py 279): INFO  * Acc@1 60.820 Acc@5 83.888
[2022-04-18 06:47:34 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 60.8%
[2022-04-18 06:47:34 tiny] (main.py 148): INFO Max accuracy: 61.69%
[2022-04-18 06:47:46 tiny] (main.py 226): INFO Train: [49/300][0/1251]	eta 4:08:24 lr 0.000936	time 11.9142 (11.9142)	loss 4.6586 (4.6586)	grad_norm 3.3031 (3.3031)	mem 5329MB
[2022-04-18 06:48:48 tiny] (main.py 226): INFO Train: [49/300][100/1251]	eta 0:14:02 lr 0.000936	time 0.7060 (0.7323)	loss 3.6406 (4.2160)	grad_norm 1.6528 (2.9362)	mem 5329MB
[2022-04-18 06:49:46 tiny] (main.py 226): INFO Train: [49/300][200/1251]	eta 0:11:31 lr 0.000936	time 0.6347 (0.6584)	loss 4.2630 (4.2177)	grad_norm 2.2542 (2.9355)	mem 5329MB
[2022-04-18 06:50:45 tiny] (main.py 226): INFO Train: [49/300][300/1251]	eta 0:10:04 lr 0.000936	time 1.0563 (0.6356)	loss 4.0337 (4.2169)	grad_norm 1.9004 (2.7800)	mem 5329MB
[2022-04-18 06:51:43 tiny] (main.py 226): INFO Train: [49/300][400/1251]	eta 0:08:48 lr 0.000935	time 0.4795 (0.6215)	loss 4.2365 (4.2318)	grad_norm 3.0303 (2.8052)	mem 5329MB
[2022-04-18 06:52:42 tiny] (main.py 226): INFO Train: [49/300][500/1251]	eta 0:07:41 lr 0.000935	time 0.3862 (0.6142)	loss 3.5648 (4.2392)	grad_norm 2.2608 (2.7744)	mem 5329MB
[2022-04-18 06:53:41 tiny] (main.py 226): INFO Train: [49/300][600/1251]	eta 0:06:37 lr 0.000935	time 0.4184 (0.6103)	loss 4.6426 (4.2435)	grad_norm 3.1101 (2.7774)	mem 5329MB
[2022-04-18 06:54:41 tiny] (main.py 226): INFO Train: [49/300][700/1251]	eta 0:05:35 lr 0.000935	time 0.6427 (0.6092)	loss 4.3414 (4.2560)	grad_norm 2.7548 (2.7813)	mem 5329MB
[2022-04-18 06:55:42 tiny] (main.py 226): INFO Train: [49/300][800/1251]	eta 0:04:35 lr 0.000935	time 0.4545 (0.6098)	loss 4.3277 (4.2549)	grad_norm 2.1453 (2.7520)	mem 5329MB
[2022-04-18 06:56:42 tiny] (main.py 226): INFO Train: [49/300][900/1251]	eta 0:03:33 lr 0.000934	time 0.5539 (0.6079)	loss 3.0693 (4.2532)	grad_norm 3.3040 (2.7248)	mem 5329MB
[2022-04-18 06:57:40 tiny] (main.py 226): INFO Train: [49/300][1000/1251]	eta 0:02:32 lr 0.000934	time 0.4701 (0.6056)	loss 5.1120 (4.2514)	grad_norm 1.6464 (2.7340)	mem 5329MB
[2022-04-18 06:58:39 tiny] (main.py 226): INFO Train: [49/300][1100/1251]	eta 0:01:31 lr 0.000934	time 0.5610 (0.6041)	loss 4.2035 (4.2528)	grad_norm 2.6725 (2.7424)	mem 5329MB
[2022-04-18 06:59:38 tiny] (main.py 226): INFO Train: [49/300][1200/1251]	eta 0:00:30 lr 0.000934	time 0.7051 (0.6028)	loss 5.0721 (4.2533)	grad_norm 2.7843 (2.7491)	mem 5329MB
[2022-04-18 07:00:00 tiny] (main.py 233): INFO EPOCH 49 training takes 0:12:26
[2022-04-18 07:00:11 tiny] (main.py 273): INFO Test: [0/49]	Time 11.456 (11.456)	Loss 1.9795 (1.9795)	Acc@1 59.473 (59.473)	Acc@5 83.105 (83.105)	Mem 5329MB
[2022-04-18 07:00:31 tiny] (main.py 279): INFO  * Acc@1 61.048 Acc@5 84.036
[2022-04-18 07:00:31 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 61.0%
[2022-04-18 07:00:31 tiny] (main.py 148): INFO Max accuracy: 61.69%
[2022-04-18 07:00:43 tiny] (main.py 226): INFO Train: [50/300][0/1251]	eta 4:15:04 lr 0.000934	time 12.2341 (12.2341)	loss 3.6843 (3.6843)	grad_norm 2.7524 (2.7524)	mem 5329MB
[2022-04-18 07:01:45 tiny] (main.py 226): INFO Train: [50/300][100/1251]	eta 0:13:57 lr 0.000933	time 0.5181 (0.7273)	loss 4.2869 (4.1966)	grad_norm 2.0283 (2.8346)	mem 5329MB
[2022-04-18 07:02:43 tiny] (main.py 226): INFO Train: [50/300][200/1251]	eta 0:11:30 lr 0.000933	time 0.4301 (0.6566)	loss 4.3178 (4.2694)	grad_norm 2.8321 (2.8158)	mem 5329MB
[2022-04-18 07:03:41 tiny] (main.py 226): INFO Train: [50/300][300/1251]	eta 0:10:00 lr 0.000933	time 0.4760 (0.6317)	loss 3.1720 (4.2583)	grad_norm 2.6468 (2.7350)	mem 5329MB
[2022-04-18 07:04:39 tiny] (main.py 226): INFO Train: [50/300][400/1251]	eta 0:08:47 lr 0.000933	time 0.6195 (0.6193)	loss 4.2460 (4.2939)	grad_norm 2.5791 (inf)	mem 5329MB
[2022-04-18 07:05:38 tiny] (main.py 226): INFO Train: [50/300][500/1251]	eta 0:07:40 lr 0.000933	time 0.8224 (0.6136)	loss 4.7447 (4.2922)	grad_norm 2.7416 (inf)	mem 5329MB
[2022-04-18 07:06:37 tiny] (main.py 226): INFO Train: [50/300][600/1251]	eta 0:06:36 lr 0.000932	time 0.6113 (0.6093)	loss 4.0491 (4.2927)	grad_norm 2.8664 (inf)	mem 5329MB
[2022-04-18 07:07:36 tiny] (main.py 226): INFO Train: [50/300][700/1251]	eta 0:05:34 lr 0.000932	time 0.7128 (0.6064)	loss 3.9637 (4.2852)	grad_norm 2.0291 (inf)	mem 5329MB
[2022-04-18 07:08:35 tiny] (main.py 226): INFO Train: [50/300][800/1251]	eta 0:04:32 lr 0.000932	time 0.4728 (0.6041)	loss 3.1274 (4.2970)	grad_norm 2.4548 (inf)	mem 5329MB
[2022-04-18 07:09:34 tiny] (main.py 226): INFO Train: [50/300][900/1251]	eta 0:03:31 lr 0.000932	time 0.5751 (0.6025)	loss 4.9820 (4.3009)	grad_norm 2.0257 (inf)	mem 5329MB
[2022-04-18 07:10:33 tiny] (main.py 226): INFO Train: [50/300][1000/1251]	eta 0:02:30 lr 0.000932	time 0.5396 (0.6010)	loss 3.5662 (4.2941)	grad_norm 1.5421 (inf)	mem 5329MB
[2022-04-18 07:11:32 tiny] (main.py 226): INFO Train: [50/300][1100/1251]	eta 0:01:30 lr 0.000931	time 0.5161 (0.5999)	loss 3.9826 (4.2885)	grad_norm 1.6694 (inf)	mem 5329MB
[2022-04-18 07:12:30 tiny] (main.py 226): INFO Train: [50/300][1200/1251]	eta 0:00:30 lr 0.000931	time 0.6285 (0.5985)	loss 4.0054 (4.2913)	grad_norm 2.5378 (inf)	mem 5329MB
[2022-04-18 07:12:52 tiny] (main.py 233): INFO EPOCH 50 training takes 0:12:20
[2022-04-18 07:13:04 tiny] (main.py 273): INFO Test: [0/49]	Time 12.147 (12.147)	Loss 1.9820 (1.9820)	Acc@1 57.227 (57.227)	Acc@5 83.105 (83.105)	Mem 5329MB
[2022-04-18 07:13:23 tiny] (main.py 279): INFO  * Acc@1 61.010 Acc@5 84.258
[2022-04-18 07:13:23 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 61.0%
[2022-04-18 07:13:23 tiny] (main.py 148): INFO Max accuracy: 61.69%
[2022-04-18 07:13:34 tiny] (main.py 226): INFO Train: [51/300][0/1251]	eta 3:45:04 lr 0.000931	time 10.7952 (10.7952)	loss 2.9908 (2.9908)	grad_norm 1.8042 (1.8042)	mem 5329MB
[2022-04-18 07:14:37 tiny] (main.py 226): INFO Train: [51/300][100/1251]	eta 0:14:01 lr 0.000931	time 0.4944 (0.7310)	loss 3.6177 (4.3027)	grad_norm 4.7209 (2.9041)	mem 5329MB
[2022-04-18 07:15:35 tiny] (main.py 226): INFO Train: [51/300][200/1251]	eta 0:11:31 lr 0.000931	time 0.5964 (0.6582)	loss 5.0286 (4.2941)	grad_norm 2.8088 (2.8218)	mem 5329MB
[2022-04-18 07:16:34 tiny] (main.py 226): INFO Train: [51/300][300/1251]	eta 0:10:04 lr 0.000930	time 0.5394 (0.6354)	loss 4.4742 (4.2806)	grad_norm 3.2178 (2.7672)	mem 5329MB
[2022-04-18 07:17:32 tiny] (main.py 226): INFO Train: [51/300][400/1251]	eta 0:08:49 lr 0.000930	time 0.5853 (0.6217)	loss 4.3438 (4.2586)	grad_norm 3.7201 (2.7583)	mem 5329MB
[2022-04-18 07:18:31 tiny] (main.py 226): INFO Train: [51/300][500/1251]	eta 0:07:41 lr 0.000930	time 0.5348 (0.6146)	loss 4.8681 (4.2628)	grad_norm 2.6104 (2.7398)	mem 5329MB
[2022-04-18 07:19:29 tiny] (main.py 226): INFO Train: [51/300][600/1251]	eta 0:06:37 lr 0.000930	time 0.7918 (0.6100)	loss 4.1091 (4.2646)	grad_norm 4.0439 (2.7632)	mem 5329MB
[2022-04-18 07:20:28 tiny] (main.py 226): INFO Train: [51/300][700/1251]	eta 0:05:34 lr 0.000930	time 0.5732 (0.6072)	loss 3.3143 (4.2652)	grad_norm 3.2177 (2.7547)	mem 5329MB
[2022-04-18 07:21:27 tiny] (main.py 226): INFO Train: [51/300][800/1251]	eta 0:04:32 lr 0.000929	time 0.5427 (0.6043)	loss 4.1167 (4.2612)	grad_norm 3.0824 (2.7500)	mem 5329MB
[2022-04-18 07:22:25 tiny] (main.py 226): INFO Train: [51/300][900/1251]	eta 0:03:31 lr 0.000929	time 0.4851 (0.6024)	loss 4.3561 (4.2596)	grad_norm 3.5365 (2.7404)	mem 5329MB
[2022-04-18 07:23:24 tiny] (main.py 226): INFO Train: [51/300][1000/1251]	eta 0:02:30 lr 0.000929	time 0.5782 (0.6011)	loss 3.6192 (4.2516)	grad_norm 3.1083 (2.7515)	mem 5329MB
[2022-04-18 07:24:23 tiny] (main.py 226): INFO Train: [51/300][1100/1251]	eta 0:01:30 lr 0.000929	time 0.4817 (0.5999)	loss 4.4472 (4.2542)	grad_norm 2.3003 (2.7512)	mem 5329MB
[2022-04-18 07:25:22 tiny] (main.py 226): INFO Train: [51/300][1200/1251]	eta 0:00:30 lr 0.000929	time 0.6635 (0.5991)	loss 3.8890 (4.2549)	grad_norm 2.9224 (2.7443)	mem 5329MB
[2022-04-18 07:25:44 tiny] (main.py 233): INFO EPOCH 51 training takes 0:12:21
[2022-04-18 07:25:56 tiny] (main.py 273): INFO Test: [0/49]	Time 11.841 (11.841)	Loss 1.8215 (1.8215)	Acc@1 64.062 (64.062)	Acc@5 84.570 (84.570)	Mem 5329MB
[2022-04-18 07:26:15 tiny] (main.py 279): INFO  * Acc@1 61.518 Acc@5 84.152
[2022-04-18 07:26:15 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 61.5%
[2022-04-18 07:26:15 tiny] (main.py 148): INFO Max accuracy: 61.69%
[2022-04-18 07:26:26 tiny] (main.py 226): INFO Train: [52/300][0/1251]	eta 3:54:21 lr 0.000928	time 11.2405 (11.2405)	loss 3.8640 (3.8640)	grad_norm 3.8510 (3.8510)	mem 5329MB
[2022-04-18 07:27:28 tiny] (main.py 226): INFO Train: [52/300][100/1251]	eta 0:13:56 lr 0.000928	time 0.7110 (0.7264)	loss 5.1139 (4.2467)	grad_norm 2.5538 (2.8127)	mem 5329MB
[2022-04-18 07:28:27 tiny] (main.py 226): INFO Train: [52/300][200/1251]	eta 0:11:30 lr 0.000928	time 0.6896 (0.6571)	loss 4.3206 (4.3276)	grad_norm 2.3549 (2.8312)	mem 5329MB
[2022-04-18 07:29:25 tiny] (main.py 226): INFO Train: [52/300][300/1251]	eta 0:10:01 lr 0.000928	time 0.5114 (0.6328)	loss 4.9787 (4.2939)	grad_norm 1.9691 (2.7543)	mem 5329MB
[2022-04-18 07:30:24 tiny] (main.py 226): INFO Train: [52/300][400/1251]	eta 0:08:48 lr 0.000928	time 0.6036 (0.6206)	loss 4.7301 (4.3044)	grad_norm 3.0706 (2.7322)	mem 5329MB
[2022-04-18 07:31:22 tiny] (main.py 226): INFO Train: [52/300][500/1251]	eta 0:07:40 lr 0.000927	time 0.5667 (0.6132)	loss 4.9603 (4.3238)	grad_norm 2.1330 (2.7654)	mem 5329MB
[2022-04-18 07:32:21 tiny] (main.py 226): INFO Train: [52/300][600/1251]	eta 0:06:36 lr 0.000927	time 0.6410 (0.6096)	loss 4.1267 (4.3042)	grad_norm 2.3502 (2.7502)	mem 5329MB
[2022-04-18 07:33:20 tiny] (main.py 226): INFO Train: [52/300][700/1251]	eta 0:05:34 lr 0.000927	time 0.6556 (0.6072)	loss 4.1982 (4.2883)	grad_norm 1.6287 (2.7416)	mem 5329MB
[2022-04-18 07:34:19 tiny] (main.py 226): INFO Train: [52/300][800/1251]	eta 0:04:32 lr 0.000927	time 0.6656 (0.6045)	loss 4.9821 (4.2781)	grad_norm 3.1966 (2.7388)	mem 5329MB
[2022-04-18 07:35:18 tiny] (main.py 226): INFO Train: [52/300][900/1251]	eta 0:03:31 lr 0.000926	time 0.4430 (0.6025)	loss 4.5569 (4.2811)	grad_norm 1.7700 (2.7529)	mem 5329MB
[2022-04-18 07:36:17 tiny] (main.py 226): INFO Train: [52/300][1000/1251]	eta 0:02:30 lr 0.000926	time 0.5883 (0.6015)	loss 4.2632 (4.2785)	grad_norm 1.9514 (2.7691)	mem 5329MB
[2022-04-18 07:37:16 tiny] (main.py 226): INFO Train: [52/300][1100/1251]	eta 0:01:30 lr 0.000926	time 0.8060 (0.6003)	loss 4.4490 (4.2828)	grad_norm 3.7594 (2.7646)	mem 5329MB
[2022-04-18 07:38:15 tiny] (main.py 226): INFO Train: [52/300][1200/1251]	eta 0:00:30 lr 0.000926	time 0.5178 (0.5994)	loss 3.8846 (4.2846)	grad_norm 2.0446 (2.7711)	mem 5329MB
[2022-04-18 07:38:37 tiny] (main.py 233): INFO EPOCH 52 training takes 0:12:21
[2022-04-18 07:38:49 tiny] (main.py 273): INFO Test: [0/49]	Time 11.765 (11.765)	Loss 1.8043 (1.8043)	Acc@1 62.402 (62.402)	Acc@5 84.180 (84.180)	Mem 5329MB
[2022-04-18 07:39:08 tiny] (main.py 279): INFO  * Acc@1 61.702 Acc@5 84.374
[2022-04-18 07:39:08 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 61.7%
[2022-04-18 07:39:08 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_52.pth saving......
[2022-04-18 07:39:08 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_52.pth saved !!!
[2022-04-18 07:39:08 tiny] (main.py 148): INFO Max accuracy: 61.70%
[2022-04-18 07:39:20 tiny] (main.py 226): INFO Train: [53/300][0/1251]	eta 4:14:07 lr 0.000926	time 12.1886 (12.1886)	loss 4.5654 (4.5654)	grad_norm 1.9081 (1.9081)	mem 5329MB
[2022-04-18 07:40:22 tiny] (main.py 226): INFO Train: [53/300][100/1251]	eta 0:14:00 lr 0.000925	time 0.8354 (0.7300)	loss 3.9079 (4.2413)	grad_norm 1.9312 (2.6019)	mem 5329MB
[2022-04-18 07:41:20 tiny] (main.py 226): INFO Train: [53/300][200/1251]	eta 0:11:32 lr 0.000925	time 0.6588 (0.6586)	loss 4.9587 (4.2151)	grad_norm 2.2011 (inf)	mem 5329MB
[2022-04-18 07:42:18 tiny] (main.py 226): INFO Train: [53/300][300/1251]	eta 0:10:01 lr 0.000925	time 0.7265 (0.6323)	loss 3.0959 (4.2388)	grad_norm 2.9746 (inf)	mem 5329MB
[2022-04-18 07:43:17 tiny] (main.py 226): INFO Train: [53/300][400/1251]	eta 0:08:48 lr 0.000925	time 0.5871 (0.6207)	loss 4.4397 (4.2380)	grad_norm 1.7889 (inf)	mem 5329MB
[2022-04-18 07:44:15 tiny] (main.py 226): INFO Train: [53/300][500/1251]	eta 0:07:40 lr 0.000925	time 0.6639 (0.6130)	loss 4.6017 (4.2458)	grad_norm 4.7232 (inf)	mem 5329MB
[2022-04-18 07:45:14 tiny] (main.py 226): INFO Train: [53/300][600/1251]	eta 0:06:36 lr 0.000924	time 0.4756 (0.6092)	loss 4.5500 (4.2623)	grad_norm 2.5618 (inf)	mem 5329MB
[2022-04-18 07:46:13 tiny] (main.py 226): INFO Train: [53/300][700/1251]	eta 0:05:34 lr 0.000924	time 0.4382 (0.6068)	loss 3.4963 (4.2638)	grad_norm 2.0388 (inf)	mem 5329MB
[2022-04-18 07:47:12 tiny] (main.py 226): INFO Train: [53/300][800/1251]	eta 0:04:32 lr 0.000924	time 0.6350 (0.6041)	loss 3.6088 (4.2553)	grad_norm 1.8399 (inf)	mem 5329MB
[2022-04-18 07:48:11 tiny] (main.py 226): INFO Train: [53/300][900/1251]	eta 0:03:31 lr 0.000924	time 0.6486 (0.6030)	loss 4.3541 (4.2500)	grad_norm 1.4816 (inf)	mem 5329MB
[2022-04-18 07:49:10 tiny] (main.py 226): INFO Train: [53/300][1000/1251]	eta 0:02:30 lr 0.000923	time 0.5701 (0.6014)	loss 3.2455 (4.2458)	grad_norm 2.8282 (inf)	mem 5329MB
[2022-04-18 07:50:09 tiny] (main.py 226): INFO Train: [53/300][1100/1251]	eta 0:01:30 lr 0.000923	time 0.7425 (0.6006)	loss 4.0026 (4.2418)	grad_norm 1.6095 (inf)	mem 5329MB
[2022-04-18 07:51:08 tiny] (main.py 226): INFO Train: [53/300][1200/1251]	eta 0:00:30 lr 0.000923	time 0.5692 (0.5998)	loss 4.5173 (4.2418)	grad_norm 1.3581 (inf)	mem 5329MB
[2022-04-18 07:51:30 tiny] (main.py 233): INFO EPOCH 53 training takes 0:12:22
[2022-04-18 07:51:41 tiny] (main.py 273): INFO Test: [0/49]	Time 11.101 (11.101)	Loss 1.8431 (1.8431)	Acc@1 63.672 (63.672)	Acc@5 85.742 (85.742)	Mem 5329MB
[2022-04-18 07:52:02 tiny] (main.py 279): INFO  * Acc@1 61.578 Acc@5 84.164
[2022-04-18 07:52:02 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 61.6%
[2022-04-18 07:52:02 tiny] (main.py 148): INFO Max accuracy: 61.70%
[2022-04-18 07:52:14 tiny] (main.py 226): INFO Train: [54/300][0/1251]	eta 4:13:26 lr 0.000923	time 12.1557 (12.1557)	loss 2.9918 (2.9918)	grad_norm 4.0368 (4.0368)	mem 5329MB
[2022-04-18 07:53:16 tiny] (main.py 226): INFO Train: [54/300][100/1251]	eta 0:13:59 lr 0.000923	time 0.4324 (0.7290)	loss 4.5971 (4.2913)	grad_norm 1.5607 (2.6504)	mem 5329MB
[2022-04-18 07:54:14 tiny] (main.py 226): INFO Train: [54/300][200/1251]	eta 0:11:31 lr 0.000922	time 0.5923 (0.6576)	loss 4.3400 (4.3037)	grad_norm 1.9265 (2.7483)	mem 5329MB
[2022-04-18 07:55:12 tiny] (main.py 226): INFO Train: [54/300][300/1251]	eta 0:10:01 lr 0.000922	time 0.4889 (0.6325)	loss 4.1947 (4.2707)	grad_norm 1.6429 (2.7543)	mem 5329MB
[2022-04-18 07:56:12 tiny] (main.py 226): INFO Train: [54/300][400/1251]	eta 0:08:49 lr 0.000922	time 0.6894 (0.6223)	loss 4.6324 (4.2662)	grad_norm 2.5541 (2.7690)	mem 5329MB
[2022-04-18 07:57:10 tiny] (main.py 226): INFO Train: [54/300][500/1251]	eta 0:07:41 lr 0.000922	time 0.4985 (0.6147)	loss 2.8728 (4.2526)	grad_norm 1.7541 (2.7978)	mem 5329MB
[2022-04-18 07:58:09 tiny] (main.py 226): INFO Train: [54/300][600/1251]	eta 0:06:37 lr 0.000922	time 0.7202 (0.6105)	loss 4.1294 (4.2555)	grad_norm 2.1827 (2.7895)	mem 5329MB
[2022-04-18 07:59:08 tiny] (main.py 226): INFO Train: [54/300][700/1251]	eta 0:05:34 lr 0.000921	time 0.7140 (0.6073)	loss 4.6436 (4.2710)	grad_norm 2.0485 (2.7735)	mem 5329MB
[2022-04-18 08:00:07 tiny] (main.py 226): INFO Train: [54/300][800/1251]	eta 0:04:32 lr 0.000921	time 0.6364 (0.6049)	loss 4.5255 (4.2794)	grad_norm 3.5191 (2.7418)	mem 5329MB
[2022-04-18 08:01:05 tiny] (main.py 226): INFO Train: [54/300][900/1251]	eta 0:03:31 lr 0.000921	time 0.5847 (0.6029)	loss 4.7340 (4.2869)	grad_norm 4.7347 (2.7562)	mem 5329MB
[2022-04-18 08:02:04 tiny] (main.py 226): INFO Train: [54/300][1000/1251]	eta 0:02:30 lr 0.000921	time 0.6068 (0.6015)	loss 4.1244 (4.2874)	grad_norm 1.8031 (2.7576)	mem 5329MB
[2022-04-18 08:03:03 tiny] (main.py 226): INFO Train: [54/300][1100/1251]	eta 0:01:30 lr 0.000920	time 0.5199 (0.6001)	loss 4.8857 (4.2874)	grad_norm 2.1906 (2.7305)	mem 5329MB
[2022-04-18 08:04:02 tiny] (main.py 226): INFO Train: [54/300][1200/1251]	eta 0:00:30 lr 0.000920	time 0.6273 (0.5995)	loss 4.9061 (4.2852)	grad_norm 2.2035 (2.7339)	mem 5329MB
[2022-04-18 08:04:24 tiny] (main.py 233): INFO EPOCH 54 training takes 0:12:21
[2022-04-18 08:04:35 tiny] (main.py 273): INFO Test: [0/49]	Time 11.321 (11.321)	Loss 1.8231 (1.8231)	Acc@1 63.281 (63.281)	Acc@5 84.277 (84.277)	Mem 5329MB
[2022-04-18 08:04:55 tiny] (main.py 279): INFO  * Acc@1 61.146 Acc@5 84.120
[2022-04-18 08:04:55 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 61.1%
[2022-04-18 08:04:55 tiny] (main.py 148): INFO Max accuracy: 61.70%
[2022-04-18 08:05:07 tiny] (main.py 226): INFO Train: [55/300][0/1251]	eta 4:12:58 lr 0.000920	time 12.1331 (12.1331)	loss 4.3975 (4.3975)	grad_norm 4.1374 (4.1374)	mem 5329MB
[2022-04-18 08:06:08 tiny] (main.py 226): INFO Train: [55/300][100/1251]	eta 0:13:58 lr 0.000920	time 0.4922 (0.7286)	loss 4.7055 (4.2218)	grad_norm 2.3011 (2.8013)	mem 5329MB
[2022-04-18 08:07:07 tiny] (main.py 226): INFO Train: [55/300][200/1251]	eta 0:11:31 lr 0.000920	time 0.5736 (0.6575)	loss 4.5849 (4.2768)	grad_norm 2.3256 (inf)	mem 5329MB
[2022-04-18 08:08:06 tiny] (main.py 226): INFO Train: [55/300][300/1251]	eta 0:10:02 lr 0.000919	time 0.6194 (0.6340)	loss 3.6948 (4.2408)	grad_norm 2.2866 (inf)	mem 5329MB
[2022-04-18 08:09:04 tiny] (main.py 226): INFO Train: [55/300][400/1251]	eta 0:08:49 lr 0.000919	time 0.6788 (0.6225)	loss 3.0243 (4.2299)	grad_norm 1.9726 (inf)	mem 5329MB
[2022-04-18 08:10:03 tiny] (main.py 226): INFO Train: [55/300][500/1251]	eta 0:07:41 lr 0.000919	time 0.5298 (0.6147)	loss 3.3893 (4.2255)	grad_norm 3.0308 (inf)	mem 5329MB
[2022-04-18 08:11:02 tiny] (main.py 226): INFO Train: [55/300][600/1251]	eta 0:06:37 lr 0.000919	time 0.4787 (0.6105)	loss 3.9811 (4.2317)	grad_norm 3.0681 (inf)	mem 5329MB
[2022-04-18 08:12:01 tiny] (main.py 226): INFO Train: [55/300][700/1251]	eta 0:05:34 lr 0.000919	time 0.8310 (0.6076)	loss 4.9854 (4.2431)	grad_norm 2.8635 (inf)	mem 5329MB
[2022-04-18 08:12:59 tiny] (main.py 226): INFO Train: [55/300][800/1251]	eta 0:04:32 lr 0.000918	time 0.6579 (0.6046)	loss 3.2352 (4.2331)	grad_norm 3.2661 (inf)	mem 5329MB
[2022-04-18 08:13:58 tiny] (main.py 226): INFO Train: [55/300][900/1251]	eta 0:03:31 lr 0.000918	time 0.6187 (0.6032)	loss 4.5882 (4.2313)	grad_norm 3.0105 (inf)	mem 5329MB
[2022-04-18 08:14:57 tiny] (main.py 226): INFO Train: [55/300][1000/1251]	eta 0:02:31 lr 0.000918	time 0.5938 (0.6017)	loss 4.7474 (4.2432)	grad_norm 2.6519 (inf)	mem 5329MB
[2022-04-18 08:15:56 tiny] (main.py 226): INFO Train: [55/300][1100/1251]	eta 0:01:30 lr 0.000918	time 0.7122 (0.6003)	loss 4.4524 (4.2358)	grad_norm 3.2621 (inf)	mem 5329MB
[2022-04-18 08:16:55 tiny] (main.py 226): INFO Train: [55/300][1200/1251]	eta 0:00:30 lr 0.000917	time 0.6813 (0.5995)	loss 3.2236 (4.2309)	grad_norm 1.7460 (inf)	mem 5329MB
[2022-04-18 08:17:16 tiny] (main.py 233): INFO EPOCH 55 training takes 0:12:21
[2022-04-18 08:17:29 tiny] (main.py 273): INFO Test: [0/49]	Time 12.402 (12.402)	Loss 1.7939 (1.7939)	Acc@1 62.109 (62.109)	Acc@5 85.547 (85.547)	Mem 5329MB
[2022-04-18 08:17:48 tiny] (main.py 279): INFO  * Acc@1 61.386 Acc@5 84.174
[2022-04-18 08:17:48 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 61.4%
[2022-04-18 08:17:48 tiny] (main.py 148): INFO Max accuracy: 61.70%
[2022-04-18 08:18:00 tiny] (main.py 226): INFO Train: [56/300][0/1251]	eta 4:11:32 lr 0.000917	time 12.0647 (12.0647)	loss 3.9999 (3.9999)	grad_norm 3.4638 (3.4638)	mem 5329MB
[2022-04-18 08:19:01 tiny] (main.py 226): INFO Train: [56/300][100/1251]	eta 0:14:01 lr 0.000917	time 0.4547 (0.7313)	loss 3.3234 (4.2061)	grad_norm 2.3723 (2.8411)	mem 5329MB
[2022-04-18 08:20:00 tiny] (main.py 226): INFO Train: [56/300][200/1251]	eta 0:11:30 lr 0.000917	time 0.4643 (0.6571)	loss 3.3851 (4.2112)	grad_norm 2.0873 (2.7687)	mem 5329MB
[2022-04-18 08:20:58 tiny] (main.py 226): INFO Train: [56/300][300/1251]	eta 0:10:01 lr 0.000917	time 0.5581 (0.6322)	loss 4.7332 (4.2365)	grad_norm 3.7615 (2.7750)	mem 5329MB
[2022-04-18 08:21:57 tiny] (main.py 226): INFO Train: [56/300][400/1251]	eta 0:08:48 lr 0.000916	time 0.5695 (0.6210)	loss 5.0144 (4.2588)	grad_norm 5.5412 (2.7668)	mem 5329MB
[2022-04-18 08:22:56 tiny] (main.py 226): INFO Train: [56/300][500/1251]	eta 0:07:41 lr 0.000916	time 0.6961 (0.6147)	loss 4.6655 (4.2557)	grad_norm 1.7975 (2.7856)	mem 5329MB
[2022-04-18 08:23:54 tiny] (main.py 226): INFO Train: [56/300][600/1251]	eta 0:06:37 lr 0.000916	time 0.5563 (0.6100)	loss 4.4018 (4.2584)	grad_norm 1.8616 (2.7443)	mem 5329MB
[2022-04-18 08:24:53 tiny] (main.py 226): INFO Train: [56/300][700/1251]	eta 0:05:34 lr 0.000916	time 0.4208 (0.6067)	loss 3.3933 (4.2655)	grad_norm 2.5142 (2.7118)	mem 5329MB
[2022-04-18 08:25:52 tiny] (main.py 226): INFO Train: [56/300][800/1251]	eta 0:04:32 lr 0.000915	time 0.5013 (0.6045)	loss 4.6757 (4.2542)	grad_norm 1.8831 (2.7255)	mem 5329MB
[2022-04-18 08:26:51 tiny] (main.py 226): INFO Train: [56/300][900/1251]	eta 0:03:31 lr 0.000915	time 0.6608 (0.6028)	loss 4.6040 (4.2559)	grad_norm 2.1428 (2.7280)	mem 5329MB
[2022-04-18 08:27:49 tiny] (main.py 226): INFO Train: [56/300][1000/1251]	eta 0:02:30 lr 0.000915	time 0.5544 (0.6012)	loss 4.8459 (4.2677)	grad_norm 1.8369 (2.7230)	mem 5329MB
[2022-04-18 08:28:47 tiny] (main.py 226): INFO Train: [56/300][1100/1251]	eta 0:01:30 lr 0.000915	time 0.5953 (0.5994)	loss 3.3730 (4.2600)	grad_norm 2.8574 (inf)	mem 5329MB
[2022-04-18 08:29:47 tiny] (main.py 226): INFO Train: [56/300][1200/1251]	eta 0:00:30 lr 0.000915	time 0.5762 (0.5988)	loss 3.6477 (4.2606)	grad_norm 1.7321 (inf)	mem 5329MB
[2022-04-18 08:30:08 tiny] (main.py 233): INFO EPOCH 56 training takes 0:12:20
[2022-04-18 08:30:20 tiny] (main.py 273): INFO Test: [0/49]	Time 12.028 (12.028)	Loss 1.9988 (1.9988)	Acc@1 60.352 (60.352)	Acc@5 83.789 (83.789)	Mem 5329MB
[2022-04-18 08:30:40 tiny] (main.py 279): INFO  * Acc@1 61.608 Acc@5 84.406
[2022-04-18 08:30:40 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 61.6%
[2022-04-18 08:30:40 tiny] (main.py 148): INFO Max accuracy: 61.70%
[2022-04-18 08:30:52 tiny] (main.py 226): INFO Train: [57/300][0/1251]	eta 4:07:34 lr 0.000914	time 11.8741 (11.8741)	loss 2.8789 (2.8789)	grad_norm 2.7678 (2.7678)	mem 5329MB
[2022-04-18 08:31:53 tiny] (main.py 226): INFO Train: [57/300][100/1251]	eta 0:13:59 lr 0.000914	time 0.6406 (0.7296)	loss 4.6110 (4.1383)	grad_norm 3.2363 (2.6322)	mem 5329MB
[2022-04-18 08:32:52 tiny] (main.py 226): INFO Train: [57/300][200/1251]	eta 0:11:29 lr 0.000914	time 0.4848 (0.6562)	loss 3.3810 (4.2106)	grad_norm 2.0441 (2.7650)	mem 5329MB
[2022-04-18 08:33:50 tiny] (main.py 226): INFO Train: [57/300][300/1251]	eta 0:10:01 lr 0.000914	time 0.5060 (0.6327)	loss 3.3918 (4.1878)	grad_norm 2.1247 (2.7966)	mem 5329MB
[2022-04-18 08:34:49 tiny] (main.py 226): INFO Train: [57/300][400/1251]	eta 0:08:48 lr 0.000913	time 0.6321 (0.6214)	loss 4.5255 (4.2208)	grad_norm 4.1340 (2.7676)	mem 5329MB
[2022-04-18 08:35:47 tiny] (main.py 226): INFO Train: [57/300][500/1251]	eta 0:07:40 lr 0.000913	time 0.6305 (0.6132)	loss 4.6978 (4.2188)	grad_norm 2.6633 (2.7604)	mem 5329MB
[2022-04-18 08:36:46 tiny] (main.py 226): INFO Train: [57/300][600/1251]	eta 0:06:36 lr 0.000913	time 0.6236 (0.6093)	loss 3.1086 (4.2104)	grad_norm 3.1170 (2.7815)	mem 5329MB
[2022-04-18 08:37:45 tiny] (main.py 226): INFO Train: [57/300][700/1251]	eta 0:05:34 lr 0.000913	time 0.6028 (0.6064)	loss 5.1419 (4.2208)	grad_norm 3.0804 (2.8165)	mem 5329MB
[2022-04-18 08:38:44 tiny] (main.py 226): INFO Train: [57/300][800/1251]	eta 0:04:32 lr 0.000913	time 0.6541 (0.6041)	loss 4.2177 (4.2259)	grad_norm 3.7168 (2.8271)	mem 5329MB
[2022-04-18 08:39:42 tiny] (main.py 226): INFO Train: [57/300][900/1251]	eta 0:03:31 lr 0.000912	time 0.4098 (0.6022)	loss 4.6335 (4.2180)	grad_norm 2.4572 (2.8247)	mem 5329MB
[2022-04-18 08:40:41 tiny] (main.py 226): INFO Train: [57/300][1000/1251]	eta 0:02:30 lr 0.000912	time 0.5496 (0.6005)	loss 4.0080 (4.2329)	grad_norm 2.4595 (2.7945)	mem 5329MB
[2022-04-18 08:41:40 tiny] (main.py 226): INFO Train: [57/300][1100/1251]	eta 0:01:30 lr 0.000912	time 0.8124 (0.5998)	loss 4.4375 (4.2286)	grad_norm 2.3120 (2.8070)	mem 5329MB
[2022-04-18 08:42:39 tiny] (main.py 226): INFO Train: [57/300][1200/1251]	eta 0:00:30 lr 0.000912	time 0.7194 (0.5986)	loss 4.7100 (4.2254)	grad_norm 2.8636 (2.7985)	mem 5329MB
[2022-04-18 08:43:00 tiny] (main.py 233): INFO EPOCH 57 training takes 0:12:20
[2022-04-18 08:43:13 tiny] (main.py 273): INFO Test: [0/49]	Time 12.213 (12.213)	Loss 1.9123 (1.9123)	Acc@1 60.645 (60.645)	Acc@5 84.375 (84.375)	Mem 5329MB
[2022-04-18 08:43:32 tiny] (main.py 279): INFO  * Acc@1 62.128 Acc@5 84.682
[2022-04-18 08:43:32 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 62.1%
[2022-04-18 08:43:32 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_57.pth saving......
[2022-04-18 08:43:32 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_57.pth saved !!!
[2022-04-18 08:43:32 tiny] (main.py 148): INFO Max accuracy: 62.13%
[2022-04-18 08:43:43 tiny] (main.py 226): INFO Train: [58/300][0/1251]	eta 3:52:47 lr 0.000911	time 11.1654 (11.1654)	loss 4.5461 (4.5461)	grad_norm 2.4196 (2.4196)	mem 5329MB
[2022-04-18 08:44:45 tiny] (main.py 226): INFO Train: [58/300][100/1251]	eta 0:13:54 lr 0.000911	time 0.7977 (0.7249)	loss 5.0751 (4.1820)	grad_norm 2.3070 (2.8613)	mem 5329MB
[2022-04-18 08:45:44 tiny] (main.py 226): INFO Train: [58/300][200/1251]	eta 0:11:31 lr 0.000911	time 0.5309 (0.6579)	loss 3.5421 (4.2098)	grad_norm 3.9551 (2.8515)	mem 5329MB
[2022-04-18 08:46:42 tiny] (main.py 226): INFO Train: [58/300][300/1251]	eta 0:10:02 lr 0.000911	time 0.4247 (0.6333)	loss 4.7074 (4.2134)	grad_norm 1.9788 (2.9146)	mem 5329MB
[2022-04-18 08:47:41 tiny] (main.py 226): INFO Train: [58/300][400/1251]	eta 0:08:48 lr 0.000911	time 0.5021 (0.6211)	loss 4.1174 (4.2356)	grad_norm 3.1292 (2.9199)	mem 5329MB
[2022-04-18 08:48:39 tiny] (main.py 226): INFO Train: [58/300][500/1251]	eta 0:07:40 lr 0.000910	time 0.6415 (0.6138)	loss 3.1119 (4.2485)	grad_norm 2.0309 (2.8689)	mem 5329MB
[2022-04-18 08:49:38 tiny] (main.py 226): INFO Train: [58/300][600/1251]	eta 0:06:36 lr 0.000910	time 0.6129 (0.6092)	loss 4.6277 (4.2664)	grad_norm 2.3692 (2.8421)	mem 5329MB
[2022-04-18 08:50:37 tiny] (main.py 226): INFO Train: [58/300][700/1251]	eta 0:05:34 lr 0.000910	time 0.7424 (0.6067)	loss 4.6038 (4.2684)	grad_norm 3.0493 (2.8616)	mem 5329MB
[2022-04-18 08:51:36 tiny] (main.py 226): INFO Train: [58/300][800/1251]	eta 0:04:32 lr 0.000910	time 0.5277 (0.6041)	loss 3.1792 (4.2659)	grad_norm 3.7581 (2.8407)	mem 5329MB
[2022-04-18 08:52:34 tiny] (main.py 226): INFO Train: [58/300][900/1251]	eta 0:03:31 lr 0.000909	time 0.4765 (0.6023)	loss 4.2713 (4.2646)	grad_norm 4.2613 (2.8477)	mem 5329MB
[2022-04-18 08:53:34 tiny] (main.py 226): INFO Train: [58/300][1000/1251]	eta 0:02:30 lr 0.000909	time 0.7328 (0.6014)	loss 3.8815 (4.2606)	grad_norm 3.9740 (2.8114)	mem 5329MB
[2022-04-18 08:54:32 tiny] (main.py 226): INFO Train: [58/300][1100/1251]	eta 0:01:30 lr 0.000909	time 0.7784 (0.6000)	loss 4.3668 (4.2583)	grad_norm 3.1972 (2.8140)	mem 5329MB
[2022-04-18 08:55:31 tiny] (main.py 226): INFO Train: [58/300][1200/1251]	eta 0:00:30 lr 0.000909	time 0.5218 (0.5986)	loss 4.5047 (4.2515)	grad_norm 2.6762 (2.8384)	mem 5329MB
[2022-04-18 08:55:53 tiny] (main.py 233): INFO EPOCH 58 training takes 0:12:20
[2022-04-18 08:56:05 tiny] (main.py 273): INFO Test: [0/49]	Time 12.778 (12.778)	Loss 1.6845 (1.6845)	Acc@1 65.039 (65.039)	Acc@5 86.621 (86.621)	Mem 5329MB
[2022-04-18 08:56:24 tiny] (main.py 279): INFO  * Acc@1 62.584 Acc@5 85.106
[2022-04-18 08:56:24 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 62.6%
[2022-04-18 08:56:24 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_58.pth saving......
[2022-04-18 08:56:24 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_58.pth saved !!!
[2022-04-18 08:56:24 tiny] (main.py 148): INFO Max accuracy: 62.58%
[2022-04-18 08:56:36 tiny] (main.py 226): INFO Train: [59/300][0/1251]	eta 4:03:53 lr 0.000908	time 11.6971 (11.6971)	loss 4.4257 (4.4257)	grad_norm 2.3331 (2.3331)	mem 5329MB
[2022-04-18 08:57:38 tiny] (main.py 226): INFO Train: [59/300][100/1251]	eta 0:13:58 lr 0.000908	time 0.5033 (0.7288)	loss 3.6639 (4.1813)	grad_norm 4.1910 (2.7898)	mem 5329MB
[2022-04-18 08:58:36 tiny] (main.py 226): INFO Train: [59/300][200/1251]	eta 0:11:28 lr 0.000908	time 0.5041 (0.6552)	loss 4.6621 (4.1960)	grad_norm 2.9227 (2.8623)	mem 5329MB
[2022-04-18 08:59:34 tiny] (main.py 226): INFO Train: [59/300][300/1251]	eta 0:10:01 lr 0.000908	time 0.5793 (0.6320)	loss 4.4292 (4.2183)	grad_norm 1.9408 (inf)	mem 5329MB
[2022-04-18 09:00:33 tiny] (main.py 226): INFO Train: [59/300][400/1251]	eta 0:08:47 lr 0.000908	time 0.7914 (0.6204)	loss 3.6679 (4.2205)	grad_norm 2.4724 (inf)	mem 5329MB
[2022-04-18 09:01:32 tiny] (main.py 226): INFO Train: [59/300][500/1251]	eta 0:07:40 lr 0.000907	time 0.6671 (0.6137)	loss 3.8741 (4.2136)	grad_norm 2.9434 (inf)	mem 5329MB
[2022-04-18 09:02:31 tiny] (main.py 226): INFO Train: [59/300][600/1251]	eta 0:06:36 lr 0.000907	time 0.6615 (0.6098)	loss 4.7664 (4.2351)	grad_norm 2.3555 (inf)	mem 5329MB
[2022-04-18 09:03:29 tiny] (main.py 226): INFO Train: [59/300][700/1251]	eta 0:05:34 lr 0.000907	time 0.6622 (0.6064)	loss 4.3903 (4.2338)	grad_norm 3.8508 (inf)	mem 5329MB
[2022-04-18 09:04:28 tiny] (main.py 226): INFO Train: [59/300][800/1251]	eta 0:04:32 lr 0.000907	time 0.5293 (0.6046)	loss 3.3356 (4.2349)	grad_norm 3.4233 (inf)	mem 5329MB
[2022-04-18 09:05:27 tiny] (main.py 226): INFO Train: [59/300][900/1251]	eta 0:03:31 lr 0.000906	time 0.5140 (0.6027)	loss 4.3713 (4.2389)	grad_norm 2.2971 (inf)	mem 5329MB
[2022-04-18 09:06:26 tiny] (main.py 226): INFO Train: [59/300][1000/1251]	eta 0:02:30 lr 0.000906	time 0.6114 (0.6012)	loss 3.4117 (4.2472)	grad_norm 3.0637 (inf)	mem 5329MB
[2022-04-18 09:07:25 tiny] (main.py 226): INFO Train: [59/300][1100/1251]	eta 0:01:30 lr 0.000906	time 0.5726 (0.6001)	loss 4.7313 (4.2478)	grad_norm 2.0875 (inf)	mem 5329MB
[2022-04-18 09:08:24 tiny] (main.py 226): INFO Train: [59/300][1200/1251]	eta 0:00:30 lr 0.000906	time 0.4820 (0.5993)	loss 4.5926 (4.2411)	grad_norm 2.8663 (inf)	mem 5329MB
[2022-04-18 09:08:46 tiny] (main.py 233): INFO EPOCH 59 training takes 0:12:21
[2022-04-18 09:08:57 tiny] (main.py 273): INFO Test: [0/49]	Time 11.726 (11.726)	Loss 1.7752 (1.7752)	Acc@1 62.793 (62.793)	Acc@5 86.523 (86.523)	Mem 5329MB
[2022-04-18 09:09:16 tiny] (main.py 279): INFO  * Acc@1 62.212 Acc@5 84.958
[2022-04-18 09:09:16 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 62.2%
[2022-04-18 09:09:16 tiny] (main.py 148): INFO Max accuracy: 62.58%
[2022-04-18 09:09:29 tiny] (main.py 226): INFO Train: [60/300][0/1251]	eta 4:23:39 lr 0.000905	time 12.6453 (12.6453)	loss 4.2005 (4.2005)	grad_norm 4.1767 (4.1767)	mem 5329MB
[2022-04-18 09:10:30 tiny] (main.py 226): INFO Train: [60/300][100/1251]	eta 0:14:02 lr 0.000905	time 0.4933 (0.7317)	loss 5.1146 (4.1999)	grad_norm 2.4383 (2.7693)	mem 5329MB
[2022-04-18 09:11:28 tiny] (main.py 226): INFO Train: [60/300][200/1251]	eta 0:11:29 lr 0.000905	time 0.4705 (0.6563)	loss 4.2815 (4.2272)	grad_norm 2.7558 (2.7664)	mem 5329MB
[2022-04-18 09:12:27 tiny] (main.py 226): INFO Train: [60/300][300/1251]	eta 0:10:02 lr 0.000905	time 0.6843 (0.6332)	loss 5.2129 (4.2296)	grad_norm 2.1233 (2.8508)	mem 5329MB
[2022-04-18 09:13:26 tiny] (main.py 226): INFO Train: [60/300][400/1251]	eta 0:08:49 lr 0.000904	time 0.6104 (0.6219)	loss 4.9294 (4.2390)	grad_norm 3.0550 (2.8275)	mem 5329MB
[2022-04-18 09:14:24 tiny] (main.py 226): INFO Train: [60/300][500/1251]	eta 0:07:41 lr 0.000904	time 0.5866 (0.6146)	loss 4.1537 (4.2388)	grad_norm 2.7167 (2.8710)	mem 5329MB
[2022-04-18 09:15:23 tiny] (main.py 226): INFO Train: [60/300][600/1251]	eta 0:06:37 lr 0.000904	time 0.5019 (0.6102)	loss 4.3561 (4.2566)	grad_norm 2.6771 (2.8558)	mem 5329MB
[2022-04-18 09:16:22 tiny] (main.py 226): INFO Train: [60/300][700/1251]	eta 0:05:34 lr 0.000904	time 0.6674 (0.6072)	loss 4.2740 (4.2617)	grad_norm 3.6401 (2.8487)	mem 5329MB
[2022-04-18 09:17:21 tiny] (main.py 226): INFO Train: [60/300][800/1251]	eta 0:04:32 lr 0.000904	time 0.6207 (0.6048)	loss 3.4073 (4.2561)	grad_norm 3.5809 (2.8422)	mem 5329MB
[2022-04-18 09:18:20 tiny] (main.py 226): INFO Train: [60/300][900/1251]	eta 0:03:31 lr 0.000903	time 0.5126 (0.6033)	loss 2.7446 (4.2486)	grad_norm 1.9590 (2.8379)	mem 5329MB
[2022-04-18 09:19:19 tiny] (main.py 226): INFO Train: [60/300][1000/1251]	eta 0:02:31 lr 0.000903	time 0.7220 (0.6020)	loss 3.3167 (4.2378)	grad_norm 1.5477 (2.8504)	mem 5329MB
[2022-04-18 09:20:18 tiny] (main.py 226): INFO Train: [60/300][1100/1251]	eta 0:01:30 lr 0.000903	time 0.6428 (0.6004)	loss 3.2709 (4.2441)	grad_norm 2.6556 (2.8492)	mem 5329MB
[2022-04-18 09:21:16 tiny] (main.py 226): INFO Train: [60/300][1200/1251]	eta 0:00:30 lr 0.000903	time 0.6608 (0.5994)	loss 4.8382 (4.2445)	grad_norm 2.8442 (2.8524)	mem 5329MB
[2022-04-18 09:21:38 tiny] (main.py 233): INFO EPOCH 60 training takes 0:12:21
[2022-04-18 09:21:49 tiny] (main.py 273): INFO Test: [0/49]	Time 11.017 (11.017)	Loss 1.8064 (1.8064)	Acc@1 63.477 (63.477)	Acc@5 84.961 (84.961)	Mem 5329MB
[2022-04-18 09:22:09 tiny] (main.py 279): INFO  * Acc@1 62.702 Acc@5 85.090
[2022-04-18 09:22:09 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 62.7%
[2022-04-18 09:22:09 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_60.pth saving......
[2022-04-18 09:22:09 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_60.pth saved !!!
[2022-04-18 09:22:09 tiny] (main.py 148): INFO Max accuracy: 62.70%
[2022-04-18 09:22:21 tiny] (main.py 226): INFO Train: [61/300][0/1251]	eta 4:07:14 lr 0.000902	time 11.8585 (11.8585)	loss 4.7931 (4.7931)	grad_norm 2.6861 (2.6861)	mem 5329MB
[2022-04-18 09:23:23 tiny] (main.py 226): INFO Train: [61/300][100/1251]	eta 0:13:56 lr 0.000902	time 0.5360 (0.7264)	loss 4.8149 (4.1905)	grad_norm 2.8726 (3.0679)	mem 5329MB
[2022-04-18 09:24:22 tiny] (main.py 226): INFO Train: [61/300][200/1251]	eta 0:11:31 lr 0.000902	time 0.5329 (0.6578)	loss 4.0892 (4.1875)	grad_norm 1.5806 (2.8660)	mem 5329MB
[2022-04-18 09:25:20 tiny] (main.py 226): INFO Train: [61/300][300/1251]	eta 0:10:02 lr 0.000902	time 0.7143 (0.6340)	loss 4.8698 (4.2115)	grad_norm 3.5396 (inf)	mem 5329MB
[2022-04-18 09:26:18 tiny] (main.py 226): INFO Train: [61/300][400/1251]	eta 0:08:48 lr 0.000901	time 0.6591 (0.6210)	loss 4.6674 (4.2188)	grad_norm 2.8370 (inf)	mem 5329MB
[2022-04-18 09:27:17 tiny] (main.py 226): INFO Train: [61/300][500/1251]	eta 0:07:40 lr 0.000901	time 0.4801 (0.6137)	loss 3.0325 (4.2171)	grad_norm 2.1973 (inf)	mem 5329MB
[2022-04-18 09:28:16 tiny] (main.py 226): INFO Train: [61/300][600/1251]	eta 0:06:36 lr 0.000901	time 0.6531 (0.6095)	loss 3.9510 (4.2318)	grad_norm 1.8047 (inf)	mem 5329MB
[2022-04-18 09:29:14 tiny] (main.py 226): INFO Train: [61/300][700/1251]	eta 0:05:33 lr 0.000901	time 0.6524 (0.6059)	loss 3.3665 (4.2253)	grad_norm 1.7656 (inf)	mem 5329MB
[2022-04-18 09:30:13 tiny] (main.py 226): INFO Train: [61/300][800/1251]	eta 0:04:32 lr 0.000900	time 0.5403 (0.6037)	loss 4.6018 (4.2332)	grad_norm 2.8844 (inf)	mem 5329MB
[2022-04-18 09:31:12 tiny] (main.py 226): INFO Train: [61/300][900/1251]	eta 0:03:31 lr 0.000900	time 0.6146 (0.6024)	loss 4.7205 (4.2424)	grad_norm 1.9396 (inf)	mem 5329MB
[2022-04-18 09:32:11 tiny] (main.py 226): INFO Train: [61/300][1000/1251]	eta 0:02:30 lr 0.000900	time 0.4798 (0.6012)	loss 4.5983 (4.2440)	grad_norm 2.1406 (inf)	mem 5329MB
[2022-04-18 09:33:10 tiny] (main.py 226): INFO Train: [61/300][1100/1251]	eta 0:01:30 lr 0.000900	time 0.6796 (0.5999)	loss 4.0542 (4.2510)	grad_norm 2.2103 (inf)	mem 5329MB
[2022-04-18 09:34:08 tiny] (main.py 226): INFO Train: [61/300][1200/1251]	eta 0:00:30 lr 0.000899	time 0.4976 (0.5986)	loss 3.3041 (4.2458)	grad_norm 2.6121 (inf)	mem 5329MB
[2022-04-18 09:34:30 tiny] (main.py 233): INFO EPOCH 61 training takes 0:12:20
[2022-04-18 09:34:42 tiny] (main.py 273): INFO Test: [0/49]	Time 11.954 (11.954)	Loss 1.8914 (1.8914)	Acc@1 59.961 (59.961)	Acc@5 84.375 (84.375)	Mem 5329MB
[2022-04-18 09:35:01 tiny] (main.py 279): INFO  * Acc@1 62.662 Acc@5 84.916
[2022-04-18 09:35:01 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 62.7%
[2022-04-18 09:35:01 tiny] (main.py 148): INFO Max accuracy: 62.70%
[2022-04-18 09:35:13 tiny] (main.py 226): INFO Train: [62/300][0/1251]	eta 4:09:17 lr 0.000899	time 11.9568 (11.9568)	loss 4.7244 (4.7244)	grad_norm 3.2701 (3.2701)	mem 5329MB
[2022-04-18 09:36:15 tiny] (main.py 226): INFO Train: [62/300][100/1251]	eta 0:14:01 lr 0.000899	time 0.6153 (0.7315)	loss 4.8403 (4.1780)	grad_norm 2.3892 (3.0044)	mem 5329MB
[2022-04-18 09:37:14 tiny] (main.py 226): INFO Train: [62/300][200/1251]	eta 0:11:33 lr 0.000899	time 0.5378 (0.6594)	loss 4.5471 (4.1457)	grad_norm 2.1300 (2.8585)	mem 5329MB
[2022-04-18 09:38:12 tiny] (main.py 226): INFO Train: [62/300][300/1251]	eta 0:10:01 lr 0.000899	time 0.5961 (0.6330)	loss 4.1778 (4.1740)	grad_norm 3.6443 (2.8686)	mem 5329MB
[2022-04-18 09:39:11 tiny] (main.py 226): INFO Train: [62/300][400/1251]	eta 0:08:49 lr 0.000898	time 0.9340 (0.6225)	loss 4.7691 (4.2004)	grad_norm 1.8958 (2.8367)	mem 5329MB
[2022-04-18 09:40:09 tiny] (main.py 226): INFO Train: [62/300][500/1251]	eta 0:07:41 lr 0.000898	time 0.5109 (0.6150)	loss 4.0267 (4.1945)	grad_norm 2.0753 (2.8589)	mem 5329MB
[2022-04-18 09:41:08 tiny] (main.py 226): INFO Train: [62/300][600/1251]	eta 0:06:37 lr 0.000898	time 0.6367 (0.6107)	loss 3.7290 (4.2040)	grad_norm 3.9486 (2.8543)	mem 5329MB
[2022-04-18 09:42:07 tiny] (main.py 226): INFO Train: [62/300][700/1251]	eta 0:05:34 lr 0.000898	time 0.4144 (0.6070)	loss 4.7539 (4.2071)	grad_norm 2.2364 (2.8627)	mem 5329MB
[2022-04-18 09:43:06 tiny] (main.py 226): INFO Train: [62/300][800/1251]	eta 0:04:32 lr 0.000897	time 0.6307 (0.6052)	loss 3.2218 (4.2071)	grad_norm 5.6436 (2.8484)	mem 5329MB
[2022-04-18 09:44:05 tiny] (main.py 226): INFO Train: [62/300][900/1251]	eta 0:03:31 lr 0.000897	time 0.7901 (0.6034)	loss 3.8287 (4.2030)	grad_norm 1.8601 (2.8648)	mem 5329MB
[2022-04-18 09:45:04 tiny] (main.py 226): INFO Train: [62/300][1000/1251]	eta 0:02:31 lr 0.000897	time 0.4983 (0.6018)	loss 4.0800 (4.2028)	grad_norm 2.2934 (2.8532)	mem 5329MB
[2022-04-18 09:46:02 tiny] (main.py 226): INFO Train: [62/300][1100/1251]	eta 0:01:30 lr 0.000897	time 0.5845 (0.6004)	loss 4.4866 (4.2113)	grad_norm 3.0039 (2.8343)	mem 5329MB
[2022-04-18 09:47:00 tiny] (main.py 226): INFO Train: [62/300][1200/1251]	eta 0:00:30 lr 0.000896	time 0.4942 (0.5989)	loss 4.9275 (4.2173)	grad_norm 2.9246 (2.8317)	mem 5329MB
[2022-04-18 09:47:22 tiny] (main.py 233): INFO EPOCH 62 training takes 0:12:21
[2022-04-18 09:47:34 tiny] (main.py 273): INFO Test: [0/49]	Time 11.501 (11.501)	Loss 1.8082 (1.8082)	Acc@1 63.965 (63.965)	Acc@5 85.742 (85.742)	Mem 5329MB
[2022-04-18 09:47:53 tiny] (main.py 279): INFO  * Acc@1 61.894 Acc@5 84.550
[2022-04-18 09:47:53 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 61.9%
[2022-04-18 09:47:53 tiny] (main.py 148): INFO Max accuracy: 62.70%
[2022-04-18 09:48:06 tiny] (main.py 226): INFO Train: [63/300][0/1251]	eta 4:14:22 lr 0.000896	time 12.2005 (12.2005)	loss 4.5838 (4.5838)	grad_norm 2.6183 (2.6183)	mem 5329MB
[2022-04-18 09:49:07 tiny] (main.py 226): INFO Train: [63/300][100/1251]	eta 0:14:01 lr 0.000896	time 0.5829 (0.7313)	loss 4.6304 (4.1740)	grad_norm 2.3844 (2.9129)	mem 5329MB
[2022-04-18 09:50:06 tiny] (main.py 226): INFO Train: [63/300][200/1251]	eta 0:11:31 lr 0.000896	time 0.6242 (0.6583)	loss 3.8781 (4.1562)	grad_norm 2.8290 (2.8502)	mem 5329MB
[2022-04-18 09:51:04 tiny] (main.py 226): INFO Train: [63/300][300/1251]	eta 0:10:03 lr 0.000895	time 0.5509 (0.6348)	loss 3.3320 (4.1516)	grad_norm 2.3281 (2.8795)	mem 5329MB
[2022-04-18 09:52:02 tiny] (main.py 226): INFO Train: [63/300][400/1251]	eta 0:08:48 lr 0.000895	time 0.3984 (0.6214)	loss 3.7163 (4.1827)	grad_norm 2.3099 (2.9120)	mem 5329MB
[2022-04-18 09:53:01 tiny] (main.py 226): INFO Train: [63/300][500/1251]	eta 0:07:41 lr 0.000895	time 0.7304 (0.6144)	loss 4.3185 (4.2110)	grad_norm 2.7761 (2.8467)	mem 5329MB
[2022-04-18 09:54:00 tiny] (main.py 226): INFO Train: [63/300][600/1251]	eta 0:06:36 lr 0.000895	time 0.6285 (0.6096)	loss 3.1912 (4.2120)	grad_norm 2.3813 (2.8104)	mem 5329MB
[2022-04-18 09:54:59 tiny] (main.py 226): INFO Train: [63/300][700/1251]	eta 0:05:34 lr 0.000894	time 0.6578 (0.6069)	loss 4.7135 (4.2242)	grad_norm 3.7167 (2.8360)	mem 5329MB
[2022-04-18 09:55:57 tiny] (main.py 226): INFO Train: [63/300][800/1251]	eta 0:04:32 lr 0.000894	time 0.4256 (0.6042)	loss 4.8530 (4.2095)	grad_norm 2.8583 (2.8315)	mem 5329MB
[2022-04-18 09:56:56 tiny] (main.py 226): INFO Train: [63/300][900/1251]	eta 0:03:31 lr 0.000894	time 0.4323 (0.6023)	loss 4.0142 (4.2020)	grad_norm 3.1722 (2.8157)	mem 5329MB
[2022-04-18 09:57:55 tiny] (main.py 226): INFO Train: [63/300][1000/1251]	eta 0:02:30 lr 0.000894	time 0.7331 (0.6014)	loss 4.7854 (4.2051)	grad_norm 2.3039 (inf)	mem 5329MB
[2022-04-18 09:58:54 tiny] (main.py 226): INFO Train: [63/300][1100/1251]	eta 0:01:30 lr 0.000893	time 0.5275 (0.6001)	loss 4.2375 (4.1970)	grad_norm 1.7397 (inf)	mem 5329MB
[2022-04-18 09:59:53 tiny] (main.py 226): INFO Train: [63/300][1200/1251]	eta 0:00:30 lr 0.000893	time 0.8754 (0.5992)	loss 3.8506 (4.2047)	grad_norm 1.8157 (inf)	mem 5329MB
[2022-04-18 10:00:14 tiny] (main.py 233): INFO EPOCH 63 training takes 0:12:21
[2022-04-18 10:00:26 tiny] (main.py 273): INFO Test: [0/49]	Time 11.110 (11.110)	Loss 1.8412 (1.8412)	Acc@1 62.109 (62.109)	Acc@5 86.426 (86.426)	Mem 5329MB
[2022-04-18 10:00:46 tiny] (main.py 279): INFO  * Acc@1 62.160 Acc@5 84.972
[2022-04-18 10:00:46 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 62.2%
[2022-04-18 10:00:46 tiny] (main.py 148): INFO Max accuracy: 62.70%
[2022-04-18 10:00:58 tiny] (main.py 226): INFO Train: [64/300][0/1251]	eta 4:08:25 lr 0.000893	time 11.9146 (11.9146)	loss 4.3156 (4.3156)	grad_norm 1.7607 (1.7607)	mem 5329MB
[2022-04-18 10:02:00 tiny] (main.py 226): INFO Train: [64/300][100/1251]	eta 0:13:59 lr 0.000893	time 0.7134 (0.7296)	loss 4.5109 (4.2039)	grad_norm 2.3788 (2.6921)	mem 5329MB
[2022-04-18 10:02:58 tiny] (main.py 226): INFO Train: [64/300][200/1251]	eta 0:11:31 lr 0.000892	time 0.7431 (0.6577)	loss 3.7832 (4.1992)	grad_norm 2.8489 (2.7949)	mem 5329MB
[2022-04-18 10:03:56 tiny] (main.py 226): INFO Train: [64/300][300/1251]	eta 0:10:01 lr 0.000892	time 0.4516 (0.6326)	loss 3.7478 (4.2033)	grad_norm 2.6955 (2.8033)	mem 5329MB
[2022-04-18 10:04:55 tiny] (main.py 226): INFO Train: [64/300][400/1251]	eta 0:08:48 lr 0.000892	time 0.5761 (0.6214)	loss 4.2802 (4.2009)	grad_norm 3.4124 (2.8210)	mem 5329MB
[2022-04-18 10:05:54 tiny] (main.py 226): INFO Train: [64/300][500/1251]	eta 0:07:41 lr 0.000892	time 0.6412 (0.6142)	loss 3.7922 (4.2026)	grad_norm 1.5066 (2.8126)	mem 5329MB
[2022-04-18 10:06:52 tiny] (main.py 226): INFO Train: [64/300][600/1251]	eta 0:06:36 lr 0.000891	time 0.5942 (0.6098)	loss 5.0408 (4.2112)	grad_norm 2.4032 (2.8122)	mem 5329MB
[2022-04-18 10:07:51 tiny] (main.py 226): INFO Train: [64/300][700/1251]	eta 0:05:34 lr 0.000891	time 0.5745 (0.6063)	loss 3.9246 (4.2043)	grad_norm 3.2251 (2.8252)	mem 5329MB
[2022-04-18 10:08:50 tiny] (main.py 226): INFO Train: [64/300][800/1251]	eta 0:04:32 lr 0.000891	time 0.5187 (0.6043)	loss 5.0362 (4.2093)	grad_norm 3.7982 (2.8363)	mem 5329MB
[2022-04-18 10:09:49 tiny] (main.py 226): INFO Train: [64/300][900/1251]	eta 0:03:31 lr 0.000891	time 0.7297 (0.6029)	loss 4.2734 (4.2189)	grad_norm 2.7060 (2.8405)	mem 5329MB
[2022-04-18 10:10:48 tiny] (main.py 226): INFO Train: [64/300][1000/1251]	eta 0:02:30 lr 0.000890	time 0.7155 (0.6011)	loss 4.1133 (4.2220)	grad_norm 2.0208 (2.8459)	mem 5329MB
[2022-04-18 10:11:47 tiny] (main.py 226): INFO Train: [64/300][1100/1251]	eta 0:01:30 lr 0.000890	time 0.6013 (0.6000)	loss 3.7952 (4.2205)	grad_norm 2.9714 (2.8349)	mem 5329MB
[2022-04-18 10:12:45 tiny] (main.py 226): INFO Train: [64/300][1200/1251]	eta 0:00:30 lr 0.000890	time 0.5703 (0.5990)	loss 4.4916 (4.2169)	grad_norm 2.4295 (2.8224)	mem 5329MB
[2022-04-18 10:13:07 tiny] (main.py 233): INFO EPOCH 64 training takes 0:12:21
[2022-04-18 10:13:20 tiny] (main.py 273): INFO Test: [0/49]	Time 12.507 (12.507)	Loss 1.8503 (1.8503)	Acc@1 61.621 (61.621)	Acc@5 85.742 (85.742)	Mem 5329MB
[2022-04-18 10:13:39 tiny] (main.py 279): INFO  * Acc@1 61.852 Acc@5 84.770
[2022-04-18 10:13:39 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 61.9%
[2022-04-18 10:13:39 tiny] (main.py 148): INFO Max accuracy: 62.70%
[2022-04-18 10:13:50 tiny] (main.py 226): INFO Train: [65/300][0/1251]	eta 3:58:11 lr 0.000890	time 11.4244 (11.4244)	loss 3.5144 (3.5144)	grad_norm 2.1768 (2.1768)	mem 5329MB
[2022-04-18 10:14:52 tiny] (main.py 226): INFO Train: [65/300][100/1251]	eta 0:13:54 lr 0.000889	time 0.6066 (0.7247)	loss 4.9591 (4.1327)	grad_norm 1.9929 (2.8461)	mem 5329MB
[2022-04-18 10:15:51 tiny] (main.py 226): INFO Train: [65/300][200/1251]	eta 0:11:31 lr 0.000889	time 0.6240 (0.6578)	loss 4.6838 (4.1554)	grad_norm 1.5607 (2.8473)	mem 5329MB
[2022-04-18 10:16:50 tiny] (main.py 226): INFO Train: [65/300][300/1251]	eta 0:10:02 lr 0.000889	time 0.6681 (0.6339)	loss 3.9913 (4.1611)	grad_norm 3.3263 (2.8586)	mem 5329MB
[2022-04-18 10:17:48 tiny] (main.py 226): INFO Train: [65/300][400/1251]	eta 0:08:49 lr 0.000889	time 0.6464 (0.6221)	loss 3.2072 (4.1800)	grad_norm 2.2926 (2.8284)	mem 5329MB
[2022-04-18 10:18:47 tiny] (main.py 226): INFO Train: [65/300][500/1251]	eta 0:07:41 lr 0.000888	time 0.6047 (0.6144)	loss 2.9389 (4.1929)	grad_norm 3.5331 (2.8809)	mem 5329MB
[2022-04-18 10:19:46 tiny] (main.py 226): INFO Train: [65/300][600/1251]	eta 0:06:37 lr 0.000888	time 0.6094 (0.6099)	loss 4.6495 (4.2021)	grad_norm 2.4351 (2.8949)	mem 5329MB
[2022-04-18 10:20:45 tiny] (main.py 226): INFO Train: [65/300][700/1251]	eta 0:05:34 lr 0.000888	time 0.6427 (0.6074)	loss 4.6575 (4.2141)	grad_norm 3.0734 (2.8704)	mem 5329MB
[2022-04-18 10:21:43 tiny] (main.py 226): INFO Train: [65/300][800/1251]	eta 0:04:32 lr 0.000888	time 0.4397 (0.6044)	loss 3.4251 (4.2293)	grad_norm 1.8145 (2.8726)	mem 5329MB
[2022-04-18 10:22:42 tiny] (main.py 226): INFO Train: [65/300][900/1251]	eta 0:03:31 lr 0.000887	time 0.4896 (0.6029)	loss 3.3753 (4.2260)	grad_norm 3.6196 (2.8633)	mem 5329MB
[2022-04-18 10:23:41 tiny] (main.py 226): INFO Train: [65/300][1000/1251]	eta 0:02:31 lr 0.000887	time 0.4783 (0.6016)	loss 2.8774 (4.2257)	grad_norm 2.6274 (2.8437)	mem 5329MB
[2022-04-18 10:24:39 tiny] (main.py 226): INFO Train: [65/300][1100/1251]	eta 0:01:30 lr 0.000887	time 0.7019 (0.5999)	loss 4.1291 (4.2201)	grad_norm 3.5885 (2.8649)	mem 5329MB
[2022-04-18 10:25:38 tiny] (main.py 226): INFO Train: [65/300][1200/1251]	eta 0:00:30 lr 0.000887	time 0.6184 (0.5989)	loss 4.8943 (4.2276)	grad_norm 2.1654 (2.8651)	mem 5329MB
[2022-04-18 10:26:00 tiny] (main.py 233): INFO EPOCH 65 training takes 0:12:21
[2022-04-18 10:26:12 tiny] (main.py 273): INFO Test: [0/49]	Time 11.925 (11.925)	Loss 1.6518 (1.6518)	Acc@1 67.188 (67.188)	Acc@5 87.402 (87.402)	Mem 5329MB
[2022-04-18 10:26:31 tiny] (main.py 279): INFO  * Acc@1 62.356 Acc@5 85.060
[2022-04-18 10:26:31 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 62.4%
[2022-04-18 10:26:31 tiny] (main.py 148): INFO Max accuracy: 62.70%
[2022-04-18 10:26:42 tiny] (main.py 226): INFO Train: [66/300][0/1251]	eta 3:36:21 lr 0.000886	time 10.3773 (10.3773)	loss 3.3931 (3.3931)	grad_norm 1.9267 (1.9267)	mem 5329MB
[2022-04-18 10:27:45 tiny] (main.py 226): INFO Train: [66/300][100/1251]	eta 0:13:57 lr 0.000886	time 0.6603 (0.7280)	loss 3.8711 (4.2083)	grad_norm 3.1085 (2.9416)	mem 5329MB
[2022-04-18 10:28:43 tiny] (main.py 226): INFO Train: [66/300][200/1251]	eta 0:11:29 lr 0.000886	time 0.6093 (0.6561)	loss 3.5726 (4.2278)	grad_norm 3.6925 (2.9030)	mem 5329MB
[2022-04-18 10:29:42 tiny] (main.py 226): INFO Train: [66/300][300/1251]	eta 0:10:01 lr 0.000886	time 0.5358 (0.6327)	loss 4.2229 (4.2241)	grad_norm 2.5685 (2.8721)	mem 5329MB
[2022-04-18 10:30:40 tiny] (main.py 226): INFO Train: [66/300][400/1251]	eta 0:08:48 lr 0.000885	time 0.5787 (0.6205)	loss 4.5457 (4.2289)	grad_norm 1.4754 (2.8425)	mem 5329MB
[2022-04-18 10:31:39 tiny] (main.py 226): INFO Train: [66/300][500/1251]	eta 0:07:41 lr 0.000885	time 0.6525 (0.6141)	loss 4.2973 (4.2022)	grad_norm 2.0651 (2.8170)	mem 5329MB
[2022-04-18 10:32:38 tiny] (main.py 226): INFO Train: [66/300][600/1251]	eta 0:06:37 lr 0.000885	time 0.6902 (0.6098)	loss 4.3436 (4.2140)	grad_norm 1.9819 (inf)	mem 5329MB
[2022-04-18 10:33:36 tiny] (main.py 226): INFO Train: [66/300][700/1251]	eta 0:05:34 lr 0.000885	time 0.6258 (0.6065)	loss 3.5843 (4.2171)	grad_norm 2.8438 (inf)	mem 5329MB
[2022-04-18 10:34:35 tiny] (main.py 226): INFO Train: [66/300][800/1251]	eta 0:04:32 lr 0.000884	time 0.6061 (0.6041)	loss 4.2809 (4.2133)	grad_norm 1.9073 (inf)	mem 5329MB
[2022-04-18 10:35:34 tiny] (main.py 226): INFO Train: [66/300][900/1251]	eta 0:03:31 lr 0.000884	time 0.3582 (0.6021)	loss 3.3859 (4.2113)	grad_norm 2.3103 (inf)	mem 5329MB
[2022-04-18 10:36:33 tiny] (main.py 226): INFO Train: [66/300][1000/1251]	eta 0:02:30 lr 0.000884	time 0.5423 (0.6008)	loss 3.1645 (4.2102)	grad_norm 2.4288 (inf)	mem 5329MB
[2022-04-18 10:37:32 tiny] (main.py 226): INFO Train: [66/300][1100/1251]	eta 0:01:30 lr 0.000883	time 0.6585 (0.5997)	loss 4.4464 (4.2160)	grad_norm 3.3275 (inf)	mem 5329MB
[2022-04-18 10:38:30 tiny] (main.py 226): INFO Train: [66/300][1200/1251]	eta 0:00:30 lr 0.000883	time 0.6520 (0.5985)	loss 4.5021 (4.2167)	grad_norm 1.9371 (inf)	mem 5329MB
[2022-04-18 10:38:52 tiny] (main.py 233): INFO EPOCH 66 training takes 0:12:21
[2022-04-18 10:39:05 tiny] (main.py 273): INFO Test: [0/49]	Time 12.590 (12.590)	Loss 1.8590 (1.8590)	Acc@1 61.621 (61.621)	Acc@5 83.398 (83.398)	Mem 5329MB
[2022-04-18 10:39:24 tiny] (main.py 279): INFO  * Acc@1 62.466 Acc@5 84.922
[2022-04-18 10:39:24 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 62.5%
[2022-04-18 10:39:24 tiny] (main.py 148): INFO Max accuracy: 62.70%
[2022-04-18 10:39:36 tiny] (main.py 226): INFO Train: [67/300][0/1251]	eta 4:12:59 lr 0.000883	time 12.1338 (12.1338)	loss 4.1308 (4.1308)	grad_norm 2.4423 (2.4423)	mem 5329MB
[2022-04-18 10:40:38 tiny] (main.py 226): INFO Train: [67/300][100/1251]	eta 0:14:04 lr 0.000883	time 0.6063 (0.7334)	loss 3.7048 (4.1281)	grad_norm 2.4787 (2.8996)	mem 5329MB
[2022-04-18 10:41:36 tiny] (main.py 226): INFO Train: [67/300][200/1251]	eta 0:11:32 lr 0.000883	time 0.6522 (0.6592)	loss 4.9158 (4.1578)	grad_norm 1.6755 (2.8645)	mem 5329MB
[2022-04-18 10:42:35 tiny] (main.py 226): INFO Train: [67/300][300/1251]	eta 0:10:03 lr 0.000882	time 0.5461 (0.6345)	loss 4.6460 (4.1816)	grad_norm 2.1650 (2.9125)	mem 5329MB
[2022-04-18 10:43:33 tiny] (main.py 226): INFO Train: [67/300][400/1251]	eta 0:08:49 lr 0.000882	time 0.5143 (0.6220)	loss 3.5027 (4.1880)	grad_norm 3.7736 (2.8223)	mem 5329MB
[2022-04-18 10:44:31 tiny] (main.py 226): INFO Train: [67/300][500/1251]	eta 0:07:41 lr 0.000882	time 0.4007 (0.6145)	loss 4.4447 (4.1963)	grad_norm 3.1427 (2.8180)	mem 5329MB
[2022-04-18 10:45:31 tiny] (main.py 226): INFO Train: [67/300][600/1251]	eta 0:06:37 lr 0.000881	time 0.6890 (0.6109)	loss 4.6331 (4.2043)	grad_norm 3.8476 (2.8403)	mem 5329MB
[2022-04-18 10:46:30 tiny] (main.py 226): INFO Train: [67/300][700/1251]	eta 0:05:34 lr 0.000881	time 0.5110 (0.6075)	loss 4.1101 (4.2019)	grad_norm 3.1414 (2.8461)	mem 5329MB
[2022-04-18 10:47:28 tiny] (main.py 226): INFO Train: [67/300][800/1251]	eta 0:04:32 lr 0.000881	time 0.4355 (0.6046)	loss 3.0771 (4.2013)	grad_norm 2.0687 (2.8745)	mem 5329MB
[2022-04-18 10:48:27 tiny] (main.py 226): INFO Train: [67/300][900/1251]	eta 0:03:31 lr 0.000881	time 0.4319 (0.6027)	loss 3.1976 (4.2182)	grad_norm 1.8372 (2.8690)	mem 5329MB
[2022-04-18 10:49:26 tiny] (main.py 226): INFO Train: [67/300][1000/1251]	eta 0:02:31 lr 0.000880	time 0.8104 (0.6016)	loss 3.8957 (4.2157)	grad_norm 5.8660 (2.8767)	mem 5329MB
[2022-04-18 10:50:24 tiny] (main.py 226): INFO Train: [67/300][1100/1251]	eta 0:01:30 lr 0.000880	time 0.7544 (0.5999)	loss 4.7254 (4.2223)	grad_norm 2.0523 (2.8775)	mem 5329MB
[2022-04-18 10:51:23 tiny] (main.py 226): INFO Train: [67/300][1200/1251]	eta 0:00:30 lr 0.000880	time 0.5890 (0.5990)	loss 4.5855 (4.2219)	grad_norm 1.8845 (2.8751)	mem 5329MB
[2022-04-18 10:51:45 tiny] (main.py 233): INFO EPOCH 67 training takes 0:12:21
[2022-04-18 10:51:56 tiny] (main.py 273): INFO Test: [0/49]	Time 10.920 (10.920)	Loss 1.7327 (1.7327)	Acc@1 64.551 (64.551)	Acc@5 85.938 (85.938)	Mem 5329MB
[2022-04-18 10:52:16 tiny] (main.py 279): INFO  * Acc@1 63.068 Acc@5 85.442
[2022-04-18 10:52:16 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 63.1%
[2022-04-18 10:52:16 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_67.pth saving......
[2022-04-18 10:52:16 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_67.pth saved !!!
[2022-04-18 10:52:16 tiny] (main.py 148): INFO Max accuracy: 63.07%
[2022-04-18 10:52:28 tiny] (main.py 226): INFO Train: [68/300][0/1251]	eta 4:10:28 lr 0.000880	time 12.0129 (12.0129)	loss 4.9581 (4.9581)	grad_norm 2.4117 (2.4117)	mem 5329MB
[2022-04-18 10:53:29 tiny] (main.py 226): INFO Train: [68/300][100/1251]	eta 0:13:56 lr 0.000879	time 0.3961 (0.7271)	loss 2.9166 (4.2195)	grad_norm 2.4047 (2.8354)	mem 5329MB
[2022-04-18 10:54:28 tiny] (main.py 226): INFO Train: [68/300][200/1251]	eta 0:11:30 lr 0.000879	time 0.6014 (0.6572)	loss 3.0334 (4.1899)	grad_norm 2.7459 (2.8477)	mem 5329MB
[2022-04-18 10:55:26 tiny] (main.py 226): INFO Train: [68/300][300/1251]	eta 0:10:01 lr 0.000879	time 0.5393 (0.6330)	loss 4.8268 (4.1881)	grad_norm 2.4604 (2.9013)	mem 5329MB
[2022-04-18 10:56:25 tiny] (main.py 226): INFO Train: [68/300][400/1251]	eta 0:08:49 lr 0.000879	time 0.5176 (0.6218)	loss 4.7395 (4.1949)	grad_norm 3.3345 (2.9319)	mem 5329MB
[2022-04-18 10:57:24 tiny] (main.py 226): INFO Train: [68/300][500/1251]	eta 0:07:41 lr 0.000878	time 0.6639 (0.6148)	loss 4.5562 (4.1987)	grad_norm 3.1224 (2.8990)	mem 5329MB
[2022-04-18 10:58:23 tiny] (main.py 226): INFO Train: [68/300][600/1251]	eta 0:06:37 lr 0.000878	time 0.5607 (0.6103)	loss 3.8784 (4.1992)	grad_norm 2.0093 (2.9182)	mem 5329MB
[2022-04-18 10:59:21 tiny] (main.py 226): INFO Train: [68/300][700/1251]	eta 0:05:34 lr 0.000878	time 0.5608 (0.6067)	loss 4.6610 (4.2057)	grad_norm 3.7080 (2.9189)	mem 5329MB
[2022-04-18 11:00:20 tiny] (main.py 226): INFO Train: [68/300][800/1251]	eta 0:04:32 lr 0.000878	time 0.5547 (0.6046)	loss 3.3347 (4.2105)	grad_norm 2.3131 (2.9213)	mem 5329MB
[2022-04-18 11:01:19 tiny] (main.py 226): INFO Train: [68/300][900/1251]	eta 0:03:31 lr 0.000877	time 0.5817 (0.6025)	loss 3.9619 (4.2033)	grad_norm 3.7852 (2.8989)	mem 5329MB
[2022-04-18 11:02:17 tiny] (main.py 226): INFO Train: [68/300][1000/1251]	eta 0:02:30 lr 0.000877	time 0.7204 (0.6009)	loss 4.8993 (4.1969)	grad_norm 1.8663 (inf)	mem 5329MB
[2022-04-18 11:03:17 tiny] (main.py 226): INFO Train: [68/300][1100/1251]	eta 0:01:30 lr 0.000877	time 0.6781 (0.6002)	loss 3.5671 (4.1922)	grad_norm 2.6335 (inf)	mem 5329MB
[2022-04-18 11:04:16 tiny] (main.py 226): INFO Train: [68/300][1200/1251]	eta 0:00:30 lr 0.000876	time 0.6251 (0.5993)	loss 3.0602 (4.1882)	grad_norm 1.8854 (inf)	mem 5329MB
[2022-04-18 11:04:38 tiny] (main.py 233): INFO EPOCH 68 training takes 0:12:21
[2022-04-18 11:04:48 tiny] (main.py 273): INFO Test: [0/49]	Time 10.111 (10.111)	Loss 1.7973 (1.7973)	Acc@1 64.160 (64.160)	Acc@5 86.426 (86.426)	Mem 5329MB
[2022-04-18 11:05:10 tiny] (main.py 279): INFO  * Acc@1 62.658 Acc@5 85.198
[2022-04-18 11:05:10 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 62.7%
[2022-04-18 11:05:10 tiny] (main.py 148): INFO Max accuracy: 63.07%
[2022-04-18 11:05:22 tiny] (main.py 226): INFO Train: [69/300][0/1251]	eta 4:12:45 lr 0.000876	time 12.1229 (12.1229)	loss 3.8259 (3.8259)	grad_norm 3.7375 (3.7375)	mem 5329MB
[2022-04-18 11:06:27 tiny] (main.py 226): INFO Train: [69/300][100/1251]	eta 0:14:39 lr 0.000876	time 0.5500 (0.7645)	loss 4.6134 (4.2088)	grad_norm 3.8158 (2.9903)	mem 5329MB
[2022-04-18 11:07:29 tiny] (main.py 226): INFO Train: [69/300][200/1251]	eta 0:12:04 lr 0.000876	time 0.5801 (0.6898)	loss 4.3981 (4.1716)	grad_norm 3.8049 (2.9350)	mem 5329MB
[2022-04-18 11:08:29 tiny] (main.py 226): INFO Train: [69/300][300/1251]	eta 0:10:29 lr 0.000875	time 0.6201 (0.6622)	loss 4.3614 (4.1552)	grad_norm 1.8059 (2.9273)	mem 5329MB
[2022-04-18 11:09:29 tiny] (main.py 226): INFO Train: [69/300][400/1251]	eta 0:09:08 lr 0.000875	time 0.5001 (0.6448)	loss 4.3524 (4.1540)	grad_norm 2.0496 (2.9572)	mem 5329MB
[2022-04-18 11:10:27 tiny] (main.py 226): INFO Train: [69/300][500/1251]	eta 0:07:55 lr 0.000875	time 0.7191 (0.6334)	loss 4.3264 (4.1471)	grad_norm 2.8217 (2.9703)	mem 5329MB
[2022-04-18 11:11:26 tiny] (main.py 226): INFO Train: [69/300][600/1251]	eta 0:06:47 lr 0.000875	time 0.5869 (0.6256)	loss 4.6170 (4.1706)	grad_norm 2.1200 (2.9508)	mem 5329MB
[2022-04-18 11:12:25 tiny] (main.py 226): INFO Train: [69/300][700/1251]	eta 0:05:41 lr 0.000874	time 0.4717 (0.6207)	loss 4.1225 (4.1709)	grad_norm 2.5623 (2.9576)	mem 5329MB
[2022-04-18 11:13:24 tiny] (main.py 226): INFO Train: [69/300][800/1251]	eta 0:04:37 lr 0.000874	time 0.6016 (0.6164)	loss 4.5612 (4.1740)	grad_norm 2.4300 (2.9371)	mem 5329MB
[2022-04-18 11:14:23 tiny] (main.py 226): INFO Train: [69/300][900/1251]	eta 0:03:35 lr 0.000874	time 0.6584 (0.6133)	loss 3.7325 (4.1725)	grad_norm 3.6488 (2.9630)	mem 5329MB
[2022-04-18 11:15:21 tiny] (main.py 226): INFO Train: [69/300][1000/1251]	eta 0:02:33 lr 0.000874	time 0.5421 (0.6108)	loss 4.3935 (4.1837)	grad_norm 2.1230 (2.9532)	mem 5329MB
[2022-04-18 11:16:20 tiny] (main.py 226): INFO Train: [69/300][1100/1251]	eta 0:01:31 lr 0.000873	time 0.7193 (0.6089)	loss 3.9918 (4.1878)	grad_norm 4.5241 (2.9482)	mem 5329MB
[2022-04-18 11:17:19 tiny] (main.py 226): INFO Train: [69/300][1200/1251]	eta 0:00:30 lr 0.000873	time 0.5871 (0.6073)	loss 3.1293 (4.1854)	grad_norm 3.9687 (2.9486)	mem 5329MB
[2022-04-18 11:17:41 tiny] (main.py 233): INFO EPOCH 69 training takes 0:12:31
[2022-04-18 11:17:53 tiny] (main.py 273): INFO Test: [0/49]	Time 11.678 (11.678)	Loss 1.9707 (1.9707)	Acc@1 61.133 (61.133)	Acc@5 83.496 (83.496)	Mem 5329MB
[2022-04-18 11:18:12 tiny] (main.py 279): INFO  * Acc@1 62.818 Acc@5 85.234
[2022-04-18 11:18:12 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 62.8%
[2022-04-18 11:18:12 tiny] (main.py 148): INFO Max accuracy: 63.07%
[2022-04-18 11:18:24 tiny] (main.py 226): INFO Train: [70/300][0/1251]	eta 4:00:07 lr 0.000873	time 11.5166 (11.5166)	loss 4.5975 (4.5975)	grad_norm 2.1918 (2.1918)	mem 5329MB
[2022-04-18 11:19:26 tiny] (main.py 226): INFO Train: [70/300][100/1251]	eta 0:14:01 lr 0.000873	time 0.4862 (0.7310)	loss 3.5800 (4.1667)	grad_norm 2.8479 (2.7408)	mem 5329MB
[2022-04-18 11:20:24 tiny] (main.py 226): INFO Train: [70/300][200/1251]	eta 0:11:30 lr 0.000872	time 0.5227 (0.6573)	loss 3.5433 (4.1857)	grad_norm 3.0804 (2.8442)	mem 5329MB
[2022-04-18 11:21:23 tiny] (main.py 226): INFO Train: [70/300][300/1251]	eta 0:10:01 lr 0.000872	time 0.5745 (0.6323)	loss 4.9992 (4.1848)	grad_norm 2.4748 (2.9004)	mem 5329MB
[2022-04-18 11:22:21 tiny] (main.py 226): INFO Train: [70/300][400/1251]	eta 0:08:48 lr 0.000872	time 0.5590 (0.6206)	loss 4.5997 (4.1779)	grad_norm 2.1974 (2.9482)	mem 5329MB
[2022-04-18 11:23:20 tiny] (main.py 226): INFO Train: [70/300][500/1251]	eta 0:07:41 lr 0.000871	time 0.6809 (0.6144)	loss 4.0181 (4.1780)	grad_norm 2.5170 (2.9436)	mem 5329MB
[2022-04-18 11:24:19 tiny] (main.py 226): INFO Train: [70/300][600/1251]	eta 0:06:37 lr 0.000871	time 0.5177 (0.6100)	loss 4.4904 (4.1628)	grad_norm 3.9426 (2.9333)	mem 5329MB
[2022-04-18 11:25:18 tiny] (main.py 226): INFO Train: [70/300][700/1251]	eta 0:05:34 lr 0.000871	time 0.5512 (0.6070)	loss 4.2875 (4.1690)	grad_norm 5.6073 (2.9506)	mem 5329MB
[2022-04-18 11:26:17 tiny] (main.py 226): INFO Train: [70/300][800/1251]	eta 0:04:32 lr 0.000871	time 0.7250 (0.6050)	loss 4.7523 (4.1746)	grad_norm 3.8315 (2.9525)	mem 5329MB
[2022-04-18 11:27:16 tiny] (main.py 226): INFO Train: [70/300][900/1251]	eta 0:03:31 lr 0.000870	time 0.4444 (0.6031)	loss 4.8699 (4.1871)	grad_norm 4.9169 (2.9512)	mem 5329MB
[2022-04-18 11:28:14 tiny] (main.py 226): INFO Train: [70/300][1000/1251]	eta 0:02:30 lr 0.000870	time 0.5695 (0.6013)	loss 5.0116 (4.1897)	grad_norm 5.7101 (2.9442)	mem 5329MB
[2022-04-18 11:29:13 tiny] (main.py 226): INFO Train: [70/300][1100/1251]	eta 0:01:30 lr 0.000870	time 0.5220 (0.6000)	loss 5.0283 (4.1993)	grad_norm 2.1958 (2.9391)	mem 5329MB
[2022-04-18 11:30:12 tiny] (main.py 226): INFO Train: [70/300][1200/1251]	eta 0:00:30 lr 0.000870	time 0.5507 (0.5990)	loss 4.0492 (4.1976)	grad_norm 4.7705 (2.9467)	mem 5329MB
[2022-04-18 11:30:34 tiny] (main.py 233): INFO EPOCH 70 training takes 0:12:21
[2022-04-18 11:30:46 tiny] (main.py 273): INFO Test: [0/49]	Time 12.028 (12.028)	Loss 1.7941 (1.7941)	Acc@1 64.160 (64.160)	Acc@5 86.035 (86.035)	Mem 5329MB
[2022-04-18 11:31:05 tiny] (main.py 279): INFO  * Acc@1 62.554 Acc@5 85.246
[2022-04-18 11:31:05 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 62.6%
[2022-04-18 11:31:05 tiny] (main.py 148): INFO Max accuracy: 63.07%
[2022-04-18 11:31:16 tiny] (main.py 226): INFO Train: [71/300][0/1251]	eta 3:59:38 lr 0.000869	time 11.4937 (11.4937)	loss 3.3772 (3.3772)	grad_norm 3.8885 (3.8885)	mem 5329MB
[2022-04-18 11:32:19 tiny] (main.py 226): INFO Train: [71/300][100/1251]	eta 0:14:03 lr 0.000869	time 0.5780 (0.7328)	loss 4.5682 (4.1780)	grad_norm 3.0588 (2.8837)	mem 5329MB
[2022-04-18 11:33:17 tiny] (main.py 226): INFO Train: [71/300][200/1251]	eta 0:11:30 lr 0.000869	time 0.5979 (0.6574)	loss 4.4459 (4.1705)	grad_norm 2.7007 (2.9033)	mem 5329MB
[2022-04-18 11:34:16 tiny] (main.py 226): INFO Train: [71/300][300/1251]	eta 0:10:03 lr 0.000869	time 0.6679 (0.6350)	loss 4.7082 (4.1475)	grad_norm 2.6405 (2.9427)	mem 5329MB
[2022-04-18 11:35:14 tiny] (main.py 226): INFO Train: [71/300][400/1251]	eta 0:08:49 lr 0.000868	time 0.5379 (0.6219)	loss 3.9320 (4.1397)	grad_norm 1.9916 (2.9580)	mem 5329MB
[2022-04-18 11:36:13 tiny] (main.py 226): INFO Train: [71/300][500/1251]	eta 0:07:41 lr 0.000868	time 0.5524 (0.6145)	loss 3.8078 (4.1450)	grad_norm 2.0605 (2.9299)	mem 5329MB
[2022-04-18 11:37:11 tiny] (main.py 226): INFO Train: [71/300][600/1251]	eta 0:06:37 lr 0.000868	time 0.5571 (0.6100)	loss 3.4690 (4.1460)	grad_norm 2.6946 (2.9111)	mem 5329MB
[2022-04-18 11:38:10 tiny] (main.py 226): INFO Train: [71/300][700/1251]	eta 0:05:34 lr 0.000867	time 0.6852 (0.6070)	loss 4.3795 (4.1656)	grad_norm 3.1204 (2.9542)	mem 5329MB
[2022-04-18 11:39:09 tiny] (main.py 226): INFO Train: [71/300][800/1251]	eta 0:04:32 lr 0.000867	time 0.4449 (0.6045)	loss 5.0063 (4.1752)	grad_norm 2.1269 (2.9225)	mem 5329MB
[2022-04-18 11:40:08 tiny] (main.py 226): INFO Train: [71/300][900/1251]	eta 0:03:31 lr 0.000867	time 0.5545 (0.6029)	loss 3.0077 (4.1738)	grad_norm 1.7676 (2.9180)	mem 5329MB
[2022-04-18 11:41:07 tiny] (main.py 226): INFO Train: [71/300][1000/1251]	eta 0:02:30 lr 0.000867	time 0.6756 (0.6013)	loss 4.3681 (4.1799)	grad_norm 2.8724 (2.9122)	mem 5329MB
[2022-04-18 11:42:05 tiny] (main.py 226): INFO Train: [71/300][1100/1251]	eta 0:01:30 lr 0.000866	time 0.6064 (0.6000)	loss 3.9876 (4.1779)	grad_norm 1.6120 (2.9092)	mem 5329MB
[2022-04-18 11:43:04 tiny] (main.py 226): INFO Train: [71/300][1200/1251]	eta 0:00:30 lr 0.000866	time 0.5566 (0.5991)	loss 4.6293 (4.1721)	grad_norm 2.2017 (2.9127)	mem 5329MB
[2022-04-18 11:43:26 tiny] (main.py 233): INFO EPOCH 71 training takes 0:12:21
[2022-04-18 11:43:38 tiny] (main.py 273): INFO Test: [0/49]	Time 12.217 (12.217)	Loss 1.7880 (1.7880)	Acc@1 62.305 (62.305)	Acc@5 86.133 (86.133)	Mem 5329MB
[2022-04-18 11:43:57 tiny] (main.py 279): INFO  * Acc@1 62.868 Acc@5 85.368
[2022-04-18 11:43:57 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 62.9%
[2022-04-18 11:43:57 tiny] (main.py 148): INFO Max accuracy: 63.07%
[2022-04-18 11:44:09 tiny] (main.py 226): INFO Train: [72/300][0/1251]	eta 3:59:40 lr 0.000866	time 11.4951 (11.4951)	loss 4.2377 (4.2377)	grad_norm 1.8979 (1.8979)	mem 5329MB
[2022-04-18 11:45:11 tiny] (main.py 226): INFO Train: [72/300][100/1251]	eta 0:13:57 lr 0.000866	time 0.5536 (0.7274)	loss 2.9495 (4.1602)	grad_norm 1.6909 (3.0340)	mem 5329MB
[2022-04-18 11:46:09 tiny] (main.py 226): INFO Train: [72/300][200/1251]	eta 0:11:30 lr 0.000865	time 0.6659 (0.6567)	loss 4.9742 (4.1793)	grad_norm 2.9945 (2.8616)	mem 5329MB
[2022-04-18 11:47:08 tiny] (main.py 226): INFO Train: [72/300][300/1251]	eta 0:10:01 lr 0.000865	time 0.5454 (0.6329)	loss 4.6487 (4.1547)	grad_norm 1.9939 (2.8484)	mem 5329MB
[2022-04-18 11:48:06 tiny] (main.py 226): INFO Train: [72/300][400/1251]	eta 0:08:48 lr 0.000865	time 0.4712 (0.6206)	loss 5.0046 (4.1706)	grad_norm 3.9844 (2.8847)	mem 5329MB
[2022-04-18 11:49:04 tiny] (main.py 226): INFO Train: [72/300][500/1251]	eta 0:07:40 lr 0.000864	time 0.6091 (0.6134)	loss 3.4580 (4.1762)	grad_norm 2.5321 (2.8874)	mem 5329MB
[2022-04-18 11:50:03 tiny] (main.py 226): INFO Train: [72/300][600/1251]	eta 0:06:36 lr 0.000864	time 0.4655 (0.6090)	loss 4.1769 (4.1573)	grad_norm 2.6260 (2.9075)	mem 5329MB
[2022-04-18 11:51:02 tiny] (main.py 226): INFO Train: [72/300][700/1251]	eta 0:05:33 lr 0.000864	time 0.5498 (0.6061)	loss 4.8963 (4.1694)	grad_norm 3.6024 (2.8761)	mem 5329MB
[2022-04-18 11:52:01 tiny] (main.py 226): INFO Train: [72/300][800/1251]	eta 0:04:32 lr 0.000864	time 0.5039 (0.6044)	loss 4.7420 (4.1785)	grad_norm 2.9065 (2.8649)	mem 5329MB
[2022-04-18 11:53:00 tiny] (main.py 226): INFO Train: [72/300][900/1251]	eta 0:03:31 lr 0.000863	time 0.5690 (0.6027)	loss 4.4344 (4.1869)	grad_norm 2.9318 (2.8810)	mem 5329MB
[2022-04-18 11:53:59 tiny] (main.py 226): INFO Train: [72/300][1000/1251]	eta 0:02:30 lr 0.000863	time 0.5671 (0.6009)	loss 4.1628 (4.1813)	grad_norm 2.2808 (2.8778)	mem 5329MB
[2022-04-18 11:54:57 tiny] (main.py 226): INFO Train: [72/300][1100/1251]	eta 0:01:30 lr 0.000863	time 0.5772 (0.5995)	loss 4.9726 (4.1899)	grad_norm 2.3470 (2.9128)	mem 5329MB
[2022-04-18 11:55:56 tiny] (main.py 226): INFO Train: [72/300][1200/1251]	eta 0:00:30 lr 0.000862	time 0.8042 (0.5987)	loss 3.3679 (4.1840)	grad_norm 2.5765 (2.8962)	mem 5329MB
[2022-04-18 11:56:18 tiny] (main.py 233): INFO EPOCH 72 training takes 0:12:20
[2022-04-18 11:56:30 tiny] (main.py 273): INFO Test: [0/49]	Time 12.376 (12.376)	Loss 1.8558 (1.8558)	Acc@1 62.988 (62.988)	Acc@5 85.059 (85.059)	Mem 5329MB
[2022-04-18 11:56:49 tiny] (main.py 279): INFO  * Acc@1 62.910 Acc@5 85.286
[2022-04-18 11:56:49 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 62.9%
[2022-04-18 11:56:49 tiny] (main.py 148): INFO Max accuracy: 63.07%
[2022-04-18 11:56:59 tiny] (main.py 226): INFO Train: [73/300][0/1251]	eta 3:33:33 lr 0.000862	time 10.2428 (10.2428)	loss 4.3535 (4.3535)	grad_norm 4.1632 (4.1632)	mem 5329MB
[2022-04-18 11:58:02 tiny] (main.py 226): INFO Train: [73/300][100/1251]	eta 0:13:57 lr 0.000862	time 0.5558 (0.7273)	loss 3.8100 (4.0278)	grad_norm 3.1952 (3.1976)	mem 5329MB
[2022-04-18 11:59:01 tiny] (main.py 226): INFO Train: [73/300][200/1251]	eta 0:11:31 lr 0.000862	time 0.5191 (0.6580)	loss 3.5562 (4.0953)	grad_norm 2.7873 (2.9767)	mem 5329MB
[2022-04-18 11:59:59 tiny] (main.py 226): INFO Train: [73/300][300/1251]	eta 0:10:02 lr 0.000861	time 0.4853 (0.6334)	loss 3.9863 (4.1329)	grad_norm 1.7054 (2.8665)	mem 5329MB
[2022-04-18 12:00:58 tiny] (main.py 226): INFO Train: [73/300][400/1251]	eta 0:08:48 lr 0.000861	time 0.8506 (0.6215)	loss 3.9137 (4.1439)	grad_norm 2.0673 (2.8840)	mem 5329MB
[2022-04-18 12:01:57 tiny] (main.py 226): INFO Train: [73/300][500/1251]	eta 0:07:41 lr 0.000861	time 0.4793 (0.6145)	loss 4.7347 (4.1244)	grad_norm 2.2250 (2.9039)	mem 5329MB
[2022-04-18 12:02:56 tiny] (main.py 226): INFO Train: [73/300][600/1251]	eta 0:06:37 lr 0.000861	time 0.6478 (0.6107)	loss 4.0636 (4.1160)	grad_norm 2.6239 (2.9032)	mem 5329MB
[2022-04-18 12:03:54 tiny] (main.py 226): INFO Train: [73/300][700/1251]	eta 0:05:34 lr 0.000860	time 0.4513 (0.6067)	loss 4.4709 (4.1202)	grad_norm 1.7711 (2.8984)	mem 5329MB
[2022-04-18 12:04:53 tiny] (main.py 226): INFO Train: [73/300][800/1251]	eta 0:04:32 lr 0.000860	time 0.7482 (0.6048)	loss 4.5008 (4.1202)	grad_norm 2.3584 (inf)	mem 5329MB
[2022-04-18 12:05:52 tiny] (main.py 226): INFO Train: [73/300][900/1251]	eta 0:03:31 lr 0.000860	time 0.5158 (0.6030)	loss 5.1833 (4.1335)	grad_norm 2.7987 (inf)	mem 5329MB
[2022-04-18 12:06:51 tiny] (main.py 226): INFO Train: [73/300][1000/1251]	eta 0:02:30 lr 0.000859	time 0.5784 (0.6015)	loss 4.5462 (4.1359)	grad_norm 2.0055 (inf)	mem 5329MB
[2022-04-18 12:07:50 tiny] (main.py 226): INFO Train: [73/300][1100/1251]	eta 0:01:30 lr 0.000859	time 0.5542 (0.6002)	loss 4.4700 (4.1334)	grad_norm 1.8972 (inf)	mem 5329MB
[2022-04-18 12:08:48 tiny] (main.py 226): INFO Train: [73/300][1200/1251]	eta 0:00:30 lr 0.000859	time 0.5929 (0.5992)	loss 3.2170 (4.1335)	grad_norm 4.1134 (inf)	mem 5329MB
[2022-04-18 12:09:10 tiny] (main.py 233): INFO EPOCH 73 training takes 0:12:21
[2022-04-18 12:09:23 tiny] (main.py 273): INFO Test: [0/49]	Time 12.577 (12.577)	Loss 1.7877 (1.7877)	Acc@1 64.062 (64.062)	Acc@5 85.547 (85.547)	Mem 5329MB
[2022-04-18 12:09:41 tiny] (main.py 279): INFO  * Acc@1 62.812 Acc@5 85.286
[2022-04-18 12:09:41 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 62.8%
[2022-04-18 12:09:41 tiny] (main.py 148): INFO Max accuracy: 63.07%
[2022-04-18 12:09:53 tiny] (main.py 226): INFO Train: [74/300][0/1251]	eta 4:11:21 lr 0.000859	time 12.0553 (12.0553)	loss 4.2274 (4.2274)	grad_norm 1.6311 (1.6311)	mem 5329MB
[2022-04-18 12:10:55 tiny] (main.py 226): INFO Train: [74/300][100/1251]	eta 0:13:57 lr 0.000858	time 0.6194 (0.7278)	loss 4.3575 (4.1412)	grad_norm 2.0396 (2.9876)	mem 5329MB
[2022-04-18 12:11:53 tiny] (main.py 226): INFO Train: [74/300][200/1251]	eta 0:11:28 lr 0.000858	time 0.4857 (0.6550)	loss 3.1683 (4.1662)	grad_norm 2.3461 (2.9270)	mem 5329MB
[2022-04-18 12:12:52 tiny] (main.py 226): INFO Train: [74/300][300/1251]	eta 0:10:02 lr 0.000858	time 0.6618 (0.6332)	loss 5.0231 (4.1217)	grad_norm 3.3608 (2.8840)	mem 5329MB
[2022-04-18 12:13:50 tiny] (main.py 226): INFO Train: [74/300][400/1251]	eta 0:08:48 lr 0.000858	time 0.5601 (0.6210)	loss 4.3475 (4.1542)	grad_norm 2.4936 (2.8706)	mem 5329MB
[2022-04-18 12:14:49 tiny] (main.py 226): INFO Train: [74/300][500/1251]	eta 0:07:41 lr 0.000857	time 0.6028 (0.6142)	loss 3.5197 (4.1618)	grad_norm 2.1568 (2.8602)	mem 5329MB
[2022-04-18 12:15:48 tiny] (main.py 226): INFO Train: [74/300][600/1251]	eta 0:06:36 lr 0.000857	time 0.4782 (0.6096)	loss 3.2601 (4.1744)	grad_norm 2.4346 (2.9001)	mem 5329MB
[2022-04-18 12:16:47 tiny] (main.py 226): INFO Train: [74/300][700/1251]	eta 0:05:34 lr 0.000857	time 0.6033 (0.6069)	loss 4.7141 (4.1610)	grad_norm 2.1053 (2.8984)	mem 5329MB
[2022-04-18 12:17:45 tiny] (main.py 226): INFO Train: [74/300][800/1251]	eta 0:04:32 lr 0.000856	time 0.5876 (0.6044)	loss 4.8009 (4.1607)	grad_norm 2.5489 (2.9008)	mem 5329MB
[2022-04-18 12:18:45 tiny] (main.py 226): INFO Train: [74/300][900/1251]	eta 0:03:31 lr 0.000856	time 0.5197 (0.6030)	loss 4.8808 (4.1631)	grad_norm 2.2650 (2.8945)	mem 5329MB
[2022-04-18 12:19:43 tiny] (main.py 226): INFO Train: [74/300][1000/1251]	eta 0:02:30 lr 0.000856	time 0.5757 (0.6008)	loss 4.2226 (4.1628)	grad_norm 2.1785 (2.8990)	mem 5329MB
[2022-04-18 12:20:41 tiny] (main.py 226): INFO Train: [74/300][1100/1251]	eta 0:01:30 lr 0.000855	time 0.5080 (0.5995)	loss 4.3930 (4.1651)	grad_norm 2.8046 (2.9030)	mem 5329MB
[2022-04-18 12:21:40 tiny] (main.py 226): INFO Train: [74/300][1200/1251]	eta 0:00:30 lr 0.000855	time 0.5161 (0.5984)	loss 3.5483 (4.1610)	grad_norm 3.2599 (2.8991)	mem 5329MB
[2022-04-18 12:22:02 tiny] (main.py 233): INFO EPOCH 74 training takes 0:12:20
[2022-04-18 12:22:14 tiny] (main.py 273): INFO Test: [0/49]	Time 11.509 (11.509)	Loss 1.8796 (1.8796)	Acc@1 62.207 (62.207)	Acc@5 83.984 (83.984)	Mem 5329MB
[2022-04-18 12:22:33 tiny] (main.py 279): INFO  * Acc@1 62.280 Acc@5 85.014
[2022-04-18 12:22:33 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 62.3%
[2022-04-18 12:22:33 tiny] (main.py 148): INFO Max accuracy: 63.07%
[2022-04-18 12:22:45 tiny] (main.py 226): INFO Train: [75/300][0/1251]	eta 4:02:10 lr 0.000855	time 11.6153 (11.6153)	loss 4.6383 (4.6383)	grad_norm 2.3319 (2.3319)	mem 5329MB
[2022-04-18 12:23:47 tiny] (main.py 226): INFO Train: [75/300][100/1251]	eta 0:13:56 lr 0.000855	time 0.7672 (0.7269)	loss 4.3369 (4.1619)	grad_norm 2.1386 (2.9129)	mem 5329MB
[2022-04-18 12:24:46 tiny] (main.py 226): INFO Train: [75/300][200/1251]	eta 0:11:32 lr 0.000854	time 0.5861 (0.6587)	loss 4.6479 (4.2095)	grad_norm 2.6420 (2.8809)	mem 5329MB
[2022-04-18 12:25:44 tiny] (main.py 226): INFO Train: [75/300][300/1251]	eta 0:10:02 lr 0.000854	time 0.5937 (0.6330)	loss 4.0837 (4.2132)	grad_norm 5.5410 (2.8456)	mem 5329MB
[2022-04-18 12:26:42 tiny] (main.py 226): INFO Train: [75/300][400/1251]	eta 0:08:48 lr 0.000854	time 0.5518 (0.6205)	loss 4.8973 (4.1988)	grad_norm 3.8430 (2.8552)	mem 5329MB
[2022-04-18 12:27:42 tiny] (main.py 226): INFO Train: [75/300][500/1251]	eta 0:07:41 lr 0.000854	time 0.6589 (0.6151)	loss 3.8777 (4.1966)	grad_norm 2.4121 (2.8972)	mem 5329MB
[2022-04-18 12:28:40 tiny] (main.py 226): INFO Train: [75/300][600/1251]	eta 0:06:37 lr 0.000853	time 0.6243 (0.6100)	loss 3.6437 (4.2069)	grad_norm 2.3408 (2.8975)	mem 5329MB
[2022-04-18 12:29:39 tiny] (main.py 226): INFO Train: [75/300][700/1251]	eta 0:05:34 lr 0.000853	time 0.7155 (0.6066)	loss 4.1328 (4.2139)	grad_norm 3.7007 (2.9121)	mem 5329MB
[2022-04-18 12:30:37 tiny] (main.py 226): INFO Train: [75/300][800/1251]	eta 0:04:32 lr 0.000853	time 0.5346 (0.6039)	loss 3.5614 (4.2075)	grad_norm 4.3469 (2.9180)	mem 5329MB
[2022-04-18 12:31:36 tiny] (main.py 226): INFO Train: [75/300][900/1251]	eta 0:03:31 lr 0.000852	time 0.5507 (0.6027)	loss 4.3946 (4.2044)	grad_norm 2.1877 (2.9206)	mem 5329MB
[2022-04-18 12:32:35 tiny] (main.py 226): INFO Train: [75/300][1000/1251]	eta 0:02:30 lr 0.000852	time 0.6329 (0.6013)	loss 4.7725 (4.2064)	grad_norm 2.2300 (2.9077)	mem 5329MB
[2022-04-18 12:33:34 tiny] (main.py 226): INFO Train: [75/300][1100/1251]	eta 0:01:30 lr 0.000852	time 0.5798 (0.6000)	loss 4.0717 (4.2081)	grad_norm 2.2676 (2.8969)	mem 5329MB
[2022-04-18 12:34:33 tiny] (main.py 226): INFO Train: [75/300][1200/1251]	eta 0:00:30 lr 0.000851	time 0.7686 (0.5989)	loss 4.7401 (4.2013)	grad_norm 4.6247 (2.8839)	mem 5329MB
[2022-04-18 12:34:54 tiny] (main.py 233): INFO EPOCH 75 training takes 0:12:20
[2022-04-18 12:35:06 tiny] (main.py 273): INFO Test: [0/49]	Time 12.212 (12.212)	Loss 1.6263 (1.6263)	Acc@1 65.820 (65.820)	Acc@5 88.281 (88.281)	Mem 5329MB
[2022-04-18 12:35:26 tiny] (main.py 279): INFO  * Acc@1 63.062 Acc@5 85.502
[2022-04-18 12:35:26 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 63.1%
[2022-04-18 12:35:26 tiny] (main.py 148): INFO Max accuracy: 63.07%
[2022-04-18 12:35:36 tiny] (main.py 226): INFO Train: [76/300][0/1251]	eta 3:42:36 lr 0.000851	time 10.6765 (10.6765)	loss 4.4008 (4.4008)	grad_norm 4.8963 (4.8963)	mem 5329MB
[2022-04-18 12:36:39 tiny] (main.py 226): INFO Train: [76/300][100/1251]	eta 0:13:58 lr 0.000851	time 0.5947 (0.7282)	loss 4.3640 (4.2230)	grad_norm 2.6437 (3.1827)	mem 5329MB
[2022-04-18 12:37:38 tiny] (main.py 226): INFO Train: [76/300][200/1251]	eta 0:11:32 lr 0.000851	time 0.8405 (0.6592)	loss 3.0754 (4.2108)	grad_norm 2.1320 (3.0632)	mem 5329MB
[2022-04-18 12:38:37 tiny] (main.py 226): INFO Train: [76/300][300/1251]	eta 0:10:03 lr 0.000850	time 0.5500 (0.6350)	loss 3.6213 (4.1641)	grad_norm 3.0342 (3.0696)	mem 5329MB
[2022-04-18 12:39:35 tiny] (main.py 226): INFO Train: [76/300][400/1251]	eta 0:08:49 lr 0.000850	time 0.5795 (0.6221)	loss 3.4383 (4.1413)	grad_norm 4.2373 (3.0219)	mem 5329MB
[2022-04-18 12:40:33 tiny] (main.py 226): INFO Train: [76/300][500/1251]	eta 0:07:41 lr 0.000850	time 0.5199 (0.6146)	loss 3.3716 (4.1505)	grad_norm 2.6651 (2.9886)	mem 5329MB
[2022-04-18 12:41:32 tiny] (main.py 226): INFO Train: [76/300][600/1251]	eta 0:06:37 lr 0.000850	time 0.6829 (0.6100)	loss 4.4324 (4.1509)	grad_norm 2.5690 (2.9910)	mem 5329MB
[2022-04-18 12:42:31 tiny] (main.py 226): INFO Train: [76/300][700/1251]	eta 0:05:34 lr 0.000849	time 0.5347 (0.6068)	loss 4.9935 (4.1647)	grad_norm 3.1069 (inf)	mem 5329MB
[2022-04-18 12:43:30 tiny] (main.py 226): INFO Train: [76/300][800/1251]	eta 0:04:32 lr 0.000849	time 0.5783 (0.6048)	loss 4.3691 (4.1686)	grad_norm 3.8630 (inf)	mem 5329MB
[2022-04-18 12:44:29 tiny] (main.py 226): INFO Train: [76/300][900/1251]	eta 0:03:31 lr 0.000849	time 0.5599 (0.6026)	loss 4.5952 (4.1697)	grad_norm 3.2008 (inf)	mem 5329MB
[2022-04-18 12:45:27 tiny] (main.py 226): INFO Train: [76/300][1000/1251]	eta 0:02:30 lr 0.000848	time 0.7271 (0.6011)	loss 4.4839 (4.1624)	grad_norm 2.9013 (inf)	mem 5329MB
[2022-04-18 12:46:26 tiny] (main.py 226): INFO Train: [76/300][1100/1251]	eta 0:01:30 lr 0.000848	time 0.6202 (0.5998)	loss 3.9995 (4.1667)	grad_norm 2.7112 (inf)	mem 5329MB
[2022-04-18 12:47:25 tiny] (main.py 226): INFO Train: [76/300][1200/1251]	eta 0:00:30 lr 0.000848	time 0.5800 (0.5990)	loss 4.7911 (4.1578)	grad_norm 2.2183 (inf)	mem 5329MB
[2022-04-18 12:47:47 tiny] (main.py 233): INFO EPOCH 76 training takes 0:12:21
[2022-04-18 12:47:58 tiny] (main.py 273): INFO Test: [0/49]	Time 11.109 (11.109)	Loss 1.8064 (1.8064)	Acc@1 61.719 (61.719)	Acc@5 85.840 (85.840)	Mem 5329MB
[2022-04-18 12:48:18 tiny] (main.py 279): INFO  * Acc@1 63.522 Acc@5 85.716
[2022-04-18 12:48:18 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 63.5%
[2022-04-18 12:48:18 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_76.pth saving......
[2022-04-18 12:48:18 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_76.pth saved !!!
[2022-04-18 12:48:18 tiny] (main.py 148): INFO Max accuracy: 63.52%
[2022-04-18 12:48:29 tiny] (main.py 226): INFO Train: [77/300][0/1251]	eta 3:59:47 lr 0.000848	time 11.5009 (11.5009)	loss 3.0712 (3.0712)	grad_norm 5.3447 (5.3447)	mem 5329MB
[2022-04-18 12:49:32 tiny] (main.py 226): INFO Train: [77/300][100/1251]	eta 0:14:00 lr 0.000847	time 0.7394 (0.7301)	loss 4.0265 (4.2121)	grad_norm 2.3276 (2.6977)	mem 5329MB
[2022-04-18 12:50:30 tiny] (main.py 226): INFO Train: [77/300][200/1251]	eta 0:11:30 lr 0.000847	time 0.5758 (0.6571)	loss 2.9070 (4.2084)	grad_norm 2.3705 (2.8368)	mem 5329MB
[2022-04-18 12:51:28 tiny] (main.py 226): INFO Train: [77/300][300/1251]	eta 0:10:02 lr 0.000847	time 0.5943 (0.6332)	loss 4.2638 (4.2180)	grad_norm 2.2988 (2.8770)	mem 5329MB
[2022-04-18 12:52:27 tiny] (main.py 226): INFO Train: [77/300][400/1251]	eta 0:08:48 lr 0.000846	time 0.7532 (0.6215)	loss 4.0893 (4.2173)	grad_norm 1.9479 (2.9011)	mem 5329MB
[2022-04-18 12:53:25 tiny] (main.py 226): INFO Train: [77/300][500/1251]	eta 0:07:41 lr 0.000846	time 0.5791 (0.6140)	loss 2.9689 (4.2235)	grad_norm 4.0842 (2.9045)	mem 5329MB
[2022-04-18 12:54:24 tiny] (main.py 226): INFO Train: [77/300][600/1251]	eta 0:06:36 lr 0.000846	time 0.5194 (0.6092)	loss 4.2636 (4.2110)	grad_norm 2.9524 (2.9323)	mem 5329MB
[2022-04-18 12:55:23 tiny] (main.py 226): INFO Train: [77/300][700/1251]	eta 0:05:34 lr 0.000846	time 0.7415 (0.6063)	loss 4.4502 (4.2033)	grad_norm 2.0119 (2.9509)	mem 5329MB
[2022-04-18 12:56:21 tiny] (main.py 226): INFO Train: [77/300][800/1251]	eta 0:04:32 lr 0.000845	time 0.6889 (0.6037)	loss 3.2313 (4.1999)	grad_norm 3.2532 (2.9562)	mem 5329MB
[2022-04-18 12:57:20 tiny] (main.py 226): INFO Train: [77/300][900/1251]	eta 0:03:31 lr 0.000845	time 0.5682 (0.6019)	loss 2.9801 (4.1939)	grad_norm 2.7648 (2.9550)	mem 5329MB
[2022-04-18 12:58:19 tiny] (main.py 226): INFO Train: [77/300][1000/1251]	eta 0:02:30 lr 0.000845	time 0.4613 (0.6007)	loss 3.3710 (4.1957)	grad_norm 2.5570 (2.9535)	mem 5329MB
[2022-04-18 12:59:18 tiny] (main.py 226): INFO Train: [77/300][1100/1251]	eta 0:01:30 lr 0.000844	time 0.5278 (0.5994)	loss 5.0287 (4.1998)	grad_norm 2.6252 (2.9416)	mem 5329MB
[2022-04-18 13:00:16 tiny] (main.py 226): INFO Train: [77/300][1200/1251]	eta 0:00:30 lr 0.000844	time 0.6924 (0.5982)	loss 4.0984 (4.1850)	grad_norm 2.1299 (2.9421)	mem 5329MB
[2022-04-18 13:00:38 tiny] (main.py 233): INFO EPOCH 77 training takes 0:12:20
[2022-04-18 13:00:49 tiny] (main.py 273): INFO Test: [0/49]	Time 10.093 (10.093)	Loss 1.8565 (1.8565)	Acc@1 63.477 (63.477)	Acc@5 85.254 (85.254)	Mem 5329MB
[2022-04-18 13:01:09 tiny] (main.py 279): INFO  * Acc@1 63.266 Acc@5 85.374
[2022-04-18 13:01:09 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 63.3%
[2022-04-18 13:01:09 tiny] (main.py 148): INFO Max accuracy: 63.52%
[2022-04-18 13:01:21 tiny] (main.py 226): INFO Train: [78/300][0/1251]	eta 4:01:47 lr 0.000844	time 11.5968 (11.5968)	loss 4.6019 (4.6019)	grad_norm 1.9624 (1.9624)	mem 5329MB
[2022-04-18 13:02:23 tiny] (main.py 226): INFO Train: [78/300][100/1251]	eta 0:14:04 lr 0.000844	time 0.5263 (0.7336)	loss 4.5260 (4.2037)	grad_norm 4.3339 (2.9197)	mem 5329MB
[2022-04-18 13:03:22 tiny] (main.py 226): INFO Train: [78/300][200/1251]	eta 0:11:33 lr 0.000843	time 0.5970 (0.6594)	loss 4.4393 (4.1437)	grad_norm 2.6205 (2.9658)	mem 5329MB
[2022-04-18 13:04:20 tiny] (main.py 226): INFO Train: [78/300][300/1251]	eta 0:10:02 lr 0.000843	time 0.6438 (0.6335)	loss 2.9906 (4.1422)	grad_norm 2.9625 (inf)	mem 5329MB
[2022-04-18 13:05:18 tiny] (main.py 226): INFO Train: [78/300][400/1251]	eta 0:08:48 lr 0.000843	time 0.5909 (0.6209)	loss 4.9660 (4.1448)	grad_norm 2.7456 (inf)	mem 5329MB
[2022-04-18 13:06:17 tiny] (main.py 226): INFO Train: [78/300][500/1251]	eta 0:07:41 lr 0.000842	time 0.8094 (0.6144)	loss 5.0015 (4.1542)	grad_norm 2.1680 (inf)	mem 5329MB
[2022-04-18 13:07:16 tiny] (main.py 226): INFO Train: [78/300][600/1251]	eta 0:06:36 lr 0.000842	time 0.7205 (0.6097)	loss 3.1685 (4.1408)	grad_norm 1.9634 (inf)	mem 5329MB
[2022-04-18 13:08:14 tiny] (main.py 226): INFO Train: [78/300][700/1251]	eta 0:05:33 lr 0.000842	time 0.4993 (0.6060)	loss 4.5402 (4.1460)	grad_norm 4.6764 (inf)	mem 5329MB
[2022-04-18 13:09:13 tiny] (main.py 226): INFO Train: [78/300][800/1251]	eta 0:04:32 lr 0.000841	time 0.5247 (0.6039)	loss 3.2203 (4.1594)	grad_norm 4.8700 (inf)	mem 5329MB
[2022-04-18 13:10:12 tiny] (main.py 226): INFO Train: [78/300][900/1251]	eta 0:03:31 lr 0.000841	time 0.6734 (0.6026)	loss 4.1659 (4.1631)	grad_norm 3.2001 (inf)	mem 5329MB
[2022-04-18 13:11:11 tiny] (main.py 226): INFO Train: [78/300][1000/1251]	eta 0:02:30 lr 0.000841	time 0.5850 (0.6013)	loss 3.0778 (4.1698)	grad_norm 3.3425 (inf)	mem 5329MB
[2022-04-18 13:12:10 tiny] (main.py 226): INFO Train: [78/300][1100/1251]	eta 0:01:30 lr 0.000841	time 0.5183 (0.5997)	loss 3.0445 (4.1729)	grad_norm 5.7108 (inf)	mem 5329MB
[2022-04-18 13:13:09 tiny] (main.py 226): INFO Train: [78/300][1200/1251]	eta 0:00:30 lr 0.000840	time 0.6409 (0.5989)	loss 4.8941 (4.1746)	grad_norm 2.4620 (inf)	mem 5329MB
[2022-04-18 13:13:31 tiny] (main.py 233): INFO EPOCH 78 training takes 0:12:21
[2022-04-18 13:13:42 tiny] (main.py 273): INFO Test: [0/49]	Time 11.946 (11.946)	Loss 1.7371 (1.7371)	Acc@1 63.867 (63.867)	Acc@5 84.961 (84.961)	Mem 5329MB
[2022-04-18 13:14:02 tiny] (main.py 279): INFO  * Acc@1 63.416 Acc@5 85.738
[2022-04-18 13:14:02 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 63.4%
[2022-04-18 13:14:02 tiny] (main.py 148): INFO Max accuracy: 63.52%
[2022-04-18 13:14:13 tiny] (main.py 226): INFO Train: [79/300][0/1251]	eta 3:46:28 lr 0.000840	time 10.8624 (10.8624)	loss 3.4914 (3.4914)	grad_norm 3.7487 (3.7487)	mem 5329MB
[2022-04-18 13:15:15 tiny] (main.py 226): INFO Train: [79/300][100/1251]	eta 0:13:53 lr 0.000840	time 0.8338 (0.7246)	loss 3.7796 (4.0723)	grad_norm 5.9049 (3.0521)	mem 5329MB
[2022-04-18 13:16:14 tiny] (main.py 226): INFO Train: [79/300][200/1251]	eta 0:11:31 lr 0.000839	time 0.7484 (0.6575)	loss 3.8671 (4.1412)	grad_norm 3.1441 (2.9348)	mem 5329MB
[2022-04-18 13:17:12 tiny] (main.py 226): INFO Train: [79/300][300/1251]	eta 0:10:01 lr 0.000839	time 0.6491 (0.6329)	loss 4.0503 (4.1307)	grad_norm 2.4165 (2.9492)	mem 5329MB
[2022-04-18 13:18:11 tiny] (main.py 226): INFO Train: [79/300][400/1251]	eta 0:08:48 lr 0.000839	time 0.8132 (0.6212)	loss 3.3669 (4.1223)	grad_norm 3.7378 (2.9588)	mem 5329MB
[2022-04-18 13:19:09 tiny] (main.py 226): INFO Train: [79/300][500/1251]	eta 0:07:41 lr 0.000839	time 0.5567 (0.6139)	loss 3.6975 (4.1474)	grad_norm 3.7875 (3.0513)	mem 5329MB
[2022-04-18 13:20:08 tiny] (main.py 226): INFO Train: [79/300][600/1251]	eta 0:06:36 lr 0.000838	time 0.5502 (0.6092)	loss 3.6589 (4.1664)	grad_norm 2.4705 (3.0120)	mem 5329MB
[2022-04-18 13:21:07 tiny] (main.py 226): INFO Train: [79/300][700/1251]	eta 0:05:34 lr 0.000838	time 0.6303 (0.6064)	loss 4.5346 (4.1756)	grad_norm 1.7158 (2.9791)	mem 5329MB
[2022-04-18 13:22:06 tiny] (main.py 226): INFO Train: [79/300][800/1251]	eta 0:04:32 lr 0.000838	time 0.4842 (0.6040)	loss 4.0769 (4.1671)	grad_norm 3.1514 (2.9648)	mem 5329MB
[2022-04-18 13:23:04 tiny] (main.py 226): INFO Train: [79/300][900/1251]	eta 0:03:31 lr 0.000837	time 0.4919 (0.6019)	loss 3.7968 (4.1631)	grad_norm 2.6643 (2.9471)	mem 5329MB
[2022-04-18 13:24:03 tiny] (main.py 226): INFO Train: [79/300][1000/1251]	eta 0:02:30 lr 0.000837	time 0.6440 (0.6007)	loss 4.0180 (4.1615)	grad_norm 1.8302 (2.9384)	mem 5329MB
[2022-04-18 13:25:01 tiny] (main.py 226): INFO Train: [79/300][1100/1251]	eta 0:01:30 lr 0.000837	time 0.6294 (0.5992)	loss 5.0869 (4.1654)	grad_norm 8.8685 (2.9370)	mem 5329MB
[2022-04-18 13:26:00 tiny] (main.py 226): INFO Train: [79/300][1200/1251]	eta 0:00:30 lr 0.000836	time 0.4931 (0.5983)	loss 3.7163 (4.1661)	grad_norm 2.0504 (2.9574)	mem 5329MB
[2022-04-18 13:26:23 tiny] (main.py 233): INFO EPOCH 79 training takes 0:12:20
[2022-04-18 13:26:34 tiny] (main.py 273): INFO Test: [0/49]	Time 11.472 (11.472)	Loss 1.8282 (1.8282)	Acc@1 65.723 (65.723)	Acc@5 85.059 (85.059)	Mem 5329MB
[2022-04-18 13:26:54 tiny] (main.py 279): INFO  * Acc@1 62.850 Acc@5 85.258
[2022-04-18 13:26:54 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 62.9%
[2022-04-18 13:26:54 tiny] (main.py 148): INFO Max accuracy: 63.52%
[2022-04-18 13:27:06 tiny] (main.py 226): INFO Train: [80/300][0/1251]	eta 4:18:34 lr 0.000836	time 12.4020 (12.4020)	loss 3.1906 (3.1906)	grad_norm 4.0065 (4.0065)	mem 5329MB
[2022-04-18 13:28:08 tiny] (main.py 226): INFO Train: [80/300][100/1251]	eta 0:14:01 lr 0.000836	time 0.4748 (0.7312)	loss 4.5241 (4.1390)	grad_norm 4.7862 (3.0767)	mem 5329MB
[2022-04-18 13:29:06 tiny] (main.py 226): INFO Train: [80/300][200/1251]	eta 0:11:30 lr 0.000836	time 0.6238 (0.6568)	loss 4.4558 (4.1744)	grad_norm 2.2791 (3.0217)	mem 5329MB
[2022-04-18 13:30:04 tiny] (main.py 226): INFO Train: [80/300][300/1251]	eta 0:10:01 lr 0.000835	time 0.6263 (0.6324)	loss 3.6751 (4.1771)	grad_norm 2.1846 (2.8725)	mem 5329MB
[2022-04-18 13:31:03 tiny] (main.py 226): INFO Train: [80/300][400/1251]	eta 0:08:48 lr 0.000835	time 0.5309 (0.6207)	loss 4.2063 (4.1436)	grad_norm 3.2377 (3.0040)	mem 5329MB
[2022-04-18 13:32:01 tiny] (main.py 226): INFO Train: [80/300][500/1251]	eta 0:07:39 lr 0.000835	time 0.5082 (0.6125)	loss 4.2871 (4.1400)	grad_norm 4.8569 (2.9605)	mem 5329MB
[2022-04-18 13:33:00 tiny] (main.py 226): INFO Train: [80/300][600/1251]	eta 0:06:36 lr 0.000834	time 0.6458 (0.6090)	loss 3.3254 (4.1365)	grad_norm 3.3630 (inf)	mem 5329MB
[2022-04-18 13:33:59 tiny] (main.py 226): INFO Train: [80/300][700/1251]	eta 0:05:34 lr 0.000834	time 0.3975 (0.6062)	loss 3.3225 (4.1415)	grad_norm 4.7969 (inf)	mem 5329MB
[2022-04-18 13:34:58 tiny] (main.py 226): INFO Train: [80/300][800/1251]	eta 0:04:32 lr 0.000834	time 0.6239 (0.6040)	loss 4.5891 (4.1470)	grad_norm 4.3971 (inf)	mem 5329MB
[2022-04-18 13:35:57 tiny] (main.py 226): INFO Train: [80/300][900/1251]	eta 0:03:31 lr 0.000833	time 0.6260 (0.6026)	loss 4.2086 (4.1346)	grad_norm 1.9546 (inf)	mem 5329MB
[2022-04-18 13:36:55 tiny] (main.py 226): INFO Train: [80/300][1000/1251]	eta 0:02:30 lr 0.000833	time 0.5038 (0.6007)	loss 3.0734 (4.1371)	grad_norm 2.9313 (inf)	mem 5329MB
[2022-04-18 13:37:54 tiny] (main.py 226): INFO Train: [80/300][1100/1251]	eta 0:01:30 lr 0.000833	time 0.6242 (0.6000)	loss 3.1731 (4.1403)	grad_norm 2.7330 (inf)	mem 5329MB
[2022-04-18 13:38:53 tiny] (main.py 226): INFO Train: [80/300][1200/1251]	eta 0:00:30 lr 0.000833	time 0.5716 (0.5988)	loss 4.5594 (4.1369)	grad_norm 2.7771 (inf)	mem 5329MB
[2022-04-18 13:39:15 tiny] (main.py 233): INFO EPOCH 80 training takes 0:12:21
[2022-04-18 13:39:26 tiny] (main.py 273): INFO Test: [0/49]	Time 10.642 (10.642)	Loss 1.7705 (1.7705)	Acc@1 63.477 (63.477)	Acc@5 86.621 (86.621)	Mem 5329MB
[2022-04-18 13:39:46 tiny] (main.py 279): INFO  * Acc@1 63.620 Acc@5 85.740
[2022-04-18 13:39:46 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 63.6%
[2022-04-18 13:39:46 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_80.pth saving......
[2022-04-18 13:39:46 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_80.pth saved !!!
[2022-04-18 13:39:46 tiny] (main.py 148): INFO Max accuracy: 63.62%
[2022-04-18 13:39:58 tiny] (main.py 226): INFO Train: [81/300][0/1251]	eta 4:13:26 lr 0.000832	time 12.1554 (12.1554)	loss 3.4622 (3.4622)	grad_norm 2.5217 (2.5217)	mem 5329MB
[2022-04-18 13:40:59 tiny] (main.py 226): INFO Train: [81/300][100/1251]	eta 0:13:52 lr 0.000832	time 0.5544 (0.7231)	loss 4.5634 (4.1441)	grad_norm 2.7879 (3.2554)	mem 5329MB
[2022-04-18 13:41:58 tiny] (main.py 226): INFO Train: [81/300][200/1251]	eta 0:11:28 lr 0.000832	time 0.6410 (0.6551)	loss 3.7651 (4.1527)	grad_norm 2.3204 (3.2041)	mem 5329MB
[2022-04-18 13:42:56 tiny] (main.py 226): INFO Train: [81/300][300/1251]	eta 0:10:01 lr 0.000831	time 0.5976 (0.6321)	loss 4.2236 (4.1471)	grad_norm 2.6994 (3.1295)	mem 5329MB
[2022-04-18 13:43:55 tiny] (main.py 226): INFO Train: [81/300][400/1251]	eta 0:08:48 lr 0.000831	time 0.6936 (0.6211)	loss 4.7851 (4.1593)	grad_norm 7.2890 (3.1194)	mem 5329MB
[2022-04-18 13:44:54 tiny] (main.py 226): INFO Train: [81/300][500/1251]	eta 0:07:41 lr 0.000831	time 0.6977 (0.6139)	loss 4.5515 (4.1663)	grad_norm 5.4370 (3.0667)	mem 5329MB
[2022-04-18 13:45:52 tiny] (main.py 226): INFO Train: [81/300][600/1251]	eta 0:06:36 lr 0.000830	time 0.5404 (0.6095)	loss 4.5675 (4.1628)	grad_norm 3.0396 (3.0699)	mem 5329MB
[2022-04-18 13:46:51 tiny] (main.py 226): INFO Train: [81/300][700/1251]	eta 0:05:33 lr 0.000830	time 0.6967 (0.6055)	loss 4.5291 (4.1717)	grad_norm 3.4950 (3.0567)	mem 5329MB
[2022-04-18 13:47:50 tiny] (main.py 226): INFO Train: [81/300][800/1251]	eta 0:04:32 lr 0.000830	time 0.3876 (0.6041)	loss 4.9904 (4.1601)	grad_norm 1.6984 (3.0414)	mem 5329MB
[2022-04-18 13:48:49 tiny] (main.py 226): INFO Train: [81/300][900/1251]	eta 0:03:31 lr 0.000830	time 0.5956 (0.6024)	loss 4.5169 (4.1692)	grad_norm 4.2113 (3.0223)	mem 5329MB
[2022-04-18 13:49:48 tiny] (main.py 226): INFO Train: [81/300][1000/1251]	eta 0:02:30 lr 0.000829	time 0.7286 (0.6012)	loss 4.2680 (4.1656)	grad_norm 2.1065 (3.0281)	mem 5329MB
[2022-04-18 13:50:47 tiny] (main.py 226): INFO Train: [81/300][1100/1251]	eta 0:01:30 lr 0.000829	time 0.5524 (0.5999)	loss 3.8358 (4.1573)	grad_norm 2.8755 (3.0238)	mem 5329MB
[2022-04-18 13:51:45 tiny] (main.py 226): INFO Train: [81/300][1200/1251]	eta 0:00:30 lr 0.000829	time 0.4041 (0.5989)	loss 3.4263 (4.1558)	grad_norm 5.4894 (3.0206)	mem 5329MB
[2022-04-18 13:52:07 tiny] (main.py 233): INFO EPOCH 81 training takes 0:12:21
[2022-04-18 13:52:20 tiny] (main.py 273): INFO Test: [0/49]	Time 12.251 (12.251)	Loss 1.6704 (1.6704)	Acc@1 65.039 (65.039)	Acc@5 86.328 (86.328)	Mem 5329MB
[2022-04-18 13:52:38 tiny] (main.py 279): INFO  * Acc@1 63.662 Acc@5 85.952
[2022-04-18 13:52:38 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 63.7%
[2022-04-18 13:52:38 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_81.pth saving......
[2022-04-18 13:52:38 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_81.pth saved !!!
[2022-04-18 13:52:38 tiny] (main.py 148): INFO Max accuracy: 63.66%
[2022-04-18 13:52:51 tiny] (main.py 226): INFO Train: [82/300][0/1251]	eta 4:20:27 lr 0.000828	time 12.4920 (12.4920)	loss 2.7383 (2.7383)	grad_norm 3.4509 (3.4509)	mem 5329MB
[2022-04-18 13:53:52 tiny] (main.py 226): INFO Train: [82/300][100/1251]	eta 0:13:55 lr 0.000828	time 0.4926 (0.7255)	loss 4.4060 (4.1366)	grad_norm 2.8149 (2.8753)	mem 5329MB
[2022-04-18 13:54:51 tiny] (main.py 226): INFO Train: [82/300][200/1251]	eta 0:11:31 lr 0.000828	time 0.5047 (0.6580)	loss 3.2442 (4.1841)	grad_norm 3.4673 (2.9580)	mem 5329MB
[2022-04-18 13:55:49 tiny] (main.py 226): INFO Train: [82/300][300/1251]	eta 0:10:01 lr 0.000828	time 0.5402 (0.6321)	loss 4.3403 (4.1739)	grad_norm 3.7592 (2.9797)	mem 5329MB
[2022-04-18 13:56:48 tiny] (main.py 226): INFO Train: [82/300][400/1251]	eta 0:08:49 lr 0.000827	time 0.6231 (0.6218)	loss 3.2110 (4.1699)	grad_norm 2.7440 (3.0355)	mem 5329MB
[2022-04-18 13:57:46 tiny] (main.py 226): INFO Train: [82/300][500/1251]	eta 0:07:41 lr 0.000827	time 0.5942 (0.6140)	loss 4.4084 (4.1537)	grad_norm 2.0616 (2.9827)	mem 5329MB
[2022-04-18 13:58:45 tiny] (main.py 226): INFO Train: [82/300][600/1251]	eta 0:06:37 lr 0.000827	time 0.6009 (0.6099)	loss 4.8189 (4.1510)	grad_norm 2.4684 (3.0293)	mem 5329MB
[2022-04-18 13:59:44 tiny] (main.py 226): INFO Train: [82/300][700/1251]	eta 0:05:34 lr 0.000826	time 0.4778 (0.6069)	loss 4.7453 (4.1636)	grad_norm 3.4210 (3.0087)	mem 5329MB
[2022-04-18 14:00:43 tiny] (main.py 226): INFO Train: [82/300][800/1251]	eta 0:04:32 lr 0.000826	time 0.7106 (0.6045)	loss 3.1231 (4.1591)	grad_norm 2.3336 (3.0121)	mem 5329MB
[2022-04-18 14:01:41 tiny] (main.py 226): INFO Train: [82/300][900/1251]	eta 0:03:31 lr 0.000826	time 0.5094 (0.6025)	loss 4.3755 (4.1649)	grad_norm 3.2833 (inf)	mem 5329MB
[2022-04-18 14:02:40 tiny] (main.py 226): INFO Train: [82/300][1000/1251]	eta 0:02:30 lr 0.000825	time 0.4933 (0.6013)	loss 3.5100 (4.1656)	grad_norm 2.3287 (inf)	mem 5329MB
[2022-04-18 14:03:39 tiny] (main.py 226): INFO Train: [82/300][1100/1251]	eta 0:01:30 lr 0.000825	time 0.5638 (0.6003)	loss 4.5196 (4.1617)	grad_norm 5.0893 (inf)	mem 5329MB
[2022-04-18 14:04:38 tiny] (main.py 226): INFO Train: [82/300][1200/1251]	eta 0:00:30 lr 0.000825	time 0.3778 (0.5990)	loss 5.0790 (4.1539)	grad_norm 2.4562 (inf)	mem 5329MB
[2022-04-18 14:05:00 tiny] (main.py 233): INFO EPOCH 82 training takes 0:12:21
[2022-04-18 14:05:12 tiny] (main.py 273): INFO Test: [0/49]	Time 11.978 (11.978)	Loss 1.7594 (1.7594)	Acc@1 62.988 (62.988)	Acc@5 85.840 (85.840)	Mem 5329MB
[2022-04-18 14:05:32 tiny] (main.py 279): INFO  * Acc@1 63.594 Acc@5 85.828
[2022-04-18 14:05:32 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 63.6%
[2022-04-18 14:05:32 tiny] (main.py 148): INFO Max accuracy: 63.66%
[2022-04-18 14:05:44 tiny] (main.py 226): INFO Train: [83/300][0/1251]	eta 4:24:45 lr 0.000825	time 12.6986 (12.6986)	loss 3.6103 (3.6103)	grad_norm 1.6747 (1.6747)	mem 5329MB
[2022-04-18 14:06:46 tiny] (main.py 226): INFO Train: [83/300][100/1251]	eta 0:14:06 lr 0.000824	time 0.6507 (0.7352)	loss 3.8317 (4.2201)	grad_norm 2.1783 (3.0983)	mem 5329MB
[2022-04-18 14:07:45 tiny] (main.py 226): INFO Train: [83/300][200/1251]	eta 0:11:35 lr 0.000824	time 0.6822 (0.6615)	loss 3.8809 (4.1740)	grad_norm 3.2074 (3.0042)	mem 5329MB
[2022-04-18 14:08:43 tiny] (main.py 226): INFO Train: [83/300][300/1251]	eta 0:10:03 lr 0.000824	time 0.5891 (0.6348)	loss 4.8487 (4.1628)	grad_norm 1.9889 (3.0388)	mem 5329MB
[2022-04-18 14:09:42 tiny] (main.py 226): INFO Train: [83/300][400/1251]	eta 0:08:50 lr 0.000823	time 0.6346 (0.6231)	loss 3.9306 (4.1424)	grad_norm 5.0939 (2.9898)	mem 5329MB
[2022-04-18 14:10:40 tiny] (main.py 226): INFO Train: [83/300][500/1251]	eta 0:07:42 lr 0.000823	time 0.5671 (0.6162)	loss 3.7189 (4.1283)	grad_norm 2.5508 (3.0027)	mem 5329MB
[2022-04-18 14:11:39 tiny] (main.py 226): INFO Train: [83/300][600/1251]	eta 0:06:37 lr 0.000823	time 0.6282 (0.6109)	loss 3.3497 (4.1283)	grad_norm 2.7568 (3.0220)	mem 5329MB
[2022-04-18 14:12:38 tiny] (main.py 226): INFO Train: [83/300][700/1251]	eta 0:05:34 lr 0.000822	time 0.6971 (0.6075)	loss 3.1908 (4.1356)	grad_norm 2.1853 (3.0137)	mem 5329MB
[2022-04-18 14:13:37 tiny] (main.py 226): INFO Train: [83/300][800/1251]	eta 0:04:33 lr 0.000822	time 0.6669 (0.6055)	loss 3.9273 (4.1313)	grad_norm 3.8599 (2.9977)	mem 5329MB
[2022-04-18 14:14:35 tiny] (main.py 226): INFO Train: [83/300][900/1251]	eta 0:03:31 lr 0.000822	time 0.7389 (0.6034)	loss 3.6190 (4.1310)	grad_norm 3.4407 (3.0205)	mem 5329MB
[2022-04-18 14:15:34 tiny] (main.py 226): INFO Train: [83/300][1000/1251]	eta 0:02:31 lr 0.000821	time 0.8421 (0.6019)	loss 4.6757 (4.1357)	grad_norm 3.0344 (2.9841)	mem 5329MB
[2022-04-18 14:16:33 tiny] (main.py 226): INFO Train: [83/300][1100/1251]	eta 0:01:30 lr 0.000821	time 0.5976 (0.6008)	loss 3.8239 (4.1283)	grad_norm 2.5255 (2.9840)	mem 5329MB
[2022-04-18 14:17:32 tiny] (main.py 226): INFO Train: [83/300][1200/1251]	eta 0:00:30 lr 0.000821	time 0.6720 (0.5998)	loss 3.5031 (4.1315)	grad_norm 3.9296 (2.9799)	mem 5329MB
[2022-04-18 14:17:53 tiny] (main.py 233): INFO EPOCH 83 training takes 0:12:21
[2022-04-18 14:18:04 tiny] (main.py 273): INFO Test: [0/49]	Time 10.383 (10.383)	Loss 1.8860 (1.8860)	Acc@1 62.988 (62.988)	Acc@5 84.375 (84.375)	Mem 5329MB
[2022-04-18 14:18:25 tiny] (main.py 279): INFO  * Acc@1 63.470 Acc@5 85.582
[2022-04-18 14:18:25 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 63.5%
[2022-04-18 14:18:25 tiny] (main.py 148): INFO Max accuracy: 63.66%
[2022-04-18 14:18:36 tiny] (main.py 226): INFO Train: [84/300][0/1251]	eta 3:43:09 lr 0.000821	time 10.7030 (10.7030)	loss 3.9844 (3.9844)	grad_norm 3.1474 (3.1474)	mem 5329MB
[2022-04-18 14:19:39 tiny] (main.py 226): INFO Train: [84/300][100/1251]	eta 0:13:55 lr 0.000820	time 0.4907 (0.7262)	loss 3.0165 (4.1363)	grad_norm 2.4792 (2.9351)	mem 5329MB
[2022-04-18 14:20:38 tiny] (main.py 226): INFO Train: [84/300][200/1251]	eta 0:11:32 lr 0.000820	time 0.6552 (0.6587)	loss 4.5685 (4.1415)	grad_norm 3.0054 (3.0614)	mem 5329MB
[2022-04-18 14:21:36 tiny] (main.py 226): INFO Train: [84/300][300/1251]	eta 0:10:01 lr 0.000820	time 0.4106 (0.6329)	loss 2.9046 (4.1139)	grad_norm 2.6277 (2.9988)	mem 5329MB
[2022-04-18 14:22:34 tiny] (main.py 226): INFO Train: [84/300][400/1251]	eta 0:08:48 lr 0.000819	time 0.5828 (0.6209)	loss 3.0866 (4.1364)	grad_norm 4.7905 (inf)	mem 5329MB
[2022-04-18 14:23:33 tiny] (main.py 226): INFO Train: [84/300][500/1251]	eta 0:07:40 lr 0.000819	time 0.7411 (0.6136)	loss 4.3381 (4.1496)	grad_norm 3.5903 (inf)	mem 5329MB
[2022-04-18 14:24:31 tiny] (main.py 226): INFO Train: [84/300][600/1251]	eta 0:06:36 lr 0.000819	time 0.6442 (0.6092)	loss 4.4029 (4.1373)	grad_norm 2.9421 (inf)	mem 5329MB
[2022-04-18 14:25:30 tiny] (main.py 226): INFO Train: [84/300][700/1251]	eta 0:05:34 lr 0.000818	time 0.7626 (0.6065)	loss 3.4368 (4.1467)	grad_norm 2.2020 (inf)	mem 5329MB
[2022-04-18 14:26:29 tiny] (main.py 226): INFO Train: [84/300][800/1251]	eta 0:04:32 lr 0.000818	time 0.5632 (0.6039)	loss 4.6458 (4.1507)	grad_norm 2.2273 (inf)	mem 5329MB
[2022-04-18 14:27:28 tiny] (main.py 226): INFO Train: [84/300][900/1251]	eta 0:03:31 lr 0.000818	time 0.6235 (0.6025)	loss 4.8096 (4.1575)	grad_norm 2.5004 (inf)	mem 5329MB
[2022-04-18 14:28:27 tiny] (main.py 226): INFO Train: [84/300][1000/1251]	eta 0:02:30 lr 0.000817	time 0.5871 (0.6008)	loss 3.2711 (4.1584)	grad_norm 2.1850 (inf)	mem 5329MB
[2022-04-18 14:29:25 tiny] (main.py 226): INFO Train: [84/300][1100/1251]	eta 0:01:30 lr 0.000817	time 0.6430 (0.5996)	loss 3.1795 (4.1566)	grad_norm 2.0256 (inf)	mem 5329MB
[2022-04-18 14:30:24 tiny] (main.py 226): INFO Train: [84/300][1200/1251]	eta 0:00:30 lr 0.000817	time 0.6043 (0.5986)	loss 4.8955 (4.1575)	grad_norm 2.6946 (inf)	mem 5329MB
[2022-04-18 14:30:46 tiny] (main.py 233): INFO EPOCH 84 training takes 0:12:20
[2022-04-18 14:30:59 tiny] (main.py 273): INFO Test: [0/49]	Time 12.481 (12.481)	Loss 1.8799 (1.8799)	Acc@1 63.672 (63.672)	Acc@5 84.668 (84.668)	Mem 5329MB
[2022-04-18 14:31:17 tiny] (main.py 279): INFO  * Acc@1 63.742 Acc@5 85.692
[2022-04-18 14:31:17 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 63.7%
[2022-04-18 14:31:17 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_84.pth saving......
[2022-04-18 14:31:17 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_84.pth saved !!!
[2022-04-18 14:31:17 tiny] (main.py 148): INFO Max accuracy: 63.74%
[2022-04-18 14:31:29 tiny] (main.py 226): INFO Train: [85/300][0/1251]	eta 4:04:05 lr 0.000817	time 11.7073 (11.7073)	loss 2.9609 (2.9609)	grad_norm 3.5692 (3.5692)	mem 5329MB
[2022-04-18 14:32:31 tiny] (main.py 226): INFO Train: [85/300][100/1251]	eta 0:13:56 lr 0.000816	time 0.5515 (0.7271)	loss 2.7971 (4.1407)	grad_norm 3.1295 (2.9598)	mem 5329MB
[2022-04-18 14:33:29 tiny] (main.py 226): INFO Train: [85/300][200/1251]	eta 0:11:28 lr 0.000816	time 0.5377 (0.6551)	loss 4.5452 (4.1398)	grad_norm 3.2067 (3.1586)	mem 5329MB
[2022-04-18 14:34:28 tiny] (main.py 226): INFO Train: [85/300][300/1251]	eta 0:10:02 lr 0.000816	time 0.4976 (0.6334)	loss 4.7323 (4.1400)	grad_norm 2.9638 (3.1306)	mem 5329MB
[2022-04-18 14:35:27 tiny] (main.py 226): INFO Train: [85/300][400/1251]	eta 0:08:48 lr 0.000815	time 0.6273 (0.6212)	loss 4.3568 (4.1417)	grad_norm 2.1784 (3.0872)	mem 5329MB
[2022-04-18 14:36:25 tiny] (main.py 226): INFO Train: [85/300][500/1251]	eta 0:07:41 lr 0.000815	time 0.5207 (0.6139)	loss 3.9699 (4.1301)	grad_norm 2.1053 (3.0701)	mem 5329MB
[2022-04-18 14:37:24 tiny] (main.py 226): INFO Train: [85/300][600/1251]	eta 0:06:37 lr 0.000815	time 0.6312 (0.6102)	loss 3.3706 (4.1320)	grad_norm 2.4909 (3.0435)	mem 5329MB
[2022-04-18 14:38:23 tiny] (main.py 226): INFO Train: [85/300][700/1251]	eta 0:05:34 lr 0.000814	time 0.6691 (0.6067)	loss 5.0413 (4.1338)	grad_norm 2.1645 (3.0193)	mem 5329MB
[2022-04-18 14:39:22 tiny] (main.py 226): INFO Train: [85/300][800/1251]	eta 0:04:32 lr 0.000814	time 0.7029 (0.6047)	loss 4.0582 (4.1279)	grad_norm 1.8107 (3.0089)	mem 5329MB
[2022-04-18 14:40:21 tiny] (main.py 226): INFO Train: [85/300][900/1251]	eta 0:03:31 lr 0.000814	time 0.7158 (0.6030)	loss 4.5042 (4.1221)	grad_norm 2.9417 (3.0172)	mem 5329MB
[2022-04-18 14:41:19 tiny] (main.py 226): INFO Train: [85/300][1000/1251]	eta 0:02:30 lr 0.000813	time 0.3958 (0.6012)	loss 3.6348 (4.1240)	grad_norm 3.8692 (3.0485)	mem 5329MB
[2022-04-18 14:42:18 tiny] (main.py 226): INFO Train: [85/300][1100/1251]	eta 0:01:30 lr 0.000813	time 0.5618 (0.6002)	loss 4.5092 (4.1260)	grad_norm 2.1374 (3.0240)	mem 5329MB
[2022-04-18 14:43:17 tiny] (main.py 226): INFO Train: [85/300][1200/1251]	eta 0:00:30 lr 0.000813	time 0.7032 (0.5993)	loss 4.6637 (4.1310)	grad_norm 2.1189 (3.0231)	mem 5329MB
[2022-04-18 14:43:39 tiny] (main.py 233): INFO EPOCH 85 training takes 0:12:21
[2022-04-18 14:43:50 tiny] (main.py 273): INFO Test: [0/49]	Time 10.393 (10.393)	Loss 1.6840 (1.6840)	Acc@1 64.551 (64.551)	Acc@5 87.695 (87.695)	Mem 5329MB
[2022-04-18 14:44:10 tiny] (main.py 279): INFO  * Acc@1 64.058 Acc@5 86.228
[2022-04-18 14:44:10 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 64.1%
[2022-04-18 14:44:10 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_85.pth saving......
[2022-04-18 14:44:10 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_85.pth saved !!!
[2022-04-18 14:44:10 tiny] (main.py 148): INFO Max accuracy: 64.06%
[2022-04-18 14:44:21 tiny] (main.py 226): INFO Train: [86/300][0/1251]	eta 3:36:32 lr 0.000812	time 10.3858 (10.3858)	loss 4.5099 (4.5099)	grad_norm 3.4781 (3.4781)	mem 5329MB
[2022-04-18 14:45:23 tiny] (main.py 226): INFO Train: [86/300][100/1251]	eta 0:13:52 lr 0.000812	time 0.5241 (0.7234)	loss 4.9957 (4.2200)	grad_norm 3.4099 (inf)	mem 5329MB
[2022-04-18 14:46:23 tiny] (main.py 226): INFO Train: [86/300][200/1251]	eta 0:11:32 lr 0.000812	time 0.5006 (0.6585)	loss 4.7020 (4.1800)	grad_norm 2.4155 (inf)	mem 5329MB
[2022-04-18 14:47:21 tiny] (main.py 226): INFO Train: [86/300][300/1251]	eta 0:10:02 lr 0.000811	time 0.5403 (0.6337)	loss 4.4290 (4.2294)	grad_norm 3.1519 (inf)	mem 5329MB
[2022-04-18 14:48:19 tiny] (main.py 226): INFO Train: [86/300][400/1251]	eta 0:08:48 lr 0.000811	time 0.5546 (0.6208)	loss 4.3370 (4.2049)	grad_norm 2.0971 (inf)	mem 5329MB
[2022-04-18 14:49:18 tiny] (main.py 226): INFO Train: [86/300][500/1251]	eta 0:07:40 lr 0.000811	time 0.5097 (0.6132)	loss 4.1371 (4.1781)	grad_norm 2.1941 (inf)	mem 5329MB
[2022-04-18 14:50:17 tiny] (main.py 226): INFO Train: [86/300][600/1251]	eta 0:06:37 lr 0.000811	time 0.7276 (0.6098)	loss 4.8956 (4.1736)	grad_norm 3.2165 (inf)	mem 5329MB
[2022-04-18 14:51:16 tiny] (main.py 226): INFO Train: [86/300][700/1251]	eta 0:05:34 lr 0.000810	time 0.6633 (0.6067)	loss 3.5184 (4.1816)	grad_norm 4.6878 (inf)	mem 5329MB
[2022-04-18 14:52:15 tiny] (main.py 226): INFO Train: [86/300][800/1251]	eta 0:04:32 lr 0.000810	time 0.7240 (0.6045)	loss 4.8122 (4.1785)	grad_norm 5.1866 (inf)	mem 5329MB
[2022-04-18 14:53:13 tiny] (main.py 226): INFO Train: [86/300][900/1251]	eta 0:03:31 lr 0.000810	time 0.4797 (0.6023)	loss 5.1229 (4.1747)	grad_norm 2.6997 (inf)	mem 5329MB
[2022-04-18 14:54:12 tiny] (main.py 226): INFO Train: [86/300][1000/1251]	eta 0:02:30 lr 0.000809	time 0.5434 (0.6011)	loss 4.4481 (4.1629)	grad_norm 2.6333 (inf)	mem 5329MB
[2022-04-18 14:55:10 tiny] (main.py 226): INFO Train: [86/300][1100/1251]	eta 0:01:30 lr 0.000809	time 0.4845 (0.5994)	loss 3.9833 (4.1584)	grad_norm 3.9319 (inf)	mem 5329MB
[2022-04-18 14:56:10 tiny] (main.py 226): INFO Train: [86/300][1200/1251]	eta 0:00:30 lr 0.000809	time 0.5612 (0.5988)	loss 4.5513 (4.1563)	grad_norm 2.1164 (inf)	mem 5329MB
[2022-04-18 14:56:31 tiny] (main.py 233): INFO EPOCH 86 training takes 0:12:21
[2022-04-18 14:56:43 tiny] (main.py 273): INFO Test: [0/49]	Time 11.842 (11.842)	Loss 1.7272 (1.7272)	Acc@1 62.402 (62.402)	Acc@5 85.449 (85.449)	Mem 5329MB
[2022-04-18 14:57:02 tiny] (main.py 279): INFO  * Acc@1 63.720 Acc@5 86.010
[2022-04-18 14:57:02 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 63.7%
[2022-04-18 14:57:02 tiny] (main.py 148): INFO Max accuracy: 64.06%
[2022-04-18 14:57:14 tiny] (main.py 226): INFO Train: [87/300][0/1251]	eta 4:02:26 lr 0.000808	time 11.6276 (11.6276)	loss 4.5489 (4.5489)	grad_norm 3.6667 (3.6667)	mem 5329MB
[2022-04-18 14:58:16 tiny] (main.py 226): INFO Train: [87/300][100/1251]	eta 0:13:55 lr 0.000808	time 0.5735 (0.7263)	loss 4.4940 (4.1475)	grad_norm 1.8930 (3.1839)	mem 5329MB
[2022-04-18 14:59:14 tiny] (main.py 226): INFO Train: [87/300][200/1251]	eta 0:11:29 lr 0.000808	time 0.4907 (0.6562)	loss 3.7252 (4.0511)	grad_norm 2.1985 (3.1947)	mem 5329MB
[2022-04-18 15:00:13 tiny] (main.py 226): INFO Train: [87/300][300/1251]	eta 0:10:01 lr 0.000807	time 0.5372 (0.6322)	loss 4.0928 (4.0764)	grad_norm 3.3671 (3.0994)	mem 5329MB
[2022-04-18 15:01:11 tiny] (main.py 226): INFO Train: [87/300][400/1251]	eta 0:08:48 lr 0.000807	time 0.5980 (0.6211)	loss 2.8910 (4.0800)	grad_norm 4.6098 (3.0931)	mem 5329MB
[2022-04-18 15:02:09 tiny] (main.py 226): INFO Train: [87/300][500/1251]	eta 0:07:40 lr 0.000807	time 0.6661 (0.6129)	loss 4.5350 (4.0921)	grad_norm 3.2846 (3.0966)	mem 5329MB
[2022-04-18 15:03:08 tiny] (main.py 226): INFO Train: [87/300][600/1251]	eta 0:06:36 lr 0.000806	time 0.6573 (0.6090)	loss 3.8330 (4.1009)	grad_norm 2.7038 (3.0628)	mem 5329MB
[2022-04-18 15:04:07 tiny] (main.py 226): INFO Train: [87/300][700/1251]	eta 0:05:33 lr 0.000806	time 0.5666 (0.6058)	loss 3.1093 (4.1056)	grad_norm 2.5994 (3.0887)	mem 5329MB
[2022-04-18 15:05:06 tiny] (main.py 226): INFO Train: [87/300][800/1251]	eta 0:04:32 lr 0.000806	time 0.6337 (0.6038)	loss 4.2293 (4.1097)	grad_norm 2.7240 (3.0929)	mem 5329MB
[2022-04-18 15:06:05 tiny] (main.py 226): INFO Train: [87/300][900/1251]	eta 0:03:31 lr 0.000805	time 0.4742 (0.6018)	loss 3.9368 (4.1004)	grad_norm 4.0086 (3.0796)	mem 5329MB
[2022-04-18 15:07:04 tiny] (main.py 226): INFO Train: [87/300][1000/1251]	eta 0:02:30 lr 0.000805	time 0.5607 (0.6006)	loss 2.9215 (4.1014)	grad_norm 3.8989 (3.0803)	mem 5329MB
[2022-04-18 15:08:03 tiny] (main.py 226): INFO Train: [87/300][1100/1251]	eta 0:01:30 lr 0.000805	time 0.6854 (0.5996)	loss 4.8760 (4.1101)	grad_norm 2.3416 (3.1044)	mem 5329MB
[2022-04-18 15:09:02 tiny] (main.py 226): INFO Train: [87/300][1200/1251]	eta 0:00:30 lr 0.000804	time 0.5218 (0.5991)	loss 4.3951 (4.1144)	grad_norm 2.4529 (3.0951)	mem 5329MB
[2022-04-18 15:09:23 tiny] (main.py 233): INFO EPOCH 87 training takes 0:12:21
[2022-04-18 15:09:35 tiny] (main.py 273): INFO Test: [0/49]	Time 11.273 (11.273)	Loss 1.7615 (1.7615)	Acc@1 63.477 (63.477)	Acc@5 86.426 (86.426)	Mem 5329MB
[2022-04-18 15:09:54 tiny] (main.py 279): INFO  * Acc@1 63.616 Acc@5 85.764
[2022-04-18 15:09:54 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 63.6%
[2022-04-18 15:09:54 tiny] (main.py 148): INFO Max accuracy: 64.06%
[2022-04-18 15:10:06 tiny] (main.py 226): INFO Train: [88/300][0/1251]	eta 4:07:48 lr 0.000804	time 11.8851 (11.8851)	loss 4.4475 (4.4475)	grad_norm 2.7306 (2.7306)	mem 5329MB
[2022-04-18 15:11:08 tiny] (main.py 226): INFO Train: [88/300][100/1251]	eta 0:14:03 lr 0.000804	time 0.6763 (0.7325)	loss 4.6222 (4.0970)	grad_norm 2.4682 (3.0905)	mem 5329MB
[2022-04-18 15:12:07 tiny] (main.py 226): INFO Train: [88/300][200/1251]	eta 0:11:33 lr 0.000804	time 0.5426 (0.6598)	loss 4.9500 (4.1094)	grad_norm 7.6122 (3.0785)	mem 5329MB
[2022-04-18 15:13:06 tiny] (main.py 226): INFO Train: [88/300][300/1251]	eta 0:10:03 lr 0.000803	time 0.4998 (0.6350)	loss 4.5345 (4.1033)	grad_norm 5.3049 (3.1208)	mem 5329MB
[2022-04-18 15:14:04 tiny] (main.py 226): INFO Train: [88/300][400/1251]	eta 0:08:49 lr 0.000803	time 0.7391 (0.6222)	loss 4.0573 (4.0948)	grad_norm 2.5735 (3.1515)	mem 5329MB
[2022-04-18 15:15:03 tiny] (main.py 226): INFO Train: [88/300][500/1251]	eta 0:07:41 lr 0.000803	time 0.7161 (0.6150)	loss 3.3320 (4.1109)	grad_norm 2.2560 (3.0816)	mem 5329MB
[2022-04-18 15:16:01 tiny] (main.py 226): INFO Train: [88/300][600/1251]	eta 0:06:37 lr 0.000802	time 0.6351 (0.6102)	loss 4.5941 (4.1157)	grad_norm 2.8224 (3.0667)	mem 5329MB
[2022-04-18 15:17:00 tiny] (main.py 226): INFO Train: [88/300][700/1251]	eta 0:05:34 lr 0.000802	time 0.4784 (0.6073)	loss 4.8693 (4.1110)	grad_norm 4.2727 (3.0817)	mem 5329MB
[2022-04-18 15:17:59 tiny] (main.py 226): INFO Train: [88/300][800/1251]	eta 0:04:32 lr 0.000802	time 0.5779 (0.6051)	loss 3.0539 (4.1086)	grad_norm 4.3426 (3.0784)	mem 5329MB
[2022-04-18 15:18:58 tiny] (main.py 226): INFO Train: [88/300][900/1251]	eta 0:03:31 lr 0.000801	time 0.5726 (0.6032)	loss 3.5833 (4.1193)	grad_norm 2.6312 (3.0642)	mem 5329MB
[2022-04-18 15:19:57 tiny] (main.py 226): INFO Train: [88/300][1000/1251]	eta 0:02:31 lr 0.000801	time 0.5177 (0.6018)	loss 4.3520 (4.1340)	grad_norm 2.2555 (3.0597)	mem 5329MB
[2022-04-18 15:20:56 tiny] (main.py 226): INFO Train: [88/300][1100/1251]	eta 0:01:30 lr 0.000801	time 0.5467 (0.6007)	loss 3.5293 (4.1404)	grad_norm 2.6770 (3.0701)	mem 5329MB
[2022-04-18 15:21:55 tiny] (main.py 226): INFO Train: [88/300][1200/1251]	eta 0:00:30 lr 0.000800	time 0.6166 (0.5998)	loss 4.4254 (4.1376)	grad_norm 3.1840 (3.0659)	mem 5329MB
[2022-04-18 15:22:16 tiny] (main.py 233): INFO EPOCH 88 training takes 0:12:21
[2022-04-18 15:22:27 tiny] (main.py 273): INFO Test: [0/49]	Time 10.544 (10.544)	Loss 1.7328 (1.7328)	Acc@1 63.477 (63.477)	Acc@5 86.719 (86.719)	Mem 5329MB
[2022-04-18 15:22:48 tiny] (main.py 279): INFO  * Acc@1 63.650 Acc@5 86.052
[2022-04-18 15:22:48 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 63.6%
[2022-04-18 15:22:48 tiny] (main.py 148): INFO Max accuracy: 64.06%
[2022-04-18 15:23:00 tiny] (main.py 226): INFO Train: [89/300][0/1251]	eta 4:21:22 lr 0.000800	time 12.5361 (12.5361)	loss 4.3685 (4.3685)	grad_norm 2.5531 (2.5531)	mem 5329MB
[2022-04-18 15:24:01 tiny] (main.py 226): INFO Train: [89/300][100/1251]	eta 0:13:57 lr 0.000800	time 0.4598 (0.7279)	loss 3.9053 (4.0265)	grad_norm 2.7720 (3.2270)	mem 5329MB
[2022-04-18 15:25:00 tiny] (main.py 226): INFO Train: [89/300][200/1251]	eta 0:11:31 lr 0.000799	time 0.5665 (0.6580)	loss 4.5951 (4.0823)	grad_norm 2.8751 (3.1375)	mem 5329MB
[2022-04-18 15:25:58 tiny] (main.py 226): INFO Train: [89/300][300/1251]	eta 0:10:02 lr 0.000799	time 0.6071 (0.6336)	loss 5.0643 (4.1177)	grad_norm 3.9597 (3.0564)	mem 5329MB
[2022-04-18 15:26:57 tiny] (main.py 226): INFO Train: [89/300][400/1251]	eta 0:08:49 lr 0.000799	time 0.6388 (0.6221)	loss 4.5876 (4.1110)	grad_norm 2.3460 (inf)	mem 5329MB
[2022-04-18 15:27:56 tiny] (main.py 226): INFO Train: [89/300][500/1251]	eta 0:07:42 lr 0.000798	time 0.5994 (0.6153)	loss 4.6283 (4.1112)	grad_norm 2.2714 (inf)	mem 5329MB
[2022-04-18 15:28:54 tiny] (main.py 226): INFO Train: [89/300][600/1251]	eta 0:06:37 lr 0.000798	time 0.5282 (0.6102)	loss 4.8474 (4.1126)	grad_norm 2.7095 (inf)	mem 5329MB
[2022-04-18 15:29:53 tiny] (main.py 226): INFO Train: [89/300][700/1251]	eta 0:05:34 lr 0.000798	time 0.6751 (0.6072)	loss 4.2621 (4.1200)	grad_norm 3.6294 (inf)	mem 5329MB
[2022-04-18 15:30:52 tiny] (main.py 226): INFO Train: [89/300][800/1251]	eta 0:04:32 lr 0.000797	time 0.4159 (0.6050)	loss 4.0960 (4.1241)	grad_norm 4.0484 (inf)	mem 5329MB
[2022-04-18 15:31:51 tiny] (main.py 226): INFO Train: [89/300][900/1251]	eta 0:03:31 lr 0.000797	time 0.5732 (0.6029)	loss 3.8270 (4.1272)	grad_norm 2.9470 (inf)	mem 5329MB
[2022-04-18 15:32:50 tiny] (main.py 226): INFO Train: [89/300][1000/1251]	eta 0:02:31 lr 0.000797	time 0.6278 (0.6019)	loss 3.4475 (4.1298)	grad_norm 3.8906 (inf)	mem 5329MB
[2022-04-18 15:33:49 tiny] (main.py 226): INFO Train: [89/300][1100/1251]	eta 0:01:30 lr 0.000796	time 0.4433 (0.6004)	loss 4.9168 (4.1327)	grad_norm 4.6448 (inf)	mem 5329MB
[2022-04-18 15:34:48 tiny] (main.py 226): INFO Train: [89/300][1200/1251]	eta 0:00:30 lr 0.000796	time 0.5279 (0.5994)	loss 4.4026 (4.1244)	grad_norm 2.3227 (inf)	mem 5329MB
[2022-04-18 15:35:09 tiny] (main.py 233): INFO EPOCH 89 training takes 0:12:21
[2022-04-18 15:35:21 tiny] (main.py 273): INFO Test: [0/49]	Time 11.644 (11.644)	Loss 1.8349 (1.8349)	Acc@1 63.867 (63.867)	Acc@5 86.621 (86.621)	Mem 5329MB
[2022-04-18 15:35:40 tiny] (main.py 279): INFO  * Acc@1 62.516 Acc@5 85.254
[2022-04-18 15:35:40 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 62.5%
[2022-04-18 15:35:40 tiny] (main.py 148): INFO Max accuracy: 64.06%
[2022-04-18 15:35:51 tiny] (main.py 226): INFO Train: [90/300][0/1251]	eta 3:43:19 lr 0.000796	time 10.7107 (10.7107)	loss 4.8313 (4.8313)	grad_norm 2.5202 (2.5202)	mem 5329MB
[2022-04-18 15:36:54 tiny] (main.py 226): INFO Train: [90/300][100/1251]	eta 0:13:56 lr 0.000796	time 0.5324 (0.7268)	loss 4.7771 (4.1709)	grad_norm 2.2788 (2.9383)	mem 5329MB
[2022-04-18 15:37:52 tiny] (main.py 226): INFO Train: [90/300][200/1251]	eta 0:11:30 lr 0.000795	time 0.9355 (0.6574)	loss 4.4036 (4.0947)	grad_norm 5.1466 (3.1234)	mem 5329MB
[2022-04-18 15:38:51 tiny] (main.py 226): INFO Train: [90/300][300/1251]	eta 0:10:01 lr 0.000795	time 0.5612 (0.6326)	loss 4.4527 (4.1064)	grad_norm 2.1549 (3.0926)	mem 5329MB
[2022-04-18 15:39:49 tiny] (main.py 226): INFO Train: [90/300][400/1251]	eta 0:08:48 lr 0.000795	time 0.5745 (0.6205)	loss 3.1794 (4.1152)	grad_norm 2.2051 (3.1210)	mem 5329MB
[2022-04-18 15:40:47 tiny] (main.py 226): INFO Train: [90/300][500/1251]	eta 0:07:40 lr 0.000794	time 0.5243 (0.6129)	loss 4.3681 (4.1178)	grad_norm 3.0474 (3.1204)	mem 5329MB
[2022-04-18 15:41:47 tiny] (main.py 226): INFO Train: [90/300][600/1251]	eta 0:06:36 lr 0.000794	time 0.6387 (0.6096)	loss 3.9246 (4.1125)	grad_norm 2.5669 (3.1035)	mem 5329MB
[2022-04-18 15:42:45 tiny] (main.py 226): INFO Train: [90/300][700/1251]	eta 0:05:34 lr 0.000794	time 0.6965 (0.6062)	loss 4.5651 (4.1179)	grad_norm 2.3517 (3.0904)	mem 5329MB
[2022-04-18 15:43:44 tiny] (main.py 226): INFO Train: [90/300][800/1251]	eta 0:04:32 lr 0.000793	time 0.4920 (0.6035)	loss 4.8358 (4.1166)	grad_norm 2.5838 (3.0848)	mem 5329MB
[2022-04-18 15:44:42 tiny] (main.py 226): INFO Train: [90/300][900/1251]	eta 0:03:31 lr 0.000793	time 0.6027 (0.6017)	loss 4.1468 (4.1198)	grad_norm 2.1796 (3.0992)	mem 5329MB
[2022-04-18 15:45:41 tiny] (main.py 226): INFO Train: [90/300][1000/1251]	eta 0:02:30 lr 0.000793	time 0.5306 (0.6007)	loss 3.8912 (4.1182)	grad_norm 3.4609 (3.1215)	mem 5329MB
[2022-04-18 15:46:41 tiny] (main.py 226): INFO Train: [90/300][1100/1251]	eta 0:01:30 lr 0.000792	time 0.4474 (0.5998)	loss 4.1623 (4.1184)	grad_norm 3.1636 (inf)	mem 5329MB
[2022-04-18 15:47:39 tiny] (main.py 226): INFO Train: [90/300][1200/1251]	eta 0:00:30 lr 0.000792	time 0.6500 (0.5989)	loss 3.3645 (4.1110)	grad_norm 2.9791 (inf)	mem 5329MB
[2022-04-18 15:48:01 tiny] (main.py 233): INFO EPOCH 90 training takes 0:12:21
[2022-04-18 15:48:13 tiny] (main.py 273): INFO Test: [0/49]	Time 11.879 (11.879)	Loss 1.7784 (1.7784)	Acc@1 62.695 (62.695)	Acc@5 85.742 (85.742)	Mem 5329MB
[2022-04-18 15:48:32 tiny] (main.py 279): INFO  * Acc@1 62.942 Acc@5 85.356
[2022-04-18 15:48:32 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 62.9%
[2022-04-18 15:48:32 tiny] (main.py 148): INFO Max accuracy: 64.06%
[2022-04-18 15:48:44 tiny] (main.py 226): INFO Train: [91/300][0/1251]	eta 4:07:54 lr 0.000792	time 11.8898 (11.8898)	loss 3.7958 (3.7958)	grad_norm 3.4443 (3.4443)	mem 5329MB
[2022-04-18 15:49:46 tiny] (main.py 226): INFO Train: [91/300][100/1251]	eta 0:13:59 lr 0.000791	time 0.5998 (0.7293)	loss 4.4037 (4.1665)	grad_norm 2.0550 (3.2812)	mem 5329MB
[2022-04-18 15:50:44 tiny] (main.py 226): INFO Train: [91/300][200/1251]	eta 0:11:29 lr 0.000791	time 0.5397 (0.6558)	loss 4.5356 (4.1538)	grad_norm 3.0572 (3.1650)	mem 5329MB
[2022-04-18 15:51:43 tiny] (main.py 226): INFO Train: [91/300][300/1251]	eta 0:10:01 lr 0.000791	time 0.4678 (0.6328)	loss 4.3850 (4.1414)	grad_norm 4.7656 (3.1612)	mem 5329MB
[2022-04-18 15:52:41 tiny] (main.py 226): INFO Train: [91/300][400/1251]	eta 0:08:48 lr 0.000790	time 0.4659 (0.6213)	loss 3.2282 (4.1578)	grad_norm 4.3515 (3.1243)	mem 5329MB
[2022-04-18 15:53:40 tiny] (main.py 226): INFO Train: [91/300][500/1251]	eta 0:07:41 lr 0.000790	time 0.4759 (0.6141)	loss 3.8835 (4.1519)	grad_norm 2.3503 (3.1659)	mem 5329MB
[2022-04-18 15:54:38 tiny] (main.py 226): INFO Train: [91/300][600/1251]	eta 0:06:36 lr 0.000790	time 0.6863 (0.6094)	loss 4.2684 (4.1625)	grad_norm 2.7329 (3.1593)	mem 5329MB
[2022-04-18 15:55:37 tiny] (main.py 226): INFO Train: [91/300][700/1251]	eta 0:05:34 lr 0.000789	time 0.4578 (0.6064)	loss 5.1207 (4.1701)	grad_norm 5.2232 (3.1153)	mem 5329MB
[2022-04-18 15:56:37 tiny] (main.py 226): INFO Train: [91/300][800/1251]	eta 0:04:32 lr 0.000789	time 0.7979 (0.6049)	loss 4.5032 (4.1747)	grad_norm 2.1241 (3.0940)	mem 5329MB
[2022-04-18 15:57:35 tiny] (main.py 226): INFO Train: [91/300][900/1251]	eta 0:03:31 lr 0.000789	time 0.5444 (0.6024)	loss 4.3927 (4.1737)	grad_norm 2.3592 (3.1050)	mem 5329MB
[2022-04-18 15:58:34 tiny] (main.py 226): INFO Train: [91/300][1000/1251]	eta 0:02:30 lr 0.000788	time 0.5892 (0.6010)	loss 4.5017 (4.1741)	grad_norm 2.6552 (3.0990)	mem 5329MB
[2022-04-18 15:59:33 tiny] (main.py 226): INFO Train: [91/300][1100/1251]	eta 0:01:30 lr 0.000788	time 0.4878 (0.6000)	loss 3.6848 (4.1714)	grad_norm 3.8433 (3.0754)	mem 5329MB
[2022-04-18 16:00:32 tiny] (main.py 226): INFO Train: [91/300][1200/1251]	eta 0:00:30 lr 0.000788	time 0.5866 (0.5991)	loss 2.9582 (4.1635)	grad_norm 3.0317 (3.0941)	mem 5329MB
[2022-04-18 16:00:54 tiny] (main.py 233): INFO EPOCH 91 training takes 0:12:21
[2022-04-18 16:01:06 tiny] (main.py 273): INFO Test: [0/49]	Time 12.083 (12.083)	Loss 1.7612 (1.7612)	Acc@1 63.086 (63.086)	Acc@5 85.547 (85.547)	Mem 5329MB
[2022-04-18 16:01:25 tiny] (main.py 279): INFO  * Acc@1 63.414 Acc@5 85.598
[2022-04-18 16:01:25 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 63.4%
[2022-04-18 16:01:25 tiny] (main.py 148): INFO Max accuracy: 64.06%
[2022-04-18 16:01:36 tiny] (main.py 226): INFO Train: [92/300][0/1251]	eta 3:55:15 lr 0.000788	time 11.2837 (11.2837)	loss 4.2027 (4.2027)	grad_norm 3.8858 (3.8858)	mem 5329MB
[2022-04-18 16:02:37 tiny] (main.py 226): INFO Train: [92/300][100/1251]	eta 0:13:47 lr 0.000787	time 0.6473 (0.7193)	loss 4.3719 (4.0259)	grad_norm 3.0962 (3.0597)	mem 5329MB
[2022-04-18 16:03:37 tiny] (main.py 226): INFO Train: [92/300][200/1251]	eta 0:11:31 lr 0.000787	time 0.6171 (0.6581)	loss 3.5720 (4.1162)	grad_norm 2.7424 (3.1336)	mem 5329MB
[2022-04-18 16:04:35 tiny] (main.py 226): INFO Train: [92/300][300/1251]	eta 0:10:00 lr 0.000786	time 0.4834 (0.6310)	loss 3.7235 (4.1285)	grad_norm 2.2647 (3.1884)	mem 5329MB
[2022-04-18 16:05:34 tiny] (main.py 226): INFO Train: [92/300][400/1251]	eta 0:08:48 lr 0.000786	time 0.6630 (0.6205)	loss 4.1855 (4.1420)	grad_norm 2.1149 (3.1864)	mem 5329MB
[2022-04-18 16:06:32 tiny] (main.py 226): INFO Train: [92/300][500/1251]	eta 0:07:40 lr 0.000786	time 0.5640 (0.6135)	loss 3.1716 (4.1524)	grad_norm 2.6245 (3.1236)	mem 5329MB
[2022-04-18 16:07:31 tiny] (main.py 226): INFO Train: [92/300][600/1251]	eta 0:06:36 lr 0.000785	time 0.8314 (0.6096)	loss 4.6354 (4.1520)	grad_norm 1.6028 (3.0903)	mem 5329MB
[2022-04-18 16:08:30 tiny] (main.py 226): INFO Train: [92/300][700/1251]	eta 0:05:33 lr 0.000785	time 0.7257 (0.6062)	loss 4.0965 (4.1473)	grad_norm 4.6079 (3.0799)	mem 5329MB
[2022-04-18 16:09:30 tiny] (main.py 226): INFO Train: [92/300][800/1251]	eta 0:04:32 lr 0.000785	time 0.6450 (0.6052)	loss 4.4602 (4.1474)	grad_norm 2.1201 (3.0571)	mem 5329MB
[2022-04-18 16:10:28 tiny] (main.py 226): INFO Train: [92/300][900/1251]	eta 0:03:31 lr 0.000784	time 0.4917 (0.6031)	loss 4.8764 (4.1435)	grad_norm 2.4090 (3.0566)	mem 5329MB
[2022-04-18 16:11:27 tiny] (main.py 226): INFO Train: [92/300][1000/1251]	eta 0:02:30 lr 0.000784	time 0.5158 (0.6011)	loss 4.8017 (4.1365)	grad_norm 3.6928 (inf)	mem 5329MB
[2022-04-18 16:12:25 tiny] (main.py 226): INFO Train: [92/300][1100/1251]	eta 0:01:30 lr 0.000784	time 0.3812 (0.6000)	loss 4.2681 (4.1333)	grad_norm 2.9251 (inf)	mem 5329MB
[2022-04-18 16:13:25 tiny] (main.py 226): INFO Train: [92/300][1200/1251]	eta 0:00:30 lr 0.000783	time 0.6480 (0.5995)	loss 3.7706 (4.1312)	grad_norm 2.0151 (inf)	mem 5329MB
[2022-04-18 16:13:47 tiny] (main.py 233): INFO EPOCH 92 training takes 0:12:21
[2022-04-18 16:13:59 tiny] (main.py 273): INFO Test: [0/49]	Time 12.026 (12.026)	Loss 1.8403 (1.8403)	Acc@1 64.355 (64.355)	Acc@5 86.133 (86.133)	Mem 5329MB
[2022-04-18 16:14:18 tiny] (main.py 279): INFO  * Acc@1 63.250 Acc@5 85.448
[2022-04-18 16:14:18 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 63.2%
[2022-04-18 16:14:18 tiny] (main.py 148): INFO Max accuracy: 64.06%
[2022-04-18 16:14:30 tiny] (main.py 226): INFO Train: [93/300][0/1251]	eta 4:17:43 lr 0.000783	time 12.3609 (12.3609)	loss 4.4606 (4.4606)	grad_norm 2.5580 (2.5580)	mem 5329MB
[2022-04-18 16:15:31 tiny] (main.py 226): INFO Train: [93/300][100/1251]	eta 0:13:57 lr 0.000783	time 0.4816 (0.7276)	loss 4.6245 (4.2015)	grad_norm 4.5691 (3.0281)	mem 5329MB
[2022-04-18 16:16:30 tiny] (main.py 226): INFO Train: [93/300][200/1251]	eta 0:11:30 lr 0.000783	time 0.6202 (0.6572)	loss 4.4121 (4.1745)	grad_norm 2.3136 (3.0786)	mem 5329MB
[2022-04-18 16:17:29 tiny] (main.py 226): INFO Train: [93/300][300/1251]	eta 0:10:03 lr 0.000782	time 0.6866 (0.6348)	loss 2.6888 (4.1793)	grad_norm 1.9011 (3.0809)	mem 5329MB
[2022-04-18 16:18:27 tiny] (main.py 226): INFO Train: [93/300][400/1251]	eta 0:08:49 lr 0.000782	time 0.8310 (0.6221)	loss 3.4995 (4.1640)	grad_norm 3.9592 (3.0686)	mem 5329MB
[2022-04-18 16:19:26 tiny] (main.py 226): INFO Train: [93/300][500/1251]	eta 0:07:42 lr 0.000782	time 0.4984 (0.6155)	loss 4.3931 (4.1662)	grad_norm 2.0662 (3.0544)	mem 5329MB
[2022-04-18 16:20:25 tiny] (main.py 226): INFO Train: [93/300][600/1251]	eta 0:06:37 lr 0.000781	time 0.5037 (0.6102)	loss 4.0015 (4.1554)	grad_norm 6.6003 (3.1108)	mem 5329MB
[2022-04-18 16:21:24 tiny] (main.py 226): INFO Train: [93/300][700/1251]	eta 0:05:34 lr 0.000781	time 0.7485 (0.6077)	loss 4.9836 (4.1526)	grad_norm 3.7783 (3.0824)	mem 5329MB
[2022-04-18 16:22:23 tiny] (main.py 226): INFO Train: [93/300][800/1251]	eta 0:04:32 lr 0.000780	time 0.8169 (0.6051)	loss 3.2061 (4.1591)	grad_norm 4.7686 (3.0965)	mem 5329MB
[2022-04-18 16:23:21 tiny] (main.py 226): INFO Train: [93/300][900/1251]	eta 0:03:31 lr 0.000780	time 0.5069 (0.6029)	loss 2.7435 (4.1537)	grad_norm 4.0486 (3.1002)	mem 5329MB
[2022-04-18 16:24:20 tiny] (main.py 226): INFO Train: [93/300][1000/1251]	eta 0:02:30 lr 0.000780	time 0.6892 (0.6011)	loss 4.8398 (4.1495)	grad_norm 2.3062 (3.1033)	mem 5329MB
[2022-04-18 16:25:19 tiny] (main.py 226): INFO Train: [93/300][1100/1251]	eta 0:01:30 lr 0.000779	time 0.5272 (0.6000)	loss 4.0209 (4.1488)	grad_norm 2.4094 (3.1148)	mem 5329MB
[2022-04-18 16:26:17 tiny] (main.py 226): INFO Train: [93/300][1200/1251]	eta 0:00:30 lr 0.000779	time 0.6198 (0.5986)	loss 3.8543 (4.1457)	grad_norm 1.9303 (3.1319)	mem 5329MB
[2022-04-18 16:26:38 tiny] (main.py 233): INFO EPOCH 93 training takes 0:12:20
[2022-04-18 16:26:50 tiny] (main.py 273): INFO Test: [0/49]	Time 11.621 (11.621)	Loss 1.8177 (1.8177)	Acc@1 64.746 (64.746)	Acc@5 84.863 (84.863)	Mem 5329MB
[2022-04-18 16:27:10 tiny] (main.py 279): INFO  * Acc@1 64.336 Acc@5 86.342
[2022-04-18 16:27:10 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 64.3%
[2022-04-18 16:27:10 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_93.pth saving......
[2022-04-18 16:27:10 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_93.pth saved !!!
[2022-04-18 16:27:10 tiny] (main.py 148): INFO Max accuracy: 64.34%
[2022-04-18 16:27:22 tiny] (main.py 226): INFO Train: [94/300][0/1251]	eta 4:02:31 lr 0.000779	time 11.6316 (11.6316)	loss 3.8207 (3.8207)	grad_norm 2.8400 (2.8400)	mem 5329MB
[2022-04-18 16:28:24 tiny] (main.py 226): INFO Train: [94/300][100/1251]	eta 0:14:02 lr 0.000779	time 0.7176 (0.7316)	loss 4.9689 (4.0789)	grad_norm 4.2056 (3.1085)	mem 5329MB
[2022-04-18 16:29:22 tiny] (main.py 226): INFO Train: [94/300][200/1251]	eta 0:11:30 lr 0.000778	time 0.5606 (0.6573)	loss 2.9707 (4.1148)	grad_norm 3.4517 (3.0562)	mem 5329MB
[2022-04-18 16:30:21 tiny] (main.py 226): INFO Train: [94/300][300/1251]	eta 0:10:01 lr 0.000778	time 0.6928 (0.6327)	loss 3.8909 (4.1130)	grad_norm 2.3538 (3.0488)	mem 5329MB
[2022-04-18 16:31:19 tiny] (main.py 226): INFO Train: [94/300][400/1251]	eta 0:08:48 lr 0.000778	time 0.7205 (0.6214)	loss 4.2901 (4.1459)	grad_norm 3.0387 (3.0562)	mem 5329MB
[2022-04-18 16:32:18 tiny] (main.py 226): INFO Train: [94/300][500/1251]	eta 0:07:40 lr 0.000777	time 0.5823 (0.6138)	loss 4.5413 (4.1200)	grad_norm 3.2799 (3.0794)	mem 5329MB
[2022-04-18 16:33:16 tiny] (main.py 226): INFO Train: [94/300][600/1251]	eta 0:06:36 lr 0.000777	time 0.5973 (0.6093)	loss 3.0986 (4.1159)	grad_norm 3.1828 (3.1044)	mem 5329MB
[2022-04-18 16:34:15 tiny] (main.py 226): INFO Train: [94/300][700/1251]	eta 0:05:34 lr 0.000777	time 0.6751 (0.6067)	loss 3.8380 (4.1302)	grad_norm 3.6202 (3.1143)	mem 5329MB
[2022-04-18 16:35:14 tiny] (main.py 226): INFO Train: [94/300][800/1251]	eta 0:04:32 lr 0.000776	time 0.7702 (0.6044)	loss 4.1741 (4.1387)	grad_norm 4.6550 (3.1131)	mem 5329MB
[2022-04-18 16:36:13 tiny] (main.py 226): INFO Train: [94/300][900/1251]	eta 0:03:31 lr 0.000776	time 0.6419 (0.6026)	loss 4.7671 (4.1347)	grad_norm 4.5189 (3.0947)	mem 5329MB
[2022-04-18 16:37:11 tiny] (main.py 226): INFO Train: [94/300][1000/1251]	eta 0:02:30 lr 0.000775	time 0.7378 (0.6007)	loss 4.7579 (4.1317)	grad_norm 1.9966 (3.0934)	mem 5329MB
[2022-04-18 16:38:10 tiny] (main.py 226): INFO Train: [94/300][1100/1251]	eta 0:01:30 lr 0.000775	time 0.6899 (0.5996)	loss 4.2934 (4.1290)	grad_norm 3.8110 (3.0812)	mem 5329MB
[2022-04-18 16:39:09 tiny] (main.py 226): INFO Train: [94/300][1200/1251]	eta 0:00:30 lr 0.000775	time 0.4668 (0.5987)	loss 3.4703 (4.1217)	grad_norm 2.5395 (3.1193)	mem 5329MB
[2022-04-18 16:39:31 tiny] (main.py 233): INFO EPOCH 94 training takes 0:12:20
[2022-04-18 16:39:42 tiny] (main.py 273): INFO Test: [0/49]	Time 11.304 (11.304)	Loss 1.8148 (1.8148)	Acc@1 63.867 (63.867)	Acc@5 85.840 (85.840)	Mem 5329MB
[2022-04-18 16:40:02 tiny] (main.py 279): INFO  * Acc@1 63.938 Acc@5 86.138
[2022-04-18 16:40:02 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 63.9%
[2022-04-18 16:40:02 tiny] (main.py 148): INFO Max accuracy: 64.34%
[2022-04-18 16:40:15 tiny] (main.py 226): INFO Train: [95/300][0/1251]	eta 4:31:03 lr 0.000775	time 13.0007 (13.0007)	loss 4.4359 (4.4359)	grad_norm 1.9689 (1.9689)	mem 5329MB
[2022-04-18 16:41:16 tiny] (main.py 226): INFO Train: [95/300][100/1251]	eta 0:14:05 lr 0.000774	time 0.5513 (0.7349)	loss 3.2169 (4.1340)	grad_norm 4.0238 (2.9801)	mem 5329MB
[2022-04-18 16:42:14 tiny] (main.py 226): INFO Train: [95/300][200/1251]	eta 0:11:31 lr 0.000774	time 0.5421 (0.6578)	loss 3.3616 (4.1066)	grad_norm 3.0468 (3.0339)	mem 5329MB
[2022-04-18 16:43:12 tiny] (main.py 226): INFO Train: [95/300][300/1251]	eta 0:10:01 lr 0.000774	time 0.6897 (0.6324)	loss 5.1293 (4.1354)	grad_norm 2.6069 (3.0911)	mem 5329MB
[2022-04-18 16:44:11 tiny] (main.py 226): INFO Train: [95/300][400/1251]	eta 0:08:48 lr 0.000773	time 0.4764 (0.6216)	loss 4.5222 (4.1359)	grad_norm 2.7290 (3.0816)	mem 5329MB
[2022-04-18 16:45:09 tiny] (main.py 226): INFO Train: [95/300][500/1251]	eta 0:07:40 lr 0.000773	time 0.6211 (0.6134)	loss 2.9838 (4.1216)	grad_norm 1.8768 (3.0773)	mem 5329MB
[2022-04-18 16:46:08 tiny] (main.py 226): INFO Train: [95/300][600/1251]	eta 0:06:36 lr 0.000773	time 0.4410 (0.6088)	loss 2.8607 (4.1285)	grad_norm 3.6679 (3.1002)	mem 5329MB
[2022-04-18 16:47:07 tiny] (main.py 226): INFO Train: [95/300][700/1251]	eta 0:05:34 lr 0.000772	time 0.5921 (0.6065)	loss 3.7577 (4.1203)	grad_norm 3.1605 (3.1163)	mem 5329MB
[2022-04-18 16:48:06 tiny] (main.py 226): INFO Train: [95/300][800/1251]	eta 0:04:32 lr 0.000772	time 0.7060 (0.6043)	loss 3.9044 (4.1141)	grad_norm 1.9313 (3.1513)	mem 5329MB
[2022-04-18 16:49:05 tiny] (main.py 226): INFO Train: [95/300][900/1251]	eta 0:03:31 lr 0.000771	time 0.6289 (0.6026)	loss 4.3028 (4.1134)	grad_norm 2.5242 (inf)	mem 5329MB
[2022-04-18 16:50:04 tiny] (main.py 226): INFO Train: [95/300][1000/1251]	eta 0:02:30 lr 0.000771	time 0.6707 (0.6010)	loss 3.4849 (4.1133)	grad_norm 1.8832 (inf)	mem 5329MB
[2022-04-18 16:51:02 tiny] (main.py 226): INFO Train: [95/300][1100/1251]	eta 0:01:30 lr 0.000771	time 0.5326 (0.5999)	loss 5.0384 (4.1148)	grad_norm 2.3630 (inf)	mem 5329MB
[2022-04-18 16:52:01 tiny] (main.py 226): INFO Train: [95/300][1200/1251]	eta 0:00:30 lr 0.000770	time 0.5393 (0.5987)	loss 4.2849 (4.1143)	grad_norm 3.5692 (inf)	mem 5329MB
[2022-04-18 16:52:23 tiny] (main.py 233): INFO EPOCH 95 training takes 0:12:21
[2022-04-18 16:52:36 tiny] (main.py 273): INFO Test: [0/49]	Time 12.718 (12.718)	Loss 1.8115 (1.8115)	Acc@1 62.305 (62.305)	Acc@5 86.133 (86.133)	Mem 5329MB
[2022-04-18 16:52:54 tiny] (main.py 279): INFO  * Acc@1 63.740 Acc@5 85.792
[2022-04-18 16:52:54 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 63.7%
[2022-04-18 16:52:54 tiny] (main.py 148): INFO Max accuracy: 64.34%
[2022-04-18 16:53:07 tiny] (main.py 226): INFO Train: [96/300][0/1251]	eta 4:16:20 lr 0.000770	time 12.2946 (12.2946)	loss 4.8480 (4.8480)	grad_norm 3.6522 (3.6522)	mem 5329MB
[2022-04-18 16:54:08 tiny] (main.py 226): INFO Train: [96/300][100/1251]	eta 0:14:01 lr 0.000770	time 0.4600 (0.7311)	loss 5.2133 (4.0367)	grad_norm 3.6990 (3.3038)	mem 5329MB
[2022-04-18 16:55:07 tiny] (main.py 226): INFO Train: [96/300][200/1251]	eta 0:11:34 lr 0.000770	time 0.4641 (0.6609)	loss 3.0150 (4.1158)	grad_norm 4.4261 (3.2322)	mem 5329MB
[2022-04-18 16:56:06 tiny] (main.py 226): INFO Train: [96/300][300/1251]	eta 0:10:05 lr 0.000769	time 0.5672 (0.6364)	loss 3.2533 (4.1099)	grad_norm 2.0585 (3.1903)	mem 5329MB
[2022-04-18 16:57:05 tiny] (main.py 226): INFO Train: [96/300][400/1251]	eta 0:08:52 lr 0.000769	time 0.5921 (0.6259)	loss 3.1827 (4.1219)	grad_norm 2.5198 (3.1784)	mem 5329MB
[2022-04-18 16:58:04 tiny] (main.py 226): INFO Train: [96/300][500/1251]	eta 0:07:43 lr 0.000768	time 0.5827 (0.6174)	loss 3.5425 (4.1065)	grad_norm 4.7183 (3.1839)	mem 5329MB
[2022-04-18 16:59:03 tiny] (main.py 226): INFO Train: [96/300][600/1251]	eta 0:06:39 lr 0.000768	time 0.5067 (0.6129)	loss 4.3024 (4.1289)	grad_norm 2.2229 (3.1497)	mem 5329MB
[2022-04-18 17:00:02 tiny] (main.py 226): INFO Train: [96/300][700/1251]	eta 0:05:36 lr 0.000768	time 0.5090 (0.6102)	loss 4.8663 (4.1301)	grad_norm 6.6728 (3.1996)	mem 5329MB
[2022-04-18 17:01:01 tiny] (main.py 226): INFO Train: [96/300][800/1251]	eta 0:04:33 lr 0.000767	time 0.7718 (0.6073)	loss 4.6420 (4.1421)	grad_norm 3.0935 (3.1968)	mem 5329MB
[2022-04-18 17:02:00 tiny] (main.py 226): INFO Train: [96/300][900/1251]	eta 0:03:32 lr 0.000767	time 0.5389 (0.6053)	loss 5.1341 (4.1449)	grad_norm 2.3027 (3.2215)	mem 5329MB
[2022-04-18 17:02:58 tiny] (main.py 226): INFO Train: [96/300][1000/1251]	eta 0:02:31 lr 0.000767	time 0.5205 (0.6032)	loss 4.1586 (4.1362)	grad_norm 2.4812 (3.2122)	mem 5329MB
[2022-04-18 17:03:57 tiny] (main.py 226): INFO Train: [96/300][1100/1251]	eta 0:01:30 lr 0.000766	time 0.4359 (0.6022)	loss 3.5993 (4.1367)	grad_norm 3.7770 (3.2124)	mem 5329MB
[2022-04-18 17:04:56 tiny] (main.py 226): INFO Train: [96/300][1200/1251]	eta 0:00:30 lr 0.000766	time 0.7123 (0.6011)	loss 4.6110 (4.1397)	grad_norm 2.5672 (3.2033)	mem 5329MB
[2022-04-18 17:05:18 tiny] (main.py 233): INFO EPOCH 96 training takes 0:12:23
[2022-04-18 17:05:31 tiny] (main.py 273): INFO Test: [0/49]	Time 12.522 (12.522)	Loss 1.8129 (1.8129)	Acc@1 63.184 (63.184)	Acc@5 85.254 (85.254)	Mem 5329MB
[2022-04-18 17:05:49 tiny] (main.py 279): INFO  * Acc@1 64.058 Acc@5 85.988
[2022-04-18 17:05:49 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 64.1%
[2022-04-18 17:05:49 tiny] (main.py 148): INFO Max accuracy: 64.34%
[2022-04-18 17:06:01 tiny] (main.py 226): INFO Train: [97/300][0/1251]	eta 4:00:58 lr 0.000766	time 11.5575 (11.5575)	loss 3.7116 (3.7116)	grad_norm 3.8857 (3.8857)	mem 5329MB
[2022-04-18 17:07:03 tiny] (main.py 226): INFO Train: [97/300][100/1251]	eta 0:13:58 lr 0.000765	time 0.5594 (0.7285)	loss 4.2645 (4.0840)	grad_norm 3.5145 (3.2015)	mem 5329MB
[2022-04-18 17:08:01 tiny] (main.py 226): INFO Train: [97/300][200/1251]	eta 0:11:30 lr 0.000765	time 0.5336 (0.6566)	loss 4.1980 (4.1533)	grad_norm 2.1248 (3.0826)	mem 5329MB
[2022-04-18 17:09:00 tiny] (main.py 226): INFO Train: [97/300][300/1251]	eta 0:10:03 lr 0.000765	time 0.7439 (0.6341)	loss 4.6811 (4.1507)	grad_norm 2.5518 (3.1303)	mem 5329MB
[2022-04-18 17:09:59 tiny] (main.py 226): INFO Train: [97/300][400/1251]	eta 0:08:49 lr 0.000764	time 0.5333 (0.6220)	loss 4.4045 (4.1577)	grad_norm 3.5187 (3.1510)	mem 5329MB
[2022-04-18 17:10:57 tiny] (main.py 226): INFO Train: [97/300][500/1251]	eta 0:07:41 lr 0.000764	time 0.5577 (0.6149)	loss 4.4236 (4.1439)	grad_norm 3.5486 (3.1926)	mem 5329MB
[2022-04-18 17:11:56 tiny] (main.py 226): INFO Train: [97/300][600/1251]	eta 0:06:37 lr 0.000764	time 0.5614 (0.6105)	loss 4.9405 (4.1370)	grad_norm 4.3563 (3.2073)	mem 5329MB
[2022-04-18 17:12:55 tiny] (main.py 226): INFO Train: [97/300][700/1251]	eta 0:05:34 lr 0.000763	time 0.5175 (0.6074)	loss 4.1119 (4.1349)	grad_norm 4.5722 (3.2104)	mem 5329MB
[2022-04-18 17:13:54 tiny] (main.py 226): INFO Train: [97/300][800/1251]	eta 0:04:32 lr 0.000763	time 0.5748 (0.6049)	loss 4.9622 (4.1246)	grad_norm 2.1321 (3.1978)	mem 5329MB
[2022-04-18 17:14:53 tiny] (main.py 226): INFO Train: [97/300][900/1251]	eta 0:03:31 lr 0.000763	time 0.5352 (0.6032)	loss 5.1220 (4.1320)	grad_norm 3.8726 (3.1676)	mem 5329MB
[2022-04-18 17:15:52 tiny] (main.py 226): INFO Train: [97/300][1000/1251]	eta 0:02:31 lr 0.000762	time 0.6546 (0.6018)	loss 2.8216 (4.1188)	grad_norm 2.7234 (3.1768)	mem 5329MB
[2022-04-18 17:16:50 tiny] (main.py 226): INFO Train: [97/300][1100/1251]	eta 0:01:30 lr 0.000762	time 0.8473 (0.6005)	loss 4.1644 (4.1118)	grad_norm 2.3857 (3.1785)	mem 5329MB
[2022-04-18 17:17:49 tiny] (main.py 226): INFO Train: [97/300][1200/1251]	eta 0:00:30 lr 0.000762	time 0.6234 (0.5992)	loss 3.8395 (4.1159)	grad_norm 3.9246 (3.1892)	mem 5329MB
[2022-04-18 17:18:11 tiny] (main.py 233): INFO EPOCH 97 training takes 0:12:21
[2022-04-18 17:18:23 tiny] (main.py 273): INFO Test: [0/49]	Time 12.595 (12.595)	Loss 1.6793 (1.6793)	Acc@1 64.453 (64.453)	Acc@5 88.184 (88.184)	Mem 5329MB
[2022-04-18 17:18:42 tiny] (main.py 279): INFO  * Acc@1 63.514 Acc@5 85.848
[2022-04-18 17:18:42 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 63.5%
[2022-04-18 17:18:42 tiny] (main.py 148): INFO Max accuracy: 64.34%
[2022-04-18 17:18:54 tiny] (main.py 226): INFO Train: [98/300][0/1251]	eta 4:02:13 lr 0.000761	time 11.6172 (11.6172)	loss 5.0600 (5.0600)	grad_norm 3.9121 (3.9121)	mem 5329MB
[2022-04-18 17:19:56 tiny] (main.py 226): INFO Train: [98/300][100/1251]	eta 0:13:56 lr 0.000761	time 0.4548 (0.7267)	loss 4.7873 (4.1287)	grad_norm 3.9424 (3.2737)	mem 5329MB
[2022-04-18 17:20:54 tiny] (main.py 226): INFO Train: [98/300][200/1251]	eta 0:11:29 lr 0.000761	time 0.6013 (0.6564)	loss 5.1272 (4.1033)	grad_norm 2.9241 (inf)	mem 5329MB
[2022-04-18 17:21:52 tiny] (main.py 226): INFO Train: [98/300][300/1251]	eta 0:10:01 lr 0.000760	time 0.5094 (0.6322)	loss 4.3522 (4.1218)	grad_norm 2.2700 (inf)	mem 5329MB
[2022-04-18 17:22:51 tiny] (main.py 226): INFO Train: [98/300][400/1251]	eta 0:08:48 lr 0.000760	time 0.6546 (0.6214)	loss 3.8018 (4.1166)	grad_norm 3.0912 (inf)	mem 5329MB
[2022-04-18 17:23:50 tiny] (main.py 226): INFO Train: [98/300][500/1251]	eta 0:07:41 lr 0.000760	time 0.7768 (0.6141)	loss 4.0438 (4.1067)	grad_norm 6.3558 (inf)	mem 5329MB
[2022-04-18 17:24:49 tiny] (main.py 226): INFO Train: [98/300][600/1251]	eta 0:06:36 lr 0.000759	time 0.5244 (0.6098)	loss 4.2808 (4.0987)	grad_norm 2.5503 (inf)	mem 5329MB
[2022-04-18 17:25:47 tiny] (main.py 226): INFO Train: [98/300][700/1251]	eta 0:05:34 lr 0.000759	time 0.6428 (0.6063)	loss 3.2949 (4.0937)	grad_norm 3.7824 (inf)	mem 5329MB
[2022-04-18 17:26:46 tiny] (main.py 226): INFO Train: [98/300][800/1251]	eta 0:04:32 lr 0.000759	time 0.4737 (0.6044)	loss 3.4694 (4.0935)	grad_norm 2.4210 (inf)	mem 5329MB
[2022-04-18 17:27:45 tiny] (main.py 226): INFO Train: [98/300][900/1251]	eta 0:03:31 lr 0.000758	time 0.4752 (0.6029)	loss 3.5280 (4.0879)	grad_norm 6.9525 (inf)	mem 5329MB
[2022-04-18 17:28:44 tiny] (main.py 226): INFO Train: [98/300][1000/1251]	eta 0:02:30 lr 0.000758	time 0.5111 (0.6012)	loss 4.4113 (4.0980)	grad_norm 1.9903 (inf)	mem 5329MB
[2022-04-18 17:29:43 tiny] (main.py 226): INFO Train: [98/300][1100/1251]	eta 0:01:30 lr 0.000758	time 0.7663 (0.6004)	loss 4.5880 (4.1025)	grad_norm 3.1640 (inf)	mem 5329MB
[2022-04-18 17:30:42 tiny] (main.py 226): INFO Train: [98/300][1200/1251]	eta 0:00:30 lr 0.000757	time 0.5226 (0.5992)	loss 3.1478 (4.1050)	grad_norm 4.1930 (inf)	mem 5329MB
[2022-04-18 17:31:04 tiny] (main.py 233): INFO EPOCH 98 training takes 0:12:21
[2022-04-18 17:31:15 tiny] (main.py 273): INFO Test: [0/49]	Time 11.713 (11.713)	Loss 1.7110 (1.7110)	Acc@1 65.625 (65.625)	Acc@5 87.402 (87.402)	Mem 5329MB
[2022-04-18 17:31:35 tiny] (main.py 279): INFO  * Acc@1 64.616 Acc@5 86.546
[2022-04-18 17:31:35 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 64.6%
[2022-04-18 17:31:35 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_98.pth saving......
[2022-04-18 17:31:35 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_98.pth saved !!!
[2022-04-18 17:31:35 tiny] (main.py 148): INFO Max accuracy: 64.62%
[2022-04-18 17:31:47 tiny] (main.py 226): INFO Train: [99/300][0/1251]	eta 4:20:56 lr 0.000757	time 12.5150 (12.5150)	loss 3.2326 (3.2326)	grad_norm 2.1072 (2.1072)	mem 5329MB
[2022-04-18 17:32:49 tiny] (main.py 226): INFO Train: [99/300][100/1251]	eta 0:14:02 lr 0.000757	time 0.5636 (0.7320)	loss 2.9593 (4.0441)	grad_norm 1.9469 (2.9486)	mem 5329MB
[2022-04-18 17:33:47 tiny] (main.py 226): INFO Train: [99/300][200/1251]	eta 0:11:31 lr 0.000756	time 0.5321 (0.6581)	loss 3.4475 (4.0343)	grad_norm 3.4915 (3.0015)	mem 5329MB
[2022-04-18 17:34:46 tiny] (main.py 226): INFO Train: [99/300][300/1251]	eta 0:10:04 lr 0.000756	time 0.5784 (0.6351)	loss 3.1010 (4.0473)	grad_norm 3.8770 (3.0492)	mem 5329MB
[2022-04-18 17:35:44 tiny] (main.py 226): INFO Train: [99/300][400/1251]	eta 0:08:49 lr 0.000756	time 0.4923 (0.6217)	loss 3.6580 (4.0898)	grad_norm 2.3390 (3.1379)	mem 5329MB
[2022-04-18 17:36:43 tiny] (main.py 226): INFO Train: [99/300][500/1251]	eta 0:07:41 lr 0.000755	time 0.5637 (0.6149)	loss 3.0496 (4.0969)	grad_norm 3.4510 (3.1154)	mem 5329MB
[2022-04-18 17:37:42 tiny] (main.py 226): INFO Train: [99/300][600/1251]	eta 0:06:37 lr 0.000755	time 0.5232 (0.6108)	loss 4.8810 (4.0882)	grad_norm 2.9600 (3.1321)	mem 5329MB
[2022-04-18 17:38:40 tiny] (main.py 226): INFO Train: [99/300][700/1251]	eta 0:05:34 lr 0.000754	time 0.5073 (0.6070)	loss 4.0062 (4.0869)	grad_norm 3.4497 (3.1552)	mem 5329MB
[2022-04-18 17:39:39 tiny] (main.py 226): INFO Train: [99/300][800/1251]	eta 0:04:32 lr 0.000754	time 0.5358 (0.6047)	loss 4.3709 (4.0911)	grad_norm 3.7764 (3.1528)	mem 5329MB
[2022-04-18 17:40:38 tiny] (main.py 226): INFO Train: [99/300][900/1251]	eta 0:03:31 lr 0.000754	time 0.5087 (0.6029)	loss 3.6749 (4.1035)	grad_norm 3.3740 (3.1490)	mem 5329MB
[2022-04-18 17:41:37 tiny] (main.py 226): INFO Train: [99/300][1000/1251]	eta 0:02:30 lr 0.000753	time 0.6960 (0.6015)	loss 3.3619 (4.1112)	grad_norm 2.6384 (3.1533)	mem 5329MB
[2022-04-18 17:42:36 tiny] (main.py 226): INFO Train: [99/300][1100/1251]	eta 0:01:30 lr 0.000753	time 0.6278 (0.6003)	loss 3.0865 (4.1122)	grad_norm 2.7234 (3.1947)	mem 5329MB
[2022-04-18 17:43:35 tiny] (main.py 226): INFO Train: [99/300][1200/1251]	eta 0:00:30 lr 0.000753	time 0.5982 (0.5992)	loss 4.5444 (4.1175)	grad_norm 2.5921 (inf)	mem 5329MB
[2022-04-18 17:43:56 tiny] (main.py 233): INFO EPOCH 99 training takes 0:12:21
[2022-04-18 17:44:07 tiny] (main.py 273): INFO Test: [0/49]	Time 11.162 (11.162)	Loss 1.7224 (1.7224)	Acc@1 65.332 (65.332)	Acc@5 86.621 (86.621)	Mem 5329MB
[2022-04-18 17:44:27 tiny] (main.py 279): INFO  * Acc@1 64.498 Acc@5 86.212
[2022-04-18 17:44:27 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 64.5%
[2022-04-18 17:44:27 tiny] (main.py 148): INFO Max accuracy: 64.62%
[2022-04-18 17:44:38 tiny] (main.py 226): INFO Train: [100/300][0/1251]	eta 3:45:49 lr 0.000753	time 10.8310 (10.8310)	loss 3.3401 (3.3401)	grad_norm 2.3717 (2.3717)	mem 5329MB
[2022-04-18 17:45:41 tiny] (main.py 226): INFO Train: [100/300][100/1251]	eta 0:13:54 lr 0.000752	time 0.5305 (0.7247)	loss 3.4842 (4.1292)	grad_norm 2.4127 (3.3378)	mem 5329MB
[2022-04-18 17:46:39 tiny] (main.py 226): INFO Train: [100/300][200/1251]	eta 0:11:30 lr 0.000752	time 0.5368 (0.6569)	loss 3.5248 (4.0434)	grad_norm 4.0977 (3.2877)	mem 5329MB
[2022-04-18 17:47:38 tiny] (main.py 226): INFO Train: [100/300][300/1251]	eta 0:10:02 lr 0.000751	time 0.6716 (0.6339)	loss 3.5967 (4.0641)	grad_norm 3.3710 (3.2027)	mem 5329MB
[2022-04-18 17:48:36 tiny] (main.py 226): INFO Train: [100/300][400/1251]	eta 0:08:48 lr 0.000751	time 0.6066 (0.6207)	loss 4.0499 (4.0765)	grad_norm 3.1721 (3.1983)	mem 5329MB
[2022-04-18 17:49:35 tiny] (main.py 226): INFO Train: [100/300][500/1251]	eta 0:07:41 lr 0.000751	time 0.6719 (0.6144)	loss 4.1543 (4.0962)	grad_norm 1.8196 (3.1763)	mem 5329MB
[2022-04-18 17:50:34 tiny] (main.py 226): INFO Train: [100/300][600/1251]	eta 0:06:37 lr 0.000750	time 0.8681 (0.6101)	loss 3.7256 (4.1077)	grad_norm 2.9248 (3.1645)	mem 5329MB
[2022-04-18 17:51:33 tiny] (main.py 226): INFO Train: [100/300][700/1251]	eta 0:05:34 lr 0.000750	time 0.6210 (0.6066)	loss 4.6388 (4.1125)	grad_norm 4.7266 (3.1813)	mem 5329MB
[2022-04-18 17:52:31 tiny] (main.py 226): INFO Train: [100/300][800/1251]	eta 0:04:32 lr 0.000750	time 0.5335 (0.6041)	loss 4.1783 (4.1014)	grad_norm 2.7619 (3.1631)	mem 5329MB
[2022-04-18 17:53:29 tiny] (main.py 226): INFO Train: [100/300][900/1251]	eta 0:03:31 lr 0.000749	time 0.4482 (0.6016)	loss 4.2826 (4.0986)	grad_norm 3.4717 (3.1796)	mem 5329MB
[2022-04-18 17:54:29 tiny] (main.py 226): INFO Train: [100/300][1000/1251]	eta 0:02:30 lr 0.000749	time 0.7124 (0.6008)	loss 3.8919 (4.0953)	grad_norm 3.2434 (3.2213)	mem 5329MB
[2022-04-18 17:55:28 tiny] (main.py 226): INFO Train: [100/300][1100/1251]	eta 0:01:30 lr 0.000749	time 0.6176 (0.5997)	loss 3.4521 (4.1002)	grad_norm 2.2047 (3.2134)	mem 5329MB
[2022-04-18 17:56:26 tiny] (main.py 226): INFO Train: [100/300][1200/1251]	eta 0:00:30 lr 0.000748	time 0.5187 (0.5985)	loss 3.3585 (4.0978)	grad_norm 1.9466 (3.2150)	mem 5329MB
[2022-04-18 17:56:48 tiny] (main.py 233): INFO EPOCH 100 training takes 0:12:20
[2022-04-18 17:57:00 tiny] (main.py 273): INFO Test: [0/49]	Time 11.581 (11.581)	Loss 1.7060 (1.7060)	Acc@1 66.016 (66.016)	Acc@5 85.938 (85.938)	Mem 5329MB
[2022-04-18 17:57:19 tiny] (main.py 279): INFO  * Acc@1 64.326 Acc@5 86.238
[2022-04-18 17:57:19 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 64.3%
[2022-04-18 17:57:19 tiny] (main.py 148): INFO Max accuracy: 64.62%
[2022-04-18 17:57:31 tiny] (main.py 226): INFO Train: [101/300][0/1251]	eta 3:53:56 lr 0.000748	time 11.2202 (11.2202)	loss 3.6053 (3.6053)	grad_norm 1.8084 (1.8084)	mem 5329MB
[2022-04-18 17:58:33 tiny] (main.py 226): INFO Train: [101/300][100/1251]	eta 0:13:58 lr 0.000748	time 0.5188 (0.7286)	loss 4.4423 (4.1284)	grad_norm 2.9361 (2.9644)	mem 5329MB
[2022-04-18 17:59:32 tiny] (main.py 226): INFO Train: [101/300][200/1251]	eta 0:11:32 lr 0.000747	time 0.5855 (0.6589)	loss 4.0137 (4.1298)	grad_norm 2.8444 (3.0396)	mem 5329MB
[2022-04-18 18:00:30 tiny] (main.py 226): INFO Train: [101/300][300/1251]	eta 0:10:02 lr 0.000747	time 0.6960 (0.6337)	loss 4.0393 (4.0946)	grad_norm 1.7862 (3.0915)	mem 5329MB
[2022-04-18 18:01:28 tiny] (main.py 226): INFO Train: [101/300][400/1251]	eta 0:08:48 lr 0.000747	time 0.6568 (0.6210)	loss 3.4429 (4.0899)	grad_norm 3.2998 (3.1489)	mem 5329MB
[2022-04-18 18:02:27 tiny] (main.py 226): INFO Train: [101/300][500/1251]	eta 0:07:41 lr 0.000746	time 0.4844 (0.6139)	loss 3.2439 (4.0859)	grad_norm 3.2877 (3.1302)	mem 5329MB
[2022-04-18 18:03:26 tiny] (main.py 226): INFO Train: [101/300][600/1251]	eta 0:06:36 lr 0.000746	time 0.7148 (0.6093)	loss 3.6346 (4.0983)	grad_norm 8.8527 (3.1916)	mem 5329MB
[2022-04-18 18:04:24 tiny] (main.py 226): INFO Train: [101/300][700/1251]	eta 0:05:34 lr 0.000745	time 0.6041 (0.6062)	loss 4.6213 (4.0935)	grad_norm 4.0194 (3.1865)	mem 5329MB
[2022-04-18 18:05:23 tiny] (main.py 226): INFO Train: [101/300][800/1251]	eta 0:04:32 lr 0.000745	time 0.4651 (0.6037)	loss 4.4628 (4.1040)	grad_norm 2.9091 (3.2167)	mem 5329MB
[2022-04-18 18:06:22 tiny] (main.py 226): INFO Train: [101/300][900/1251]	eta 0:03:31 lr 0.000745	time 0.4663 (0.6025)	loss 3.9052 (4.1017)	grad_norm 4.1781 (3.2085)	mem 5329MB
[2022-04-18 18:07:21 tiny] (main.py 226): INFO Train: [101/300][1000/1251]	eta 0:02:30 lr 0.000744	time 0.5789 (0.6005)	loss 3.8812 (4.1022)	grad_norm 5.9223 (3.2103)	mem 5329MB
[2022-04-18 18:08:20 tiny] (main.py 226): INFO Train: [101/300][1100/1251]	eta 0:01:30 lr 0.000744	time 0.4703 (0.5997)	loss 3.9000 (4.1000)	grad_norm 6.1885 (3.2097)	mem 5329MB
[2022-04-18 18:09:19 tiny] (main.py 226): INFO Train: [101/300][1200/1251]	eta 0:00:30 lr 0.000744	time 0.7960 (0.5989)	loss 4.4043 (4.1043)	grad_norm 4.0039 (3.2106)	mem 5329MB
[2022-04-18 18:09:40 tiny] (main.py 233): INFO EPOCH 101 training takes 0:12:20
[2022-04-18 18:09:52 tiny] (main.py 273): INFO Test: [0/49]	Time 11.889 (11.889)	Loss 1.7773 (1.7773)	Acc@1 63.965 (63.965)	Acc@5 85.547 (85.547)	Mem 5329MB
[2022-04-18 18:10:12 tiny] (main.py 279): INFO  * Acc@1 63.644 Acc@5 86.090
[2022-04-18 18:10:12 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 63.6%
[2022-04-18 18:10:12 tiny] (main.py 148): INFO Max accuracy: 64.62%
[2022-04-18 18:10:23 tiny] (main.py 226): INFO Train: [102/300][0/1251]	eta 4:08:29 lr 0.000743	time 11.9177 (11.9177)	loss 4.5398 (4.5398)	grad_norm 2.8187 (2.8187)	mem 5329MB
[2022-04-18 18:11:25 tiny] (main.py 226): INFO Train: [102/300][100/1251]	eta 0:13:56 lr 0.000743	time 0.7729 (0.7266)	loss 5.1762 (4.0417)	grad_norm 4.2597 (3.5829)	mem 5329MB
[2022-04-18 18:12:24 tiny] (main.py 226): INFO Train: [102/300][200/1251]	eta 0:11:31 lr 0.000743	time 0.4201 (0.6582)	loss 4.5372 (4.0181)	grad_norm 5.0188 (3.2990)	mem 5329MB
[2022-04-18 18:13:22 tiny] (main.py 226): INFO Train: [102/300][300/1251]	eta 0:10:02 lr 0.000742	time 0.5848 (0.6331)	loss 4.1103 (4.0757)	grad_norm 3.5038 (3.3130)	mem 5329MB
[2022-04-18 18:14:21 tiny] (main.py 226): INFO Train: [102/300][400/1251]	eta 0:08:48 lr 0.000742	time 0.5559 (0.6210)	loss 4.4057 (4.0981)	grad_norm 4.2932 (3.3250)	mem 5329MB
[2022-04-18 18:15:19 tiny] (main.py 226): INFO Train: [102/300][500/1251]	eta 0:07:41 lr 0.000742	time 0.6647 (0.6142)	loss 3.8226 (4.0916)	grad_norm 4.0619 (3.3135)	mem 5329MB
[2022-04-18 18:16:18 tiny] (main.py 226): INFO Train: [102/300][600/1251]	eta 0:06:37 lr 0.000741	time 0.5667 (0.6100)	loss 3.7509 (4.0841)	grad_norm 2.2481 (3.2979)	mem 5329MB
[2022-04-18 18:17:17 tiny] (main.py 226): INFO Train: [102/300][700/1251]	eta 0:05:34 lr 0.000741	time 0.5996 (0.6070)	loss 5.0253 (4.0864)	grad_norm 2.3294 (inf)	mem 5329MB
[2022-04-18 18:18:16 tiny] (main.py 226): INFO Train: [102/300][800/1251]	eta 0:04:32 lr 0.000741	time 0.4997 (0.6047)	loss 4.4176 (4.0926)	grad_norm 2.8464 (inf)	mem 5329MB
[2022-04-18 18:19:15 tiny] (main.py 226): INFO Train: [102/300][900/1251]	eta 0:03:31 lr 0.000740	time 0.4126 (0.6029)	loss 4.9390 (4.0987)	grad_norm 2.3525 (inf)	mem 5329MB
[2022-04-18 18:20:14 tiny] (main.py 226): INFO Train: [102/300][1000/1251]	eta 0:02:30 lr 0.000740	time 0.7753 (0.6015)	loss 4.3411 (4.1003)	grad_norm 2.7068 (inf)	mem 5329MB
[2022-04-18 18:21:13 tiny] (main.py 226): INFO Train: [102/300][1100/1251]	eta 0:01:30 lr 0.000739	time 0.5267 (0.6004)	loss 5.0845 (4.0976)	grad_norm 2.9249 (inf)	mem 5329MB
[2022-04-18 18:22:11 tiny] (main.py 226): INFO Train: [102/300][1200/1251]	eta 0:00:30 lr 0.000739	time 0.5516 (0.5993)	loss 3.5196 (4.0918)	grad_norm 5.0035 (inf)	mem 5329MB
[2022-04-18 18:22:33 tiny] (main.py 233): INFO EPOCH 102 training takes 0:12:21
[2022-04-18 18:22:45 tiny] (main.py 273): INFO Test: [0/49]	Time 11.631 (11.631)	Loss 1.7108 (1.7108)	Acc@1 64.941 (64.941)	Acc@5 87.109 (87.109)	Mem 5329MB
[2022-04-18 18:23:05 tiny] (main.py 279): INFO  * Acc@1 64.728 Acc@5 86.652
[2022-04-18 18:23:05 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 64.7%
[2022-04-18 18:23:05 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_102.pth saving......
[2022-04-18 18:23:05 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_102.pth saved !!!
[2022-04-18 18:23:05 tiny] (main.py 148): INFO Max accuracy: 64.73%
[2022-04-18 18:23:17 tiny] (main.py 226): INFO Train: [103/300][0/1251]	eta 4:09:43 lr 0.000739	time 11.9772 (11.9772)	loss 4.2071 (4.2071)	grad_norm 2.6713 (2.6713)	mem 5329MB
[2022-04-18 18:24:19 tiny] (main.py 226): INFO Train: [103/300][100/1251]	eta 0:14:00 lr 0.000739	time 0.7536 (0.7300)	loss 4.3785 (4.0763)	grad_norm 4.0621 (3.4961)	mem 5329MB
[2022-04-18 18:25:17 tiny] (main.py 226): INFO Train: [103/300][200/1251]	eta 0:11:31 lr 0.000738	time 0.5962 (0.6582)	loss 4.2998 (4.0809)	grad_norm 3.9168 (3.4579)	mem 5329MB
[2022-04-18 18:26:16 tiny] (main.py 226): INFO Train: [103/300][300/1251]	eta 0:10:02 lr 0.000738	time 0.5783 (0.6332)	loss 3.3628 (4.0684)	grad_norm 3.2515 (3.5466)	mem 5329MB
[2022-04-18 18:27:14 tiny] (main.py 226): INFO Train: [103/300][400/1251]	eta 0:08:48 lr 0.000737	time 0.4192 (0.6208)	loss 4.8234 (4.0699)	grad_norm 2.6641 (3.4179)	mem 5329MB
[2022-04-18 18:28:13 tiny] (main.py 226): INFO Train: [103/300][500/1251]	eta 0:07:41 lr 0.000737	time 0.6450 (0.6144)	loss 4.4398 (4.0707)	grad_norm 2.1068 (3.3599)	mem 5329MB
[2022-04-18 18:29:12 tiny] (main.py 226): INFO Train: [103/300][600/1251]	eta 0:06:37 lr 0.000737	time 0.6925 (0.6107)	loss 3.0395 (4.0714)	grad_norm 3.5961 (3.3542)	mem 5329MB
[2022-04-18 18:30:10 tiny] (main.py 226): INFO Train: [103/300][700/1251]	eta 0:05:34 lr 0.000736	time 0.4628 (0.6068)	loss 2.8514 (4.0831)	grad_norm 2.6075 (3.3490)	mem 5329MB
[2022-04-18 18:31:09 tiny] (main.py 226): INFO Train: [103/300][800/1251]	eta 0:04:32 lr 0.000736	time 0.5625 (0.6042)	loss 5.0410 (4.0754)	grad_norm 3.2143 (3.3384)	mem 5329MB
[2022-04-18 18:32:08 tiny] (main.py 226): INFO Train: [103/300][900/1251]	eta 0:03:31 lr 0.000736	time 0.7089 (0.6031)	loss 4.2163 (4.0762)	grad_norm 4.8387 (3.3462)	mem 5329MB
[2022-04-18 18:33:07 tiny] (main.py 226): INFO Train: [103/300][1000/1251]	eta 0:02:31 lr 0.000735	time 0.5859 (0.6017)	loss 4.1574 (4.0923)	grad_norm 2.6397 (3.3607)	mem 5329MB
[2022-04-18 18:34:06 tiny] (main.py 226): INFO Train: [103/300][1100/1251]	eta 0:01:30 lr 0.000735	time 0.5062 (0.6003)	loss 4.5063 (4.0907)	grad_norm 7.9567 (3.3535)	mem 5329MB
[2022-04-18 18:35:05 tiny] (main.py 226): INFO Train: [103/300][1200/1251]	eta 0:00:30 lr 0.000735	time 0.5310 (0.5995)	loss 4.4517 (4.0952)	grad_norm 2.2537 (3.3359)	mem 5329MB
[2022-04-18 18:35:27 tiny] (main.py 233): INFO EPOCH 103 training takes 0:12:21
[2022-04-18 18:35:39 tiny] (main.py 273): INFO Test: [0/49]	Time 12.482 (12.482)	Loss 1.8158 (1.8158)	Acc@1 65.527 (65.527)	Acc@5 86.816 (86.816)	Mem 5329MB
[2022-04-18 18:35:58 tiny] (main.py 279): INFO  * Acc@1 64.182 Acc@5 86.216
[2022-04-18 18:35:58 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 64.2%
[2022-04-18 18:35:58 tiny] (main.py 148): INFO Max accuracy: 64.73%
[2022-04-18 18:36:10 tiny] (main.py 226): INFO Train: [104/300][0/1251]	eta 4:11:52 lr 0.000734	time 12.0802 (12.0802)	loss 4.0862 (4.0862)	grad_norm 3.2123 (3.2123)	mem 5329MB
[2022-04-18 18:37:12 tiny] (main.py 226): INFO Train: [104/300][100/1251]	eta 0:14:00 lr 0.000734	time 0.7152 (0.7302)	loss 4.4008 (4.0342)	grad_norm 2.3097 (3.1927)	mem 5329MB
[2022-04-18 18:38:10 tiny] (main.py 226): INFO Train: [104/300][200/1251]	eta 0:11:29 lr 0.000734	time 0.5703 (0.6560)	loss 3.7260 (4.0837)	grad_norm 3.6722 (3.2989)	mem 5329MB
[2022-04-18 18:39:09 tiny] (main.py 226): INFO Train: [104/300][300/1251]	eta 0:10:02 lr 0.000733	time 0.6568 (0.6330)	loss 4.5453 (4.0897)	grad_norm 2.1180 (3.2540)	mem 5329MB
[2022-04-18 18:40:07 tiny] (main.py 226): INFO Train: [104/300][400/1251]	eta 0:08:48 lr 0.000733	time 0.6172 (0.6206)	loss 3.8722 (4.0841)	grad_norm 3.3464 (inf)	mem 5329MB
[2022-04-18 18:41:06 tiny] (main.py 226): INFO Train: [104/300][500/1251]	eta 0:07:41 lr 0.000732	time 0.5123 (0.6143)	loss 4.5123 (4.0761)	grad_norm 2.7791 (inf)	mem 5329MB
[2022-04-18 18:42:05 tiny] (main.py 226): INFO Train: [104/300][600/1251]	eta 0:06:36 lr 0.000732	time 0.6143 (0.6093)	loss 4.1898 (4.0765)	grad_norm 1.9900 (inf)	mem 5329MB
[2022-04-18 18:43:03 tiny] (main.py 226): INFO Train: [104/300][700/1251]	eta 0:05:33 lr 0.000732	time 0.3638 (0.6060)	loss 4.2853 (4.0754)	grad_norm 2.6814 (inf)	mem 5329MB
[2022-04-18 18:44:02 tiny] (main.py 226): INFO Train: [104/300][800/1251]	eta 0:04:32 lr 0.000731	time 0.4388 (0.6033)	loss 4.7241 (4.0828)	grad_norm 2.3946 (inf)	mem 5329MB
[2022-04-18 18:45:00 tiny] (main.py 226): INFO Train: [104/300][900/1251]	eta 0:03:31 lr 0.000731	time 0.7661 (0.6016)	loss 4.4115 (4.0875)	grad_norm 4.1367 (inf)	mem 5329MB
[2022-04-18 18:46:00 tiny] (main.py 226): INFO Train: [104/300][1000/1251]	eta 0:02:30 lr 0.000731	time 0.6171 (0.6006)	loss 4.2447 (4.0798)	grad_norm 2.8701 (inf)	mem 5329MB
[2022-04-18 18:46:58 tiny] (main.py 226): INFO Train: [104/300][1100/1251]	eta 0:01:30 lr 0.000730	time 0.6128 (0.5993)	loss 4.9340 (4.0805)	grad_norm 2.7020 (inf)	mem 5329MB
[2022-04-18 18:47:57 tiny] (main.py 226): INFO Train: [104/300][1200/1251]	eta 0:00:30 lr 0.000730	time 0.5585 (0.5986)	loss 2.8328 (4.0814)	grad_norm 2.3238 (inf)	mem 5329MB
[2022-04-18 18:48:20 tiny] (main.py 233): INFO EPOCH 104 training takes 0:12:21
[2022-04-18 18:48:31 tiny] (main.py 273): INFO Test: [0/49]	Time 11.059 (11.059)	Loss 1.7102 (1.7102)	Acc@1 63.965 (63.965)	Acc@5 87.305 (87.305)	Mem 5329MB
[2022-04-18 18:48:50 tiny] (main.py 279): INFO  * Acc@1 64.246 Acc@5 86.152
[2022-04-18 18:48:50 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 64.2%
[2022-04-18 18:48:50 tiny] (main.py 148): INFO Max accuracy: 64.73%
[2022-04-18 18:49:02 tiny] (main.py 226): INFO Train: [105/300][0/1251]	eta 3:53:15 lr 0.000730	time 11.1875 (11.1875)	loss 4.2857 (4.2857)	grad_norm 2.2650 (2.2650)	mem 5329MB
[2022-04-18 18:50:04 tiny] (main.py 226): INFO Train: [105/300][100/1251]	eta 0:14:00 lr 0.000729	time 0.4347 (0.7300)	loss 4.6905 (4.0047)	grad_norm 4.0765 (3.1189)	mem 5329MB
[2022-04-18 18:51:03 tiny] (main.py 226): INFO Train: [105/300][200/1251]	eta 0:11:32 lr 0.000729	time 0.7247 (0.6585)	loss 4.4375 (4.0294)	grad_norm 2.3079 (3.3454)	mem 5329MB
[2022-04-18 18:52:02 tiny] (main.py 226): INFO Train: [105/300][300/1251]	eta 0:10:03 lr 0.000729	time 0.7338 (0.6350)	loss 4.4269 (4.0571)	grad_norm 3.0593 (3.2651)	mem 5329MB
[2022-04-18 18:53:00 tiny] (main.py 226): INFO Train: [105/300][400/1251]	eta 0:08:48 lr 0.000728	time 0.5598 (0.6216)	loss 3.7700 (4.0457)	grad_norm 3.1478 (3.2028)	mem 5329MB
[2022-04-18 18:53:58 tiny] (main.py 226): INFO Train: [105/300][500/1251]	eta 0:07:41 lr 0.000728	time 0.6494 (0.6141)	loss 3.3047 (4.0569)	grad_norm 2.1839 (3.2738)	mem 5329MB
[2022-04-18 18:54:57 tiny] (main.py 226): INFO Train: [105/300][600/1251]	eta 0:06:36 lr 0.000728	time 0.5849 (0.6096)	loss 3.7056 (4.0479)	grad_norm 3.2939 (3.2521)	mem 5329MB
[2022-04-18 18:55:56 tiny] (main.py 226): INFO Train: [105/300][700/1251]	eta 0:05:34 lr 0.000727	time 0.8271 (0.6072)	loss 4.6885 (4.0560)	grad_norm 4.1289 (3.2590)	mem 5329MB
[2022-04-18 18:56:55 tiny] (main.py 226): INFO Train: [105/300][800/1251]	eta 0:04:32 lr 0.000727	time 0.7468 (0.6048)	loss 4.3603 (4.0652)	grad_norm 3.8103 (3.2798)	mem 5329MB
[2022-04-18 18:57:54 tiny] (main.py 226): INFO Train: [105/300][900/1251]	eta 0:03:31 lr 0.000726	time 0.6416 (0.6029)	loss 3.8764 (4.0725)	grad_norm 2.2243 (3.2863)	mem 5329MB
[2022-04-18 18:58:52 tiny] (main.py 226): INFO Train: [105/300][1000/1251]	eta 0:02:30 lr 0.000726	time 0.5402 (0.6013)	loss 4.1817 (4.0739)	grad_norm 2.3910 (3.2874)	mem 5329MB
[2022-04-18 18:59:52 tiny] (main.py 226): INFO Train: [105/300][1100/1251]	eta 0:01:30 lr 0.000726	time 0.7228 (0.6004)	loss 2.8362 (4.0793)	grad_norm 1.8601 (3.2761)	mem 5329MB
[2022-04-18 19:00:50 tiny] (main.py 226): INFO Train: [105/300][1200/1251]	eta 0:00:30 lr 0.000725	time 0.6414 (0.5993)	loss 4.8382 (4.0887)	grad_norm 4.5901 (inf)	mem 5329MB
[2022-04-18 19:01:12 tiny] (main.py 233): INFO EPOCH 105 training takes 0:12:21
[2022-04-18 19:01:24 tiny] (main.py 273): INFO Test: [0/49]	Time 11.856 (11.856)	Loss 1.8326 (1.8326)	Acc@1 63.770 (63.770)	Acc@5 85.352 (85.352)	Mem 5329MB
[2022-04-18 19:01:43 tiny] (main.py 279): INFO  * Acc@1 63.654 Acc@5 85.794
[2022-04-18 19:01:43 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 63.7%
[2022-04-18 19:01:43 tiny] (main.py 148): INFO Max accuracy: 64.73%
[2022-04-18 19:01:55 tiny] (main.py 226): INFO Train: [106/300][0/1251]	eta 4:06:16 lr 0.000725	time 11.8119 (11.8119)	loss 4.0032 (4.0032)	grad_norm 8.5867 (8.5867)	mem 5329MB
[2022-04-18 19:02:57 tiny] (main.py 226): INFO Train: [106/300][100/1251]	eta 0:13:59 lr 0.000725	time 0.6860 (0.7293)	loss 3.7323 (4.0032)	grad_norm 4.9876 (3.5289)	mem 5329MB
[2022-04-18 19:03:55 tiny] (main.py 226): INFO Train: [106/300][200/1251]	eta 0:11:28 lr 0.000724	time 0.5986 (0.6547)	loss 4.4740 (4.0137)	grad_norm 3.4756 (3.4058)	mem 5329MB
[2022-04-18 19:04:53 tiny] (main.py 226): INFO Train: [106/300][300/1251]	eta 0:10:00 lr 0.000724	time 0.5574 (0.6311)	loss 3.9378 (4.0736)	grad_norm 4.4470 (3.4227)	mem 5329MB
[2022-04-18 19:05:52 tiny] (main.py 226): INFO Train: [106/300][400/1251]	eta 0:08:48 lr 0.000724	time 0.7304 (0.6212)	loss 3.8987 (4.0913)	grad_norm 3.4977 (3.4482)	mem 5329MB
[2022-04-18 19:06:51 tiny] (main.py 226): INFO Train: [106/300][500/1251]	eta 0:07:41 lr 0.000723	time 0.4967 (0.6141)	loss 4.3321 (4.1053)	grad_norm 2.1849 (3.3713)	mem 5329MB
[2022-04-18 19:07:50 tiny] (main.py 226): INFO Train: [106/300][600/1251]	eta 0:06:36 lr 0.000723	time 0.4680 (0.6097)	loss 3.4977 (4.0959)	grad_norm 1.9518 (3.3804)	mem 5329MB
[2022-04-18 19:08:48 tiny] (main.py 226): INFO Train: [106/300][700/1251]	eta 0:05:34 lr 0.000722	time 0.4316 (0.6065)	loss 3.1558 (4.1050)	grad_norm 2.3017 (3.3352)	mem 5329MB
[2022-04-18 19:09:47 tiny] (main.py 226): INFO Train: [106/300][800/1251]	eta 0:04:32 lr 0.000722	time 0.7272 (0.6042)	loss 4.5247 (4.1083)	grad_norm 3.9994 (3.3520)	mem 5329MB
[2022-04-18 19:10:46 tiny] (main.py 226): INFO Train: [106/300][900/1251]	eta 0:03:31 lr 0.000722	time 0.6185 (0.6029)	loss 4.2510 (4.1109)	grad_norm 3.6549 (3.3456)	mem 5329MB
[2022-04-18 19:11:45 tiny] (main.py 226): INFO Train: [106/300][1000/1251]	eta 0:02:31 lr 0.000721	time 0.5677 (0.6016)	loss 4.3430 (4.1130)	grad_norm 2.4432 (3.3327)	mem 5329MB
[2022-04-18 19:12:44 tiny] (main.py 226): INFO Train: [106/300][1100/1251]	eta 0:01:30 lr 0.000721	time 0.6236 (0.6003)	loss 4.4232 (4.1097)	grad_norm 3.4070 (3.3509)	mem 5329MB
[2022-04-18 19:13:43 tiny] (main.py 226): INFO Train: [106/300][1200/1251]	eta 0:00:30 lr 0.000721	time 0.5467 (0.5995)	loss 3.1300 (4.1002)	grad_norm 2.3118 (3.3407)	mem 5329MB
[2022-04-18 19:14:05 tiny] (main.py 233): INFO EPOCH 106 training takes 0:12:21
[2022-04-18 19:14:17 tiny] (main.py 273): INFO Test: [0/49]	Time 11.950 (11.950)	Loss 1.7180 (1.7180)	Acc@1 63.672 (63.672)	Acc@5 87.402 (87.402)	Mem 5329MB
[2022-04-18 19:14:36 tiny] (main.py 279): INFO  * Acc@1 64.830 Acc@5 86.470
[2022-04-18 19:14:36 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 64.8%
[2022-04-18 19:14:36 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_106.pth saving......
[2022-04-18 19:14:36 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_106.pth saved !!!
[2022-04-18 19:14:36 tiny] (main.py 148): INFO Max accuracy: 64.83%
[2022-04-18 19:14:46 tiny] (main.py 226): INFO Train: [107/300][0/1251]	eta 3:25:18 lr 0.000720	time 9.8471 (9.8471)	loss 3.1919 (3.1919)	grad_norm 4.9854 (4.9854)	mem 5329MB
[2022-04-18 19:15:50 tiny] (main.py 226): INFO Train: [107/300][100/1251]	eta 0:13:54 lr 0.000720	time 0.6063 (0.7252)	loss 4.5284 (4.0396)	grad_norm 6.1269 (3.3167)	mem 5329MB
[2022-04-18 19:16:48 tiny] (main.py 226): INFO Train: [107/300][200/1251]	eta 0:11:28 lr 0.000720	time 0.5261 (0.6553)	loss 3.4176 (4.0213)	grad_norm 4.0093 (3.4342)	mem 5329MB
[2022-04-18 19:17:47 tiny] (main.py 226): INFO Train: [107/300][300/1251]	eta 0:10:03 lr 0.000719	time 0.6871 (0.6342)	loss 4.4794 (4.0614)	grad_norm 2.6953 (3.4600)	mem 5329MB
[2022-04-18 19:18:46 tiny] (main.py 226): INFO Train: [107/300][400/1251]	eta 0:08:49 lr 0.000719	time 0.4754 (0.6224)	loss 4.8441 (4.0832)	grad_norm 2.8269 (3.3213)	mem 5329MB
[2022-04-18 19:19:45 tiny] (main.py 226): INFO Train: [107/300][500/1251]	eta 0:07:41 lr 0.000719	time 0.5858 (0.6151)	loss 3.0511 (4.0758)	grad_norm 2.2045 (3.3293)	mem 5329MB
[2022-04-18 19:20:43 tiny] (main.py 226): INFO Train: [107/300][600/1251]	eta 0:06:37 lr 0.000718	time 0.5879 (0.6104)	loss 3.3288 (4.0683)	grad_norm 3.5320 (3.3656)	mem 5329MB
[2022-04-18 19:21:42 tiny] (main.py 226): INFO Train: [107/300][700/1251]	eta 0:05:34 lr 0.000718	time 0.5503 (0.6077)	loss 4.3874 (4.0721)	grad_norm 2.7028 (3.3596)	mem 5329MB
[2022-04-18 19:22:41 tiny] (main.py 226): INFO Train: [107/300][800/1251]	eta 0:04:32 lr 0.000717	time 0.5375 (0.6051)	loss 4.4589 (4.0651)	grad_norm 4.3254 (3.3652)	mem 5329MB
[2022-04-18 19:23:40 tiny] (main.py 226): INFO Train: [107/300][900/1251]	eta 0:03:31 lr 0.000717	time 0.6451 (0.6028)	loss 3.6727 (4.0695)	grad_norm inf (inf)	mem 5329MB
[2022-04-18 19:24:38 tiny] (main.py 226): INFO Train: [107/300][1000/1251]	eta 0:02:30 lr 0.000717	time 0.6360 (0.6013)	loss 4.5971 (4.0764)	grad_norm 3.0696 (inf)	mem 5329MB
[2022-04-18 19:25:37 tiny] (main.py 226): INFO Train: [107/300][1100/1251]	eta 0:01:30 lr 0.000716	time 0.5905 (0.6004)	loss 4.6839 (4.0823)	grad_norm 2.2856 (inf)	mem 5329MB
[2022-04-18 19:26:36 tiny] (main.py 226): INFO Train: [107/300][1200/1251]	eta 0:00:30 lr 0.000716	time 0.5419 (0.5993)	loss 4.3430 (4.0811)	grad_norm 3.0749 (inf)	mem 5329MB
[2022-04-18 19:26:58 tiny] (main.py 233): INFO EPOCH 107 training takes 0:12:21
[2022-04-18 19:27:10 tiny] (main.py 273): INFO Test: [0/49]	Time 12.149 (12.149)	Loss 1.7056 (1.7056)	Acc@1 66.699 (66.699)	Acc@5 86.230 (86.230)	Mem 5329MB
[2022-04-18 19:27:29 tiny] (main.py 279): INFO  * Acc@1 64.960 Acc@5 86.574
[2022-04-18 19:27:29 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 65.0%
[2022-04-18 19:27:29 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_107.pth saving......
[2022-04-18 19:27:29 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_107.pth saved !!!
[2022-04-18 19:27:29 tiny] (main.py 148): INFO Max accuracy: 64.96%
[2022-04-18 19:27:40 tiny] (main.py 226): INFO Train: [108/300][0/1251]	eta 3:57:29 lr 0.000716	time 11.3907 (11.3907)	loss 4.3044 (4.3044)	grad_norm 3.3738 (3.3738)	mem 5329MB
[2022-04-18 19:28:42 tiny] (main.py 226): INFO Train: [108/300][100/1251]	eta 0:13:56 lr 0.000715	time 0.4604 (0.7264)	loss 4.6784 (4.1093)	grad_norm 1.9837 (3.3884)	mem 5329MB
[2022-04-18 19:29:41 tiny] (main.py 226): INFO Train: [108/300][200/1251]	eta 0:11:29 lr 0.000715	time 0.6655 (0.6562)	loss 4.8184 (4.1245)	grad_norm 6.1567 (3.3750)	mem 5329MB
[2022-04-18 19:30:39 tiny] (main.py 226): INFO Train: [108/300][300/1251]	eta 0:10:01 lr 0.000715	time 0.6339 (0.6326)	loss 4.5501 (4.1319)	grad_norm 2.1533 (3.4489)	mem 5329MB
[2022-04-18 19:31:38 tiny] (main.py 226): INFO Train: [108/300][400/1251]	eta 0:08:49 lr 0.000714	time 0.5271 (0.6218)	loss 4.5458 (4.1035)	grad_norm 4.2784 (3.4378)	mem 5329MB
[2022-04-18 19:32:36 tiny] (main.py 226): INFO Train: [108/300][500/1251]	eta 0:07:40 lr 0.000714	time 0.5176 (0.6132)	loss 3.0678 (4.1105)	grad_norm 1.9962 (3.4343)	mem 5329MB
[2022-04-18 19:33:35 tiny] (main.py 226): INFO Train: [108/300][600/1251]	eta 0:06:36 lr 0.000714	time 0.6707 (0.6088)	loss 3.2367 (4.1182)	grad_norm 2.7805 (3.4363)	mem 5329MB
[2022-04-18 19:34:34 tiny] (main.py 226): INFO Train: [108/300][700/1251]	eta 0:05:33 lr 0.000713	time 0.7643 (0.6059)	loss 3.3124 (4.1152)	grad_norm 2.3334 (3.3917)	mem 5329MB
[2022-04-18 19:35:33 tiny] (main.py 226): INFO Train: [108/300][800/1251]	eta 0:04:32 lr 0.000713	time 0.7479 (0.6039)	loss 4.5130 (4.1138)	grad_norm 3.1356 (3.4018)	mem 5329MB
[2022-04-18 19:36:31 tiny] (main.py 226): INFO Train: [108/300][900/1251]	eta 0:03:31 lr 0.000712	time 0.7560 (0.6022)	loss 3.5268 (4.1177)	grad_norm 2.6150 (3.4165)	mem 5329MB
[2022-04-18 19:37:31 tiny] (main.py 226): INFO Train: [108/300][1000/1251]	eta 0:02:30 lr 0.000712	time 0.8376 (0.6011)	loss 4.3664 (4.1216)	grad_norm 2.4285 (3.4257)	mem 5329MB
[2022-04-18 19:38:29 tiny] (main.py 226): INFO Train: [108/300][1100/1251]	eta 0:01:30 lr 0.000712	time 0.5140 (0.5997)	loss 3.6368 (4.1171)	grad_norm 2.0397 (3.4238)	mem 5329MB
[2022-04-18 19:39:28 tiny] (main.py 226): INFO Train: [108/300][1200/1251]	eta 0:00:30 lr 0.000711	time 0.4137 (0.5990)	loss 3.5358 (4.1207)	grad_norm 3.2114 (3.4154)	mem 5329MB
[2022-04-18 19:39:50 tiny] (main.py 233): INFO EPOCH 108 training takes 0:12:21
[2022-04-18 19:40:02 tiny] (main.py 273): INFO Test: [0/49]	Time 11.846 (11.846)	Loss 1.7023 (1.7023)	Acc@1 67.188 (67.188)	Acc@5 87.207 (87.207)	Mem 5329MB
[2022-04-18 19:40:22 tiny] (main.py 279): INFO  * Acc@1 64.622 Acc@5 86.464
[2022-04-18 19:40:22 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 64.6%
[2022-04-18 19:40:22 tiny] (main.py 148): INFO Max accuracy: 64.96%
[2022-04-18 19:40:34 tiny] (main.py 226): INFO Train: [109/300][0/1251]	eta 4:08:20 lr 0.000711	time 11.9106 (11.9106)	loss 3.9252 (3.9252)	grad_norm 2.2057 (2.2057)	mem 5329MB
[2022-04-18 19:41:35 tiny] (main.py 226): INFO Train: [109/300][100/1251]	eta 0:13:57 lr 0.000711	time 0.4712 (0.7274)	loss 3.6752 (4.0115)	grad_norm 2.3077 (3.4094)	mem 5329MB
[2022-04-18 19:42:34 tiny] (main.py 226): INFO Train: [109/300][200/1251]	eta 0:11:31 lr 0.000710	time 0.5930 (0.6577)	loss 3.8742 (3.9840)	grad_norm 3.9237 (3.4253)	mem 5329MB
[2022-04-18 19:43:32 tiny] (main.py 226): INFO Train: [109/300][300/1251]	eta 0:10:01 lr 0.000710	time 0.8307 (0.6329)	loss 4.1529 (4.0235)	grad_norm 2.2425 (3.5027)	mem 5329MB
[2022-04-18 19:44:31 tiny] (main.py 226): INFO Train: [109/300][400/1251]	eta 0:08:48 lr 0.000710	time 0.6031 (0.6211)	loss 3.0728 (4.0325)	grad_norm 2.4624 (3.4521)	mem 5329MB
[2022-04-18 19:45:29 tiny] (main.py 226): INFO Train: [109/300][500/1251]	eta 0:07:41 lr 0.000709	time 0.5009 (0.6144)	loss 4.6950 (4.0444)	grad_norm 2.3897 (3.4334)	mem 5329MB
[2022-04-18 19:46:28 tiny] (main.py 226): INFO Train: [109/300][600/1251]	eta 0:06:37 lr 0.000709	time 0.5716 (0.6101)	loss 3.8808 (4.0501)	grad_norm 3.4451 (3.4234)	mem 5329MB
[2022-04-18 19:47:27 tiny] (main.py 226): INFO Train: [109/300][700/1251]	eta 0:05:34 lr 0.000708	time 0.5532 (0.6064)	loss 4.3823 (4.0705)	grad_norm 3.7110 (inf)	mem 5329MB
[2022-04-18 19:48:26 tiny] (main.py 226): INFO Train: [109/300][800/1251]	eta 0:04:32 lr 0.000708	time 0.4478 (0.6044)	loss 4.9635 (4.0704)	grad_norm 2.4388 (inf)	mem 5329MB
[2022-04-18 19:49:25 tiny] (main.py 226): INFO Train: [109/300][900/1251]	eta 0:03:31 lr 0.000708	time 0.5443 (0.6031)	loss 3.6334 (4.0676)	grad_norm 2.2189 (inf)	mem 5329MB
[2022-04-18 19:50:24 tiny] (main.py 226): INFO Train: [109/300][1000/1251]	eta 0:02:30 lr 0.000707	time 0.5237 (0.6014)	loss 3.3993 (4.0744)	grad_norm 2.9502 (inf)	mem 5329MB
[2022-04-18 19:51:23 tiny] (main.py 226): INFO Train: [109/300][1100/1251]	eta 0:01:30 lr 0.000707	time 0.6043 (0.6004)	loss 4.1060 (4.0706)	grad_norm 4.8612 (inf)	mem 5329MB
[2022-04-18 19:52:22 tiny] (main.py 226): INFO Train: [109/300][1200/1251]	eta 0:00:30 lr 0.000707	time 0.5912 (0.5996)	loss 3.2136 (4.0692)	grad_norm 4.2857 (inf)	mem 5329MB
[2022-04-18 19:52:43 tiny] (main.py 233): INFO EPOCH 109 training takes 0:12:21
[2022-04-18 19:52:54 tiny] (main.py 273): INFO Test: [0/49]	Time 10.504 (10.504)	Loss 1.7402 (1.7402)	Acc@1 64.160 (64.160)	Acc@5 86.133 (86.133)	Mem 5329MB
[2022-04-18 19:53:14 tiny] (main.py 279): INFO  * Acc@1 64.844 Acc@5 86.576
[2022-04-18 19:53:14 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 64.8%
[2022-04-18 19:53:14 tiny] (main.py 148): INFO Max accuracy: 64.96%
[2022-04-18 19:53:27 tiny] (main.py 226): INFO Train: [110/300][0/1251]	eta 4:18:06 lr 0.000706	time 12.3792 (12.3792)	loss 4.6064 (4.6064)	grad_norm 3.3971 (3.3971)	mem 5329MB
[2022-04-18 19:54:29 tiny] (main.py 226): INFO Train: [110/300][100/1251]	eta 0:14:06 lr 0.000706	time 0.4884 (0.7350)	loss 4.1338 (4.0683)	grad_norm 5.9396 (3.4411)	mem 5329MB
[2022-04-18 19:55:27 tiny] (main.py 226): INFO Train: [110/300][200/1251]	eta 0:11:33 lr 0.000706	time 0.4388 (0.6601)	loss 4.3362 (4.0920)	grad_norm 4.3445 (3.5336)	mem 5329MB
[2022-04-18 19:56:26 tiny] (main.py 226): INFO Train: [110/300][300/1251]	eta 0:10:04 lr 0.000705	time 0.4568 (0.6351)	loss 3.0134 (4.0770)	grad_norm 3.1337 (3.4087)	mem 5329MB
[2022-04-18 19:57:24 tiny] (main.py 226): INFO Train: [110/300][400/1251]	eta 0:08:48 lr 0.000705	time 0.4064 (0.6215)	loss 3.9090 (4.0798)	grad_norm 3.6299 (3.3725)	mem 5329MB
[2022-04-18 19:58:23 tiny] (main.py 226): INFO Train: [110/300][500/1251]	eta 0:07:41 lr 0.000704	time 0.7013 (0.6152)	loss 4.4750 (4.0841)	grad_norm 2.3488 (3.4200)	mem 5329MB
[2022-04-18 19:59:21 tiny] (main.py 226): INFO Train: [110/300][600/1251]	eta 0:06:36 lr 0.000704	time 0.4884 (0.6097)	loss 4.9063 (4.0867)	grad_norm 4.2071 (3.4439)	mem 5329MB
[2022-04-18 20:00:20 tiny] (main.py 226): INFO Train: [110/300][700/1251]	eta 0:05:34 lr 0.000704	time 0.6418 (0.6067)	loss 4.3642 (4.0792)	grad_norm 4.0948 (3.4250)	mem 5329MB
[2022-04-18 20:01:19 tiny] (main.py 226): INFO Train: [110/300][800/1251]	eta 0:04:32 lr 0.000703	time 0.6717 (0.6045)	loss 3.3253 (4.0678)	grad_norm 2.4880 (3.4464)	mem 5329MB
[2022-04-18 20:02:17 tiny] (main.py 226): INFO Train: [110/300][900/1251]	eta 0:03:31 lr 0.000703	time 0.4680 (0.6027)	loss 4.6007 (4.0644)	grad_norm 3.2208 (3.4284)	mem 5329MB
[2022-04-18 20:03:17 tiny] (main.py 226): INFO Train: [110/300][1000/1251]	eta 0:02:31 lr 0.000703	time 0.6591 (0.6020)	loss 4.5343 (4.0600)	grad_norm 2.3419 (3.4280)	mem 5329MB
[2022-04-18 20:04:16 tiny] (main.py 226): INFO Train: [110/300][1100/1251]	eta 0:01:30 lr 0.000702	time 0.5814 (0.6007)	loss 4.9290 (4.0542)	grad_norm 3.9000 (3.4194)	mem 5329MB
[2022-04-18 20:05:15 tiny] (main.py 226): INFO Train: [110/300][1200/1251]	eta 0:00:30 lr 0.000702	time 0.6966 (0.5997)	loss 4.4011 (4.0541)	grad_norm 2.3428 (3.4185)	mem 5329MB
[2022-04-18 20:05:37 tiny] (main.py 233): INFO EPOCH 110 training takes 0:12:22
[2022-04-18 20:05:48 tiny] (main.py 273): INFO Test: [0/49]	Time 11.745 (11.745)	Loss 1.8029 (1.8029)	Acc@1 64.746 (64.746)	Acc@5 86.719 (86.719)	Mem 5329MB
[2022-04-18 20:06:08 tiny] (main.py 279): INFO  * Acc@1 64.844 Acc@5 86.700
[2022-04-18 20:06:08 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 64.8%
[2022-04-18 20:06:08 tiny] (main.py 148): INFO Max accuracy: 64.96%
[2022-04-18 20:06:20 tiny] (main.py 226): INFO Train: [111/300][0/1251]	eta 4:06:15 lr 0.000702	time 11.8107 (11.8107)	loss 3.9122 (3.9122)	grad_norm 4.3235 (4.3235)	mem 5329MB
[2022-04-18 20:07:21 tiny] (main.py 226): INFO Train: [111/300][100/1251]	eta 0:13:54 lr 0.000701	time 0.5685 (0.7248)	loss 4.0458 (4.0523)	grad_norm 3.5710 (3.7692)	mem 5329MB
[2022-04-18 20:08:20 tiny] (main.py 226): INFO Train: [111/300][200/1251]	eta 0:11:31 lr 0.000701	time 0.7890 (0.6575)	loss 4.2664 (4.0389)	grad_norm 6.9963 (3.6630)	mem 5329MB
[2022-04-18 20:09:18 tiny] (main.py 226): INFO Train: [111/300][300/1251]	eta 0:10:02 lr 0.000700	time 0.5744 (0.6333)	loss 2.9362 (4.0549)	grad_norm 4.2531 (3.5479)	mem 5329MB
[2022-04-18 20:10:17 tiny] (main.py 226): INFO Train: [111/300][400/1251]	eta 0:08:48 lr 0.000700	time 0.5745 (0.6216)	loss 3.0345 (4.0500)	grad_norm 4.7718 (3.5724)	mem 5329MB
[2022-04-18 20:11:16 tiny] (main.py 226): INFO Train: [111/300][500/1251]	eta 0:07:41 lr 0.000700	time 0.5408 (0.6151)	loss 4.0675 (4.0681)	grad_norm 3.7704 (3.5670)	mem 5329MB
[2022-04-18 20:12:14 tiny] (main.py 226): INFO Train: [111/300][600/1251]	eta 0:06:37 lr 0.000699	time 0.7265 (0.6102)	loss 4.3976 (4.0748)	grad_norm 2.1238 (3.5142)	mem 5329MB
[2022-04-18 20:13:13 tiny] (main.py 226): INFO Train: [111/300][700/1251]	eta 0:05:34 lr 0.000699	time 0.5843 (0.6069)	loss 4.4803 (4.0846)	grad_norm 3.3453 (3.5277)	mem 5329MB
[2022-04-18 20:14:12 tiny] (main.py 226): INFO Train: [111/300][800/1251]	eta 0:04:32 lr 0.000699	time 0.5749 (0.6043)	loss 3.3146 (4.0730)	grad_norm 5.7216 (3.4828)	mem 5329MB
[2022-04-18 20:15:11 tiny] (main.py 226): INFO Train: [111/300][900/1251]	eta 0:03:31 lr 0.000698	time 0.7469 (0.6030)	loss 4.7125 (4.0705)	grad_norm 2.2421 (3.4725)	mem 5329MB
[2022-04-18 20:16:09 tiny] (main.py 226): INFO Train: [111/300][1000/1251]	eta 0:02:30 lr 0.000698	time 0.7949 (0.6010)	loss 3.6440 (4.0810)	grad_norm 2.9886 (3.4612)	mem 5329MB
[2022-04-18 20:17:09 tiny] (main.py 226): INFO Train: [111/300][1100/1251]	eta 0:01:30 lr 0.000697	time 0.7213 (0.6003)	loss 3.0336 (4.0824)	grad_norm 2.9328 (inf)	mem 5329MB
[2022-04-18 20:18:08 tiny] (main.py 226): INFO Train: [111/300][1200/1251]	eta 0:00:30 lr 0.000697	time 0.5796 (0.5993)	loss 5.0190 (4.0858)	grad_norm 4.5276 (inf)	mem 5329MB
[2022-04-18 20:18:29 tiny] (main.py 233): INFO EPOCH 111 training takes 0:12:21
[2022-04-18 20:18:42 tiny] (main.py 273): INFO Test: [0/49]	Time 12.115 (12.115)	Loss 1.7351 (1.7351)	Acc@1 63.477 (63.477)	Acc@5 86.621 (86.621)	Mem 5329MB
[2022-04-18 20:19:00 tiny] (main.py 279): INFO  * Acc@1 64.654 Acc@5 86.502
[2022-04-18 20:19:00 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 64.7%
[2022-04-18 20:19:00 tiny] (main.py 148): INFO Max accuracy: 64.96%
[2022-04-18 20:19:12 tiny] (main.py 226): INFO Train: [112/300][0/1251]	eta 3:56:47 lr 0.000697	time 11.3570 (11.3570)	loss 4.5248 (4.5248)	grad_norm 2.8579 (2.8579)	mem 5329MB
[2022-04-18 20:20:14 tiny] (main.py 226): INFO Train: [112/300][100/1251]	eta 0:13:57 lr 0.000696	time 0.5186 (0.7280)	loss 4.5652 (4.0750)	grad_norm 2.9658 (3.2991)	mem 5329MB
[2022-04-18 20:21:12 tiny] (main.py 226): INFO Train: [112/300][200/1251]	eta 0:11:30 lr 0.000696	time 0.3910 (0.6569)	loss 4.4845 (4.0512)	grad_norm 4.4003 (3.2842)	mem 5329MB
[2022-04-18 20:22:11 tiny] (main.py 226): INFO Train: [112/300][300/1251]	eta 0:10:01 lr 0.000696	time 0.4692 (0.6325)	loss 4.5141 (4.0405)	grad_norm 2.0302 (3.3358)	mem 5329MB
[2022-04-18 20:23:10 tiny] (main.py 226): INFO Train: [112/300][400/1251]	eta 0:08:48 lr 0.000695	time 0.5760 (0.6212)	loss 4.1777 (4.0749)	grad_norm 3.9456 (3.3525)	mem 5329MB
[2022-04-18 20:24:08 tiny] (main.py 226): INFO Train: [112/300][500/1251]	eta 0:07:41 lr 0.000695	time 0.5892 (0.6140)	loss 4.2439 (4.0721)	grad_norm 3.2243 (3.3796)	mem 5329MB
[2022-04-18 20:25:07 tiny] (main.py 226): INFO Train: [112/300][600/1251]	eta 0:06:37 lr 0.000695	time 0.8823 (0.6106)	loss 4.4451 (4.0761)	grad_norm 3.0337 (3.4343)	mem 5329MB
[2022-04-18 20:26:06 tiny] (main.py 226): INFO Train: [112/300][700/1251]	eta 0:05:34 lr 0.000694	time 0.6654 (0.6067)	loss 3.5335 (4.0722)	grad_norm 3.5875 (3.3935)	mem 5329MB
[2022-04-18 20:27:05 tiny] (main.py 226): INFO Train: [112/300][800/1251]	eta 0:04:32 lr 0.000694	time 0.4624 (0.6045)	loss 3.6089 (4.0700)	grad_norm 6.3344 (3.3741)	mem 5329MB
[2022-04-18 20:28:03 tiny] (main.py 226): INFO Train: [112/300][900/1251]	eta 0:03:31 lr 0.000693	time 0.6603 (0.6027)	loss 3.3794 (4.0696)	grad_norm 4.0001 (3.3873)	mem 5329MB
[2022-04-18 20:29:03 tiny] (main.py 226): INFO Train: [112/300][1000/1251]	eta 0:02:31 lr 0.000693	time 0.6621 (0.6018)	loss 4.8874 (4.0749)	grad_norm 4.4682 (3.4096)	mem 5329MB
[2022-04-18 20:30:01 tiny] (main.py 226): INFO Train: [112/300][1100/1251]	eta 0:01:30 lr 0.000693	time 0.6319 (0.6002)	loss 4.0832 (4.0675)	grad_norm 2.8832 (3.4084)	mem 5329MB
[2022-04-18 20:31:00 tiny] (main.py 226): INFO Train: [112/300][1200/1251]	eta 0:00:30 lr 0.000692	time 0.4852 (0.5989)	loss 4.2813 (4.0572)	grad_norm 1.8878 (3.3936)	mem 5329MB
[2022-04-18 20:31:22 tiny] (main.py 233): INFO EPOCH 112 training takes 0:12:21
[2022-04-18 20:31:34 tiny] (main.py 273): INFO Test: [0/49]	Time 12.701 (12.701)	Loss 1.7464 (1.7464)	Acc@1 66.016 (66.016)	Acc@5 86.035 (86.035)	Mem 5329MB
[2022-04-18 20:31:53 tiny] (main.py 279): INFO  * Acc@1 64.704 Acc@5 86.402
[2022-04-18 20:31:53 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 64.7%
[2022-04-18 20:31:53 tiny] (main.py 148): INFO Max accuracy: 64.96%
[2022-04-18 20:32:04 tiny] (main.py 226): INFO Train: [113/300][0/1251]	eta 3:54:10 lr 0.000692	time 11.2315 (11.2315)	loss 3.2868 (3.2868)	grad_norm 2.7161 (2.7161)	mem 5329MB
[2022-04-18 20:33:07 tiny] (main.py 226): INFO Train: [113/300][100/1251]	eta 0:13:59 lr 0.000692	time 0.6980 (0.7293)	loss 4.2161 (4.0048)	grad_norm 7.6469 (3.4491)	mem 5329MB
[2022-04-18 20:34:06 tiny] (main.py 226): INFO Train: [113/300][200/1251]	eta 0:11:32 lr 0.000691	time 0.4915 (0.6588)	loss 5.0397 (4.0415)	grad_norm 3.0885 (3.4241)	mem 5329MB
[2022-04-18 20:35:05 tiny] (main.py 226): INFO Train: [113/300][300/1251]	eta 0:10:04 lr 0.000691	time 0.7590 (0.6354)	loss 4.2827 (4.0489)	grad_norm 2.7769 (3.4261)	mem 5329MB
[2022-04-18 20:36:03 tiny] (main.py 226): INFO Train: [113/300][400/1251]	eta 0:08:49 lr 0.000690	time 0.6874 (0.6226)	loss 4.5846 (4.0795)	grad_norm 3.9415 (3.4434)	mem 5329MB
[2022-04-18 20:37:02 tiny] (main.py 226): INFO Train: [113/300][500/1251]	eta 0:07:42 lr 0.000690	time 0.8358 (0.6156)	loss 4.5961 (4.0770)	grad_norm 8.5912 (3.4353)	mem 5329MB
[2022-04-18 20:38:00 tiny] (main.py 226): INFO Train: [113/300][600/1251]	eta 0:06:37 lr 0.000690	time 0.6773 (0.6108)	loss 4.1464 (4.0681)	grad_norm 3.1820 (inf)	mem 5329MB
[2022-04-18 20:38:59 tiny] (main.py 226): INFO Train: [113/300][700/1251]	eta 0:05:34 lr 0.000689	time 0.4770 (0.6073)	loss 4.8314 (4.0577)	grad_norm 3.1322 (inf)	mem 5329MB
[2022-04-18 20:39:57 tiny] (main.py 226): INFO Train: [113/300][800/1251]	eta 0:04:32 lr 0.000689	time 0.5889 (0.6044)	loss 4.1630 (4.0630)	grad_norm 4.3614 (inf)	mem 5329MB
[2022-04-18 20:40:56 tiny] (main.py 226): INFO Train: [113/300][900/1251]	eta 0:03:31 lr 0.000689	time 0.4194 (0.6027)	loss 4.3859 (4.0554)	grad_norm 6.9735 (inf)	mem 5329MB
[2022-04-18 20:41:56 tiny] (main.py 226): INFO Train: [113/300][1000/1251]	eta 0:02:31 lr 0.000688	time 0.4946 (0.6017)	loss 4.0497 (4.0539)	grad_norm 3.6821 (inf)	mem 5329MB
[2022-04-18 20:42:54 tiny] (main.py 226): INFO Train: [113/300][1100/1251]	eta 0:01:30 lr 0.000688	time 0.6727 (0.6005)	loss 4.6128 (4.0538)	grad_norm 3.3157 (inf)	mem 5329MB
[2022-04-18 20:43:53 tiny] (main.py 226): INFO Train: [113/300][1200/1251]	eta 0:00:30 lr 0.000687	time 0.6044 (0.5995)	loss 4.0421 (4.0569)	grad_norm 2.2311 (inf)	mem 5329MB
[2022-04-18 20:44:15 tiny] (main.py 233): INFO EPOCH 113 training takes 0:12:21
[2022-04-18 20:44:27 tiny] (main.py 273): INFO Test: [0/49]	Time 11.960 (11.960)	Loss 1.6571 (1.6571)	Acc@1 65.625 (65.625)	Acc@5 87.695 (87.695)	Mem 5329MB
[2022-04-18 20:44:46 tiny] (main.py 279): INFO  * Acc@1 65.222 Acc@5 87.012
[2022-04-18 20:44:46 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 65.2%
[2022-04-18 20:44:46 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_113.pth saving......
[2022-04-18 20:44:46 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_113.pth saved !!!
[2022-04-18 20:44:46 tiny] (main.py 148): INFO Max accuracy: 65.22%
[2022-04-18 20:44:58 tiny] (main.py 226): INFO Train: [114/300][0/1251]	eta 3:56:40 lr 0.000687	time 11.3514 (11.3514)	loss 4.5511 (4.5511)	grad_norm 3.3330 (3.3330)	mem 5329MB
[2022-04-18 20:46:00 tiny] (main.py 226): INFO Train: [114/300][100/1251]	eta 0:14:04 lr 0.000687	time 0.7143 (0.7339)	loss 5.0252 (4.0239)	grad_norm 3.3940 (3.8302)	mem 5329MB
[2022-04-18 20:46:59 tiny] (main.py 226): INFO Train: [114/300][200/1251]	eta 0:11:33 lr 0.000686	time 0.5567 (0.6596)	loss 4.8318 (4.0735)	grad_norm 2.7671 (3.6554)	mem 5329MB
[2022-04-18 20:47:57 tiny] (main.py 226): INFO Train: [114/300][300/1251]	eta 0:10:02 lr 0.000686	time 0.4872 (0.6341)	loss 4.0905 (4.0707)	grad_norm 3.4130 (3.5714)	mem 5329MB
[2022-04-18 20:48:56 tiny] (main.py 226): INFO Train: [114/300][400/1251]	eta 0:08:49 lr 0.000686	time 0.5464 (0.6221)	loss 4.6437 (4.0751)	grad_norm 5.1219 (3.5991)	mem 5329MB
[2022-04-18 20:49:54 tiny] (main.py 226): INFO Train: [114/300][500/1251]	eta 0:07:41 lr 0.000685	time 0.5981 (0.6150)	loss 2.9146 (4.0607)	grad_norm 5.6644 (3.6063)	mem 5329MB
[2022-04-18 20:50:53 tiny] (main.py 226): INFO Train: [114/300][600/1251]	eta 0:06:37 lr 0.000685	time 0.6503 (0.6100)	loss 4.3083 (4.0427)	grad_norm 3.1902 (3.5979)	mem 5329MB
[2022-04-18 20:51:52 tiny] (main.py 226): INFO Train: [114/300][700/1251]	eta 0:05:34 lr 0.000685	time 0.7591 (0.6069)	loss 3.1664 (4.0601)	grad_norm 4.2776 (3.5674)	mem 5329MB
[2022-04-18 20:52:50 tiny] (main.py 226): INFO Train: [114/300][800/1251]	eta 0:04:32 lr 0.000684	time 0.4022 (0.6045)	loss 4.9398 (4.0606)	grad_norm 3.6779 (3.5568)	mem 5329MB
[2022-04-18 20:53:49 tiny] (main.py 226): INFO Train: [114/300][900/1251]	eta 0:03:31 lr 0.000684	time 0.6421 (0.6028)	loss 4.1199 (4.0668)	grad_norm 3.8998 (3.5710)	mem 5329MB
[2022-04-18 20:54:48 tiny] (main.py 226): INFO Train: [114/300][1000/1251]	eta 0:02:30 lr 0.000683	time 0.5714 (0.6014)	loss 3.9042 (4.0632)	grad_norm 3.1052 (3.5800)	mem 5329MB
[2022-04-18 20:55:47 tiny] (main.py 226): INFO Train: [114/300][1100/1251]	eta 0:01:30 lr 0.000683	time 0.7473 (0.6002)	loss 4.2837 (4.0559)	grad_norm 2.5968 (3.5549)	mem 5329MB
[2022-04-18 20:56:46 tiny] (main.py 226): INFO Train: [114/300][1200/1251]	eta 0:00:30 lr 0.000683	time 0.6435 (0.5994)	loss 4.5565 (4.0582)	grad_norm 5.8221 (3.5632)	mem 5329MB
[2022-04-18 20:57:08 tiny] (main.py 233): INFO EPOCH 114 training takes 0:12:21
[2022-04-18 20:57:19 tiny] (main.py 273): INFO Test: [0/49]	Time 11.129 (11.129)	Loss 1.7917 (1.7917)	Acc@1 64.258 (64.258)	Acc@5 85.742 (85.742)	Mem 5329MB
[2022-04-18 20:57:39 tiny] (main.py 279): INFO  * Acc@1 64.768 Acc@5 86.680
[2022-04-18 20:57:39 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 64.8%
[2022-04-18 20:57:39 tiny] (main.py 148): INFO Max accuracy: 65.22%
[2022-04-18 20:57:50 tiny] (main.py 226): INFO Train: [115/300][0/1251]	eta 3:52:30 lr 0.000682	time 11.1517 (11.1517)	loss 5.0885 (5.0885)	grad_norm 3.2248 (3.2248)	mem 5329MB
[2022-04-18 20:58:52 tiny] (main.py 226): INFO Train: [115/300][100/1251]	eta 0:13:59 lr 0.000682	time 0.7656 (0.7294)	loss 2.8794 (4.0367)	grad_norm 2.8643 (3.7011)	mem 5329MB
[2022-04-18 20:59:51 tiny] (main.py 226): INFO Train: [115/300][200/1251]	eta 0:11:31 lr 0.000682	time 0.6572 (0.6581)	loss 4.4647 (4.0281)	grad_norm 2.1218 (3.5311)	mem 5329MB
[2022-04-18 21:00:49 tiny] (main.py 226): INFO Train: [115/300][300/1251]	eta 0:10:01 lr 0.000681	time 0.5841 (0.6327)	loss 4.6396 (4.0583)	grad_norm 2.9133 (3.4741)	mem 5329MB
[2022-04-18 21:01:48 tiny] (main.py 226): INFO Train: [115/300][400/1251]	eta 0:08:48 lr 0.000681	time 0.6574 (0.6215)	loss 2.9182 (4.0505)	grad_norm 4.8004 (inf)	mem 5329MB
[2022-04-18 21:02:47 tiny] (main.py 226): INFO Train: [115/300][500/1251]	eta 0:07:41 lr 0.000680	time 0.7419 (0.6146)	loss 2.8255 (4.0381)	grad_norm 4.8356 (inf)	mem 5329MB
[2022-04-18 21:03:45 tiny] (main.py 226): INFO Train: [115/300][600/1251]	eta 0:06:37 lr 0.000680	time 0.6438 (0.6101)	loss 4.3804 (4.0369)	grad_norm 3.4074 (inf)	mem 5329MB
[2022-04-18 21:04:44 tiny] (main.py 226): INFO Train: [115/300][700/1251]	eta 0:05:34 lr 0.000680	time 0.6021 (0.6068)	loss 4.1340 (4.0422)	grad_norm 2.3599 (inf)	mem 5329MB
[2022-04-18 21:05:43 tiny] (main.py 226): INFO Train: [115/300][800/1251]	eta 0:04:32 lr 0.000679	time 0.6859 (0.6046)	loss 4.9774 (4.0508)	grad_norm 2.9789 (inf)	mem 5329MB
[2022-04-18 21:06:42 tiny] (main.py 226): INFO Train: [115/300][900/1251]	eta 0:03:31 lr 0.000679	time 0.6802 (0.6030)	loss 4.6899 (4.0383)	grad_norm 3.6128 (inf)	mem 5329MB
[2022-04-18 21:07:41 tiny] (main.py 226): INFO Train: [115/300][1000/1251]	eta 0:02:30 lr 0.000679	time 0.5028 (0.6014)	loss 3.9190 (4.0381)	grad_norm 4.8155 (inf)	mem 5329MB
[2022-04-18 21:08:40 tiny] (main.py 226): INFO Train: [115/300][1100/1251]	eta 0:01:30 lr 0.000678	time 0.4920 (0.6003)	loss 3.5622 (4.0358)	grad_norm 2.5487 (inf)	mem 5329MB
[2022-04-18 21:09:39 tiny] (main.py 226): INFO Train: [115/300][1200/1251]	eta 0:00:30 lr 0.000678	time 0.4856 (0.5993)	loss 3.5797 (4.0316)	grad_norm 2.8108 (inf)	mem 5329MB
[2022-04-18 21:10:00 tiny] (main.py 233): INFO EPOCH 115 training takes 0:12:21
[2022-04-18 21:10:13 tiny] (main.py 273): INFO Test: [0/49]	Time 12.730 (12.730)	Loss 1.7595 (1.7595)	Acc@1 64.062 (64.062)	Acc@5 86.035 (86.035)	Mem 5329MB
[2022-04-18 21:10:31 tiny] (main.py 279): INFO  * Acc@1 64.892 Acc@5 86.426
[2022-04-18 21:10:31 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 64.9%
[2022-04-18 21:10:31 tiny] (main.py 148): INFO Max accuracy: 65.22%
[2022-04-18 21:10:42 tiny] (main.py 226): INFO Train: [116/300][0/1251]	eta 3:41:53 lr 0.000678	time 10.6424 (10.6424)	loss 4.0211 (4.0211)	grad_norm 6.9236 (6.9236)	mem 5329MB
[2022-04-18 21:11:45 tiny] (main.py 226): INFO Train: [116/300][100/1251]	eta 0:13:59 lr 0.000677	time 0.7536 (0.7295)	loss 4.5033 (4.0875)	grad_norm 4.4917 (3.5742)	mem 5329MB
[2022-04-18 21:12:43 tiny] (main.py 226): INFO Train: [116/300][200/1251]	eta 0:11:30 lr 0.000677	time 0.7305 (0.6573)	loss 3.9251 (4.0626)	grad_norm 2.1738 (3.5458)	mem 5329MB
[2022-04-18 21:13:42 tiny] (main.py 226): INFO Train: [116/300][300/1251]	eta 0:10:01 lr 0.000676	time 0.5861 (0.6321)	loss 4.1544 (4.0533)	grad_norm 6.1890 (3.4550)	mem 5329MB
[2022-04-18 21:14:40 tiny] (main.py 226): INFO Train: [116/300][400/1251]	eta 0:08:48 lr 0.000676	time 0.5517 (0.6207)	loss 3.3468 (4.0625)	grad_norm 3.1733 (3.4535)	mem 5329MB
[2022-04-18 21:15:39 tiny] (main.py 226): INFO Train: [116/300][500/1251]	eta 0:07:41 lr 0.000676	time 0.4851 (0.6140)	loss 3.8849 (4.0692)	grad_norm 3.4226 (3.4396)	mem 5329MB
[2022-04-18 21:16:38 tiny] (main.py 226): INFO Train: [116/300][600/1251]	eta 0:06:37 lr 0.000675	time 0.4811 (0.6099)	loss 4.1853 (4.0689)	grad_norm 3.5098 (3.4497)	mem 5329MB
[2022-04-18 21:17:37 tiny] (main.py 226): INFO Train: [116/300][700/1251]	eta 0:05:34 lr 0.000675	time 0.5287 (0.6067)	loss 3.6612 (4.0646)	grad_norm 4.6629 (3.4507)	mem 5329MB
[2022-04-18 21:18:35 tiny] (main.py 226): INFO Train: [116/300][800/1251]	eta 0:04:32 lr 0.000674	time 0.5318 (0.6037)	loss 4.4568 (4.0650)	grad_norm 2.5504 (3.4573)	mem 5329MB
[2022-04-18 21:19:33 tiny] (main.py 226): INFO Train: [116/300][900/1251]	eta 0:03:31 lr 0.000674	time 0.5172 (0.6017)	loss 4.4689 (4.0680)	grad_norm 2.1928 (3.4271)	mem 5329MB
[2022-04-18 21:20:32 tiny] (main.py 226): INFO Train: [116/300][1000/1251]	eta 0:02:30 lr 0.000674	time 0.6792 (0.6006)	loss 3.8249 (4.0707)	grad_norm 2.4956 (3.4457)	mem 5329MB
[2022-04-18 21:21:31 tiny] (main.py 226): INFO Train: [116/300][1100/1251]	eta 0:01:30 lr 0.000673	time 0.7138 (0.5993)	loss 4.3442 (4.0744)	grad_norm 4.2391 (3.4320)	mem 5329MB
[2022-04-18 21:22:30 tiny] (main.py 226): INFO Train: [116/300][1200/1251]	eta 0:00:30 lr 0.000673	time 0.4976 (0.5985)	loss 4.2613 (4.0676)	grad_norm 3.8244 (inf)	mem 5329MB
[2022-04-18 21:22:52 tiny] (main.py 233): INFO EPOCH 116 training takes 0:12:20
[2022-04-18 21:23:03 tiny] (main.py 273): INFO Test: [0/49]	Time 11.051 (11.051)	Loss 1.7739 (1.7739)	Acc@1 61.719 (61.719)	Acc@5 84.961 (84.961)	Mem 5329MB
[2022-04-18 21:23:23 tiny] (main.py 279): INFO  * Acc@1 64.668 Acc@5 86.372
[2022-04-18 21:23:23 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 64.7%
[2022-04-18 21:23:23 tiny] (main.py 148): INFO Max accuracy: 65.22%
[2022-04-18 21:23:34 tiny] (main.py 226): INFO Train: [117/300][0/1251]	eta 3:49:34 lr 0.000673	time 11.0109 (11.0109)	loss 4.2237 (4.2237)	grad_norm 3.3130 (3.3130)	mem 5329MB
[2022-04-18 21:24:36 tiny] (main.py 226): INFO Train: [117/300][100/1251]	eta 0:13:58 lr 0.000672	time 0.6930 (0.7285)	loss 4.8899 (4.0996)	grad_norm 3.3097 (3.6153)	mem 5329MB
[2022-04-18 21:25:36 tiny] (main.py 226): INFO Train: [117/300][200/1251]	eta 0:11:33 lr 0.000672	time 0.6556 (0.6597)	loss 3.8235 (4.0923)	grad_norm 4.0753 (3.6392)	mem 5329MB
[2022-04-18 21:26:34 tiny] (main.py 226): INFO Train: [117/300][300/1251]	eta 0:10:03 lr 0.000672	time 0.6015 (0.6342)	loss 2.9029 (4.0514)	grad_norm 2.6144 (3.5987)	mem 5329MB
[2022-04-18 21:27:32 tiny] (main.py 226): INFO Train: [117/300][400/1251]	eta 0:08:49 lr 0.000671	time 0.5766 (0.6219)	loss 2.9614 (4.0513)	grad_norm 3.3808 (3.5263)	mem 5329MB
[2022-04-18 21:28:31 tiny] (main.py 226): INFO Train: [117/300][500/1251]	eta 0:07:42 lr 0.000671	time 0.7104 (0.6154)	loss 4.0328 (4.0741)	grad_norm 3.7484 (3.5351)	mem 5329MB
[2022-04-18 21:29:30 tiny] (main.py 226): INFO Train: [117/300][600/1251]	eta 0:06:37 lr 0.000670	time 0.4291 (0.6105)	loss 3.9194 (4.0701)	grad_norm 2.1314 (3.5422)	mem 5329MB
[2022-04-18 21:30:29 tiny] (main.py 226): INFO Train: [117/300][700/1251]	eta 0:05:34 lr 0.000670	time 0.6617 (0.6076)	loss 4.1032 (4.0577)	grad_norm 4.7036 (3.5446)	mem 5329MB
[2022-04-18 21:31:28 tiny] (main.py 226): INFO Train: [117/300][800/1251]	eta 0:04:32 lr 0.000670	time 0.6453 (0.6051)	loss 4.3908 (4.0610)	grad_norm 2.2684 (3.5308)	mem 5329MB
[2022-04-18 21:32:27 tiny] (main.py 226): INFO Train: [117/300][900/1251]	eta 0:03:31 lr 0.000669	time 0.7200 (0.6034)	loss 4.6400 (4.0595)	grad_norm 5.3197 (3.5531)	mem 5329MB
[2022-04-18 21:33:25 tiny] (main.py 226): INFO Train: [117/300][1000/1251]	eta 0:02:31 lr 0.000669	time 0.4553 (0.6018)	loss 3.3583 (4.0621)	grad_norm 4.8634 (3.5531)	mem 5329MB
[2022-04-18 21:34:24 tiny] (main.py 226): INFO Train: [117/300][1100/1251]	eta 0:01:30 lr 0.000668	time 0.7436 (0.6007)	loss 4.7666 (4.0616)	grad_norm 2.6264 (3.5295)	mem 5329MB
[2022-04-18 21:35:23 tiny] (main.py 226): INFO Train: [117/300][1200/1251]	eta 0:00:30 lr 0.000668	time 0.5144 (0.5993)	loss 4.2632 (4.0614)	grad_norm 4.6481 (3.5259)	mem 5329MB
[2022-04-18 21:35:45 tiny] (main.py 233): INFO EPOCH 117 training takes 0:12:21
[2022-04-18 21:35:57 tiny] (main.py 273): INFO Test: [0/49]	Time 12.264 (12.264)	Loss 1.7478 (1.7478)	Acc@1 67.773 (67.773)	Acc@5 87.500 (87.500)	Mem 5329MB
[2022-04-18 21:36:16 tiny] (main.py 279): INFO  * Acc@1 65.246 Acc@5 86.690
[2022-04-18 21:36:16 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 65.2%
[2022-04-18 21:36:16 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_117.pth saving......
[2022-04-18 21:36:16 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_117.pth saved !!!
[2022-04-18 21:36:16 tiny] (main.py 148): INFO Max accuracy: 65.25%
[2022-04-18 21:36:28 tiny] (main.py 226): INFO Train: [118/300][0/1251]	eta 4:10:40 lr 0.000668	time 12.0225 (12.0225)	loss 3.0265 (3.0265)	grad_norm 2.6539 (2.6539)	mem 5329MB
[2022-04-18 21:37:30 tiny] (main.py 226): INFO Train: [118/300][100/1251]	eta 0:14:03 lr 0.000667	time 0.6304 (0.7329)	loss 4.1700 (4.0475)	grad_norm 3.6385 (3.4832)	mem 5329MB
[2022-04-18 21:38:28 tiny] (main.py 226): INFO Train: [118/300][200/1251]	eta 0:11:30 lr 0.000667	time 0.6003 (0.6567)	loss 3.2589 (4.0839)	grad_norm 3.2191 (3.5115)	mem 5329MB
[2022-04-18 21:39:27 tiny] (main.py 226): INFO Train: [118/300][300/1251]	eta 0:10:02 lr 0.000667	time 0.5570 (0.6334)	loss 3.8567 (4.0331)	grad_norm 2.6833 (3.5001)	mem 5329MB
[2022-04-18 21:40:25 tiny] (main.py 226): INFO Train: [118/300][400/1251]	eta 0:08:48 lr 0.000666	time 0.5931 (0.6216)	loss 3.6507 (4.0457)	grad_norm 2.1223 (3.4813)	mem 5329MB
[2022-04-18 21:41:24 tiny] (main.py 226): INFO Train: [118/300][500/1251]	eta 0:07:41 lr 0.000666	time 0.6043 (0.6149)	loss 3.7773 (4.0469)	grad_norm 4.1552 (3.4928)	mem 5329MB
[2022-04-18 21:42:23 tiny] (main.py 226): INFO Train: [118/300][600/1251]	eta 0:06:37 lr 0.000665	time 0.8468 (0.6106)	loss 4.7574 (4.0608)	grad_norm 3.5281 (3.5066)	mem 5329MB
[2022-04-18 21:43:21 tiny] (main.py 226): INFO Train: [118/300][700/1251]	eta 0:05:34 lr 0.000665	time 0.4640 (0.6065)	loss 4.1038 (4.0588)	grad_norm 4.0567 (3.4945)	mem 5329MB
[2022-04-18 21:44:20 tiny] (main.py 226): INFO Train: [118/300][800/1251]	eta 0:04:32 lr 0.000665	time 0.4879 (0.6043)	loss 4.3840 (4.0638)	grad_norm 2.1285 (3.5206)	mem 5329MB
[2022-04-18 21:45:20 tiny] (main.py 226): INFO Train: [118/300][900/1251]	eta 0:03:31 lr 0.000664	time 0.7604 (0.6034)	loss 4.3341 (4.0578)	grad_norm 6.5483 (inf)	mem 5329MB
[2022-04-18 21:46:19 tiny] (main.py 226): INFO Train: [118/300][1000/1251]	eta 0:02:31 lr 0.000664	time 0.6237 (0.6020)	loss 4.5403 (4.0562)	grad_norm 2.5416 (inf)	mem 5329MB
[2022-04-18 21:47:17 tiny] (main.py 226): INFO Train: [118/300][1100/1251]	eta 0:01:30 lr 0.000663	time 0.5503 (0.6005)	loss 3.7326 (4.0546)	grad_norm 4.3600 (inf)	mem 5329MB
[2022-04-18 21:48:16 tiny] (main.py 226): INFO Train: [118/300][1200/1251]	eta 0:00:30 lr 0.000663	time 0.5200 (0.5993)	loss 4.5278 (4.0605)	grad_norm 3.3054 (inf)	mem 5329MB
[2022-04-18 21:48:38 tiny] (main.py 233): INFO EPOCH 118 training takes 0:12:22
[2022-04-18 21:48:49 tiny] (main.py 273): INFO Test: [0/49]	Time 11.249 (11.249)	Loss 1.8775 (1.8775)	Acc@1 61.230 (61.230)	Acc@5 84.277 (84.277)	Mem 5329MB
[2022-04-18 21:49:09 tiny] (main.py 279): INFO  * Acc@1 65.018 Acc@5 86.642
[2022-04-18 21:49:09 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 65.0%
[2022-04-18 21:49:09 tiny] (main.py 148): INFO Max accuracy: 65.25%
[2022-04-18 21:49:21 tiny] (main.py 226): INFO Train: [119/300][0/1251]	eta 3:57:38 lr 0.000663	time 11.3974 (11.3974)	loss 4.4744 (4.4744)	grad_norm 2.2324 (2.2324)	mem 5329MB
[2022-04-18 21:50:23 tiny] (main.py 226): INFO Train: [119/300][100/1251]	eta 0:13:57 lr 0.000662	time 0.5105 (0.7274)	loss 4.1405 (3.9582)	grad_norm 4.3961 (3.2976)	mem 5329MB
[2022-04-18 21:51:22 tiny] (main.py 226): INFO Train: [119/300][200/1251]	eta 0:11:31 lr 0.000662	time 0.6461 (0.6583)	loss 4.7166 (3.9899)	grad_norm 3.5930 (3.3451)	mem 5329MB
[2022-04-18 21:52:20 tiny] (main.py 226): INFO Train: [119/300][300/1251]	eta 0:10:02 lr 0.000662	time 0.6532 (0.6336)	loss 3.8647 (3.9952)	grad_norm 3.2090 (3.3333)	mem 5329MB
[2022-04-18 21:53:19 tiny] (main.py 226): INFO Train: [119/300][400/1251]	eta 0:08:49 lr 0.000661	time 0.5515 (0.6223)	loss 3.4987 (4.0076)	grad_norm 2.7322 (3.3515)	mem 5329MB
[2022-04-18 21:54:17 tiny] (main.py 226): INFO Train: [119/300][500/1251]	eta 0:07:41 lr 0.000661	time 0.4637 (0.6145)	loss 3.6699 (4.0116)	grad_norm 3.0593 (3.3292)	mem 5329MB
[2022-04-18 21:55:16 tiny] (main.py 226): INFO Train: [119/300][600/1251]	eta 0:06:37 lr 0.000661	time 0.6744 (0.6103)	loss 3.2959 (4.0231)	grad_norm 3.9799 (3.3640)	mem 5329MB
[2022-04-18 21:56:15 tiny] (main.py 226): INFO Train: [119/300][700/1251]	eta 0:05:34 lr 0.000660	time 0.5209 (0.6067)	loss 2.8528 (4.0372)	grad_norm 2.8934 (3.4065)	mem 5329MB
[2022-04-18 21:57:13 tiny] (main.py 226): INFO Train: [119/300][800/1251]	eta 0:04:32 lr 0.000660	time 0.4064 (0.6044)	loss 4.2694 (4.0297)	grad_norm 2.4450 (3.3858)	mem 5329MB
[2022-04-18 21:58:12 tiny] (main.py 226): INFO Train: [119/300][900/1251]	eta 0:03:31 lr 0.000659	time 0.5492 (0.6026)	loss 3.1172 (4.0358)	grad_norm 2.4535 (3.4511)	mem 5329MB
[2022-04-18 21:59:11 tiny] (main.py 226): INFO Train: [119/300][1000/1251]	eta 0:02:30 lr 0.000659	time 0.4492 (0.6009)	loss 4.2182 (4.0378)	grad_norm 4.9961 (3.4335)	mem 5329MB
[2022-04-18 22:00:10 tiny] (main.py 226): INFO Train: [119/300][1100/1251]	eta 0:01:30 lr 0.000659	time 0.8486 (0.6003)	loss 4.4640 (4.0471)	grad_norm 3.8439 (3.4417)	mem 5329MB
[2022-04-18 22:01:08 tiny] (main.py 226): INFO Train: [119/300][1200/1251]	eta 0:00:30 lr 0.000658	time 0.5052 (0.5988)	loss 5.0986 (4.0538)	grad_norm 4.2475 (3.4753)	mem 5329MB
[2022-04-18 22:01:30 tiny] (main.py 233): INFO EPOCH 119 training takes 0:12:21
[2022-04-18 22:01:42 tiny] (main.py 273): INFO Test: [0/49]	Time 11.934 (11.934)	Loss 1.6175 (1.6175)	Acc@1 67.969 (67.969)	Acc@5 87.891 (87.891)	Mem 5329MB
[2022-04-18 22:02:02 tiny] (main.py 279): INFO  * Acc@1 65.746 Acc@5 87.230
[2022-04-18 22:02:02 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 65.7%
[2022-04-18 22:02:02 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_119.pth saving......
[2022-04-18 22:02:02 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_119.pth saved !!!
[2022-04-18 22:02:02 tiny] (main.py 148): INFO Max accuracy: 65.75%
[2022-04-18 22:02:14 tiny] (main.py 226): INFO Train: [120/300][0/1251]	eta 3:59:09 lr 0.000658	time 11.4702 (11.4702)	loss 3.5740 (3.5740)	grad_norm 2.7443 (2.7443)	mem 5329MB
[2022-04-18 22:03:15 tiny] (main.py 226): INFO Train: [120/300][100/1251]	eta 0:13:55 lr 0.000658	time 0.5353 (0.7258)	loss 4.4177 (4.0290)	grad_norm 3.0891 (3.4253)	mem 5329MB
[2022-04-18 22:04:14 tiny] (main.py 226): INFO Train: [120/300][200/1251]	eta 0:11:31 lr 0.000657	time 0.4780 (0.6580)	loss 4.2244 (4.0344)	grad_norm 3.7307 (3.5583)	mem 5329MB
[2022-04-18 22:05:12 tiny] (main.py 226): INFO Train: [120/300][300/1251]	eta 0:10:01 lr 0.000657	time 0.5268 (0.6328)	loss 3.1274 (4.0576)	grad_norm 2.2634 (3.5388)	mem 5329MB
[2022-04-18 22:06:11 tiny] (main.py 226): INFO Train: [120/300][400/1251]	eta 0:08:48 lr 0.000656	time 0.4578 (0.6205)	loss 2.8021 (4.0716)	grad_norm 5.0115 (3.6091)	mem 5329MB
[2022-04-18 22:07:10 tiny] (main.py 226): INFO Train: [120/300][500/1251]	eta 0:07:41 lr 0.000656	time 0.6409 (0.6142)	loss 3.8600 (4.0721)	grad_norm 5.5450 (3.5608)	mem 5329MB
[2022-04-18 22:08:08 tiny] (main.py 226): INFO Train: [120/300][600/1251]	eta 0:06:36 lr 0.000656	time 0.5991 (0.6094)	loss 4.0420 (4.0734)	grad_norm 2.6610 (3.5648)	mem 5329MB
[2022-04-18 22:09:08 tiny] (main.py 226): INFO Train: [120/300][700/1251]	eta 0:05:34 lr 0.000655	time 0.6880 (0.6070)	loss 3.0491 (4.0687)	grad_norm 6.0577 (inf)	mem 5329MB
[2022-04-18 22:10:06 tiny] (main.py 226): INFO Train: [120/300][800/1251]	eta 0:04:32 lr 0.000655	time 0.5388 (0.6045)	loss 3.7506 (4.0645)	grad_norm 2.6072 (inf)	mem 5329MB
[2022-04-18 22:11:05 tiny] (main.py 226): INFO Train: [120/300][900/1251]	eta 0:03:31 lr 0.000654	time 0.6011 (0.6028)	loss 3.9188 (4.0707)	grad_norm 2.4388 (inf)	mem 5329MB
[2022-04-18 22:12:04 tiny] (main.py 226): INFO Train: [120/300][1000/1251]	eta 0:02:30 lr 0.000654	time 0.5252 (0.6011)	loss 3.5287 (4.0739)	grad_norm 2.6289 (inf)	mem 5329MB
[2022-04-18 22:13:02 tiny] (main.py 226): INFO Train: [120/300][1100/1251]	eta 0:01:30 lr 0.000654	time 0.7522 (0.5995)	loss 4.5516 (4.0713)	grad_norm 3.2627 (inf)	mem 5329MB
[2022-04-18 22:14:01 tiny] (main.py 226): INFO Train: [120/300][1200/1251]	eta 0:00:30 lr 0.000653	time 0.7779 (0.5990)	loss 4.8522 (4.0671)	grad_norm 2.4983 (inf)	mem 5329MB
[2022-04-18 22:14:23 tiny] (main.py 233): INFO EPOCH 120 training takes 0:12:20
[2022-04-18 22:14:34 tiny] (main.py 273): INFO Test: [0/49]	Time 11.427 (11.427)	Loss 1.7809 (1.7809)	Acc@1 62.402 (62.402)	Acc@5 85.938 (85.938)	Mem 5329MB
[2022-04-18 22:14:54 tiny] (main.py 279): INFO  * Acc@1 65.024 Acc@5 86.872
[2022-04-18 22:14:54 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 65.0%
[2022-04-18 22:14:54 tiny] (main.py 148): INFO Max accuracy: 65.75%
[2022-04-18 22:15:06 tiny] (main.py 226): INFO Train: [121/300][0/1251]	eta 4:14:57 lr 0.000653	time 12.2283 (12.2283)	loss 3.5335 (3.5335)	grad_norm 2.5394 (2.5394)	mem 5329MB
[2022-04-18 22:16:08 tiny] (main.py 226): INFO Train: [121/300][100/1251]	eta 0:13:59 lr 0.000653	time 0.4334 (0.7298)	loss 3.8376 (4.0143)	grad_norm 2.4664 (3.4500)	mem 5329MB
[2022-04-18 22:17:06 tiny] (main.py 226): INFO Train: [121/300][200/1251]	eta 0:11:31 lr 0.000652	time 0.4028 (0.6577)	loss 3.8356 (3.9806)	grad_norm 3.6724 (3.4321)	mem 5329MB
[2022-04-18 22:18:05 tiny] (main.py 226): INFO Train: [121/300][300/1251]	eta 0:10:03 lr 0.000652	time 0.5488 (0.6348)	loss 3.8312 (3.9977)	grad_norm 1.9108 (3.5384)	mem 5329MB
[2022-04-18 22:19:04 tiny] (main.py 226): INFO Train: [121/300][400/1251]	eta 0:08:49 lr 0.000651	time 0.5815 (0.6225)	loss 3.8104 (4.0111)	grad_norm 3.4188 (3.5420)	mem 5329MB
[2022-04-18 22:20:02 tiny] (main.py 226): INFO Train: [121/300][500/1251]	eta 0:07:41 lr 0.000651	time 0.5642 (0.6151)	loss 4.4771 (4.0384)	grad_norm 2.1253 (3.5709)	mem 5329MB
[2022-04-18 22:21:01 tiny] (main.py 226): INFO Train: [121/300][600/1251]	eta 0:06:37 lr 0.000651	time 0.5494 (0.6107)	loss 3.5484 (4.0349)	grad_norm 3.3592 (3.5712)	mem 5329MB
[2022-04-18 22:22:00 tiny] (main.py 226): INFO Train: [121/300][700/1251]	eta 0:05:34 lr 0.000650	time 0.4738 (0.6072)	loss 4.3765 (4.0402)	grad_norm 2.4372 (3.6241)	mem 5329MB
[2022-04-18 22:22:59 tiny] (main.py 226): INFO Train: [121/300][800/1251]	eta 0:04:32 lr 0.000650	time 0.6608 (0.6053)	loss 3.6092 (4.0494)	grad_norm 3.3579 (3.6242)	mem 5329MB
[2022-04-18 22:23:58 tiny] (main.py 226): INFO Train: [121/300][900/1251]	eta 0:03:31 lr 0.000649	time 0.5008 (0.6036)	loss 4.5868 (4.0471)	grad_norm 7.6357 (3.6100)	mem 5329MB
[2022-04-18 22:24:56 tiny] (main.py 226): INFO Train: [121/300][1000/1251]	eta 0:02:31 lr 0.000649	time 0.5828 (0.6017)	loss 3.8222 (4.0487)	grad_norm 3.0032 (3.6253)	mem 5329MB
[2022-04-18 22:25:55 tiny] (main.py 226): INFO Train: [121/300][1100/1251]	eta 0:01:30 lr 0.000649	time 0.6612 (0.6005)	loss 3.7307 (4.0493)	grad_norm 4.5103 (3.6243)	mem 5329MB
[2022-04-18 22:26:54 tiny] (main.py 226): INFO Train: [121/300][1200/1251]	eta 0:00:30 lr 0.000648	time 0.5136 (0.5992)	loss 2.9918 (4.0413)	grad_norm 4.2065 (3.6330)	mem 5329MB
[2022-04-18 22:27:16 tiny] (main.py 233): INFO EPOCH 121 training takes 0:12:21
[2022-04-18 22:27:28 tiny] (main.py 273): INFO Test: [0/49]	Time 12.483 (12.483)	Loss 1.7650 (1.7650)	Acc@1 64.941 (64.941)	Acc@5 86.816 (86.816)	Mem 5329MB
[2022-04-18 22:27:47 tiny] (main.py 279): INFO  * Acc@1 65.164 Acc@5 86.968
[2022-04-18 22:27:47 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 65.2%
[2022-04-18 22:27:47 tiny] (main.py 148): INFO Max accuracy: 65.75%
[2022-04-18 22:27:59 tiny] (main.py 226): INFO Train: [122/300][0/1251]	eta 4:16:01 lr 0.000648	time 12.2793 (12.2793)	loss 4.2997 (4.2997)	grad_norm 3.6089 (3.6089)	mem 5329MB
[2022-04-18 22:29:01 tiny] (main.py 226): INFO Train: [122/300][100/1251]	eta 0:14:02 lr 0.000648	time 0.6839 (0.7319)	loss 2.8760 (3.9372)	grad_norm 2.2705 (3.7829)	mem 5329MB
[2022-04-18 22:29:59 tiny] (main.py 226): INFO Train: [122/300][200/1251]	eta 0:11:31 lr 0.000647	time 0.6128 (0.6576)	loss 3.6421 (3.9576)	grad_norm 2.4357 (3.6589)	mem 5329MB
[2022-04-18 22:30:58 tiny] (main.py 226): INFO Train: [122/300][300/1251]	eta 0:10:03 lr 0.000647	time 0.5593 (0.6343)	loss 3.7721 (3.9830)	grad_norm 2.5648 (3.6206)	mem 5329MB
[2022-04-18 22:31:56 tiny] (main.py 226): INFO Train: [122/300][400/1251]	eta 0:08:49 lr 0.000646	time 0.8445 (0.6216)	loss 4.5724 (3.9831)	grad_norm 3.6845 (inf)	mem 5329MB
[2022-04-18 22:32:55 tiny] (main.py 226): INFO Train: [122/300][500/1251]	eta 0:07:41 lr 0.000646	time 0.7441 (0.6143)	loss 4.4232 (3.9875)	grad_norm 3.2643 (inf)	mem 5329MB
[2022-04-18 22:33:54 tiny] (main.py 226): INFO Train: [122/300][600/1251]	eta 0:06:37 lr 0.000646	time 0.5584 (0.6101)	loss 3.1079 (3.9824)	grad_norm 2.8431 (inf)	mem 5329MB
[2022-04-18 22:34:52 tiny] (main.py 226): INFO Train: [122/300][700/1251]	eta 0:05:34 lr 0.000645	time 0.5598 (0.6065)	loss 4.2723 (4.0062)	grad_norm 2.0219 (inf)	mem 5329MB
[2022-04-18 22:35:51 tiny] (main.py 226): INFO Train: [122/300][800/1251]	eta 0:04:32 lr 0.000645	time 0.4997 (0.6045)	loss 4.1509 (4.0206)	grad_norm 3.5581 (inf)	mem 5329MB
[2022-04-18 22:36:50 tiny] (main.py 226): INFO Train: [122/300][900/1251]	eta 0:03:31 lr 0.000644	time 0.4510 (0.6030)	loss 4.4268 (4.0286)	grad_norm 2.3417 (inf)	mem 5329MB
[2022-04-18 22:37:49 tiny] (main.py 226): INFO Train: [122/300][1000/1251]	eta 0:02:31 lr 0.000644	time 0.6539 (0.6020)	loss 4.3058 (4.0258)	grad_norm 2.1270 (inf)	mem 5329MB
[2022-04-18 22:38:48 tiny] (main.py 226): INFO Train: [122/300][1100/1251]	eta 0:01:30 lr 0.000644	time 0.8363 (0.6005)	loss 3.8009 (4.0247)	grad_norm 6.4888 (inf)	mem 5329MB
[2022-04-18 22:39:47 tiny] (main.py 226): INFO Train: [122/300][1200/1251]	eta 0:00:30 lr 0.000643	time 0.6520 (0.5992)	loss 4.7286 (4.0292)	grad_norm 3.3572 (inf)	mem 5329MB
[2022-04-18 22:40:09 tiny] (main.py 233): INFO EPOCH 122 training takes 0:12:21
[2022-04-18 22:40:21 tiny] (main.py 273): INFO Test: [0/49]	Time 12.265 (12.265)	Loss 1.7707 (1.7707)	Acc@1 66.211 (66.211)	Acc@5 85.059 (85.059)	Mem 5329MB
[2022-04-18 22:40:40 tiny] (main.py 279): INFO  * Acc@1 65.574 Acc@5 87.124
[2022-04-18 22:40:40 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 65.6%
[2022-04-18 22:40:40 tiny] (main.py 148): INFO Max accuracy: 65.75%
[2022-04-18 22:40:52 tiny] (main.py 226): INFO Train: [123/300][0/1251]	eta 4:15:49 lr 0.000643	time 12.2695 (12.2695)	loss 4.2587 (4.2587)	grad_norm 3.8885 (3.8885)	mem 5329MB
[2022-04-18 22:41:54 tiny] (main.py 226): INFO Train: [123/300][100/1251]	eta 0:14:01 lr 0.000643	time 0.5864 (0.7310)	loss 4.0956 (3.9701)	grad_norm 2.9571 (3.8174)	mem 5329MB
[2022-04-18 22:42:52 tiny] (main.py 226): INFO Train: [123/300][200/1251]	eta 0:11:31 lr 0.000642	time 0.6125 (0.6582)	loss 4.1071 (4.0533)	grad_norm 5.1626 (3.6300)	mem 5329MB
[2022-04-18 22:43:51 tiny] (main.py 226): INFO Train: [123/300][300/1251]	eta 0:10:03 lr 0.000642	time 0.5453 (0.6350)	loss 4.2347 (4.0096)	grad_norm 5.8156 (3.7111)	mem 5329MB
[2022-04-18 22:44:49 tiny] (main.py 226): INFO Train: [123/300][400/1251]	eta 0:08:49 lr 0.000642	time 0.6860 (0.6218)	loss 4.5686 (4.0365)	grad_norm 3.3105 (3.6529)	mem 5329MB
[2022-04-18 22:45:48 tiny] (main.py 226): INFO Train: [123/300][500/1251]	eta 0:07:41 lr 0.000641	time 0.4292 (0.6150)	loss 4.4346 (4.0357)	grad_norm 4.1257 (3.5995)	mem 5329MB
[2022-04-18 22:46:47 tiny] (main.py 226): INFO Train: [123/300][600/1251]	eta 0:06:37 lr 0.000641	time 0.4625 (0.6106)	loss 4.6396 (4.0547)	grad_norm 2.6351 (3.6059)	mem 5329MB
[2022-04-18 22:47:46 tiny] (main.py 226): INFO Train: [123/300][700/1251]	eta 0:05:34 lr 0.000640	time 0.5224 (0.6073)	loss 3.9108 (4.0563)	grad_norm 5.3464 (3.5996)	mem 5329MB
[2022-04-18 22:48:44 tiny] (main.py 226): INFO Train: [123/300][800/1251]	eta 0:04:32 lr 0.000640	time 0.5732 (0.6048)	loss 4.3960 (4.0573)	grad_norm 6.9112 (3.5988)	mem 5329MB
[2022-04-18 22:49:43 tiny] (main.py 226): INFO Train: [123/300][900/1251]	eta 0:03:31 lr 0.000640	time 0.6989 (0.6030)	loss 4.4671 (4.0520)	grad_norm 4.0027 (3.5982)	mem 5329MB
[2022-04-18 22:50:42 tiny] (main.py 226): INFO Train: [123/300][1000/1251]	eta 0:02:31 lr 0.000639	time 0.6129 (0.6016)	loss 3.9286 (4.0547)	grad_norm 3.0890 (3.6226)	mem 5329MB
[2022-04-18 22:51:42 tiny] (main.py 226): INFO Train: [123/300][1100/1251]	eta 0:01:30 lr 0.000639	time 0.6987 (0.6009)	loss 4.3003 (4.0579)	grad_norm 3.8231 (3.6318)	mem 5329MB
[2022-04-18 22:52:40 tiny] (main.py 226): INFO Train: [123/300][1200/1251]	eta 0:00:30 lr 0.000638	time 0.6412 (0.5995)	loss 4.4672 (4.0585)	grad_norm 2.4798 (3.6251)	mem 5329MB
[2022-04-18 22:53:02 tiny] (main.py 233): INFO EPOCH 123 training takes 0:12:21
[2022-04-18 22:53:13 tiny] (main.py 273): INFO Test: [0/49]	Time 11.262 (11.262)	Loss 1.6404 (1.6404)	Acc@1 69.336 (69.336)	Acc@5 87.305 (87.305)	Mem 5329MB
[2022-04-18 22:53:33 tiny] (main.py 279): INFO  * Acc@1 65.410 Acc@5 86.826
[2022-04-18 22:53:33 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 65.4%
[2022-04-18 22:53:33 tiny] (main.py 148): INFO Max accuracy: 65.75%
[2022-04-18 22:53:44 tiny] (main.py 226): INFO Train: [124/300][0/1251]	eta 3:53:19 lr 0.000638	time 11.1910 (11.1910)	loss 3.9733 (3.9733)	grad_norm 3.4366 (3.4366)	mem 5329MB
[2022-04-18 22:54:46 tiny] (main.py 226): INFO Train: [124/300][100/1251]	eta 0:13:59 lr 0.000638	time 0.5292 (0.7290)	loss 4.8761 (3.9912)	grad_norm 2.9627 (3.4420)	mem 5329MB
[2022-04-18 22:55:45 tiny] (main.py 226): INFO Train: [124/300][200/1251]	eta 0:11:30 lr 0.000637	time 0.5084 (0.6569)	loss 4.8351 (4.0137)	grad_norm 2.8114 (3.5846)	mem 5329MB
[2022-04-18 22:56:43 tiny] (main.py 226): INFO Train: [124/300][300/1251]	eta 0:10:01 lr 0.000637	time 0.7139 (0.6327)	loss 3.7195 (4.0394)	grad_norm 3.8801 (3.6611)	mem 5329MB
[2022-04-18 22:57:42 tiny] (main.py 226): INFO Train: [124/300][400/1251]	eta 0:08:49 lr 0.000637	time 0.6125 (0.6218)	loss 4.0525 (4.0561)	grad_norm 4.3276 (3.7014)	mem 5329MB
[2022-04-18 22:58:40 tiny] (main.py 226): INFO Train: [124/300][500/1251]	eta 0:07:41 lr 0.000636	time 0.4559 (0.6140)	loss 3.6800 (4.0599)	grad_norm 3.0228 (3.6725)	mem 5329MB
[2022-04-18 22:59:39 tiny] (main.py 226): INFO Train: [124/300][600/1251]	eta 0:06:37 lr 0.000636	time 0.5989 (0.6099)	loss 4.4307 (4.0578)	grad_norm 3.2846 (inf)	mem 5329MB
[2022-04-18 23:00:38 tiny] (main.py 226): INFO Train: [124/300][700/1251]	eta 0:05:34 lr 0.000635	time 0.4836 (0.6069)	loss 4.3253 (4.0562)	grad_norm 3.2498 (inf)	mem 5329MB
[2022-04-18 23:01:37 tiny] (main.py 226): INFO Train: [124/300][800/1251]	eta 0:04:32 lr 0.000635	time 0.5757 (0.6045)	loss 5.2371 (4.0607)	grad_norm 3.5312 (inf)	mem 5329MB
[2022-04-18 23:02:36 tiny] (main.py 226): INFO Train: [124/300][900/1251]	eta 0:03:31 lr 0.000635	time 0.5762 (0.6028)	loss 4.5705 (4.0587)	grad_norm 4.9464 (inf)	mem 5329MB
[2022-04-18 23:03:35 tiny] (main.py 226): INFO Train: [124/300][1000/1251]	eta 0:02:30 lr 0.000634	time 0.7046 (0.6014)	loss 4.1438 (4.0625)	grad_norm 4.0846 (inf)	mem 5329MB
[2022-04-18 23:04:34 tiny] (main.py 226): INFO Train: [124/300][1100/1251]	eta 0:01:30 lr 0.000634	time 0.6102 (0.6001)	loss 4.4009 (4.0655)	grad_norm 2.5500 (inf)	mem 5329MB
[2022-04-18 23:05:32 tiny] (main.py 226): INFO Train: [124/300][1200/1251]	eta 0:00:30 lr 0.000633	time 0.5565 (0.5989)	loss 3.3071 (4.0693)	grad_norm 4.1570 (inf)	mem 5329MB
[2022-04-18 23:05:55 tiny] (main.py 233): INFO EPOCH 124 training takes 0:12:21
[2022-04-18 23:06:07 tiny] (main.py 273): INFO Test: [0/49]	Time 12.132 (12.132)	Loss 1.6723 (1.6723)	Acc@1 66.016 (66.016)	Acc@5 87.988 (87.988)	Mem 5329MB
[2022-04-18 23:06:26 tiny] (main.py 279): INFO  * Acc@1 65.072 Acc@5 86.802
[2022-04-18 23:06:26 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 65.1%
[2022-04-18 23:06:26 tiny] (main.py 148): INFO Max accuracy: 65.75%
[2022-04-18 23:06:38 tiny] (main.py 226): INFO Train: [125/300][0/1251]	eta 4:13:19 lr 0.000633	time 12.1497 (12.1497)	loss 4.0079 (4.0079)	grad_norm 2.7343 (2.7343)	mem 5329MB
[2022-04-18 23:07:39 tiny] (main.py 226): INFO Train: [125/300][100/1251]	eta 0:13:59 lr 0.000633	time 0.5998 (0.7292)	loss 4.0535 (3.9937)	grad_norm 3.6528 (3.9869)	mem 5329MB
[2022-04-18 23:08:38 tiny] (main.py 226): INFO Train: [125/300][200/1251]	eta 0:11:30 lr 0.000632	time 0.5940 (0.6574)	loss 4.4031 (4.0291)	grad_norm 2.7449 (3.8672)	mem 5329MB
[2022-04-18 23:09:36 tiny] (main.py 226): INFO Train: [125/300][300/1251]	eta 0:10:01 lr 0.000632	time 0.5605 (0.6327)	loss 3.6509 (4.0729)	grad_norm 2.9010 (3.7654)	mem 5329MB
[2022-04-18 23:10:35 tiny] (main.py 226): INFO Train: [125/300][400/1251]	eta 0:08:48 lr 0.000632	time 0.4069 (0.6208)	loss 4.6245 (4.0475)	grad_norm 5.2326 (3.6953)	mem 5329MB
[2022-04-18 23:11:33 tiny] (main.py 226): INFO Train: [125/300][500/1251]	eta 0:07:41 lr 0.000631	time 0.6104 (0.6142)	loss 4.8251 (4.0266)	grad_norm 3.4840 (3.6729)	mem 5329MB
[2022-04-18 23:12:32 tiny] (main.py 226): INFO Train: [125/300][600/1251]	eta 0:06:37 lr 0.000631	time 0.5822 (0.6100)	loss 3.7068 (4.0349)	grad_norm 3.8237 (3.6740)	mem 5329MB
[2022-04-18 23:13:32 tiny] (main.py 226): INFO Train: [125/300][700/1251]	eta 0:05:34 lr 0.000630	time 0.7993 (0.6076)	loss 4.0775 (4.0246)	grad_norm 2.9083 (3.6703)	mem 5329MB
[2022-04-18 23:14:30 tiny] (main.py 226): INFO Train: [125/300][800/1251]	eta 0:04:32 lr 0.000630	time 0.4962 (0.6047)	loss 3.8279 (4.0236)	grad_norm 2.6586 (3.6369)	mem 5329MB
[2022-04-18 23:15:29 tiny] (main.py 226): INFO Train: [125/300][900/1251]	eta 0:03:31 lr 0.000630	time 0.6492 (0.6028)	loss 4.2773 (4.0284)	grad_norm 4.1768 (3.6261)	mem 5329MB
[2022-04-18 23:16:27 tiny] (main.py 226): INFO Train: [125/300][1000/1251]	eta 0:02:30 lr 0.000629	time 0.5955 (0.6012)	loss 3.9291 (4.0298)	grad_norm 3.3916 (3.6342)	mem 5329MB
[2022-04-18 23:17:26 tiny] (main.py 226): INFO Train: [125/300][1100/1251]	eta 0:01:30 lr 0.000629	time 0.6439 (0.6001)	loss 4.3936 (4.0260)	grad_norm 3.0432 (3.6453)	mem 5329MB
[2022-04-18 23:18:25 tiny] (main.py 226): INFO Train: [125/300][1200/1251]	eta 0:00:30 lr 0.000628	time 0.4890 (0.5990)	loss 3.9368 (4.0353)	grad_norm 3.7246 (3.6392)	mem 5329MB
[2022-04-18 23:18:47 tiny] (main.py 233): INFO EPOCH 125 training takes 0:12:21
[2022-04-18 23:18:58 tiny] (main.py 273): INFO Test: [0/49]	Time 11.382 (11.382)	Loss 1.7636 (1.7636)	Acc@1 64.258 (64.258)	Acc@5 84.570 (84.570)	Mem 5329MB
[2022-04-18 23:19:18 tiny] (main.py 279): INFO  * Acc@1 64.996 Acc@5 86.708
[2022-04-18 23:19:18 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 65.0%
[2022-04-18 23:19:18 tiny] (main.py 148): INFO Max accuracy: 65.75%
[2022-04-18 23:19:30 tiny] (main.py 226): INFO Train: [126/300][0/1251]	eta 4:06:54 lr 0.000628	time 11.8423 (11.8423)	loss 4.3104 (4.3104)	grad_norm 3.5685 (3.5685)	mem 5329MB
[2022-04-18 23:20:32 tiny] (main.py 226): INFO Train: [126/300][100/1251]	eta 0:14:01 lr 0.000628	time 0.7004 (0.7313)	loss 4.3901 (4.0692)	grad_norm 5.4622 (3.5972)	mem 5329MB
[2022-04-18 23:21:30 tiny] (main.py 226): INFO Train: [126/300][200/1251]	eta 0:11:32 lr 0.000627	time 0.7193 (0.6585)	loss 4.6180 (4.0629)	grad_norm 3.8975 (3.6416)	mem 5329MB
[2022-04-18 23:22:29 tiny] (main.py 226): INFO Train: [126/300][300/1251]	eta 0:10:02 lr 0.000627	time 0.4518 (0.6333)	loss 2.7688 (4.0762)	grad_norm 4.5600 (inf)	mem 5329MB
[2022-04-18 23:23:27 tiny] (main.py 226): INFO Train: [126/300][400/1251]	eta 0:08:48 lr 0.000626	time 0.5220 (0.6211)	loss 3.9773 (4.0705)	grad_norm 2.4135 (inf)	mem 5329MB
[2022-04-18 23:24:26 tiny] (main.py 226): INFO Train: [126/300][500/1251]	eta 0:07:41 lr 0.000626	time 0.5847 (0.6147)	loss 3.4890 (4.0596)	grad_norm 3.7896 (inf)	mem 5329MB
[2022-04-18 23:25:25 tiny] (main.py 226): INFO Train: [126/300][600/1251]	eta 0:06:37 lr 0.000626	time 0.6378 (0.6100)	loss 3.5976 (4.0553)	grad_norm 3.6161 (inf)	mem 5329MB
[2022-04-18 23:26:24 tiny] (main.py 226): INFO Train: [126/300][700/1251]	eta 0:05:34 lr 0.000625	time 0.5948 (0.6071)	loss 3.9135 (4.0609)	grad_norm 3.4958 (inf)	mem 5329MB
[2022-04-18 23:27:22 tiny] (main.py 226): INFO Train: [126/300][800/1251]	eta 0:04:32 lr 0.000625	time 0.7014 (0.6045)	loss 4.5513 (4.0496)	grad_norm 3.8890 (inf)	mem 5329MB
[2022-04-18 23:28:21 tiny] (main.py 226): INFO Train: [126/300][900/1251]	eta 0:03:31 lr 0.000624	time 0.5680 (0.6027)	loss 4.2099 (4.0527)	grad_norm 6.6281 (inf)	mem 5329MB
[2022-04-18 23:29:20 tiny] (main.py 226): INFO Train: [126/300][1000/1251]	eta 0:02:30 lr 0.000624	time 0.8741 (0.6013)	loss 4.5783 (4.0473)	grad_norm 4.3275 (inf)	mem 5329MB
[2022-04-18 23:30:19 tiny] (main.py 226): INFO Train: [126/300][1100/1251]	eta 0:01:30 lr 0.000624	time 0.5313 (0.6004)	loss 3.3728 (4.0445)	grad_norm 2.8719 (inf)	mem 5329MB
[2022-04-18 23:31:18 tiny] (main.py 226): INFO Train: [126/300][1200/1251]	eta 0:00:30 lr 0.000623	time 0.6095 (0.5995)	loss 4.6153 (4.0420)	grad_norm 3.9620 (inf)	mem 5329MB
[2022-04-18 23:31:39 tiny] (main.py 233): INFO EPOCH 126 training takes 0:12:21
[2022-04-18 23:31:50 tiny] (main.py 273): INFO Test: [0/49]	Time 10.935 (10.935)	Loss 1.5854 (1.5854)	Acc@1 68.457 (68.457)	Acc@5 87.500 (87.500)	Mem 5329MB
[2022-04-18 23:32:11 tiny] (main.py 279): INFO  * Acc@1 65.806 Acc@5 86.982
[2022-04-18 23:32:11 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 65.8%
[2022-04-18 23:32:11 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_126.pth saving......
[2022-04-18 23:32:11 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_126.pth saved !!!
[2022-04-18 23:32:11 tiny] (main.py 148): INFO Max accuracy: 65.81%
[2022-04-18 23:32:23 tiny] (main.py 226): INFO Train: [127/300][0/1251]	eta 4:11:37 lr 0.000623	time 12.0686 (12.0686)	loss 4.9487 (4.9487)	grad_norm 3.3592 (3.3592)	mem 5329MB
[2022-04-18 23:33:25 tiny] (main.py 226): INFO Train: [127/300][100/1251]	eta 0:14:00 lr 0.000623	time 0.7084 (0.7298)	loss 3.9023 (3.9692)	grad_norm 3.7499 (3.7963)	mem 5329MB
[2022-04-18 23:34:23 tiny] (main.py 226): INFO Train: [127/300][200/1251]	eta 0:11:29 lr 0.000622	time 0.6303 (0.6565)	loss 4.0146 (4.0471)	grad_norm 3.2704 (3.6820)	mem 5329MB
[2022-04-18 23:35:21 tiny] (main.py 226): INFO Train: [127/300][300/1251]	eta 0:10:01 lr 0.000622	time 0.6198 (0.6320)	loss 4.3322 (4.0361)	grad_norm 2.3246 (3.6374)	mem 5329MB
[2022-04-18 23:36:20 tiny] (main.py 226): INFO Train: [127/300][400/1251]	eta 0:08:48 lr 0.000621	time 0.3676 (0.6206)	loss 4.0361 (4.0407)	grad_norm 2.1479 (3.7553)	mem 5329MB
[2022-04-18 23:37:19 tiny] (main.py 226): INFO Train: [127/300][500/1251]	eta 0:07:40 lr 0.000621	time 0.6040 (0.6134)	loss 3.9198 (4.0275)	grad_norm 2.8947 (3.7409)	mem 5329MB
[2022-04-18 23:38:17 tiny] (main.py 226): INFO Train: [127/300][600/1251]	eta 0:06:36 lr 0.000621	time 0.6111 (0.6094)	loss 4.3415 (4.0218)	grad_norm 2.3565 (3.6943)	mem 5329MB
[2022-04-18 23:39:16 tiny] (main.py 226): INFO Train: [127/300][700/1251]	eta 0:05:34 lr 0.000620	time 0.6621 (0.6065)	loss 4.4381 (4.0306)	grad_norm 3.6759 (3.7108)	mem 5329MB
[2022-04-18 23:40:15 tiny] (main.py 226): INFO Train: [127/300][800/1251]	eta 0:04:32 lr 0.000620	time 0.7516 (0.6041)	loss 3.2707 (4.0235)	grad_norm 5.6402 (3.6818)	mem 5329MB
[2022-04-18 23:41:15 tiny] (main.py 226): INFO Train: [127/300][900/1251]	eta 0:03:31 lr 0.000619	time 0.5309 (0.6030)	loss 4.2753 (4.0159)	grad_norm 3.0337 (3.6627)	mem 5329MB
[2022-04-18 23:42:13 tiny] (main.py 226): INFO Train: [127/300][1000/1251]	eta 0:02:30 lr 0.000619	time 0.6581 (0.6009)	loss 4.1401 (4.0241)	grad_norm 3.0217 (3.6914)	mem 5329MB
[2022-04-18 23:43:12 tiny] (main.py 226): INFO Train: [127/300][1100/1251]	eta 0:01:30 lr 0.000619	time 0.8471 (0.5997)	loss 4.4608 (4.0194)	grad_norm 2.9981 (3.6655)	mem 5329MB
[2022-04-18 23:44:10 tiny] (main.py 226): INFO Train: [127/300][1200/1251]	eta 0:00:30 lr 0.000618	time 0.4208 (0.5988)	loss 3.3794 (4.0163)	grad_norm 2.6072 (inf)	mem 5329MB
[2022-04-18 23:44:32 tiny] (main.py 233): INFO EPOCH 127 training takes 0:12:20
[2022-04-18 23:44:43 tiny] (main.py 273): INFO Test: [0/49]	Time 11.228 (11.228)	Loss 1.6815 (1.6815)	Acc@1 65.625 (65.625)	Acc@5 86.621 (86.621)	Mem 5329MB
[2022-04-18 23:45:04 tiny] (main.py 279): INFO  * Acc@1 64.768 Acc@5 86.756
[2022-04-18 23:45:04 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 64.8%
[2022-04-18 23:45:04 tiny] (main.py 148): INFO Max accuracy: 65.81%
[2022-04-18 23:45:16 tiny] (main.py 226): INFO Train: [128/300][0/1251]	eta 4:19:47 lr 0.000618	time 12.4598 (12.4598)	loss 4.0062 (4.0062)	grad_norm 2.9430 (2.9430)	mem 5329MB
[2022-04-18 23:46:18 tiny] (main.py 226): INFO Train: [128/300][100/1251]	eta 0:14:02 lr 0.000618	time 0.7007 (0.7318)	loss 4.8035 (4.0532)	grad_norm 6.1076 (3.5936)	mem 5329MB
[2022-04-18 23:47:16 tiny] (main.py 226): INFO Train: [128/300][200/1251]	eta 0:11:30 lr 0.000617	time 0.6546 (0.6574)	loss 4.9965 (4.0553)	grad_norm 3.3035 (3.7590)	mem 5329MB
[2022-04-18 23:48:14 tiny] (main.py 226): INFO Train: [128/300][300/1251]	eta 0:10:02 lr 0.000617	time 0.5310 (0.6334)	loss 3.9282 (4.0179)	grad_norm 4.2946 (3.6536)	mem 5329MB
[2022-04-18 23:49:13 tiny] (main.py 226): INFO Train: [128/300][400/1251]	eta 0:08:49 lr 0.000616	time 0.5452 (0.6218)	loss 4.4830 (4.0232)	grad_norm 3.2099 (3.6667)	mem 5329MB
[2022-04-18 23:50:12 tiny] (main.py 226): INFO Train: [128/300][500/1251]	eta 0:07:41 lr 0.000616	time 0.4474 (0.6144)	loss 4.3308 (4.0235)	grad_norm 3.3206 (3.7185)	mem 5329MB
[2022-04-18 23:51:10 tiny] (main.py 226): INFO Train: [128/300][600/1251]	eta 0:06:36 lr 0.000616	time 0.7947 (0.6094)	loss 3.4362 (4.0205)	grad_norm 3.4155 (3.6772)	mem 5329MB
[2022-04-18 23:52:09 tiny] (main.py 226): INFO Train: [128/300][700/1251]	eta 0:05:34 lr 0.000615	time 0.3239 (0.6066)	loss 4.1984 (4.0197)	grad_norm 3.9193 (3.6779)	mem 5329MB
[2022-04-18 23:53:08 tiny] (main.py 226): INFO Train: [128/300][800/1251]	eta 0:04:32 lr 0.000615	time 0.4618 (0.6043)	loss 3.6806 (4.0142)	grad_norm 2.8099 (3.6359)	mem 5329MB
[2022-04-18 23:54:07 tiny] (main.py 226): INFO Train: [128/300][900/1251]	eta 0:03:31 lr 0.000614	time 0.5277 (0.6028)	loss 4.4030 (4.0151)	grad_norm 2.0499 (3.6480)	mem 5329MB
[2022-04-18 23:55:06 tiny] (main.py 226): INFO Train: [128/300][1000/1251]	eta 0:02:31 lr 0.000614	time 0.7192 (0.6018)	loss 4.5287 (4.0187)	grad_norm 2.5792 (3.6461)	mem 5329MB
[2022-04-18 23:56:05 tiny] (main.py 226): INFO Train: [128/300][1100/1251]	eta 0:01:30 lr 0.000614	time 0.7063 (0.6005)	loss 4.1178 (4.0182)	grad_norm 7.7423 (3.6366)	mem 5329MB
[2022-04-18 23:57:04 tiny] (main.py 226): INFO Train: [128/300][1200/1251]	eta 0:00:30 lr 0.000613	time 0.6047 (0.5994)	loss 4.0021 (4.0189)	grad_norm 5.4280 (3.6569)	mem 5329MB
[2022-04-18 23:57:26 tiny] (main.py 233): INFO EPOCH 128 training takes 0:12:21
[2022-04-18 23:57:37 tiny] (main.py 273): INFO Test: [0/49]	Time 11.272 (11.272)	Loss 1.6918 (1.6918)	Acc@1 65.234 (65.234)	Acc@5 86.133 (86.133)	Mem 5329MB
[2022-04-18 23:57:56 tiny] (main.py 279): INFO  * Acc@1 65.476 Acc@5 86.984
[2022-04-18 23:57:56 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 65.5%
[2022-04-18 23:57:56 tiny] (main.py 148): INFO Max accuracy: 65.81%
[2022-04-18 23:58:08 tiny] (main.py 226): INFO Train: [129/300][0/1251]	eta 4:10:01 lr 0.000613	time 11.9912 (11.9912)	loss 4.8740 (4.8740)	grad_norm 2.9724 (2.9724)	mem 5329MB
[2022-04-18 23:59:10 tiny] (main.py 226): INFO Train: [129/300][100/1251]	eta 0:13:58 lr 0.000613	time 0.8141 (0.7285)	loss 4.2922 (3.9697)	grad_norm 2.9625 (3.6941)	mem 5329MB
[2022-04-19 00:00:08 tiny] (main.py 226): INFO Train: [129/300][200/1251]	eta 0:11:29 lr 0.000612	time 0.6934 (0.6559)	loss 4.8343 (4.0051)	grad_norm 6.4247 (3.7388)	mem 5329MB
[2022-04-19 00:01:07 tiny] (main.py 226): INFO Train: [129/300][300/1251]	eta 0:10:02 lr 0.000612	time 0.5605 (0.6333)	loss 4.0016 (4.0221)	grad_norm 4.0685 (3.8361)	mem 5329MB
[2022-04-19 00:02:06 tiny] (main.py 226): INFO Train: [129/300][400/1251]	eta 0:08:48 lr 0.000611	time 0.4511 (0.6216)	loss 3.6546 (4.0536)	grad_norm 4.5820 (3.8012)	mem 5329MB
[2022-04-19 00:03:05 tiny] (main.py 226): INFO Train: [129/300][500/1251]	eta 0:07:42 lr 0.000611	time 0.8505 (0.6152)	loss 4.4580 (4.0440)	grad_norm 3.6760 (3.7598)	mem 5329MB
[2022-04-19 00:04:03 tiny] (main.py 226): INFO Train: [129/300][600/1251]	eta 0:06:37 lr 0.000611	time 0.4872 (0.6099)	loss 3.5673 (4.0445)	grad_norm 3.9557 (3.6677)	mem 5329MB
[2022-04-19 00:05:02 tiny] (main.py 226): INFO Train: [129/300][700/1251]	eta 0:05:34 lr 0.000610	time 0.5866 (0.6070)	loss 4.2541 (4.0369)	grad_norm 3.9751 (inf)	mem 5329MB
[2022-04-19 00:06:01 tiny] (main.py 226): INFO Train: [129/300][800/1251]	eta 0:04:32 lr 0.000610	time 0.4996 (0.6047)	loss 4.8880 (4.0431)	grad_norm 4.3909 (inf)	mem 5329MB
[2022-04-19 00:06:59 tiny] (main.py 226): INFO Train: [129/300][900/1251]	eta 0:03:31 lr 0.000609	time 0.6160 (0.6024)	loss 3.9175 (4.0485)	grad_norm 3.7259 (inf)	mem 5329MB
[2022-04-19 00:07:58 tiny] (main.py 226): INFO Train: [129/300][1000/1251]	eta 0:02:30 lr 0.000609	time 0.6714 (0.6012)	loss 4.2373 (4.0524)	grad_norm 3.1284 (inf)	mem 5329MB
[2022-04-19 00:08:58 tiny] (main.py 226): INFO Train: [129/300][1100/1251]	eta 0:01:30 lr 0.000609	time 0.5662 (0.6004)	loss 4.4094 (4.0592)	grad_norm 2.0907 (inf)	mem 5329MB
[2022-04-19 00:09:57 tiny] (main.py 226): INFO Train: [129/300][1200/1251]	eta 0:00:30 lr 0.000608	time 0.7166 (0.5997)	loss 4.2741 (4.0554)	grad_norm 3.1148 (inf)	mem 5329MB
[2022-04-19 00:10:19 tiny] (main.py 233): INFO EPOCH 129 training takes 0:12:22
[2022-04-19 00:10:31 tiny] (main.py 273): INFO Test: [0/49]	Time 11.993 (11.993)	Loss 1.6895 (1.6895)	Acc@1 62.891 (62.891)	Acc@5 86.328 (86.328)	Mem 5329MB
[2022-04-19 00:10:50 tiny] (main.py 279): INFO  * Acc@1 65.256 Acc@5 87.012
[2022-04-19 00:10:50 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 65.3%
[2022-04-19 00:10:50 tiny] (main.py 148): INFO Max accuracy: 65.81%
[2022-04-19 00:11:01 tiny] (main.py 226): INFO Train: [130/300][0/1251]	eta 3:59:35 lr 0.000608	time 11.4912 (11.4912)	loss 4.1514 (4.1514)	grad_norm 4.5700 (4.5700)	mem 5329MB
[2022-04-19 00:12:04 tiny] (main.py 226): INFO Train: [130/300][100/1251]	eta 0:14:00 lr 0.000608	time 0.8320 (0.7302)	loss 3.5692 (4.0557)	grad_norm 4.2222 (3.5726)	mem 5329MB
[2022-04-19 00:13:02 tiny] (main.py 226): INFO Train: [130/300][200/1251]	eta 0:11:32 lr 0.000607	time 0.5202 (0.6588)	loss 4.7236 (4.0957)	grad_norm 3.1070 (3.5907)	mem 5329MB
[2022-04-19 00:14:02 tiny] (main.py 226): INFO Train: [130/300][300/1251]	eta 0:10:05 lr 0.000607	time 0.8664 (0.6370)	loss 4.8893 (4.0944)	grad_norm 2.6771 (3.6332)	mem 5329MB
[2022-04-19 00:15:00 tiny] (main.py 226): INFO Train: [130/300][400/1251]	eta 0:08:50 lr 0.000606	time 0.3723 (0.6234)	loss 3.9431 (4.0754)	grad_norm 5.4096 (3.6889)	mem 5329MB
[2022-04-19 00:15:59 tiny] (main.py 226): INFO Train: [130/300][500/1251]	eta 0:07:42 lr 0.000606	time 0.6850 (0.6163)	loss 5.0271 (4.0784)	grad_norm 2.5944 (3.6501)	mem 5329MB
[2022-04-19 00:16:58 tiny] (main.py 226): INFO Train: [130/300][600/1251]	eta 0:06:38 lr 0.000605	time 0.5527 (0.6120)	loss 3.6672 (4.0802)	grad_norm 2.0701 (3.6643)	mem 5329MB
[2022-04-19 00:17:56 tiny] (main.py 226): INFO Train: [130/300][700/1251]	eta 0:05:35 lr 0.000605	time 0.4910 (0.6082)	loss 4.2963 (4.0627)	grad_norm 3.6671 (3.6968)	mem 5329MB
[2022-04-19 00:18:55 tiny] (main.py 226): INFO Train: [130/300][800/1251]	eta 0:04:33 lr 0.000605	time 0.5134 (0.6058)	loss 4.8504 (4.0662)	grad_norm 4.7400 (3.7216)	mem 5329MB
[2022-04-19 00:19:54 tiny] (main.py 226): INFO Train: [130/300][900/1251]	eta 0:03:32 lr 0.000604	time 0.5629 (0.6040)	loss 3.9890 (4.0647)	grad_norm 3.0475 (3.7150)	mem 5329MB
[2022-04-19 00:20:53 tiny] (main.py 226): INFO Train: [130/300][1000/1251]	eta 0:02:31 lr 0.000604	time 0.7044 (0.6022)	loss 4.0490 (4.0732)	grad_norm 3.7379 (3.7012)	mem 5329MB
[2022-04-19 00:21:52 tiny] (main.py 226): INFO Train: [130/300][1100/1251]	eta 0:01:30 lr 0.000603	time 0.4885 (0.6011)	loss 4.3170 (4.0666)	grad_norm 2.7930 (3.7125)	mem 5329MB
[2022-04-19 00:22:51 tiny] (main.py 226): INFO Train: [130/300][1200/1251]	eta 0:00:30 lr 0.000603	time 0.5311 (0.6001)	loss 4.8784 (4.0705)	grad_norm 3.1622 (3.6964)	mem 5329MB
[2022-04-19 00:23:13 tiny] (main.py 233): INFO EPOCH 130 training takes 0:12:22
[2022-04-19 00:23:23 tiny] (main.py 273): INFO Test: [0/49]	Time 10.144 (10.144)	Loss 1.6003 (1.6003)	Acc@1 68.164 (68.164)	Acc@5 89.453 (89.453)	Mem 5329MB
[2022-04-19 00:23:44 tiny] (main.py 279): INFO  * Acc@1 65.628 Acc@5 87.250
[2022-04-19 00:23:44 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 65.6%
[2022-04-19 00:23:44 tiny] (main.py 148): INFO Max accuracy: 65.81%
[2022-04-19 00:23:55 tiny] (main.py 226): INFO Train: [131/300][0/1251]	eta 3:54:32 lr 0.000603	time 11.2490 (11.2490)	loss 4.0734 (4.0734)	grad_norm 6.4820 (6.4820)	mem 5329MB
[2022-04-19 00:24:58 tiny] (main.py 226): INFO Train: [131/300][100/1251]	eta 0:13:56 lr 0.000602	time 0.6028 (0.7272)	loss 4.3782 (4.0367)	grad_norm 3.0390 (3.4458)	mem 5329MB
[2022-04-19 00:25:56 tiny] (main.py 226): INFO Train: [131/300][200/1251]	eta 0:11:31 lr 0.000602	time 0.5827 (0.6579)	loss 3.2134 (4.0164)	grad_norm 2.3557 (3.4740)	mem 5329MB
[2022-04-19 00:26:55 tiny] (main.py 226): INFO Train: [131/300][300/1251]	eta 0:10:02 lr 0.000602	time 0.4194 (0.6338)	loss 3.9620 (4.0269)	grad_norm 3.6155 (inf)	mem 5329MB
[2022-04-19 00:27:53 tiny] (main.py 226): INFO Train: [131/300][400/1251]	eta 0:08:48 lr 0.000601	time 0.5263 (0.6216)	loss 3.9215 (4.0210)	grad_norm 2.2957 (inf)	mem 5329MB
[2022-04-19 00:28:52 tiny] (main.py 226): INFO Train: [131/300][500/1251]	eta 0:07:41 lr 0.000601	time 0.5582 (0.6147)	loss 4.8968 (3.9886)	grad_norm 4.2137 (inf)	mem 5329MB
[2022-04-19 00:29:51 tiny] (main.py 226): INFO Train: [131/300][600/1251]	eta 0:06:37 lr 0.000600	time 0.6043 (0.6101)	loss 4.7498 (3.9966)	grad_norm 4.3170 (inf)	mem 5329MB
[2022-04-19 00:30:50 tiny] (main.py 226): INFO Train: [131/300][700/1251]	eta 0:05:34 lr 0.000600	time 0.5684 (0.6079)	loss 4.0639 (3.9977)	grad_norm 4.3308 (inf)	mem 5329MB
[2022-04-19 00:31:49 tiny] (main.py 226): INFO Train: [131/300][800/1251]	eta 0:04:33 lr 0.000600	time 0.4232 (0.6055)	loss 3.9338 (4.0028)	grad_norm 2.4921 (inf)	mem 5329MB
[2022-04-19 00:32:48 tiny] (main.py 226): INFO Train: [131/300][900/1251]	eta 0:03:31 lr 0.000599	time 0.5253 (0.6036)	loss 4.7077 (4.0096)	grad_norm 2.9222 (inf)	mem 5329MB
[2022-04-19 00:33:47 tiny] (main.py 226): INFO Train: [131/300][1000/1251]	eta 0:02:31 lr 0.000599	time 0.9444 (0.6021)	loss 3.7497 (4.0079)	grad_norm 3.9420 (inf)	mem 5329MB
[2022-04-19 00:34:46 tiny] (main.py 226): INFO Train: [131/300][1100/1251]	eta 0:01:30 lr 0.000598	time 0.5630 (0.6009)	loss 4.6274 (4.0181)	grad_norm 7.0121 (inf)	mem 5329MB
[2022-04-19 00:35:45 tiny] (main.py 226): INFO Train: [131/300][1200/1251]	eta 0:00:30 lr 0.000598	time 0.6110 (0.5998)	loss 2.9488 (4.0220)	grad_norm 2.9873 (inf)	mem 5329MB
[2022-04-19 00:36:06 tiny] (main.py 233): INFO EPOCH 131 training takes 0:12:21
[2022-04-19 00:36:18 tiny] (main.py 273): INFO Test: [0/49]	Time 11.944 (11.944)	Loss 1.7397 (1.7397)	Acc@1 65.723 (65.723)	Acc@5 87.012 (87.012)	Mem 5329MB
[2022-04-19 00:36:37 tiny] (main.py 279): INFO  * Acc@1 65.448 Acc@5 87.028
[2022-04-19 00:36:37 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 65.4%
[2022-04-19 00:36:37 tiny] (main.py 148): INFO Max accuracy: 65.81%
[2022-04-19 00:36:50 tiny] (main.py 226): INFO Train: [132/300][0/1251]	eta 4:18:42 lr 0.000598	time 12.4083 (12.4083)	loss 4.6867 (4.6867)	grad_norm 5.5083 (5.5083)	mem 5329MB
[2022-04-19 00:37:51 tiny] (main.py 226): INFO Train: [132/300][100/1251]	eta 0:14:00 lr 0.000597	time 0.5800 (0.7300)	loss 3.0035 (3.9176)	grad_norm 3.8360 (3.7569)	mem 5329MB
[2022-04-19 00:38:50 tiny] (main.py 226): INFO Train: [132/300][200/1251]	eta 0:11:32 lr 0.000597	time 0.6064 (0.6587)	loss 3.1197 (3.9655)	grad_norm 3.8141 (3.7053)	mem 5329MB
[2022-04-19 00:39:48 tiny] (main.py 226): INFO Train: [132/300][300/1251]	eta 0:10:03 lr 0.000597	time 0.6016 (0.6343)	loss 3.6307 (3.9861)	grad_norm 5.2274 (3.7969)	mem 5329MB
[2022-04-19 00:40:46 tiny] (main.py 226): INFO Train: [132/300][400/1251]	eta 0:08:48 lr 0.000596	time 0.6181 (0.6216)	loss 5.1213 (4.0179)	grad_norm 3.1807 (3.8080)	mem 5329MB
[2022-04-19 00:41:45 tiny] (main.py 226): INFO Train: [132/300][500/1251]	eta 0:07:41 lr 0.000596	time 0.5067 (0.6143)	loss 4.2865 (4.0106)	grad_norm 3.1976 (3.8224)	mem 5329MB
[2022-04-19 00:42:45 tiny] (main.py 226): INFO Train: [132/300][600/1251]	eta 0:06:38 lr 0.000595	time 0.8837 (0.6114)	loss 4.3570 (4.0304)	grad_norm 3.2455 (3.7503)	mem 5329MB
[2022-04-19 00:43:43 tiny] (main.py 226): INFO Train: [132/300][700/1251]	eta 0:05:34 lr 0.000595	time 0.5196 (0.6071)	loss 4.3817 (4.0147)	grad_norm 4.0773 (3.7674)	mem 5329MB
[2022-04-19 00:44:42 tiny] (main.py 226): INFO Train: [132/300][800/1251]	eta 0:04:33 lr 0.000594	time 0.7152 (0.6055)	loss 2.8278 (4.0117)	grad_norm 4.9846 (3.8023)	mem 5329MB
[2022-04-19 00:45:41 tiny] (main.py 226): INFO Train: [132/300][900/1251]	eta 0:03:31 lr 0.000594	time 0.7847 (0.6032)	loss 3.6655 (4.0116)	grad_norm 2.1224 (3.8030)	mem 5329MB
[2022-04-19 00:46:39 tiny] (main.py 226): INFO Train: [132/300][1000/1251]	eta 0:02:30 lr 0.000594	time 0.6560 (0.6016)	loss 3.8579 (4.0177)	grad_norm 4.0201 (3.8000)	mem 5329MB
[2022-04-19 00:47:38 tiny] (main.py 226): INFO Train: [132/300][1100/1251]	eta 0:01:30 lr 0.000593	time 0.6640 (0.6002)	loss 3.1010 (4.0174)	grad_norm 5.1848 (3.7606)	mem 5329MB
[2022-04-19 00:48:37 tiny] (main.py 226): INFO Train: [132/300][1200/1251]	eta 0:00:30 lr 0.000593	time 0.6494 (0.5994)	loss 3.7257 (4.0269)	grad_norm 4.1907 (3.7811)	mem 5329MB
[2022-04-19 00:48:59 tiny] (main.py 233): INFO EPOCH 132 training takes 0:12:21
[2022-04-19 00:49:11 tiny] (main.py 273): INFO Test: [0/49]	Time 11.906 (11.906)	Loss 1.7290 (1.7290)	Acc@1 66.211 (66.211)	Acc@5 87.109 (87.109)	Mem 5329MB
[2022-04-19 00:49:30 tiny] (main.py 279): INFO  * Acc@1 65.766 Acc@5 87.216
[2022-04-19 00:49:30 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 65.8%
[2022-04-19 00:49:30 tiny] (main.py 148): INFO Max accuracy: 65.81%
[2022-04-19 00:49:42 tiny] (main.py 226): INFO Train: [133/300][0/1251]	eta 4:13:37 lr 0.000593	time 12.1641 (12.1641)	loss 4.6457 (4.6457)	grad_norm 2.5592 (2.5592)	mem 5329MB
[2022-04-19 00:50:43 tiny] (main.py 226): INFO Train: [133/300][100/1251]	eta 0:14:00 lr 0.000592	time 0.7354 (0.7300)	loss 4.7680 (3.9643)	grad_norm 2.5488 (3.4286)	mem 5329MB
[2022-04-19 00:51:42 tiny] (main.py 226): INFO Train: [133/300][200/1251]	eta 0:11:31 lr 0.000592	time 0.4754 (0.6578)	loss 4.1679 (4.0294)	grad_norm 2.6275 (3.4723)	mem 5329MB
[2022-04-19 00:52:40 tiny] (main.py 226): INFO Train: [133/300][300/1251]	eta 0:10:02 lr 0.000591	time 0.5789 (0.6332)	loss 2.6320 (4.0066)	grad_norm 3.1386 (3.6268)	mem 5329MB
[2022-04-19 00:53:39 tiny] (main.py 226): INFO Train: [133/300][400/1251]	eta 0:08:48 lr 0.000591	time 0.5462 (0.6208)	loss 2.9739 (4.0217)	grad_norm 4.3551 (inf)	mem 5329MB
[2022-04-19 00:54:37 tiny] (main.py 226): INFO Train: [133/300][500/1251]	eta 0:07:41 lr 0.000591	time 0.5984 (0.6139)	loss 3.6417 (4.0262)	grad_norm 4.4507 (inf)	mem 5329MB
[2022-04-19 00:55:36 tiny] (main.py 226): INFO Train: [133/300][600/1251]	eta 0:06:37 lr 0.000590	time 0.5791 (0.6099)	loss 4.8004 (4.0322)	grad_norm 3.4833 (inf)	mem 5329MB
[2022-04-19 00:56:35 tiny] (main.py 226): INFO Train: [133/300][700/1251]	eta 0:05:33 lr 0.000590	time 0.5095 (0.6061)	loss 4.3663 (4.0109)	grad_norm 2.3394 (inf)	mem 5329MB
[2022-04-19 00:57:34 tiny] (main.py 226): INFO Train: [133/300][800/1251]	eta 0:04:32 lr 0.000589	time 0.5997 (0.6041)	loss 4.4026 (4.0175)	grad_norm 3.3358 (inf)	mem 5329MB
[2022-04-19 00:58:32 tiny] (main.py 226): INFO Train: [133/300][900/1251]	eta 0:03:31 lr 0.000589	time 0.5828 (0.6023)	loss 4.9809 (4.0149)	grad_norm 3.7098 (inf)	mem 5329MB
[2022-04-19 00:59:32 tiny] (main.py 226): INFO Train: [133/300][1000/1251]	eta 0:02:30 lr 0.000589	time 0.3911 (0.6015)	loss 4.2726 (4.0175)	grad_norm 2.6078 (inf)	mem 5329MB
[2022-04-19 01:00:31 tiny] (main.py 226): INFO Train: [133/300][1100/1251]	eta 0:01:30 lr 0.000588	time 0.5218 (0.6004)	loss 4.4132 (4.0176)	grad_norm 2.4177 (inf)	mem 5329MB
[2022-04-19 01:01:29 tiny] (main.py 226): INFO Train: [133/300][1200/1251]	eta 0:00:30 lr 0.000588	time 0.5466 (0.5992)	loss 3.4579 (4.0192)	grad_norm 3.2698 (inf)	mem 5329MB
[2022-04-19 01:01:52 tiny] (main.py 233): INFO EPOCH 133 training takes 0:12:22
[2022-04-19 01:02:04 tiny] (main.py 273): INFO Test: [0/49]	Time 11.849 (11.849)	Loss 1.6871 (1.6871)	Acc@1 67.285 (67.285)	Acc@5 87.402 (87.402)	Mem 5329MB
[2022-04-19 01:02:23 tiny] (main.py 279): INFO  * Acc@1 65.600 Acc@5 87.050
[2022-04-19 01:02:23 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 65.6%
[2022-04-19 01:02:23 tiny] (main.py 148): INFO Max accuracy: 65.81%
[2022-04-19 01:02:36 tiny] (main.py 226): INFO Train: [134/300][0/1251]	eta 4:15:09 lr 0.000588	time 12.2378 (12.2378)	loss 4.2298 (4.2298)	grad_norm 6.5211 (6.5211)	mem 5329MB
[2022-04-19 01:03:36 tiny] (main.py 226): INFO Train: [134/300][100/1251]	eta 0:13:52 lr 0.000587	time 0.4557 (0.7235)	loss 3.0725 (3.9473)	grad_norm 4.2396 (3.7324)	mem 5329MB
[2022-04-19 01:04:35 tiny] (main.py 226): INFO Train: [134/300][200/1251]	eta 0:11:29 lr 0.000587	time 0.6642 (0.6556)	loss 4.1506 (3.9401)	grad_norm 2.8601 (3.8071)	mem 5329MB
[2022-04-19 01:05:34 tiny] (main.py 226): INFO Train: [134/300][300/1251]	eta 0:10:01 lr 0.000586	time 0.6360 (0.6327)	loss 4.4754 (4.0041)	grad_norm 2.9064 (3.8230)	mem 5329MB
[2022-04-19 01:06:32 tiny] (main.py 226): INFO Train: [134/300][400/1251]	eta 0:08:48 lr 0.000586	time 0.6481 (0.6209)	loss 4.8433 (4.0084)	grad_norm 6.5176 (3.7916)	mem 5329MB
[2022-04-19 01:07:30 tiny] (main.py 226): INFO Train: [134/300][500/1251]	eta 0:07:40 lr 0.000586	time 0.5399 (0.6131)	loss 4.3549 (3.9835)	grad_norm 4.4245 (3.7984)	mem 5329MB
[2022-04-19 01:08:29 tiny] (main.py 226): INFO Train: [134/300][600/1251]	eta 0:06:36 lr 0.000585	time 0.5577 (0.6093)	loss 3.4996 (3.9984)	grad_norm 2.9476 (3.7576)	mem 5329MB
[2022-04-19 01:09:29 tiny] (main.py 226): INFO Train: [134/300][700/1251]	eta 0:05:34 lr 0.000585	time 0.6144 (0.6066)	loss 3.0620 (4.0027)	grad_norm 5.8835 (3.7741)	mem 5329MB
[2022-04-19 01:10:27 tiny] (main.py 226): INFO Train: [134/300][800/1251]	eta 0:04:32 lr 0.000584	time 0.4595 (0.6042)	loss 3.1029 (4.0104)	grad_norm 3.6512 (3.7427)	mem 5329MB
[2022-04-19 01:11:26 tiny] (main.py 226): INFO Train: [134/300][900/1251]	eta 0:03:31 lr 0.000584	time 0.5918 (0.6029)	loss 4.5405 (4.0179)	grad_norm 2.9668 (3.7621)	mem 5329MB
[2022-04-19 01:12:26 tiny] (main.py 226): INFO Train: [134/300][1000/1251]	eta 0:02:31 lr 0.000583	time 0.5501 (0.6016)	loss 4.6207 (4.0101)	grad_norm 3.5080 (3.7618)	mem 5329MB
[2022-04-19 01:13:24 tiny] (main.py 226): INFO Train: [134/300][1100/1251]	eta 0:01:30 lr 0.000583	time 0.4474 (0.6002)	loss 4.3173 (4.0123)	grad_norm 3.2747 (3.7866)	mem 5329MB
[2022-04-19 01:14:23 tiny] (main.py 226): INFO Train: [134/300][1200/1251]	eta 0:00:30 lr 0.000583	time 0.8883 (0.5995)	loss 3.7996 (4.0129)	grad_norm 3.9218 (inf)	mem 5329MB
[2022-04-19 01:14:45 tiny] (main.py 233): INFO EPOCH 134 training takes 0:12:21
[2022-04-19 01:14:57 tiny] (main.py 273): INFO Test: [0/49]	Time 12.243 (12.243)	Loss 1.6882 (1.6882)	Acc@1 66.309 (66.309)	Acc@5 86.426 (86.426)	Mem 5329MB
[2022-04-19 01:15:16 tiny] (main.py 279): INFO  * Acc@1 65.776 Acc@5 87.258
[2022-04-19 01:15:16 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 65.8%
[2022-04-19 01:15:16 tiny] (main.py 148): INFO Max accuracy: 65.81%
[2022-04-19 01:15:28 tiny] (main.py 226): INFO Train: [135/300][0/1251]	eta 4:09:38 lr 0.000582	time 11.9736 (11.9736)	loss 4.6205 (4.6205)	grad_norm 3.9858 (3.9858)	mem 5329MB
[2022-04-19 01:16:31 tiny] (main.py 226): INFO Train: [135/300][100/1251]	eta 0:14:06 lr 0.000582	time 0.7138 (0.7357)	loss 4.4435 (4.0586)	grad_norm 2.4293 (4.0580)	mem 5329MB
[2022-04-19 01:17:28 tiny] (main.py 226): INFO Train: [135/300][200/1251]	eta 0:11:30 lr 0.000582	time 0.6538 (0.6574)	loss 4.5185 (4.1286)	grad_norm 2.6141 (3.7431)	mem 5329MB
[2022-04-19 01:18:27 tiny] (main.py 226): INFO Train: [135/300][300/1251]	eta 0:10:02 lr 0.000581	time 0.5921 (0.6333)	loss 3.7944 (4.0781)	grad_norm 3.9291 (3.6981)	mem 5329MB
[2022-04-19 01:19:26 tiny] (main.py 226): INFO Train: [135/300][400/1251]	eta 0:08:49 lr 0.000581	time 0.5118 (0.6217)	loss 4.0087 (4.0718)	grad_norm 2.6774 (3.8436)	mem 5329MB
[2022-04-19 01:20:24 tiny] (main.py 226): INFO Train: [135/300][500/1251]	eta 0:07:41 lr 0.000580	time 0.6202 (0.6151)	loss 3.8803 (4.0754)	grad_norm 2.9628 (3.7634)	mem 5329MB
[2022-04-19 01:21:23 tiny] (main.py 226): INFO Train: [135/300][600/1251]	eta 0:06:37 lr 0.000580	time 0.6986 (0.6104)	loss 4.4880 (4.0772)	grad_norm 4.4222 (3.8032)	mem 5329MB
[2022-04-19 01:22:22 tiny] (main.py 226): INFO Train: [135/300][700/1251]	eta 0:05:34 lr 0.000580	time 0.5374 (0.6074)	loss 4.8892 (4.0680)	grad_norm 3.3669 (3.8448)	mem 5329MB
[2022-04-19 01:23:21 tiny] (main.py 226): INFO Train: [135/300][800/1251]	eta 0:04:32 lr 0.000579	time 0.6401 (0.6051)	loss 4.8326 (4.0705)	grad_norm 3.2227 (3.8111)	mem 5329MB
[2022-04-19 01:24:19 tiny] (main.py 226): INFO Train: [135/300][900/1251]	eta 0:03:31 lr 0.000579	time 0.5588 (0.6027)	loss 3.6063 (4.0663)	grad_norm 2.1225 (3.8060)	mem 5329MB
[2022-04-19 01:25:18 tiny] (main.py 226): INFO Train: [135/300][1000/1251]	eta 0:02:30 lr 0.000578	time 0.6354 (0.6013)	loss 3.0045 (4.0603)	grad_norm 4.8521 (3.8638)	mem 5329MB
[2022-04-19 01:26:17 tiny] (main.py 226): INFO Train: [135/300][1100/1251]	eta 0:01:30 lr 0.000578	time 0.6276 (0.6002)	loss 4.3667 (4.0559)	grad_norm 2.9067 (3.8428)	mem 5329MB
[2022-04-19 01:27:16 tiny] (main.py 226): INFO Train: [135/300][1200/1251]	eta 0:00:30 lr 0.000578	time 0.5657 (0.5995)	loss 3.6011 (4.0515)	grad_norm 2.6200 (3.8353)	mem 5329MB
[2022-04-19 01:27:38 tiny] (main.py 233): INFO EPOCH 135 training takes 0:12:22
[2022-04-19 01:27:51 tiny] (main.py 273): INFO Test: [0/49]	Time 12.201 (12.201)	Loss 1.7015 (1.7015)	Acc@1 67.480 (67.480)	Acc@5 87.988 (87.988)	Mem 5329MB
[2022-04-19 01:28:09 tiny] (main.py 279): INFO  * Acc@1 65.864 Acc@5 87.186
[2022-04-19 01:28:09 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 65.9%
[2022-04-19 01:28:09 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_135.pth saving......
[2022-04-19 01:28:09 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_135.pth saved !!!
[2022-04-19 01:28:09 tiny] (main.py 148): INFO Max accuracy: 65.86%
[2022-04-19 01:28:20 tiny] (main.py 226): INFO Train: [136/300][0/1251]	eta 3:49:33 lr 0.000577	time 11.0101 (11.0101)	loss 4.0306 (4.0306)	grad_norm 2.6507 (2.6507)	mem 5329MB
[2022-04-19 01:29:23 tiny] (main.py 226): INFO Train: [136/300][100/1251]	eta 0:13:54 lr 0.000577	time 0.6587 (0.7248)	loss 4.6163 (3.9429)	grad_norm 2.7327 (3.9227)	mem 5329MB
[2022-04-19 01:30:22 tiny] (main.py 226): INFO Train: [136/300][200/1251]	eta 0:11:30 lr 0.000576	time 0.7063 (0.6574)	loss 4.3877 (4.0636)	grad_norm 2.3413 (3.7929)	mem 5329MB
[2022-04-19 01:31:20 tiny] (main.py 226): INFO Train: [136/300][300/1251]	eta 0:10:02 lr 0.000576	time 0.6647 (0.6334)	loss 4.1291 (4.0480)	grad_norm 4.8868 (3.7532)	mem 5329MB
[2022-04-19 01:32:19 tiny] (main.py 226): INFO Train: [136/300][400/1251]	eta 0:08:48 lr 0.000576	time 0.6551 (0.6211)	loss 2.6475 (4.0383)	grad_norm 2.9615 (3.7650)	mem 5329MB
[2022-04-19 01:33:17 tiny] (main.py 226): INFO Train: [136/300][500/1251]	eta 0:07:41 lr 0.000575	time 0.4427 (0.6142)	loss 4.9664 (4.0312)	grad_norm 3.4329 (3.7904)	mem 5329MB
[2022-04-19 01:34:16 tiny] (main.py 226): INFO Train: [136/300][600/1251]	eta 0:06:37 lr 0.000575	time 0.8101 (0.6104)	loss 4.3923 (4.0411)	grad_norm 7.4480 (3.7981)	mem 5329MB
[2022-04-19 01:35:15 tiny] (main.py 226): INFO Train: [136/300][700/1251]	eta 0:05:34 lr 0.000574	time 0.6067 (0.6070)	loss 4.9872 (4.0464)	grad_norm 2.9788 (inf)	mem 5329MB
[2022-04-19 01:36:13 tiny] (main.py 226): INFO Train: [136/300][800/1251]	eta 0:04:32 lr 0.000574	time 0.4858 (0.6043)	loss 4.5829 (4.0465)	grad_norm 2.1315 (inf)	mem 5329MB
[2022-04-19 01:37:12 tiny] (main.py 226): INFO Train: [136/300][900/1251]	eta 0:03:31 lr 0.000574	time 0.4074 (0.6024)	loss 4.4912 (4.0410)	grad_norm 3.3111 (inf)	mem 5329MB
[2022-04-19 01:38:11 tiny] (main.py 226): INFO Train: [136/300][1000/1251]	eta 0:02:30 lr 0.000573	time 0.6137 (0.6013)	loss 4.4940 (4.0308)	grad_norm 4.9271 (inf)	mem 5329MB
[2022-04-19 01:39:10 tiny] (main.py 226): INFO Train: [136/300][1100/1251]	eta 0:01:30 lr 0.000573	time 0.6331 (0.6001)	loss 4.4869 (4.0273)	grad_norm 8.0446 (inf)	mem 5329MB
[2022-04-19 01:40:09 tiny] (main.py 226): INFO Train: [136/300][1200/1251]	eta 0:00:30 lr 0.000572	time 0.5715 (0.5992)	loss 4.4795 (4.0272)	grad_norm 3.4395 (inf)	mem 5329MB
[2022-04-19 01:40:30 tiny] (main.py 233): INFO EPOCH 136 training takes 0:12:21
[2022-04-19 01:40:42 tiny] (main.py 273): INFO Test: [0/49]	Time 11.954 (11.954)	Loss 1.6945 (1.6945)	Acc@1 65.625 (65.625)	Acc@5 86.523 (86.523)	Mem 5329MB
[2022-04-19 01:41:01 tiny] (main.py 279): INFO  * Acc@1 66.118 Acc@5 87.270
[2022-04-19 01:41:01 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 66.1%
[2022-04-19 01:41:01 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_136.pth saving......
[2022-04-19 01:41:02 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_136.pth saved !!!
[2022-04-19 01:41:02 tiny] (main.py 148): INFO Max accuracy: 66.12%
[2022-04-19 01:41:14 tiny] (main.py 226): INFO Train: [137/300][0/1251]	eta 4:26:24 lr 0.000572	time 12.7771 (12.7771)	loss 3.5874 (3.5874)	grad_norm 2.6666 (2.6666)	mem 5329MB
[2022-04-19 01:42:15 tiny] (main.py 226): INFO Train: [137/300][100/1251]	eta 0:13:58 lr 0.000572	time 0.5288 (0.7281)	loss 2.8232 (3.9955)	grad_norm 4.5614 (3.8117)	mem 5329MB
[2022-04-19 01:43:13 tiny] (main.py 226): INFO Train: [137/300][200/1251]	eta 0:11:28 lr 0.000571	time 0.6013 (0.6552)	loss 4.6662 (4.0265)	grad_norm 2.5426 (3.6934)	mem 5329MB
[2022-04-19 01:44:12 tiny] (main.py 226): INFO Train: [137/300][300/1251]	eta 0:10:02 lr 0.000571	time 0.9456 (0.6333)	loss 3.6744 (4.0135)	grad_norm 4.1857 (3.6581)	mem 5329MB
[2022-04-19 01:45:11 tiny] (main.py 226): INFO Train: [137/300][400/1251]	eta 0:08:48 lr 0.000571	time 0.6421 (0.6214)	loss 4.3026 (3.9969)	grad_norm 4.1021 (3.6990)	mem 5329MB
[2022-04-19 01:46:09 tiny] (main.py 226): INFO Train: [137/300][500/1251]	eta 0:07:41 lr 0.000570	time 0.6381 (0.6142)	loss 3.9165 (3.9965)	grad_norm 5.8983 (3.7395)	mem 5329MB
[2022-04-19 01:47:08 tiny] (main.py 226): INFO Train: [137/300][600/1251]	eta 0:06:36 lr 0.000570	time 0.6471 (0.6096)	loss 4.7252 (3.9818)	grad_norm 3.6142 (3.8273)	mem 5329MB
[2022-04-19 01:48:07 tiny] (main.py 226): INFO Train: [137/300][700/1251]	eta 0:05:34 lr 0.000569	time 0.3664 (0.6065)	loss 2.8545 (3.9889)	grad_norm 2.6911 (3.8135)	mem 5329MB
[2022-04-19 01:49:06 tiny] (main.py 226): INFO Train: [137/300][800/1251]	eta 0:04:32 lr 0.000569	time 0.4429 (0.6048)	loss 3.7579 (3.9832)	grad_norm 3.5761 (3.8168)	mem 5329MB
[2022-04-19 01:50:05 tiny] (main.py 226): INFO Train: [137/300][900/1251]	eta 0:03:31 lr 0.000568	time 0.7110 (0.6029)	loss 4.1298 (3.9868)	grad_norm 2.3420 (3.8419)	mem 5329MB
[2022-04-19 01:51:04 tiny] (main.py 226): INFO Train: [137/300][1000/1251]	eta 0:02:31 lr 0.000568	time 0.7247 (0.6016)	loss 3.8189 (4.0011)	grad_norm 3.8261 (3.8386)	mem 5329MB
[2022-04-19 01:52:03 tiny] (main.py 226): INFO Train: [137/300][1100/1251]	eta 0:01:30 lr 0.000568	time 0.5902 (0.6006)	loss 3.9297 (4.0098)	grad_norm 2.6125 (3.8506)	mem 5329MB
[2022-04-19 01:53:02 tiny] (main.py 226): INFO Train: [137/300][1200/1251]	eta 0:00:30 lr 0.000567	time 0.5510 (0.5996)	loss 4.7928 (4.0068)	grad_norm 3.4431 (3.8544)	mem 5329MB
[2022-04-19 01:53:24 tiny] (main.py 233): INFO EPOCH 137 training takes 0:12:21
[2022-04-19 01:53:35 tiny] (main.py 273): INFO Test: [0/49]	Time 11.103 (11.103)	Loss 1.7256 (1.7256)	Acc@1 63.965 (63.965)	Acc@5 86.426 (86.426)	Mem 5329MB
[2022-04-19 01:53:55 tiny] (main.py 279): INFO  * Acc@1 65.446 Acc@5 86.994
[2022-04-19 01:53:55 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 65.4%
[2022-04-19 01:53:55 tiny] (main.py 148): INFO Max accuracy: 66.12%
[2022-04-19 01:54:08 tiny] (main.py 226): INFO Train: [138/300][0/1251]	eta 4:21:03 lr 0.000567	time 12.5209 (12.5209)	loss 4.4220 (4.4220)	grad_norm 2.4644 (2.4644)	mem 5329MB
[2022-04-19 01:55:09 tiny] (main.py 226): INFO Train: [138/300][100/1251]	eta 0:14:04 lr 0.000567	time 0.6666 (0.7340)	loss 3.0783 (4.0190)	grad_norm 2.8387 (3.8891)	mem 5329MB
[2022-04-19 01:56:07 tiny] (main.py 226): INFO Train: [138/300][200/1251]	eta 0:11:29 lr 0.000566	time 0.4432 (0.6561)	loss 3.9695 (4.0549)	grad_norm 3.5721 (3.9002)	mem 5329MB
[2022-04-19 01:57:06 tiny] (main.py 226): INFO Train: [138/300][300/1251]	eta 0:10:03 lr 0.000566	time 0.6187 (0.6346)	loss 3.0512 (4.0364)	grad_norm 5.6117 (3.9219)	mem 5329MB
[2022-04-19 01:58:05 tiny] (main.py 226): INFO Train: [138/300][400/1251]	eta 0:08:49 lr 0.000565	time 0.6324 (0.6226)	loss 2.9252 (3.9943)	grad_norm 3.8637 (3.9239)	mem 5329MB
[2022-04-19 01:59:04 tiny] (main.py 226): INFO Train: [138/300][500/1251]	eta 0:07:42 lr 0.000565	time 0.7163 (0.6156)	loss 4.3689 (3.9886)	grad_norm 2.8095 (3.8794)	mem 5329MB
[2022-04-19 02:00:02 tiny] (main.py 226): INFO Train: [138/300][600/1251]	eta 0:06:37 lr 0.000565	time 0.4557 (0.6106)	loss 4.0273 (3.9693)	grad_norm 4.8915 (3.8816)	mem 5329MB
[2022-04-19 02:01:01 tiny] (main.py 226): INFO Train: [138/300][700/1251]	eta 0:05:35 lr 0.000564	time 0.6936 (0.6080)	loss 3.7563 (3.9784)	grad_norm 2.7200 (inf)	mem 5329MB
[2022-04-19 02:02:00 tiny] (main.py 226): INFO Train: [138/300][800/1251]	eta 0:04:33 lr 0.000564	time 0.4150 (0.6055)	loss 3.4579 (3.9810)	grad_norm 3.9476 (inf)	mem 5329MB
[2022-04-19 02:02:59 tiny] (main.py 226): INFO Train: [138/300][900/1251]	eta 0:03:31 lr 0.000563	time 0.5607 (0.6035)	loss 3.2638 (3.9986)	grad_norm 6.7769 (inf)	mem 5329MB
[2022-04-19 02:03:58 tiny] (main.py 226): INFO Train: [138/300][1000/1251]	eta 0:02:31 lr 0.000563	time 1.0000 (0.6022)	loss 4.9375 (4.0085)	grad_norm 8.6368 (inf)	mem 5329MB
[2022-04-19 02:04:57 tiny] (main.py 226): INFO Train: [138/300][1100/1251]	eta 0:01:30 lr 0.000563	time 0.7082 (0.6008)	loss 4.1236 (4.0118)	grad_norm 3.7359 (inf)	mem 5329MB
[2022-04-19 02:05:55 tiny] (main.py 226): INFO Train: [138/300][1200/1251]	eta 0:00:30 lr 0.000562	time 0.3904 (0.5997)	loss 4.3693 (4.0120)	grad_norm 2.4204 (inf)	mem 5329MB
[2022-04-19 02:06:18 tiny] (main.py 233): INFO EPOCH 138 training takes 0:12:22
[2022-04-19 02:06:29 tiny] (main.py 273): INFO Test: [0/49]	Time 11.836 (11.836)	Loss 1.6737 (1.6737)	Acc@1 66.016 (66.016)	Acc@5 89.062 (89.062)	Mem 5329MB
[2022-04-19 02:06:48 tiny] (main.py 279): INFO  * Acc@1 66.022 Acc@5 87.316
[2022-04-19 02:06:48 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 66.0%
[2022-04-19 02:06:48 tiny] (main.py 148): INFO Max accuracy: 66.12%
[2022-04-19 02:07:00 tiny] (main.py 226): INFO Train: [139/300][0/1251]	eta 4:00:33 lr 0.000562	time 11.5378 (11.5378)	loss 2.8382 (2.8382)	grad_norm 3.7390 (3.7390)	mem 5329MB
[2022-04-19 02:08:02 tiny] (main.py 226): INFO Train: [139/300][100/1251]	eta 0:14:00 lr 0.000561	time 0.4923 (0.7306)	loss 4.0225 (3.9350)	grad_norm 4.3701 (3.9915)	mem 5329MB
[2022-04-19 02:09:01 tiny] (main.py 226): INFO Train: [139/300][200/1251]	eta 0:11:32 lr 0.000561	time 0.5656 (0.6590)	loss 2.9965 (4.0022)	grad_norm 3.1000 (4.0206)	mem 5329MB
[2022-04-19 02:09:59 tiny] (main.py 226): INFO Train: [139/300][300/1251]	eta 0:10:02 lr 0.000561	time 0.4518 (0.6334)	loss 4.9294 (3.9977)	grad_norm 4.4631 (4.0219)	mem 5329MB
[2022-04-19 02:10:58 tiny] (main.py 226): INFO Train: [139/300][400/1251]	eta 0:08:49 lr 0.000560	time 0.5747 (0.6220)	loss 3.7765 (4.0069)	grad_norm 4.0575 (4.0017)	mem 5329MB
[2022-04-19 02:11:56 tiny] (main.py 226): INFO Train: [139/300][500/1251]	eta 0:07:41 lr 0.000560	time 0.5503 (0.6147)	loss 3.6531 (4.0126)	grad_norm 5.9144 (4.0073)	mem 5329MB
[2022-04-19 02:12:56 tiny] (main.py 226): INFO Train: [139/300][600/1251]	eta 0:06:37 lr 0.000559	time 0.6668 (0.6108)	loss 4.2350 (4.0081)	grad_norm 4.0880 (3.9957)	mem 5329MB
[2022-04-19 02:13:54 tiny] (main.py 226): INFO Train: [139/300][700/1251]	eta 0:05:34 lr 0.000559	time 0.5408 (0.6075)	loss 4.5821 (4.0103)	grad_norm 3.9435 (3.9703)	mem 5329MB
[2022-04-19 02:14:53 tiny] (main.py 226): INFO Train: [139/300][800/1251]	eta 0:04:32 lr 0.000559	time 0.8544 (0.6046)	loss 3.8933 (4.0001)	grad_norm 4.7475 (3.9617)	mem 5329MB
[2022-04-19 02:15:52 tiny] (main.py 226): INFO Train: [139/300][900/1251]	eta 0:03:31 lr 0.000558	time 0.5633 (0.6029)	loss 4.8022 (3.9953)	grad_norm 2.8504 (3.9386)	mem 5329MB
[2022-04-19 02:16:51 tiny] (main.py 226): INFO Train: [139/300][1000/1251]	eta 0:02:30 lr 0.000558	time 0.6203 (0.6014)	loss 4.3975 (3.9940)	grad_norm 3.1362 (3.9063)	mem 5329MB
[2022-04-19 02:17:49 tiny] (main.py 226): INFO Train: [139/300][1100/1251]	eta 0:01:30 lr 0.000557	time 0.5368 (0.6000)	loss 4.0373 (3.9931)	grad_norm 3.1958 (3.9421)	mem 5329MB
[2022-04-19 02:18:48 tiny] (main.py 226): INFO Train: [139/300][1200/1251]	eta 0:00:30 lr 0.000557	time 0.6154 (0.5989)	loss 4.9451 (3.9937)	grad_norm 2.4057 (3.9149)	mem 5329MB
[2022-04-19 02:19:10 tiny] (main.py 233): INFO EPOCH 139 training takes 0:12:21
[2022-04-19 02:19:22 tiny] (main.py 273): INFO Test: [0/49]	Time 11.839 (11.839)	Loss 1.7737 (1.7737)	Acc@1 65.527 (65.527)	Acc@5 87.207 (87.207)	Mem 5329MB
[2022-04-19 02:19:41 tiny] (main.py 279): INFO  * Acc@1 65.660 Acc@5 87.068
[2022-04-19 02:19:41 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 65.7%
[2022-04-19 02:19:41 tiny] (main.py 148): INFO Max accuracy: 66.12%
[2022-04-19 02:19:53 tiny] (main.py 226): INFO Train: [140/300][0/1251]	eta 4:02:41 lr 0.000557	time 11.6396 (11.6396)	loss 4.7542 (4.7542)	grad_norm 5.4400 (5.4400)	mem 5329MB
[2022-04-19 02:20:55 tiny] (main.py 226): INFO Train: [140/300][100/1251]	eta 0:14:02 lr 0.000556	time 0.6856 (0.7316)	loss 3.4224 (4.0290)	grad_norm 3.1246 (3.8711)	mem 5329MB
[2022-04-19 02:21:53 tiny] (main.py 226): INFO Train: [140/300][200/1251]	eta 0:11:31 lr 0.000556	time 0.5729 (0.6582)	loss 4.1172 (4.0156)	grad_norm 4.8234 (3.7804)	mem 5329MB
[2022-04-19 02:22:52 tiny] (main.py 226): INFO Train: [140/300][300/1251]	eta 0:10:03 lr 0.000556	time 0.6482 (0.6350)	loss 4.2728 (4.0117)	grad_norm 3.2383 (3.8068)	mem 5329MB
[2022-04-19 02:23:51 tiny] (main.py 226): INFO Train: [140/300][400/1251]	eta 0:08:49 lr 0.000555	time 0.7768 (0.6227)	loss 3.8863 (4.0170)	grad_norm 3.4070 (3.8847)	mem 5329MB
[2022-04-19 02:24:49 tiny] (main.py 226): INFO Train: [140/300][500/1251]	eta 0:07:41 lr 0.000555	time 0.7461 (0.6152)	loss 4.0503 (4.0239)	grad_norm 3.1757 (3.9177)	mem 5329MB
[2022-04-19 02:25:48 tiny] (main.py 226): INFO Train: [140/300][600/1251]	eta 0:06:37 lr 0.000554	time 0.5837 (0.6106)	loss 2.8901 (4.0191)	grad_norm 3.6322 (3.9235)	mem 5329MB
[2022-04-19 02:26:47 tiny] (main.py 226): INFO Train: [140/300][700/1251]	eta 0:05:34 lr 0.000554	time 0.5867 (0.6071)	loss 3.9004 (4.0251)	grad_norm 2.8446 (3.9392)	mem 5329MB
[2022-04-19 02:27:45 tiny] (main.py 226): INFO Train: [140/300][800/1251]	eta 0:04:32 lr 0.000553	time 0.6547 (0.6046)	loss 4.6368 (4.0120)	grad_norm 2.7428 (3.8847)	mem 5329MB
[2022-04-19 02:28:44 tiny] (main.py 226): INFO Train: [140/300][900/1251]	eta 0:03:31 lr 0.000553	time 0.5168 (0.6030)	loss 3.5103 (4.0216)	grad_norm 3.1240 (3.8962)	mem 5329MB
[2022-04-19 02:29:43 tiny] (main.py 226): INFO Train: [140/300][1000/1251]	eta 0:02:30 lr 0.000553	time 0.5606 (0.6014)	loss 3.6385 (4.0146)	grad_norm 4.8836 (3.8955)	mem 5329MB
[2022-04-19 02:30:42 tiny] (main.py 226): INFO Train: [140/300][1100/1251]	eta 0:01:30 lr 0.000552	time 0.5997 (0.6004)	loss 4.4159 (4.0151)	grad_norm 3.6065 (3.8944)	mem 5329MB
[2022-04-19 02:31:41 tiny] (main.py 226): INFO Train: [140/300][1200/1251]	eta 0:00:30 lr 0.000552	time 0.4993 (0.5992)	loss 4.4735 (4.0237)	grad_norm 3.1675 (3.9064)	mem 5329MB
[2022-04-19 02:32:03 tiny] (main.py 233): INFO EPOCH 140 training takes 0:12:21
[2022-04-19 02:32:14 tiny] (main.py 273): INFO Test: [0/49]	Time 11.314 (11.314)	Loss 1.8045 (1.8045)	Acc@1 63.965 (63.965)	Acc@5 86.914 (86.914)	Mem 5329MB
[2022-04-19 02:32:34 tiny] (main.py 279): INFO  * Acc@1 65.552 Acc@5 87.254
[2022-04-19 02:32:34 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 65.6%
[2022-04-19 02:32:34 tiny] (main.py 148): INFO Max accuracy: 66.12%
[2022-04-19 02:32:45 tiny] (main.py 226): INFO Train: [141/300][0/1251]	eta 3:56:35 lr 0.000552	time 11.3471 (11.3471)	loss 2.9631 (2.9631)	grad_norm 5.2378 (5.2378)	mem 5329MB
[2022-04-19 02:33:48 tiny] (main.py 226): INFO Train: [141/300][100/1251]	eta 0:14:01 lr 0.000551	time 0.6438 (0.7311)	loss 3.4644 (3.9569)	grad_norm 2.6352 (3.9457)	mem 5329MB
[2022-04-19 02:34:46 tiny] (main.py 226): INFO Train: [141/300][200/1251]	eta 0:11:30 lr 0.000551	time 0.6180 (0.6570)	loss 4.1102 (3.8854)	grad_norm 5.0388 (4.0113)	mem 5329MB
[2022-04-19 02:35:45 tiny] (main.py 226): INFO Train: [141/300][300/1251]	eta 0:10:03 lr 0.000550	time 0.4726 (0.6350)	loss 3.2938 (3.9123)	grad_norm 4.3589 (3.9551)	mem 5329MB
[2022-04-19 02:36:43 tiny] (main.py 226): INFO Train: [141/300][400/1251]	eta 0:08:49 lr 0.000550	time 0.5550 (0.6220)	loss 4.4195 (3.9199)	grad_norm 3.9499 (3.9446)	mem 5329MB
[2022-04-19 02:37:42 tiny] (main.py 226): INFO Train: [141/300][500/1251]	eta 0:07:41 lr 0.000550	time 0.6044 (0.6147)	loss 3.6240 (3.9224)	grad_norm 2.1624 (3.9076)	mem 5329MB
[2022-04-19 02:38:41 tiny] (main.py 226): INFO Train: [141/300][600/1251]	eta 0:06:37 lr 0.000549	time 0.7637 (0.6103)	loss 4.7235 (3.9377)	grad_norm 3.6838 (3.8976)	mem 5329MB
[2022-04-19 02:39:39 tiny] (main.py 226): INFO Train: [141/300][700/1251]	eta 0:05:34 lr 0.000549	time 0.4657 (0.6066)	loss 4.4025 (3.9522)	grad_norm 4.2730 (3.8798)	mem 5329MB
[2022-04-19 02:40:38 tiny] (main.py 226): INFO Train: [141/300][800/1251]	eta 0:04:32 lr 0.000548	time 0.4598 (0.6042)	loss 3.9323 (3.9548)	grad_norm 4.1433 (3.8450)	mem 5329MB
[2022-04-19 02:41:37 tiny] (main.py 226): INFO Train: [141/300][900/1251]	eta 0:03:31 lr 0.000548	time 0.5044 (0.6021)	loss 3.6473 (3.9704)	grad_norm 4.9902 (3.8288)	mem 5329MB
[2022-04-19 02:42:36 tiny] (main.py 226): INFO Train: [141/300][1000/1251]	eta 0:02:30 lr 0.000547	time 0.6107 (0.6015)	loss 4.5612 (3.9814)	grad_norm 6.6188 (3.8386)	mem 5329MB
[2022-04-19 02:43:35 tiny] (main.py 226): INFO Train: [141/300][1100/1251]	eta 0:01:30 lr 0.000547	time 0.5981 (0.5999)	loss 3.7004 (3.9947)	grad_norm 3.9287 (3.8482)	mem 5329MB
[2022-04-19 02:44:34 tiny] (main.py 226): INFO Train: [141/300][1200/1251]	eta 0:00:30 lr 0.000547	time 0.5231 (0.5992)	loss 3.7720 (4.0040)	grad_norm 4.0509 (3.8852)	mem 5329MB
[2022-04-19 02:44:56 tiny] (main.py 233): INFO EPOCH 141 training takes 0:12:21
[2022-04-19 02:45:07 tiny] (main.py 273): INFO Test: [0/49]	Time 10.835 (10.835)	Loss 1.5077 (1.5077)	Acc@1 67.676 (67.676)	Acc@5 89.844 (89.844)	Mem 5329MB
[2022-04-19 02:45:27 tiny] (main.py 279): INFO  * Acc@1 66.368 Acc@5 87.528
[2022-04-19 02:45:27 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 66.4%
[2022-04-19 02:45:27 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_141.pth saving......
[2022-04-19 02:45:27 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_141.pth saved !!!
[2022-04-19 02:45:27 tiny] (main.py 148): INFO Max accuracy: 66.37%
[2022-04-19 02:45:38 tiny] (main.py 226): INFO Train: [142/300][0/1251]	eta 3:59:32 lr 0.000546	time 11.4884 (11.4884)	loss 2.9715 (2.9715)	grad_norm 4.4918 (4.4918)	mem 5329MB
[2022-04-19 02:46:40 tiny] (main.py 226): INFO Train: [142/300][100/1251]	eta 0:13:54 lr 0.000546	time 0.5624 (0.7247)	loss 4.0348 (3.9631)	grad_norm 4.0290 (3.5513)	mem 5329MB
[2022-04-19 02:47:39 tiny] (main.py 226): INFO Train: [142/300][200/1251]	eta 0:11:29 lr 0.000546	time 0.5047 (0.6562)	loss 4.2302 (3.9478)	grad_norm 5.7391 (3.8085)	mem 5329MB
[2022-04-19 02:48:37 tiny] (main.py 226): INFO Train: [142/300][300/1251]	eta 0:10:01 lr 0.000545	time 0.4774 (0.6320)	loss 3.9626 (3.9672)	grad_norm 2.7124 (3.6986)	mem 5329MB
[2022-04-19 02:49:36 tiny] (main.py 226): INFO Train: [142/300][400/1251]	eta 0:08:48 lr 0.000545	time 0.7305 (0.6208)	loss 4.4742 (3.9544)	grad_norm 3.6401 (inf)	mem 5329MB
[2022-04-19 02:50:35 tiny] (main.py 226): INFO Train: [142/300][500/1251]	eta 0:07:40 lr 0.000544	time 0.6329 (0.6138)	loss 3.7932 (3.9607)	grad_norm 4.2590 (inf)	mem 5329MB
[2022-04-19 02:51:34 tiny] (main.py 226): INFO Train: [142/300][600/1251]	eta 0:06:37 lr 0.000544	time 0.6037 (0.6100)	loss 4.4116 (3.9558)	grad_norm 3.0656 (inf)	mem 5329MB
[2022-04-19 02:52:32 tiny] (main.py 226): INFO Train: [142/300][700/1251]	eta 0:05:34 lr 0.000544	time 0.5952 (0.6069)	loss 3.5853 (3.9600)	grad_norm 3.0232 (inf)	mem 5329MB
[2022-04-19 02:53:31 tiny] (main.py 226): INFO Train: [142/300][800/1251]	eta 0:04:32 lr 0.000543	time 0.5310 (0.6045)	loss 4.2782 (3.9667)	grad_norm 4.5710 (inf)	mem 5329MB
[2022-04-19 02:54:30 tiny] (main.py 226): INFO Train: [142/300][900/1251]	eta 0:03:31 lr 0.000543	time 0.5075 (0.6025)	loss 3.8430 (3.9797)	grad_norm 3.0784 (inf)	mem 5329MB
[2022-04-19 02:55:29 tiny] (main.py 226): INFO Train: [142/300][1000/1251]	eta 0:02:30 lr 0.000542	time 0.4429 (0.6011)	loss 4.1115 (3.9861)	grad_norm 2.8787 (inf)	mem 5329MB
[2022-04-19 02:56:27 tiny] (main.py 226): INFO Train: [142/300][1100/1251]	eta 0:01:30 lr 0.000542	time 0.5099 (0.5996)	loss 4.3963 (3.9842)	grad_norm 3.7002 (inf)	mem 5329MB
[2022-04-19 02:57:26 tiny] (main.py 226): INFO Train: [142/300][1200/1251]	eta 0:00:30 lr 0.000541	time 0.5356 (0.5988)	loss 2.6325 (3.9809)	grad_norm 5.7536 (inf)	mem 5329MB
[2022-04-19 02:57:48 tiny] (main.py 233): INFO EPOCH 142 training takes 0:12:21
[2022-04-19 02:58:00 tiny] (main.py 273): INFO Test: [0/49]	Time 12.363 (12.363)	Loss 1.6937 (1.6937)	Acc@1 65.723 (65.723)	Acc@5 87.598 (87.598)	Mem 5329MB
[2022-04-19 02:58:19 tiny] (main.py 279): INFO  * Acc@1 65.994 Acc@5 87.242
[2022-04-19 02:58:19 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 66.0%
[2022-04-19 02:58:19 tiny] (main.py 148): INFO Max accuracy: 66.37%
[2022-04-19 02:58:31 tiny] (main.py 226): INFO Train: [143/300][0/1251]	eta 4:00:28 lr 0.000541	time 11.5332 (11.5332)	loss 3.4670 (3.4670)	grad_norm 4.2971 (4.2971)	mem 5329MB
[2022-04-19 02:59:33 tiny] (main.py 226): INFO Train: [143/300][100/1251]	eta 0:13:59 lr 0.000541	time 0.6836 (0.7295)	loss 4.1309 (4.0462)	grad_norm 9.2609 (3.9087)	mem 5329MB
[2022-04-19 03:00:32 tiny] (main.py 226): INFO Train: [143/300][200/1251]	eta 0:11:32 lr 0.000540	time 0.6867 (0.6593)	loss 3.3172 (4.0201)	grad_norm 3.6484 (4.0734)	mem 5329MB
[2022-04-19 03:01:30 tiny] (main.py 226): INFO Train: [143/300][300/1251]	eta 0:10:02 lr 0.000540	time 0.5827 (0.6334)	loss 3.8787 (3.9942)	grad_norm 6.6800 (3.9278)	mem 5329MB
[2022-04-19 03:02:29 tiny] (main.py 226): INFO Train: [143/300][400/1251]	eta 0:08:49 lr 0.000540	time 0.9776 (0.6224)	loss 4.8929 (3.9844)	grad_norm 5.0520 (3.9117)	mem 5329MB
[2022-04-19 03:03:27 tiny] (main.py 226): INFO Train: [143/300][500/1251]	eta 0:07:41 lr 0.000539	time 0.7158 (0.6146)	loss 4.2378 (3.9656)	grad_norm 2.9825 (3.8936)	mem 5329MB
[2022-04-19 03:04:26 tiny] (main.py 226): INFO Train: [143/300][600/1251]	eta 0:06:37 lr 0.000539	time 0.6210 (0.6098)	loss 4.4296 (3.9795)	grad_norm 3.9082 (3.9107)	mem 5329MB
[2022-04-19 03:05:25 tiny] (main.py 226): INFO Train: [143/300][700/1251]	eta 0:05:34 lr 0.000538	time 0.6988 (0.6072)	loss 4.4023 (3.9664)	grad_norm 4.4573 (3.8958)	mem 5329MB
[2022-04-19 03:06:24 tiny] (main.py 226): INFO Train: [143/300][800/1251]	eta 0:04:32 lr 0.000538	time 0.5363 (0.6048)	loss 4.4038 (3.9533)	grad_norm 3.6790 (3.9004)	mem 5329MB
[2022-04-19 03:07:22 tiny] (main.py 226): INFO Train: [143/300][900/1251]	eta 0:03:31 lr 0.000538	time 0.5009 (0.6028)	loss 4.6078 (3.9602)	grad_norm 3.6246 (3.9305)	mem 5329MB
[2022-04-19 03:08:21 tiny] (main.py 226): INFO Train: [143/300][1000/1251]	eta 0:02:30 lr 0.000537	time 0.4978 (0.6015)	loss 2.7582 (3.9574)	grad_norm 3.5802 (3.9905)	mem 5329MB
[2022-04-19 03:09:20 tiny] (main.py 226): INFO Train: [143/300][1100/1251]	eta 0:01:30 lr 0.000537	time 0.7445 (0.6000)	loss 4.3001 (3.9553)	grad_norm 2.2207 (3.9509)	mem 5329MB
[2022-04-19 03:10:19 tiny] (main.py 226): INFO Train: [143/300][1200/1251]	eta 0:00:30 lr 0.000536	time 0.3980 (0.5990)	loss 4.8010 (3.9638)	grad_norm 3.0459 (nan)	mem 5329MB
[2022-04-19 03:10:41 tiny] (main.py 233): INFO EPOCH 143 training takes 0:12:21
[2022-04-19 03:10:52 tiny] (main.py 273): INFO Test: [0/49]	Time 11.585 (11.585)	Loss 1.6975 (1.6975)	Acc@1 64.746 (64.746)	Acc@5 88.086 (88.086)	Mem 5329MB
[2022-04-19 03:11:12 tiny] (main.py 279): INFO  * Acc@1 66.470 Acc@5 87.650
[2022-04-19 03:11:12 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 66.5%
[2022-04-19 03:11:12 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_143.pth saving......
[2022-04-19 03:11:12 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_143.pth saved !!!
[2022-04-19 03:11:12 tiny] (main.py 148): INFO Max accuracy: 66.47%
[2022-04-19 03:11:23 tiny] (main.py 226): INFO Train: [144/300][0/1251]	eta 3:53:44 lr 0.000536	time 11.2110 (11.2110)	loss 4.1034 (4.1034)	grad_norm 2.4985 (2.4985)	mem 5329MB
[2022-04-19 03:12:25 tiny] (main.py 226): INFO Train: [144/300][100/1251]	eta 0:13:52 lr 0.000536	time 0.6375 (0.7236)	loss 4.5538 (3.9304)	grad_norm 2.6515 (3.8070)	mem 5329MB
[2022-04-19 03:13:24 tiny] (main.py 226): INFO Train: [144/300][200/1251]	eta 0:11:28 lr 0.000535	time 0.4616 (0.6546)	loss 3.9051 (3.9033)	grad_norm 4.2780 (3.8969)	mem 5329MB
[2022-04-19 03:14:22 tiny] (main.py 226): INFO Train: [144/300][300/1251]	eta 0:10:01 lr 0.000535	time 0.6462 (0.6321)	loss 4.1397 (3.9227)	grad_norm 5.7801 (3.9613)	mem 5329MB
[2022-04-19 03:15:20 tiny] (main.py 226): INFO Train: [144/300][400/1251]	eta 0:08:46 lr 0.000534	time 0.4563 (0.6191)	loss 4.5500 (3.9409)	grad_norm 4.6731 (3.8850)	mem 5329MB
[2022-04-19 03:16:19 tiny] (main.py 226): INFO Train: [144/300][500/1251]	eta 0:07:40 lr 0.000534	time 0.6279 (0.6127)	loss 3.4317 (3.9460)	grad_norm 3.0125 (3.8970)	mem 5329MB
[2022-04-19 03:17:18 tiny] (main.py 226): INFO Train: [144/300][600/1251]	eta 0:06:35 lr 0.000534	time 0.5109 (0.6082)	loss 3.6933 (3.9648)	grad_norm 2.8665 (3.9351)	mem 5329MB
[2022-04-19 03:18:16 tiny] (main.py 226): INFO Train: [144/300][700/1251]	eta 0:05:33 lr 0.000533	time 0.4639 (0.6050)	loss 4.1092 (3.9556)	grad_norm 3.1995 (3.9496)	mem 5329MB
[2022-04-19 03:19:15 tiny] (main.py 226): INFO Train: [144/300][800/1251]	eta 0:04:32 lr 0.000533	time 0.4688 (0.6035)	loss 4.5806 (3.9601)	grad_norm 2.1851 (3.9475)	mem 5329MB
[2022-04-19 03:20:14 tiny] (main.py 226): INFO Train: [144/300][900/1251]	eta 0:03:31 lr 0.000532	time 0.9322 (0.6020)	loss 4.6676 (3.9570)	grad_norm 5.5478 (3.9182)	mem 5329MB
[2022-04-19 03:21:14 tiny] (main.py 226): INFO Train: [144/300][1000/1251]	eta 0:02:30 lr 0.000532	time 0.5234 (0.6010)	loss 4.1942 (3.9559)	grad_norm 4.2536 (3.9126)	mem 5329MB
[2022-04-19 03:22:13 tiny] (main.py 226): INFO Train: [144/300][1100/1251]	eta 0:01:30 lr 0.000532	time 0.5619 (0.5999)	loss 3.7325 (3.9612)	grad_norm 4.9426 (3.9154)	mem 5329MB
[2022-04-19 03:23:12 tiny] (main.py 226): INFO Train: [144/300][1200/1251]	eta 0:00:30 lr 0.000531	time 0.5688 (0.5991)	loss 4.7485 (3.9647)	grad_norm 5.7579 (3.9046)	mem 5329MB
[2022-04-19 03:23:33 tiny] (main.py 233): INFO EPOCH 144 training takes 0:12:21
[2022-04-19 03:23:46 tiny] (main.py 273): INFO Test: [0/49]	Time 12.567 (12.567)	Loss 1.7524 (1.7524)	Acc@1 64.746 (64.746)	Acc@5 86.230 (86.230)	Mem 5329MB
[2022-04-19 03:24:04 tiny] (main.py 279): INFO  * Acc@1 66.406 Acc@5 87.488
[2022-04-19 03:24:04 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 66.4%
[2022-04-19 03:24:04 tiny] (main.py 148): INFO Max accuracy: 66.47%
[2022-04-19 03:24:15 tiny] (main.py 226): INFO Train: [145/300][0/1251]	eta 3:47:04 lr 0.000531	time 10.8910 (10.8910)	loss 3.1855 (3.1855)	grad_norm 2.4497 (2.4497)	mem 5329MB
[2022-04-19 03:25:18 tiny] (main.py 226): INFO Train: [145/300][100/1251]	eta 0:13:59 lr 0.000530	time 0.5440 (0.7294)	loss 3.2169 (3.9561)	grad_norm 3.4889 (4.3109)	mem 5329MB
[2022-04-19 03:26:16 tiny] (main.py 226): INFO Train: [145/300][200/1251]	eta 0:11:31 lr 0.000530	time 0.4774 (0.6579)	loss 3.2186 (4.0022)	grad_norm 3.0639 (4.1813)	mem 5329MB
[2022-04-19 03:27:16 tiny] (main.py 226): INFO Train: [145/300][300/1251]	eta 0:10:04 lr 0.000530	time 0.6769 (0.6355)	loss 4.6469 (4.0239)	grad_norm 4.2537 (4.2824)	mem 5329MB
[2022-04-19 03:28:14 tiny] (main.py 226): INFO Train: [145/300][400/1251]	eta 0:08:51 lr 0.000529	time 0.4484 (0.6240)	loss 4.1432 (4.0203)	grad_norm 3.1471 (4.1805)	mem 5329MB
[2022-04-19 03:29:13 tiny] (main.py 226): INFO Train: [145/300][500/1251]	eta 0:07:42 lr 0.000529	time 0.5798 (0.6156)	loss 3.4454 (3.9988)	grad_norm 3.5429 (4.1211)	mem 5329MB
[2022-04-19 03:30:12 tiny] (main.py 226): INFO Train: [145/300][600/1251]	eta 0:06:38 lr 0.000528	time 0.5517 (0.6118)	loss 4.4447 (4.0040)	grad_norm 2.7367 (4.1038)	mem 5329MB
[2022-04-19 03:31:11 tiny] (main.py 226): INFO Train: [145/300][700/1251]	eta 0:05:35 lr 0.000528	time 0.5594 (0.6083)	loss 4.1470 (3.9999)	grad_norm 5.6897 (4.0894)	mem 5329MB
[2022-04-19 03:32:10 tiny] (main.py 226): INFO Train: [145/300][800/1251]	eta 0:04:33 lr 0.000528	time 0.6492 (0.6064)	loss 2.9654 (3.9965)	grad_norm 8.4468 (inf)	mem 5329MB
[2022-04-19 03:33:09 tiny] (main.py 226): INFO Train: [145/300][900/1251]	eta 0:03:32 lr 0.000527	time 0.5110 (0.6042)	loss 4.2911 (3.9896)	grad_norm 2.9459 (inf)	mem 5329MB
[2022-04-19 03:34:07 tiny] (main.py 226): INFO Train: [145/300][1000/1251]	eta 0:02:31 lr 0.000527	time 0.5989 (0.6025)	loss 3.2243 (3.9857)	grad_norm 3.7398 (inf)	mem 5329MB
[2022-04-19 03:35:06 tiny] (main.py 226): INFO Train: [145/300][1100/1251]	eta 0:01:30 lr 0.000526	time 0.6775 (0.6006)	loss 4.4079 (3.9818)	grad_norm 4.3462 (inf)	mem 5329MB
[2022-04-19 03:36:05 tiny] (main.py 226): INFO Train: [145/300][1200/1251]	eta 0:00:30 lr 0.000526	time 0.6508 (0.5999)	loss 4.6352 (3.9852)	grad_norm 4.8656 (inf)	mem 5329MB
[2022-04-19 03:36:26 tiny] (main.py 233): INFO EPOCH 145 training takes 0:12:21
[2022-04-19 03:36:39 tiny] (main.py 273): INFO Test: [0/49]	Time 12.860 (12.860)	Loss 1.6680 (1.6680)	Acc@1 66.504 (66.504)	Acc@5 88.281 (88.281)	Mem 5329MB
[2022-04-19 03:36:58 tiny] (main.py 279): INFO  * Acc@1 66.240 Acc@5 87.472
[2022-04-19 03:36:58 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 66.2%
[2022-04-19 03:36:58 tiny] (main.py 148): INFO Max accuracy: 66.47%
[2022-04-19 03:37:11 tiny] (main.py 226): INFO Train: [146/300][0/1251]	eta 4:12:27 lr 0.000526	time 12.1084 (12.1084)	loss 4.8468 (4.8468)	grad_norm 3.3057 (3.3057)	mem 5329MB
[2022-04-19 03:38:12 tiny] (main.py 226): INFO Train: [146/300][100/1251]	eta 0:13:56 lr 0.000525	time 0.6110 (0.7272)	loss 2.7431 (3.8974)	grad_norm 3.5201 (3.9536)	mem 5329MB
[2022-04-19 03:39:11 tiny] (main.py 226): INFO Train: [146/300][200/1251]	eta 0:11:30 lr 0.000525	time 0.5135 (0.6570)	loss 2.6471 (3.9201)	grad_norm 3.1968 (3.9749)	mem 5329MB
[2022-04-19 03:40:09 tiny] (main.py 226): INFO Train: [146/300][300/1251]	eta 0:10:00 lr 0.000524	time 0.4112 (0.6315)	loss 3.3452 (3.9297)	grad_norm 4.1081 (3.9533)	mem 5329MB
[2022-04-19 03:41:07 tiny] (main.py 226): INFO Train: [146/300][400/1251]	eta 0:08:47 lr 0.000524	time 0.4564 (0.6200)	loss 4.9779 (3.9383)	grad_norm 4.4373 (3.9140)	mem 5329MB
[2022-04-19 03:42:06 tiny] (main.py 226): INFO Train: [146/300][500/1251]	eta 0:07:41 lr 0.000524	time 0.6213 (0.6141)	loss 2.8972 (3.9581)	grad_norm 4.3203 (3.9889)	mem 5329MB
[2022-04-19 03:43:05 tiny] (main.py 226): INFO Train: [146/300][600/1251]	eta 0:06:36 lr 0.000523	time 0.4201 (0.6096)	loss 4.6756 (3.9594)	grad_norm 4.8274 (4.0109)	mem 5329MB
[2022-04-19 03:44:04 tiny] (main.py 226): INFO Train: [146/300][700/1251]	eta 0:05:34 lr 0.000523	time 0.6347 (0.6068)	loss 2.8509 (3.9596)	grad_norm 3.5460 (3.9764)	mem 5329MB
[2022-04-19 03:45:02 tiny] (main.py 226): INFO Train: [146/300][800/1251]	eta 0:04:32 lr 0.000522	time 0.6142 (0.6039)	loss 4.2334 (3.9599)	grad_norm 4.6717 (3.9825)	mem 5329MB
[2022-04-19 03:46:01 tiny] (main.py 226): INFO Train: [146/300][900/1251]	eta 0:03:31 lr 0.000522	time 0.7779 (0.6025)	loss 3.3413 (3.9603)	grad_norm 5.6244 (3.9600)	mem 5329MB
[2022-04-19 03:47:00 tiny] (main.py 226): INFO Train: [146/300][1000/1251]	eta 0:02:30 lr 0.000522	time 0.5651 (0.6013)	loss 4.2850 (3.9644)	grad_norm 4.8396 (3.9669)	mem 5329MB
[2022-04-19 03:47:59 tiny] (main.py 226): INFO Train: [146/300][1100/1251]	eta 0:01:30 lr 0.000521	time 0.8131 (0.6001)	loss 2.6977 (3.9642)	grad_norm 3.8280 (3.9745)	mem 5329MB
[2022-04-19 03:48:58 tiny] (main.py 226): INFO Train: [146/300][1200/1251]	eta 0:00:30 lr 0.000521	time 0.7259 (0.5988)	loss 5.0516 (3.9672)	grad_norm 8.3906 (3.9753)	mem 5329MB
[2022-04-19 03:49:19 tiny] (main.py 233): INFO EPOCH 146 training takes 0:12:20
[2022-04-19 03:49:31 tiny] (main.py 273): INFO Test: [0/49]	Time 12.071 (12.071)	Loss 1.7847 (1.7847)	Acc@1 63.867 (63.867)	Acc@5 87.207 (87.207)	Mem 5329MB
[2022-04-19 03:49:50 tiny] (main.py 279): INFO  * Acc@1 66.266 Acc@5 87.624
[2022-04-19 03:49:50 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 66.3%
[2022-04-19 03:49:50 tiny] (main.py 148): INFO Max accuracy: 66.47%
[2022-04-19 03:50:02 tiny] (main.py 226): INFO Train: [147/300][0/1251]	eta 4:09:52 lr 0.000521	time 11.9844 (11.9844)	loss 4.2341 (4.2341)	grad_norm 3.7582 (3.7582)	mem 5329MB
[2022-04-19 03:51:04 tiny] (main.py 226): INFO Train: [147/300][100/1251]	eta 0:13:58 lr 0.000520	time 0.7040 (0.7281)	loss 4.3371 (3.9903)	grad_norm 2.7579 (3.7546)	mem 5329MB
[2022-04-19 03:52:02 tiny] (main.py 226): INFO Train: [147/300][200/1251]	eta 0:11:30 lr 0.000520	time 0.6205 (0.6567)	loss 3.5818 (3.9556)	grad_norm 2.8780 (3.9658)	mem 5329MB
[2022-04-19 03:53:01 tiny] (main.py 226): INFO Train: [147/300][300/1251]	eta 0:10:02 lr 0.000519	time 0.8546 (0.6337)	loss 3.9496 (3.9435)	grad_norm 6.0017 (3.8927)	mem 5329MB
[2022-04-19 03:54:00 tiny] (main.py 226): INFO Train: [147/300][400/1251]	eta 0:08:49 lr 0.000519	time 0.6156 (0.6224)	loss 2.8516 (3.9295)	grad_norm 3.6180 (3.8500)	mem 5329MB
[2022-04-19 03:54:58 tiny] (main.py 226): INFO Train: [147/300][500/1251]	eta 0:07:41 lr 0.000518	time 0.5030 (0.6143)	loss 3.9131 (3.9498)	grad_norm 3.5490 (inf)	mem 5329MB
[2022-04-19 03:55:57 tiny] (main.py 226): INFO Train: [147/300][600/1251]	eta 0:06:37 lr 0.000518	time 0.6106 (0.6102)	loss 2.9632 (3.9600)	grad_norm 2.6682 (inf)	mem 5329MB
[2022-04-19 03:56:56 tiny] (main.py 226): INFO Train: [147/300][700/1251]	eta 0:05:34 lr 0.000518	time 0.4716 (0.6068)	loss 4.7226 (3.9514)	grad_norm 5.7518 (inf)	mem 5329MB
[2022-04-19 03:57:55 tiny] (main.py 226): INFO Train: [147/300][800/1251]	eta 0:04:32 lr 0.000517	time 0.4853 (0.6045)	loss 4.6437 (3.9730)	grad_norm 4.4901 (inf)	mem 5329MB
[2022-04-19 03:58:53 tiny] (main.py 226): INFO Train: [147/300][900/1251]	eta 0:03:31 lr 0.000517	time 0.4573 (0.6026)	loss 4.4530 (3.9799)	grad_norm 7.1241 (inf)	mem 5329MB
[2022-04-19 03:59:52 tiny] (main.py 226): INFO Train: [147/300][1000/1251]	eta 0:02:30 lr 0.000516	time 0.5389 (0.6014)	loss 3.3109 (3.9718)	grad_norm 3.2663 (inf)	mem 5329MB
[2022-04-19 04:00:51 tiny] (main.py 226): INFO Train: [147/300][1100/1251]	eta 0:01:30 lr 0.000516	time 0.5307 (0.5999)	loss 4.2216 (3.9713)	grad_norm 2.4427 (inf)	mem 5329MB
[2022-04-19 04:01:49 tiny] (main.py 226): INFO Train: [147/300][1200/1251]	eta 0:00:30 lr 0.000516	time 0.4201 (0.5985)	loss 3.7201 (3.9729)	grad_norm 2.8629 (inf)	mem 5329MB
[2022-04-19 04:02:11 tiny] (main.py 233): INFO EPOCH 147 training takes 0:12:20
[2022-04-19 04:02:24 tiny] (main.py 273): INFO Test: [0/49]	Time 12.741 (12.741)	Loss 1.6040 (1.6040)	Acc@1 67.773 (67.773)	Acc@5 88.672 (88.672)	Mem 5329MB
[2022-04-19 04:02:42 tiny] (main.py 279): INFO  * Acc@1 66.288 Acc@5 87.656
[2022-04-19 04:02:42 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 66.3%
[2022-04-19 04:02:42 tiny] (main.py 148): INFO Max accuracy: 66.47%
[2022-04-19 04:02:54 tiny] (main.py 226): INFO Train: [148/300][0/1251]	eta 4:11:49 lr 0.000515	time 12.0778 (12.0778)	loss 3.9183 (3.9183)	grad_norm 6.3014 (6.3014)	mem 5329MB
[2022-04-19 04:03:56 tiny] (main.py 226): INFO Train: [148/300][100/1251]	eta 0:14:05 lr 0.000515	time 0.5184 (0.7344)	loss 2.8191 (4.0022)	grad_norm 2.7770 (4.2334)	mem 5329MB
[2022-04-19 04:04:54 tiny] (main.py 226): INFO Train: [148/300][200/1251]	eta 0:11:31 lr 0.000515	time 0.6424 (0.6579)	loss 4.3090 (3.9388)	grad_norm 3.1968 (4.0289)	mem 5329MB
[2022-04-19 04:05:53 tiny] (main.py 226): INFO Train: [148/300][300/1251]	eta 0:10:03 lr 0.000514	time 0.5216 (0.6348)	loss 4.3384 (3.9325)	grad_norm 2.9240 (4.0755)	mem 5329MB
[2022-04-19 04:06:51 tiny] (main.py 226): INFO Train: [148/300][400/1251]	eta 0:08:49 lr 0.000514	time 0.6315 (0.6217)	loss 4.8413 (3.9594)	grad_norm 3.5063 (4.0462)	mem 5329MB
[2022-04-19 04:07:50 tiny] (main.py 226): INFO Train: [148/300][500/1251]	eta 0:07:41 lr 0.000513	time 0.5238 (0.6142)	loss 3.8704 (3.9572)	grad_norm 2.3070 (3.9893)	mem 5329MB
[2022-04-19 04:08:49 tiny] (main.py 226): INFO Train: [148/300][600/1251]	eta 0:06:37 lr 0.000513	time 0.6118 (0.6100)	loss 4.7442 (3.9762)	grad_norm 2.6815 (4.0231)	mem 5329MB
[2022-04-19 04:09:48 tiny] (main.py 226): INFO Train: [148/300][700/1251]	eta 0:05:34 lr 0.000512	time 0.3593 (0.6072)	loss 4.2755 (3.9742)	grad_norm 2.8529 (4.0096)	mem 5329MB
[2022-04-19 04:10:46 tiny] (main.py 226): INFO Train: [148/300][800/1251]	eta 0:04:32 lr 0.000512	time 0.7059 (0.6047)	loss 4.3905 (3.9671)	grad_norm 2.8948 (3.9813)	mem 5329MB
[2022-04-19 04:11:45 tiny] (main.py 226): INFO Train: [148/300][900/1251]	eta 0:03:31 lr 0.000512	time 0.7311 (0.6031)	loss 3.6788 (3.9753)	grad_norm 3.4696 (4.0217)	mem 5329MB
[2022-04-19 04:12:44 tiny] (main.py 226): INFO Train: [148/300][1000/1251]	eta 0:02:30 lr 0.000511	time 0.4197 (0.6014)	loss 2.7080 (3.9837)	grad_norm 5.0219 (4.0052)	mem 5329MB
[2022-04-19 04:13:43 tiny] (main.py 226): INFO Train: [148/300][1100/1251]	eta 0:01:30 lr 0.000511	time 0.6077 (0.6003)	loss 4.3553 (3.9861)	grad_norm 5.2872 (3.9987)	mem 5329MB
[2022-04-19 04:14:42 tiny] (main.py 226): INFO Train: [148/300][1200/1251]	eta 0:00:30 lr 0.000510	time 0.5776 (0.5994)	loss 4.2276 (3.9861)	grad_norm 3.1859 (3.9980)	mem 5329MB
[2022-04-19 04:15:04 tiny] (main.py 233): INFO EPOCH 148 training takes 0:12:21
[2022-04-19 04:15:16 tiny] (main.py 273): INFO Test: [0/49]	Time 12.461 (12.461)	Loss 1.5709 (1.5709)	Acc@1 69.238 (69.238)	Acc@5 87.793 (87.793)	Mem 5329MB
[2022-04-19 04:15:36 tiny] (main.py 279): INFO  * Acc@1 66.386 Acc@5 87.656
[2022-04-19 04:15:36 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 66.4%
[2022-04-19 04:15:36 tiny] (main.py 148): INFO Max accuracy: 66.47%
[2022-04-19 04:15:48 tiny] (main.py 226): INFO Train: [149/300][0/1251]	eta 4:10:49 lr 0.000510	time 12.0303 (12.0303)	loss 4.3731 (4.3731)	grad_norm 5.6135 (5.6135)	mem 5329MB
[2022-04-19 04:16:49 tiny] (main.py 226): INFO Train: [149/300][100/1251]	eta 0:13:58 lr 0.000510	time 0.5687 (0.7282)	loss 4.2139 (3.9521)	grad_norm 3.5767 (4.1719)	mem 5329MB
[2022-04-19 04:17:47 tiny] (main.py 226): INFO Train: [149/300][200/1251]	eta 0:11:27 lr 0.000509	time 0.4940 (0.6540)	loss 3.7479 (3.9802)	grad_norm 3.9266 (4.1236)	mem 5329MB
[2022-04-19 04:18:46 tiny] (main.py 226): INFO Train: [149/300][300/1251]	eta 0:10:01 lr 0.000509	time 0.6879 (0.6323)	loss 3.4904 (4.0008)	grad_norm 3.5051 (4.1212)	mem 5329MB
[2022-04-19 04:19:44 tiny] (main.py 226): INFO Train: [149/300][400/1251]	eta 0:08:48 lr 0.000509	time 0.7807 (0.6206)	loss 4.3870 (4.0035)	grad_norm 10.1453 (4.1090)	mem 5329MB
[2022-04-19 04:20:43 tiny] (main.py 226): INFO Train: [149/300][500/1251]	eta 0:07:40 lr 0.000508	time 0.6326 (0.6131)	loss 4.8076 (4.0043)	grad_norm 3.4879 (4.0554)	mem 5329MB
[2022-04-19 04:21:42 tiny] (main.py 226): INFO Train: [149/300][600/1251]	eta 0:06:36 lr 0.000508	time 0.6620 (0.6090)	loss 3.7929 (3.9945)	grad_norm 3.7633 (3.9973)	mem 5329MB
[2022-04-19 04:22:40 tiny] (main.py 226): INFO Train: [149/300][700/1251]	eta 0:05:33 lr 0.000507	time 0.6194 (0.6061)	loss 3.1729 (3.9839)	grad_norm 4.1267 (4.0865)	mem 5329MB
[2022-04-19 04:23:40 tiny] (main.py 226): INFO Train: [149/300][800/1251]	eta 0:04:32 lr 0.000507	time 0.6253 (0.6043)	loss 4.0089 (3.9704)	grad_norm 3.2138 (4.0975)	mem 5329MB
[2022-04-19 04:24:38 tiny] (main.py 226): INFO Train: [149/300][900/1251]	eta 0:03:31 lr 0.000506	time 0.6057 (0.6025)	loss 4.2644 (3.9650)	grad_norm 8.5690 (4.0821)	mem 5329MB
[2022-04-19 04:25:37 tiny] (main.py 226): INFO Train: [149/300][1000/1251]	eta 0:02:30 lr 0.000506	time 0.6210 (0.6012)	loss 3.4335 (3.9706)	grad_norm 2.3359 (nan)	mem 5329MB
[2022-04-19 04:26:36 tiny] (main.py 226): INFO Train: [149/300][1100/1251]	eta 0:01:30 lr 0.000506	time 0.6674 (0.6003)	loss 3.7311 (3.9682)	grad_norm 3.0843 (nan)	mem 5329MB
[2022-04-19 04:27:35 tiny] (main.py 226): INFO Train: [149/300][1200/1251]	eta 0:00:30 lr 0.000505	time 0.5946 (0.5991)	loss 3.7678 (3.9655)	grad_norm 4.1458 (nan)	mem 5329MB
[2022-04-19 04:27:57 tiny] (main.py 233): INFO EPOCH 149 training takes 0:12:21
[2022-04-19 04:28:10 tiny] (main.py 273): INFO Test: [0/49]	Time 12.674 (12.674)	Loss 1.6461 (1.6461)	Acc@1 65.039 (65.039)	Acc@5 89.062 (89.062)	Mem 5329MB
[2022-04-19 04:28:29 tiny] (main.py 279): INFO  * Acc@1 67.194 Acc@5 88.200
[2022-04-19 04:28:29 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 67.2%
[2022-04-19 04:28:29 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_149.pth saving......
[2022-04-19 04:28:29 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_149.pth saved !!!
[2022-04-19 04:28:29 tiny] (main.py 148): INFO Max accuracy: 67.19%
[2022-04-19 04:28:40 tiny] (main.py 226): INFO Train: [150/300][0/1251]	eta 3:56:06 lr 0.000505	time 11.3243 (11.3243)	loss 4.3988 (4.3988)	grad_norm 3.3599 (3.3599)	mem 5329MB
[2022-04-19 04:29:42 tiny] (main.py 226): INFO Train: [150/300][100/1251]	eta 0:13:56 lr 0.000505	time 0.6476 (0.7269)	loss 2.9633 (4.0097)	grad_norm 4.3479 (4.2136)	mem 5329MB
[2022-04-19 04:30:41 tiny] (main.py 226): INFO Train: [150/300][200/1251]	eta 0:11:30 lr 0.000504	time 0.4856 (0.6569)	loss 3.4871 (3.9760)	grad_norm 6.2237 (4.4215)	mem 5329MB
[2022-04-19 04:31:39 tiny] (main.py 226): INFO Train: [150/300][300/1251]	eta 0:10:02 lr 0.000504	time 0.6400 (0.6332)	loss 4.4648 (3.9539)	grad_norm 2.7587 (4.3415)	mem 5329MB
[2022-04-19 04:32:38 tiny] (main.py 226): INFO Train: [150/300][400/1251]	eta 0:08:49 lr 0.000503	time 0.6943 (0.6217)	loss 3.0386 (3.9412)	grad_norm 4.0517 (4.2529)	mem 5329MB
[2022-04-19 04:33:37 tiny] (main.py 226): INFO Train: [150/300][500/1251]	eta 0:07:41 lr 0.000503	time 0.4895 (0.6145)	loss 4.5893 (3.9171)	grad_norm 5.9434 (4.2415)	mem 5329MB
[2022-04-19 04:34:36 tiny] (main.py 226): INFO Train: [150/300][600/1251]	eta 0:06:37 lr 0.000503	time 0.6627 (0.6109)	loss 2.9544 (3.9251)	grad_norm 4.5929 (4.2036)	mem 5329MB
[2022-04-19 04:35:35 tiny] (main.py 226): INFO Train: [150/300][700/1251]	eta 0:05:35 lr 0.000502	time 0.7348 (0.6081)	loss 3.5875 (3.9378)	grad_norm 3.1563 (4.1334)	mem 5329MB
[2022-04-19 04:36:34 tiny] (main.py 226): INFO Train: [150/300][800/1251]	eta 0:04:33 lr 0.000502	time 0.5931 (0.6054)	loss 3.1330 (3.9425)	grad_norm 2.3162 (4.1434)	mem 5329MB
[2022-04-19 04:37:33 tiny] (main.py 226): INFO Train: [150/300][900/1251]	eta 0:03:31 lr 0.000501	time 0.6389 (0.6037)	loss 4.3007 (3.9475)	grad_norm 5.4647 (4.1547)	mem 5329MB
[2022-04-19 04:38:31 tiny] (main.py 226): INFO Train: [150/300][1000/1251]	eta 0:02:31 lr 0.000501	time 0.6400 (0.6019)	loss 4.0144 (3.9450)	grad_norm 3.0504 (4.1324)	mem 5329MB
[2022-04-19 04:39:30 tiny] (main.py 226): INFO Train: [150/300][1100/1251]	eta 0:01:30 lr 0.000500	time 0.5673 (0.6008)	loss 4.0358 (3.9531)	grad_norm 5.2014 (4.1260)	mem 5329MB
[2022-04-19 04:40:29 tiny] (main.py 226): INFO Train: [150/300][1200/1251]	eta 0:00:30 lr 0.000500	time 0.4749 (0.5995)	loss 4.3731 (3.9472)	grad_norm 3.6132 (4.1223)	mem 5329MB
[2022-04-19 04:40:50 tiny] (main.py 233): INFO EPOCH 150 training takes 0:12:21
[2022-04-19 04:41:01 tiny] (main.py 273): INFO Test: [0/49]	Time 11.542 (11.542)	Loss 1.6387 (1.6387)	Acc@1 67.676 (67.676)	Acc@5 87.500 (87.500)	Mem 5329MB
[2022-04-19 04:41:21 tiny] (main.py 279): INFO  * Acc@1 66.336 Acc@5 87.538
[2022-04-19 04:41:21 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 66.3%
[2022-04-19 04:41:21 tiny] (main.py 148): INFO Max accuracy: 67.19%
[2022-04-19 04:41:33 tiny] (main.py 226): INFO Train: [151/300][0/1251]	eta 4:05:03 lr 0.000500	time 11.7535 (11.7535)	loss 4.3657 (4.3657)	grad_norm 7.6039 (7.6039)	mem 5329MB
[2022-04-19 04:42:35 tiny] (main.py 226): INFO Train: [151/300][100/1251]	eta 0:13:57 lr 0.000499	time 0.5838 (0.7278)	loss 3.6847 (4.0096)	grad_norm 3.1275 (4.0793)	mem 5329MB
[2022-04-19 04:43:34 tiny] (main.py 226): INFO Train: [151/300][200/1251]	eta 0:11:32 lr 0.000499	time 0.4707 (0.6585)	loss 3.2676 (3.9988)	grad_norm 3.8361 (3.9422)	mem 5329MB
[2022-04-19 04:44:32 tiny] (main.py 226): INFO Train: [151/300][300/1251]	eta 0:10:02 lr 0.000499	time 0.3972 (0.6341)	loss 4.3704 (3.9990)	grad_norm 2.9417 (4.0071)	mem 5329MB
[2022-04-19 04:45:31 tiny] (main.py 226): INFO Train: [151/300][400/1251]	eta 0:08:48 lr 0.000498	time 0.5366 (0.6216)	loss 3.0857 (4.0040)	grad_norm 4.0946 (4.0720)	mem 5329MB
[2022-04-19 04:46:29 tiny] (main.py 226): INFO Train: [151/300][500/1251]	eta 0:07:41 lr 0.000498	time 0.4642 (0.6144)	loss 4.3058 (3.9919)	grad_norm 4.1708 (4.0782)	mem 5329MB
[2022-04-19 04:47:28 tiny] (main.py 226): INFO Train: [151/300][600/1251]	eta 0:06:37 lr 0.000497	time 0.4795 (0.6101)	loss 3.3926 (3.9950)	grad_norm 3.5619 (4.1410)	mem 5329MB
[2022-04-19 04:48:27 tiny] (main.py 226): INFO Train: [151/300][700/1251]	eta 0:05:34 lr 0.000497	time 0.6362 (0.6079)	loss 3.6050 (3.9900)	grad_norm 2.5493 (4.1526)	mem 5329MB
[2022-04-19 04:49:26 tiny] (main.py 226): INFO Train: [151/300][800/1251]	eta 0:04:33 lr 0.000497	time 0.4277 (0.6055)	loss 4.2771 (3.9987)	grad_norm 7.4897 (4.1424)	mem 5329MB
[2022-04-19 04:50:25 tiny] (main.py 226): INFO Train: [151/300][900/1251]	eta 0:03:31 lr 0.000496	time 0.7452 (0.6032)	loss 4.5696 (4.0018)	grad_norm 6.4125 (4.1440)	mem 5329MB
[2022-04-19 04:51:24 tiny] (main.py 226): INFO Train: [151/300][1000/1251]	eta 0:02:31 lr 0.000496	time 0.6024 (0.6018)	loss 4.2241 (3.9968)	grad_norm 2.4938 (4.1968)	mem 5329MB
[2022-04-19 04:52:23 tiny] (main.py 226): INFO Train: [151/300][1100/1251]	eta 0:01:30 lr 0.000495	time 0.6552 (0.6011)	loss 3.5803 (4.0059)	grad_norm 3.2989 (4.1638)	mem 5329MB
[2022-04-19 04:53:22 tiny] (main.py 226): INFO Train: [151/300][1200/1251]	eta 0:00:30 lr 0.000495	time 0.5465 (0.5999)	loss 2.8152 (4.0059)	grad_norm 2.8068 (4.1672)	mem 5329MB
[2022-04-19 04:53:44 tiny] (main.py 233): INFO EPOCH 151 training takes 0:12:22
[2022-04-19 04:53:55 tiny] (main.py 273): INFO Test: [0/49]	Time 11.428 (11.428)	Loss 1.6637 (1.6637)	Acc@1 66.992 (66.992)	Acc@5 88.672 (88.672)	Mem 5329MB
[2022-04-19 04:54:14 tiny] (main.py 279): INFO  * Acc@1 67.076 Acc@5 87.812
[2022-04-19 04:54:14 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 67.1%
[2022-04-19 04:54:14 tiny] (main.py 148): INFO Max accuracy: 67.19%
[2022-04-19 04:54:27 tiny] (main.py 226): INFO Train: [152/300][0/1251]	eta 4:14:10 lr 0.000495	time 12.1906 (12.1906)	loss 4.5498 (4.5498)	grad_norm 4.8941 (4.8941)	mem 5329MB
[2022-04-19 04:55:28 tiny] (main.py 226): INFO Train: [152/300][100/1251]	eta 0:13:57 lr 0.000494	time 0.5157 (0.7277)	loss 4.5432 (3.9701)	grad_norm 4.3872 (3.9538)	mem 5329MB
[2022-04-19 04:56:27 tiny] (main.py 226): INFO Train: [152/300][200/1251]	eta 0:11:31 lr 0.000494	time 0.7009 (0.6582)	loss 2.7207 (3.9823)	grad_norm 4.3154 (3.9780)	mem 5329MB
[2022-04-19 04:57:25 tiny] (main.py 226): INFO Train: [152/300][300/1251]	eta 0:10:00 lr 0.000493	time 0.6389 (0.6318)	loss 3.0883 (3.9902)	grad_norm 3.3408 (4.0083)	mem 5329MB
[2022-04-19 04:58:23 tiny] (main.py 226): INFO Train: [152/300][400/1251]	eta 0:08:48 lr 0.000493	time 0.5097 (0.6206)	loss 4.1604 (3.9755)	grad_norm 4.8211 (4.0716)	mem 5329MB
[2022-04-19 04:59:22 tiny] (main.py 226): INFO Train: [152/300][500/1251]	eta 0:07:41 lr 0.000493	time 0.6300 (0.6143)	loss 4.4400 (3.9676)	grad_norm 4.7695 (4.1255)	mem 5329MB
[2022-04-19 05:00:21 tiny] (main.py 226): INFO Train: [152/300][600/1251]	eta 0:06:36 lr 0.000492	time 0.5689 (0.6098)	loss 4.0174 (3.9478)	grad_norm 2.7916 (4.1309)	mem 5329MB
[2022-04-19 05:01:20 tiny] (main.py 226): INFO Train: [152/300][700/1251]	eta 0:05:34 lr 0.000492	time 0.5437 (0.6073)	loss 3.2626 (3.9568)	grad_norm 3.5537 (4.1626)	mem 5329MB
[2022-04-19 05:02:19 tiny] (main.py 226): INFO Train: [152/300][800/1251]	eta 0:04:32 lr 0.000491	time 0.6590 (0.6050)	loss 4.5572 (3.9532)	grad_norm 2.9510 (4.1462)	mem 5329MB
[2022-04-19 05:03:17 tiny] (main.py 226): INFO Train: [152/300][900/1251]	eta 0:03:31 lr 0.000491	time 0.5339 (0.6027)	loss 4.0425 (3.9729)	grad_norm 4.7071 (4.1098)	mem 5329MB
[2022-04-19 05:04:16 tiny] (main.py 226): INFO Train: [152/300][1000/1251]	eta 0:02:30 lr 0.000490	time 0.5777 (0.6011)	loss 4.1514 (3.9763)	grad_norm 4.9864 (4.1166)	mem 5329MB
[2022-04-19 05:05:15 tiny] (main.py 226): INFO Train: [152/300][1100/1251]	eta 0:01:30 lr 0.000490	time 0.6356 (0.6003)	loss 4.8204 (3.9694)	grad_norm 2.9419 (4.1050)	mem 5329MB
[2022-04-19 05:06:14 tiny] (main.py 226): INFO Train: [152/300][1200/1251]	eta 0:00:30 lr 0.000490	time 0.5945 (0.5989)	loss 4.8370 (3.9761)	grad_norm 5.9972 (4.1202)	mem 5329MB
[2022-04-19 05:06:36 tiny] (main.py 233): INFO EPOCH 152 training takes 0:12:21
[2022-04-19 05:06:48 tiny] (main.py 273): INFO Test: [0/49]	Time 12.582 (12.582)	Loss 1.7012 (1.7012)	Acc@1 65.723 (65.723)	Acc@5 86.621 (86.621)	Mem 5329MB
[2022-04-19 05:07:07 tiny] (main.py 279): INFO  * Acc@1 66.356 Acc@5 87.608
[2022-04-19 05:07:07 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 66.4%
[2022-04-19 05:07:07 tiny] (main.py 148): INFO Max accuracy: 67.19%
[2022-04-19 05:07:18 tiny] (main.py 226): INFO Train: [153/300][0/1251]	eta 4:04:32 lr 0.000489	time 11.7286 (11.7286)	loss 3.5801 (3.5801)	grad_norm 7.6992 (7.6992)	mem 5329MB
[2022-04-19 05:08:20 tiny] (main.py 226): INFO Train: [153/300][100/1251]	eta 0:13:58 lr 0.000489	time 0.5668 (0.7284)	loss 3.1919 (3.8592)	grad_norm 3.7022 (3.8749)	mem 5329MB
[2022-04-19 05:09:19 tiny] (main.py 226): INFO Train: [153/300][200/1251]	eta 0:11:31 lr 0.000489	time 0.4798 (0.6582)	loss 3.4642 (3.8820)	grad_norm 3.2920 (inf)	mem 5329MB
[2022-04-19 05:10:18 tiny] (main.py 226): INFO Train: [153/300][300/1251]	eta 0:10:04 lr 0.000488	time 0.7036 (0.6361)	loss 4.1227 (3.9198)	grad_norm 3.8743 (inf)	mem 5329MB
[2022-04-19 05:11:17 tiny] (main.py 226): INFO Train: [153/300][400/1251]	eta 0:08:50 lr 0.000488	time 0.6574 (0.6232)	loss 3.8855 (3.9281)	grad_norm 3.9689 (inf)	mem 5329MB
[2022-04-19 05:12:15 tiny] (main.py 226): INFO Train: [153/300][500/1251]	eta 0:07:42 lr 0.000487	time 1.0112 (0.6161)	loss 3.8536 (3.9338)	grad_norm 5.5011 (inf)	mem 5329MB
[2022-04-19 05:13:14 tiny] (main.py 226): INFO Train: [153/300][600/1251]	eta 0:06:37 lr 0.000487	time 0.7559 (0.6106)	loss 3.1218 (3.9422)	grad_norm 4.6210 (inf)	mem 5329MB
[2022-04-19 05:14:13 tiny] (main.py 226): INFO Train: [153/300][700/1251]	eta 0:05:35 lr 0.000487	time 0.6169 (0.6082)	loss 3.8257 (3.9403)	grad_norm 5.5729 (inf)	mem 5329MB
[2022-04-19 05:15:12 tiny] (main.py 226): INFO Train: [153/300][800/1251]	eta 0:04:33 lr 0.000486	time 0.6046 (0.6056)	loss 4.1545 (3.9435)	grad_norm 2.6078 (inf)	mem 5329MB
[2022-04-19 05:16:11 tiny] (main.py 226): INFO Train: [153/300][900/1251]	eta 0:03:31 lr 0.000486	time 0.5553 (0.6038)	loss 4.2000 (3.9390)	grad_norm 3.2200 (inf)	mem 5329MB
[2022-04-19 05:17:10 tiny] (main.py 226): INFO Train: [153/300][1000/1251]	eta 0:02:31 lr 0.000485	time 0.5897 (0.6025)	loss 3.8389 (3.9477)	grad_norm 5.0835 (inf)	mem 5329MB
[2022-04-19 05:18:08 tiny] (main.py 226): INFO Train: [153/300][1100/1251]	eta 0:01:30 lr 0.000485	time 0.4799 (0.6010)	loss 4.2765 (3.9491)	grad_norm 5.2174 (inf)	mem 5329MB
[2022-04-19 05:19:07 tiny] (main.py 226): INFO Train: [153/300][1200/1251]	eta 0:00:30 lr 0.000484	time 0.5849 (0.6000)	loss 3.6431 (3.9405)	grad_norm 3.1552 (inf)	mem 5329MB
[2022-04-19 05:19:29 tiny] (main.py 233): INFO EPOCH 153 training takes 0:12:22
[2022-04-19 05:19:40 tiny] (main.py 273): INFO Test: [0/49]	Time 10.865 (10.865)	Loss 1.7495 (1.7495)	Acc@1 64.551 (64.551)	Acc@5 86.816 (86.816)	Mem 5329MB
[2022-04-19 05:20:01 tiny] (main.py 279): INFO  * Acc@1 66.010 Acc@5 87.268
[2022-04-19 05:20:01 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 66.0%
[2022-04-19 05:20:01 tiny] (main.py 148): INFO Max accuracy: 67.19%
[2022-04-19 05:20:11 tiny] (main.py 226): INFO Train: [154/300][0/1251]	eta 3:36:12 lr 0.000484	time 10.3700 (10.3700)	loss 3.5320 (3.5320)	grad_norm 2.6122 (2.6122)	mem 5329MB
[2022-04-19 05:21:14 tiny] (main.py 226): INFO Train: [154/300][100/1251]	eta 0:13:58 lr 0.000484	time 0.5341 (0.7286)	loss 4.6674 (3.9066)	grad_norm 4.5857 (4.2569)	mem 5329MB
[2022-04-19 05:22:13 tiny] (main.py 226): INFO Train: [154/300][200/1251]	eta 0:11:31 lr 0.000483	time 0.4015 (0.6577)	loss 4.1953 (3.9661)	grad_norm 2.1925 (4.0487)	mem 5329MB
[2022-04-19 05:23:12 tiny] (main.py 226): INFO Train: [154/300][300/1251]	eta 0:10:03 lr 0.000483	time 0.3956 (0.6347)	loss 4.0184 (3.9422)	grad_norm 5.8458 (4.1978)	mem 5329MB
[2022-04-19 05:24:11 tiny] (main.py 226): INFO Train: [154/300][400/1251]	eta 0:08:50 lr 0.000483	time 0.5653 (0.6232)	loss 4.4408 (3.9430)	grad_norm 4.8179 (4.1545)	mem 5329MB
[2022-04-19 05:25:09 tiny] (main.py 226): INFO Train: [154/300][500/1251]	eta 0:07:42 lr 0.000482	time 0.7259 (0.6159)	loss 3.8712 (3.9346)	grad_norm 2.2633 (4.2383)	mem 5329MB
[2022-04-19 05:26:07 tiny] (main.py 226): INFO Train: [154/300][600/1251]	eta 0:06:37 lr 0.000482	time 0.4689 (0.6104)	loss 3.1025 (3.9370)	grad_norm 2.9086 (4.1286)	mem 5329MB
[2022-04-19 05:27:07 tiny] (main.py 226): INFO Train: [154/300][700/1251]	eta 0:05:34 lr 0.000481	time 0.5801 (0.6076)	loss 4.4600 (3.9516)	grad_norm 4.0621 (4.2036)	mem 5329MB
[2022-04-19 05:28:05 tiny] (main.py 226): INFO Train: [154/300][800/1251]	eta 0:04:32 lr 0.000481	time 0.4395 (0.6049)	loss 5.0255 (3.9532)	grad_norm 4.0458 (4.1788)	mem 5329MB
[2022-04-19 05:29:04 tiny] (main.py 226): INFO Train: [154/300][900/1251]	eta 0:03:31 lr 0.000481	time 0.5714 (0.6036)	loss 3.4290 (3.9440)	grad_norm 5.1372 (4.1951)	mem 5329MB
[2022-04-19 05:30:03 tiny] (main.py 226): INFO Train: [154/300][1000/1251]	eta 0:02:31 lr 0.000480	time 0.6225 (0.6018)	loss 4.7619 (3.9364)	grad_norm 4.9568 (inf)	mem 5329MB
[2022-04-19 05:31:02 tiny] (main.py 226): INFO Train: [154/300][1100/1251]	eta 0:01:30 lr 0.000480	time 0.5803 (0.6009)	loss 4.3685 (3.9404)	grad_norm 6.3092 (inf)	mem 5329MB
[2022-04-19 05:32:01 tiny] (main.py 226): INFO Train: [154/300][1200/1251]	eta 0:00:30 lr 0.000479	time 0.3524 (0.6000)	loss 3.3988 (3.9453)	grad_norm 4.8071 (inf)	mem 5329MB
[2022-04-19 05:32:23 tiny] (main.py 233): INFO EPOCH 154 training takes 0:12:22
[2022-04-19 05:32:35 tiny] (main.py 273): INFO Test: [0/49]	Time 11.780 (11.780)	Loss 1.6571 (1.6571)	Acc@1 65.625 (65.625)	Acc@5 87.500 (87.500)	Mem 5329MB
[2022-04-19 05:32:55 tiny] (main.py 279): INFO  * Acc@1 66.796 Acc@5 87.750
[2022-04-19 05:32:55 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 66.8%
[2022-04-19 05:32:55 tiny] (main.py 148): INFO Max accuracy: 67.19%
[2022-04-19 05:33:07 tiny] (main.py 226): INFO Train: [155/300][0/1251]	eta 4:12:30 lr 0.000479	time 12.1106 (12.1106)	loss 4.1731 (4.1731)	grad_norm 3.6521 (3.6521)	mem 5329MB
[2022-04-19 05:34:09 tiny] (main.py 226): INFO Train: [155/300][100/1251]	eta 0:14:03 lr 0.000479	time 0.4631 (0.7332)	loss 4.2148 (3.9249)	grad_norm 2.5904 (4.3724)	mem 5329MB
[2022-04-19 05:35:07 tiny] (main.py 226): INFO Train: [155/300][200/1251]	eta 0:11:34 lr 0.000478	time 0.6528 (0.6607)	loss 3.7707 (3.9332)	grad_norm 5.1151 (4.2108)	mem 5329MB
[2022-04-19 05:36:06 tiny] (main.py 226): INFO Train: [155/300][300/1251]	eta 0:10:04 lr 0.000478	time 0.5401 (0.6353)	loss 3.5966 (3.9490)	grad_norm 5.4012 (4.1446)	mem 5329MB
[2022-04-19 05:37:05 tiny] (main.py 226): INFO Train: [155/300][400/1251]	eta 0:08:50 lr 0.000477	time 0.5215 (0.6236)	loss 4.0837 (3.9492)	grad_norm 9.7266 (4.1605)	mem 5329MB
[2022-04-19 05:38:04 tiny] (main.py 226): INFO Train: [155/300][500/1251]	eta 0:07:43 lr 0.000477	time 0.4749 (0.6171)	loss 3.3634 (3.9460)	grad_norm 3.1997 (4.1779)	mem 5329MB
[2022-04-19 05:39:02 tiny] (main.py 226): INFO Train: [155/300][600/1251]	eta 0:06:37 lr 0.000477	time 0.4218 (0.6112)	loss 4.1272 (3.9409)	grad_norm 3.0848 (inf)	mem 5329MB
[2022-04-19 05:40:01 tiny] (main.py 226): INFO Train: [155/300][700/1251]	eta 0:05:35 lr 0.000476	time 0.5665 (0.6081)	loss 3.3859 (3.9461)	grad_norm 6.6620 (inf)	mem 5329MB
[2022-04-19 05:41:00 tiny] (main.py 226): INFO Train: [155/300][800/1251]	eta 0:04:33 lr 0.000476	time 0.6567 (0.6060)	loss 3.9292 (3.9538)	grad_norm 5.1905 (inf)	mem 5329MB
[2022-04-19 05:41:59 tiny] (main.py 226): INFO Train: [155/300][900/1251]	eta 0:03:31 lr 0.000475	time 0.4197 (0.6039)	loss 2.6068 (3.9614)	grad_norm 3.5946 (inf)	mem 5329MB
[2022-04-19 05:42:58 tiny] (main.py 226): INFO Train: [155/300][1000/1251]	eta 0:02:31 lr 0.000475	time 0.5578 (0.6025)	loss 4.4606 (3.9610)	grad_norm 4.2063 (inf)	mem 5329MB
[2022-04-19 05:43:56 tiny] (main.py 226): INFO Train: [155/300][1100/1251]	eta 0:01:30 lr 0.000475	time 0.5723 (0.6010)	loss 3.4109 (3.9610)	grad_norm 4.5483 (inf)	mem 5329MB
[2022-04-19 05:44:55 tiny] (main.py 226): INFO Train: [155/300][1200/1251]	eta 0:00:30 lr 0.000474	time 0.4635 (0.6002)	loss 3.3540 (3.9599)	grad_norm 5.4035 (inf)	mem 5329MB
[2022-04-19 05:45:17 tiny] (main.py 233): INFO EPOCH 155 training takes 0:12:22
[2022-04-19 05:45:30 tiny] (main.py 273): INFO Test: [0/49]	Time 12.585 (12.585)	Loss 1.6430 (1.6430)	Acc@1 67.383 (67.383)	Acc@5 89.551 (89.551)	Mem 5329MB
[2022-04-19 05:45:49 tiny] (main.py 279): INFO  * Acc@1 66.520 Acc@5 87.582
[2022-04-19 05:45:49 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 66.5%
[2022-04-19 05:45:49 tiny] (main.py 148): INFO Max accuracy: 67.19%
[2022-04-19 05:46:00 tiny] (main.py 226): INFO Train: [156/300][0/1251]	eta 3:56:40 lr 0.000474	time 11.3517 (11.3517)	loss 4.4632 (4.4632)	grad_norm 3.0292 (3.0292)	mem 5329MB
[2022-04-19 05:47:02 tiny] (main.py 226): INFO Train: [156/300][100/1251]	eta 0:13:55 lr 0.000474	time 0.5007 (0.7262)	loss 4.7664 (3.9976)	grad_norm 3.2869 (4.1323)	mem 5329MB
[2022-04-19 05:48:01 tiny] (main.py 226): INFO Train: [156/300][200/1251]	eta 0:11:31 lr 0.000473	time 0.5769 (0.6579)	loss 4.2194 (3.9604)	grad_norm 4.5727 (4.0707)	mem 5329MB
[2022-04-19 05:48:59 tiny] (main.py 226): INFO Train: [156/300][300/1251]	eta 0:10:01 lr 0.000473	time 0.5068 (0.6323)	loss 4.2833 (3.9365)	grad_norm 4.5162 (4.1348)	mem 5329MB
[2022-04-19 05:49:58 tiny] (main.py 226): INFO Train: [156/300][400/1251]	eta 0:08:48 lr 0.000472	time 0.4611 (0.6207)	loss 4.3042 (3.9248)	grad_norm 3.7073 (4.1713)	mem 5329MB
[2022-04-19 05:50:57 tiny] (main.py 226): INFO Train: [156/300][500/1251]	eta 0:07:41 lr 0.000472	time 0.4305 (0.6144)	loss 4.2006 (3.9510)	grad_norm 12.7511 (4.2991)	mem 5329MB
[2022-04-19 05:51:56 tiny] (main.py 226): INFO Train: [156/300][600/1251]	eta 0:06:37 lr 0.000471	time 0.8119 (0.6104)	loss 4.2794 (3.9511)	grad_norm 4.2830 (4.2996)	mem 5329MB
[2022-04-19 05:52:55 tiny] (main.py 226): INFO Train: [156/300][700/1251]	eta 0:05:34 lr 0.000471	time 0.5451 (0.6072)	loss 4.3724 (3.9520)	grad_norm 4.2182 (4.2330)	mem 5329MB
[2022-04-19 05:53:53 tiny] (main.py 226): INFO Train: [156/300][800/1251]	eta 0:04:32 lr 0.000471	time 0.5577 (0.6048)	loss 4.0399 (3.9506)	grad_norm 2.9412 (4.2215)	mem 5329MB
[2022-04-19 05:54:53 tiny] (main.py 226): INFO Train: [156/300][900/1251]	eta 0:03:31 lr 0.000470	time 0.5936 (0.6033)	loss 4.3667 (3.9611)	grad_norm 3.3707 (4.2499)	mem 5329MB
[2022-04-19 05:55:51 tiny] (main.py 226): INFO Train: [156/300][1000/1251]	eta 0:02:31 lr 0.000470	time 0.6250 (0.6017)	loss 4.7348 (3.9627)	grad_norm 2.9278 (4.2340)	mem 5329MB
[2022-04-19 05:56:50 tiny] (main.py 226): INFO Train: [156/300][1100/1251]	eta 0:01:30 lr 0.000469	time 0.5511 (0.6004)	loss 3.6682 (3.9651)	grad_norm 2.8048 (4.2517)	mem 5329MB
[2022-04-19 05:57:49 tiny] (main.py 226): INFO Train: [156/300][1200/1251]	eta 0:00:30 lr 0.000469	time 0.6845 (0.5993)	loss 3.0325 (3.9616)	grad_norm 4.8089 (4.2503)	mem 5329MB
[2022-04-19 05:58:11 tiny] (main.py 233): INFO EPOCH 156 training takes 0:12:21
[2022-04-19 05:58:22 tiny] (main.py 273): INFO Test: [0/49]	Time 10.919 (10.919)	Loss 1.6308 (1.6308)	Acc@1 66.504 (66.504)	Acc@5 87.402 (87.402)	Mem 5329MB
[2022-04-19 05:58:42 tiny] (main.py 279): INFO  * Acc@1 67.038 Acc@5 87.984
[2022-04-19 05:58:42 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 67.0%
[2022-04-19 05:58:42 tiny] (main.py 148): INFO Max accuracy: 67.19%
[2022-04-19 05:58:54 tiny] (main.py 226): INFO Train: [157/300][0/1251]	eta 4:05:11 lr 0.000469	time 11.7595 (11.7595)	loss 2.7813 (2.7813)	grad_norm 3.1683 (3.1683)	mem 5329MB
[2022-04-19 05:59:56 tiny] (main.py 226): INFO Train: [157/300][100/1251]	eta 0:13:59 lr 0.000468	time 0.4787 (0.7297)	loss 3.8834 (3.9695)	grad_norm 7.0436 (4.5496)	mem 5329MB
[2022-04-19 06:00:54 tiny] (main.py 226): INFO Train: [157/300][200/1251]	eta 0:11:30 lr 0.000468	time 0.4457 (0.6575)	loss 4.6517 (3.9475)	grad_norm 3.0166 (4.4182)	mem 5329MB
[2022-04-19 06:01:53 tiny] (main.py 226): INFO Train: [157/300][300/1251]	eta 0:10:02 lr 0.000468	time 0.5796 (0.6333)	loss 2.5719 (3.9572)	grad_norm 4.7886 (4.4629)	mem 5329MB
[2022-04-19 06:02:52 tiny] (main.py 226): INFO Train: [157/300][400/1251]	eta 0:08:50 lr 0.000467	time 0.5181 (0.6229)	loss 4.1184 (3.9558)	grad_norm 3.6511 (4.4435)	mem 5329MB
[2022-04-19 06:03:50 tiny] (main.py 226): INFO Train: [157/300][500/1251]	eta 0:07:42 lr 0.000467	time 0.5123 (0.6153)	loss 4.1390 (3.9411)	grad_norm 4.2463 (4.4311)	mem 5329MB
[2022-04-19 06:04:49 tiny] (main.py 226): INFO Train: [157/300][600/1251]	eta 0:06:37 lr 0.000466	time 0.7565 (0.6108)	loss 4.2873 (3.9426)	grad_norm 4.2325 (4.3768)	mem 5329MB
[2022-04-19 06:05:47 tiny] (main.py 226): INFO Train: [157/300][700/1251]	eta 0:05:34 lr 0.000466	time 0.4141 (0.6067)	loss 4.3208 (3.9488)	grad_norm 3.1876 (4.4534)	mem 5329MB
[2022-04-19 06:06:46 tiny] (main.py 226): INFO Train: [157/300][800/1251]	eta 0:04:32 lr 0.000465	time 0.5958 (0.6047)	loss 2.8488 (3.9435)	grad_norm 7.8526 (4.4020)	mem 5329MB
[2022-04-19 06:07:45 tiny] (main.py 226): INFO Train: [157/300][900/1251]	eta 0:03:31 lr 0.000465	time 0.4017 (0.6030)	loss 4.2795 (3.9512)	grad_norm 3.9400 (4.3879)	mem 5329MB
[2022-04-19 06:08:44 tiny] (main.py 226): INFO Train: [157/300][1000/1251]	eta 0:02:30 lr 0.000465	time 0.5756 (0.6013)	loss 4.2936 (3.9456)	grad_norm 3.8838 (4.3450)	mem 5329MB
[2022-04-19 06:09:42 tiny] (main.py 226): INFO Train: [157/300][1100/1251]	eta 0:01:30 lr 0.000464	time 0.4492 (0.5998)	loss 4.8637 (3.9394)	grad_norm 3.2829 (4.3512)	mem 5329MB
[2022-04-19 06:10:41 tiny] (main.py 226): INFO Train: [157/300][1200/1251]	eta 0:00:30 lr 0.000464	time 0.7840 (0.5989)	loss 4.1258 (3.9404)	grad_norm 3.0510 (4.3630)	mem 5329MB
[2022-04-19 06:11:03 tiny] (main.py 233): INFO EPOCH 157 training takes 0:12:21
[2022-04-19 06:11:15 tiny] (main.py 273): INFO Test: [0/49]	Time 11.351 (11.351)	Loss 1.6835 (1.6835)	Acc@1 66.113 (66.113)	Acc@5 87.305 (87.305)	Mem 5329MB
[2022-04-19 06:11:34 tiny] (main.py 279): INFO  * Acc@1 66.920 Acc@5 88.020
[2022-04-19 06:11:34 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 66.9%
[2022-04-19 06:11:34 tiny] (main.py 148): INFO Max accuracy: 67.19%
[2022-04-19 06:11:46 tiny] (main.py 226): INFO Train: [158/300][0/1251]	eta 4:13:16 lr 0.000464	time 12.1478 (12.1478)	loss 3.1136 (3.1136)	grad_norm 2.6318 (2.6318)	mem 5329MB
[2022-04-19 06:12:48 tiny] (main.py 226): INFO Train: [158/300][100/1251]	eta 0:14:01 lr 0.000463	time 0.6309 (0.7310)	loss 4.6960 (4.0236)	grad_norm 2.6037 (4.3498)	mem 5329MB
[2022-04-19 06:13:46 tiny] (main.py 226): INFO Train: [158/300][200/1251]	eta 0:11:31 lr 0.000463	time 0.7323 (0.6575)	loss 3.6472 (3.9850)	grad_norm 5.8110 (4.2588)	mem 5329MB
[2022-04-19 06:14:45 tiny] (main.py 226): INFO Train: [158/300][300/1251]	eta 0:10:01 lr 0.000462	time 0.7164 (0.6324)	loss 4.3411 (3.9425)	grad_norm 3.3389 (4.2643)	mem 5329MB
[2022-04-19 06:15:43 tiny] (main.py 226): INFO Train: [158/300][400/1251]	eta 0:08:48 lr 0.000462	time 0.4913 (0.6212)	loss 3.4980 (3.9449)	grad_norm 3.5542 (4.2805)	mem 5329MB
[2022-04-19 06:16:42 tiny] (main.py 226): INFO Train: [158/300][500/1251]	eta 0:07:41 lr 0.000462	time 0.4399 (0.6147)	loss 4.0050 (3.9496)	grad_norm 3.7770 (4.3017)	mem 5329MB
[2022-04-19 06:17:41 tiny] (main.py 226): INFO Train: [158/300][600/1251]	eta 0:06:37 lr 0.000461	time 0.6624 (0.6101)	loss 4.3525 (3.9603)	grad_norm 3.2483 (4.2748)	mem 5329MB
[2022-04-19 06:18:40 tiny] (main.py 226): INFO Train: [158/300][700/1251]	eta 0:05:34 lr 0.000461	time 0.6669 (0.6068)	loss 3.4798 (3.9727)	grad_norm 3.6421 (4.2982)	mem 5329MB
[2022-04-19 06:19:39 tiny] (main.py 226): INFO Train: [158/300][800/1251]	eta 0:04:32 lr 0.000460	time 0.6110 (0.6045)	loss 2.8267 (3.9670)	grad_norm 3.8001 (4.2910)	mem 5329MB
[2022-04-19 06:20:37 tiny] (main.py 226): INFO Train: [158/300][900/1251]	eta 0:03:31 lr 0.000460	time 0.5659 (0.6027)	loss 4.7721 (3.9719)	grad_norm 2.5478 (inf)	mem 5329MB
[2022-04-19 06:21:36 tiny] (main.py 226): INFO Train: [158/300][1000/1251]	eta 0:02:30 lr 0.000459	time 0.7129 (0.6015)	loss 4.5057 (3.9745)	grad_norm 3.5952 (inf)	mem 5329MB
[2022-04-19 06:22:35 tiny] (main.py 226): INFO Train: [158/300][1100/1251]	eta 0:01:30 lr 0.000459	time 0.5214 (0.6001)	loss 4.8027 (3.9773)	grad_norm 3.2913 (inf)	mem 5329MB
[2022-04-19 06:23:34 tiny] (main.py 226): INFO Train: [158/300][1200/1251]	eta 0:00:30 lr 0.000459	time 0.5524 (0.5991)	loss 4.4171 (3.9761)	grad_norm 5.3495 (inf)	mem 5329MB
[2022-04-19 06:23:56 tiny] (main.py 233): INFO EPOCH 158 training takes 0:12:21
[2022-04-19 06:24:07 tiny] (main.py 273): INFO Test: [0/49]	Time 10.985 (10.985)	Loss 1.7861 (1.7861)	Acc@1 64.746 (64.746)	Acc@5 86.328 (86.328)	Mem 5329MB
[2022-04-19 06:24:27 tiny] (main.py 279): INFO  * Acc@1 66.620 Acc@5 87.770
[2022-04-19 06:24:27 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 66.6%
[2022-04-19 06:24:27 tiny] (main.py 148): INFO Max accuracy: 67.19%
[2022-04-19 06:24:39 tiny] (main.py 226): INFO Train: [159/300][0/1251]	eta 4:18:24 lr 0.000458	time 12.3938 (12.3938)	loss 4.1816 (4.1816)	grad_norm 3.7126 (3.7126)	mem 5329MB
[2022-04-19 06:25:41 tiny] (main.py 226): INFO Train: [159/300][100/1251]	eta 0:13:59 lr 0.000458	time 0.5726 (0.7293)	loss 4.8180 (3.9726)	grad_norm 2.8552 (4.4586)	mem 5329MB
[2022-04-19 06:26:39 tiny] (main.py 226): INFO Train: [159/300][200/1251]	eta 0:11:29 lr 0.000458	time 0.5687 (0.6563)	loss 3.8120 (3.9364)	grad_norm 2.3525 (4.2695)	mem 5329MB
[2022-04-19 06:27:37 tiny] (main.py 226): INFO Train: [159/300][300/1251]	eta 0:10:00 lr 0.000457	time 0.6201 (0.6319)	loss 4.8745 (3.9602)	grad_norm 3.3816 (4.3639)	mem 5329MB
[2022-04-19 06:28:36 tiny] (main.py 226): INFO Train: [159/300][400/1251]	eta 0:08:48 lr 0.000457	time 0.7229 (0.6213)	loss 3.4132 (3.9467)	grad_norm 3.2995 (4.3458)	mem 5329MB
[2022-04-19 06:29:35 tiny] (main.py 226): INFO Train: [159/300][500/1251]	eta 0:07:41 lr 0.000456	time 0.5895 (0.6143)	loss 2.8725 (3.9303)	grad_norm 2.6982 (4.2870)	mem 5329MB
[2022-04-19 06:30:33 tiny] (main.py 226): INFO Train: [159/300][600/1251]	eta 0:06:36 lr 0.000456	time 0.4487 (0.6097)	loss 3.4138 (3.9234)	grad_norm 3.6802 (4.2844)	mem 5329MB
[2022-04-19 06:31:32 tiny] (main.py 226): INFO Train: [159/300][700/1251]	eta 0:05:34 lr 0.000456	time 0.7145 (0.6070)	loss 3.5495 (3.9305)	grad_norm 3.2737 (4.3981)	mem 5329MB
[2022-04-19 06:32:32 tiny] (main.py 226): INFO Train: [159/300][800/1251]	eta 0:04:32 lr 0.000455	time 0.5200 (0.6050)	loss 4.5022 (3.9391)	grad_norm 3.6016 (4.3842)	mem 5329MB
[2022-04-19 06:33:30 tiny] (main.py 226): INFO Train: [159/300][900/1251]	eta 0:03:31 lr 0.000455	time 0.5168 (0.6027)	loss 4.9602 (3.9467)	grad_norm 4.6533 (4.3551)	mem 5329MB
[2022-04-19 06:34:29 tiny] (main.py 226): INFO Train: [159/300][1000/1251]	eta 0:02:30 lr 0.000454	time 0.5973 (0.6011)	loss 4.8380 (3.9462)	grad_norm 4.8399 (4.3787)	mem 5329MB
[2022-04-19 06:35:27 tiny] (main.py 226): INFO Train: [159/300][1100/1251]	eta 0:01:30 lr 0.000454	time 0.4859 (0.5996)	loss 4.3727 (3.9495)	grad_norm 4.5893 (4.3302)	mem 5329MB
[2022-04-19 06:36:26 tiny] (main.py 226): INFO Train: [159/300][1200/1251]	eta 0:00:30 lr 0.000453	time 0.5825 (0.5990)	loss 3.5058 (3.9470)	grad_norm 2.9845 (4.3275)	mem 5329MB
[2022-04-19 06:36:48 tiny] (main.py 233): INFO EPOCH 159 training takes 0:12:20
[2022-04-19 06:37:00 tiny] (main.py 273): INFO Test: [0/49]	Time 11.678 (11.678)	Loss 1.5323 (1.5323)	Acc@1 69.531 (69.531)	Acc@5 88.281 (88.281)	Mem 5329MB
[2022-04-19 06:37:19 tiny] (main.py 279): INFO  * Acc@1 67.110 Acc@5 88.092
[2022-04-19 06:37:19 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 67.1%
[2022-04-19 06:37:19 tiny] (main.py 148): INFO Max accuracy: 67.19%
[2022-04-19 06:37:31 tiny] (main.py 226): INFO Train: [160/300][0/1251]	eta 4:18:25 lr 0.000453	time 12.3944 (12.3944)	loss 4.6533 (4.6533)	grad_norm 2.7315 (2.7315)	mem 5329MB
[2022-04-19 06:38:33 tiny] (main.py 226): INFO Train: [160/300][100/1251]	eta 0:14:00 lr 0.000453	time 0.6854 (0.7298)	loss 4.2815 (3.9531)	grad_norm 4.7485 (4.4364)	mem 5329MB
[2022-04-19 06:39:32 tiny] (main.py 226): INFO Train: [160/300][200/1251]	eta 0:11:32 lr 0.000452	time 0.5677 (0.6593)	loss 4.4029 (3.9370)	grad_norm 5.6198 (4.3507)	mem 5329MB
[2022-04-19 06:40:33 tiny] (main.py 226): INFO Train: [160/300][300/1251]	eta 0:10:11 lr 0.000452	time 0.6291 (0.6432)	loss 3.0146 (3.9273)	grad_norm 6.1866 (4.2611)	mem 5329MB
[2022-04-19 06:41:34 tiny] (main.py 226): INFO Train: [160/300][400/1251]	eta 0:09:00 lr 0.000452	time 0.7599 (0.6352)	loss 4.8895 (3.9285)	grad_norm 3.2359 (inf)	mem 5329MB
[2022-04-19 06:42:35 tiny] (main.py 226): INFO Train: [160/300][500/1251]	eta 0:07:53 lr 0.000451	time 0.6753 (0.6306)	loss 3.2499 (3.9171)	grad_norm 3.4368 (inf)	mem 5329MB
[2022-04-19 06:43:36 tiny] (main.py 226): INFO Train: [160/300][600/1251]	eta 0:06:48 lr 0.000451	time 0.7638 (0.6276)	loss 4.7098 (3.9157)	grad_norm 7.5254 (inf)	mem 5329MB
[2022-04-19 06:44:36 tiny] (main.py 226): INFO Train: [160/300][700/1251]	eta 0:05:43 lr 0.000450	time 0.6201 (0.6239)	loss 2.9660 (3.9119)	grad_norm 3.1824 (inf)	mem 5329MB
[2022-04-19 06:45:36 tiny] (main.py 226): INFO Train: [160/300][800/1251]	eta 0:04:39 lr 0.000450	time 0.5819 (0.6201)	loss 4.3600 (3.9087)	grad_norm 3.6965 (inf)	mem 5329MB
[2022-04-19 06:46:35 tiny] (main.py 226): INFO Train: [160/300][900/1251]	eta 0:03:36 lr 0.000450	time 0.7857 (0.6171)	loss 4.6043 (3.9123)	grad_norm 4.1541 (inf)	mem 5329MB
[2022-04-19 06:47:34 tiny] (main.py 226): INFO Train: [160/300][1000/1251]	eta 0:02:34 lr 0.000449	time 0.5007 (0.6138)	loss 4.7876 (3.9136)	grad_norm 3.4649 (inf)	mem 5329MB
[2022-04-19 06:48:33 tiny] (main.py 226): INFO Train: [160/300][1100/1251]	eta 0:01:32 lr 0.000449	time 0.6440 (0.6119)	loss 4.4595 (3.9034)	grad_norm 3.7722 (inf)	mem 5329MB
[2022-04-19 06:49:31 tiny] (main.py 226): INFO Train: [160/300][1200/1251]	eta 0:00:31 lr 0.000448	time 0.5376 (0.6095)	loss 4.3289 (3.9100)	grad_norm 3.2574 (inf)	mem 5329MB
[2022-04-19 06:49:53 tiny] (main.py 233): INFO EPOCH 160 training takes 0:12:34
[2022-04-19 06:50:05 tiny] (main.py 273): INFO Test: [0/49]	Time 11.857 (11.857)	Loss 1.6398 (1.6398)	Acc@1 67.480 (67.480)	Acc@5 89.062 (89.062)	Mem 5329MB
[2022-04-19 06:50:24 tiny] (main.py 279): INFO  * Acc@1 66.732 Acc@5 87.682
[2022-04-19 06:50:24 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 66.7%
[2022-04-19 06:50:24 tiny] (main.py 148): INFO Max accuracy: 67.19%
[2022-04-19 06:50:36 tiny] (main.py 226): INFO Train: [161/300][0/1251]	eta 4:08:48 lr 0.000448	time 11.9334 (11.9334)	loss 4.1201 (4.1201)	grad_norm 4.0087 (4.0087)	mem 5329MB
[2022-04-19 06:51:38 tiny] (main.py 226): INFO Train: [161/300][100/1251]	eta 0:13:56 lr 0.000448	time 0.5925 (0.7266)	loss 3.7479 (3.8580)	grad_norm 2.9471 (4.0548)	mem 5329MB
[2022-04-19 06:52:36 tiny] (main.py 226): INFO Train: [161/300][200/1251]	eta 0:11:29 lr 0.000447	time 0.4294 (0.6560)	loss 3.5315 (3.8575)	grad_norm 4.2853 (4.0879)	mem 5329MB
[2022-04-19 06:53:35 tiny] (main.py 226): INFO Train: [161/300][300/1251]	eta 0:10:02 lr 0.000447	time 0.5213 (0.6335)	loss 4.5284 (3.8904)	grad_norm 4.6463 (4.2007)	mem 5329MB
[2022-04-19 06:54:34 tiny] (main.py 226): INFO Train: [161/300][400/1251]	eta 0:08:49 lr 0.000446	time 0.7944 (0.6217)	loss 4.7606 (3.9178)	grad_norm 3.8027 (4.1962)	mem 5329MB
[2022-04-19 06:55:33 tiny] (main.py 226): INFO Train: [161/300][500/1251]	eta 0:07:41 lr 0.000446	time 0.6089 (0.6151)	loss 3.4667 (3.9251)	grad_norm 2.2938 (4.1736)	mem 5329MB
[2022-04-19 06:56:31 tiny] (main.py 226): INFO Train: [161/300][600/1251]	eta 0:06:36 lr 0.000446	time 0.5787 (0.6098)	loss 4.6202 (3.9230)	grad_norm 3.8423 (4.2921)	mem 5329MB
[2022-04-19 06:57:30 tiny] (main.py 226): INFO Train: [161/300][700/1251]	eta 0:05:34 lr 0.000445	time 0.4206 (0.6072)	loss 4.9964 (3.9269)	grad_norm 4.5496 (4.2788)	mem 5329MB
[2022-04-19 06:58:29 tiny] (main.py 226): INFO Train: [161/300][800/1251]	eta 0:04:32 lr 0.000445	time 0.6053 (0.6050)	loss 3.9722 (3.9361)	grad_norm 3.2211 (4.2980)	mem 5329MB
[2022-04-19 06:59:28 tiny] (main.py 226): INFO Train: [161/300][900/1251]	eta 0:03:31 lr 0.000444	time 0.4584 (0.6033)	loss 4.3993 (3.9406)	grad_norm 4.0050 (4.2815)	mem 5329MB
[2022-04-19 07:00:27 tiny] (main.py 226): INFO Train: [161/300][1000/1251]	eta 0:02:31 lr 0.000444	time 0.7332 (0.6019)	loss 4.4813 (3.9447)	grad_norm 4.6322 (4.2773)	mem 5329MB
[2022-04-19 07:01:26 tiny] (main.py 226): INFO Train: [161/300][1100/1251]	eta 0:01:30 lr 0.000444	time 0.5674 (0.6005)	loss 4.5015 (3.9415)	grad_norm 3.4449 (4.2717)	mem 5329MB
[2022-04-19 07:02:24 tiny] (main.py 226): INFO Train: [161/300][1200/1251]	eta 0:00:30 lr 0.000443	time 0.7067 (0.5995)	loss 4.1578 (3.9421)	grad_norm 5.6993 (nan)	mem 5329MB
[2022-04-19 07:02:46 tiny] (main.py 233): INFO EPOCH 161 training takes 0:12:21
[2022-04-19 07:02:59 tiny] (main.py 273): INFO Test: [0/49]	Time 12.234 (12.234)	Loss 1.5323 (1.5323)	Acc@1 67.578 (67.578)	Acc@5 87.988 (87.988)	Mem 5329MB
[2022-04-19 07:03:17 tiny] (main.py 279): INFO  * Acc@1 67.264 Acc@5 88.118
[2022-04-19 07:03:17 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 67.3%
[2022-04-19 07:03:17 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_161.pth saving......
[2022-04-19 07:03:18 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_161.pth saved !!!
[2022-04-19 07:03:18 tiny] (main.py 148): INFO Max accuracy: 67.26%
[2022-04-19 07:03:28 tiny] (main.py 226): INFO Train: [162/300][0/1251]	eta 3:41:09 lr 0.000443	time 10.6068 (10.6068)	loss 3.2589 (3.2589)	grad_norm 2.9383 (2.9383)	mem 5329MB
[2022-04-19 07:04:31 tiny] (main.py 226): INFO Train: [162/300][100/1251]	eta 0:14:00 lr 0.000443	time 0.6331 (0.7303)	loss 3.4342 (3.8539)	grad_norm 2.8195 (4.6754)	mem 5329MB
[2022-04-19 07:05:30 tiny] (main.py 226): INFO Train: [162/300][200/1251]	eta 0:11:32 lr 0.000442	time 0.6454 (0.6586)	loss 3.7792 (3.8810)	grad_norm 2.6226 (4.4691)	mem 5329MB
[2022-04-19 07:06:29 tiny] (main.py 226): INFO Train: [162/300][300/1251]	eta 0:10:03 lr 0.000442	time 0.6275 (0.6345)	loss 4.1451 (3.8828)	grad_norm 4.3879 (4.6413)	mem 5329MB
[2022-04-19 07:07:27 tiny] (main.py 226): INFO Train: [162/300][400/1251]	eta 0:08:49 lr 0.000441	time 0.6017 (0.6221)	loss 3.8138 (3.9037)	grad_norm 2.9513 (4.5670)	mem 5329MB
[2022-04-19 07:08:26 tiny] (main.py 226): INFO Train: [162/300][500/1251]	eta 0:07:41 lr 0.000441	time 0.5161 (0.6149)	loss 4.4273 (3.9125)	grad_norm 3.6146 (4.5364)	mem 5329MB
[2022-04-19 07:09:25 tiny] (main.py 226): INFO Train: [162/300][600/1251]	eta 0:06:37 lr 0.000440	time 0.7022 (0.6108)	loss 3.2031 (3.9242)	grad_norm 3.6812 (4.5286)	mem 5329MB
[2022-04-19 07:10:23 tiny] (main.py 226): INFO Train: [162/300][700/1251]	eta 0:05:34 lr 0.000440	time 0.7298 (0.6074)	loss 4.2418 (3.9323)	grad_norm 4.3127 (4.5044)	mem 5329MB
[2022-04-19 07:11:22 tiny] (main.py 226): INFO Train: [162/300][800/1251]	eta 0:04:32 lr 0.000440	time 0.7214 (0.6049)	loss 4.2285 (3.9415)	grad_norm 3.4771 (4.5266)	mem 5329MB
[2022-04-19 07:12:21 tiny] (main.py 226): INFO Train: [162/300][900/1251]	eta 0:03:31 lr 0.000439	time 0.5604 (0.6030)	loss 3.8774 (3.9390)	grad_norm 2.9187 (4.5367)	mem 5329MB
[2022-04-19 07:13:19 tiny] (main.py 226): INFO Train: [162/300][1000/1251]	eta 0:02:30 lr 0.000439	time 0.5644 (0.6013)	loss 2.8903 (3.9345)	grad_norm 3.7958 (4.4926)	mem 5329MB
[2022-04-19 07:14:19 tiny] (main.py 226): INFO Train: [162/300][1100/1251]	eta 0:01:30 lr 0.000438	time 0.5618 (0.6003)	loss 4.7556 (3.9415)	grad_norm 3.0571 (4.4762)	mem 5329MB
[2022-04-19 07:15:18 tiny] (main.py 226): INFO Train: [162/300][1200/1251]	eta 0:00:30 lr 0.000438	time 0.4010 (0.5995)	loss 4.6960 (3.9522)	grad_norm 4.5319 (4.5004)	mem 5329MB
[2022-04-19 07:15:40 tiny] (main.py 233): INFO EPOCH 162 training takes 0:12:22
[2022-04-19 07:15:52 tiny] (main.py 273): INFO Test: [0/49]	Time 12.272 (12.272)	Loss 1.7052 (1.7052)	Acc@1 63.867 (63.867)	Acc@5 86.230 (86.230)	Mem 5329MB
[2022-04-19 07:16:11 tiny] (main.py 279): INFO  * Acc@1 67.236 Acc@5 88.234
[2022-04-19 07:16:11 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 67.2%
[2022-04-19 07:16:11 tiny] (main.py 148): INFO Max accuracy: 67.26%
[2022-04-19 07:16:22 tiny] (main.py 226): INFO Train: [163/300][0/1251]	eta 3:48:34 lr 0.000438	time 10.9626 (10.9626)	loss 4.3040 (4.3040)	grad_norm 3.7081 (3.7081)	mem 5329MB
[2022-04-19 07:17:25 tiny] (main.py 226): INFO Train: [163/300][100/1251]	eta 0:13:58 lr 0.000437	time 0.5837 (0.7285)	loss 2.9594 (3.9664)	grad_norm 5.3008 (4.2917)	mem 5329MB
[2022-04-19 07:18:23 tiny] (main.py 226): INFO Train: [163/300][200/1251]	eta 0:11:30 lr 0.000437	time 0.5286 (0.6566)	loss 4.0812 (3.9321)	grad_norm 2.8365 (4.3205)	mem 5329MB
[2022-04-19 07:19:21 tiny] (main.py 226): INFO Train: [163/300][300/1251]	eta 0:10:01 lr 0.000437	time 0.5382 (0.6321)	loss 2.5185 (3.9233)	grad_norm 2.9454 (4.2489)	mem 5329MB
[2022-04-19 07:20:20 tiny] (main.py 226): INFO Train: [163/300][400/1251]	eta 0:08:48 lr 0.000436	time 0.4753 (0.6210)	loss 3.5929 (3.9472)	grad_norm 3.4808 (4.3119)	mem 5329MB
[2022-04-19 07:21:18 tiny] (main.py 226): INFO Train: [163/300][500/1251]	eta 0:07:40 lr 0.000436	time 0.5535 (0.6135)	loss 2.7763 (3.9367)	grad_norm 4.8351 (4.3103)	mem 5329MB
[2022-04-19 07:22:17 tiny] (main.py 226): INFO Train: [163/300][600/1251]	eta 0:06:36 lr 0.000435	time 0.4610 (0.6095)	loss 3.7811 (3.9400)	grad_norm 4.0638 (4.3205)	mem 5329MB
[2022-04-19 07:23:16 tiny] (main.py 226): INFO Train: [163/300][700/1251]	eta 0:05:34 lr 0.000435	time 0.3575 (0.6066)	loss 4.7371 (3.9431)	grad_norm 6.3076 (inf)	mem 5329MB
[2022-04-19 07:24:15 tiny] (main.py 226): INFO Train: [163/300][800/1251]	eta 0:04:32 lr 0.000435	time 0.5685 (0.6042)	loss 4.2029 (3.9336)	grad_norm 3.4441 (inf)	mem 5329MB
[2022-04-19 07:25:14 tiny] (main.py 226): INFO Train: [163/300][900/1251]	eta 0:03:31 lr 0.000434	time 0.5903 (0.6026)	loss 4.6361 (3.9416)	grad_norm 4.7272 (inf)	mem 5329MB
[2022-04-19 07:26:12 tiny] (main.py 226): INFO Train: [163/300][1000/1251]	eta 0:02:30 lr 0.000434	time 0.4139 (0.6006)	loss 2.6163 (3.9407)	grad_norm 4.4562 (inf)	mem 5329MB
[2022-04-19 07:27:12 tiny] (main.py 226): INFO Train: [163/300][1100/1251]	eta 0:01:30 lr 0.000433	time 0.6503 (0.5998)	loss 4.8193 (3.9369)	grad_norm 3.2246 (inf)	mem 5329MB
[2022-04-19 07:28:10 tiny] (main.py 226): INFO Train: [163/300][1200/1251]	eta 0:00:30 lr 0.000433	time 0.5835 (0.5989)	loss 4.3865 (3.9369)	grad_norm 3.2661 (inf)	mem 5329MB
[2022-04-19 07:28:32 tiny] (main.py 233): INFO EPOCH 163 training takes 0:12:21
[2022-04-19 07:28:42 tiny] (main.py 273): INFO Test: [0/49]	Time 10.093 (10.093)	Loss 1.7412 (1.7412)	Acc@1 63.574 (63.574)	Acc@5 86.035 (86.035)	Mem 5329MB
[2022-04-19 07:29:03 tiny] (main.py 279): INFO  * Acc@1 67.454 Acc@5 88.088
[2022-04-19 07:29:03 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 67.5%
[2022-04-19 07:29:03 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_163.pth saving......
[2022-04-19 07:29:03 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_163.pth saved !!!
[2022-04-19 07:29:03 tiny] (main.py 148): INFO Max accuracy: 67.45%
[2022-04-19 07:29:15 tiny] (main.py 226): INFO Train: [164/300][0/1251]	eta 4:08:58 lr 0.000433	time 11.9411 (11.9411)	loss 4.3064 (4.3064)	grad_norm 6.5606 (6.5606)	mem 5329MB
[2022-04-19 07:30:17 tiny] (main.py 226): INFO Train: [164/300][100/1251]	eta 0:13:55 lr 0.000432	time 0.7490 (0.7257)	loss 3.1094 (4.0542)	grad_norm 7.7157 (4.8084)	mem 5329MB
[2022-04-19 07:31:16 tiny] (main.py 226): INFO Train: [164/300][200/1251]	eta 0:11:31 lr 0.000432	time 0.8503 (0.6581)	loss 4.1214 (4.0253)	grad_norm 3.1235 (4.7940)	mem 5329MB
[2022-04-19 07:32:14 tiny] (main.py 226): INFO Train: [164/300][300/1251]	eta 0:10:02 lr 0.000431	time 0.5897 (0.6341)	loss 3.1191 (3.9801)	grad_norm 6.5351 (4.5778)	mem 5329MB
[2022-04-19 07:33:13 tiny] (main.py 226): INFO Train: [164/300][400/1251]	eta 0:08:49 lr 0.000431	time 0.7104 (0.6218)	loss 4.3547 (3.9734)	grad_norm 3.6416 (4.5225)	mem 5329MB
[2022-04-19 07:34:12 tiny] (main.py 226): INFO Train: [164/300][500/1251]	eta 0:07:42 lr 0.000431	time 0.5963 (0.6160)	loss 3.7380 (3.9706)	grad_norm 3.6509 (4.5256)	mem 5329MB
[2022-04-19 07:35:11 tiny] (main.py 226): INFO Train: [164/300][600/1251]	eta 0:06:38 lr 0.000430	time 0.5655 (0.6121)	loss 4.7723 (3.9670)	grad_norm 3.2259 (4.6149)	mem 5329MB
[2022-04-19 07:36:10 tiny] (main.py 226): INFO Train: [164/300][700/1251]	eta 0:05:35 lr 0.000430	time 0.6315 (0.6085)	loss 4.3057 (3.9651)	grad_norm 2.8304 (4.6260)	mem 5329MB
[2022-04-19 07:37:09 tiny] (main.py 226): INFO Train: [164/300][800/1251]	eta 0:04:33 lr 0.000429	time 0.5072 (0.6066)	loss 3.9349 (3.9722)	grad_norm 3.2571 (4.5512)	mem 5329MB
[2022-04-19 07:38:07 tiny] (main.py 226): INFO Train: [164/300][900/1251]	eta 0:03:31 lr 0.000429	time 0.6436 (0.6039)	loss 4.1605 (3.9758)	grad_norm 2.7454 (4.5087)	mem 5329MB
[2022-04-19 07:39:06 tiny] (main.py 226): INFO Train: [164/300][1000/1251]	eta 0:02:31 lr 0.000429	time 0.6228 (0.6025)	loss 2.7345 (3.9669)	grad_norm 3.4826 (4.5593)	mem 5329MB
[2022-04-19 07:40:05 tiny] (main.py 226): INFO Train: [164/300][1100/1251]	eta 0:01:30 lr 0.000428	time 0.5268 (0.6007)	loss 4.3911 (3.9648)	grad_norm 3.2545 (4.5243)	mem 5329MB
[2022-04-19 07:41:04 tiny] (main.py 226): INFO Train: [164/300][1200/1251]	eta 0:00:30 lr 0.000428	time 0.6074 (0.5997)	loss 3.4020 (3.9665)	grad_norm 11.0582 (4.5209)	mem 5329MB
[2022-04-19 07:41:26 tiny] (main.py 233): INFO EPOCH 164 training takes 0:12:22
[2022-04-19 07:41:37 tiny] (main.py 273): INFO Test: [0/49]	Time 11.391 (11.391)	Loss 1.6157 (1.6157)	Acc@1 67.480 (67.480)	Acc@5 88.867 (88.867)	Mem 5329MB
[2022-04-19 07:41:57 tiny] (main.py 279): INFO  * Acc@1 67.098 Acc@5 88.180
[2022-04-19 07:41:57 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 67.1%
[2022-04-19 07:41:57 tiny] (main.py 148): INFO Max accuracy: 67.45%
[2022-04-19 07:42:08 tiny] (main.py 226): INFO Train: [165/300][0/1251]	eta 3:49:30 lr 0.000428	time 11.0077 (11.0077)	loss 3.3892 (3.3892)	grad_norm 2.8418 (2.8418)	mem 5329MB
[2022-04-19 07:43:10 tiny] (main.py 226): INFO Train: [165/300][100/1251]	eta 0:14:00 lr 0.000427	time 0.5542 (0.7299)	loss 4.2497 (3.9791)	grad_norm 3.4689 (4.3701)	mem 5329MB
[2022-04-19 07:44:09 tiny] (main.py 226): INFO Train: [165/300][200/1251]	eta 0:11:30 lr 0.000427	time 0.6957 (0.6567)	loss 3.6747 (3.9400)	grad_norm 4.1417 (4.4126)	mem 5329MB
[2022-04-19 07:45:07 tiny] (main.py 226): INFO Train: [165/300][300/1251]	eta 0:10:02 lr 0.000426	time 0.5117 (0.6334)	loss 3.0076 (3.9613)	grad_norm 3.0879 (inf)	mem 5329MB
[2022-04-19 07:46:06 tiny] (main.py 226): INFO Train: [165/300][400/1251]	eta 0:08:48 lr 0.000426	time 0.5615 (0.6216)	loss 3.5689 (3.9509)	grad_norm 2.6977 (inf)	mem 5329MB
[2022-04-19 07:47:04 tiny] (main.py 226): INFO Train: [165/300][500/1251]	eta 0:07:41 lr 0.000426	time 0.4814 (0.6139)	loss 4.7490 (3.9536)	grad_norm 8.0834 (inf)	mem 5329MB
[2022-04-19 07:48:04 tiny] (main.py 226): INFO Train: [165/300][600/1251]	eta 0:06:37 lr 0.000425	time 0.4853 (0.6103)	loss 4.0799 (3.9552)	grad_norm 4.6351 (inf)	mem 5329MB
[2022-04-19 07:49:02 tiny] (main.py 226): INFO Train: [165/300][700/1251]	eta 0:05:34 lr 0.000425	time 0.4571 (0.6066)	loss 4.2182 (3.9692)	grad_norm 6.7638 (inf)	mem 5329MB
[2022-04-19 07:50:01 tiny] (main.py 226): INFO Train: [165/300][800/1251]	eta 0:04:32 lr 0.000424	time 0.4998 (0.6042)	loss 3.7620 (3.9658)	grad_norm 4.4446 (inf)	mem 5329MB
[2022-04-19 07:51:00 tiny] (main.py 226): INFO Train: [165/300][900/1251]	eta 0:03:31 lr 0.000424	time 0.6443 (0.6025)	loss 3.5434 (3.9590)	grad_norm 5.7600 (inf)	mem 5329MB
[2022-04-19 07:51:59 tiny] (main.py 226): INFO Train: [165/300][1000/1251]	eta 0:02:30 lr 0.000423	time 0.6922 (0.6016)	loss 4.3073 (3.9475)	grad_norm 7.0672 (inf)	mem 5329MB
[2022-04-19 07:52:57 tiny] (main.py 226): INFO Train: [165/300][1100/1251]	eta 0:01:30 lr 0.000423	time 0.6992 (0.6001)	loss 4.3772 (3.9431)	grad_norm 4.9227 (inf)	mem 5329MB
[2022-04-19 07:53:56 tiny] (main.py 226): INFO Train: [165/300][1200/1251]	eta 0:00:30 lr 0.000423	time 0.6592 (0.5990)	loss 4.5369 (3.9497)	grad_norm 3.9207 (inf)	mem 5329MB
[2022-04-19 07:54:18 tiny] (main.py 233): INFO EPOCH 165 training takes 0:12:21
[2022-04-19 07:54:30 tiny] (main.py 273): INFO Test: [0/49]	Time 11.381 (11.381)	Loss 1.6895 (1.6895)	Acc@1 64.844 (64.844)	Acc@5 87.305 (87.305)	Mem 5329MB
[2022-04-19 07:54:49 tiny] (main.py 279): INFO  * Acc@1 67.038 Acc@5 88.028
[2022-04-19 07:54:49 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 67.0%
[2022-04-19 07:54:49 tiny] (main.py 148): INFO Max accuracy: 67.45%
[2022-04-19 07:55:01 tiny] (main.py 226): INFO Train: [166/300][0/1251]	eta 4:00:45 lr 0.000422	time 11.5473 (11.5473)	loss 4.7435 (4.7435)	grad_norm 5.7200 (5.7200)	mem 5329MB
[2022-04-19 07:56:03 tiny] (main.py 226): INFO Train: [166/300][100/1251]	eta 0:14:01 lr 0.000422	time 0.5712 (0.7309)	loss 4.3917 (3.9451)	grad_norm 7.4491 (4.6576)	mem 5329MB
[2022-04-19 07:57:01 tiny] (main.py 226): INFO Train: [166/300][200/1251]	eta 0:11:31 lr 0.000422	time 0.3783 (0.6578)	loss 3.8557 (3.8938)	grad_norm 4.9115 (4.4780)	mem 5329MB
[2022-04-19 07:58:00 tiny] (main.py 226): INFO Train: [166/300][300/1251]	eta 0:10:02 lr 0.000421	time 0.5057 (0.6332)	loss 4.4303 (3.8992)	grad_norm 2.9286 (4.5456)	mem 5329MB
[2022-04-19 07:58:58 tiny] (main.py 226): INFO Train: [166/300][400/1251]	eta 0:08:49 lr 0.000421	time 0.7534 (0.6218)	loss 3.7756 (3.9063)	grad_norm 2.9273 (4.5626)	mem 5329MB
[2022-04-19 07:59:57 tiny] (main.py 226): INFO Train: [166/300][500/1251]	eta 0:07:41 lr 0.000420	time 0.4256 (0.6143)	loss 4.3703 (3.9087)	grad_norm 4.3733 (4.5649)	mem 5329MB
[2022-04-19 08:00:56 tiny] (main.py 226): INFO Train: [166/300][600/1251]	eta 0:06:37 lr 0.000420	time 0.4146 (0.6101)	loss 3.8761 (3.9111)	grad_norm 4.0457 (4.4812)	mem 5329MB
[2022-04-19 08:01:55 tiny] (main.py 226): INFO Train: [166/300][700/1251]	eta 0:05:34 lr 0.000420	time 0.5842 (0.6069)	loss 4.2839 (3.9199)	grad_norm 2.8684 (4.4438)	mem 5329MB
[2022-04-19 08:02:53 tiny] (main.py 226): INFO Train: [166/300][800/1251]	eta 0:04:32 lr 0.000419	time 0.6940 (0.6045)	loss 2.9079 (3.9152)	grad_norm 6.0720 (4.4184)	mem 5329MB
[2022-04-19 08:03:52 tiny] (main.py 226): INFO Train: [166/300][900/1251]	eta 0:03:31 lr 0.000419	time 0.5709 (0.6027)	loss 4.1888 (3.9099)	grad_norm 2.7034 (4.4059)	mem 5329MB
[2022-04-19 08:04:51 tiny] (main.py 226): INFO Train: [166/300][1000/1251]	eta 0:02:30 lr 0.000418	time 0.5804 (0.6013)	loss 4.4356 (3.9169)	grad_norm 3.1961 (4.4128)	mem 5329MB
[2022-04-19 08:05:50 tiny] (main.py 226): INFO Train: [166/300][1100/1251]	eta 0:01:30 lr 0.000418	time 0.7167 (0.6002)	loss 4.3291 (3.9130)	grad_norm 3.8812 (inf)	mem 5329MB
[2022-04-19 08:06:49 tiny] (main.py 226): INFO Train: [166/300][1200/1251]	eta 0:00:30 lr 0.000418	time 0.5973 (0.5991)	loss 4.4615 (3.9240)	grad_norm 3.7375 (inf)	mem 5329MB
[2022-04-19 08:07:10 tiny] (main.py 233): INFO EPOCH 166 training takes 0:12:21
[2022-04-19 08:07:21 tiny] (main.py 273): INFO Test: [0/49]	Time 10.915 (10.915)	Loss 1.5876 (1.5876)	Acc@1 66.699 (66.699)	Acc@5 87.988 (87.988)	Mem 5329MB
[2022-04-19 08:07:42 tiny] (main.py 279): INFO  * Acc@1 67.048 Acc@5 88.034
[2022-04-19 08:07:42 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 67.0%
[2022-04-19 08:07:42 tiny] (main.py 148): INFO Max accuracy: 67.45%
[2022-04-19 08:07:54 tiny] (main.py 226): INFO Train: [167/300][0/1251]	eta 4:08:12 lr 0.000417	time 11.9041 (11.9041)	loss 4.5582 (4.5582)	grad_norm 5.7335 (5.7335)	mem 5329MB
[2022-04-19 08:08:55 tiny] (main.py 226): INFO Train: [167/300][100/1251]	eta 0:14:00 lr 0.000417	time 0.5459 (0.7300)	loss 4.1614 (3.9161)	grad_norm 3.5571 (4.6654)	mem 5329MB
[2022-04-19 08:09:54 tiny] (main.py 226): INFO Train: [167/300][200/1251]	eta 0:11:33 lr 0.000417	time 0.7017 (0.6598)	loss 4.2663 (3.9984)	grad_norm 3.4071 (4.5144)	mem 5329MB
[2022-04-19 08:10:53 tiny] (main.py 226): INFO Train: [167/300][300/1251]	eta 0:10:04 lr 0.000416	time 0.6450 (0.6352)	loss 4.7612 (4.0002)	grad_norm 6.2425 (4.4828)	mem 5329MB
[2022-04-19 08:11:51 tiny] (main.py 226): INFO Train: [167/300][400/1251]	eta 0:08:49 lr 0.000416	time 0.4519 (0.6225)	loss 4.8192 (3.9594)	grad_norm 4.1947 (4.4710)	mem 5329MB
[2022-04-19 08:12:50 tiny] (main.py 226): INFO Train: [167/300][500/1251]	eta 0:07:42 lr 0.000415	time 0.7336 (0.6161)	loss 4.7037 (3.9622)	grad_norm 4.3522 (4.4862)	mem 5329MB
[2022-04-19 08:13:49 tiny] (main.py 226): INFO Train: [167/300][600/1251]	eta 0:06:37 lr 0.000415	time 0.7008 (0.6113)	loss 4.7269 (3.9655)	grad_norm 3.8971 (nan)	mem 5329MB
[2022-04-19 08:14:48 tiny] (main.py 226): INFO Train: [167/300][700/1251]	eta 0:05:34 lr 0.000414	time 0.4975 (0.6076)	loss 4.7661 (3.9678)	grad_norm 3.0555 (nan)	mem 5329MB
[2022-04-19 08:15:47 tiny] (main.py 226): INFO Train: [167/300][800/1251]	eta 0:04:33 lr 0.000414	time 0.4800 (0.6055)	loss 3.8512 (3.9656)	grad_norm 5.8807 (nan)	mem 5329MB
[2022-04-19 08:16:45 tiny] (main.py 226): INFO Train: [167/300][900/1251]	eta 0:03:31 lr 0.000414	time 0.5192 (0.6031)	loss 3.1935 (3.9555)	grad_norm 2.7863 (nan)	mem 5329MB
[2022-04-19 08:17:44 tiny] (main.py 226): INFO Train: [167/300][1000/1251]	eta 0:02:30 lr 0.000413	time 0.5280 (0.6016)	loss 2.7323 (3.9554)	grad_norm 2.8729 (nan)	mem 5329MB
[2022-04-19 08:18:43 tiny] (main.py 226): INFO Train: [167/300][1100/1251]	eta 0:01:30 lr 0.000413	time 0.5109 (0.6003)	loss 3.9138 (3.9509)	grad_norm 3.5330 (nan)	mem 5329MB
[2022-04-19 08:19:41 tiny] (main.py 226): INFO Train: [167/300][1200/1251]	eta 0:00:30 lr 0.000412	time 0.3499 (0.5990)	loss 4.7324 (3.9478)	grad_norm 3.2709 (nan)	mem 5329MB
[2022-04-19 08:20:03 tiny] (main.py 233): INFO EPOCH 167 training takes 0:12:21
[2022-04-19 08:20:15 tiny] (main.py 273): INFO Test: [0/49]	Time 11.886 (11.886)	Loss 1.6146 (1.6146)	Acc@1 66.504 (66.504)	Acc@5 87.500 (87.500)	Mem 5329MB
[2022-04-19 08:20:34 tiny] (main.py 279): INFO  * Acc@1 67.522 Acc@5 88.180
[2022-04-19 08:20:34 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 67.5%
[2022-04-19 08:20:34 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_167.pth saving......
[2022-04-19 08:20:35 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_167.pth saved !!!
[2022-04-19 08:20:35 tiny] (main.py 148): INFO Max accuracy: 67.52%
[2022-04-19 08:20:47 tiny] (main.py 226): INFO Train: [168/300][0/1251]	eta 4:17:35 lr 0.000412	time 12.3547 (12.3547)	loss 4.0654 (4.0654)	grad_norm 3.1234 (3.1234)	mem 5329MB
[2022-04-19 08:21:48 tiny] (main.py 226): INFO Train: [168/300][100/1251]	eta 0:14:00 lr 0.000412	time 0.5699 (0.7304)	loss 4.3620 (3.9882)	grad_norm 4.2851 (4.1458)	mem 5329MB
[2022-04-19 08:22:47 tiny] (main.py 226): INFO Train: [168/300][200/1251]	eta 0:11:32 lr 0.000411	time 0.5904 (0.6585)	loss 3.4346 (3.9251)	grad_norm 3.1671 (4.3822)	mem 5329MB
[2022-04-19 08:23:45 tiny] (main.py 226): INFO Train: [168/300][300/1251]	eta 0:10:02 lr 0.000411	time 0.6397 (0.6337)	loss 3.6631 (3.9172)	grad_norm 9.5138 (4.4522)	mem 5329MB
[2022-04-19 08:24:44 tiny] (main.py 226): INFO Train: [168/300][400/1251]	eta 0:08:48 lr 0.000411	time 0.6310 (0.6209)	loss 4.1493 (3.9309)	grad_norm 4.1926 (4.5585)	mem 5329MB
[2022-04-19 08:25:42 tiny] (main.py 226): INFO Train: [168/300][500/1251]	eta 0:07:41 lr 0.000410	time 0.7552 (0.6140)	loss 3.5593 (3.9200)	grad_norm 2.9813 (4.5764)	mem 5329MB
[2022-04-19 08:26:41 tiny] (main.py 226): INFO Train: [168/300][600/1251]	eta 0:06:36 lr 0.000410	time 0.6599 (0.6097)	loss 4.1255 (3.9130)	grad_norm 3.9237 (4.5017)	mem 5329MB
[2022-04-19 08:27:40 tiny] (main.py 226): INFO Train: [168/300][700/1251]	eta 0:05:34 lr 0.000409	time 0.4961 (0.6066)	loss 3.2642 (3.9045)	grad_norm 4.0097 (4.4615)	mem 5329MB
[2022-04-19 08:28:39 tiny] (main.py 226): INFO Train: [168/300][800/1251]	eta 0:04:32 lr 0.000409	time 0.5687 (0.6044)	loss 3.0109 (3.9113)	grad_norm 4.2751 (4.4573)	mem 5329MB
[2022-04-19 08:29:37 tiny] (main.py 226): INFO Train: [168/300][900/1251]	eta 0:03:31 lr 0.000409	time 0.3783 (0.6023)	loss 4.0355 (3.9271)	grad_norm 5.3069 (4.4339)	mem 5329MB
[2022-04-19 08:30:36 tiny] (main.py 226): INFO Train: [168/300][1000/1251]	eta 0:02:30 lr 0.000408	time 0.7428 (0.6009)	loss 2.9831 (3.9282)	grad_norm 3.7773 (4.4394)	mem 5329MB
[2022-04-19 08:31:35 tiny] (main.py 226): INFO Train: [168/300][1100/1251]	eta 0:01:30 lr 0.000408	time 0.6074 (0.5997)	loss 3.7032 (3.9292)	grad_norm 3.3739 (4.4410)	mem 5329MB
[2022-04-19 08:32:34 tiny] (main.py 226): INFO Train: [168/300][1200/1251]	eta 0:00:30 lr 0.000407	time 0.3958 (0.5992)	loss 4.0708 (3.9138)	grad_norm 4.1494 (4.4481)	mem 5329MB
[2022-04-19 08:32:56 tiny] (main.py 233): INFO EPOCH 168 training takes 0:12:21
[2022-04-19 08:33:08 tiny] (main.py 273): INFO Test: [0/49]	Time 11.407 (11.407)	Loss 1.5103 (1.5103)	Acc@1 66.504 (66.504)	Acc@5 89.355 (89.355)	Mem 5329MB
[2022-04-19 08:33:28 tiny] (main.py 279): INFO  * Acc@1 66.742 Acc@5 87.890
[2022-04-19 08:33:28 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 66.7%
[2022-04-19 08:33:28 tiny] (main.py 148): INFO Max accuracy: 67.52%
[2022-04-19 08:33:38 tiny] (main.py 226): INFO Train: [169/300][0/1251]	eta 3:29:09 lr 0.000407	time 10.0313 (10.0313)	loss 4.2050 (4.2050)	grad_norm 4.9186 (4.9186)	mem 5329MB
[2022-04-19 08:34:41 tiny] (main.py 226): INFO Train: [169/300][100/1251]	eta 0:13:59 lr 0.000407	time 0.6621 (0.7297)	loss 4.1700 (3.8705)	grad_norm 2.2216 (4.6669)	mem 5329MB
[2022-04-19 08:35:40 tiny] (main.py 226): INFO Train: [169/300][200/1251]	eta 0:11:31 lr 0.000406	time 0.6635 (0.6577)	loss 4.6766 (3.8610)	grad_norm 3.2649 (4.3226)	mem 5329MB
[2022-04-19 08:36:39 tiny] (main.py 226): INFO Train: [169/300][300/1251]	eta 0:10:02 lr 0.000406	time 0.5842 (0.6340)	loss 3.9650 (3.8990)	grad_norm 5.4454 (4.4121)	mem 5329MB
[2022-04-19 08:37:37 tiny] (main.py 226): INFO Train: [169/300][400/1251]	eta 0:08:49 lr 0.000406	time 0.6398 (0.6224)	loss 4.2233 (3.9035)	grad_norm 4.3414 (4.4111)	mem 5329MB
[2022-04-19 08:38:36 tiny] (main.py 226): INFO Train: [169/300][500/1251]	eta 0:07:41 lr 0.000405	time 0.4966 (0.6151)	loss 4.0570 (3.9207)	grad_norm 3.9037 (4.3798)	mem 5329MB
[2022-04-19 08:39:35 tiny] (main.py 226): INFO Train: [169/300][600/1251]	eta 0:06:37 lr 0.000405	time 0.7797 (0.6109)	loss 3.2894 (3.9371)	grad_norm 6.9279 (4.4097)	mem 5329MB
[2022-04-19 08:40:33 tiny] (main.py 226): INFO Train: [169/300][700/1251]	eta 0:05:34 lr 0.000404	time 0.3808 (0.6073)	loss 4.3435 (3.9354)	grad_norm 4.5484 (4.4050)	mem 5329MB
[2022-04-19 08:41:32 tiny] (main.py 226): INFO Train: [169/300][800/1251]	eta 0:04:32 lr 0.000404	time 0.6999 (0.6053)	loss 4.5914 (3.9334)	grad_norm 3.9403 (4.4711)	mem 5329MB
[2022-04-19 08:42:31 tiny] (main.py 226): INFO Train: [169/300][900/1251]	eta 0:03:31 lr 0.000404	time 0.6163 (0.6030)	loss 4.6385 (3.9245)	grad_norm 3.9093 (4.4554)	mem 5329MB
[2022-04-19 08:43:30 tiny] (main.py 226): INFO Train: [169/300][1000/1251]	eta 0:02:30 lr 0.000403	time 0.5091 (0.6015)	loss 4.6359 (3.9309)	grad_norm 6.7247 (4.4461)	mem 5329MB
[2022-04-19 08:44:29 tiny] (main.py 226): INFO Train: [169/300][1100/1251]	eta 0:01:30 lr 0.000403	time 0.5672 (0.6003)	loss 4.2171 (3.9339)	grad_norm 5.9103 (4.4423)	mem 5329MB
[2022-04-19 08:45:27 tiny] (main.py 226): INFO Train: [169/300][1200/1251]	eta 0:00:30 lr 0.000402	time 0.5372 (0.5992)	loss 2.6174 (3.9347)	grad_norm 5.4890 (4.4244)	mem 5329MB
[2022-04-19 08:45:49 tiny] (main.py 233): INFO EPOCH 169 training takes 0:12:21
[2022-04-19 08:46:01 tiny] (main.py 273): INFO Test: [0/49]	Time 12.151 (12.151)	Loss 1.7092 (1.7092)	Acc@1 66.211 (66.211)	Acc@5 87.402 (87.402)	Mem 5329MB
[2022-04-19 08:46:20 tiny] (main.py 279): INFO  * Acc@1 67.416 Acc@5 88.212
[2022-04-19 08:46:20 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 67.4%
[2022-04-19 08:46:20 tiny] (main.py 148): INFO Max accuracy: 67.52%
[2022-04-19 08:46:34 tiny] (main.py 226): INFO Train: [170/300][0/1251]	eta 4:32:07 lr 0.000402	time 13.0513 (13.0513)	loss 3.0815 (3.0815)	grad_norm 3.5846 (3.5846)	mem 5329MB
[2022-04-19 08:47:34 tiny] (main.py 226): INFO Train: [170/300][100/1251]	eta 0:14:00 lr 0.000402	time 0.5369 (0.7298)	loss 4.1775 (3.9212)	grad_norm 3.3469 (4.5813)	mem 5329MB
[2022-04-19 08:48:33 tiny] (main.py 226): INFO Train: [170/300][200/1251]	eta 0:11:32 lr 0.000401	time 0.5114 (0.6591)	loss 3.1455 (3.9366)	grad_norm 3.0462 (4.3958)	mem 5329MB
[2022-04-19 08:49:31 tiny] (main.py 226): INFO Train: [170/300][300/1251]	eta 0:10:02 lr 0.000401	time 0.5199 (0.6339)	loss 4.2378 (3.9307)	grad_norm 3.6314 (4.4044)	mem 5329MB
[2022-04-19 08:50:30 tiny] (main.py 226): INFO Train: [170/300][400/1251]	eta 0:08:49 lr 0.000400	time 0.5678 (0.6224)	loss 4.5911 (3.9205)	grad_norm 4.0452 (4.3653)	mem 5329MB
[2022-04-19 08:51:29 tiny] (main.py 226): INFO Train: [170/300][500/1251]	eta 0:07:42 lr 0.000400	time 0.5459 (0.6154)	loss 4.0424 (3.9179)	grad_norm 3.6113 (4.4046)	mem 5329MB
[2022-04-19 08:52:28 tiny] (main.py 226): INFO Train: [170/300][600/1251]	eta 0:06:37 lr 0.000400	time 0.5229 (0.6109)	loss 4.2457 (3.9134)	grad_norm 3.4554 (4.4302)	mem 5329MB
[2022-04-19 08:53:26 tiny] (main.py 226): INFO Train: [170/300][700/1251]	eta 0:05:34 lr 0.000399	time 0.6028 (0.6076)	loss 4.2866 (3.9165)	grad_norm 4.2875 (4.4465)	mem 5329MB
[2022-04-19 08:54:26 tiny] (main.py 226): INFO Train: [170/300][800/1251]	eta 0:04:33 lr 0.000399	time 0.6407 (0.6056)	loss 4.1385 (3.9191)	grad_norm 4.5853 (4.4680)	mem 5329MB
[2022-04-19 08:55:24 tiny] (main.py 226): INFO Train: [170/300][900/1251]	eta 0:03:31 lr 0.000398	time 0.6220 (0.6037)	loss 3.1434 (3.9308)	grad_norm 3.7068 (inf)	mem 5329MB
[2022-04-19 08:56:24 tiny] (main.py 226): INFO Train: [170/300][1000/1251]	eta 0:02:31 lr 0.000398	time 0.7263 (0.6024)	loss 4.6964 (3.9272)	grad_norm 3.5063 (inf)	mem 5329MB
[2022-04-19 08:57:22 tiny] (main.py 226): INFO Train: [170/300][1100/1251]	eta 0:01:30 lr 0.000398	time 0.6526 (0.6008)	loss 4.5899 (3.9164)	grad_norm 4.8330 (inf)	mem 5329MB
[2022-04-19 08:58:21 tiny] (main.py 226): INFO Train: [170/300][1200/1251]	eta 0:00:30 lr 0.000397	time 0.7104 (0.5999)	loss 4.2721 (3.9204)	grad_norm 4.7792 (inf)	mem 5329MB
[2022-04-19 08:58:42 tiny] (main.py 233): INFO EPOCH 170 training takes 0:12:21
[2022-04-19 08:58:54 tiny] (main.py 273): INFO Test: [0/49]	Time 12.009 (12.009)	Loss 1.6981 (1.6981)	Acc@1 64.746 (64.746)	Acc@5 88.574 (88.574)	Mem 5329MB
[2022-04-19 08:59:13 tiny] (main.py 279): INFO  * Acc@1 67.346 Acc@5 88.074
[2022-04-19 08:59:13 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 67.3%
[2022-04-19 08:59:13 tiny] (main.py 148): INFO Max accuracy: 67.52%
[2022-04-19 08:59:26 tiny] (main.py 226): INFO Train: [171/300][0/1251]	eta 4:15:25 lr 0.000397	time 12.2503 (12.2503)	loss 4.9445 (4.9445)	grad_norm 4.8248 (4.8248)	mem 5329MB
[2022-04-19 09:00:27 tiny] (main.py 226): INFO Train: [171/300][100/1251]	eta 0:13:59 lr 0.000397	time 0.5185 (0.7296)	loss 2.8602 (3.8291)	grad_norm 3.2365 (4.3882)	mem 5329MB
[2022-04-19 09:01:26 tiny] (main.py 226): INFO Train: [171/300][200/1251]	eta 0:11:31 lr 0.000396	time 0.5704 (0.6579)	loss 3.3298 (3.8769)	grad_norm 4.5946 (4.4741)	mem 5329MB
[2022-04-19 09:02:24 tiny] (main.py 226): INFO Train: [171/300][300/1251]	eta 0:10:02 lr 0.000396	time 0.6165 (0.6336)	loss 3.9014 (3.8596)	grad_norm 5.4418 (4.4807)	mem 5329MB
[2022-04-19 09:03:23 tiny] (main.py 226): INFO Train: [171/300][400/1251]	eta 0:08:49 lr 0.000395	time 0.4744 (0.6222)	loss 4.5014 (3.8823)	grad_norm 6.1737 (4.5565)	mem 5329MB
[2022-04-19 09:04:22 tiny] (main.py 226): INFO Train: [171/300][500/1251]	eta 0:07:41 lr 0.000395	time 0.4831 (0.6148)	loss 4.1027 (3.8837)	grad_norm 4.3906 (4.6157)	mem 5329MB
[2022-04-19 09:05:21 tiny] (main.py 226): INFO Train: [171/300][600/1251]	eta 0:06:37 lr 0.000395	time 0.7456 (0.6107)	loss 2.6733 (3.8952)	grad_norm 5.3717 (4.5813)	mem 5329MB
[2022-04-19 09:06:19 tiny] (main.py 226): INFO Train: [171/300][700/1251]	eta 0:05:34 lr 0.000394	time 0.5634 (0.6076)	loss 4.5438 (3.9078)	grad_norm 3.3634 (4.6155)	mem 5329MB
[2022-04-19 09:07:18 tiny] (main.py 226): INFO Train: [171/300][800/1251]	eta 0:04:32 lr 0.000394	time 0.5645 (0.6051)	loss 4.0775 (3.9097)	grad_norm 3.9924 (4.6314)	mem 5329MB
[2022-04-19 09:08:17 tiny] (main.py 226): INFO Train: [171/300][900/1251]	eta 0:03:31 lr 0.000393	time 0.4891 (0.6034)	loss 4.5051 (3.9161)	grad_norm 4.6604 (4.6342)	mem 5329MB
[2022-04-19 09:09:16 tiny] (main.py 226): INFO Train: [171/300][1000/1251]	eta 0:02:31 lr 0.000393	time 0.6447 (0.6020)	loss 3.3948 (3.9131)	grad_norm 5.5734 (4.6259)	mem 5329MB
[2022-04-19 09:10:15 tiny] (main.py 226): INFO Train: [171/300][1100/1251]	eta 0:01:30 lr 0.000393	time 0.6205 (0.6008)	loss 3.4971 (3.9121)	grad_norm 2.9353 (4.6391)	mem 5329MB
[2022-04-19 09:11:14 tiny] (main.py 226): INFO Train: [171/300][1200/1251]	eta 0:00:30 lr 0.000392	time 0.5428 (0.6000)	loss 4.9745 (3.9177)	grad_norm 2.9293 (4.6659)	mem 5329MB
[2022-04-19 09:11:36 tiny] (main.py 233): INFO EPOCH 171 training takes 0:12:22
[2022-04-19 09:11:48 tiny] (main.py 273): INFO Test: [0/49]	Time 11.962 (11.962)	Loss 1.5672 (1.5672)	Acc@1 67.480 (67.480)	Acc@5 88.867 (88.867)	Mem 5329MB
[2022-04-19 09:12:07 tiny] (main.py 279): INFO  * Acc@1 67.816 Acc@5 88.312
[2022-04-19 09:12:07 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 67.8%
[2022-04-19 09:12:07 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_171.pth saving......
[2022-04-19 09:12:07 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_171.pth saved !!!
[2022-04-19 09:12:07 tiny] (main.py 148): INFO Max accuracy: 67.82%
[2022-04-19 09:12:18 tiny] (main.py 226): INFO Train: [172/300][0/1251]	eta 4:03:41 lr 0.000392	time 11.6878 (11.6878)	loss 2.8673 (2.8673)	grad_norm 2.8004 (2.8004)	mem 5329MB
[2022-04-19 09:13:20 tiny] (main.py 226): INFO Train: [172/300][100/1251]	eta 0:13:56 lr 0.000392	time 0.6203 (0.7265)	loss 4.0669 (3.8430)	grad_norm 4.3336 (4.2797)	mem 5329MB
[2022-04-19 09:14:19 tiny] (main.py 226): INFO Train: [172/300][200/1251]	eta 0:11:31 lr 0.000391	time 0.5286 (0.6580)	loss 3.7323 (3.8210)	grad_norm 7.6081 (4.5072)	mem 5329MB
[2022-04-19 09:15:17 tiny] (main.py 226): INFO Train: [172/300][300/1251]	eta 0:10:01 lr 0.000391	time 0.6721 (0.6327)	loss 4.4829 (3.8379)	grad_norm 3.4078 (4.5753)	mem 5329MB
[2022-04-19 09:16:16 tiny] (main.py 226): INFO Train: [172/300][400/1251]	eta 0:08:48 lr 0.000390	time 0.5214 (0.6214)	loss 4.4283 (3.8420)	grad_norm 3.7760 (inf)	mem 5329MB
[2022-04-19 09:17:15 tiny] (main.py 226): INFO Train: [172/300][500/1251]	eta 0:07:41 lr 0.000390	time 0.6306 (0.6143)	loss 4.1213 (3.8559)	grad_norm 4.0209 (inf)	mem 5329MB
[2022-04-19 09:18:13 tiny] (main.py 226): INFO Train: [172/300][600/1251]	eta 0:06:36 lr 0.000390	time 0.5505 (0.6095)	loss 4.0458 (3.8684)	grad_norm 4.3863 (nan)	mem 5329MB
[2022-04-19 09:19:12 tiny] (main.py 226): INFO Train: [172/300][700/1251]	eta 0:05:34 lr 0.000389	time 0.5936 (0.6071)	loss 4.7830 (3.8733)	grad_norm 7.2814 (nan)	mem 5329MB
[2022-04-19 09:20:11 tiny] (main.py 226): INFO Train: [172/300][800/1251]	eta 0:04:32 lr 0.000389	time 0.7501 (0.6047)	loss 4.2741 (3.8841)	grad_norm 5.6891 (nan)	mem 5329MB
[2022-04-19 09:21:10 tiny] (main.py 226): INFO Train: [172/300][900/1251]	eta 0:03:31 lr 0.000388	time 0.5325 (0.6024)	loss 4.3378 (3.8858)	grad_norm 3.1328 (nan)	mem 5329MB
[2022-04-19 09:22:09 tiny] (main.py 226): INFO Train: [172/300][1000/1251]	eta 0:02:31 lr 0.000388	time 0.7568 (0.6017)	loss 4.2171 (3.8904)	grad_norm 3.9869 (nan)	mem 5329MB
[2022-04-19 09:23:08 tiny] (main.py 226): INFO Train: [172/300][1100/1251]	eta 0:01:30 lr 0.000388	time 0.6038 (0.6004)	loss 4.5461 (3.8928)	grad_norm 4.1717 (nan)	mem 5329MB
[2022-04-19 09:24:07 tiny] (main.py 226): INFO Train: [172/300][1200/1251]	eta 0:00:30 lr 0.000387	time 0.6288 (0.5995)	loss 4.6900 (3.8891)	grad_norm 4.9835 (nan)	mem 5329MB
[2022-04-19 09:24:29 tiny] (main.py 233): INFO EPOCH 172 training takes 0:12:21
[2022-04-19 09:24:40 tiny] (main.py 273): INFO Test: [0/49]	Time 11.215 (11.215)	Loss 1.6504 (1.6504)	Acc@1 66.797 (66.797)	Acc@5 88.086 (88.086)	Mem 5329MB
[2022-04-19 09:25:00 tiny] (main.py 279): INFO  * Acc@1 67.544 Acc@5 88.258
[2022-04-19 09:25:00 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 67.5%
[2022-04-19 09:25:00 tiny] (main.py 148): INFO Max accuracy: 67.82%
[2022-04-19 09:25:12 tiny] (main.py 226): INFO Train: [173/300][0/1251]	eta 4:06:57 lr 0.000387	time 11.8449 (11.8449)	loss 4.4389 (4.4389)	grad_norm 4.2529 (4.2529)	mem 5329MB
[2022-04-19 09:26:14 tiny] (main.py 226): INFO Train: [173/300][100/1251]	eta 0:13:59 lr 0.000387	time 0.5547 (0.7297)	loss 3.3307 (3.8645)	grad_norm 3.2482 (4.5772)	mem 5329MB
[2022-04-19 09:27:12 tiny] (main.py 226): INFO Train: [173/300][200/1251]	eta 0:11:30 lr 0.000386	time 0.6704 (0.6569)	loss 2.9369 (3.9090)	grad_norm 4.2135 (4.6322)	mem 5329MB
[2022-04-19 09:28:11 tiny] (main.py 226): INFO Train: [173/300][300/1251]	eta 0:10:02 lr 0.000386	time 0.5746 (0.6339)	loss 3.8961 (3.9258)	grad_norm 4.9567 (4.7488)	mem 5329MB
[2022-04-19 09:29:10 tiny] (main.py 226): INFO Train: [173/300][400/1251]	eta 0:08:50 lr 0.000385	time 0.7247 (0.6229)	loss 4.2381 (3.9073)	grad_norm 6.9785 (4.7879)	mem 5329MB
[2022-04-19 09:30:08 tiny] (main.py 226): INFO Train: [173/300][500/1251]	eta 0:07:42 lr 0.000385	time 0.5463 (0.6153)	loss 3.7092 (3.9069)	grad_norm 3.3971 (4.8044)	mem 5329MB
[2022-04-19 09:31:07 tiny] (main.py 226): INFO Train: [173/300][600/1251]	eta 0:06:37 lr 0.000385	time 0.5483 (0.6107)	loss 3.8458 (3.9092)	grad_norm 2.7778 (4.7414)	mem 5329MB
[2022-04-19 09:32:06 tiny] (main.py 226): INFO Train: [173/300][700/1251]	eta 0:05:34 lr 0.000384	time 0.6131 (0.6074)	loss 2.8961 (3.9225)	grad_norm 4.2092 (4.7581)	mem 5329MB
[2022-04-19 09:33:05 tiny] (main.py 226): INFO Train: [173/300][800/1251]	eta 0:04:32 lr 0.000384	time 0.6633 (0.6053)	loss 4.3218 (3.9171)	grad_norm 5.1665 (4.7148)	mem 5329MB
[2022-04-19 09:34:04 tiny] (main.py 226): INFO Train: [173/300][900/1251]	eta 0:03:31 lr 0.000383	time 0.7269 (0.6034)	loss 2.8629 (3.9240)	grad_norm 3.4547 (4.6789)	mem 5329MB
[2022-04-19 09:35:02 tiny] (main.py 226): INFO Train: [173/300][1000/1251]	eta 0:02:31 lr 0.000383	time 0.5742 (0.6019)	loss 4.2159 (3.9341)	grad_norm 4.4853 (4.6816)	mem 5329MB
[2022-04-19 09:36:02 tiny] (main.py 226): INFO Train: [173/300][1100/1251]	eta 0:01:30 lr 0.000383	time 0.6108 (0.6010)	loss 3.2658 (3.9286)	grad_norm 3.4185 (4.6835)	mem 5329MB
[2022-04-19 09:37:01 tiny] (main.py 226): INFO Train: [173/300][1200/1251]	eta 0:00:30 lr 0.000382	time 0.7314 (0.6003)	loss 3.9100 (3.9239)	grad_norm 6.9576 (4.6738)	mem 5329MB
[2022-04-19 09:37:23 tiny] (main.py 233): INFO EPOCH 173 training takes 0:12:22
[2022-04-19 09:37:35 tiny] (main.py 273): INFO Test: [0/49]	Time 12.213 (12.213)	Loss 1.6078 (1.6078)	Acc@1 66.992 (66.992)	Acc@5 87.305 (87.305)	Mem 5329MB
[2022-04-19 09:37:54 tiny] (main.py 279): INFO  * Acc@1 67.896 Acc@5 88.446
[2022-04-19 09:37:54 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 67.9%
[2022-04-19 09:37:54 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_173.pth saving......
[2022-04-19 09:37:54 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_173.pth saved !!!
[2022-04-19 09:37:54 tiny] (main.py 148): INFO Max accuracy: 67.90%
[2022-04-19 09:38:06 tiny] (main.py 226): INFO Train: [174/300][0/1251]	eta 4:07:29 lr 0.000382	time 11.8700 (11.8700)	loss 3.5130 (3.5130)	grad_norm 5.9778 (5.9778)	mem 5329MB
[2022-04-19 09:39:08 tiny] (main.py 226): INFO Train: [174/300][100/1251]	eta 0:13:58 lr 0.000381	time 0.4650 (0.7286)	loss 3.6415 (3.8785)	grad_norm 4.0550 (5.4380)	mem 5329MB
[2022-04-19 09:40:07 tiny] (main.py 226): INFO Train: [174/300][200/1251]	eta 0:11:32 lr 0.000381	time 0.7057 (0.6588)	loss 4.3152 (3.9130)	grad_norm 4.3085 (5.0149)	mem 5329MB
[2022-04-19 09:41:06 tiny] (main.py 226): INFO Train: [174/300][300/1251]	eta 0:10:03 lr 0.000381	time 0.5933 (0.6346)	loss 2.7704 (3.9082)	grad_norm 4.8105 (4.9624)	mem 5329MB
[2022-04-19 09:42:04 tiny] (main.py 226): INFO Train: [174/300][400/1251]	eta 0:08:49 lr 0.000380	time 0.5448 (0.6225)	loss 4.4960 (3.9280)	grad_norm 2.5177 (4.8794)	mem 5329MB
[2022-04-19 09:43:03 tiny] (main.py 226): INFO Train: [174/300][500/1251]	eta 0:07:41 lr 0.000380	time 0.5966 (0.6151)	loss 3.7643 (3.9452)	grad_norm 3.4100 (4.9210)	mem 5329MB
[2022-04-19 09:44:02 tiny] (main.py 226): INFO Train: [174/300][600/1251]	eta 0:06:38 lr 0.000379	time 0.5102 (0.6115)	loss 3.8346 (3.9350)	grad_norm 2.6184 (4.8830)	mem 5329MB
[2022-04-19 09:45:01 tiny] (main.py 226): INFO Train: [174/300][700/1251]	eta 0:05:35 lr 0.000379	time 0.4043 (0.6081)	loss 2.7253 (3.9189)	grad_norm 5.6884 (4.8087)	mem 5329MB
[2022-04-19 09:46:00 tiny] (main.py 226): INFO Train: [174/300][800/1251]	eta 0:04:33 lr 0.000379	time 0.4626 (0.6060)	loss 3.2806 (3.9132)	grad_norm 3.2045 (4.8019)	mem 5329MB
[2022-04-19 09:46:58 tiny] (main.py 226): INFO Train: [174/300][900/1251]	eta 0:03:31 lr 0.000378	time 0.4752 (0.6036)	loss 4.3014 (3.9164)	grad_norm 2.8736 (4.7662)	mem 5329MB
[2022-04-19 09:47:57 tiny] (main.py 226): INFO Train: [174/300][1000/1251]	eta 0:02:31 lr 0.000378	time 0.6205 (0.6021)	loss 3.7205 (3.9128)	grad_norm 2.7956 (4.7265)	mem 5329MB
[2022-04-19 09:48:56 tiny] (main.py 226): INFO Train: [174/300][1100/1251]	eta 0:01:30 lr 0.000377	time 0.4542 (0.6007)	loss 2.9269 (3.9124)	grad_norm 3.1831 (4.7397)	mem 5329MB
[2022-04-19 09:49:55 tiny] (main.py 226): INFO Train: [174/300][1200/1251]	eta 0:00:30 lr 0.000377	time 0.5233 (0.5999)	loss 3.8671 (3.9140)	grad_norm 12.0518 (4.7470)	mem 5329MB
[2022-04-19 09:50:17 tiny] (main.py 233): INFO EPOCH 174 training takes 0:12:22
[2022-04-19 09:50:27 tiny] (main.py 273): INFO Test: [0/49]	Time 10.684 (10.684)	Loss 1.5682 (1.5682)	Acc@1 67.773 (67.773)	Acc@5 88.379 (88.379)	Mem 5329MB
[2022-04-19 09:50:48 tiny] (main.py 279): INFO  * Acc@1 67.994 Acc@5 88.524
[2022-04-19 09:50:48 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 68.0%
[2022-04-19 09:50:48 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_174.pth saving......
[2022-04-19 09:50:48 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_174.pth saved !!!
[2022-04-19 09:50:48 tiny] (main.py 148): INFO Max accuracy: 67.99%
[2022-04-19 09:51:00 tiny] (main.py 226): INFO Train: [175/300][0/1251]	eta 4:10:12 lr 0.000377	time 12.0001 (12.0001)	loss 4.4836 (4.4836)	grad_norm 4.4461 (4.4461)	mem 5329MB
[2022-04-19 09:52:02 tiny] (main.py 226): INFO Train: [175/300][100/1251]	eta 0:14:01 lr 0.000376	time 0.4646 (0.7312)	loss 4.3876 (3.9739)	grad_norm 3.5204 (4.9972)	mem 5329MB
[2022-04-19 09:53:00 tiny] (main.py 226): INFO Train: [175/300][200/1251]	eta 0:11:32 lr 0.000376	time 0.4321 (0.6588)	loss 4.3335 (3.9206)	grad_norm 3.2260 (5.1008)	mem 5329MB
[2022-04-19 09:53:59 tiny] (main.py 226): INFO Train: [175/300][300/1251]	eta 0:10:03 lr 0.000376	time 0.5299 (0.6348)	loss 3.8329 (3.9097)	grad_norm 9.8802 (4.9820)	mem 5329MB
[2022-04-19 09:54:58 tiny] (main.py 226): INFO Train: [175/300][400/1251]	eta 0:08:50 lr 0.000375	time 0.6520 (0.6239)	loss 2.9862 (3.8959)	grad_norm 3.9215 (4.8371)	mem 5329MB
[2022-04-19 09:56:00 tiny] (main.py 226): INFO Train: [175/300][500/1251]	eta 0:07:47 lr 0.000375	time 0.3382 (0.6225)	loss 4.3675 (3.9047)	grad_norm 2.5220 (4.7665)	mem 5329MB
[2022-04-19 09:57:00 tiny] (main.py 226): INFO Train: [175/300][600/1251]	eta 0:06:42 lr 0.000374	time 0.5201 (0.6184)	loss 3.5239 (3.9196)	grad_norm 4.2494 (4.7477)	mem 5329MB
[2022-04-19 09:57:58 tiny] (main.py 226): INFO Train: [175/300][700/1251]	eta 0:05:38 lr 0.000374	time 0.6413 (0.6140)	loss 3.9773 (3.9056)	grad_norm 5.2941 (4.7405)	mem 5329MB
[2022-04-19 09:58:57 tiny] (main.py 226): INFO Train: [175/300][800/1251]	eta 0:04:35 lr 0.000374	time 0.6818 (0.6105)	loss 4.1100 (3.8996)	grad_norm 5.2834 (4.7709)	mem 5329MB
[2022-04-19 09:59:56 tiny] (main.py 226): INFO Train: [175/300][900/1251]	eta 0:03:33 lr 0.000373	time 0.4602 (0.6079)	loss 4.8194 (3.9010)	grad_norm 4.9460 (inf)	mem 5329MB
[2022-04-19 10:00:55 tiny] (main.py 226): INFO Train: [175/300][1000/1251]	eta 0:02:32 lr 0.000373	time 0.6795 (0.6063)	loss 4.4276 (3.8919)	grad_norm 3.6708 (inf)	mem 5329MB
[2022-04-19 10:01:53 tiny] (main.py 226): INFO Train: [175/300][1100/1251]	eta 0:01:31 lr 0.000372	time 0.6479 (0.6043)	loss 4.3171 (3.8936)	grad_norm 5.0626 (inf)	mem 5329MB
[2022-04-19 10:02:52 tiny] (main.py 226): INFO Train: [175/300][1200/1251]	eta 0:00:30 lr 0.000372	time 0.5636 (0.6030)	loss 4.1057 (3.8908)	grad_norm 3.4040 (inf)	mem 5329MB
[2022-04-19 10:03:14 tiny] (main.py 233): INFO EPOCH 175 training takes 0:12:26
[2022-04-19 10:03:25 tiny] (main.py 273): INFO Test: [0/49]	Time 11.359 (11.359)	Loss 1.6541 (1.6541)	Acc@1 67.480 (67.480)	Acc@5 87.793 (87.793)	Mem 5329MB
[2022-04-19 10:03:45 tiny] (main.py 279): INFO  * Acc@1 67.296 Acc@5 88.042
[2022-04-19 10:03:45 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 67.3%
[2022-04-19 10:03:45 tiny] (main.py 148): INFO Max accuracy: 67.99%
[2022-04-19 10:03:56 tiny] (main.py 226): INFO Train: [176/300][0/1251]	eta 3:52:08 lr 0.000372	time 11.1340 (11.1340)	loss 3.9518 (3.9518)	grad_norm 5.1128 (5.1128)	mem 5329MB
[2022-04-19 10:04:59 tiny] (main.py 226): INFO Train: [176/300][100/1251]	eta 0:14:04 lr 0.000371	time 0.6698 (0.7334)	loss 4.5929 (3.9386)	grad_norm 3.9980 (4.8922)	mem 5329MB
[2022-04-19 10:05:58 tiny] (main.py 226): INFO Train: [176/300][200/1251]	eta 0:11:33 lr 0.000371	time 0.6092 (0.6603)	loss 4.5932 (3.8766)	grad_norm 4.5043 (nan)	mem 5329MB
[2022-04-19 10:06:56 tiny] (main.py 226): INFO Train: [176/300][300/1251]	eta 0:10:04 lr 0.000371	time 0.4934 (0.6358)	loss 3.7653 (3.8863)	grad_norm 4.3927 (nan)	mem 5329MB
[2022-04-19 10:07:55 tiny] (main.py 226): INFO Train: [176/300][400/1251]	eta 0:08:49 lr 0.000370	time 0.7441 (0.6224)	loss 3.2798 (3.9236)	grad_norm 4.2565 (nan)	mem 5329MB
[2022-04-19 10:08:53 tiny] (main.py 226): INFO Train: [176/300][500/1251]	eta 0:07:41 lr 0.000370	time 0.4898 (0.6150)	loss 3.8134 (3.9396)	grad_norm 5.8239 (nan)	mem 5329MB
[2022-04-19 10:09:52 tiny] (main.py 226): INFO Train: [176/300][600/1251]	eta 0:06:37 lr 0.000369	time 0.5489 (0.6111)	loss 3.8164 (3.9267)	grad_norm 4.1190 (nan)	mem 5329MB
[2022-04-19 10:10:52 tiny] (main.py 226): INFO Train: [176/300][700/1251]	eta 0:05:35 lr 0.000369	time 0.6137 (0.6088)	loss 2.8152 (3.9181)	grad_norm 3.1530 (nan)	mem 5329MB
[2022-04-19 10:11:50 tiny] (main.py 226): INFO Train: [176/300][800/1251]	eta 0:04:32 lr 0.000369	time 0.4575 (0.6053)	loss 2.7305 (3.9187)	grad_norm 5.0454 (nan)	mem 5329MB
[2022-04-19 10:12:49 tiny] (main.py 226): INFO Train: [176/300][900/1251]	eta 0:03:31 lr 0.000368	time 0.5353 (0.6038)	loss 3.5213 (3.9087)	grad_norm 4.1329 (nan)	mem 5329MB
[2022-04-19 10:13:48 tiny] (main.py 226): INFO Train: [176/300][1000/1251]	eta 0:02:31 lr 0.000368	time 0.6358 (0.6020)	loss 4.1280 (3.9083)	grad_norm 5.6199 (nan)	mem 5329MB
[2022-04-19 10:14:46 tiny] (main.py 226): INFO Train: [176/300][1100/1251]	eta 0:01:30 lr 0.000368	time 0.6305 (0.6006)	loss 3.9262 (3.9062)	grad_norm 4.8991 (nan)	mem 5329MB
[2022-04-19 10:15:45 tiny] (main.py 226): INFO Train: [176/300][1200/1251]	eta 0:00:30 lr 0.000367	time 0.5157 (0.5994)	loss 3.0210 (3.9008)	grad_norm 5.4033 (nan)	mem 5329MB
[2022-04-19 10:16:07 tiny] (main.py 233): INFO EPOCH 176 training takes 0:12:21
[2022-04-19 10:16:18 tiny] (main.py 273): INFO Test: [0/49]	Time 11.149 (11.149)	Loss 1.5910 (1.5910)	Acc@1 67.188 (67.188)	Acc@5 89.648 (89.648)	Mem 5329MB
[2022-04-19 10:16:38 tiny] (main.py 279): INFO  * Acc@1 67.924 Acc@5 88.618
[2022-04-19 10:16:38 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 67.9%
[2022-04-19 10:16:38 tiny] (main.py 148): INFO Max accuracy: 67.99%
[2022-04-19 10:16:50 tiny] (main.py 226): INFO Train: [177/300][0/1251]	eta 4:03:08 lr 0.000367	time 11.6613 (11.6613)	loss 4.6871 (4.6871)	grad_norm 4.9955 (4.9955)	mem 5329MB
[2022-04-19 10:17:51 tiny] (main.py 226): INFO Train: [177/300][100/1251]	eta 0:13:58 lr 0.000367	time 0.5671 (0.7285)	loss 3.5410 (3.8812)	grad_norm 4.6207 (4.5995)	mem 5329MB
[2022-04-19 10:18:50 tiny] (main.py 226): INFO Train: [177/300][200/1251]	eta 0:11:32 lr 0.000366	time 0.5306 (0.6589)	loss 4.1710 (3.9037)	grad_norm 4.5609 (4.7308)	mem 5329MB
[2022-04-19 10:19:49 tiny] (main.py 226): INFO Train: [177/300][300/1251]	eta 0:10:04 lr 0.000366	time 0.6727 (0.6361)	loss 4.6977 (3.9332)	grad_norm 6.4668 (4.7784)	mem 5329MB
[2022-04-19 10:20:47 tiny] (main.py 226): INFO Train: [177/300][400/1251]	eta 0:08:49 lr 0.000365	time 0.4128 (0.6223)	loss 4.6368 (3.8843)	grad_norm 3.7990 (4.7434)	mem 5329MB
[2022-04-19 10:21:46 tiny] (main.py 226): INFO Train: [177/300][500/1251]	eta 0:07:42 lr 0.000365	time 0.4952 (0.6155)	loss 4.2481 (3.8786)	grad_norm 5.2768 (4.8019)	mem 5329MB
[2022-04-19 10:22:45 tiny] (main.py 226): INFO Train: [177/300][600/1251]	eta 0:06:38 lr 0.000365	time 0.5712 (0.6115)	loss 4.4892 (3.9094)	grad_norm 9.9169 (4.7778)	mem 5329MB
[2022-04-19 10:23:44 tiny] (main.py 226): INFO Train: [177/300][700/1251]	eta 0:05:35 lr 0.000364	time 0.6274 (0.6081)	loss 2.6964 (3.9179)	grad_norm 2.5638 (4.7601)	mem 5329MB
[2022-04-19 10:24:43 tiny] (main.py 226): INFO Train: [177/300][800/1251]	eta 0:04:32 lr 0.000364	time 0.6009 (0.6053)	loss 4.3690 (3.9165)	grad_norm 6.6461 (4.7510)	mem 5329MB
[2022-04-19 10:25:41 tiny] (main.py 226): INFO Train: [177/300][900/1251]	eta 0:03:31 lr 0.000363	time 0.4406 (0.6029)	loss 4.3122 (3.9147)	grad_norm 6.1064 (4.7223)	mem 5329MB
[2022-04-19 10:26:40 tiny] (main.py 226): INFO Train: [177/300][1000/1251]	eta 0:02:31 lr 0.000363	time 0.5534 (0.6017)	loss 4.6254 (3.9145)	grad_norm 2.8095 (inf)	mem 5329MB
[2022-04-19 10:27:39 tiny] (main.py 226): INFO Train: [177/300][1100/1251]	eta 0:01:30 lr 0.000363	time 0.4326 (0.6006)	loss 3.3963 (3.9121)	grad_norm 4.6432 (inf)	mem 5329MB
[2022-04-19 10:28:38 tiny] (main.py 226): INFO Train: [177/300][1200/1251]	eta 0:00:30 lr 0.000362	time 0.6287 (0.5998)	loss 3.8239 (3.9059)	grad_norm 5.5677 (inf)	mem 5329MB
[2022-04-19 10:29:00 tiny] (main.py 233): INFO EPOCH 177 training takes 0:12:22
[2022-04-19 10:29:12 tiny] (main.py 273): INFO Test: [0/49]	Time 11.661 (11.661)	Loss 1.4768 (1.4768)	Acc@1 71.094 (71.094)	Acc@5 90.723 (90.723)	Mem 5329MB
[2022-04-19 10:29:31 tiny] (main.py 279): INFO  * Acc@1 68.068 Acc@5 88.564
[2022-04-19 10:29:31 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 68.1%
[2022-04-19 10:29:31 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_177.pth saving......
[2022-04-19 10:29:31 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_177.pth saved !!!
[2022-04-19 10:29:31 tiny] (main.py 148): INFO Max accuracy: 68.07%
[2022-04-19 10:29:44 tiny] (main.py 226): INFO Train: [178/300][0/1251]	eta 4:15:00 lr 0.000362	time 12.2302 (12.2302)	loss 2.7132 (2.7132)	grad_norm 3.7245 (3.7245)	mem 5329MB
[2022-04-19 10:30:45 tiny] (main.py 226): INFO Train: [178/300][100/1251]	eta 0:13:59 lr 0.000362	time 0.4070 (0.7294)	loss 4.6473 (3.9198)	grad_norm 3.0423 (5.0408)	mem 5329MB
[2022-04-19 10:31:43 tiny] (main.py 226): INFO Train: [178/300][200/1251]	eta 0:11:30 lr 0.000361	time 0.5027 (0.6566)	loss 3.9427 (3.9424)	grad_norm 3.6609 (4.8887)	mem 5329MB
[2022-04-19 10:32:42 tiny] (main.py 226): INFO Train: [178/300][300/1251]	eta 0:10:03 lr 0.000361	time 0.5041 (0.6343)	loss 4.3212 (3.9088)	grad_norm 3.3873 (4.7954)	mem 5329MB
[2022-04-19 10:33:41 tiny] (main.py 226): INFO Train: [178/300][400/1251]	eta 0:08:49 lr 0.000360	time 0.5094 (0.6223)	loss 3.4345 (3.9012)	grad_norm 5.7717 (4.7777)	mem 5329MB
[2022-04-19 10:34:40 tiny] (main.py 226): INFO Train: [178/300][500/1251]	eta 0:07:42 lr 0.000360	time 0.5340 (0.6154)	loss 2.9898 (3.9041)	grad_norm 4.1231 (4.8019)	mem 5329MB
[2022-04-19 10:35:38 tiny] (main.py 226): INFO Train: [178/300][600/1251]	eta 0:06:37 lr 0.000360	time 0.4981 (0.6108)	loss 4.2676 (3.8902)	grad_norm 3.0795 (4.7887)	mem 5329MB
[2022-04-19 10:36:37 tiny] (main.py 226): INFO Train: [178/300][700/1251]	eta 0:05:34 lr 0.000359	time 0.7784 (0.6071)	loss 3.4379 (3.8931)	grad_norm 3.6617 (4.7556)	mem 5329MB
[2022-04-19 10:37:37 tiny] (main.py 226): INFO Train: [178/300][800/1251]	eta 0:04:33 lr 0.000359	time 0.6886 (0.6058)	loss 3.5277 (3.9054)	grad_norm 8.4144 (4.8489)	mem 5329MB
[2022-04-19 10:38:35 tiny] (main.py 226): INFO Train: [178/300][900/1251]	eta 0:03:31 lr 0.000358	time 0.5746 (0.6037)	loss 3.9782 (3.9135)	grad_norm 4.4375 (4.8121)	mem 5329MB
[2022-04-19 10:39:34 tiny] (main.py 226): INFO Train: [178/300][1000/1251]	eta 0:02:31 lr 0.000358	time 0.7271 (0.6021)	loss 3.0576 (3.9032)	grad_norm 4.7218 (4.8269)	mem 5329MB
[2022-04-19 10:40:33 tiny] (main.py 226): INFO Train: [178/300][1100/1251]	eta 0:01:30 lr 0.000358	time 0.5193 (0.6008)	loss 4.2301 (3.9102)	grad_norm 4.4523 (4.8361)	mem 5329MB
[2022-04-19 10:41:32 tiny] (main.py 226): INFO Train: [178/300][1200/1251]	eta 0:00:30 lr 0.000357	time 0.6369 (0.6001)	loss 4.6426 (3.9077)	grad_norm 3.1301 (4.8598)	mem 5329MB
[2022-04-19 10:41:54 tiny] (main.py 233): INFO EPOCH 178 training takes 0:12:22
[2022-04-19 10:42:05 tiny] (main.py 273): INFO Test: [0/49]	Time 11.914 (11.914)	Loss 1.5995 (1.5995)	Acc@1 67.578 (67.578)	Acc@5 88.770 (88.770)	Mem 5329MB
[2022-04-19 10:42:24 tiny] (main.py 279): INFO  * Acc@1 67.796 Acc@5 88.528
[2022-04-19 10:42:24 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 67.8%
[2022-04-19 10:42:24 tiny] (main.py 148): INFO Max accuracy: 68.07%
[2022-04-19 10:42:36 tiny] (main.py 226): INFO Train: [179/300][0/1251]	eta 4:10:45 lr 0.000357	time 12.0268 (12.0268)	loss 4.2239 (4.2239)	grad_norm 5.1771 (5.1771)	mem 5329MB
[2022-04-19 10:43:38 tiny] (main.py 226): INFO Train: [179/300][100/1251]	eta 0:13:58 lr 0.000357	time 0.5131 (0.7282)	loss 3.5465 (3.9178)	grad_norm 4.7366 (4.4792)	mem 5329MB
[2022-04-19 10:44:36 tiny] (main.py 226): INFO Train: [179/300][200/1251]	eta 0:11:30 lr 0.000356	time 0.7478 (0.6573)	loss 2.9746 (3.9253)	grad_norm 3.7954 (4.4800)	mem 5329MB
[2022-04-19 10:45:35 tiny] (main.py 226): INFO Train: [179/300][300/1251]	eta 0:10:03 lr 0.000356	time 0.4629 (0.6343)	loss 3.1316 (3.9137)	grad_norm 6.2867 (4.6428)	mem 5329MB
[2022-04-19 10:46:34 tiny] (main.py 226): INFO Train: [179/300][400/1251]	eta 0:08:49 lr 0.000355	time 0.6211 (0.6217)	loss 3.6583 (3.8996)	grad_norm 9.5168 (4.6485)	mem 5329MB
[2022-04-19 10:47:32 tiny] (main.py 226): INFO Train: [179/300][500/1251]	eta 0:07:41 lr 0.000355	time 0.4841 (0.6142)	loss 4.2577 (3.8958)	grad_norm 5.2647 (4.6593)	mem 5329MB
[2022-04-19 10:48:31 tiny] (main.py 226): INFO Train: [179/300][600/1251]	eta 0:06:37 lr 0.000355	time 0.8097 (0.6100)	loss 3.9531 (3.9006)	grad_norm 3.6998 (4.6156)	mem 5329MB
[2022-04-19 10:49:30 tiny] (main.py 226): INFO Train: [179/300][700/1251]	eta 0:05:34 lr 0.000354	time 0.5697 (0.6069)	loss 3.7713 (3.9026)	grad_norm 4.5477 (4.6605)	mem 5329MB
[2022-04-19 10:50:29 tiny] (main.py 226): INFO Train: [179/300][800/1251]	eta 0:04:32 lr 0.000354	time 0.6601 (0.6045)	loss 4.2620 (3.8968)	grad_norm 2.8257 (4.6549)	mem 5329MB
[2022-04-19 10:51:28 tiny] (main.py 226): INFO Train: [179/300][900/1251]	eta 0:03:31 lr 0.000353	time 0.5240 (0.6031)	loss 4.7640 (3.8884)	grad_norm 3.3986 (4.7224)	mem 5329MB
[2022-04-19 10:52:26 tiny] (main.py 226): INFO Train: [179/300][1000/1251]	eta 0:02:30 lr 0.000353	time 0.5023 (0.6015)	loss 4.2202 (3.8905)	grad_norm 5.7540 (4.7165)	mem 5329MB
[2022-04-19 10:53:25 tiny] (main.py 226): INFO Train: [179/300][1100/1251]	eta 0:01:30 lr 0.000353	time 0.5074 (0.6003)	loss 4.8473 (3.8844)	grad_norm 4.4009 (4.7282)	mem 5329MB
[2022-04-19 10:54:24 tiny] (main.py 226): INFO Train: [179/300][1200/1251]	eta 0:00:30 lr 0.000352	time 0.7628 (0.5994)	loss 4.4440 (3.8845)	grad_norm 5.5134 (4.7463)	mem 5329MB
[2022-04-19 10:54:46 tiny] (main.py 233): INFO EPOCH 179 training takes 0:12:21
[2022-04-19 10:54:58 tiny] (main.py 273): INFO Test: [0/49]	Time 12.217 (12.217)	Loss 1.7084 (1.7084)	Acc@1 65.723 (65.723)	Acc@5 87.695 (87.695)	Mem 5329MB
[2022-04-19 10:55:17 tiny] (main.py 279): INFO  * Acc@1 67.848 Acc@5 88.558
[2022-04-19 10:55:17 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 67.8%
[2022-04-19 10:55:17 tiny] (main.py 148): INFO Max accuracy: 68.07%
[2022-04-19 10:55:29 tiny] (main.py 226): INFO Train: [180/300][0/1251]	eta 4:09:11 lr 0.000352	time 11.9513 (11.9513)	loss 4.0211 (4.0211)	grad_norm 5.0368 (5.0368)	mem 5329MB
[2022-04-19 10:56:31 tiny] (main.py 226): INFO Train: [180/300][100/1251]	eta 0:14:02 lr 0.000352	time 0.6111 (0.7319)	loss 3.1338 (3.8898)	grad_norm 4.4448 (4.8986)	mem 5329MB
[2022-04-19 10:57:29 tiny] (main.py 226): INFO Train: [180/300][200/1251]	eta 0:11:29 lr 0.000351	time 0.6556 (0.6557)	loss 3.4131 (3.8677)	grad_norm 3.2567 (5.0535)	mem 5329MB
[2022-04-19 10:58:28 tiny] (main.py 226): INFO Train: [180/300][300/1251]	eta 0:10:02 lr 0.000351	time 0.5709 (0.6330)	loss 4.0740 (3.8584)	grad_norm 4.7512 (5.0445)	mem 5329MB
[2022-04-19 10:59:27 tiny] (main.py 226): INFO Train: [180/300][400/1251]	eta 0:08:49 lr 0.000350	time 0.5433 (0.6222)	loss 4.4920 (3.8711)	grad_norm 4.0111 (4.9615)	mem 5329MB
[2022-04-19 11:00:26 tiny] (main.py 226): INFO Train: [180/300][500/1251]	eta 0:07:42 lr 0.000350	time 0.6037 (0.6153)	loss 2.6396 (3.8696)	grad_norm 5.6282 (4.9581)	mem 5329MB
[2022-04-19 11:01:24 tiny] (main.py 226): INFO Train: [180/300][600/1251]	eta 0:06:37 lr 0.000350	time 0.6377 (0.6105)	loss 3.4560 (3.8771)	grad_norm 3.5720 (4.9705)	mem 5329MB
[2022-04-19 11:02:23 tiny] (main.py 226): INFO Train: [180/300][700/1251]	eta 0:05:34 lr 0.000349	time 0.5248 (0.6068)	loss 4.1878 (3.8847)	grad_norm 4.9692 (4.9082)	mem 5329MB
[2022-04-19 11:03:22 tiny] (main.py 226): INFO Train: [180/300][800/1251]	eta 0:04:32 lr 0.000349	time 0.6031 (0.6052)	loss 3.5011 (3.8897)	grad_norm 4.5512 (nan)	mem 5329MB
[2022-04-19 11:04:21 tiny] (main.py 226): INFO Train: [180/300][900/1251]	eta 0:03:31 lr 0.000348	time 0.6728 (0.6033)	loss 4.6693 (3.8989)	grad_norm 13.5411 (nan)	mem 5329MB
[2022-04-19 11:05:20 tiny] (main.py 226): INFO Train: [180/300][1000/1251]	eta 0:02:31 lr 0.000348	time 0.5285 (0.6021)	loss 4.1619 (3.8931)	grad_norm 4.6298 (nan)	mem 5329MB
[2022-04-19 11:06:19 tiny] (main.py 226): INFO Train: [180/300][1100/1251]	eta 0:01:30 lr 0.000348	time 0.6514 (0.6012)	loss 4.2839 (3.8970)	grad_norm 4.1829 (nan)	mem 5329MB
[2022-04-19 11:07:18 tiny] (main.py 226): INFO Train: [180/300][1200/1251]	eta 0:00:30 lr 0.000347	time 0.6744 (0.5998)	loss 4.6588 (3.8958)	grad_norm 5.1566 (nan)	mem 5329MB
[2022-04-19 11:07:39 tiny] (main.py 233): INFO EPOCH 180 training takes 0:12:22
[2022-04-19 11:07:51 tiny] (main.py 273): INFO Test: [0/49]	Time 11.440 (11.440)	Loss 1.6491 (1.6491)	Acc@1 65.234 (65.234)	Acc@5 88.477 (88.477)	Mem 5329MB
[2022-04-19 11:08:11 tiny] (main.py 279): INFO  * Acc@1 68.290 Acc@5 88.476
[2022-04-19 11:08:11 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 68.3%
[2022-04-19 11:08:11 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_180.pth saving......
[2022-04-19 11:08:11 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_180.pth saved !!!
[2022-04-19 11:08:11 tiny] (main.py 148): INFO Max accuracy: 68.29%
[2022-04-19 11:08:23 tiny] (main.py 226): INFO Train: [181/300][0/1251]	eta 4:11:33 lr 0.000347	time 12.0649 (12.0649)	loss 4.6653 (4.6653)	grad_norm 4.5350 (4.5350)	mem 5329MB
[2022-04-19 11:09:25 tiny] (main.py 226): INFO Train: [181/300][100/1251]	eta 0:14:04 lr 0.000347	time 0.4817 (0.7334)	loss 3.0575 (4.0076)	grad_norm 5.4157 (5.3750)	mem 5329MB
[2022-04-19 11:10:23 tiny] (main.py 226): INFO Train: [181/300][200/1251]	eta 0:11:30 lr 0.000346	time 0.5099 (0.6574)	loss 4.5761 (3.9932)	grad_norm 3.5533 (5.1500)	mem 5329MB
[2022-04-19 11:11:22 tiny] (main.py 226): INFO Train: [181/300][300/1251]	eta 0:10:02 lr 0.000346	time 0.5804 (0.6341)	loss 2.9146 (3.9596)	grad_norm 4.5871 (4.9831)	mem 5329MB
[2022-04-19 11:12:20 tiny] (main.py 226): INFO Train: [181/300][400/1251]	eta 0:08:48 lr 0.000346	time 0.5354 (0.6215)	loss 3.5696 (3.9270)	grad_norm 4.2982 (4.9913)	mem 5329MB
[2022-04-19 11:13:19 tiny] (main.py 226): INFO Train: [181/300][500/1251]	eta 0:07:41 lr 0.000345	time 0.6227 (0.6142)	loss 4.0852 (3.9414)	grad_norm 3.7248 (4.9633)	mem 5329MB
[2022-04-19 11:14:18 tiny] (main.py 226): INFO Train: [181/300][600/1251]	eta 0:06:37 lr 0.000345	time 0.6586 (0.6102)	loss 4.2088 (3.9330)	grad_norm 5.8636 (5.0233)	mem 5329MB
[2022-04-19 11:15:16 tiny] (main.py 226): INFO Train: [181/300][700/1251]	eta 0:05:34 lr 0.000344	time 0.6038 (0.6067)	loss 4.2625 (3.9274)	grad_norm 4.9218 (4.9803)	mem 5329MB
[2022-04-19 11:16:16 tiny] (main.py 226): INFO Train: [181/300][800/1251]	eta 0:04:32 lr 0.000344	time 0.6259 (0.6049)	loss 4.1150 (3.9124)	grad_norm 9.4505 (5.0018)	mem 5329MB
[2022-04-19 11:17:14 tiny] (main.py 226): INFO Train: [181/300][900/1251]	eta 0:03:31 lr 0.000344	time 0.7647 (0.6025)	loss 4.1727 (3.9027)	grad_norm 4.6154 (4.9512)	mem 5329MB
[2022-04-19 11:18:13 tiny] (main.py 226): INFO Train: [181/300][1000/1251]	eta 0:02:30 lr 0.000343	time 0.5074 (0.6011)	loss 3.4066 (3.8975)	grad_norm 3.4440 (4.9479)	mem 5329MB
[2022-04-19 11:19:11 tiny] (main.py 226): INFO Train: [181/300][1100/1251]	eta 0:01:30 lr 0.000343	time 0.6553 (0.5998)	loss 3.3124 (3.9015)	grad_norm 3.3547 (4.9489)	mem 5329MB
[2022-04-19 11:20:10 tiny] (main.py 226): INFO Train: [181/300][1200/1251]	eta 0:00:30 lr 0.000342	time 0.6382 (0.5990)	loss 3.2828 (3.9022)	grad_norm 3.0911 (4.9860)	mem 5329MB
[2022-04-19 11:20:32 tiny] (main.py 233): INFO EPOCH 181 training takes 0:12:21
[2022-04-19 11:20:44 tiny] (main.py 273): INFO Test: [0/49]	Time 11.894 (11.894)	Loss 1.5151 (1.5151)	Acc@1 70.703 (70.703)	Acc@5 89.551 (89.551)	Mem 5329MB
[2022-04-19 11:21:03 tiny] (main.py 279): INFO  * Acc@1 68.222 Acc@5 88.676
[2022-04-19 11:21:03 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 68.2%
[2022-04-19 11:21:03 tiny] (main.py 148): INFO Max accuracy: 68.29%
[2022-04-19 11:21:15 tiny] (main.py 226): INFO Train: [182/300][0/1251]	eta 4:04:23 lr 0.000342	time 11.7218 (11.7218)	loss 2.8057 (2.8057)	grad_norm 3.1387 (3.1387)	mem 5329MB
[2022-04-19 11:22:16 tiny] (main.py 226): INFO Train: [182/300][100/1251]	eta 0:13:51 lr 0.000342	time 0.5015 (0.7228)	loss 4.0789 (3.8621)	grad_norm 4.9610 (5.1088)	mem 5329MB
[2022-04-19 11:23:15 tiny] (main.py 226): INFO Train: [182/300][200/1251]	eta 0:11:32 lr 0.000341	time 0.5336 (0.6585)	loss 3.9308 (3.8715)	grad_norm 3.5366 (4.8681)	mem 5329MB
[2022-04-19 11:24:14 tiny] (main.py 226): INFO Train: [182/300][300/1251]	eta 0:10:03 lr 0.000341	time 0.7310 (0.6346)	loss 4.9313 (3.8896)	grad_norm 5.8007 (5.0003)	mem 5329MB
[2022-04-19 11:25:13 tiny] (main.py 226): INFO Train: [182/300][400/1251]	eta 0:08:49 lr 0.000341	time 0.5290 (0.6225)	loss 4.2479 (3.9228)	grad_norm 6.1738 (5.0676)	mem 5329MB
[2022-04-19 11:26:12 tiny] (main.py 226): INFO Train: [182/300][500/1251]	eta 0:07:42 lr 0.000340	time 0.5029 (0.6156)	loss 4.2891 (3.9128)	grad_norm 4.8742 (5.0615)	mem 5329MB
[2022-04-19 11:27:10 tiny] (main.py 226): INFO Train: [182/300][600/1251]	eta 0:06:37 lr 0.000340	time 0.5861 (0.6105)	loss 4.2203 (3.9124)	grad_norm 5.7587 (5.0542)	mem 5329MB
[2022-04-19 11:28:09 tiny] (main.py 226): INFO Train: [182/300][700/1251]	eta 0:05:34 lr 0.000339	time 0.7913 (0.6077)	loss 3.9473 (3.9135)	grad_norm 5.3845 (4.9873)	mem 5329MB
[2022-04-19 11:29:08 tiny] (main.py 226): INFO Train: [182/300][800/1251]	eta 0:04:32 lr 0.000339	time 0.5220 (0.6053)	loss 2.8770 (3.8943)	grad_norm 5.8380 (5.0038)	mem 5329MB
[2022-04-19 11:30:07 tiny] (main.py 226): INFO Train: [182/300][900/1251]	eta 0:03:31 lr 0.000339	time 0.5681 (0.6037)	loss 3.9782 (3.8883)	grad_norm 5.8052 (5.0264)	mem 5329MB
[2022-04-19 11:31:06 tiny] (main.py 226): INFO Train: [182/300][1000/1251]	eta 0:02:31 lr 0.000338	time 0.5191 (0.6022)	loss 4.3414 (3.8945)	grad_norm 4.5731 (5.0517)	mem 5329MB
[2022-04-19 11:32:05 tiny] (main.py 226): INFO Train: [182/300][1100/1251]	eta 0:01:30 lr 0.000338	time 0.4764 (0.6009)	loss 4.2235 (3.9024)	grad_norm 5.7097 (5.0348)	mem 5329MB
[2022-04-19 11:33:04 tiny] (main.py 226): INFO Train: [182/300][1200/1251]	eta 0:00:30 lr 0.000338	time 0.6682 (0.5999)	loss 3.9921 (3.8995)	grad_norm 4.2192 (5.0253)	mem 5329MB
[2022-04-19 11:33:25 tiny] (main.py 233): INFO EPOCH 182 training takes 0:12:21
[2022-04-19 11:33:38 tiny] (main.py 273): INFO Test: [0/49]	Time 12.591 (12.591)	Loss 1.4729 (1.4729)	Acc@1 70.801 (70.801)	Acc@5 91.602 (91.602)	Mem 5329MB
[2022-04-19 11:33:56 tiny] (main.py 279): INFO  * Acc@1 67.892 Acc@5 88.390
[2022-04-19 11:33:56 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 67.9%
[2022-04-19 11:33:56 tiny] (main.py 148): INFO Max accuracy: 68.29%
[2022-04-19 11:34:08 tiny] (main.py 226): INFO Train: [183/300][0/1251]	eta 4:04:48 lr 0.000337	time 11.7416 (11.7416)	loss 3.7407 (3.7407)	grad_norm 3.4560 (3.4560)	mem 5329MB
[2022-04-19 11:35:10 tiny] (main.py 226): INFO Train: [183/300][100/1251]	eta 0:14:01 lr 0.000337	time 0.5658 (0.7310)	loss 3.2852 (3.8484)	grad_norm 3.2672 (5.3183)	mem 5329MB
[2022-04-19 11:36:08 tiny] (main.py 226): INFO Train: [183/300][200/1251]	eta 0:11:31 lr 0.000337	time 0.7141 (0.6581)	loss 4.4067 (3.9465)	grad_norm 4.6810 (5.1981)	mem 5329MB
[2022-04-19 11:37:07 tiny] (main.py 226): INFO Train: [183/300][300/1251]	eta 0:10:03 lr 0.000336	time 0.5585 (0.6345)	loss 3.4958 (3.9312)	grad_norm 3.2966 (inf)	mem 5329MB
[2022-04-19 11:38:06 tiny] (main.py 226): INFO Train: [183/300][400/1251]	eta 0:08:50 lr 0.000336	time 0.4242 (0.6229)	loss 4.7010 (3.9174)	grad_norm 7.9594 (inf)	mem 5329MB
[2022-04-19 11:39:04 tiny] (main.py 226): INFO Train: [183/300][500/1251]	eta 0:07:42 lr 0.000335	time 0.5789 (0.6154)	loss 4.4641 (3.8868)	grad_norm 5.8532 (inf)	mem 5329MB
[2022-04-19 11:40:03 tiny] (main.py 226): INFO Train: [183/300][600/1251]	eta 0:06:37 lr 0.000335	time 0.3988 (0.6107)	loss 4.1818 (3.8896)	grad_norm 3.8421 (inf)	mem 5329MB
[2022-04-19 11:41:02 tiny] (main.py 226): INFO Train: [183/300][700/1251]	eta 0:05:34 lr 0.000335	time 0.6545 (0.6073)	loss 4.3869 (3.9040)	grad_norm 3.5902 (inf)	mem 5329MB
[2022-04-19 11:42:01 tiny] (main.py 226): INFO Train: [183/300][800/1251]	eta 0:04:33 lr 0.000334	time 0.6940 (0.6059)	loss 4.2566 (3.8994)	grad_norm 6.8478 (inf)	mem 5329MB
[2022-04-19 11:43:00 tiny] (main.py 226): INFO Train: [183/300][900/1251]	eta 0:03:32 lr 0.000334	time 0.5474 (0.6041)	loss 3.8961 (3.8983)	grad_norm 5.8290 (inf)	mem 5329MB
[2022-04-19 11:43:59 tiny] (main.py 226): INFO Train: [183/300][1000/1251]	eta 0:02:31 lr 0.000333	time 0.7757 (0.6024)	loss 2.6934 (3.8979)	grad_norm 4.2456 (inf)	mem 5329MB
[2022-04-19 11:44:58 tiny] (main.py 226): INFO Train: [183/300][1100/1251]	eta 0:01:30 lr 0.000333	time 0.5664 (0.6009)	loss 3.7564 (3.8957)	grad_norm 3.5285 (inf)	mem 5329MB
[2022-04-19 11:45:57 tiny] (main.py 226): INFO Train: [183/300][1200/1251]	eta 0:00:30 lr 0.000333	time 0.7649 (0.6000)	loss 4.1348 (3.8823)	grad_norm 5.6432 (inf)	mem 5329MB
[2022-04-19 11:46:18 tiny] (main.py 233): INFO EPOCH 183 training takes 0:12:22
[2022-04-19 11:46:31 tiny] (main.py 273): INFO Test: [0/49]	Time 12.291 (12.291)	Loss 1.5798 (1.5798)	Acc@1 66.699 (66.699)	Acc@5 88.379 (88.379)	Mem 5329MB
[2022-04-19 11:46:50 tiny] (main.py 279): INFO  * Acc@1 68.198 Acc@5 88.570
[2022-04-19 11:46:50 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 68.2%
[2022-04-19 11:46:50 tiny] (main.py 148): INFO Max accuracy: 68.29%
[2022-04-19 11:47:00 tiny] (main.py 226): INFO Train: [184/300][0/1251]	eta 3:36:36 lr 0.000332	time 10.3891 (10.3891)	loss 2.8111 (2.8111)	grad_norm 3.8448 (3.8448)	mem 5329MB
[2022-04-19 11:48:03 tiny] (main.py 226): INFO Train: [184/300][100/1251]	eta 0:13:59 lr 0.000332	time 0.6656 (0.7289)	loss 2.4226 (3.8695)	grad_norm 5.6454 (4.9548)	mem 5329MB
[2022-04-19 11:49:02 tiny] (main.py 226): INFO Train: [184/300][200/1251]	eta 0:11:32 lr 0.000332	time 0.3401 (0.6584)	loss 3.2365 (3.8691)	grad_norm 6.3057 (5.0310)	mem 5329MB
[2022-04-19 11:50:01 tiny] (main.py 226): INFO Train: [184/300][300/1251]	eta 0:10:04 lr 0.000331	time 0.6601 (0.6354)	loss 3.6389 (3.9089)	grad_norm 3.7298 (4.9257)	mem 5329MB
[2022-04-19 11:50:59 tiny] (main.py 226): INFO Train: [184/300][400/1251]	eta 0:08:49 lr 0.000331	time 0.4856 (0.6223)	loss 3.8935 (3.9127)	grad_norm 3.5414 (4.8150)	mem 5329MB
[2022-04-19 11:51:58 tiny] (main.py 226): INFO Train: [184/300][500/1251]	eta 0:07:41 lr 0.000331	time 0.5918 (0.6151)	loss 3.7176 (3.9217)	grad_norm 4.7363 (4.8233)	mem 5329MB
[2022-04-19 11:52:57 tiny] (main.py 226): INFO Train: [184/300][600/1251]	eta 0:06:37 lr 0.000330	time 0.5915 (0.6110)	loss 4.0434 (3.9308)	grad_norm 4.6461 (4.8901)	mem 5329MB
[2022-04-19 11:53:56 tiny] (main.py 226): INFO Train: [184/300][700/1251]	eta 0:05:35 lr 0.000330	time 0.5950 (0.6080)	loss 4.7136 (3.9306)	grad_norm 3.7507 (4.8706)	mem 5329MB
[2022-04-19 11:54:55 tiny] (main.py 226): INFO Train: [184/300][800/1251]	eta 0:04:32 lr 0.000329	time 0.4344 (0.6053)	loss 4.1707 (3.9246)	grad_norm 7.3038 (4.9439)	mem 5329MB
[2022-04-19 11:55:53 tiny] (main.py 226): INFO Train: [184/300][900/1251]	eta 0:03:31 lr 0.000329	time 0.4992 (0.6032)	loss 4.1878 (3.9197)	grad_norm 3.2992 (4.8976)	mem 5329MB
[2022-04-19 11:56:52 tiny] (main.py 226): INFO Train: [184/300][1000/1251]	eta 0:02:31 lr 0.000329	time 0.5574 (0.6016)	loss 2.6959 (3.9070)	grad_norm 5.5893 (4.9172)	mem 5329MB
[2022-04-19 11:57:51 tiny] (main.py 226): INFO Train: [184/300][1100/1251]	eta 0:01:30 lr 0.000328	time 0.6899 (0.6004)	loss 3.4932 (3.9045)	grad_norm 5.4557 (nan)	mem 5329MB
[2022-04-19 11:58:50 tiny] (main.py 226): INFO Train: [184/300][1200/1251]	eta 0:00:30 lr 0.000328	time 0.3596 (0.5993)	loss 3.5855 (3.9092)	grad_norm 4.9169 (nan)	mem 5329MB
[2022-04-19 11:59:11 tiny] (main.py 233): INFO EPOCH 184 training takes 0:12:21
[2022-04-19 11:59:22 tiny] (main.py 273): INFO Test: [0/49]	Time 11.398 (11.398)	Loss 1.5117 (1.5117)	Acc@1 69.434 (69.434)	Acc@5 90.234 (90.234)	Mem 5329MB
[2022-04-19 11:59:42 tiny] (main.py 279): INFO  * Acc@1 68.624 Acc@5 88.722
[2022-04-19 11:59:42 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 68.6%
[2022-04-19 11:59:42 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_184.pth saving......
[2022-04-19 11:59:42 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_184.pth saved !!!
[2022-04-19 11:59:42 tiny] (main.py 148): INFO Max accuracy: 68.62%
[2022-04-19 11:59:55 tiny] (main.py 226): INFO Train: [185/300][0/1251]	eta 4:21:44 lr 0.000328	time 12.5536 (12.5536)	loss 3.6450 (3.6450)	grad_norm 2.7985 (2.7985)	mem 5329MB
[2022-04-19 12:00:56 tiny] (main.py 226): INFO Train: [185/300][100/1251]	eta 0:14:02 lr 0.000327	time 0.6165 (0.7318)	loss 2.9382 (3.7940)	grad_norm 3.5825 (4.9710)	mem 5329MB
[2022-04-19 12:01:54 tiny] (main.py 226): INFO Train: [185/300][200/1251]	eta 0:11:30 lr 0.000327	time 0.7617 (0.6574)	loss 3.8914 (3.8166)	grad_norm 4.0997 (5.3621)	mem 5329MB
[2022-04-19 12:02:53 tiny] (main.py 226): INFO Train: [185/300][300/1251]	eta 0:10:02 lr 0.000326	time 0.6871 (0.6333)	loss 3.5645 (3.8539)	grad_norm 8.3873 (5.3750)	mem 5329MB
[2022-04-19 12:03:51 tiny] (main.py 226): INFO Train: [185/300][400/1251]	eta 0:08:48 lr 0.000326	time 0.5476 (0.6206)	loss 4.2384 (3.8695)	grad_norm 6.1818 (5.2963)	mem 5329MB
[2022-04-19 12:04:50 tiny] (main.py 226): INFO Train: [185/300][500/1251]	eta 0:07:41 lr 0.000326	time 0.7136 (0.6147)	loss 4.0378 (3.8683)	grad_norm 4.0942 (5.2341)	mem 5329MB
[2022-04-19 12:05:49 tiny] (main.py 226): INFO Train: [185/300][600/1251]	eta 0:06:37 lr 0.000325	time 0.6419 (0.6101)	loss 3.6569 (3.8724)	grad_norm 3.8443 (5.2088)	mem 5329MB
[2022-04-19 12:06:47 tiny] (main.py 226): INFO Train: [185/300][700/1251]	eta 0:05:34 lr 0.000325	time 0.6135 (0.6065)	loss 3.9789 (3.8844)	grad_norm 4.5255 (5.2107)	mem 5329MB
[2022-04-19 12:07:46 tiny] (main.py 226): INFO Train: [185/300][800/1251]	eta 0:04:32 lr 0.000325	time 0.5253 (0.6045)	loss 3.8766 (3.8925)	grad_norm 3.5733 (5.1660)	mem 5329MB
[2022-04-19 12:08:45 tiny] (main.py 226): INFO Train: [185/300][900/1251]	eta 0:03:31 lr 0.000324	time 0.6358 (0.6030)	loss 3.8465 (3.8893)	grad_norm 3.8842 (5.1604)	mem 5329MB
[2022-04-19 12:09:44 tiny] (main.py 226): INFO Train: [185/300][1000/1251]	eta 0:02:30 lr 0.000324	time 0.6094 (0.6016)	loss 3.9533 (3.8936)	grad_norm 3.6966 (5.1324)	mem 5329MB
[2022-04-19 12:10:42 tiny] (main.py 226): INFO Train: [185/300][1100/1251]	eta 0:01:30 lr 0.000323	time 0.4739 (0.5998)	loss 2.6749 (3.8951)	grad_norm 4.3105 (5.1006)	mem 5329MB
[2022-04-19 12:11:42 tiny] (main.py 226): INFO Train: [185/300][1200/1251]	eta 0:00:30 lr 0.000323	time 0.5155 (0.5992)	loss 4.3739 (3.8970)	grad_norm 3.0694 (5.0955)	mem 5329MB
[2022-04-19 12:12:04 tiny] (main.py 233): INFO EPOCH 185 training takes 0:12:21
[2022-04-19 12:12:16 tiny] (main.py 273): INFO Test: [0/49]	Time 12.301 (12.301)	Loss 1.5256 (1.5256)	Acc@1 69.141 (69.141)	Acc@5 88.672 (88.672)	Mem 5329MB
[2022-04-19 12:12:35 tiny] (main.py 279): INFO  * Acc@1 68.354 Acc@5 88.502
[2022-04-19 12:12:35 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 68.4%
[2022-04-19 12:12:35 tiny] (main.py 148): INFO Max accuracy: 68.62%
[2022-04-19 12:12:46 tiny] (main.py 226): INFO Train: [186/300][0/1251]	eta 4:03:33 lr 0.000323	time 11.6811 (11.6811)	loss 3.3236 (3.3236)	grad_norm 4.7283 (4.7283)	mem 5329MB
[2022-04-19 12:13:48 tiny] (main.py 226): INFO Train: [186/300][100/1251]	eta 0:13:55 lr 0.000322	time 0.5373 (0.7262)	loss 2.5310 (3.9162)	grad_norm 4.3710 (5.6608)	mem 5329MB
[2022-04-19 12:14:46 tiny] (main.py 226): INFO Train: [186/300][200/1251]	eta 0:11:30 lr 0.000322	time 0.6637 (0.6566)	loss 3.4011 (3.8807)	grad_norm 4.0370 (5.2283)	mem 5329MB
[2022-04-19 12:15:44 tiny] (main.py 226): INFO Train: [186/300][300/1251]	eta 0:10:00 lr 0.000322	time 0.5220 (0.6311)	loss 4.1848 (3.8833)	grad_norm 6.5842 (5.2608)	mem 5329MB
[2022-04-19 12:16:44 tiny] (main.py 226): INFO Train: [186/300][400/1251]	eta 0:08:49 lr 0.000321	time 0.8318 (0.6223)	loss 4.0366 (3.8968)	grad_norm 7.9728 (5.3907)	mem 5329MB
[2022-04-19 12:17:43 tiny] (main.py 226): INFO Train: [186/300][500/1251]	eta 0:07:41 lr 0.000321	time 0.5159 (0.6150)	loss 3.1881 (3.8840)	grad_norm 3.6094 (5.2397)	mem 5329MB
[2022-04-19 12:18:41 tiny] (main.py 226): INFO Train: [186/300][600/1251]	eta 0:06:37 lr 0.000320	time 0.5908 (0.6105)	loss 4.1642 (3.8823)	grad_norm 11.4537 (5.2487)	mem 5329MB
[2022-04-19 12:19:40 tiny] (main.py 226): INFO Train: [186/300][700/1251]	eta 0:05:34 lr 0.000320	time 0.6498 (0.6068)	loss 4.4330 (3.8788)	grad_norm 5.8856 (5.1677)	mem 5329MB
[2022-04-19 12:20:38 tiny] (main.py 226): INFO Train: [186/300][800/1251]	eta 0:04:32 lr 0.000320	time 0.5564 (0.6042)	loss 4.7712 (3.8876)	grad_norm 5.3312 (5.1740)	mem 5329MB
[2022-04-19 12:21:37 tiny] (main.py 226): INFO Train: [186/300][900/1251]	eta 0:03:31 lr 0.000319	time 0.7084 (0.6025)	loss 4.2974 (3.8892)	grad_norm 4.9583 (nan)	mem 5329MB
[2022-04-19 12:22:36 tiny] (main.py 226): INFO Train: [186/300][1000/1251]	eta 0:02:30 lr 0.000319	time 0.5415 (0.6013)	loss 2.7715 (3.8777)	grad_norm 4.2757 (nan)	mem 5329MB
[2022-04-19 12:23:35 tiny] (main.py 226): INFO Train: [186/300][1100/1251]	eta 0:01:30 lr 0.000319	time 0.6623 (0.6003)	loss 4.3280 (3.8702)	grad_norm 11.9558 (nan)	mem 5329MB
[2022-04-19 12:24:34 tiny] (main.py 226): INFO Train: [186/300][1200/1251]	eta 0:00:30 lr 0.000318	time 0.6181 (0.5994)	loss 4.4056 (3.8634)	grad_norm 5.7409 (nan)	mem 5329MB
[2022-04-19 12:24:56 tiny] (main.py 233): INFO EPOCH 186 training takes 0:12:21
[2022-04-19 12:25:08 tiny] (main.py 273): INFO Test: [0/49]	Time 12.138 (12.138)	Loss 1.4924 (1.4924)	Acc@1 68.652 (68.652)	Acc@5 90.625 (90.625)	Mem 5329MB
[2022-04-19 12:25:27 tiny] (main.py 279): INFO  * Acc@1 68.568 Acc@5 88.858
[2022-04-19 12:25:27 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 68.6%
[2022-04-19 12:25:27 tiny] (main.py 148): INFO Max accuracy: 68.62%
[2022-04-19 12:25:39 tiny] (main.py 226): INFO Train: [187/300][0/1251]	eta 4:07:26 lr 0.000318	time 11.8680 (11.8680)	loss 3.6850 (3.6850)	grad_norm 3.9345 (3.9345)	mem 5329MB
[2022-04-19 12:26:41 tiny] (main.py 226): INFO Train: [187/300][100/1251]	eta 0:13:58 lr 0.000318	time 0.5691 (0.7289)	loss 4.5722 (3.8949)	grad_norm 4.1711 (4.8955)	mem 5329MB
[2022-04-19 12:27:40 tiny] (main.py 226): INFO Train: [187/300][200/1251]	eta 0:11:32 lr 0.000317	time 0.5653 (0.6589)	loss 4.2682 (3.9008)	grad_norm 4.9919 (5.1650)	mem 5329MB
[2022-04-19 12:28:39 tiny] (main.py 226): INFO Train: [187/300][300/1251]	eta 0:10:03 lr 0.000317	time 0.6500 (0.6349)	loss 4.3293 (3.9164)	grad_norm 4.5310 (5.1260)	mem 5329MB
[2022-04-19 12:29:37 tiny] (main.py 226): INFO Train: [187/300][400/1251]	eta 0:08:49 lr 0.000316	time 0.5593 (0.6217)	loss 4.7409 (3.8948)	grad_norm 5.5577 (5.1803)	mem 5329MB
[2022-04-19 12:30:36 tiny] (main.py 226): INFO Train: [187/300][500/1251]	eta 0:07:41 lr 0.000316	time 0.5838 (0.6151)	loss 3.0040 (3.8957)	grad_norm 2.9641 (5.1868)	mem 5329MB
[2022-04-19 12:31:34 tiny] (main.py 226): INFO Train: [187/300][600/1251]	eta 0:06:37 lr 0.000316	time 0.5563 (0.6106)	loss 4.6284 (3.9114)	grad_norm 4.8818 (5.1995)	mem 5329MB
[2022-04-19 12:32:33 tiny] (main.py 226): INFO Train: [187/300][700/1251]	eta 0:05:34 lr 0.000315	time 0.5541 (0.6070)	loss 3.4264 (3.8927)	grad_norm 3.3453 (5.1801)	mem 5329MB
[2022-04-19 12:33:32 tiny] (main.py 226): INFO Train: [187/300][800/1251]	eta 0:04:32 lr 0.000315	time 0.4729 (0.6048)	loss 3.2126 (3.8809)	grad_norm 3.4786 (5.1565)	mem 5329MB
[2022-04-19 12:34:31 tiny] (main.py 226): INFO Train: [187/300][900/1251]	eta 0:03:31 lr 0.000315	time 0.5294 (0.6031)	loss 2.9384 (3.8652)	grad_norm 4.3065 (5.1047)	mem 5329MB
[2022-04-19 12:35:30 tiny] (main.py 226): INFO Train: [187/300][1000/1251]	eta 0:02:31 lr 0.000314	time 0.6701 (0.6019)	loss 4.0745 (3.8771)	grad_norm 3.2844 (5.0791)	mem 5329MB
[2022-04-19 12:36:28 tiny] (main.py 226): INFO Train: [187/300][1100/1251]	eta 0:01:30 lr 0.000314	time 0.7173 (0.6003)	loss 4.6828 (3.8742)	grad_norm 6.4576 (5.0590)	mem 5329MB
[2022-04-19 12:37:27 tiny] (main.py 226): INFO Train: [187/300][1200/1251]	eta 0:00:30 lr 0.000313	time 0.5682 (0.5994)	loss 4.0191 (3.8787)	grad_norm 4.4852 (5.0673)	mem 5329MB
[2022-04-19 12:37:49 tiny] (main.py 233): INFO EPOCH 187 training takes 0:12:21
[2022-04-19 12:38:02 tiny] (main.py 273): INFO Test: [0/49]	Time 12.323 (12.323)	Loss 1.5779 (1.5779)	Acc@1 67.383 (67.383)	Acc@5 88.574 (88.574)	Mem 5329MB
[2022-04-19 12:38:21 tiny] (main.py 279): INFO  * Acc@1 68.304 Acc@5 88.682
[2022-04-19 12:38:21 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 68.3%
[2022-04-19 12:38:21 tiny] (main.py 148): INFO Max accuracy: 68.62%
[2022-04-19 12:38:33 tiny] (main.py 226): INFO Train: [188/300][0/1251]	eta 4:12:16 lr 0.000313	time 12.0999 (12.0999)	loss 3.2632 (3.2632)	grad_norm 8.7624 (8.7624)	mem 5329MB
[2022-04-19 12:39:34 tiny] (main.py 226): INFO Train: [188/300][100/1251]	eta 0:14:02 lr 0.000313	time 0.5858 (0.7316)	loss 3.9187 (3.8546)	grad_norm 3.7941 (5.1346)	mem 5329MB
[2022-04-19 12:40:33 tiny] (main.py 226): INFO Train: [188/300][200/1251]	eta 0:11:30 lr 0.000312	time 0.5354 (0.6566)	loss 3.6446 (3.9085)	grad_norm 2.8766 (5.0967)	mem 5329MB
[2022-04-19 12:41:31 tiny] (main.py 226): INFO Train: [188/300][300/1251]	eta 0:10:02 lr 0.000312	time 0.4876 (0.6334)	loss 3.8684 (3.9018)	grad_norm 8.7758 (5.3727)	mem 5329MB
[2022-04-19 12:42:30 tiny] (main.py 226): INFO Train: [188/300][400/1251]	eta 0:08:48 lr 0.000312	time 0.5114 (0.6216)	loss 4.6038 (3.9139)	grad_norm 4.1047 (5.2916)	mem 5329MB
[2022-04-19 12:43:29 tiny] (main.py 226): INFO Train: [188/300][500/1251]	eta 0:07:41 lr 0.000311	time 0.7808 (0.6149)	loss 3.0851 (3.9074)	grad_norm 3.6338 (5.2511)	mem 5329MB
[2022-04-19 12:44:28 tiny] (main.py 226): INFO Train: [188/300][600/1251]	eta 0:06:37 lr 0.000311	time 0.7221 (0.6106)	loss 3.8546 (3.8856)	grad_norm 4.7231 (inf)	mem 5329MB
[2022-04-19 12:45:26 tiny] (main.py 226): INFO Train: [188/300][700/1251]	eta 0:05:34 lr 0.000311	time 0.5538 (0.6072)	loss 3.1540 (3.8868)	grad_norm 5.9144 (inf)	mem 5329MB
[2022-04-19 12:46:25 tiny] (main.py 226): INFO Train: [188/300][800/1251]	eta 0:04:32 lr 0.000310	time 0.5524 (0.6046)	loss 4.8270 (3.8918)	grad_norm 5.8003 (inf)	mem 5329MB
[2022-04-19 12:47:24 tiny] (main.py 226): INFO Train: [188/300][900/1251]	eta 0:03:31 lr 0.000310	time 0.6653 (0.6033)	loss 4.3673 (3.8889)	grad_norm 4.9699 (inf)	mem 5329MB
[2022-04-19 12:48:23 tiny] (main.py 226): INFO Train: [188/300][1000/1251]	eta 0:02:31 lr 0.000309	time 0.7974 (0.6018)	loss 2.9576 (3.8822)	grad_norm 5.6159 (inf)	mem 5329MB
[2022-04-19 12:49:22 tiny] (main.py 226): INFO Train: [188/300][1100/1251]	eta 0:01:30 lr 0.000309	time 0.4415 (0.6004)	loss 2.7738 (3.8763)	grad_norm 4.1574 (inf)	mem 5329MB
[2022-04-19 12:50:21 tiny] (main.py 226): INFO Train: [188/300][1200/1251]	eta 0:00:30 lr 0.000309	time 0.5836 (0.5997)	loss 4.3119 (3.8769)	grad_norm 3.6375 (inf)	mem 5329MB
[2022-04-19 12:50:43 tiny] (main.py 233): INFO EPOCH 188 training takes 0:12:21
[2022-04-19 12:50:55 tiny] (main.py 273): INFO Test: [0/49]	Time 12.001 (12.001)	Loss 1.6219 (1.6219)	Acc@1 67.969 (67.969)	Acc@5 87.598 (87.598)	Mem 5329MB
[2022-04-19 12:51:14 tiny] (main.py 279): INFO  * Acc@1 68.660 Acc@5 88.860
[2022-04-19 12:51:14 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 68.7%
[2022-04-19 12:51:14 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_188.pth saving......
[2022-04-19 12:51:14 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_188.pth saved !!!
[2022-04-19 12:51:14 tiny] (main.py 148): INFO Max accuracy: 68.66%
[2022-04-19 12:51:24 tiny] (main.py 226): INFO Train: [189/300][0/1251]	eta 3:41:30 lr 0.000308	time 10.6238 (10.6238)	loss 3.7574 (3.7574)	grad_norm 6.1170 (6.1170)	mem 5329MB
[2022-04-19 12:52:27 tiny] (main.py 226): INFO Train: [189/300][100/1251]	eta 0:13:58 lr 0.000308	time 0.5096 (0.7286)	loss 4.0868 (3.8218)	grad_norm 3.5737 (5.4684)	mem 5329MB
[2022-04-19 12:53:26 tiny] (main.py 226): INFO Train: [189/300][200/1251]	eta 0:11:31 lr 0.000308	time 0.6598 (0.6578)	loss 3.2643 (3.8795)	grad_norm 5.6020 (5.3875)	mem 5329MB
[2022-04-19 12:54:24 tiny] (main.py 226): INFO Train: [189/300][300/1251]	eta 0:10:02 lr 0.000307	time 0.6424 (0.6335)	loss 4.3850 (3.8657)	grad_norm 4.7233 (5.1872)	mem 5329MB
[2022-04-19 12:55:23 tiny] (main.py 226): INFO Train: [189/300][400/1251]	eta 0:08:49 lr 0.000307	time 0.5360 (0.6218)	loss 4.1283 (3.8503)	grad_norm 3.1474 (5.2205)	mem 5329MB
[2022-04-19 12:56:22 tiny] (main.py 226): INFO Train: [189/300][500/1251]	eta 0:07:41 lr 0.000307	time 0.5807 (0.6147)	loss 4.2426 (3.8427)	grad_norm 3.5941 (5.2142)	mem 5329MB
[2022-04-19 12:57:21 tiny] (main.py 226): INFO Train: [189/300][600/1251]	eta 0:06:37 lr 0.000306	time 0.6019 (0.6104)	loss 4.6068 (3.8340)	grad_norm 4.8479 (5.2919)	mem 5329MB
[2022-04-19 12:58:19 tiny] (main.py 226): INFO Train: [189/300][700/1251]	eta 0:05:34 lr 0.000306	time 0.4572 (0.6071)	loss 4.0228 (3.8296)	grad_norm 3.9781 (5.2245)	mem 5329MB
[2022-04-19 12:59:19 tiny] (main.py 226): INFO Train: [189/300][800/1251]	eta 0:04:32 lr 0.000305	time 0.6037 (0.6052)	loss 4.1280 (3.8374)	grad_norm 3.8210 (5.1713)	mem 5329MB
[2022-04-19 13:00:18 tiny] (main.py 226): INFO Train: [189/300][900/1251]	eta 0:03:31 lr 0.000305	time 0.4767 (0.6036)	loss 4.2136 (3.8319)	grad_norm 4.0665 (5.1649)	mem 5329MB
[2022-04-19 13:01:16 tiny] (main.py 226): INFO Train: [189/300][1000/1251]	eta 0:02:31 lr 0.000305	time 0.4494 (0.6017)	loss 3.5192 (3.8337)	grad_norm 5.0496 (5.0988)	mem 5329MB
[2022-04-19 13:02:15 tiny] (main.py 226): INFO Train: [189/300][1100/1251]	eta 0:01:30 lr 0.000304	time 0.4977 (0.6006)	loss 4.1686 (3.8305)	grad_norm 4.8592 (5.1041)	mem 5329MB
[2022-04-19 13:03:13 tiny] (main.py 226): INFO Train: [189/300][1200/1251]	eta 0:00:30 lr 0.000304	time 0.4823 (0.5993)	loss 4.2114 (3.8371)	grad_norm 7.4607 (5.1516)	mem 5329MB
[2022-04-19 13:03:36 tiny] (main.py 233): INFO EPOCH 189 training takes 0:12:21
[2022-04-19 13:03:48 tiny] (main.py 273): INFO Test: [0/49]	Time 12.242 (12.242)	Loss 1.5943 (1.5943)	Acc@1 66.504 (66.504)	Acc@5 88.965 (88.965)	Mem 5329MB
[2022-04-19 13:04:07 tiny] (main.py 279): INFO  * Acc@1 68.510 Acc@5 88.816
[2022-04-19 13:04:07 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 68.5%
[2022-04-19 13:04:07 tiny] (main.py 148): INFO Max accuracy: 68.66%
[2022-04-19 13:04:18 tiny] (main.py 226): INFO Train: [190/300][0/1251]	eta 3:53:31 lr 0.000304	time 11.2005 (11.2005)	loss 3.7961 (3.7961)	grad_norm 5.1592 (5.1592)	mem 5329MB
[2022-04-19 13:05:21 tiny] (main.py 226): INFO Train: [190/300][100/1251]	eta 0:14:03 lr 0.000303	time 0.4486 (0.7327)	loss 4.5737 (3.8216)	grad_norm 4.3918 (nan)	mem 5329MB
[2022-04-19 13:06:19 tiny] (main.py 226): INFO Train: [190/300][200/1251]	eta 0:11:31 lr 0.000303	time 0.5828 (0.6581)	loss 3.0235 (3.8808)	grad_norm 7.2698 (nan)	mem 5329MB
[2022-04-19 13:07:18 tiny] (main.py 226): INFO Train: [190/300][300/1251]	eta 0:10:03 lr 0.000303	time 0.6258 (0.6348)	loss 3.9972 (3.8538)	grad_norm 7.8414 (nan)	mem 5329MB
[2022-04-19 13:08:16 tiny] (main.py 226): INFO Train: [190/300][400/1251]	eta 0:08:50 lr 0.000302	time 0.5844 (0.6229)	loss 3.6802 (3.8491)	grad_norm 4.8978 (nan)	mem 5329MB
[2022-04-19 13:09:15 tiny] (main.py 226): INFO Train: [190/300][500/1251]	eta 0:07:42 lr 0.000302	time 0.5146 (0.6152)	loss 4.6630 (3.8629)	grad_norm 3.6958 (nan)	mem 5329MB
[2022-04-19 13:10:14 tiny] (main.py 226): INFO Train: [190/300][600/1251]	eta 0:06:37 lr 0.000301	time 0.8416 (0.6104)	loss 3.8891 (3.8524)	grad_norm 7.2495 (nan)	mem 5329MB
[2022-04-19 13:11:12 tiny] (main.py 226): INFO Train: [190/300][700/1251]	eta 0:05:34 lr 0.000301	time 0.5763 (0.6073)	loss 4.1194 (3.8640)	grad_norm 4.4487 (nan)	mem 5329MB
[2022-04-19 13:12:11 tiny] (main.py 226): INFO Train: [190/300][800/1251]	eta 0:04:32 lr 0.000301	time 0.4002 (0.6052)	loss 3.8256 (3.8572)	grad_norm 6.8448 (nan)	mem 5329MB
[2022-04-19 13:13:10 tiny] (main.py 226): INFO Train: [190/300][900/1251]	eta 0:03:31 lr 0.000300	time 0.5746 (0.6030)	loss 2.8737 (3.8548)	grad_norm 3.7638 (nan)	mem 5329MB
[2022-04-19 13:14:09 tiny] (main.py 226): INFO Train: [190/300][1000/1251]	eta 0:02:31 lr 0.000300	time 0.5608 (0.6018)	loss 4.2811 (3.8530)	grad_norm 4.1392 (nan)	mem 5329MB
[2022-04-19 13:15:08 tiny] (main.py 226): INFO Train: [190/300][1100/1251]	eta 0:01:30 lr 0.000300	time 0.6254 (0.6008)	loss 4.5750 (3.8579)	grad_norm 5.1924 (nan)	mem 5329MB
[2022-04-19 13:16:07 tiny] (main.py 226): INFO Train: [190/300][1200/1251]	eta 0:00:30 lr 0.000299	time 0.4731 (0.5996)	loss 2.7907 (3.8545)	grad_norm 8.1937 (nan)	mem 5329MB
[2022-04-19 13:16:29 tiny] (main.py 233): INFO EPOCH 190 training takes 0:12:22
[2022-04-19 13:16:41 tiny] (main.py 273): INFO Test: [0/49]	Time 11.730 (11.730)	Loss 1.6334 (1.6334)	Acc@1 67.969 (67.969)	Acc@5 86.914 (86.914)	Mem 5329MB
[2022-04-19 13:17:00 tiny] (main.py 279): INFO  * Acc@1 68.392 Acc@5 88.776
[2022-04-19 13:17:00 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 68.4%
[2022-04-19 13:17:00 tiny] (main.py 148): INFO Max accuracy: 68.66%
[2022-04-19 13:17:12 tiny] (main.py 226): INFO Train: [191/300][0/1251]	eta 4:09:15 lr 0.000299	time 11.9544 (11.9544)	loss 4.2272 (4.2272)	grad_norm 4.5181 (4.5181)	mem 5329MB
[2022-04-19 13:18:14 tiny] (main.py 226): INFO Train: [191/300][100/1251]	eta 0:13:59 lr 0.000299	time 0.5452 (0.7294)	loss 4.1327 (3.8095)	grad_norm 4.3094 (4.9343)	mem 5329MB
[2022-04-19 13:19:12 tiny] (main.py 226): INFO Train: [191/300][200/1251]	eta 0:11:33 lr 0.000298	time 0.6588 (0.6595)	loss 4.0916 (3.8500)	grad_norm 4.1544 (5.2269)	mem 5329MB
[2022-04-19 13:20:11 tiny] (main.py 226): INFO Train: [191/300][300/1251]	eta 0:10:03 lr 0.000298	time 0.6620 (0.6350)	loss 3.5338 (3.8643)	grad_norm 4.0434 (5.2268)	mem 5329MB
[2022-04-19 13:21:09 tiny] (main.py 226): INFO Train: [191/300][400/1251]	eta 0:08:49 lr 0.000297	time 0.6121 (0.6220)	loss 4.7317 (3.8992)	grad_norm 3.4038 (5.1314)	mem 5329MB
[2022-04-19 13:22:08 tiny] (main.py 226): INFO Train: [191/300][500/1251]	eta 0:07:42 lr 0.000297	time 0.6045 (0.6154)	loss 4.5202 (3.8828)	grad_norm 4.6183 (5.1622)	mem 5329MB
[2022-04-19 13:23:07 tiny] (main.py 226): INFO Train: [191/300][600/1251]	eta 0:06:37 lr 0.000297	time 0.5527 (0.6104)	loss 4.1673 (3.8941)	grad_norm 3.2862 (5.1379)	mem 5329MB
[2022-04-19 13:24:06 tiny] (main.py 226): INFO Train: [191/300][700/1251]	eta 0:05:34 lr 0.000296	time 0.7184 (0.6072)	loss 3.0147 (3.8866)	grad_norm 4.8976 (5.1554)	mem 5329MB
[2022-04-19 13:25:05 tiny] (main.py 226): INFO Train: [191/300][800/1251]	eta 0:04:33 lr 0.000296	time 0.7911 (0.6057)	loss 3.5873 (3.8871)	grad_norm 6.4759 (5.1369)	mem 5329MB
[2022-04-19 13:26:03 tiny] (main.py 226): INFO Train: [191/300][900/1251]	eta 0:03:31 lr 0.000296	time 0.6700 (0.6032)	loss 4.1826 (3.8801)	grad_norm 7.5886 (5.1125)	mem 5329MB
[2022-04-19 13:27:02 tiny] (main.py 226): INFO Train: [191/300][1000/1251]	eta 0:02:31 lr 0.000295	time 0.7426 (0.6019)	loss 4.3707 (3.8651)	grad_norm 6.7966 (nan)	mem 5329MB
[2022-04-19 13:28:01 tiny] (main.py 226): INFO Train: [191/300][1100/1251]	eta 0:01:30 lr 0.000295	time 0.6041 (0.6007)	loss 3.1023 (3.8696)	grad_norm 4.8820 (nan)	mem 5329MB
[2022-04-19 13:29:00 tiny] (main.py 226): INFO Train: [191/300][1200/1251]	eta 0:00:30 lr 0.000294	time 0.7953 (0.6000)	loss 2.7903 (3.8682)	grad_norm 5.7941 (nan)	mem 5329MB
[2022-04-19 13:29:23 tiny] (main.py 233): INFO EPOCH 191 training takes 0:12:22
[2022-04-19 13:29:34 tiny] (main.py 273): INFO Test: [0/49]	Time 11.519 (11.519)	Loss 1.5900 (1.5900)	Acc@1 66.602 (66.602)	Acc@5 87.109 (87.109)	Mem 5329MB
[2022-04-19 13:29:54 tiny] (main.py 279): INFO  * Acc@1 68.580 Acc@5 88.832
[2022-04-19 13:29:54 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 68.6%
[2022-04-19 13:29:54 tiny] (main.py 148): INFO Max accuracy: 68.66%
[2022-04-19 13:30:05 tiny] (main.py 226): INFO Train: [192/300][0/1251]	eta 4:03:53 lr 0.000294	time 11.6976 (11.6976)	loss 2.4635 (2.4635)	grad_norm 3.0771 (3.0771)	mem 5329MB
[2022-04-19 13:31:07 tiny] (main.py 226): INFO Train: [192/300][100/1251]	eta 0:13:57 lr 0.000294	time 0.6970 (0.7273)	loss 4.7462 (3.8863)	grad_norm 5.0962 (5.5810)	mem 5329MB
[2022-04-19 13:32:06 tiny] (main.py 226): INFO Train: [192/300][200/1251]	eta 0:11:31 lr 0.000293	time 0.6179 (0.6579)	loss 4.1987 (3.8370)	grad_norm 3.5062 (5.6566)	mem 5329MB
[2022-04-19 13:33:05 tiny] (main.py 226): INFO Train: [192/300][300/1251]	eta 0:10:03 lr 0.000293	time 0.6116 (0.6347)	loss 2.6067 (3.8429)	grad_norm 5.4651 (5.4241)	mem 5329MB
[2022-04-19 13:34:03 tiny] (main.py 226): INFO Train: [192/300][400/1251]	eta 0:08:49 lr 0.000293	time 0.6553 (0.6223)	loss 4.3927 (3.8555)	grad_norm 7.8505 (5.3162)	mem 5329MB
[2022-04-19 13:35:02 tiny] (main.py 226): INFO Train: [192/300][500/1251]	eta 0:07:42 lr 0.000292	time 0.5319 (0.6157)	loss 4.4211 (3.8500)	grad_norm 6.2761 (5.4173)	mem 5329MB
[2022-04-19 13:36:01 tiny] (main.py 226): INFO Train: [192/300][600/1251]	eta 0:06:37 lr 0.000292	time 0.5302 (0.6107)	loss 4.4785 (3.8553)	grad_norm 4.5414 (5.4072)	mem 5329MB
[2022-04-19 13:37:00 tiny] (main.py 226): INFO Train: [192/300][700/1251]	eta 0:05:35 lr 0.000292	time 0.5911 (0.6083)	loss 3.5520 (3.8504)	grad_norm 3.7163 (5.3748)	mem 5329MB
[2022-04-19 13:37:59 tiny] (main.py 226): INFO Train: [192/300][800/1251]	eta 0:04:33 lr 0.000291	time 0.6031 (0.6055)	loss 3.6030 (3.8538)	grad_norm 4.4794 (5.3400)	mem 5329MB
[2022-04-19 13:38:58 tiny] (main.py 226): INFO Train: [192/300][900/1251]	eta 0:03:32 lr 0.000291	time 0.6169 (0.6041)	loss 4.2073 (3.8718)	grad_norm 5.2978 (5.3570)	mem 5329MB
[2022-04-19 13:39:57 tiny] (main.py 226): INFO Train: [192/300][1000/1251]	eta 0:02:31 lr 0.000290	time 0.6154 (0.6024)	loss 3.7049 (3.8705)	grad_norm 7.5639 (5.3453)	mem 5329MB
[2022-04-19 13:40:56 tiny] (main.py 226): INFO Train: [192/300][1100/1251]	eta 0:01:30 lr 0.000290	time 0.6055 (0.6012)	loss 4.1543 (3.8668)	grad_norm 4.9580 (5.3486)	mem 5329MB
[2022-04-19 13:41:55 tiny] (main.py 226): INFO Train: [192/300][1200/1251]	eta 0:00:30 lr 0.000290	time 0.6659 (0.6002)	loss 3.0383 (3.8691)	grad_norm 3.7014 (5.4005)	mem 5329MB
[2022-04-19 13:42:17 tiny] (main.py 233): INFO EPOCH 192 training takes 0:12:23
[2022-04-19 13:42:29 tiny] (main.py 273): INFO Test: [0/49]	Time 11.953 (11.953)	Loss 1.4734 (1.4734)	Acc@1 67.676 (67.676)	Acc@5 88.965 (88.965)	Mem 5329MB
[2022-04-19 13:42:48 tiny] (main.py 279): INFO  * Acc@1 68.586 Acc@5 88.904
[2022-04-19 13:42:48 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 68.6%
[2022-04-19 13:42:48 tiny] (main.py 148): INFO Max accuracy: 68.66%
[2022-04-19 13:43:00 tiny] (main.py 226): INFO Train: [193/300][0/1251]	eta 4:11:23 lr 0.000290	time 12.0573 (12.0573)	loss 3.9782 (3.9782)	grad_norm 5.0944 (5.0944)	mem 5329MB
[2022-04-19 13:44:01 tiny] (main.py 226): INFO Train: [193/300][100/1251]	eta 0:13:56 lr 0.000289	time 0.5884 (0.7266)	loss 3.2878 (3.8956)	grad_norm 4.7117 (5.1877)	mem 5329MB
[2022-04-19 13:45:00 tiny] (main.py 226): INFO Train: [193/300][200/1251]	eta 0:11:32 lr 0.000289	time 0.4842 (0.6592)	loss 2.7220 (3.8774)	grad_norm 6.7614 (5.2157)	mem 5329MB
[2022-04-19 13:45:59 tiny] (main.py 226): INFO Train: [193/300][300/1251]	eta 0:10:04 lr 0.000288	time 0.5673 (0.6355)	loss 2.5791 (3.8553)	grad_norm 4.0452 (5.1402)	mem 5329MB
[2022-04-19 13:46:57 tiny] (main.py 226): INFO Train: [193/300][400/1251]	eta 0:08:49 lr 0.000288	time 0.5980 (0.6225)	loss 4.1362 (3.8316)	grad_norm 15.0241 (5.2325)	mem 5329MB
[2022-04-19 13:47:56 tiny] (main.py 226): INFO Train: [193/300][500/1251]	eta 0:07:42 lr 0.000288	time 0.7909 (0.6164)	loss 3.6147 (3.8267)	grad_norm 6.9548 (5.2241)	mem 5329MB
[2022-04-19 13:48:55 tiny] (main.py 226): INFO Train: [193/300][600/1251]	eta 0:06:37 lr 0.000287	time 0.6049 (0.6111)	loss 4.8404 (3.8347)	grad_norm 8.4012 (5.2405)	mem 5329MB
[2022-04-19 13:49:54 tiny] (main.py 226): INFO Train: [193/300][700/1251]	eta 0:05:35 lr 0.000287	time 0.6041 (0.6083)	loss 4.3719 (3.8406)	grad_norm 3.1694 (5.1885)	mem 5329MB
[2022-04-19 13:50:53 tiny] (main.py 226): INFO Train: [193/300][800/1251]	eta 0:04:33 lr 0.000287	time 0.4785 (0.6058)	loss 3.9444 (3.8413)	grad_norm 2.6389 (5.2444)	mem 5329MB
[2022-04-19 13:51:52 tiny] (main.py 226): INFO Train: [193/300][900/1251]	eta 0:03:31 lr 0.000286	time 0.5614 (0.6038)	loss 4.4266 (3.8374)	grad_norm 5.9534 (5.2528)	mem 5329MB
[2022-04-19 13:52:50 tiny] (main.py 226): INFO Train: [193/300][1000/1251]	eta 0:02:31 lr 0.000286	time 0.7583 (0.6023)	loss 4.1862 (3.8387)	grad_norm 4.6662 (5.2497)	mem 5329MB
[2022-04-19 13:53:49 tiny] (main.py 226): INFO Train: [193/300][1100/1251]	eta 0:01:30 lr 0.000285	time 0.5094 (0.6007)	loss 3.0836 (3.8367)	grad_norm 3.4295 (5.2666)	mem 5329MB
[2022-04-19 13:54:48 tiny] (main.py 226): INFO Train: [193/300][1200/1251]	eta 0:00:30 lr 0.000285	time 0.6180 (0.5998)	loss 3.5057 (3.8283)	grad_norm 5.2145 (5.2641)	mem 5329MB
[2022-04-19 13:55:10 tiny] (main.py 233): INFO EPOCH 193 training takes 0:12:22
[2022-04-19 13:55:22 tiny] (main.py 273): INFO Test: [0/49]	Time 11.970 (11.970)	Loss 1.6607 (1.6607)	Acc@1 65.820 (65.820)	Acc@5 86.719 (86.719)	Mem 5329MB
[2022-04-19 13:55:41 tiny] (main.py 279): INFO  * Acc@1 68.550 Acc@5 88.856
[2022-04-19 13:55:41 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 68.6%
[2022-04-19 13:55:41 tiny] (main.py 148): INFO Max accuracy: 68.66%
[2022-04-19 13:55:52 tiny] (main.py 226): INFO Train: [194/300][0/1251]	eta 3:45:35 lr 0.000285	time 10.8194 (10.8194)	loss 3.6147 (3.6147)	grad_norm 3.5664 (3.5664)	mem 5329MB
[2022-04-19 13:56:55 tiny] (main.py 226): INFO Train: [194/300][100/1251]	eta 0:14:02 lr 0.000285	time 0.4981 (0.7318)	loss 4.2482 (3.9364)	grad_norm 3.9274 (5.4452)	mem 5329MB
[2022-04-19 13:57:53 tiny] (main.py 226): INFO Train: [194/300][200/1251]	eta 0:11:31 lr 0.000284	time 0.5356 (0.6584)	loss 4.1908 (3.8710)	grad_norm 3.6167 (5.5067)	mem 5329MB
[2022-04-19 13:58:52 tiny] (main.py 226): INFO Train: [194/300][300/1251]	eta 0:10:03 lr 0.000284	time 0.7237 (0.6345)	loss 3.7990 (3.8544)	grad_norm 5.2201 (5.6161)	mem 5329MB
[2022-04-19 13:59:51 tiny] (main.py 226): INFO Train: [194/300][400/1251]	eta 0:08:50 lr 0.000283	time 0.7136 (0.6230)	loss 3.9597 (3.8487)	grad_norm 4.7222 (5.5051)	mem 5329MB
[2022-04-19 14:00:49 tiny] (main.py 226): INFO Train: [194/300][500/1251]	eta 0:07:42 lr 0.000283	time 0.6883 (0.6153)	loss 3.8180 (3.8488)	grad_norm 3.8326 (5.3727)	mem 5329MB
[2022-04-19 14:01:48 tiny] (main.py 226): INFO Train: [194/300][600/1251]	eta 0:06:37 lr 0.000283	time 0.6758 (0.6106)	loss 4.1551 (3.8619)	grad_norm 3.5611 (inf)	mem 5329MB
[2022-04-19 14:02:46 tiny] (main.py 226): INFO Train: [194/300][700/1251]	eta 0:05:34 lr 0.000282	time 0.5120 (0.6067)	loss 4.1644 (3.8439)	grad_norm 3.5144 (inf)	mem 5329MB
[2022-04-19 14:03:45 tiny] (main.py 226): INFO Train: [194/300][800/1251]	eta 0:04:32 lr 0.000282	time 0.5101 (0.6046)	loss 4.5378 (3.8521)	grad_norm 3.8865 (inf)	mem 5329MB
[2022-04-19 14:04:44 tiny] (main.py 226): INFO Train: [194/300][900/1251]	eta 0:03:31 lr 0.000282	time 0.6449 (0.6030)	loss 4.1084 (3.8343)	grad_norm 7.9185 (inf)	mem 5329MB
[2022-04-19 14:05:43 tiny] (main.py 226): INFO Train: [194/300][1000/1251]	eta 0:02:30 lr 0.000281	time 0.5381 (0.6012)	loss 2.7102 (3.8392)	grad_norm 10.9562 (inf)	mem 5329MB
[2022-04-19 14:06:41 tiny] (main.py 226): INFO Train: [194/300][1100/1251]	eta 0:01:30 lr 0.000281	time 0.5752 (0.6000)	loss 4.0436 (3.8331)	grad_norm 5.4307 (inf)	mem 5329MB
[2022-04-19 14:07:41 tiny] (main.py 226): INFO Train: [194/300][1200/1251]	eta 0:00:30 lr 0.000280	time 0.4479 (0.5996)	loss 2.6728 (3.8323)	grad_norm 5.0970 (inf)	mem 5329MB
[2022-04-19 14:08:03 tiny] (main.py 233): INFO EPOCH 194 training takes 0:12:22
[2022-04-19 14:08:15 tiny] (main.py 273): INFO Test: [0/49]	Time 12.030 (12.030)	Loss 1.5750 (1.5750)	Acc@1 70.898 (70.898)	Acc@5 87.988 (87.988)	Mem 5329MB
[2022-04-19 14:08:34 tiny] (main.py 279): INFO  * Acc@1 68.740 Acc@5 88.850
[2022-04-19 14:08:34 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 68.7%
[2022-04-19 14:08:34 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_194.pth saving......
[2022-04-19 14:08:34 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_194.pth saved !!!
[2022-04-19 14:08:34 tiny] (main.py 148): INFO Max accuracy: 68.74%
[2022-04-19 14:08:45 tiny] (main.py 226): INFO Train: [195/300][0/1251]	eta 4:00:21 lr 0.000280	time 11.5282 (11.5282)	loss 4.1784 (4.1784)	grad_norm 5.1957 (5.1957)	mem 5329MB
[2022-04-19 14:09:48 tiny] (main.py 226): INFO Train: [195/300][100/1251]	eta 0:14:01 lr 0.000280	time 0.6525 (0.7314)	loss 4.4621 (3.8128)	grad_norm 6.6426 (5.4156)	mem 5329MB
[2022-04-19 14:10:46 tiny] (main.py 226): INFO Train: [195/300][200/1251]	eta 0:11:32 lr 0.000280	time 0.5934 (0.6592)	loss 4.1805 (3.8430)	grad_norm 7.2899 (5.3762)	mem 5329MB
[2022-04-19 14:11:45 tiny] (main.py 226): INFO Train: [195/300][300/1251]	eta 0:10:03 lr 0.000279	time 0.4985 (0.6350)	loss 2.8347 (3.8588)	grad_norm 6.3041 (5.4088)	mem 5329MB
[2022-04-19 14:12:43 tiny] (main.py 226): INFO Train: [195/300][400/1251]	eta 0:08:49 lr 0.000279	time 0.4655 (0.6219)	loss 4.1834 (3.8494)	grad_norm 5.3072 (5.4988)	mem 5329MB
[2022-04-19 14:13:41 tiny] (main.py 226): INFO Train: [195/300][500/1251]	eta 0:07:40 lr 0.000278	time 0.6094 (0.6133)	loss 3.7840 (3.8464)	grad_norm 4.2067 (5.4377)	mem 5329MB
[2022-04-19 14:14:40 tiny] (main.py 226): INFO Train: [195/300][600/1251]	eta 0:06:36 lr 0.000278	time 0.7125 (0.6098)	loss 4.1867 (3.8410)	grad_norm 3.2354 (5.4513)	mem 5329MB
[2022-04-19 14:15:40 tiny] (main.py 226): INFO Train: [195/300][700/1251]	eta 0:05:35 lr 0.000278	time 0.7780 (0.6080)	loss 3.1298 (3.8486)	grad_norm 4.6370 (5.4259)	mem 5329MB
[2022-04-19 14:16:39 tiny] (main.py 226): INFO Train: [195/300][800/1251]	eta 0:04:33 lr 0.000277	time 0.6267 (0.6055)	loss 3.4053 (3.8522)	grad_norm 3.7452 (5.4385)	mem 5329MB
[2022-04-19 14:17:38 tiny] (main.py 226): INFO Train: [195/300][900/1251]	eta 0:03:31 lr 0.000277	time 0.9225 (0.6037)	loss 3.1190 (3.8419)	grad_norm 3.7614 (5.4273)	mem 5329MB
[2022-04-19 14:18:37 tiny] (main.py 226): INFO Train: [195/300][1000/1251]	eta 0:02:31 lr 0.000277	time 0.6196 (0.6022)	loss 4.3301 (3.8545)	grad_norm 3.7298 (5.4183)	mem 5329MB
[2022-04-19 14:19:36 tiny] (main.py 226): INFO Train: [195/300][1100/1251]	eta 0:01:30 lr 0.000276	time 0.5576 (0.6009)	loss 2.9407 (3.8553)	grad_norm 6.1006 (5.4444)	mem 5329MB
[2022-04-19 14:20:35 tiny] (main.py 226): INFO Train: [195/300][1200/1251]	eta 0:00:30 lr 0.000276	time 0.5023 (0.6001)	loss 3.4266 (3.8490)	grad_norm 4.6840 (5.4206)	mem 5329MB
[2022-04-19 14:20:56 tiny] (main.py 233): INFO EPOCH 195 training takes 0:12:22
[2022-04-19 14:21:08 tiny] (main.py 273): INFO Test: [0/49]	Time 11.678 (11.678)	Loss 1.6360 (1.6360)	Acc@1 66.797 (66.797)	Acc@5 87.695 (87.695)	Mem 5329MB
[2022-04-19 14:21:27 tiny] (main.py 279): INFO  * Acc@1 69.112 Acc@5 89.124
[2022-04-19 14:21:27 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 69.1%
[2022-04-19 14:21:27 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_195.pth saving......
[2022-04-19 14:21:27 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_195.pth saved !!!
[2022-04-19 14:21:27 tiny] (main.py 148): INFO Max accuracy: 69.11%
[2022-04-19 14:21:39 tiny] (main.py 226): INFO Train: [196/300][0/1251]	eta 3:58:38 lr 0.000276	time 11.4455 (11.4455)	loss 4.0281 (4.0281)	grad_norm 7.6832 (7.6832)	mem 5329MB
[2022-04-19 14:22:41 tiny] (main.py 226): INFO Train: [196/300][100/1251]	eta 0:13:56 lr 0.000275	time 0.8652 (0.7270)	loss 3.0549 (3.8161)	grad_norm 6.9276 (nan)	mem 5329MB
[2022-04-19 14:23:40 tiny] (main.py 226): INFO Train: [196/300][200/1251]	eta 0:11:32 lr 0.000275	time 0.6554 (0.6586)	loss 2.4931 (3.7820)	grad_norm 6.9004 (nan)	mem 5329MB
[2022-04-19 14:24:38 tiny] (main.py 226): INFO Train: [196/300][300/1251]	eta 0:10:03 lr 0.000275	time 0.6132 (0.6343)	loss 4.0283 (3.7504)	grad_norm 5.1454 (nan)	mem 5329MB
[2022-04-19 14:25:37 tiny] (main.py 226): INFO Train: [196/300][400/1251]	eta 0:08:48 lr 0.000274	time 0.4454 (0.6216)	loss 3.9677 (3.7719)	grad_norm 4.2277 (nan)	mem 5329MB
[2022-04-19 14:26:35 tiny] (main.py 226): INFO Train: [196/300][500/1251]	eta 0:07:41 lr 0.000274	time 0.4769 (0.6140)	loss 4.2371 (3.8010)	grad_norm 5.5323 (nan)	mem 5329MB
[2022-04-19 14:27:34 tiny] (main.py 226): INFO Train: [196/300][600/1251]	eta 0:06:36 lr 0.000273	time 0.5545 (0.6095)	loss 4.1897 (3.8143)	grad_norm 3.8978 (nan)	mem 5329MB
[2022-04-19 14:28:33 tiny] (main.py 226): INFO Train: [196/300][700/1251]	eta 0:05:34 lr 0.000273	time 0.7090 (0.6069)	loss 4.3529 (3.8374)	grad_norm 6.7594 (nan)	mem 5329MB
[2022-04-19 14:29:31 tiny] (main.py 226): INFO Train: [196/300][800/1251]	eta 0:04:32 lr 0.000273	time 0.5398 (0.6042)	loss 4.5073 (3.8356)	grad_norm 4.1651 (nan)	mem 5329MB
[2022-04-19 14:30:30 tiny] (main.py 226): INFO Train: [196/300][900/1251]	eta 0:03:31 lr 0.000272	time 0.4858 (0.6028)	loss 3.0645 (3.8250)	grad_norm 7.1916 (nan)	mem 5329MB
[2022-04-19 14:31:29 tiny] (main.py 226): INFO Train: [196/300][1000/1251]	eta 0:02:30 lr 0.000272	time 0.7020 (0.6015)	loss 3.3051 (3.8310)	grad_norm 4.9963 (nan)	mem 5329MB
[2022-04-19 14:32:28 tiny] (main.py 226): INFO Train: [196/300][1100/1251]	eta 0:01:30 lr 0.000272	time 0.6435 (0.6003)	loss 3.1432 (3.8371)	grad_norm 5.0968 (nan)	mem 5329MB
[2022-04-19 14:33:27 tiny] (main.py 226): INFO Train: [196/300][1200/1251]	eta 0:00:30 lr 0.000271	time 0.5875 (0.5992)	loss 4.2280 (3.8429)	grad_norm 3.1571 (nan)	mem 5329MB
[2022-04-19 14:33:49 tiny] (main.py 233): INFO EPOCH 196 training takes 0:12:21
[2022-04-19 14:34:01 tiny] (main.py 273): INFO Test: [0/49]	Time 11.828 (11.828)	Loss 1.5573 (1.5573)	Acc@1 69.824 (69.824)	Acc@5 88.965 (88.965)	Mem 5329MB
[2022-04-19 14:34:20 tiny] (main.py 279): INFO  * Acc@1 68.600 Acc@5 88.860
[2022-04-19 14:34:20 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 68.6%
[2022-04-19 14:34:20 tiny] (main.py 148): INFO Max accuracy: 69.11%
[2022-04-19 14:34:32 tiny] (main.py 226): INFO Train: [197/300][0/1251]	eta 4:10:11 lr 0.000271	time 11.9996 (11.9996)	loss 3.9244 (3.9244)	grad_norm 4.1470 (4.1470)	mem 5329MB
[2022-04-19 14:35:34 tiny] (main.py 226): INFO Train: [197/300][100/1251]	eta 0:14:01 lr 0.000271	time 0.4453 (0.7310)	loss 4.1901 (3.8170)	grad_norm 3.5027 (5.4666)	mem 5329MB
[2022-04-19 14:36:33 tiny] (main.py 226): INFO Train: [197/300][200/1251]	eta 0:11:31 lr 0.000270	time 0.4808 (0.6582)	loss 3.7885 (3.8451)	grad_norm 3.8373 (5.5317)	mem 5329MB
[2022-04-19 14:37:31 tiny] (main.py 226): INFO Train: [197/300][300/1251]	eta 0:10:02 lr 0.000270	time 0.6323 (0.6337)	loss 4.2773 (3.8564)	grad_norm 6.1607 (5.7648)	mem 5329MB
[2022-04-19 14:38:29 tiny] (main.py 226): INFO Train: [197/300][400/1251]	eta 0:08:48 lr 0.000270	time 0.5787 (0.6208)	loss 3.1710 (3.8434)	grad_norm 3.6765 (5.6281)	mem 5329MB
[2022-04-19 14:39:28 tiny] (main.py 226): INFO Train: [197/300][500/1251]	eta 0:07:41 lr 0.000269	time 0.5465 (0.6151)	loss 4.0353 (3.8387)	grad_norm 13.4860 (5.5976)	mem 5329MB
[2022-04-19 14:40:28 tiny] (main.py 226): INFO Train: [197/300][600/1251]	eta 0:06:38 lr 0.000269	time 0.6873 (0.6114)	loss 4.4066 (3.8301)	grad_norm 7.0231 (5.6225)	mem 5329MB
[2022-04-19 14:41:27 tiny] (main.py 226): INFO Train: [197/300][700/1251]	eta 0:05:35 lr 0.000269	time 0.6754 (0.6082)	loss 4.2987 (3.8380)	grad_norm 11.1064 (5.5996)	mem 5329MB
[2022-04-19 14:42:26 tiny] (main.py 226): INFO Train: [197/300][800/1251]	eta 0:04:33 lr 0.000268	time 0.6011 (0.6059)	loss 3.5510 (3.8428)	grad_norm 3.6844 (5.6410)	mem 5329MB
[2022-04-19 14:43:24 tiny] (main.py 226): INFO Train: [197/300][900/1251]	eta 0:03:31 lr 0.000268	time 0.5994 (0.6037)	loss 4.0718 (3.8358)	grad_norm 7.9824 (5.6112)	mem 5329MB
[2022-04-19 14:44:23 tiny] (main.py 226): INFO Train: [197/300][1000/1251]	eta 0:02:31 lr 0.000267	time 0.6470 (0.6026)	loss 4.3014 (3.8409)	grad_norm 5.2808 (5.5484)	mem 5329MB
[2022-04-19 14:45:22 tiny] (main.py 226): INFO Train: [197/300][1100/1251]	eta 0:01:30 lr 0.000267	time 0.4388 (0.6010)	loss 4.2535 (3.8407)	grad_norm 7.1953 (5.5605)	mem 5329MB
[2022-04-19 14:46:21 tiny] (main.py 226): INFO Train: [197/300][1200/1251]	eta 0:00:30 lr 0.000267	time 0.6066 (0.6002)	loss 4.1120 (3.8442)	grad_norm 4.3975 (5.5595)	mem 5329MB
[2022-04-19 14:46:43 tiny] (main.py 233): INFO EPOCH 197 training takes 0:12:22
[2022-04-19 14:46:55 tiny] (main.py 273): INFO Test: [0/49]	Time 12.083 (12.083)	Loss 1.5919 (1.5919)	Acc@1 67.676 (67.676)	Acc@5 89.258 (89.258)	Mem 5329MB
[2022-04-19 14:47:14 tiny] (main.py 279): INFO  * Acc@1 68.872 Acc@5 89.084
[2022-04-19 14:47:14 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 68.9%
[2022-04-19 14:47:14 tiny] (main.py 148): INFO Max accuracy: 69.11%
[2022-04-19 14:47:25 tiny] (main.py 226): INFO Train: [198/300][0/1251]	eta 3:47:02 lr 0.000267	time 10.8895 (10.8895)	loss 3.9166 (3.9166)	grad_norm 4.9902 (4.9902)	mem 5329MB
[2022-04-19 14:48:28 tiny] (main.py 226): INFO Train: [198/300][100/1251]	eta 0:14:03 lr 0.000266	time 0.4160 (0.7325)	loss 3.9636 (3.8989)	grad_norm 3.5274 (inf)	mem 5329MB
[2022-04-19 14:49:26 tiny] (main.py 226): INFO Train: [198/300][200/1251]	eta 0:11:31 lr 0.000266	time 0.5274 (0.6579)	loss 4.6402 (3.8588)	grad_norm 3.3520 (inf)	mem 5329MB
[2022-04-19 14:50:25 tiny] (main.py 226): INFO Train: [198/300][300/1251]	eta 0:10:02 lr 0.000265	time 0.5357 (0.6331)	loss 3.7719 (3.8315)	grad_norm 5.0195 (inf)	mem 5329MB
[2022-04-19 14:51:23 tiny] (main.py 226): INFO Train: [198/300][400/1251]	eta 0:08:48 lr 0.000265	time 0.6328 (0.6209)	loss 3.8883 (3.8358)	grad_norm 6.5754 (inf)	mem 5329MB
[2022-04-19 14:52:22 tiny] (main.py 226): INFO Train: [198/300][500/1251]	eta 0:07:41 lr 0.000265	time 0.5722 (0.6148)	loss 3.8000 (3.8239)	grad_norm 8.0561 (inf)	mem 5329MB
[2022-04-19 14:53:21 tiny] (main.py 226): INFO Train: [198/300][600/1251]	eta 0:06:37 lr 0.000264	time 0.5773 (0.6102)	loss 3.5142 (3.8437)	grad_norm 4.6580 (inf)	mem 5329MB
[2022-04-19 14:54:20 tiny] (main.py 226): INFO Train: [198/300][700/1251]	eta 0:05:34 lr 0.000264	time 0.7087 (0.6067)	loss 3.4745 (3.8345)	grad_norm 4.5018 (inf)	mem 5329MB
[2022-04-19 14:55:19 tiny] (main.py 226): INFO Train: [198/300][800/1251]	eta 0:04:32 lr 0.000264	time 0.7023 (0.6047)	loss 2.9924 (3.8326)	grad_norm 4.6463 (inf)	mem 5329MB
[2022-04-19 14:56:18 tiny] (main.py 226): INFO Train: [198/300][900/1251]	eta 0:03:31 lr 0.000263	time 0.5368 (0.6030)	loss 3.3392 (3.8242)	grad_norm 3.4831 (inf)	mem 5329MB
[2022-04-19 14:57:17 tiny] (main.py 226): INFO Train: [198/300][1000/1251]	eta 0:02:31 lr 0.000263	time 0.6143 (0.6020)	loss 3.7483 (3.8228)	grad_norm 4.4019 (inf)	mem 5329MB
[2022-04-19 14:58:15 tiny] (main.py 226): INFO Train: [198/300][1100/1251]	eta 0:01:30 lr 0.000263	time 0.6008 (0.6006)	loss 4.0675 (3.8200)	grad_norm 4.4047 (inf)	mem 5329MB
[2022-04-19 14:59:15 tiny] (main.py 226): INFO Train: [198/300][1200/1251]	eta 0:00:30 lr 0.000262	time 0.5811 (0.5998)	loss 3.7809 (3.8271)	grad_norm 4.1469 (inf)	mem 5329MB
[2022-04-19 14:59:36 tiny] (main.py 233): INFO EPOCH 198 training takes 0:12:22
[2022-04-19 14:59:47 tiny] (main.py 273): INFO Test: [0/49]	Time 10.822 (10.822)	Loss 1.5550 (1.5550)	Acc@1 68.555 (68.555)	Acc@5 89.355 (89.355)	Mem 5329MB
[2022-04-19 15:00:08 tiny] (main.py 279): INFO  * Acc@1 68.830 Acc@5 89.022
[2022-04-19 15:00:08 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 68.8%
[2022-04-19 15:00:08 tiny] (main.py 148): INFO Max accuracy: 69.11%
[2022-04-19 15:00:21 tiny] (main.py 226): INFO Train: [199/300][0/1251]	eta 4:22:26 lr 0.000262	time 12.5874 (12.5874)	loss 2.8019 (2.8019)	grad_norm 3.7149 (3.7149)	mem 5329MB
[2022-04-19 15:01:22 tiny] (main.py 226): INFO Train: [199/300][100/1251]	eta 0:14:03 lr 0.000262	time 0.6988 (0.7324)	loss 4.3919 (3.8222)	grad_norm 4.4392 (nan)	mem 5329MB
[2022-04-19 15:02:20 tiny] (main.py 226): INFO Train: [199/300][200/1251]	eta 0:11:31 lr 0.000261	time 0.6261 (0.6580)	loss 2.5720 (3.8375)	grad_norm 6.1939 (nan)	mem 5329MB
[2022-04-19 15:03:19 tiny] (main.py 226): INFO Train: [199/300][300/1251]	eta 0:10:02 lr 0.000261	time 0.4738 (0.6334)	loss 3.0642 (3.8393)	grad_norm 4.7803 (nan)	mem 5329MB
[2022-04-19 15:04:18 tiny] (main.py 226): INFO Train: [199/300][400/1251]	eta 0:08:50 lr 0.000261	time 0.5111 (0.6231)	loss 3.5116 (3.8327)	grad_norm 4.8805 (nan)	mem 5329MB
[2022-04-19 15:05:16 tiny] (main.py 226): INFO Train: [199/300][500/1251]	eta 0:07:42 lr 0.000260	time 0.6152 (0.6157)	loss 3.2220 (3.8231)	grad_norm 5.2325 (nan)	mem 5329MB
[2022-04-19 15:06:15 tiny] (main.py 226): INFO Train: [199/300][600/1251]	eta 0:06:37 lr 0.000260	time 0.4121 (0.6107)	loss 3.9962 (3.8228)	grad_norm 3.7216 (nan)	mem 5329MB
[2022-04-19 15:07:14 tiny] (main.py 226): INFO Train: [199/300][700/1251]	eta 0:05:34 lr 0.000259	time 0.5423 (0.6077)	loss 3.7669 (3.8241)	grad_norm 7.0736 (nan)	mem 5329MB
[2022-04-19 15:08:13 tiny] (main.py 226): INFO Train: [199/300][800/1251]	eta 0:04:33 lr 0.000259	time 0.6624 (0.6055)	loss 4.4827 (3.8308)	grad_norm 5.2872 (nan)	mem 5329MB
[2022-04-19 15:09:12 tiny] (main.py 226): INFO Train: [199/300][900/1251]	eta 0:03:31 lr 0.000259	time 0.5015 (0.6035)	loss 3.0075 (3.8416)	grad_norm 4.3992 (nan)	mem 5329MB
[2022-04-19 15:10:11 tiny] (main.py 226): INFO Train: [199/300][1000/1251]	eta 0:02:31 lr 0.000258	time 0.7684 (0.6022)	loss 4.3035 (3.8387)	grad_norm 6.8217 (nan)	mem 5329MB
[2022-04-19 15:11:10 tiny] (main.py 226): INFO Train: [199/300][1100/1251]	eta 0:01:30 lr 0.000258	time 0.4394 (0.6011)	loss 4.1153 (3.8319)	grad_norm 7.3808 (nan)	mem 5329MB
[2022-04-19 15:12:09 tiny] (main.py 226): INFO Train: [199/300][1200/1251]	eta 0:00:30 lr 0.000258	time 0.4978 (0.5999)	loss 4.2007 (3.8204)	grad_norm 7.5788 (nan)	mem 5329MB
[2022-04-19 15:12:30 tiny] (main.py 233): INFO EPOCH 199 training takes 0:12:22
[2022-04-19 15:12:43 tiny] (main.py 273): INFO Test: [0/49]	Time 12.735 (12.735)	Loss 1.4819 (1.4819)	Acc@1 70.508 (70.508)	Acc@5 89.355 (89.355)	Mem 5329MB
[2022-04-19 15:13:02 tiny] (main.py 279): INFO  * Acc@1 69.290 Acc@5 89.132
[2022-04-19 15:13:02 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 69.3%
[2022-04-19 15:13:02 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_199.pth saving......
[2022-04-19 15:13:02 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_199.pth saved !!!
[2022-04-19 15:13:02 tiny] (main.py 148): INFO Max accuracy: 69.29%
[2022-04-19 15:13:13 tiny] (main.py 226): INFO Train: [200/300][0/1251]	eta 3:39:06 lr 0.000258	time 10.5088 (10.5088)	loss 3.7174 (3.7174)	grad_norm 4.9732 (4.9732)	mem 5329MB
[2022-04-19 15:14:16 tiny] (main.py 226): INFO Train: [200/300][100/1251]	eta 0:14:04 lr 0.000257	time 0.4457 (0.7334)	loss 4.0776 (3.7926)	grad_norm 4.6525 (5.5876)	mem 5329MB
[2022-04-19 15:15:14 tiny] (main.py 226): INFO Train: [200/300][200/1251]	eta 0:11:30 lr 0.000257	time 0.4807 (0.6575)	loss 3.5937 (3.8086)	grad_norm 5.7552 (5.3204)	mem 5329MB
[2022-04-19 15:16:13 tiny] (main.py 226): INFO Train: [200/300][300/1251]	eta 0:10:03 lr 0.000256	time 0.4933 (0.6342)	loss 3.7835 (3.8084)	grad_norm 3.8169 (5.3661)	mem 5329MB
[2022-04-19 15:17:12 tiny] (main.py 226): INFO Train: [200/300][400/1251]	eta 0:08:49 lr 0.000256	time 0.4683 (0.6226)	loss 3.5804 (3.8082)	grad_norm 4.5971 (5.3665)	mem 5329MB
[2022-04-19 15:18:10 tiny] (main.py 226): INFO Train: [200/300][500/1251]	eta 0:07:41 lr 0.000256	time 0.6342 (0.6149)	loss 4.0823 (3.8026)	grad_norm 6.6742 (5.3980)	mem 5329MB
[2022-04-19 15:19:10 tiny] (main.py 226): INFO Train: [200/300][600/1251]	eta 0:06:37 lr 0.000255	time 0.6417 (0.6112)	loss 4.0060 (3.8054)	grad_norm 7.0868 (5.4919)	mem 5329MB
[2022-04-19 15:20:08 tiny] (main.py 226): INFO Train: [200/300][700/1251]	eta 0:05:34 lr 0.000255	time 0.5458 (0.6075)	loss 3.5289 (3.8151)	grad_norm 3.2200 (5.5069)	mem 5329MB
[2022-04-19 15:21:08 tiny] (main.py 226): INFO Train: [200/300][800/1251]	eta 0:04:33 lr 0.000255	time 0.4926 (0.6058)	loss 3.9655 (3.8257)	grad_norm 4.0384 (5.5584)	mem 5329MB
[2022-04-19 15:22:07 tiny] (main.py 226): INFO Train: [200/300][900/1251]	eta 0:03:32 lr 0.000254	time 0.6543 (0.6040)	loss 3.9240 (3.8271)	grad_norm 7.5989 (5.5586)	mem 5329MB
[2022-04-19 15:23:06 tiny] (main.py 226): INFO Train: [200/300][1000/1251]	eta 0:02:31 lr 0.000254	time 0.5757 (0.6027)	loss 2.9386 (3.8312)	grad_norm 19.9705 (5.6146)	mem 5329MB
[2022-04-19 15:24:04 tiny] (main.py 226): INFO Train: [200/300][1100/1251]	eta 0:01:30 lr 0.000254	time 0.6951 (0.6011)	loss 4.0818 (3.8263)	grad_norm 5.9417 (5.6390)	mem 5329MB
[2022-04-19 15:25:03 tiny] (main.py 226): INFO Train: [200/300][1200/1251]	eta 0:00:30 lr 0.000253	time 0.5921 (0.5998)	loss 4.3902 (3.8335)	grad_norm 4.6375 (5.6195)	mem 5329MB
[2022-04-19 15:25:25 tiny] (main.py 233): INFO EPOCH 200 training takes 0:12:22
[2022-04-19 15:25:35 tiny] (main.py 273): INFO Test: [0/49]	Time 10.736 (10.736)	Loss 1.5699 (1.5699)	Acc@1 69.824 (69.824)	Acc@5 90.234 (90.234)	Mem 5329MB
[2022-04-19 15:25:56 tiny] (main.py 279): INFO  * Acc@1 68.976 Acc@5 89.066
[2022-04-19 15:25:56 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 69.0%
[2022-04-19 15:25:56 tiny] (main.py 148): INFO Max accuracy: 69.29%
[2022-04-19 15:26:07 tiny] (main.py 226): INFO Train: [201/300][0/1251]	eta 4:01:07 lr 0.000253	time 11.5644 (11.5644)	loss 3.0207 (3.0207)	grad_norm 4.2993 (4.2993)	mem 5329MB
[2022-04-19 15:27:09 tiny] (main.py 226): INFO Train: [201/300][100/1251]	eta 0:14:00 lr 0.000253	time 0.6203 (0.7299)	loss 4.0030 (3.8542)	grad_norm 4.0254 (6.1401)	mem 5329MB
[2022-04-19 15:28:08 tiny] (main.py 226): INFO Train: [201/300][200/1251]	eta 0:11:30 lr 0.000252	time 0.6348 (0.6573)	loss 4.6113 (3.9131)	grad_norm 5.2554 (5.5936)	mem 5329MB
[2022-04-19 15:29:07 tiny] (main.py 226): INFO Train: [201/300][300/1251]	eta 0:10:02 lr 0.000252	time 0.7651 (0.6341)	loss 4.2059 (3.8546)	grad_norm 5.9465 (5.9034)	mem 5329MB
[2022-04-19 15:30:05 tiny] (main.py 226): INFO Train: [201/300][400/1251]	eta 0:08:49 lr 0.000252	time 0.4672 (0.6222)	loss 4.0413 (3.8520)	grad_norm 3.5915 (5.8115)	mem 5329MB
[2022-04-19 15:31:04 tiny] (main.py 226): INFO Train: [201/300][500/1251]	eta 0:07:42 lr 0.000251	time 0.7279 (0.6153)	loss 4.3298 (3.8675)	grad_norm 3.3020 (5.7066)	mem 5329MB
[2022-04-19 15:32:03 tiny] (main.py 226): INFO Train: [201/300][600/1251]	eta 0:06:37 lr 0.000251	time 0.7377 (0.6108)	loss 4.5584 (3.8594)	grad_norm 5.9000 (5.6914)	mem 5329MB
[2022-04-19 15:33:01 tiny] (main.py 226): INFO Train: [201/300][700/1251]	eta 0:05:34 lr 0.000251	time 0.8115 (0.6073)	loss 4.0233 (3.8513)	grad_norm 4.9203 (5.7126)	mem 5329MB
[2022-04-19 15:34:00 tiny] (main.py 226): INFO Train: [201/300][800/1251]	eta 0:04:32 lr 0.000250	time 0.4163 (0.6049)	loss 4.7072 (3.8581)	grad_norm 4.8379 (5.6951)	mem 5329MB
[2022-04-19 15:35:00 tiny] (main.py 226): INFO Train: [201/300][900/1251]	eta 0:03:31 lr 0.000250	time 0.8856 (0.6035)	loss 3.8560 (3.8577)	grad_norm 10.5234 (5.6739)	mem 5329MB
[2022-04-19 15:35:59 tiny] (main.py 226): INFO Train: [201/300][1000/1251]	eta 0:02:31 lr 0.000249	time 0.7248 (0.6022)	loss 3.5431 (3.8572)	grad_norm 3.6833 (5.7110)	mem 5329MB
[2022-04-19 15:36:57 tiny] (main.py 226): INFO Train: [201/300][1100/1251]	eta 0:01:30 lr 0.000249	time 0.4586 (0.6005)	loss 4.6793 (3.8487)	grad_norm 4.7304 (5.7638)	mem 5329MB
[2022-04-19 15:37:56 tiny] (main.py 226): INFO Train: [201/300][1200/1251]	eta 0:00:30 lr 0.000249	time 0.5801 (0.5996)	loss 4.0502 (3.8479)	grad_norm 3.7235 (5.7150)	mem 5329MB
[2022-04-19 15:38:18 tiny] (main.py 233): INFO EPOCH 201 training takes 0:12:21
[2022-04-19 15:38:30 tiny] (main.py 273): INFO Test: [0/49]	Time 11.995 (11.995)	Loss 1.6057 (1.6057)	Acc@1 68.848 (68.848)	Acc@5 88.965 (88.965)	Mem 5329MB
[2022-04-19 15:38:49 tiny] (main.py 279): INFO  * Acc@1 69.086 Acc@5 89.182
[2022-04-19 15:38:49 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 69.1%
[2022-04-19 15:38:49 tiny] (main.py 148): INFO Max accuracy: 69.29%
[2022-04-19 15:39:00 tiny] (main.py 226): INFO Train: [202/300][0/1251]	eta 3:59:08 lr 0.000249	time 11.4698 (11.4698)	loss 4.3353 (4.3353)	grad_norm 4.3587 (4.3587)	mem 5329MB
[2022-04-19 15:40:03 tiny] (main.py 226): INFO Train: [202/300][100/1251]	eta 0:14:03 lr 0.000248	time 0.4456 (0.7328)	loss 4.5764 (3.9683)	grad_norm 3.6500 (5.0951)	mem 5329MB
[2022-04-19 15:41:01 tiny] (main.py 226): INFO Train: [202/300][200/1251]	eta 0:11:32 lr 0.000248	time 0.5761 (0.6589)	loss 3.8381 (3.8639)	grad_norm 4.8928 (5.3320)	mem 5329MB
[2022-04-19 15:42:00 tiny] (main.py 226): INFO Train: [202/300][300/1251]	eta 0:10:03 lr 0.000248	time 0.5619 (0.6350)	loss 4.2136 (3.8509)	grad_norm 5.4583 (5.5317)	mem 5329MB
[2022-04-19 15:42:58 tiny] (main.py 226): INFO Train: [202/300][400/1251]	eta 0:08:49 lr 0.000247	time 0.5217 (0.6227)	loss 4.7062 (3.8340)	grad_norm 4.9944 (nan)	mem 5329MB
[2022-04-19 15:43:57 tiny] (main.py 226): INFO Train: [202/300][500/1251]	eta 0:07:42 lr 0.000247	time 0.3843 (0.6152)	loss 4.1642 (3.8459)	grad_norm 3.8319 (nan)	mem 5329MB
[2022-04-19 15:44:56 tiny] (main.py 226): INFO Train: [202/300][600/1251]	eta 0:06:37 lr 0.000246	time 0.7131 (0.6105)	loss 4.3467 (3.8544)	grad_norm 3.4751 (nan)	mem 5329MB
[2022-04-19 15:45:54 tiny] (main.py 226): INFO Train: [202/300][700/1251]	eta 0:05:34 lr 0.000246	time 0.5091 (0.6070)	loss 4.2916 (3.8497)	grad_norm 4.5107 (nan)	mem 5329MB
[2022-04-19 15:46:53 tiny] (main.py 226): INFO Train: [202/300][800/1251]	eta 0:04:32 lr 0.000246	time 0.5167 (0.6046)	loss 4.4293 (3.8395)	grad_norm 5.1626 (nan)	mem 5329MB
[2022-04-19 15:47:52 tiny] (main.py 226): INFO Train: [202/300][900/1251]	eta 0:03:31 lr 0.000245	time 0.7361 (0.6029)	loss 3.8430 (3.8297)	grad_norm 4.0809 (nan)	mem 5329MB
[2022-04-19 15:48:51 tiny] (main.py 226): INFO Train: [202/300][1000/1251]	eta 0:02:31 lr 0.000245	time 0.6025 (0.6016)	loss 4.0842 (3.8237)	grad_norm 4.1455 (nan)	mem 5329MB
[2022-04-19 15:49:50 tiny] (main.py 226): INFO Train: [202/300][1100/1251]	eta 0:01:30 lr 0.000245	time 0.4750 (0.6005)	loss 3.8072 (3.8270)	grad_norm 6.0085 (nan)	mem 5329MB
[2022-04-19 15:50:49 tiny] (main.py 226): INFO Train: [202/300][1200/1251]	eta 0:00:30 lr 0.000244	time 0.5351 (0.5996)	loss 4.0014 (3.8300)	grad_norm 6.2813 (nan)	mem 5329MB
[2022-04-19 15:51:10 tiny] (main.py 233): INFO EPOCH 202 training takes 0:12:21
[2022-04-19 15:51:21 tiny] (main.py 273): INFO Test: [0/49]	Time 10.704 (10.704)	Loss 1.4832 (1.4832)	Acc@1 70.215 (70.215)	Acc@5 89.258 (89.258)	Mem 5329MB
[2022-04-19 15:51:41 tiny] (main.py 279): INFO  * Acc@1 69.256 Acc@5 89.278
[2022-04-19 15:51:41 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 69.3%
[2022-04-19 15:51:41 tiny] (main.py 148): INFO Max accuracy: 69.29%
[2022-04-19 15:51:53 tiny] (main.py 226): INFO Train: [203/300][0/1251]	eta 4:03:42 lr 0.000244	time 11.6886 (11.6886)	loss 3.3513 (3.3513)	grad_norm 3.7088 (3.7088)	mem 5329MB
[2022-04-19 15:52:55 tiny] (main.py 226): INFO Train: [203/300][100/1251]	eta 0:13:57 lr 0.000244	time 0.4992 (0.7279)	loss 4.4049 (3.8618)	grad_norm 5.4601 (6.4231)	mem 5329MB
[2022-04-19 15:53:54 tiny] (main.py 226): INFO Train: [203/300][200/1251]	eta 0:11:32 lr 0.000243	time 0.5279 (0.6587)	loss 4.7252 (3.8929)	grad_norm 5.1397 (nan)	mem 5329MB
[2022-04-19 15:54:53 tiny] (main.py 226): INFO Train: [203/300][300/1251]	eta 0:10:04 lr 0.000243	time 0.5565 (0.6351)	loss 4.0838 (3.8506)	grad_norm 6.3124 (nan)	mem 5329MB
[2022-04-19 15:55:51 tiny] (main.py 226): INFO Train: [203/300][400/1251]	eta 0:08:49 lr 0.000243	time 0.6870 (0.6224)	loss 3.3592 (3.8265)	grad_norm 3.7391 (nan)	mem 5329MB
[2022-04-19 15:56:50 tiny] (main.py 226): INFO Train: [203/300][500/1251]	eta 0:07:41 lr 0.000242	time 0.6226 (0.6151)	loss 2.7083 (3.8180)	grad_norm 8.9125 (nan)	mem 5329MB
[2022-04-19 15:57:48 tiny] (main.py 226): INFO Train: [203/300][600/1251]	eta 0:06:37 lr 0.000242	time 0.5623 (0.6101)	loss 4.7012 (3.8321)	grad_norm 6.4237 (nan)	mem 5329MB
[2022-04-19 15:58:47 tiny] (main.py 226): INFO Train: [203/300][700/1251]	eta 0:05:34 lr 0.000242	time 0.6793 (0.6074)	loss 3.5019 (3.8366)	grad_norm 12.0038 (nan)	mem 5329MB
[2022-04-19 15:59:46 tiny] (main.py 226): INFO Train: [203/300][800/1251]	eta 0:04:32 lr 0.000241	time 0.5206 (0.6050)	loss 3.6018 (3.8478)	grad_norm 4.5505 (nan)	mem 5329MB
[2022-04-19 16:00:45 tiny] (main.py 226): INFO Train: [203/300][900/1251]	eta 0:03:31 lr 0.000241	time 0.5079 (0.6033)	loss 3.5293 (3.8475)	grad_norm 4.9077 (nan)	mem 5329MB
[2022-04-19 16:01:44 tiny] (main.py 226): INFO Train: [203/300][1000/1251]	eta 0:02:31 lr 0.000241	time 0.6847 (0.6021)	loss 2.8640 (3.8519)	grad_norm 5.4132 (nan)	mem 5329MB
[2022-04-19 16:02:43 tiny] (main.py 226): INFO Train: [203/300][1100/1251]	eta 0:01:30 lr 0.000240	time 0.6871 (0.6009)	loss 2.9728 (3.8498)	grad_norm 3.2140 (nan)	mem 5329MB
[2022-04-19 16:03:42 tiny] (main.py 226): INFO Train: [203/300][1200/1251]	eta 0:00:30 lr 0.000240	time 0.6114 (0.5997)	loss 4.4166 (3.8536)	grad_norm 5.3518 (nan)	mem 5329MB
[2022-04-19 16:04:04 tiny] (main.py 233): INFO EPOCH 203 training takes 0:12:22
[2022-04-19 16:04:15 tiny] (main.py 273): INFO Test: [0/49]	Time 11.544 (11.544)	Loss 1.6213 (1.6213)	Acc@1 66.504 (66.504)	Acc@5 87.695 (87.695)	Mem 5329MB
[2022-04-19 16:04:35 tiny] (main.py 279): INFO  * Acc@1 69.298 Acc@5 89.290
[2022-04-19 16:04:35 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 69.3%
[2022-04-19 16:04:35 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_203.pth saving......
[2022-04-19 16:04:35 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_203.pth saved !!!
[2022-04-19 16:04:35 tiny] (main.py 148): INFO Max accuracy: 69.30%
[2022-04-19 16:04:47 tiny] (main.py 226): INFO Train: [204/300][0/1251]	eta 4:09:32 lr 0.000240	time 11.9687 (11.9687)	loss 2.7109 (2.7109)	grad_norm 4.1246 (4.1246)	mem 5329MB
[2022-04-19 16:05:49 tiny] (main.py 226): INFO Train: [204/300][100/1251]	eta 0:14:02 lr 0.000239	time 0.6367 (0.7316)	loss 3.9930 (3.9049)	grad_norm 4.6436 (5.3024)	mem 5329MB
[2022-04-19 16:06:48 tiny] (main.py 226): INFO Train: [204/300][200/1251]	eta 0:11:31 lr 0.000239	time 0.5887 (0.6580)	loss 4.1431 (3.8411)	grad_norm 4.4132 (5.5507)	mem 5329MB
[2022-04-19 16:07:46 tiny] (main.py 226): INFO Train: [204/300][300/1251]	eta 0:10:02 lr 0.000239	time 0.4677 (0.6336)	loss 2.7236 (3.8580)	grad_norm 8.0583 (5.7095)	mem 5329MB
[2022-04-19 16:08:45 tiny] (main.py 226): INFO Train: [204/300][400/1251]	eta 0:08:50 lr 0.000238	time 0.5608 (0.6236)	loss 3.5654 (3.8749)	grad_norm 4.7358 (5.6877)	mem 5329MB
[2022-04-19 16:09:44 tiny] (main.py 226): INFO Train: [204/300][500/1251]	eta 0:07:42 lr 0.000238	time 0.8228 (0.6164)	loss 3.9072 (3.8608)	grad_norm 4.4743 (5.6376)	mem 5329MB
[2022-04-19 16:10:43 tiny] (main.py 226): INFO Train: [204/300][600/1251]	eta 0:06:38 lr 0.000238	time 0.6522 (0.6116)	loss 2.9450 (3.8751)	grad_norm 3.5924 (5.7365)	mem 5329MB
[2022-04-19 16:11:41 tiny] (main.py 226): INFO Train: [204/300][700/1251]	eta 0:05:34 lr 0.000237	time 0.7064 (0.6076)	loss 4.2039 (3.8684)	grad_norm 4.8294 (5.8036)	mem 5329MB
[2022-04-19 16:12:41 tiny] (main.py 226): INFO Train: [204/300][800/1251]	eta 0:04:33 lr 0.000237	time 0.3531 (0.6058)	loss 3.7946 (3.8676)	grad_norm 3.5498 (5.7265)	mem 5329MB
[2022-04-19 16:13:39 tiny] (main.py 226): INFO Train: [204/300][900/1251]	eta 0:03:31 lr 0.000237	time 0.5732 (0.6038)	loss 3.0237 (3.8602)	grad_norm 6.1002 (5.7525)	mem 5329MB
[2022-04-19 16:14:38 tiny] (main.py 226): INFO Train: [204/300][1000/1251]	eta 0:02:31 lr 0.000236	time 0.5272 (0.6022)	loss 3.0693 (3.8544)	grad_norm 4.8757 (5.7474)	mem 5329MB
[2022-04-19 16:15:37 tiny] (main.py 226): INFO Train: [204/300][1100/1251]	eta 0:01:30 lr 0.000236	time 0.4916 (0.6013)	loss 3.4531 (3.8604)	grad_norm 4.6168 (5.6933)	mem 5329MB
[2022-04-19 16:16:37 tiny] (main.py 226): INFO Train: [204/300][1200/1251]	eta 0:00:30 lr 0.000236	time 0.8810 (0.6006)	loss 3.3104 (3.8588)	grad_norm 6.1679 (5.7027)	mem 5329MB
[2022-04-19 16:16:58 tiny] (main.py 233): INFO EPOCH 204 training takes 0:12:22
[2022-04-19 16:17:11 tiny] (main.py 273): INFO Test: [0/49]	Time 12.527 (12.527)	Loss 1.5182 (1.5182)	Acc@1 67.188 (67.188)	Acc@5 89.453 (89.453)	Mem 5329MB
[2022-04-19 16:17:30 tiny] (main.py 279): INFO  * Acc@1 69.462 Acc@5 89.310
[2022-04-19 16:17:30 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 69.5%
[2022-04-19 16:17:30 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_204.pth saving......
[2022-04-19 16:17:30 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_204.pth saved !!!
[2022-04-19 16:17:30 tiny] (main.py 148): INFO Max accuracy: 69.46%
[2022-04-19 16:17:42 tiny] (main.py 226): INFO Train: [205/300][0/1251]	eta 4:14:18 lr 0.000235	time 12.1972 (12.1972)	loss 4.0274 (4.0274)	grad_norm 4.3374 (4.3374)	mem 5329MB
[2022-04-19 16:18:43 tiny] (main.py 226): INFO Train: [205/300][100/1251]	eta 0:13:56 lr 0.000235	time 0.6014 (0.7264)	loss 3.7480 (3.9500)	grad_norm 10.0645 (6.2850)	mem 5329MB
[2022-04-19 16:19:42 tiny] (main.py 226): INFO Train: [205/300][200/1251]	eta 0:11:30 lr 0.000235	time 0.6342 (0.6566)	loss 4.6215 (3.8741)	grad_norm 5.9875 (6.3050)	mem 5329MB
[2022-04-19 16:20:40 tiny] (main.py 226): INFO Train: [205/300][300/1251]	eta 0:10:02 lr 0.000234	time 0.7750 (0.6336)	loss 4.0186 (3.8212)	grad_norm 7.0199 (6.0523)	mem 5329MB
[2022-04-19 16:21:39 tiny] (main.py 226): INFO Train: [205/300][400/1251]	eta 0:08:49 lr 0.000234	time 0.5514 (0.6217)	loss 4.0067 (3.8068)	grad_norm 12.6068 (6.0788)	mem 5329MB
[2022-04-19 16:22:38 tiny] (main.py 226): INFO Train: [205/300][500/1251]	eta 0:07:42 lr 0.000234	time 0.4883 (0.6153)	loss 4.2898 (3.8318)	grad_norm 4.6610 (6.0641)	mem 5329MB
[2022-04-19 16:23:37 tiny] (main.py 226): INFO Train: [205/300][600/1251]	eta 0:06:38 lr 0.000233	time 0.5971 (0.6115)	loss 4.1318 (3.8371)	grad_norm 5.4123 (5.9958)	mem 5329MB
[2022-04-19 16:24:36 tiny] (main.py 226): INFO Train: [205/300][700/1251]	eta 0:05:34 lr 0.000233	time 0.5142 (0.6077)	loss 3.9172 (3.8200)	grad_norm 7.9765 (5.9578)	mem 5329MB
[2022-04-21 02:16:18 tiny] (main.py 347): INFO Full config saved to output/tiny/default/config.json
[2022-04-21 02:16:18 tiny] (main.py 350): INFO AMP_OPT_LEVEL: O1
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 256
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: ../../Data/raw-data/imagenet-data/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 16
  PIN_MEMORY: true
  ZIP_MODE: false
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DFvT:
    APE: false
    DEPTHS:
    - 1
    - 1
    - 2
    - 1
    EMBED_DIM: 48
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    SIZE: tiny
    WINDOW_SIZE: 7
  DROP_PATH_RATE: 0.0
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: tiny
  NUM_CLASSES: 1000
  RESUME: ''
  TYPE: DFvT
OUTPUT: output/tiny/default
PRINT_FREQ: 100
SAVE_FREQ: 1000
SEED: 0
TAG: default
TEST:
  CROP: true
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: true
  BASE_LR: 0.001
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MIN_LR: 1.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.0e-06
  WEIGHT_DECAY: 0.05

[2022-04-21 02:16:23 tiny] (main.py 80): INFO Creating model:DFvT/tiny
[2022-04-21 02:16:24 tiny] (main.py 85): INFO DFvT(
  (patch_embed): PatchEmbed(
    (proj1): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (proj2): Conv2d(24, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (silu): SiLU(inplace=True)
    (norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (norm1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=48, input_resolution=(28, 28), depth=1
      (blocks): ModuleList(
        (0): TransformerBlock(
          dim=48, input_resolution=(28, 28), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (select): DANE(
            (fc_spatial): Sequential(
              (0): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=48, out_features=1, bias=False)
            )
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc_channel): Sequential(
              (0): Linear(in_features=48, out_features=3, bias=False)
              (1): SiLU(inplace=True)
              (2): LayerNorm((3,), eps=1e-05, elementwise_affine=True)
              (3): Linear(in_features=3, out_features=48, bias=False)
            )
            (sigmoid): Sigmoid()
          )
          (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=48, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=48, out_features=144, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=48, out_features=48, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=48, out_features=192, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=192, out_features=48, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(28, 28), dim=48
        (reduction): Linear(in_features=48, out_features=96, bias=False)
        (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=1
      (blocks): ModuleList(
        (0): TransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (select): DANE(
            (fc_spatial): Sequential(
              (0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=96, out_features=1, bias=False)
            )
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc_channel): Sequential(
              (0): Linear(in_features=96, out_features=6, bias=False)
              (1): SiLU(inplace=True)
              (2): LayerNorm((6,), eps=1e-05, elementwise_affine=True)
              (3): Linear(in_features=6, out_features=96, bias=False)
            )
            (sigmoid): Sigmoid()
          )
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=96, out_features=192, bias=False)
        (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0): TransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=12, window_size=7, shift_size=0, mlp_ratio=4.0
          (select): DANE(
            (fc_spatial): Sequential(
              (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=192, out_features=1, bias=False)
            )
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc_channel): Sequential(
              (0): Linear(in_features=192, out_features=12, bias=False)
              (1): SiLU(inplace=True)
              (2): LayerNorm((12,), eps=1e-05, elementwise_affine=True)
              (3): Linear(in_features=12, out_features=192, bias=False)
            )
            (sigmoid): Sigmoid()
          )
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=12
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): TransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=12, window_size=7, shift_size=0, mlp_ratio=4.0
          (select): DANE(
            (fc_spatial): Sequential(
              (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=192, out_features=1, bias=False)
            )
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc_channel): Sequential(
              (0): Linear(in_features=192, out_features=12, bias=False)
              (1): SiLU(inplace=True)
              (2): LayerNorm((12,), eps=1e-05, elementwise_affine=True)
              (3): Linear(in_features=12, out_features=192, bias=False)
            )
            (sigmoid): Sigmoid()
          )
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=12
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(7, 7), dim=192
        (reduction): Linear(in_features=192, out_features=384, bias=False)
        (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
      )
    )
    (3): BasicLayer(
      dim=384, input_resolution=(7, 7), depth=1
      (blocks): ModuleList(
        (0): TransformerBlock(
          dim=384, input_resolution=(7, 7), num_heads=24, window_size=7, shift_size=0, mlp_ratio=4.0
          (select): DANE(
            (fc_spatial): Sequential(
              (0): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (1): Linear(in_features=384, out_features=1, bias=False)
            )
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc_channel): Sequential(
              (0): Linear(in_features=384, out_features=24, bias=False)
              (1): SiLU(inplace=True)
              (2): LayerNorm((24,), eps=1e-05, elementwise_affine=True)
              (3): Linear(in_features=24, out_features=384, bias=False)
            )
            (sigmoid): Sigmoid()
          )
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=384, window_size=(7, 7), num_heads=24
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (convlayers): ModuleList(
    (0): ConvBlock(
      (conv1x1_1): Sequential(
        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): SiLU(inplace=True)
        (6): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (7): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (8): SiLU(inplace=True)
      )
      (conv1): Sequential(
        (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)
        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
      (conv1x1_2): Sequential(
        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
    )
    (1): ConvBlock(
      (conv1x1_1): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): SiLU(inplace=True)
        (6): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (8): SiLU(inplace=True)
      )
      (conv1): Sequential(
        (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
      (conv1x1_2): Sequential(
        (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
    )
    (2): ConvBlock(
      (conv1x1_1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): SiLU(inplace=True)
        (6): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (7): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (8): SiLU(inplace=True)
      )
      (conv1): Sequential(
        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
      (conv1x1_2): Sequential(
        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
    )
    (3): ConvBlock(
      (conv1x1_1): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): SiLU(inplace=True)
        (6): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (7): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (8): SiLU(inplace=True)
      )
      (conv1): Sequential(
        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
      (conv1x1_2): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SiLU(inplace=True)
      )
    )
  )
  (multiresolution_conv): ModuleList(
    (0): Sequential(
      (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Sequential(
      (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
      (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): Sequential(
      (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
      (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (head): Linear(in_features=384, out_features=1000, bias=True)
)
[2022-04-21 02:16:24 tiny] (main.py 94): INFO number of params: 3967627
[2022-04-21 02:16:24 tiny] (main.py 97): INFO number of GFLOPs: 0.27142848
[2022-04-21 02:16:24 tiny] (main.py 119): INFO auto resuming from output/tiny/default/ckpt_epoch_204.pth
[2022-04-21 02:16:24 tiny] (utils.py 20): INFO ==============> Resuming form output/tiny/default/ckpt_epoch_204.pth....................
[2022-04-21 02:16:24 tiny] (utils.py 27): INFO <All keys matched successfully>
[2022-04-21 02:16:24 tiny] (utils.py 37): INFO => loaded successfully 'output/tiny/default/ckpt_epoch_204.pth' (epoch 204)
[2022-04-21 02:16:39 tiny] (main.py 273): INFO Test: [0/49]	Time 15.392 (15.392)	Loss 1.5406 (1.5406)	Acc@1 67.480 (67.480)	Acc@5 88.574 (88.574)	Mem 1045MB
[2022-04-21 02:16:55 tiny] (main.py 279): INFO  * Acc@1 69.534 Acc@5 89.306
[2022-04-21 02:16:55 tiny] (main.py 126): INFO Accuracy of the network on the 50000 test images: 69.5%
[2022-04-21 02:16:55 tiny] (main.py 134): INFO Start training
[2022-04-21 02:17:08 tiny] (main.py 226): INFO Train: [205/300][0/1251]	eta 4:30:59 lr 0.000235	time 12.9970 (12.9970)	loss 4.6507 (4.6507)	grad_norm 6.0893 (6.0893)	mem 5313MB
[2022-04-21 02:18:09 tiny] (main.py 226): INFO Train: [205/300][100/1251]	eta 0:13:55 lr 0.000235	time 0.5740 (0.7260)	loss 4.1620 (3.9253)	grad_norm 11.7516 (5.8023)	mem 5325MB
[2022-04-21 02:19:07 tiny] (main.py 226): INFO Train: [205/300][200/1251]	eta 0:11:28 lr 0.000235	time 0.6317 (0.6553)	loss 3.5609 (3.8474)	grad_norm 5.6556 (nan)	mem 5325MB
[2022-04-21 02:20:06 tiny] (main.py 226): INFO Train: [205/300][300/1251]	eta 0:10:00 lr 0.000234	time 0.6318 (0.6320)	loss 3.8335 (3.7957)	grad_norm 7.1204 (nan)	mem 5325MB
[2022-04-21 02:21:05 tiny] (main.py 226): INFO Train: [205/300][400/1251]	eta 0:08:49 lr 0.000234	time 0.6281 (0.6217)	loss 3.9911 (3.8072)	grad_norm 5.3221 (nan)	mem 5325MB
[2022-04-21 02:22:03 tiny] (main.py 226): INFO Train: [205/300][500/1251]	eta 0:07:40 lr 0.000234	time 0.6194 (0.6137)	loss 4.2329 (3.8107)	grad_norm 6.0616 (nan)	mem 5325MB
[2022-04-21 02:23:02 tiny] (main.py 226): INFO Train: [205/300][600/1251]	eta 0:06:36 lr 0.000233	time 0.6422 (0.6096)	loss 2.6230 (3.8220)	grad_norm 8.5454 (nan)	mem 5325MB
[2022-04-21 02:24:00 tiny] (main.py 226): INFO Train: [205/300][700/1251]	eta 0:05:33 lr 0.000233	time 0.5788 (0.6058)	loss 4.1657 (3.8170)	grad_norm 4.2509 (nan)	mem 5325MB
[2022-04-21 02:24:59 tiny] (main.py 226): INFO Train: [205/300][800/1251]	eta 0:04:32 lr 0.000233	time 0.4694 (0.6039)	loss 4.4752 (3.8231)	grad_norm 4.2708 (nan)	mem 5325MB
[2022-04-21 02:25:57 tiny] (main.py 226): INFO Train: [205/300][900/1251]	eta 0:03:31 lr 0.000232	time 0.4730 (0.6017)	loss 4.0826 (3.8084)	grad_norm 4.9063 (nan)	mem 5325MB
[2022-04-21 02:26:56 tiny] (main.py 226): INFO Train: [205/300][1000/1251]	eta 0:02:30 lr 0.000232	time 0.3836 (0.6003)	loss 3.6360 (3.8083)	grad_norm 3.3879 (nan)	mem 5325MB
[2022-04-21 02:27:55 tiny] (main.py 226): INFO Train: [205/300][1100/1251]	eta 0:01:30 lr 0.000232	time 0.5940 (0.5994)	loss 4.2171 (3.8099)	grad_norm 4.3762 (nan)	mem 5325MB
[2022-04-21 02:28:54 tiny] (main.py 226): INFO Train: [205/300][1200/1251]	eta 0:00:30 lr 0.000231	time 0.4010 (0.5981)	loss 4.0596 (3.8185)	grad_norm 5.2792 (nan)	mem 5325MB
[2022-04-21 02:29:15 tiny] (main.py 233): INFO EPOCH 205 training takes 0:12:20
[2022-04-21 02:29:26 tiny] (main.py 273): INFO Test: [0/49]	Time 10.860 (10.860)	Loss 1.5449 (1.5449)	Acc@1 69.629 (69.629)	Acc@5 89.746 (89.746)	Mem 5325MB
[2022-04-21 02:29:46 tiny] (main.py 279): INFO  * Acc@1 69.222 Acc@5 89.182
[2022-04-21 02:29:46 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 69.2%
[2022-04-21 02:29:46 tiny] (main.py 148): INFO Max accuracy: 69.46%
[2022-04-21 02:29:57 tiny] (main.py 226): INFO Train: [206/300][0/1251]	eta 3:45:45 lr 0.000231	time 10.8274 (10.8274)	loss 3.7121 (3.7121)	grad_norm 7.8044 (7.8044)	mem 5325MB
[2022-04-21 02:31:00 tiny] (main.py 226): INFO Train: [206/300][100/1251]	eta 0:13:58 lr 0.000231	time 0.6619 (0.7287)	loss 4.2915 (3.8705)	grad_norm 4.5288 (6.3626)	mem 5325MB
[2022-04-21 02:31:58 tiny] (main.py 226): INFO Train: [206/300][200/1251]	eta 0:11:28 lr 0.000230	time 0.5832 (0.6555)	loss 4.1856 (3.8806)	grad_norm 4.0076 (6.1986)	mem 5325MB
[2022-04-21 02:32:56 tiny] (main.py 226): INFO Train: [206/300][300/1251]	eta 0:09:59 lr 0.000230	time 0.5675 (0.6308)	loss 2.8847 (3.8317)	grad_norm 7.3493 (6.0218)	mem 5325MB
[2022-04-21 02:33:55 tiny] (main.py 226): INFO Train: [206/300][400/1251]	eta 0:08:47 lr 0.000230	time 0.9006 (0.6196)	loss 2.8621 (3.8174)	grad_norm 5.5895 (5.9188)	mem 5325MB
[2022-04-21 02:34:53 tiny] (main.py 226): INFO Train: [206/300][500/1251]	eta 0:07:39 lr 0.000229	time 0.5614 (0.6122)	loss 3.6975 (3.8120)	grad_norm 3.6121 (5.7742)	mem 5325MB
[2022-04-21 02:35:51 tiny] (main.py 226): INFO Train: [206/300][600/1251]	eta 0:06:35 lr 0.000229	time 0.5186 (0.6080)	loss 3.3919 (3.8124)	grad_norm 4.3141 (5.7900)	mem 5325MB
[2022-04-21 02:36:50 tiny] (main.py 226): INFO Train: [206/300][700/1251]	eta 0:05:33 lr 0.000229	time 0.4854 (0.6054)	loss 3.9585 (3.8010)	grad_norm 5.3801 (5.7382)	mem 5325MB
[2022-04-21 02:37:49 tiny] (main.py 226): INFO Train: [206/300][800/1251]	eta 0:04:31 lr 0.000228	time 0.4432 (0.6029)	loss 4.0706 (3.7984)	grad_norm 7.9519 (5.7375)	mem 5325MB
[2022-04-21 02:38:48 tiny] (main.py 226): INFO Train: [206/300][900/1251]	eta 0:03:31 lr 0.000228	time 0.6466 (0.6012)	loss 4.1088 (3.8054)	grad_norm 3.4784 (5.7378)	mem 5325MB
[2022-04-21 02:39:47 tiny] (main.py 226): INFO Train: [206/300][1000/1251]	eta 0:02:30 lr 0.000228	time 0.4107 (0.6000)	loss 4.6164 (3.7996)	grad_norm 5.5404 (5.7953)	mem 5325MB
[2022-04-21 02:40:46 tiny] (main.py 226): INFO Train: [206/300][1100/1251]	eta 0:01:30 lr 0.000227	time 0.5001 (0.5990)	loss 3.5985 (3.8018)	grad_norm 3.4620 (5.7634)	mem 5325MB
[2022-04-21 02:41:44 tiny] (main.py 226): INFO Train: [206/300][1200/1251]	eta 0:00:30 lr 0.000227	time 0.5998 (0.5979)	loss 4.7392 (3.8044)	grad_norm 6.6087 (5.7644)	mem 5325MB
[2022-04-21 02:42:06 tiny] (main.py 233): INFO EPOCH 206 training takes 0:12:20
[2022-04-21 02:42:18 tiny] (main.py 273): INFO Test: [0/49]	Time 11.973 (11.973)	Loss 1.5629 (1.5629)	Acc@1 69.238 (69.238)	Acc@5 90.625 (90.625)	Mem 5325MB
[2022-04-21 02:42:37 tiny] (main.py 279): INFO  * Acc@1 69.700 Acc@5 89.610
[2022-04-21 02:42:37 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 69.7%
[2022-04-21 02:42:37 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_206.pth saving......
[2022-04-21 02:42:37 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_206.pth saved !!!
[2022-04-21 02:42:37 tiny] (main.py 148): INFO Max accuracy: 69.70%
[2022-04-21 02:42:49 tiny] (main.py 226): INFO Train: [207/300][0/1251]	eta 4:04:54 lr 0.000227	time 11.7461 (11.7461)	loss 3.5614 (3.5614)	grad_norm 4.9429 (4.9429)	mem 5325MB
[2022-04-21 02:43:50 tiny] (main.py 226): INFO Train: [207/300][100/1251]	eta 0:13:53 lr 0.000226	time 0.5213 (0.7241)	loss 3.8799 (3.8825)	grad_norm 4.2064 (5.8597)	mem 5325MB
[2022-04-21 02:44:49 tiny] (main.py 226): INFO Train: [207/300][200/1251]	eta 0:11:27 lr 0.000226	time 0.6306 (0.6544)	loss 4.0988 (3.8775)	grad_norm 5.5512 (5.9077)	mem 5325MB
[2022-04-21 02:45:47 tiny] (main.py 226): INFO Train: [207/300][300/1251]	eta 0:09:59 lr 0.000226	time 0.5840 (0.6307)	loss 4.0805 (3.8592)	grad_norm 4.9878 (5.7798)	mem 5325MB
[2022-04-21 02:46:46 tiny] (main.py 226): INFO Train: [207/300][400/1251]	eta 0:08:48 lr 0.000225	time 0.5219 (0.6207)	loss 2.4948 (3.8153)	grad_norm 4.2607 (6.1614)	mem 5325MB
[2022-04-21 02:47:44 tiny] (main.py 226): INFO Train: [207/300][500/1251]	eta 0:07:39 lr 0.000225	time 0.7857 (0.6124)	loss 4.1279 (3.8195)	grad_norm 4.1536 (6.0802)	mem 5325MB
[2022-04-21 02:48:43 tiny] (main.py 226): INFO Train: [207/300][600/1251]	eta 0:06:35 lr 0.000225	time 0.5789 (0.6081)	loss 3.4505 (3.8054)	grad_norm 12.8943 (6.0553)	mem 5325MB
[2022-04-21 02:49:41 tiny] (main.py 226): INFO Train: [207/300][700/1251]	eta 0:05:33 lr 0.000224	time 0.6025 (0.6048)	loss 4.6176 (3.8034)	grad_norm 7.2912 (6.0140)	mem 5325MB
[2022-04-21 02:50:40 tiny] (main.py 226): INFO Train: [207/300][800/1251]	eta 0:04:32 lr 0.000224	time 0.5859 (0.6033)	loss 4.3151 (3.8163)	grad_norm 4.7541 (6.0187)	mem 5325MB
[2022-04-21 02:51:39 tiny] (main.py 226): INFO Train: [207/300][900/1251]	eta 0:03:31 lr 0.000224	time 0.6573 (0.6020)	loss 4.0062 (3.8143)	grad_norm 5.6801 (5.9190)	mem 5325MB
[2022-04-21 02:52:39 tiny] (main.py 226): INFO Train: [207/300][1000/1251]	eta 0:02:30 lr 0.000223	time 0.4433 (0.6010)	loss 4.5592 (3.8098)	grad_norm 3.9741 (5.9419)	mem 5325MB
[2022-04-21 02:53:36 tiny] (main.py 226): INFO Train: [207/300][1100/1251]	eta 0:01:30 lr 0.000223	time 0.4824 (0.5990)	loss 2.7284 (3.8106)	grad_norm 4.9730 (5.9132)	mem 5325MB
[2022-04-21 02:54:36 tiny] (main.py 226): INFO Train: [207/300][1200/1251]	eta 0:00:30 lr 0.000223	time 0.5389 (0.5984)	loss 3.9293 (3.8177)	grad_norm 3.7162 (5.9256)	mem 5325MB
[2022-04-21 02:54:57 tiny] (main.py 233): INFO EPOCH 207 training takes 0:12:20
[2022-04-21 02:55:08 tiny] (main.py 273): INFO Test: [0/49]	Time 10.467 (10.467)	Loss 1.6343 (1.6343)	Acc@1 66.699 (66.699)	Acc@5 87.402 (87.402)	Mem 5325MB
[2022-04-21 02:55:28 tiny] (main.py 279): INFO  * Acc@1 69.492 Acc@5 89.348
[2022-04-21 02:55:28 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 69.5%
[2022-04-21 02:55:28 tiny] (main.py 148): INFO Max accuracy: 69.70%
[2022-04-21 02:55:40 tiny] (main.py 226): INFO Train: [208/300][0/1251]	eta 4:13:22 lr 0.000222	time 12.1526 (12.1526)	loss 3.7730 (3.7730)	grad_norm 6.2352 (6.2352)	mem 5325MB
[2022-04-21 02:56:42 tiny] (main.py 226): INFO Train: [208/300][100/1251]	eta 0:13:59 lr 0.000222	time 0.7509 (0.7292)	loss 3.3744 (3.8247)	grad_norm 4.5185 (5.9638)	mem 5325MB
[2022-04-21 02:57:40 tiny] (main.py 226): INFO Train: [208/300][200/1251]	eta 0:11:30 lr 0.000222	time 0.6650 (0.6573)	loss 4.4576 (3.7651)	grad_norm 4.9188 (5.9120)	mem 5325MB
[2022-04-21 02:58:38 tiny] (main.py 226): INFO Train: [208/300][300/1251]	eta 0:09:59 lr 0.000221	time 0.6497 (0.6306)	loss 3.2316 (3.8005)	grad_norm 3.5349 (6.3575)	mem 5325MB
[2022-04-21 02:59:36 tiny] (main.py 226): INFO Train: [208/300][400/1251]	eta 0:08:47 lr 0.000221	time 0.6193 (0.6194)	loss 3.2125 (3.7829)	grad_norm 3.6966 (6.2078)	mem 5325MB
[2022-04-21 03:00:35 tiny] (main.py 226): INFO Train: [208/300][500/1251]	eta 0:07:40 lr 0.000221	time 0.5434 (0.6127)	loss 4.0606 (3.7905)	grad_norm 6.7357 (6.1242)	mem 5325MB
[2022-04-21 03:01:33 tiny] (main.py 226): INFO Train: [208/300][600/1251]	eta 0:06:35 lr 0.000220	time 0.5237 (0.6081)	loss 4.0133 (3.7811)	grad_norm 4.8970 (nan)	mem 5325MB
[2022-04-21 03:02:32 tiny] (main.py 226): INFO Train: [208/300][700/1251]	eta 0:05:33 lr 0.000220	time 0.6046 (0.6046)	loss 3.3322 (3.7846)	grad_norm 4.8801 (nan)	mem 5325MB
[2022-04-21 03:03:31 tiny] (main.py 226): INFO Train: [208/300][800/1251]	eta 0:04:31 lr 0.000220	time 0.5382 (0.6030)	loss 3.8487 (3.7889)	grad_norm 6.8192 (nan)	mem 5325MB
[2022-04-21 03:04:30 tiny] (main.py 226): INFO Train: [208/300][900/1251]	eta 0:03:31 lr 0.000219	time 0.4483 (0.6013)	loss 4.4751 (3.7991)	grad_norm 5.3501 (nan)	mem 5325MB
[2022-04-21 03:05:29 tiny] (main.py 226): INFO Train: [208/300][1000/1251]	eta 0:02:30 lr 0.000219	time 0.3927 (0.6000)	loss 4.0321 (3.8092)	grad_norm 4.9069 (nan)	mem 5325MB
[2022-04-21 03:06:28 tiny] (main.py 226): INFO Train: [208/300][1100/1251]	eta 0:01:30 lr 0.000219	time 0.6544 (0.5991)	loss 4.9312 (3.8064)	grad_norm 5.0390 (nan)	mem 5325MB
[2022-04-21 03:07:26 tiny] (main.py 226): INFO Train: [208/300][1200/1251]	eta 0:00:30 lr 0.000218	time 0.4327 (0.5981)	loss 4.1075 (3.8042)	grad_norm 4.0068 (nan)	mem 5325MB
[2022-04-21 03:07:48 tiny] (main.py 233): INFO EPOCH 208 training takes 0:12:20
[2022-04-21 03:08:00 tiny] (main.py 273): INFO Test: [0/49]	Time 12.177 (12.177)	Loss 1.4794 (1.4794)	Acc@1 70.996 (70.996)	Acc@5 90.723 (90.723)	Mem 5325MB
[2022-04-21 03:08:19 tiny] (main.py 279): INFO  * Acc@1 69.490 Acc@5 89.278
[2022-04-21 03:08:19 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 69.5%
[2022-04-21 03:08:19 tiny] (main.py 148): INFO Max accuracy: 69.70%
[2022-04-21 03:08:31 tiny] (main.py 226): INFO Train: [209/300][0/1251]	eta 4:10:07 lr 0.000218	time 11.9962 (11.9962)	loss 4.1811 (4.1811)	grad_norm 5.1900 (5.1900)	mem 5325MB
[2022-04-21 03:09:33 tiny] (main.py 226): INFO Train: [209/300][100/1251]	eta 0:13:58 lr 0.000218	time 0.5608 (0.7285)	loss 4.7789 (3.7529)	grad_norm 5.4508 (5.5302)	mem 5325MB
[2022-04-21 03:10:31 tiny] (main.py 226): INFO Train: [209/300][200/1251]	eta 0:11:30 lr 0.000218	time 0.7656 (0.6574)	loss 4.1339 (3.7929)	grad_norm 4.6829 (5.5832)	mem 5325MB
[2022-04-21 03:11:30 tiny] (main.py 226): INFO Train: [209/300][300/1251]	eta 0:10:02 lr 0.000217	time 0.5662 (0.6337)	loss 3.5073 (3.8380)	grad_norm 3.5456 (5.5739)	mem 5325MB
[2022-04-21 03:12:29 tiny] (main.py 226): INFO Train: [209/300][400/1251]	eta 0:08:48 lr 0.000217	time 0.6664 (0.6216)	loss 4.3189 (3.8192)	grad_norm 5.5793 (5.7630)	mem 5325MB
[2022-04-21 03:13:27 tiny] (main.py 226): INFO Train: [209/300][500/1251]	eta 0:07:40 lr 0.000217	time 0.4804 (0.6135)	loss 4.5993 (3.8166)	grad_norm 7.9620 (5.8081)	mem 5325MB
[2022-04-21 03:14:26 tiny] (main.py 226): INFO Train: [209/300][600/1251]	eta 0:06:36 lr 0.000216	time 0.8827 (0.6098)	loss 3.3307 (3.8076)	grad_norm 8.4217 (5.8598)	mem 5325MB
[2022-04-21 03:15:24 tiny] (main.py 226): INFO Train: [209/300][700/1251]	eta 0:05:34 lr 0.000216	time 0.6068 (0.6062)	loss 3.3682 (3.8143)	grad_norm 9.5869 (5.9555)	mem 5325MB
[2022-04-21 03:16:23 tiny] (main.py 226): INFO Train: [209/300][800/1251]	eta 0:04:32 lr 0.000216	time 0.6399 (0.6037)	loss 4.6346 (3.8073)	grad_norm 5.2777 (5.9209)	mem 5325MB
[2022-04-21 03:17:22 tiny] (main.py 226): INFO Train: [209/300][900/1251]	eta 0:03:31 lr 0.000215	time 0.5771 (0.6020)	loss 4.1383 (3.8186)	grad_norm 4.7394 (5.9306)	mem 5325MB
[2022-04-21 03:18:21 tiny] (main.py 226): INFO Train: [209/300][1000/1251]	eta 0:02:30 lr 0.000215	time 0.4452 (0.6008)	loss 4.2921 (3.8253)	grad_norm 6.6613 (5.9200)	mem 5325MB
[2022-04-21 03:19:20 tiny] (main.py 226): INFO Train: [209/300][1100/1251]	eta 0:01:30 lr 0.000215	time 0.5661 (0.5997)	loss 3.2565 (3.8266)	grad_norm 3.7666 (5.8928)	mem 5325MB
[2022-04-21 03:20:18 tiny] (main.py 226): INFO Train: [209/300][1200/1251]	eta 0:00:30 lr 0.000214	time 0.5349 (0.5987)	loss 3.3349 (3.8246)	grad_norm 3.4811 (5.9337)	mem 5325MB
[2022-04-21 03:20:40 tiny] (main.py 233): INFO EPOCH 209 training takes 0:12:20
[2022-04-21 03:20:50 tiny] (main.py 273): INFO Test: [0/49]	Time 10.071 (10.071)	Loss 1.5383 (1.5383)	Acc@1 71.387 (71.387)	Acc@5 90.137 (90.137)	Mem 5325MB
[2022-04-21 03:21:11 tiny] (main.py 279): INFO  * Acc@1 69.522 Acc@5 89.196
[2022-04-21 03:21:11 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 69.5%
[2022-04-21 03:21:11 tiny] (main.py 148): INFO Max accuracy: 69.70%
[2022-04-21 03:21:21 tiny] (main.py 226): INFO Train: [210/300][0/1251]	eta 3:25:41 lr 0.000214	time 9.8651 (9.8651)	loss 3.8530 (3.8530)	grad_norm 7.1021 (7.1021)	mem 5325MB
[2022-04-21 03:22:25 tiny] (main.py 226): INFO Train: [210/300][100/1251]	eta 0:14:02 lr 0.000214	time 0.7410 (0.7321)	loss 3.4673 (3.9159)	grad_norm 8.3855 (5.9478)	mem 5325MB
[2022-04-21 03:23:23 tiny] (main.py 226): INFO Train: [210/300][200/1251]	eta 0:11:30 lr 0.000213	time 0.6737 (0.6574)	loss 2.6258 (3.8597)	grad_norm 10.1460 (5.9724)	mem 5325MB
[2022-04-21 03:24:21 tiny] (main.py 226): INFO Train: [210/300][300/1251]	eta 0:10:01 lr 0.000213	time 0.3662 (0.6322)	loss 3.3644 (3.8310)	grad_norm 3.0573 (5.7422)	mem 5325MB
[2022-04-21 03:25:20 tiny] (main.py 226): INFO Train: [210/300][400/1251]	eta 0:08:48 lr 0.000213	time 0.6146 (0.6212)	loss 3.6687 (3.8317)	grad_norm 7.5896 (5.7462)	mem 5325MB
[2022-04-21 03:26:19 tiny] (main.py 226): INFO Train: [210/300][500/1251]	eta 0:07:41 lr 0.000212	time 0.5930 (0.6139)	loss 4.5231 (3.8212)	grad_norm 5.2108 (5.8545)	mem 5325MB
[2022-04-21 03:27:17 tiny] (main.py 226): INFO Train: [210/300][600/1251]	eta 0:06:36 lr 0.000212	time 0.6482 (0.6096)	loss 3.4156 (3.8143)	grad_norm 4.6501 (nan)	mem 5325MB
[2022-04-21 03:28:16 tiny] (main.py 226): INFO Train: [210/300][700/1251]	eta 0:05:33 lr 0.000212	time 0.6248 (0.6060)	loss 3.9065 (3.8039)	grad_norm 5.6669 (nan)	mem 5325MB
[2022-04-21 03:29:15 tiny] (main.py 226): INFO Train: [210/300][800/1251]	eta 0:04:32 lr 0.000211	time 0.9474 (0.6039)	loss 4.2005 (3.7925)	grad_norm 4.5958 (nan)	mem 5325MB
[2022-04-21 03:30:14 tiny] (main.py 226): INFO Train: [210/300][900/1251]	eta 0:03:31 lr 0.000211	time 0.5034 (0.6022)	loss 4.5521 (3.7952)	grad_norm 6.1945 (nan)	mem 5325MB
[2022-04-21 03:31:13 tiny] (main.py 226): INFO Train: [210/300][1000/1251]	eta 0:02:30 lr 0.000211	time 0.7735 (0.6010)	loss 3.6751 (3.7983)	grad_norm 4.3917 (nan)	mem 5325MB
[2022-04-21 03:32:11 tiny] (main.py 226): INFO Train: [210/300][1100/1251]	eta 0:01:30 lr 0.000210	time 0.6729 (0.5995)	loss 4.1045 (3.8020)	grad_norm 3.9237 (nan)	mem 5325MB
[2022-04-21 03:33:10 tiny] (main.py 226): INFO Train: [210/300][1200/1251]	eta 0:00:30 lr 0.000210	time 0.6276 (0.5986)	loss 3.9496 (3.7997)	grad_norm 4.9417 (nan)	mem 5325MB
[2022-04-21 03:33:32 tiny] (main.py 233): INFO EPOCH 210 training takes 0:12:20
[2022-04-21 03:33:44 tiny] (main.py 273): INFO Test: [0/49]	Time 12.307 (12.307)	Loss 1.5107 (1.5107)	Acc@1 71.289 (71.289)	Acc@5 89.258 (89.258)	Mem 5325MB
[2022-04-21 03:34:03 tiny] (main.py 279): INFO  * Acc@1 69.638 Acc@5 89.280
[2022-04-21 03:34:03 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 69.6%
[2022-04-21 03:34:03 tiny] (main.py 148): INFO Max accuracy: 69.70%
[2022-04-21 03:34:14 tiny] (main.py 226): INFO Train: [211/300][0/1251]	eta 4:01:26 lr 0.000210	time 11.5801 (11.5801)	loss 3.0855 (3.0855)	grad_norm 5.4730 (5.4730)	mem 5325MB
[2022-04-21 03:35:17 tiny] (main.py 226): INFO Train: [211/300][100/1251]	eta 0:13:59 lr 0.000210	time 0.5365 (0.7295)	loss 4.2273 (3.7412)	grad_norm 5.1629 (6.1577)	mem 5325MB
[2022-04-21 03:36:15 tiny] (main.py 226): INFO Train: [211/300][200/1251]	eta 0:11:29 lr 0.000209	time 0.6192 (0.6561)	loss 3.4940 (3.7784)	grad_norm 5.2007 (6.1294)	mem 5325MB
[2022-04-21 03:37:13 tiny] (main.py 226): INFO Train: [211/300][300/1251]	eta 0:10:01 lr 0.000209	time 0.5583 (0.6320)	loss 3.9057 (3.7612)	grad_norm 5.9859 (6.2578)	mem 5325MB
[2022-04-21 03:38:12 tiny] (main.py 226): INFO Train: [211/300][400/1251]	eta 0:08:48 lr 0.000209	time 0.4327 (0.6216)	loss 4.4396 (3.7854)	grad_norm 12.8876 (6.2022)	mem 5325MB
[2022-04-21 03:39:11 tiny] (main.py 226): INFO Train: [211/300][500/1251]	eta 0:07:41 lr 0.000208	time 0.5113 (0.6143)	loss 4.1671 (3.7764)	grad_norm 5.5277 (6.1070)	mem 5325MB
[2022-04-21 03:40:10 tiny] (main.py 226): INFO Train: [211/300][600/1251]	eta 0:06:37 lr 0.000208	time 0.7065 (0.6102)	loss 4.0656 (3.7738)	grad_norm 7.9821 (6.1286)	mem 5325MB
[2022-04-21 03:41:08 tiny] (main.py 226): INFO Train: [211/300][700/1251]	eta 0:05:34 lr 0.000208	time 0.7240 (0.6065)	loss 4.6135 (3.7743)	grad_norm 7.8791 (6.0698)	mem 5325MB
[2022-04-21 03:42:07 tiny] (main.py 226): INFO Train: [211/300][800/1251]	eta 0:04:32 lr 0.000207	time 0.4874 (0.6044)	loss 2.8480 (3.7769)	grad_norm 5.2205 (6.1062)	mem 5325MB
[2022-04-21 03:43:06 tiny] (main.py 226): INFO Train: [211/300][900/1251]	eta 0:03:31 lr 0.000207	time 0.5846 (0.6024)	loss 3.6091 (3.7841)	grad_norm 8.2194 (6.1456)	mem 5325MB
[2022-04-21 03:44:05 tiny] (main.py 226): INFO Train: [211/300][1000/1251]	eta 0:02:30 lr 0.000207	time 0.5849 (0.6012)	loss 4.4887 (3.7882)	grad_norm 4.6669 (6.1345)	mem 5325MB
[2022-04-21 03:45:03 tiny] (main.py 226): INFO Train: [211/300][1100/1251]	eta 0:01:30 lr 0.000206	time 0.5227 (0.5995)	loss 4.0881 (3.7972)	grad_norm 6.7706 (6.1251)	mem 5325MB
[2022-04-21 03:46:02 tiny] (main.py 226): INFO Train: [211/300][1200/1251]	eta 0:00:30 lr 0.000206	time 0.7216 (0.5989)	loss 3.5521 (3.7969)	grad_norm 8.7198 (6.1348)	mem 5325MB
[2022-04-21 03:46:25 tiny] (main.py 233): INFO EPOCH 211 training takes 0:12:22
[2022-04-21 03:46:36 tiny] (main.py 273): INFO Test: [0/49]	Time 10.571 (10.571)	Loss 1.5169 (1.5169)	Acc@1 70.605 (70.605)	Acc@5 90.625 (90.625)	Mem 5325MB
[2022-04-21 03:46:56 tiny] (main.py 279): INFO  * Acc@1 69.462 Acc@5 89.244
[2022-04-21 03:46:56 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 69.5%
[2022-04-21 03:46:56 tiny] (main.py 148): INFO Max accuracy: 69.70%
[2022-04-21 03:47:08 tiny] (main.py 226): INFO Train: [212/300][0/1251]	eta 3:58:26 lr 0.000206	time 11.4361 (11.4361)	loss 4.0361 (4.0361)	grad_norm 5.2118 (5.2118)	mem 5325MB
[2022-04-21 03:48:10 tiny] (main.py 226): INFO Train: [212/300][100/1251]	eta 0:13:56 lr 0.000205	time 0.7630 (0.7268)	loss 3.1945 (3.8044)	grad_norm 4.2047 (5.5164)	mem 5325MB
[2022-04-21 03:49:08 tiny] (main.py 226): INFO Train: [212/300][200/1251]	eta 0:11:28 lr 0.000205	time 0.6442 (0.6551)	loss 3.9959 (3.7911)	grad_norm 4.6148 (5.9079)	mem 5325MB
[2022-04-21 03:50:06 tiny] (main.py 226): INFO Train: [212/300][300/1251]	eta 0:10:00 lr 0.000205	time 0.4902 (0.6312)	loss 3.6618 (3.7859)	grad_norm 3.9157 (5.9310)	mem 5325MB
[2022-04-21 03:51:05 tiny] (main.py 226): INFO Train: [212/300][400/1251]	eta 0:08:47 lr 0.000204	time 0.5805 (0.6200)	loss 3.5276 (3.7754)	grad_norm 4.5557 (5.9759)	mem 5325MB
[2022-04-21 03:52:03 tiny] (main.py 226): INFO Train: [212/300][500/1251]	eta 0:07:39 lr 0.000204	time 0.7624 (0.6125)	loss 3.6313 (3.7727)	grad_norm 6.2487 (nan)	mem 5325MB
[2022-04-21 03:53:02 tiny] (main.py 226): INFO Train: [212/300][600/1251]	eta 0:06:36 lr 0.000204	time 0.5487 (0.6085)	loss 3.6606 (3.7708)	grad_norm 3.8959 (nan)	mem 5325MB
[2022-04-21 03:54:01 tiny] (main.py 226): INFO Train: [212/300][700/1251]	eta 0:05:33 lr 0.000203	time 0.5802 (0.6055)	loss 3.8449 (3.7891)	grad_norm 11.6921 (nan)	mem 5325MB
[2022-04-21 03:55:00 tiny] (main.py 226): INFO Train: [212/300][800/1251]	eta 0:04:32 lr 0.000203	time 0.5225 (0.6038)	loss 4.6811 (3.7914)	grad_norm 5.3574 (nan)	mem 5325MB
[2022-04-21 03:55:59 tiny] (main.py 226): INFO Train: [212/300][900/1251]	eta 0:03:31 lr 0.000203	time 0.6024 (0.6020)	loss 2.9866 (3.7873)	grad_norm 5.9428 (nan)	mem 5325MB
[2022-04-21 03:56:57 tiny] (main.py 226): INFO Train: [212/300][1000/1251]	eta 0:02:30 lr 0.000202	time 0.6092 (0.6006)	loss 4.1168 (3.7953)	grad_norm 3.8325 (nan)	mem 5325MB
[2022-04-21 03:57:56 tiny] (main.py 226): INFO Train: [212/300][1100/1251]	eta 0:01:30 lr 0.000202	time 0.5191 (0.5992)	loss 3.9455 (3.7897)	grad_norm 6.1335 (nan)	mem 5325MB
[2022-04-21 03:58:55 tiny] (main.py 226): INFO Train: [212/300][1200/1251]	eta 0:00:30 lr 0.000202	time 0.5066 (0.5985)	loss 2.6809 (3.7883)	grad_norm 4.5217 (nan)	mem 5325MB
[2022-04-21 03:59:17 tiny] (main.py 233): INFO EPOCH 212 training takes 0:12:20
[2022-04-21 03:59:29 tiny] (main.py 273): INFO Test: [0/49]	Time 11.785 (11.785)	Loss 1.4874 (1.4874)	Acc@1 70.020 (70.020)	Acc@5 89.941 (89.941)	Mem 5325MB
[2022-04-21 03:59:48 tiny] (main.py 279): INFO  * Acc@1 69.828 Acc@5 89.564
[2022-04-21 03:59:48 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 69.8%
[2022-04-21 03:59:48 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_212.pth saving......
[2022-04-21 03:59:48 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_212.pth saved !!!
[2022-04-21 03:59:48 tiny] (main.py 148): INFO Max accuracy: 69.83%
[2022-04-21 03:59:59 tiny] (main.py 226): INFO Train: [213/300][0/1251]	eta 3:39:54 lr 0.000202	time 10.5470 (10.5470)	loss 3.7828 (3.7828)	grad_norm 9.1643 (9.1643)	mem 5325MB
[2022-04-21 04:01:02 tiny] (main.py 226): INFO Train: [213/300][100/1251]	eta 0:14:04 lr 0.000201	time 0.5783 (0.7333)	loss 3.3077 (3.8849)	grad_norm 5.4200 (5.9996)	mem 5325MB
[2022-04-21 04:02:00 tiny] (main.py 226): INFO Train: [213/300][200/1251]	eta 0:11:32 lr 0.000201	time 0.5853 (0.6589)	loss 2.8869 (3.8582)	grad_norm 4.9740 (5.8939)	mem 5325MB
[2022-04-21 04:02:59 tiny] (main.py 226): INFO Train: [213/300][300/1251]	eta 0:10:02 lr 0.000201	time 0.4327 (0.6331)	loss 2.8484 (3.8557)	grad_norm 5.6080 (5.9383)	mem 5325MB
[2022-04-21 04:03:58 tiny] (main.py 226): INFO Train: [213/300][400/1251]	eta 0:08:50 lr 0.000200	time 0.6626 (0.6234)	loss 4.0241 (3.8259)	grad_norm 3.7322 (5.9295)	mem 5325MB
[2022-04-21 04:04:56 tiny] (main.py 226): INFO Train: [213/300][500/1251]	eta 0:07:41 lr 0.000200	time 0.6750 (0.6150)	loss 3.9038 (3.8188)	grad_norm 3.9822 (5.9157)	mem 5325MB
[2022-04-21 04:05:54 tiny] (main.py 226): INFO Train: [213/300][600/1251]	eta 0:06:36 lr 0.000200	time 0.4587 (0.6096)	loss 4.2673 (3.8011)	grad_norm 4.8474 (5.9034)	mem 5325MB
[2022-04-21 04:06:54 tiny] (main.py 226): INFO Train: [213/300][700/1251]	eta 0:05:34 lr 0.000199	time 0.5559 (0.6071)	loss 3.0797 (3.8045)	grad_norm 5.4385 (6.0957)	mem 5325MB
[2022-04-21 04:07:52 tiny] (main.py 226): INFO Train: [213/300][800/1251]	eta 0:04:32 lr 0.000199	time 0.5544 (0.6047)	loss 3.9424 (3.7995)	grad_norm 4.9254 (6.1074)	mem 5325MB
[2022-04-21 04:08:51 tiny] (main.py 226): INFO Train: [213/300][900/1251]	eta 0:03:31 lr 0.000199	time 0.5670 (0.6030)	loss 3.7955 (3.8027)	grad_norm 4.9390 (6.0499)	mem 5325MB
[2022-04-21 04:09:50 tiny] (main.py 226): INFO Train: [213/300][1000/1251]	eta 0:02:30 lr 0.000198	time 0.7435 (0.6014)	loss 3.7937 (3.8023)	grad_norm 3.2747 (5.9462)	mem 5325MB
[2022-04-21 04:10:49 tiny] (main.py 226): INFO Train: [213/300][1100/1251]	eta 0:01:30 lr 0.000198	time 0.5203 (0.6001)	loss 4.0585 (3.8029)	grad_norm 4.4551 (5.9889)	mem 5325MB
[2022-04-21 04:11:48 tiny] (main.py 226): INFO Train: [213/300][1200/1251]	eta 0:00:30 lr 0.000198	time 0.6778 (0.5996)	loss 3.3294 (3.8007)	grad_norm 5.0703 (6.0358)	mem 5325MB
[2022-04-21 04:12:10 tiny] (main.py 233): INFO EPOCH 213 training takes 0:12:22
[2022-04-21 04:12:21 tiny] (main.py 273): INFO Test: [0/49]	Time 10.896 (10.896)	Loss 1.5399 (1.5399)	Acc@1 68.066 (68.066)	Acc@5 90.234 (90.234)	Mem 5325MB
[2022-04-21 04:12:41 tiny] (main.py 279): INFO  * Acc@1 69.974 Acc@5 89.688
[2022-04-21 04:12:41 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 70.0%
[2022-04-21 04:12:41 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_213.pth saving......
[2022-04-21 04:12:41 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_213.pth saved !!!
[2022-04-21 04:12:41 tiny] (main.py 148): INFO Max accuracy: 69.97%
[2022-04-21 04:12:52 tiny] (main.py 226): INFO Train: [214/300][0/1251]	eta 3:42:32 lr 0.000198	time 10.6732 (10.6732)	loss 3.1188 (3.1188)	grad_norm 4.1618 (4.1618)	mem 5325MB
[2022-04-21 04:13:55 tiny] (main.py 226): INFO Train: [214/300][100/1251]	eta 0:14:00 lr 0.000197	time 0.6101 (0.7306)	loss 4.1200 (3.8049)	grad_norm 5.3616 (5.8807)	mem 5325MB
[2022-04-21 04:14:54 tiny] (main.py 226): INFO Train: [214/300][200/1251]	eta 0:11:31 lr 0.000197	time 0.6929 (0.6579)	loss 3.8865 (3.8090)	grad_norm 4.2805 (6.0375)	mem 5325MB
[2022-04-21 04:15:52 tiny] (main.py 226): INFO Train: [214/300][300/1251]	eta 0:10:02 lr 0.000197	time 0.6541 (0.6338)	loss 3.0342 (3.8317)	grad_norm 3.9726 (6.1165)	mem 5325MB
[2022-04-21 04:16:51 tiny] (main.py 226): INFO Train: [214/300][400/1251]	eta 0:08:48 lr 0.000196	time 0.7276 (0.6216)	loss 2.9217 (3.7993)	grad_norm 5.7059 (6.0489)	mem 5325MB
[2022-04-21 04:17:49 tiny] (main.py 226): INFO Train: [214/300][500/1251]	eta 0:07:41 lr 0.000196	time 0.3841 (0.6141)	loss 4.0206 (3.7819)	grad_norm 8.6268 (6.0383)	mem 5325MB
[2022-04-21 04:18:48 tiny] (main.py 226): INFO Train: [214/300][600/1251]	eta 0:06:37 lr 0.000196	time 0.4544 (0.6099)	loss 3.1925 (3.7864)	grad_norm 3.5908 (6.0231)	mem 5325MB
[2022-04-21 04:19:47 tiny] (main.py 226): INFO Train: [214/300][700/1251]	eta 0:05:34 lr 0.000195	time 0.5186 (0.6069)	loss 4.3269 (3.7845)	grad_norm 8.8086 (6.1024)	mem 5325MB
[2022-04-21 04:20:46 tiny] (main.py 226): INFO Train: [214/300][800/1251]	eta 0:04:32 lr 0.000195	time 0.6270 (0.6047)	loss 2.7347 (3.7849)	grad_norm 4.7077 (6.0802)	mem 5325MB
[2022-04-21 04:21:44 tiny] (main.py 226): INFO Train: [214/300][900/1251]	eta 0:03:31 lr 0.000195	time 0.7817 (0.6029)	loss 4.6813 (3.7764)	grad_norm 5.9820 (6.0547)	mem 5325MB
[2022-04-21 04:22:43 tiny] (main.py 226): INFO Train: [214/300][1000/1251]	eta 0:02:30 lr 0.000194	time 0.5274 (0.6015)	loss 4.3237 (3.7701)	grad_norm 5.4039 (6.0407)	mem 5325MB
[2022-04-21 04:23:43 tiny] (main.py 226): INFO Train: [214/300][1100/1251]	eta 0:01:30 lr 0.000194	time 0.6964 (0.6007)	loss 3.7995 (3.7738)	grad_norm 6.6185 (6.0577)	mem 5325MB
[2022-04-21 04:24:41 tiny] (main.py 226): INFO Train: [214/300][1200/1251]	eta 0:00:30 lr 0.000194	time 0.4154 (0.5991)	loss 3.0473 (3.7620)	grad_norm 5.9415 (6.1050)	mem 5325MB
[2022-04-21 04:25:03 tiny] (main.py 233): INFO EPOCH 214 training takes 0:12:21
[2022-04-21 04:25:15 tiny] (main.py 273): INFO Test: [0/49]	Time 12.071 (12.071)	Loss 1.4809 (1.4809)	Acc@1 69.922 (69.922)	Acc@5 89.160 (89.160)	Mem 5325MB
[2022-04-21 04:25:34 tiny] (main.py 279): INFO  * Acc@1 69.678 Acc@5 89.464
[2022-04-21 04:25:34 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 69.7%
[2022-04-21 04:25:34 tiny] (main.py 148): INFO Max accuracy: 69.97%
[2022-04-21 04:25:45 tiny] (main.py 226): INFO Train: [215/300][0/1251]	eta 3:44:28 lr 0.000193	time 10.7658 (10.7658)	loss 4.1311 (4.1311)	grad_norm 6.3529 (6.3529)	mem 5325MB
[2022-04-21 04:26:47 tiny] (main.py 226): INFO Train: [215/300][100/1251]	eta 0:13:56 lr 0.000193	time 0.5134 (0.7265)	loss 3.7998 (3.8262)	grad_norm 5.9434 (6.0663)	mem 5325MB
[2022-04-21 04:27:46 tiny] (main.py 226): INFO Train: [215/300][200/1251]	eta 0:11:28 lr 0.000193	time 0.3649 (0.6550)	loss 3.8664 (3.8331)	grad_norm 4.4860 (5.8740)	mem 5325MB
[2022-04-21 04:28:44 tiny] (main.py 226): INFO Train: [215/300][300/1251]	eta 0:10:01 lr 0.000193	time 0.4303 (0.6323)	loss 4.1383 (3.8067)	grad_norm 6.9242 (5.9190)	mem 5325MB
[2022-04-21 04:29:43 tiny] (main.py 226): INFO Train: [215/300][400/1251]	eta 0:08:49 lr 0.000192	time 0.4417 (0.6218)	loss 2.7855 (3.8184)	grad_norm 5.1756 (5.9834)	mem 5325MB
[2022-04-21 04:30:42 tiny] (main.py 226): INFO Train: [215/300][500/1251]	eta 0:07:41 lr 0.000192	time 0.5072 (0.6150)	loss 4.2008 (3.8125)	grad_norm 6.4221 (6.0336)	mem 5325MB
[2022-04-21 04:31:41 tiny] (main.py 226): INFO Train: [215/300][600/1251]	eta 0:06:37 lr 0.000192	time 0.5894 (0.6100)	loss 3.9196 (3.8194)	grad_norm 5.5086 (6.0776)	mem 5325MB
[2022-04-21 04:32:39 tiny] (main.py 226): INFO Train: [215/300][700/1251]	eta 0:05:34 lr 0.000191	time 0.5768 (0.6069)	loss 4.5500 (3.8197)	grad_norm 6.0580 (nan)	mem 5325MB
[2022-04-21 04:33:38 tiny] (main.py 226): INFO Train: [215/300][800/1251]	eta 0:04:32 lr 0.000191	time 0.5731 (0.6043)	loss 2.3550 (3.8073)	grad_norm 4.8579 (nan)	mem 5325MB
[2022-04-21 04:34:37 tiny] (main.py 226): INFO Train: [215/300][900/1251]	eta 0:03:31 lr 0.000191	time 0.6054 (0.6025)	loss 2.5740 (3.7982)	grad_norm 9.0055 (nan)	mem 5325MB
[2022-04-21 04:35:36 tiny] (main.py 226): INFO Train: [215/300][1000/1251]	eta 0:02:30 lr 0.000190	time 0.4122 (0.6011)	loss 4.5102 (3.8036)	grad_norm 3.7006 (nan)	mem 5325MB
[2022-04-21 04:36:35 tiny] (main.py 226): INFO Train: [215/300][1100/1251]	eta 0:01:30 lr 0.000190	time 0.6888 (0.6002)	loss 4.0994 (3.7886)	grad_norm 3.3852 (nan)	mem 5325MB
[2022-04-21 04:37:34 tiny] (main.py 226): INFO Train: [215/300][1200/1251]	eta 0:00:30 lr 0.000190	time 0.4712 (0.5992)	loss 4.5624 (3.7826)	grad_norm 7.2076 (nan)	mem 5325MB
[2022-04-21 04:37:56 tiny] (main.py 233): INFO EPOCH 215 training takes 0:12:21
[2022-04-21 04:38:08 tiny] (main.py 273): INFO Test: [0/49]	Time 11.696 (11.696)	Loss 1.6457 (1.6457)	Acc@1 69.141 (69.141)	Acc@5 88.672 (88.672)	Mem 5325MB
[2022-04-21 04:38:26 tiny] (main.py 279): INFO  * Acc@1 69.708 Acc@5 89.436
[2022-04-21 04:38:26 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 69.7%
[2022-04-21 04:38:26 tiny] (main.py 148): INFO Max accuracy: 69.97%
[2022-04-21 04:38:38 tiny] (main.py 226): INFO Train: [216/300][0/1251]	eta 4:11:30 lr 0.000189	time 12.0629 (12.0629)	loss 4.4603 (4.4603)	grad_norm 6.2436 (6.2436)	mem 5325MB
[2022-04-21 04:39:40 tiny] (main.py 226): INFO Train: [216/300][100/1251]	eta 0:14:00 lr 0.000189	time 0.6740 (0.7298)	loss 3.7172 (3.8003)	grad_norm 5.9625 (nan)	mem 5325MB
[2022-04-21 04:40:39 tiny] (main.py 226): INFO Train: [216/300][200/1251]	eta 0:11:31 lr 0.000189	time 0.4702 (0.6582)	loss 3.0210 (3.7575)	grad_norm 5.2921 (nan)	mem 5325MB
[2022-04-21 04:41:37 tiny] (main.py 226): INFO Train: [216/300][300/1251]	eta 0:10:02 lr 0.000189	time 0.4061 (0.6331)	loss 4.5763 (3.7890)	grad_norm 4.8075 (nan)	mem 5325MB
[2022-04-21 04:42:35 tiny] (main.py 226): INFO Train: [216/300][400/1251]	eta 0:08:48 lr 0.000188	time 0.3849 (0.6212)	loss 4.0469 (3.8076)	grad_norm 6.6987 (nan)	mem 5325MB
[2022-04-21 04:43:34 tiny] (main.py 226): INFO Train: [216/300][500/1251]	eta 0:07:40 lr 0.000188	time 0.5914 (0.6137)	loss 4.1798 (3.7941)	grad_norm 5.0043 (nan)	mem 5325MB
[2022-04-21 04:44:33 tiny] (main.py 226): INFO Train: [216/300][600/1251]	eta 0:06:36 lr 0.000188	time 0.3777 (0.6096)	loss 4.0070 (3.7893)	grad_norm 6.0186 (nan)	mem 5325MB
[2022-04-21 04:45:31 tiny] (main.py 226): INFO Train: [216/300][700/1251]	eta 0:05:34 lr 0.000187	time 0.5074 (0.6063)	loss 4.1584 (3.8044)	grad_norm 17.2517 (nan)	mem 5325MB
[2022-04-21 04:46:30 tiny] (main.py 226): INFO Train: [216/300][800/1251]	eta 0:04:32 lr 0.000187	time 0.6185 (0.6039)	loss 4.0696 (3.8145)	grad_norm 5.4010 (nan)	mem 5325MB
[2022-04-21 04:47:29 tiny] (main.py 226): INFO Train: [216/300][900/1251]	eta 0:03:31 lr 0.000187	time 0.5319 (0.6019)	loss 2.6071 (3.8148)	grad_norm 5.4855 (nan)	mem 5325MB
[2022-04-21 04:48:27 tiny] (main.py 226): INFO Train: [216/300][1000/1251]	eta 0:02:30 lr 0.000186	time 0.5442 (0.6005)	loss 4.1717 (3.7991)	grad_norm 4.0003 (nan)	mem 5325MB
[2022-04-21 04:49:27 tiny] (main.py 226): INFO Train: [216/300][1100/1251]	eta 0:01:30 lr 0.000186	time 0.4853 (0.6001)	loss 4.5505 (3.7972)	grad_norm 9.7767 (nan)	mem 5325MB
[2022-04-21 04:50:26 tiny] (main.py 226): INFO Train: [216/300][1200/1251]	eta 0:00:30 lr 0.000186	time 0.5912 (0.5989)	loss 3.5114 (3.7961)	grad_norm 6.5472 (nan)	mem 5325MB
[2022-04-21 04:50:48 tiny] (main.py 233): INFO EPOCH 216 training takes 0:12:21
[2022-04-21 04:50:59 tiny] (main.py 273): INFO Test: [0/49]	Time 11.073 (11.073)	Loss 1.5143 (1.5143)	Acc@1 69.531 (69.531)	Acc@5 88.770 (88.770)	Mem 5325MB
[2022-04-21 04:51:19 tiny] (main.py 279): INFO  * Acc@1 70.080 Acc@5 89.524
[2022-04-21 04:51:19 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 70.1%
[2022-04-21 04:51:19 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_216.pth saving......
[2022-04-21 04:51:19 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_216.pth saved !!!
[2022-04-21 04:51:19 tiny] (main.py 148): INFO Max accuracy: 70.08%
[2022-04-21 04:51:30 tiny] (main.py 226): INFO Train: [217/300][0/1251]	eta 3:54:29 lr 0.000185	time 11.2464 (11.2464)	loss 4.5663 (4.5663)	grad_norm 6.1467 (6.1467)	mem 5325MB
[2022-04-21 04:52:32 tiny] (main.py 226): INFO Train: [217/300][100/1251]	eta 0:13:49 lr 0.000185	time 0.5374 (0.7208)	loss 3.5716 (3.7278)	grad_norm 15.3184 (7.3153)	mem 5325MB
[2022-04-21 04:53:31 tiny] (main.py 226): INFO Train: [217/300][200/1251]	eta 0:11:30 lr 0.000185	time 0.6704 (0.6565)	loss 4.1140 (3.7656)	grad_norm 6.1003 (6.6349)	mem 5325MB
[2022-04-21 04:54:29 tiny] (main.py 226): INFO Train: [217/300][300/1251]	eta 0:10:01 lr 0.000185	time 0.5780 (0.6322)	loss 4.1887 (3.7812)	grad_norm 18.8848 (6.6164)	mem 5325MB
[2022-04-21 04:55:29 tiny] (main.py 226): INFO Train: [217/300][400/1251]	eta 0:08:49 lr 0.000184	time 0.6911 (0.6222)	loss 4.0931 (3.7688)	grad_norm 5.9466 (6.5022)	mem 5325MB
[2022-04-21 04:56:27 tiny] (main.py 226): INFO Train: [217/300][500/1251]	eta 0:07:41 lr 0.000184	time 0.6502 (0.6152)	loss 4.7217 (3.7625)	grad_norm 11.7517 (6.3766)	mem 5325MB
[2022-04-21 04:57:26 tiny] (main.py 226): INFO Train: [217/300][600/1251]	eta 0:06:37 lr 0.000184	time 0.4043 (0.6100)	loss 4.3452 (3.7727)	grad_norm 4.9292 (6.4229)	mem 5325MB
[2022-04-21 04:58:24 tiny] (main.py 226): INFO Train: [217/300][700/1251]	eta 0:05:34 lr 0.000183	time 0.6784 (0.6068)	loss 3.6097 (3.7751)	grad_norm 5.8057 (6.4004)	mem 5325MB
[2022-04-21 04:59:23 tiny] (main.py 226): INFO Train: [217/300][800/1251]	eta 0:04:32 lr 0.000183	time 0.4843 (0.6045)	loss 3.3037 (3.7743)	grad_norm 8.2822 (6.3738)	mem 5325MB
[2022-04-21 05:00:22 tiny] (main.py 226): INFO Train: [217/300][900/1251]	eta 0:03:31 lr 0.000183	time 0.7038 (0.6030)	loss 4.1874 (3.7863)	grad_norm 9.5993 (6.3926)	mem 5325MB
[2022-04-21 05:01:21 tiny] (main.py 226): INFO Train: [217/300][1000/1251]	eta 0:02:31 lr 0.000182	time 0.7281 (0.6017)	loss 3.6526 (3.7736)	grad_norm 5.3592 (6.4149)	mem 5325MB
[2022-04-21 05:02:20 tiny] (main.py 226): INFO Train: [217/300][1100/1251]	eta 0:01:30 lr 0.000182	time 0.5080 (0.6004)	loss 3.5121 (3.7713)	grad_norm 4.7752 (6.3818)	mem 5325MB
[2022-04-21 05:03:19 tiny] (main.py 226): INFO Train: [217/300][1200/1251]	eta 0:00:30 lr 0.000182	time 0.5857 (0.5995)	loss 3.0918 (3.7778)	grad_norm 4.9411 (6.3502)	mem 5325MB
[2022-04-21 05:03:41 tiny] (main.py 233): INFO EPOCH 217 training takes 0:12:21
[2022-04-21 05:03:53 tiny] (main.py 273): INFO Test: [0/49]	Time 12.493 (12.493)	Loss 1.5219 (1.5219)	Acc@1 70.801 (70.801)	Acc@5 88.672 (88.672)	Mem 5325MB
[2022-04-21 05:04:12 tiny] (main.py 279): INFO  * Acc@1 69.944 Acc@5 89.578
[2022-04-21 05:04:12 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 69.9%
[2022-04-21 05:04:12 tiny] (main.py 148): INFO Max accuracy: 70.08%
[2022-04-21 05:04:23 tiny] (main.py 226): INFO Train: [218/300][0/1251]	eta 3:43:55 lr 0.000182	time 10.7397 (10.7397)	loss 2.7125 (2.7125)	grad_norm 9.0709 (9.0709)	mem 5325MB
[2022-04-21 05:05:26 tiny] (main.py 226): INFO Train: [218/300][100/1251]	eta 0:14:00 lr 0.000181	time 0.5509 (0.7302)	loss 2.9650 (3.6866)	grad_norm 5.6217 (6.0495)	mem 5325MB
[2022-04-21 05:06:24 tiny] (main.py 226): INFO Train: [218/300][200/1251]	eta 0:11:31 lr 0.000181	time 0.8101 (0.6579)	loss 3.3543 (3.7178)	grad_norm 4.3334 (5.9943)	mem 5325MB
[2022-04-21 05:07:22 tiny] (main.py 226): INFO Train: [218/300][300/1251]	eta 0:10:01 lr 0.000181	time 0.5296 (0.6329)	loss 4.1554 (3.7257)	grad_norm 17.7748 (6.2630)	mem 5325MB
[2022-04-21 05:08:21 tiny] (main.py 226): INFO Train: [218/300][400/1251]	eta 0:08:49 lr 0.000180	time 0.6251 (0.6223)	loss 4.1335 (3.7391)	grad_norm 5.7963 (6.3082)	mem 5325MB
[2022-04-21 05:09:20 tiny] (main.py 226): INFO Train: [218/300][500/1251]	eta 0:07:42 lr 0.000180	time 0.5441 (0.6156)	loss 4.7514 (3.7584)	grad_norm 5.0561 (6.3673)	mem 5325MB
[2022-04-21 05:10:19 tiny] (main.py 226): INFO Train: [218/300][600/1251]	eta 0:06:37 lr 0.000180	time 0.6394 (0.6110)	loss 4.2959 (3.7586)	grad_norm 6.7557 (6.3945)	mem 5325MB
[2022-04-21 05:11:18 tiny] (main.py 226): INFO Train: [218/300][700/1251]	eta 0:05:34 lr 0.000179	time 0.4409 (0.6077)	loss 4.5520 (3.7620)	grad_norm 5.3947 (6.4013)	mem 5325MB
[2022-04-21 05:12:17 tiny] (main.py 226): INFO Train: [218/300][800/1251]	eta 0:04:33 lr 0.000179	time 0.5861 (0.6054)	loss 3.6378 (3.7512)	grad_norm 4.3415 (6.3403)	mem 5325MB
[2022-04-21 05:13:15 tiny] (main.py 226): INFO Train: [218/300][900/1251]	eta 0:03:31 lr 0.000179	time 0.5065 (0.6032)	loss 3.2274 (3.7586)	grad_norm 4.1550 (6.4210)	mem 5325MB
[2022-04-21 05:14:14 tiny] (main.py 226): INFO Train: [218/300][1000/1251]	eta 0:02:31 lr 0.000178	time 0.4993 (0.6017)	loss 3.8889 (3.7578)	grad_norm 5.5424 (6.4175)	mem 5325MB
[2022-04-21 05:15:13 tiny] (main.py 226): INFO Train: [218/300][1100/1251]	eta 0:01:30 lr 0.000178	time 0.6817 (0.6006)	loss 4.3151 (3.7574)	grad_norm 4.8134 (6.3807)	mem 5325MB
[2022-04-21 05:16:12 tiny] (main.py 226): INFO Train: [218/300][1200/1251]	eta 0:00:30 lr 0.000178	time 0.6153 (0.5995)	loss 3.4995 (3.7549)	grad_norm 6.4961 (6.3916)	mem 5325MB
[2022-04-21 05:16:34 tiny] (main.py 233): INFO EPOCH 218 training takes 0:12:22
[2022-04-21 05:16:45 tiny] (main.py 273): INFO Test: [0/49]	Time 11.075 (11.075)	Loss 1.4756 (1.4756)	Acc@1 70.703 (70.703)	Acc@5 89.258 (89.258)	Mem 5325MB
[2022-04-21 05:17:05 tiny] (main.py 279): INFO  * Acc@1 70.118 Acc@5 89.680
[2022-04-21 05:17:05 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 70.1%
[2022-04-21 05:17:05 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_218.pth saving......
[2022-04-21 05:17:05 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_218.pth saved !!!
[2022-04-21 05:17:05 tiny] (main.py 148): INFO Max accuracy: 70.12%
[2022-04-21 05:17:17 tiny] (main.py 226): INFO Train: [219/300][0/1251]	eta 4:08:15 lr 0.000178	time 11.9069 (11.9069)	loss 4.1699 (4.1699)	grad_norm 11.6092 (11.6092)	mem 5325MB
[2022-04-21 05:18:19 tiny] (main.py 226): INFO Train: [219/300][100/1251]	eta 0:13:57 lr 0.000177	time 0.6456 (0.7279)	loss 3.3825 (3.7936)	grad_norm 9.6037 (6.2614)	mem 5325MB
[2022-04-21 05:19:17 tiny] (main.py 226): INFO Train: [219/300][200/1251]	eta 0:11:30 lr 0.000177	time 0.5862 (0.6566)	loss 4.3743 (3.7592)	grad_norm 5.2957 (6.3847)	mem 5325MB
[2022-04-21 05:20:16 tiny] (main.py 226): INFO Train: [219/300][300/1251]	eta 0:10:03 lr 0.000177	time 0.6766 (0.6343)	loss 3.5161 (3.7546)	grad_norm 4.7892 (nan)	mem 5325MB
[2022-04-21 05:21:15 tiny] (main.py 226): INFO Train: [219/300][400/1251]	eta 0:08:49 lr 0.000176	time 0.5341 (0.6223)	loss 4.0922 (3.7476)	grad_norm 4.8105 (nan)	mem 5325MB
[2022-04-21 05:22:13 tiny] (main.py 226): INFO Train: [219/300][500/1251]	eta 0:07:41 lr 0.000176	time 0.4775 (0.6143)	loss 4.5389 (3.7391)	grad_norm 5.6043 (nan)	mem 5325MB
[2022-04-21 05:23:12 tiny] (main.py 226): INFO Train: [219/300][600/1251]	eta 0:06:37 lr 0.000176	time 0.5765 (0.6107)	loss 3.8627 (3.7555)	grad_norm 3.8815 (nan)	mem 5325MB
[2022-04-21 05:24:11 tiny] (main.py 226): INFO Train: [219/300][700/1251]	eta 0:05:34 lr 0.000175	time 0.4374 (0.6074)	loss 3.8995 (3.7595)	grad_norm 10.3944 (nan)	mem 5325MB
[2022-04-21 05:25:10 tiny] (main.py 226): INFO Train: [219/300][800/1251]	eta 0:04:33 lr 0.000175	time 0.6805 (0.6054)	loss 2.5572 (3.7753)	grad_norm 4.6295 (nan)	mem 5325MB
[2022-04-21 05:26:09 tiny] (main.py 226): INFO Train: [219/300][900/1251]	eta 0:03:31 lr 0.000175	time 0.5458 (0.6033)	loss 3.1513 (3.7785)	grad_norm 4.9405 (nan)	mem 5325MB
[2022-04-21 05:27:08 tiny] (main.py 226): INFO Train: [219/300][1000/1251]	eta 0:02:31 lr 0.000175	time 0.5558 (0.6018)	loss 3.4053 (3.7769)	grad_norm 7.4222 (nan)	mem 5325MB
[2022-04-21 05:28:06 tiny] (main.py 226): INFO Train: [219/300][1100/1251]	eta 0:01:30 lr 0.000174	time 0.5073 (0.6005)	loss 4.4184 (3.7721)	grad_norm 6.4769 (nan)	mem 5325MB
[2022-04-21 05:29:05 tiny] (main.py 226): INFO Train: [219/300][1200/1251]	eta 0:00:30 lr 0.000174	time 0.7310 (0.5994)	loss 3.8686 (3.7681)	grad_norm 7.1842 (nan)	mem 5325MB
[2022-04-21 05:29:27 tiny] (main.py 233): INFO EPOCH 219 training takes 0:12:22
[2022-04-21 05:29:39 tiny] (main.py 273): INFO Test: [0/49]	Time 11.699 (11.699)	Loss 1.6421 (1.6421)	Acc@1 67.090 (67.090)	Acc@5 88.086 (88.086)	Mem 5325MB
[2022-04-21 05:29:58 tiny] (main.py 279): INFO  * Acc@1 70.034 Acc@5 89.638
[2022-04-21 05:29:58 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 70.0%
[2022-04-21 05:29:58 tiny] (main.py 148): INFO Max accuracy: 70.12%
[2022-04-21 05:30:10 tiny] (main.py 226): INFO Train: [220/300][0/1251]	eta 4:14:27 lr 0.000174	time 12.2042 (12.2042)	loss 4.0417 (4.0417)	grad_norm 6.6682 (6.6682)	mem 5325MB
[2022-04-21 05:31:12 tiny] (main.py 226): INFO Train: [220/300][100/1251]	eta 0:14:05 lr 0.000173	time 0.6431 (0.7342)	loss 4.2397 (3.7510)	grad_norm 10.9171 (6.0842)	mem 5325MB
[2022-04-21 05:32:11 tiny] (main.py 226): INFO Train: [220/300][200/1251]	eta 0:11:32 lr 0.000173	time 0.5812 (0.6585)	loss 4.4106 (3.7444)	grad_norm 9.0516 (6.0946)	mem 5325MB
[2022-04-21 05:33:09 tiny] (main.py 226): INFO Train: [220/300][300/1251]	eta 0:10:02 lr 0.000173	time 0.6820 (0.6337)	loss 4.1907 (3.7534)	grad_norm 8.7038 (6.5821)	mem 5325MB
[2022-04-21 05:34:08 tiny] (main.py 226): INFO Train: [220/300][400/1251]	eta 0:08:49 lr 0.000173	time 0.4500 (0.6221)	loss 3.0435 (3.7499)	grad_norm 4.4000 (6.6163)	mem 5325MB
[2022-04-21 05:35:06 tiny] (main.py 226): INFO Train: [220/300][500/1251]	eta 0:07:41 lr 0.000172	time 0.8051 (0.6146)	loss 3.0225 (3.7671)	grad_norm 6.3719 (6.4473)	mem 5325MB
[2022-04-21 05:36:05 tiny] (main.py 226): INFO Train: [220/300][600/1251]	eta 0:06:37 lr 0.000172	time 0.4932 (0.6106)	loss 3.3926 (3.7608)	grad_norm 4.3640 (6.5080)	mem 5325MB
[2022-04-21 05:37:04 tiny] (main.py 226): INFO Train: [220/300][700/1251]	eta 0:05:34 lr 0.000172	time 0.5869 (0.6069)	loss 4.1140 (3.7666)	grad_norm 7.5676 (6.4486)	mem 5325MB
[2022-04-21 05:38:03 tiny] (main.py 226): INFO Train: [220/300][800/1251]	eta 0:04:33 lr 0.000171	time 0.5186 (0.6054)	loss 3.5591 (3.7718)	grad_norm 4.6668 (6.4505)	mem 5325MB
[2022-04-21 05:39:01 tiny] (main.py 226): INFO Train: [220/300][900/1251]	eta 0:03:31 lr 0.000171	time 0.5685 (0.6028)	loss 3.2764 (3.7682)	grad_norm 11.0592 (6.4506)	mem 5325MB
[2022-04-21 05:40:00 tiny] (main.py 226): INFO Train: [220/300][1000/1251]	eta 0:02:30 lr 0.000171	time 0.6263 (0.6013)	loss 4.3290 (3.7710)	grad_norm 5.2773 (6.3751)	mem 5325MB
[2022-04-21 05:40:59 tiny] (main.py 226): INFO Train: [220/300][1100/1251]	eta 0:01:30 lr 0.000170	time 0.5183 (0.6002)	loss 4.3765 (3.7631)	grad_norm 6.5262 (6.3931)	mem 5325MB
[2022-04-21 05:41:59 tiny] (main.py 226): INFO Train: [220/300][1200/1251]	eta 0:00:30 lr 0.000170	time 0.6384 (0.5999)	loss 4.5812 (3.7684)	grad_norm 5.7939 (6.3904)	mem 5325MB
[2022-04-21 05:42:21 tiny] (main.py 233): INFO EPOCH 220 training takes 0:12:22
[2022-04-21 05:42:32 tiny] (main.py 273): INFO Test: [0/49]	Time 10.635 (10.635)	Loss 1.5034 (1.5034)	Acc@1 70.020 (70.020)	Acc@5 89.746 (89.746)	Mem 5325MB
[2022-04-21 05:42:52 tiny] (main.py 279): INFO  * Acc@1 70.120 Acc@5 89.834
[2022-04-21 05:42:52 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 70.1%
[2022-04-21 05:42:52 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_220.pth saving......
[2022-04-21 05:42:52 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_220.pth saved !!!
[2022-04-21 05:42:52 tiny] (main.py 148): INFO Max accuracy: 70.12%
[2022-04-21 05:43:02 tiny] (main.py 226): INFO Train: [221/300][0/1251]	eta 3:23:12 lr 0.000170	time 9.7463 (9.7463)	loss 4.0886 (4.0886)	grad_norm 11.5664 (11.5664)	mem 5325MB
[2022-04-21 05:44:05 tiny] (main.py 226): INFO Train: [221/300][100/1251]	eta 0:13:54 lr 0.000170	time 0.4529 (0.7248)	loss 3.9580 (3.8568)	grad_norm 4.2379 (6.6870)	mem 5325MB
[2022-04-21 05:45:04 tiny] (main.py 226): INFO Train: [221/300][200/1251]	eta 0:11:29 lr 0.000169	time 0.7437 (0.6565)	loss 3.9967 (3.7622)	grad_norm 5.7611 (6.4128)	mem 5325MB
[2022-04-21 05:46:02 tiny] (main.py 226): INFO Train: [221/300][300/1251]	eta 0:10:01 lr 0.000169	time 0.4548 (0.6326)	loss 3.7470 (3.7628)	grad_norm 4.4464 (6.3618)	mem 5325MB
[2022-04-21 05:47:00 tiny] (main.py 226): INFO Train: [221/300][400/1251]	eta 0:08:47 lr 0.000169	time 0.5094 (0.6202)	loss 4.0590 (3.7486)	grad_norm 7.5705 (6.4481)	mem 5325MB
[2022-04-21 05:47:59 tiny] (main.py 226): INFO Train: [221/300][500/1251]	eta 0:07:40 lr 0.000168	time 0.7038 (0.6137)	loss 3.8636 (3.7596)	grad_norm 5.1052 (6.4191)	mem 5325MB
[2022-04-21 05:48:58 tiny] (main.py 226): INFO Train: [221/300][600/1251]	eta 0:06:36 lr 0.000168	time 0.6346 (0.6092)	loss 4.0888 (3.7802)	grad_norm 5.0341 (6.4613)	mem 5325MB
[2022-04-21 05:49:57 tiny] (main.py 226): INFO Train: [221/300][700/1251]	eta 0:05:34 lr 0.000168	time 0.7171 (0.6065)	loss 3.9005 (3.7779)	grad_norm 5.7344 (6.4281)	mem 5325MB
[2022-04-21 05:50:56 tiny] (main.py 226): INFO Train: [221/300][800/1251]	eta 0:04:32 lr 0.000168	time 0.6111 (0.6041)	loss 4.2293 (3.7760)	grad_norm 7.4259 (6.5446)	mem 5325MB
[2022-04-21 05:51:54 tiny] (main.py 226): INFO Train: [221/300][900/1251]	eta 0:03:31 lr 0.000167	time 0.6110 (0.6023)	loss 3.9670 (3.7740)	grad_norm 4.4633 (6.5419)	mem 5325MB
[2022-04-21 05:52:54 tiny] (main.py 226): INFO Train: [221/300][1000/1251]	eta 0:02:30 lr 0.000167	time 0.3582 (0.6012)	loss 3.9536 (3.7670)	grad_norm 4.2531 (6.4900)	mem 5325MB
[2022-04-21 05:53:52 tiny] (main.py 226): INFO Train: [221/300][1100/1251]	eta 0:01:30 lr 0.000167	time 0.5905 (0.5996)	loss 4.1015 (3.7611)	grad_norm 7.5701 (6.5133)	mem 5325MB
[2022-04-21 05:54:51 tiny] (main.py 226): INFO Train: [221/300][1200/1251]	eta 0:00:30 lr 0.000166	time 0.5187 (0.5990)	loss 3.7779 (3.7628)	grad_norm 4.5716 (6.5009)	mem 5325MB
[2022-04-21 05:55:13 tiny] (main.py 233): INFO EPOCH 221 training takes 0:12:20
[2022-04-21 05:55:24 tiny] (main.py 273): INFO Test: [0/49]	Time 11.253 (11.253)	Loss 1.5525 (1.5525)	Acc@1 69.629 (69.629)	Acc@5 89.258 (89.258)	Mem 5325MB
[2022-04-21 05:55:44 tiny] (main.py 279): INFO  * Acc@1 70.262 Acc@5 89.842
[2022-04-21 05:55:44 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 70.3%
[2022-04-21 05:55:44 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_221.pth saving......
[2022-04-21 05:55:44 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_221.pth saved !!!
[2022-04-21 05:55:44 tiny] (main.py 148): INFO Max accuracy: 70.26%
[2022-04-21 05:55:55 tiny] (main.py 226): INFO Train: [222/300][0/1251]	eta 3:50:39 lr 0.000166	time 11.0624 (11.0624)	loss 3.4947 (3.4947)	grad_norm 4.7437 (4.7437)	mem 5325MB
[2022-04-21 05:56:57 tiny] (main.py 226): INFO Train: [222/300][100/1251]	eta 0:13:55 lr 0.000166	time 0.6612 (0.7258)	loss 4.0554 (3.7134)	grad_norm 3.6226 (7.4149)	mem 5325MB
[2022-04-21 05:57:55 tiny] (main.py 226): INFO Train: [222/300][200/1251]	eta 0:11:28 lr 0.000166	time 0.6302 (0.6550)	loss 4.3358 (3.6842)	grad_norm 8.0253 (6.8691)	mem 5325MB
[2022-04-21 05:58:54 tiny] (main.py 226): INFO Train: [222/300][300/1251]	eta 0:10:02 lr 0.000165	time 0.5479 (0.6332)	loss 3.8228 (3.6729)	grad_norm 11.8599 (6.6429)	mem 5325MB
[2022-04-21 05:59:53 tiny] (main.py 226): INFO Train: [222/300][400/1251]	eta 0:08:49 lr 0.000165	time 0.5118 (0.6217)	loss 4.4216 (3.6778)	grad_norm 7.0766 (6.5883)	mem 5325MB
[2022-04-21 06:00:52 tiny] (main.py 226): INFO Train: [222/300][500/1251]	eta 0:07:41 lr 0.000165	time 0.5322 (0.6144)	loss 3.2606 (3.7070)	grad_norm 5.1612 (6.4313)	mem 5325MB
[2022-04-21 06:01:50 tiny] (main.py 226): INFO Train: [222/300][600/1251]	eta 0:06:37 lr 0.000164	time 0.6171 (0.6101)	loss 4.7027 (3.7174)	grad_norm 6.1206 (nan)	mem 5325MB
[2022-04-21 06:02:49 tiny] (main.py 226): INFO Train: [222/300][700/1251]	eta 0:05:34 lr 0.000164	time 0.5032 (0.6067)	loss 3.8900 (3.7230)	grad_norm 6.5184 (nan)	mem 5325MB
[2022-04-21 06:03:48 tiny] (main.py 226): INFO Train: [222/300][800/1251]	eta 0:04:32 lr 0.000164	time 0.7177 (0.6048)	loss 4.1698 (3.7301)	grad_norm 5.3978 (nan)	mem 5325MB
[2022-04-21 06:04:47 tiny] (main.py 226): INFO Train: [222/300][900/1251]	eta 0:03:31 lr 0.000163	time 0.4964 (0.6031)	loss 4.0945 (3.7254)	grad_norm 7.4653 (nan)	mem 5325MB
[2022-04-21 06:05:46 tiny] (main.py 226): INFO Train: [222/300][1000/1251]	eta 0:02:31 lr 0.000163	time 0.6139 (0.6017)	loss 4.2813 (3.7377)	grad_norm 4.8831 (nan)	mem 5325MB
[2022-04-21 06:06:45 tiny] (main.py 226): INFO Train: [222/300][1100/1251]	eta 0:01:30 lr 0.000163	time 0.5723 (0.6006)	loss 4.0836 (3.7475)	grad_norm 9.7000 (nan)	mem 5325MB
[2022-04-21 06:07:44 tiny] (main.py 226): INFO Train: [222/300][1200/1251]	eta 0:00:30 lr 0.000163	time 0.3863 (0.5996)	loss 4.3721 (3.7574)	grad_norm 3.4695 (nan)	mem 5325MB
[2022-04-21 06:08:06 tiny] (main.py 233): INFO EPOCH 222 training takes 0:12:22
[2022-04-21 06:08:17 tiny] (main.py 273): INFO Test: [0/49]	Time 10.951 (10.951)	Loss 1.5048 (1.5048)	Acc@1 69.531 (69.531)	Acc@5 90.234 (90.234)	Mem 5325MB
[2022-04-21 06:08:37 tiny] (main.py 279): INFO  * Acc@1 70.288 Acc@5 89.794
[2022-04-21 06:08:37 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 70.3%
[2022-04-21 06:08:37 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_222.pth saving......
[2022-04-21 06:08:37 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_222.pth saved !!!
[2022-04-21 06:08:37 tiny] (main.py 148): INFO Max accuracy: 70.29%
[2022-04-21 06:08:48 tiny] (main.py 226): INFO Train: [223/300][0/1251]	eta 3:45:27 lr 0.000162	time 10.8134 (10.8134)	loss 3.6523 (3.6523)	grad_norm 5.1669 (5.1669)	mem 5325MB
[2022-04-21 06:09:51 tiny] (main.py 226): INFO Train: [223/300][100/1251]	eta 0:13:57 lr 0.000162	time 0.6357 (0.7280)	loss 3.3892 (3.6829)	grad_norm 9.5315 (7.1777)	mem 5325MB
[2022-04-21 06:10:49 tiny] (main.py 226): INFO Train: [223/300][200/1251]	eta 0:11:28 lr 0.000162	time 0.4753 (0.6553)	loss 4.5206 (3.7052)	grad_norm 11.0410 (6.7850)	mem 5325MB
[2022-04-21 06:11:48 tiny] (main.py 226): INFO Train: [223/300][300/1251]	eta 0:10:03 lr 0.000161	time 0.5578 (0.6342)	loss 3.6520 (3.7418)	grad_norm 5.5370 (6.7884)	mem 5325MB
[2022-04-21 06:12:46 tiny] (main.py 226): INFO Train: [223/300][400/1251]	eta 0:08:48 lr 0.000161	time 0.4589 (0.6206)	loss 4.0676 (3.7296)	grad_norm 7.1458 (6.7803)	mem 5325MB
[2022-04-21 06:13:45 tiny] (main.py 226): INFO Train: [223/300][500/1251]	eta 0:07:41 lr 0.000161	time 0.6896 (0.6150)	loss 3.8757 (3.7385)	grad_norm 7.0440 (6.6252)	mem 5325MB
[2022-04-21 06:14:44 tiny] (main.py 226): INFO Train: [223/300][600/1251]	eta 0:06:37 lr 0.000161	time 0.5296 (0.6102)	loss 4.4667 (3.7229)	grad_norm 6.1042 (6.6786)	mem 5325MB
[2022-04-21 06:15:43 tiny] (main.py 226): INFO Train: [223/300][700/1251]	eta 0:05:34 lr 0.000160	time 0.6407 (0.6077)	loss 4.0230 (3.7247)	grad_norm 4.7986 (6.7197)	mem 5325MB
[2022-04-21 06:16:42 tiny] (main.py 226): INFO Train: [223/300][800/1251]	eta 0:04:32 lr 0.000160	time 0.6075 (0.6050)	loss 3.6015 (3.7355)	grad_norm 6.4835 (6.7398)	mem 5325MB
[2022-04-21 06:17:41 tiny] (main.py 226): INFO Train: [223/300][900/1251]	eta 0:03:31 lr 0.000160	time 0.6718 (0.6032)	loss 4.0294 (3.7260)	grad_norm 5.2584 (6.7979)	mem 5325MB
[2022-04-21 06:18:39 tiny] (main.py 226): INFO Train: [223/300][1000/1251]	eta 0:02:30 lr 0.000159	time 0.5758 (0.6015)	loss 4.2633 (3.7298)	grad_norm 5.2703 (6.8257)	mem 5325MB
[2022-04-21 06:19:38 tiny] (main.py 226): INFO Train: [223/300][1100/1251]	eta 0:01:30 lr 0.000159	time 0.7060 (0.6000)	loss 4.3144 (3.7411)	grad_norm 5.7496 (6.8006)	mem 5325MB
[2022-04-21 06:20:37 tiny] (main.py 226): INFO Train: [223/300][1200/1251]	eta 0:00:30 lr 0.000159	time 0.6548 (0.5991)	loss 4.4937 (3.7420)	grad_norm 6.2699 (6.7472)	mem 5325MB
[2022-04-21 06:20:59 tiny] (main.py 233): INFO EPOCH 223 training takes 0:12:22
[2022-04-21 06:21:11 tiny] (main.py 273): INFO Test: [0/49]	Time 11.441 (11.441)	Loss 1.5750 (1.5750)	Acc@1 67.090 (67.090)	Acc@5 89.551 (89.551)	Mem 5325MB
[2022-04-21 06:21:30 tiny] (main.py 279): INFO  * Acc@1 70.156 Acc@5 89.944
[2022-04-21 06:21:30 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 70.2%
[2022-04-21 06:21:30 tiny] (main.py 148): INFO Max accuracy: 70.29%
[2022-04-21 06:21:42 tiny] (main.py 226): INFO Train: [224/300][0/1251]	eta 3:59:11 lr 0.000159	time 11.4722 (11.4722)	loss 3.5357 (3.5357)	grad_norm 6.7916 (6.7916)	mem 5325MB
[2022-04-21 06:22:44 tiny] (main.py 226): INFO Train: [224/300][100/1251]	eta 0:13:59 lr 0.000158	time 0.5007 (0.7296)	loss 3.9243 (3.6938)	grad_norm 8.3462 (6.3077)	mem 5325MB
[2022-04-21 06:23:43 tiny] (main.py 226): INFO Train: [224/300][200/1251]	eta 0:11:32 lr 0.000158	time 0.5903 (0.6590)	loss 2.4999 (3.7355)	grad_norm 5.5441 (6.3922)	mem 5325MB
[2022-04-21 06:24:41 tiny] (main.py 226): INFO Train: [224/300][300/1251]	eta 0:10:02 lr 0.000158	time 0.5462 (0.6334)	loss 3.0764 (3.7318)	grad_norm 8.7389 (6.5037)	mem 5325MB
[2022-04-21 06:25:39 tiny] (main.py 226): INFO Train: [224/300][400/1251]	eta 0:08:49 lr 0.000157	time 0.6906 (0.6218)	loss 2.9856 (3.7577)	grad_norm 4.5842 (6.5481)	mem 5325MB
[2022-04-21 06:26:38 tiny] (main.py 226): INFO Train: [224/300][500/1251]	eta 0:07:42 lr 0.000157	time 0.4931 (0.6155)	loss 3.7937 (3.7563)	grad_norm 6.9548 (6.5997)	mem 5325MB
[2022-04-21 06:27:36 tiny] (main.py 226): INFO Train: [224/300][600/1251]	eta 0:06:36 lr 0.000157	time 0.4712 (0.6096)	loss 3.7714 (3.7562)	grad_norm 5.5160 (6.6393)	mem 5325MB
[2022-04-21 06:28:36 tiny] (main.py 226): INFO Train: [224/300][700/1251]	eta 0:05:34 lr 0.000157	time 0.6254 (0.6071)	loss 4.1881 (3.7464)	grad_norm 9.2226 (nan)	mem 5325MB
[2022-04-21 06:29:34 tiny] (main.py 226): INFO Train: [224/300][800/1251]	eta 0:04:32 lr 0.000156	time 0.6204 (0.6043)	loss 3.8740 (3.7547)	grad_norm 6.7789 (nan)	mem 5325MB
[2022-04-21 06:30:33 tiny] (main.py 226): INFO Train: [224/300][900/1251]	eta 0:03:31 lr 0.000156	time 0.4371 (0.6024)	loss 3.8233 (3.7629)	grad_norm 8.2294 (nan)	mem 5325MB
[2022-04-21 06:31:32 tiny] (main.py 226): INFO Train: [224/300][1000/1251]	eta 0:02:30 lr 0.000156	time 0.6733 (0.6015)	loss 3.9622 (3.7748)	grad_norm 8.5509 (nan)	mem 5325MB
[2022-04-21 06:32:31 tiny] (main.py 226): INFO Train: [224/300][1100/1251]	eta 0:01:30 lr 0.000155	time 0.5893 (0.6001)	loss 4.4836 (3.7693)	grad_norm 7.0334 (nan)	mem 5325MB
[2022-04-21 06:33:30 tiny] (main.py 226): INFO Train: [224/300][1200/1251]	eta 0:00:30 lr 0.000155	time 0.6730 (0.5990)	loss 4.0461 (3.7681)	grad_norm 5.6845 (nan)	mem 5325MB
[2022-04-21 06:33:51 tiny] (main.py 233): INFO EPOCH 224 training takes 0:12:21
[2022-04-21 06:34:02 tiny] (main.py 273): INFO Test: [0/49]	Time 10.545 (10.545)	Loss 1.5408 (1.5408)	Acc@1 69.727 (69.727)	Acc@5 89.160 (89.160)	Mem 5325MB
[2022-04-21 06:34:22 tiny] (main.py 279): INFO  * Acc@1 70.214 Acc@5 89.670
[2022-04-21 06:34:22 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 70.2%
[2022-04-21 06:34:22 tiny] (main.py 148): INFO Max accuracy: 70.29%
[2022-04-21 06:34:33 tiny] (main.py 226): INFO Train: [225/300][0/1251]	eta 3:41:46 lr 0.000155	time 10.6366 (10.6366)	loss 3.3655 (3.3655)	grad_norm 6.4758 (6.4758)	mem 5325MB
[2022-04-21 06:35:36 tiny] (main.py 226): INFO Train: [225/300][100/1251]	eta 0:13:58 lr 0.000155	time 0.7578 (0.7286)	loss 3.7802 (3.6401)	grad_norm 4.2300 (6.5980)	mem 5325MB
[2022-04-21 06:36:34 tiny] (main.py 226): INFO Train: [225/300][200/1251]	eta 0:11:31 lr 0.000154	time 0.5566 (0.6577)	loss 3.6657 (3.7147)	grad_norm 4.8290 (7.0453)	mem 5325MB
[2022-04-21 06:37:33 tiny] (main.py 226): INFO Train: [225/300][300/1251]	eta 0:10:01 lr 0.000154	time 0.4240 (0.6325)	loss 2.4437 (3.7290)	grad_norm 4.7768 (7.1147)	mem 5325MB
[2022-04-21 06:38:31 tiny] (main.py 226): INFO Train: [225/300][400/1251]	eta 0:08:48 lr 0.000154	time 0.6444 (0.6214)	loss 4.2348 (3.7221)	grad_norm 8.3373 (7.0792)	mem 5325MB
[2022-04-21 06:39:30 tiny] (main.py 226): INFO Train: [225/300][500/1251]	eta 0:07:41 lr 0.000154	time 0.5261 (0.6150)	loss 3.9764 (3.7124)	grad_norm 8.3019 (6.9370)	mem 5325MB
[2022-04-21 06:40:29 tiny] (main.py 226): INFO Train: [225/300][600/1251]	eta 0:06:37 lr 0.000153	time 1.0194 (0.6109)	loss 3.9469 (3.7134)	grad_norm 19.5390 (6.8993)	mem 5325MB
[2022-04-21 06:41:28 tiny] (main.py 226): INFO Train: [225/300][700/1251]	eta 0:05:34 lr 0.000153	time 0.5484 (0.6073)	loss 4.5133 (3.7121)	grad_norm 4.1356 (6.8745)	mem 5325MB
[2022-04-21 06:42:26 tiny] (main.py 226): INFO Train: [225/300][800/1251]	eta 0:04:32 lr 0.000153	time 0.6640 (0.6045)	loss 3.6183 (3.7178)	grad_norm 5.5045 (6.8345)	mem 5325MB
[2022-04-21 06:43:25 tiny] (main.py 226): INFO Train: [225/300][900/1251]	eta 0:03:31 lr 0.000152	time 0.5373 (0.6027)	loss 4.0689 (3.7139)	grad_norm 7.3496 (6.7628)	mem 5325MB
[2022-04-21 06:44:24 tiny] (main.py 226): INFO Train: [225/300][1000/1251]	eta 0:02:30 lr 0.000152	time 0.4401 (0.6013)	loss 4.2258 (3.7075)	grad_norm 5.5278 (6.7163)	mem 5325MB
[2022-04-21 06:45:23 tiny] (main.py 226): INFO Train: [225/300][1100/1251]	eta 0:01:30 lr 0.000152	time 0.6242 (0.6004)	loss 3.7310 (3.7066)	grad_norm 5.9254 (6.7205)	mem 5325MB
[2022-04-21 06:46:22 tiny] (main.py 226): INFO Train: [225/300][1200/1251]	eta 0:00:30 lr 0.000151	time 0.6709 (0.5996)	loss 3.8970 (3.7089)	grad_norm 5.1712 (6.7068)	mem 5325MB
[2022-04-21 06:46:45 tiny] (main.py 233): INFO EPOCH 225 training takes 0:12:22
[2022-04-21 06:46:56 tiny] (main.py 273): INFO Test: [0/49]	Time 11.236 (11.236)	Loss 1.6088 (1.6088)	Acc@1 66.895 (66.895)	Acc@5 88.965 (88.965)	Mem 5325MB
[2022-04-21 06:47:16 tiny] (main.py 279): INFO  * Acc@1 70.494 Acc@5 90.008
[2022-04-21 06:47:16 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 70.5%
[2022-04-21 06:47:16 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_225.pth saving......
[2022-04-21 06:47:16 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_225.pth saved !!!
[2022-04-21 06:47:16 tiny] (main.py 148): INFO Max accuracy: 70.49%
[2022-04-21 06:47:27 tiny] (main.py 226): INFO Train: [226/300][0/1251]	eta 3:41:55 lr 0.000151	time 10.6440 (10.6440)	loss 3.3885 (3.3885)	grad_norm 6.0530 (6.0530)	mem 5325MB
[2022-04-21 06:48:29 tiny] (main.py 226): INFO Train: [226/300][100/1251]	eta 0:13:55 lr 0.000151	time 0.4057 (0.7260)	loss 3.8560 (3.7801)	grad_norm 16.6268 (6.2714)	mem 5325MB
[2022-04-21 06:49:28 tiny] (main.py 226): INFO Train: [226/300][200/1251]	eta 0:11:30 lr 0.000151	time 0.6004 (0.6569)	loss 3.7276 (3.7965)	grad_norm 4.5841 (6.5767)	mem 5325MB
[2022-04-21 06:50:27 tiny] (main.py 226): INFO Train: [226/300][300/1251]	eta 0:10:01 lr 0.000150	time 0.5151 (0.6328)	loss 3.6186 (3.7917)	grad_norm 9.1589 (6.5185)	mem 5325MB
[2022-04-21 06:51:25 tiny] (main.py 226): INFO Train: [226/300][400/1251]	eta 0:08:48 lr 0.000150	time 0.4924 (0.6215)	loss 3.4118 (3.7737)	grad_norm 10.4811 (6.5819)	mem 5325MB
[2022-04-21 06:52:24 tiny] (main.py 226): INFO Train: [226/300][500/1251]	eta 0:07:41 lr 0.000150	time 0.7340 (0.6150)	loss 4.2113 (3.7778)	grad_norm 7.2564 (6.6745)	mem 5325MB
[2022-04-21 06:53:23 tiny] (main.py 226): INFO Train: [226/300][600/1251]	eta 0:06:36 lr 0.000150	time 0.5818 (0.6097)	loss 4.3749 (3.7799)	grad_norm 4.7867 (6.7233)	mem 5325MB
[2022-04-21 06:54:22 tiny] (main.py 226): INFO Train: [226/300][700/1251]	eta 0:05:34 lr 0.000149	time 0.5682 (0.6073)	loss 3.4391 (3.7811)	grad_norm 4.1642 (nan)	mem 5325MB
[2022-04-21 06:55:21 tiny] (main.py 226): INFO Train: [226/300][800/1251]	eta 0:04:32 lr 0.000149	time 0.5276 (0.6049)	loss 2.6641 (3.7740)	grad_norm 9.4533 (nan)	mem 5325MB
[2022-04-21 06:56:20 tiny] (main.py 226): INFO Train: [226/300][900/1251]	eta 0:03:31 lr 0.000149	time 0.5543 (0.6036)	loss 3.6384 (3.7848)	grad_norm 4.7994 (nan)	mem 5325MB
[2022-04-21 06:57:20 tiny] (main.py 226): INFO Train: [226/300][1000/1251]	eta 0:02:31 lr 0.000148	time 0.6394 (0.6030)	loss 4.2070 (3.7765)	grad_norm 5.9445 (nan)	mem 5325MB
[2022-04-21 06:58:20 tiny] (main.py 226): INFO Train: [226/300][1100/1251]	eta 0:01:31 lr 0.000148	time 0.5758 (0.6033)	loss 4.5122 (3.7705)	grad_norm 7.5869 (nan)	mem 5325MB
[2022-04-21 06:59:22 tiny] (main.py 226): INFO Train: [226/300][1200/1251]	eta 0:00:30 lr 0.000148	time 0.6000 (0.6044)	loss 3.9407 (3.7663)	grad_norm 9.8195 (nan)	mem 5325MB
[2022-04-21 06:59:44 tiny] (main.py 233): INFO EPOCH 226 training takes 0:12:28
[2022-04-21 06:59:55 tiny] (main.py 273): INFO Test: [0/49]	Time 10.308 (10.308)	Loss 1.4743 (1.4743)	Acc@1 71.094 (71.094)	Acc@5 91.016 (91.016)	Mem 5325MB
[2022-04-21 07:00:17 tiny] (main.py 279): INFO  * Acc@1 70.318 Acc@5 89.914
[2022-04-21 07:00:17 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 70.3%
[2022-04-21 07:00:17 tiny] (main.py 148): INFO Max accuracy: 70.49%
[2022-04-21 07:00:29 tiny] (main.py 226): INFO Train: [227/300][0/1251]	eta 4:27:03 lr 0.000148	time 12.8085 (12.8085)	loss 4.4767 (4.4767)	grad_norm 6.8864 (6.8864)	mem 5325MB
[2022-04-21 07:01:33 tiny] (main.py 226): INFO Train: [227/300][100/1251]	eta 0:14:34 lr 0.000147	time 0.4715 (0.7598)	loss 4.2718 (3.7447)	grad_norm 5.5450 (6.8401)	mem 5325MB
[2022-04-21 07:02:35 tiny] (main.py 226): INFO Train: [227/300][200/1251]	eta 0:12:04 lr 0.000147	time 0.6892 (0.6894)	loss 3.8688 (3.7366)	grad_norm 10.6548 (6.8025)	mem 5325MB
[2022-04-21 07:03:36 tiny] (main.py 226): INFO Train: [227/300][300/1251]	eta 0:10:29 lr 0.000147	time 0.4271 (0.6623)	loss 3.5704 (3.7376)	grad_norm 4.9065 (6.7032)	mem 5325MB
[2022-04-21 07:04:38 tiny] (main.py 226): INFO Train: [227/300][400/1251]	eta 0:09:13 lr 0.000147	time 0.6235 (0.6509)	loss 4.0501 (3.7463)	grad_norm 5.4345 (6.6787)	mem 5325MB
[2022-04-21 07:05:39 tiny] (main.py 226): INFO Train: [227/300][500/1251]	eta 0:08:03 lr 0.000146	time 0.6002 (0.6432)	loss 4.0355 (3.7451)	grad_norm 6.8286 (6.8571)	mem 5325MB
[2022-04-21 07:06:45 tiny] (main.py 226): INFO Train: [227/300][600/1251]	eta 0:07:00 lr 0.000146	time 0.4710 (0.6458)	loss 3.6866 (3.7469)	grad_norm 8.4845 (6.8068)	mem 5325MB
[2022-04-21 07:07:45 tiny] (main.py 226): INFO Train: [227/300][700/1251]	eta 0:05:52 lr 0.000146	time 0.6451 (0.6391)	loss 3.9806 (3.7412)	grad_norm 6.0726 (6.7221)	mem 5325MB
[2022-04-21 07:08:44 tiny] (main.py 226): INFO Train: [227/300][800/1251]	eta 0:04:45 lr 0.000145	time 0.6272 (0.6332)	loss 3.9741 (3.7443)	grad_norm 5.1263 (6.7760)	mem 5325MB
[2022-04-21 07:09:42 tiny] (main.py 226): INFO Train: [227/300][900/1251]	eta 0:03:40 lr 0.000145	time 0.4337 (0.6280)	loss 3.7007 (3.7372)	grad_norm 4.6132 (6.7502)	mem 5325MB
[2022-04-21 07:10:42 tiny] (main.py 226): INFO Train: [227/300][1000/1251]	eta 0:02:36 lr 0.000145	time 0.6921 (0.6245)	loss 3.7805 (3.7339)	grad_norm 5.8017 (6.7840)	mem 5325MB
[2022-04-21 07:11:41 tiny] (main.py 226): INFO Train: [227/300][1100/1251]	eta 0:01:33 lr 0.000145	time 0.6959 (0.6212)	loss 4.6397 (3.7455)	grad_norm 6.7656 (6.7409)	mem 5325MB
[2022-04-21 07:12:40 tiny] (main.py 226): INFO Train: [227/300][1200/1251]	eta 0:00:31 lr 0.000144	time 0.8215 (0.6185)	loss 3.7726 (3.7503)	grad_norm 4.1948 (6.7828)	mem 5325MB
[2022-04-21 07:13:01 tiny] (main.py 233): INFO EPOCH 227 training takes 0:12:44
[2022-04-21 07:13:11 tiny] (main.py 273): INFO Test: [0/49]	Time 9.595 (9.595)	Loss 1.5701 (1.5701)	Acc@1 69.824 (69.824)	Acc@5 89.062 (89.062)	Mem 5325MB
[2022-04-21 07:13:32 tiny] (main.py 279): INFO  * Acc@1 70.384 Acc@5 89.974
[2022-04-21 07:13:32 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 70.4%
[2022-04-21 07:13:32 tiny] (main.py 148): INFO Max accuracy: 70.49%
[2022-04-21 07:13:43 tiny] (main.py 226): INFO Train: [228/300][0/1251]	eta 3:44:54 lr 0.000144	time 10.7873 (10.7873)	loss 3.0067 (3.0067)	grad_norm 6.0053 (6.0053)	mem 5325MB
[2022-04-21 07:14:46 tiny] (main.py 226): INFO Train: [228/300][100/1251]	eta 0:13:59 lr 0.000144	time 0.5628 (0.7291)	loss 3.7716 (3.7710)	grad_norm 7.9240 (6.7420)	mem 5325MB
[2022-04-21 07:15:45 tiny] (main.py 226): INFO Train: [228/300][200/1251]	eta 0:11:32 lr 0.000144	time 0.7894 (0.6587)	loss 3.7223 (3.6975)	grad_norm 5.0967 (6.5338)	mem 5325MB
[2022-04-21 07:16:43 tiny] (main.py 226): INFO Train: [228/300][300/1251]	eta 0:10:01 lr 0.000143	time 0.4449 (0.6327)	loss 3.6235 (3.7005)	grad_norm 5.4228 (6.7396)	mem 5325MB
[2022-04-21 07:17:41 tiny] (main.py 226): INFO Train: [228/300][400/1251]	eta 0:08:48 lr 0.000143	time 0.5402 (0.6208)	loss 4.1842 (3.7139)	grad_norm 10.9693 (6.8357)	mem 5325MB
[2022-04-21 07:18:40 tiny] (main.py 226): INFO Train: [228/300][500/1251]	eta 0:07:40 lr 0.000143	time 0.4305 (0.6138)	loss 3.6669 (3.7073)	grad_norm nan (nan)	mem 5325MB
[2022-04-21 07:19:39 tiny] (main.py 226): INFO Train: [228/300][600/1251]	eta 0:06:36 lr 0.000142	time 0.5311 (0.6098)	loss 4.6341 (3.7375)	grad_norm 5.7469 (nan)	mem 5325MB
[2022-04-21 07:20:38 tiny] (main.py 226): INFO Train: [228/300][700/1251]	eta 0:05:34 lr 0.000142	time 0.6212 (0.6072)	loss 3.9175 (3.7328)	grad_norm 5.3935 (nan)	mem 5325MB
[2022-04-21 07:21:37 tiny] (main.py 226): INFO Train: [228/300][800/1251]	eta 0:04:32 lr 0.000142	time 0.6288 (0.6049)	loss 4.1140 (3.7389)	grad_norm 20.1856 (nan)	mem 5325MB
[2022-04-21 07:22:36 tiny] (main.py 226): INFO Train: [228/300][900/1251]	eta 0:03:31 lr 0.000142	time 0.5944 (0.6034)	loss 3.8462 (3.7345)	grad_norm 7.7374 (nan)	mem 5325MB
[2022-04-21 07:23:35 tiny] (main.py 226): INFO Train: [228/300][1000/1251]	eta 0:02:31 lr 0.000141	time 0.8500 (0.6021)	loss 2.7631 (3.7350)	grad_norm 5.0850 (nan)	mem 5325MB
[2022-04-21 07:24:34 tiny] (main.py 226): INFO Train: [228/300][1100/1251]	eta 0:01:30 lr 0.000141	time 0.6680 (0.6008)	loss 4.5204 (3.7397)	grad_norm 5.3306 (nan)	mem 5325MB
[2022-04-21 07:25:33 tiny] (main.py 226): INFO Train: [228/300][1200/1251]	eta 0:00:30 lr 0.000141	time 0.6005 (0.5998)	loss 2.8295 (3.7380)	grad_norm 9.5668 (nan)	mem 5325MB
[2022-04-21 07:25:55 tiny] (main.py 233): INFO EPOCH 228 training takes 0:12:22
[2022-04-21 07:26:07 tiny] (main.py 273): INFO Test: [0/49]	Time 11.946 (11.946)	Loss 1.4791 (1.4791)	Acc@1 69.824 (69.824)	Acc@5 89.551 (89.551)	Mem 5325MB
[2022-04-21 07:26:26 tiny] (main.py 279): INFO  * Acc@1 69.968 Acc@5 89.782
[2022-04-21 07:26:26 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 70.0%
[2022-04-21 07:26:26 tiny] (main.py 148): INFO Max accuracy: 70.49%
[2022-04-21 07:26:39 tiny] (main.py 226): INFO Train: [229/300][0/1251]	eta 4:18:07 lr 0.000141	time 12.3802 (12.3802)	loss 4.0512 (4.0512)	grad_norm 5.1066 (5.1066)	mem 5325MB
[2022-04-21 07:27:40 tiny] (main.py 226): INFO Train: [229/300][100/1251]	eta 0:13:59 lr 0.000140	time 0.5622 (0.7298)	loss 3.9779 (3.7345)	grad_norm 5.6797 (6.5469)	mem 5325MB
[2022-04-21 07:28:39 tiny] (main.py 226): INFO Train: [229/300][200/1251]	eta 0:11:33 lr 0.000140	time 0.6691 (0.6594)	loss 2.5267 (3.7620)	grad_norm 5.5381 (6.4741)	mem 5325MB
[2022-04-21 07:29:38 tiny] (main.py 226): INFO Train: [229/300][300/1251]	eta 0:10:04 lr 0.000140	time 0.5549 (0.6353)	loss 3.6927 (3.7653)	grad_norm 6.2999 (6.8578)	mem 5325MB
[2022-04-21 07:30:36 tiny] (main.py 226): INFO Train: [229/300][400/1251]	eta 0:08:49 lr 0.000140	time 0.5221 (0.6224)	loss 3.7921 (3.7521)	grad_norm 6.1972 (6.7908)	mem 5325MB
[2022-04-21 07:31:35 tiny] (main.py 226): INFO Train: [229/300][500/1251]	eta 0:07:42 lr 0.000139	time 0.6491 (0.6152)	loss 2.8014 (3.7438)	grad_norm 6.1368 (6.7207)	mem 5325MB
[2022-04-21 07:32:33 tiny] (main.py 226): INFO Train: [229/300][600/1251]	eta 0:06:37 lr 0.000139	time 0.6315 (0.6106)	loss 3.5150 (3.7322)	grad_norm 4.6929 (6.7282)	mem 5325MB
[2022-04-21 07:33:32 tiny] (main.py 226): INFO Train: [229/300][700/1251]	eta 0:05:34 lr 0.000139	time 0.5212 (0.6075)	loss 4.1345 (3.7296)	grad_norm 5.0941 (6.8362)	mem 5325MB
[2022-04-21 07:34:31 tiny] (main.py 226): INFO Train: [229/300][800/1251]	eta 0:04:33 lr 0.000138	time 0.5962 (0.6057)	loss 3.9673 (3.7505)	grad_norm 5.5272 (6.8980)	mem 5325MB
[2022-04-21 07:35:30 tiny] (main.py 226): INFO Train: [229/300][900/1251]	eta 0:03:31 lr 0.000138	time 0.5913 (0.6037)	loss 2.6740 (3.7549)	grad_norm 10.0364 (6.8469)	mem 5325MB
[2022-04-21 07:36:29 tiny] (main.py 226): INFO Train: [229/300][1000/1251]	eta 0:02:31 lr 0.000138	time 0.5009 (0.6021)	loss 4.5629 (3.7473)	grad_norm 5.8215 (6.8285)	mem 5325MB
[2022-04-21 07:37:28 tiny] (main.py 226): INFO Train: [229/300][1100/1251]	eta 0:01:30 lr 0.000138	time 0.5193 (0.6009)	loss 3.9989 (3.7612)	grad_norm 5.9771 (6.9007)	mem 5325MB
[2022-04-21 07:38:27 tiny] (main.py 226): INFO Train: [229/300][1200/1251]	eta 0:00:30 lr 0.000137	time 0.5389 (0.5999)	loss 3.9618 (3.7581)	grad_norm 9.5351 (6.9131)	mem 5325MB
[2022-04-21 07:38:49 tiny] (main.py 233): INFO EPOCH 229 training takes 0:12:22
[2022-04-21 07:39:00 tiny] (main.py 273): INFO Test: [0/49]	Time 11.334 (11.334)	Loss 1.5982 (1.5982)	Acc@1 68.848 (68.848)	Acc@5 87.695 (87.695)	Mem 5325MB
[2022-04-21 07:39:19 tiny] (main.py 279): INFO  * Acc@1 70.394 Acc@5 89.954
[2022-04-21 07:39:19 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 70.4%
[2022-04-21 07:39:19 tiny] (main.py 148): INFO Max accuracy: 70.49%
[2022-04-21 07:39:30 tiny] (main.py 226): INFO Train: [230/300][0/1251]	eta 3:49:11 lr 0.000137	time 10.9926 (10.9926)	loss 4.6525 (4.6525)	grad_norm 9.3815 (9.3815)	mem 5325MB
[2022-04-21 07:40:33 tiny] (main.py 226): INFO Train: [230/300][100/1251]	eta 0:13:58 lr 0.000137	time 0.4802 (0.7288)	loss 4.6540 (3.7255)	grad_norm 6.2025 (7.0814)	mem 5325MB
[2022-04-21 07:41:32 tiny] (main.py 226): INFO Train: [230/300][200/1251]	eta 0:11:31 lr 0.000137	time 0.6277 (0.6583)	loss 4.0462 (3.7545)	grad_norm 8.3853 (6.7153)	mem 5325MB
[2022-04-21 07:42:31 tiny] (main.py 226): INFO Train: [230/300][300/1251]	eta 0:10:03 lr 0.000136	time 0.6782 (0.6348)	loss 4.3215 (3.7500)	grad_norm 8.3279 (7.0720)	mem 5325MB
[2022-04-21 07:43:29 tiny] (main.py 226): INFO Train: [230/300][400/1251]	eta 0:08:49 lr 0.000136	time 0.7123 (0.6223)	loss 4.5390 (3.7529)	grad_norm 7.5194 (6.9682)	mem 5325MB
[2022-04-21 07:44:28 tiny] (main.py 226): INFO Train: [230/300][500/1251]	eta 0:07:42 lr 0.000136	time 0.4969 (0.6153)	loss 4.1476 (3.7572)	grad_norm 6.0610 (6.9179)	mem 5325MB
[2022-04-21 07:45:27 tiny] (main.py 226): INFO Train: [230/300][600/1251]	eta 0:06:38 lr 0.000135	time 0.6053 (0.6117)	loss 3.7980 (3.7549)	grad_norm 9.9335 (6.8820)	mem 5325MB
[2022-04-21 07:46:26 tiny] (main.py 226): INFO Train: [230/300][700/1251]	eta 0:05:34 lr 0.000135	time 0.5120 (0.6079)	loss 2.9503 (3.7533)	grad_norm 5.1296 (nan)	mem 5325MB
[2022-04-21 07:47:25 tiny] (main.py 226): INFO Train: [230/300][800/1251]	eta 0:04:33 lr 0.000135	time 0.4292 (0.6060)	loss 3.7641 (3.7460)	grad_norm 6.4235 (nan)	mem 5325MB
[2022-04-21 07:48:23 tiny] (main.py 226): INFO Train: [230/300][900/1251]	eta 0:03:31 lr 0.000135	time 0.5691 (0.6035)	loss 3.8152 (3.7587)	grad_norm 5.0101 (nan)	mem 5325MB
[2022-04-21 07:49:22 tiny] (main.py 226): INFO Train: [230/300][1000/1251]	eta 0:02:31 lr 0.000134	time 0.5559 (0.6022)	loss 3.0915 (3.7595)	grad_norm 7.3271 (nan)	mem 5325MB
[2022-04-21 07:50:21 tiny] (main.py 226): INFO Train: [230/300][1100/1251]	eta 0:01:30 lr 0.000134	time 0.7745 (0.6009)	loss 3.1478 (3.7628)	grad_norm 6.7348 (nan)	mem 5325MB
[2022-04-21 07:51:20 tiny] (main.py 226): INFO Train: [230/300][1200/1251]	eta 0:00:30 lr 0.000134	time 0.6740 (0.5998)	loss 4.3660 (3.7633)	grad_norm 5.2036 (nan)	mem 5325MB
[2022-04-21 07:51:42 tiny] (main.py 233): INFO EPOCH 230 training takes 0:12:22
[2022-04-21 07:51:53 tiny] (main.py 273): INFO Test: [0/49]	Time 11.067 (11.067)	Loss 1.5183 (1.5183)	Acc@1 70.508 (70.508)	Acc@5 90.430 (90.430)	Mem 5325MB
[2022-04-21 07:52:12 tiny] (main.py 279): INFO  * Acc@1 70.654 Acc@5 90.022
[2022-04-21 07:52:12 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 70.7%
[2022-04-21 07:52:12 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_230.pth saving......
[2022-04-21 07:52:12 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_230.pth saved !!!
[2022-04-21 07:52:12 tiny] (main.py 148): INFO Max accuracy: 70.65%
[2022-04-21 07:52:24 tiny] (main.py 226): INFO Train: [231/300][0/1251]	eta 3:55:53 lr 0.000134	time 11.3135 (11.3135)	loss 3.7415 (3.7415)	grad_norm 8.0241 (8.0241)	mem 5325MB
[2022-04-21 07:53:26 tiny] (main.py 226): INFO Train: [231/300][100/1251]	eta 0:13:56 lr 0.000133	time 0.6170 (0.7266)	loss 4.5112 (3.6856)	grad_norm 6.0657 (6.9827)	mem 5325MB
[2022-04-21 07:54:24 tiny] (main.py 226): INFO Train: [231/300][200/1251]	eta 0:11:29 lr 0.000133	time 0.6203 (0.6564)	loss 4.0186 (3.7153)	grad_norm 6.0160 (7.2746)	mem 5325MB
[2022-04-21 07:55:23 tiny] (main.py 226): INFO Train: [231/300][300/1251]	eta 0:10:01 lr 0.000133	time 0.6566 (0.6328)	loss 4.6606 (3.7380)	grad_norm 9.7513 (7.1317)	mem 5325MB
[2022-04-21 07:56:21 tiny] (main.py 226): INFO Train: [231/300][400/1251]	eta 0:08:48 lr 0.000133	time 0.4984 (0.6205)	loss 3.9229 (3.7376)	grad_norm 5.2664 (7.0581)	mem 5325MB
[2022-04-21 07:57:20 tiny] (main.py 226): INFO Train: [231/300][500/1251]	eta 0:07:41 lr 0.000132	time 0.7153 (0.6146)	loss 4.2125 (3.7361)	grad_norm 8.3313 (7.1071)	mem 5325MB
[2022-04-21 07:58:19 tiny] (main.py 226): INFO Train: [231/300][600/1251]	eta 0:06:37 lr 0.000132	time 0.5777 (0.6099)	loss 4.1609 (3.7518)	grad_norm 5.7010 (7.1088)	mem 5325MB
[2022-04-21 07:59:18 tiny] (main.py 226): INFO Train: [231/300][700/1251]	eta 0:05:34 lr 0.000132	time 0.5385 (0.6067)	loss 4.6392 (3.7403)	grad_norm 5.1927 (7.0617)	mem 5325MB
[2022-04-21 08:00:17 tiny] (main.py 226): INFO Train: [231/300][800/1251]	eta 0:04:32 lr 0.000132	time 0.8084 (0.6053)	loss 4.4869 (3.7509)	grad_norm 4.9332 (6.9812)	mem 5325MB
[2022-04-21 08:01:16 tiny] (main.py 226): INFO Train: [231/300][900/1251]	eta 0:03:31 lr 0.000131	time 0.7025 (0.6034)	loss 4.4008 (3.7439)	grad_norm 4.1582 (7.0291)	mem 5325MB
[2022-04-21 08:02:15 tiny] (main.py 226): INFO Train: [231/300][1000/1251]	eta 0:02:31 lr 0.000131	time 0.5399 (0.6021)	loss 3.9034 (3.7510)	grad_norm 15.3013 (7.0014)	mem 5325MB
[2022-04-21 08:03:14 tiny] (main.py 226): INFO Train: [231/300][1100/1251]	eta 0:01:30 lr 0.000131	time 0.5637 (0.6010)	loss 4.1534 (3.7599)	grad_norm 5.1281 (6.9716)	mem 5325MB
[2022-04-21 08:04:13 tiny] (main.py 226): INFO Train: [231/300][1200/1251]	eta 0:00:30 lr 0.000130	time 0.5008 (0.5998)	loss 3.6868 (3.7474)	grad_norm 5.6721 (6.9731)	mem 5325MB
[2022-04-21 08:04:35 tiny] (main.py 233): INFO EPOCH 231 training takes 0:12:22
[2022-04-21 08:04:47 tiny] (main.py 273): INFO Test: [0/49]	Time 11.851 (11.851)	Loss 1.4802 (1.4802)	Acc@1 70.996 (70.996)	Acc@5 89.258 (89.258)	Mem 5325MB
[2022-04-21 08:05:06 tiny] (main.py 279): INFO  * Acc@1 70.674 Acc@5 90.172
[2022-04-21 08:05:06 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 70.7%
[2022-04-21 08:05:06 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_231.pth saving......
[2022-04-21 08:05:06 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_231.pth saved !!!
[2022-04-21 08:05:06 tiny] (main.py 148): INFO Max accuracy: 70.67%
[2022-04-21 08:05:17 tiny] (main.py 226): INFO Train: [232/300][0/1251]	eta 3:44:00 lr 0.000130	time 10.7439 (10.7439)	loss 4.0775 (4.0775)	grad_norm 10.4348 (10.4348)	mem 5325MB
[2022-04-21 08:06:20 tiny] (main.py 226): INFO Train: [232/300][100/1251]	eta 0:13:56 lr 0.000130	time 0.4490 (0.7266)	loss 4.0609 (3.8074)	grad_norm 10.7826 (7.0561)	mem 5325MB
[2022-04-21 08:07:18 tiny] (main.py 226): INFO Train: [232/300][200/1251]	eta 0:11:27 lr 0.000130	time 0.5833 (0.6541)	loss 4.1323 (3.7188)	grad_norm 18.5370 (7.2400)	mem 5325MB
[2022-04-21 08:08:16 tiny] (main.py 226): INFO Train: [232/300][300/1251]	eta 0:09:59 lr 0.000129	time 0.5017 (0.6303)	loss 3.4417 (3.7163)	grad_norm 8.6567 (7.2490)	mem 5325MB
[2022-04-21 08:09:16 tiny] (main.py 226): INFO Train: [232/300][400/1251]	eta 0:08:49 lr 0.000129	time 0.7951 (0.6219)	loss 3.2542 (3.6973)	grad_norm 5.5135 (nan)	mem 5325MB
[2022-04-21 08:10:14 tiny] (main.py 226): INFO Train: [232/300][500/1251]	eta 0:07:41 lr 0.000129	time 0.7675 (0.6143)	loss 3.7919 (3.6904)	grad_norm 9.9666 (nan)	mem 5325MB
[2022-04-21 08:11:13 tiny] (main.py 226): INFO Train: [232/300][600/1251]	eta 0:06:37 lr 0.000129	time 0.7368 (0.6106)	loss 3.9870 (3.7107)	grad_norm 9.1809 (nan)	mem 5325MB
[2022-04-21 08:12:12 tiny] (main.py 226): INFO Train: [232/300][700/1251]	eta 0:05:34 lr 0.000128	time 0.5099 (0.6070)	loss 3.4934 (3.7080)	grad_norm 9.8453 (nan)	mem 5325MB
[2022-04-21 08:13:11 tiny] (main.py 226): INFO Train: [232/300][800/1251]	eta 0:04:32 lr 0.000128	time 0.5987 (0.6047)	loss 3.6383 (3.7126)	grad_norm 4.2572 (nan)	mem 5325MB
[2022-04-21 08:14:10 tiny] (main.py 226): INFO Train: [232/300][900/1251]	eta 0:03:31 lr 0.000128	time 1.2144 (0.6034)	loss 3.0750 (3.7002)	grad_norm 5.7369 (nan)	mem 5325MB
[2022-04-21 08:15:09 tiny] (main.py 226): INFO Train: [232/300][1000/1251]	eta 0:02:31 lr 0.000128	time 0.6856 (0.6020)	loss 4.4707 (3.7186)	grad_norm 9.2399 (nan)	mem 5325MB
[2022-04-21 08:16:08 tiny] (main.py 226): INFO Train: [232/300][1100/1251]	eta 0:01:30 lr 0.000127	time 0.6363 (0.6008)	loss 3.4315 (3.7221)	grad_norm 7.2383 (nan)	mem 5325MB
[2022-04-21 08:17:07 tiny] (main.py 226): INFO Train: [232/300][1200/1251]	eta 0:00:30 lr 0.000127	time 0.4151 (0.5997)	loss 2.9759 (3.7258)	grad_norm 7.5393 (nan)	mem 5325MB
[2022-04-21 08:17:28 tiny] (main.py 233): INFO EPOCH 232 training takes 0:12:21
[2022-04-21 08:17:40 tiny] (main.py 273): INFO Test: [0/49]	Time 11.841 (11.841)	Loss 1.4576 (1.4576)	Acc@1 69.629 (69.629)	Acc@5 90.820 (90.820)	Mem 5325MB
[2022-04-21 08:17:59 tiny] (main.py 279): INFO  * Acc@1 70.736 Acc@5 90.082
[2022-04-21 08:17:59 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 70.7%
[2022-04-21 08:17:59 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_232.pth saving......
[2022-04-21 08:17:59 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_232.pth saved !!!
[2022-04-21 08:17:59 tiny] (main.py 148): INFO Max accuracy: 70.74%
[2022-04-21 08:18:11 tiny] (main.py 226): INFO Train: [233/300][0/1251]	eta 4:11:12 lr 0.000127	time 12.0486 (12.0486)	loss 3.8988 (3.8988)	grad_norm 5.5501 (5.5501)	mem 5325MB
[2022-04-21 08:19:13 tiny] (main.py 226): INFO Train: [233/300][100/1251]	eta 0:13:58 lr 0.000127	time 0.4893 (0.7286)	loss 4.5295 (3.7311)	grad_norm 7.6270 (7.2613)	mem 5325MB
[2022-04-21 08:20:12 tiny] (main.py 226): INFO Train: [233/300][200/1251]	eta 0:11:33 lr 0.000126	time 0.8340 (0.6594)	loss 3.7243 (3.8047)	grad_norm 6.9224 (6.9509)	mem 5325MB
[2022-04-21 08:21:10 tiny] (main.py 226): INFO Train: [233/300][300/1251]	eta 0:10:01 lr 0.000126	time 0.3978 (0.6327)	loss 2.6689 (3.7737)	grad_norm 4.5188 (6.9041)	mem 5325MB
[2022-04-21 08:22:09 tiny] (main.py 226): INFO Train: [233/300][400/1251]	eta 0:08:50 lr 0.000126	time 0.6400 (0.6234)	loss 3.0775 (3.7359)	grad_norm 8.7449 (7.0899)	mem 5325MB
[2022-04-21 08:23:08 tiny] (main.py 226): INFO Train: [233/300][500/1251]	eta 0:07:42 lr 0.000126	time 0.4900 (0.6155)	loss 3.3907 (3.7388)	grad_norm 4.6477 (7.1998)	mem 5325MB
[2022-04-21 08:24:06 tiny] (main.py 226): INFO Train: [233/300][600/1251]	eta 0:06:37 lr 0.000125	time 0.6968 (0.6109)	loss 4.0899 (3.7519)	grad_norm 4.4597 (7.1861)	mem 5325MB
[2022-04-21 08:25:05 tiny] (main.py 226): INFO Train: [233/300][700/1251]	eta 0:05:34 lr 0.000125	time 0.6637 (0.6075)	loss 3.9990 (3.7313)	grad_norm 6.6506 (7.1991)	mem 5325MB
[2022-04-21 08:26:04 tiny] (main.py 226): INFO Train: [233/300][800/1251]	eta 0:04:33 lr 0.000125	time 0.5111 (0.6054)	loss 3.5898 (3.7272)	grad_norm 4.8814 (7.2033)	mem 5325MB
[2022-04-21 08:27:03 tiny] (main.py 226): INFO Train: [233/300][900/1251]	eta 0:03:31 lr 0.000125	time 0.5496 (0.6038)	loss 4.2514 (3.7155)	grad_norm 8.7713 (7.2322)	mem 5325MB
[2022-04-21 08:28:02 tiny] (main.py 226): INFO Train: [233/300][1000/1251]	eta 0:02:31 lr 0.000124	time 0.5434 (0.6022)	loss 3.4080 (3.7094)	grad_norm 5.3639 (7.2298)	mem 5325MB
[2022-04-21 08:29:01 tiny] (main.py 226): INFO Train: [233/300][1100/1251]	eta 0:01:30 lr 0.000124	time 0.7709 (0.6010)	loss 3.7539 (3.7046)	grad_norm 6.4015 (7.2061)	mem 5325MB
[2022-04-21 08:30:00 tiny] (main.py 226): INFO Train: [233/300][1200/1251]	eta 0:00:30 lr 0.000124	time 0.5381 (0.6000)	loss 3.7960 (3.7063)	grad_norm 6.7150 (7.2182)	mem 5325MB
[2022-04-21 08:30:22 tiny] (main.py 233): INFO EPOCH 233 training takes 0:12:22
[2022-04-21 08:30:33 tiny] (main.py 273): INFO Test: [0/49]	Time 11.187 (11.187)	Loss 1.5145 (1.5145)	Acc@1 70.410 (70.410)	Acc@5 90.234 (90.234)	Mem 5325MB
[2022-04-21 08:30:53 tiny] (main.py 279): INFO  * Acc@1 70.744 Acc@5 90.088
[2022-04-21 08:30:53 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 70.7%
[2022-04-21 08:30:53 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_233.pth saving......
[2022-04-21 08:30:53 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_233.pth saved !!!
[2022-04-21 08:30:53 tiny] (main.py 148): INFO Max accuracy: 70.74%
[2022-04-21 08:31:04 tiny] (main.py 226): INFO Train: [234/300][0/1251]	eta 4:01:15 lr 0.000124	time 11.5708 (11.5708)	loss 4.0127 (4.0127)	grad_norm 5.6863 (5.6863)	mem 5325MB
[2022-04-21 08:32:07 tiny] (main.py 226): INFO Train: [234/300][100/1251]	eta 0:14:01 lr 0.000123	time 0.6974 (0.7314)	loss 4.4415 (3.6483)	grad_norm 8.6067 (7.3037)	mem 5325MB
[2022-04-21 08:33:05 tiny] (main.py 226): INFO Train: [234/300][200/1251]	eta 0:11:31 lr 0.000123	time 0.4417 (0.6578)	loss 2.8801 (3.6549)	grad_norm 7.9710 (7.3124)	mem 5325MB
[2022-04-21 08:34:04 tiny] (main.py 226): INFO Train: [234/300][300/1251]	eta 0:10:03 lr 0.000123	time 0.4989 (0.6349)	loss 3.6660 (3.6823)	grad_norm 19.9644 (7.8860)	mem 5325MB
[2022-04-21 08:35:02 tiny] (main.py 226): INFO Train: [234/300][400/1251]	eta 0:08:49 lr 0.000123	time 0.5066 (0.6222)	loss 3.4955 (3.6955)	grad_norm 4.9963 (7.6873)	mem 5325MB
[2022-04-21 08:36:01 tiny] (main.py 226): INFO Train: [234/300][500/1251]	eta 0:07:42 lr 0.000122	time 0.6682 (0.6159)	loss 3.2491 (3.6977)	grad_norm 6.2657 (7.5805)	mem 5325MB
[2022-04-21 08:37:00 tiny] (main.py 226): INFO Train: [234/300][600/1251]	eta 0:06:37 lr 0.000122	time 0.5626 (0.6106)	loss 4.2197 (3.6952)	grad_norm 8.8003 (7.4779)	mem 5325MB
[2022-04-21 08:37:59 tiny] (main.py 226): INFO Train: [234/300][700/1251]	eta 0:05:34 lr 0.000122	time 0.6058 (0.6076)	loss 4.2863 (3.7055)	grad_norm 4.1610 (nan)	mem 5325MB
[2022-04-21 08:38:57 tiny] (main.py 226): INFO Train: [234/300][800/1251]	eta 0:04:32 lr 0.000121	time 0.8057 (0.6051)	loss 3.9471 (3.7073)	grad_norm 5.4637 (nan)	mem 5325MB
[2022-04-21 08:39:57 tiny] (main.py 226): INFO Train: [234/300][900/1251]	eta 0:03:31 lr 0.000121	time 0.5066 (0.6037)	loss 4.4057 (3.7094)	grad_norm 7.6300 (nan)	mem 5325MB
[2022-04-21 08:40:56 tiny] (main.py 226): INFO Train: [234/300][1000/1251]	eta 0:02:31 lr 0.000121	time 0.6565 (0.6022)	loss 4.5843 (3.7064)	grad_norm 5.5653 (nan)	mem 5325MB
[2022-04-21 08:41:54 tiny] (main.py 226): INFO Train: [234/300][1100/1251]	eta 0:01:30 lr 0.000121	time 0.4856 (0.6008)	loss 3.5185 (3.7117)	grad_norm 4.2398 (nan)	mem 5325MB
[2022-04-21 08:42:53 tiny] (main.py 226): INFO Train: [234/300][1200/1251]	eta 0:00:30 lr 0.000120	time 0.5544 (0.6001)	loss 4.4856 (3.7142)	grad_norm 6.5741 (nan)	mem 5325MB
[2022-04-21 08:43:15 tiny] (main.py 233): INFO EPOCH 234 training takes 0:12:22
[2022-04-21 08:43:27 tiny] (main.py 273): INFO Test: [0/49]	Time 12.009 (12.009)	Loss 1.4839 (1.4839)	Acc@1 69.629 (69.629)	Acc@5 89.844 (89.844)	Mem 5325MB
[2022-04-21 08:43:46 tiny] (main.py 279): INFO  * Acc@1 70.872 Acc@5 90.236
[2022-04-21 08:43:46 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 70.9%
[2022-04-21 08:43:46 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_234.pth saving......
[2022-04-21 08:43:46 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_234.pth saved !!!
[2022-04-21 08:43:46 tiny] (main.py 148): INFO Max accuracy: 70.87%
[2022-04-21 08:43:58 tiny] (main.py 226): INFO Train: [235/300][0/1251]	eta 4:08:29 lr 0.000120	time 11.9177 (11.9177)	loss 4.3767 (4.3767)	grad_norm 12.1259 (12.1259)	mem 5325MB
[2022-04-21 08:45:00 tiny] (main.py 226): INFO Train: [235/300][100/1251]	eta 0:13:58 lr 0.000120	time 0.5343 (0.7282)	loss 2.6668 (3.7127)	grad_norm 5.3787 (7.1982)	mem 5325MB
[2022-04-21 08:45:59 tiny] (main.py 226): INFO Train: [235/300][200/1251]	eta 0:11:31 lr 0.000120	time 0.4951 (0.6584)	loss 4.3757 (3.7796)	grad_norm 5.1927 (7.3533)	mem 5325MB
[2022-04-21 08:46:57 tiny] (main.py 226): INFO Train: [235/300][300/1251]	eta 0:10:02 lr 0.000120	time 0.3623 (0.6334)	loss 3.6040 (3.7282)	grad_norm 8.7191 (7.0805)	mem 5325MB
[2022-04-21 08:47:55 tiny] (main.py 226): INFO Train: [235/300][400/1251]	eta 0:08:48 lr 0.000119	time 0.5152 (0.6213)	loss 3.9307 (3.7418)	grad_norm 5.4904 (7.2725)	mem 5325MB
[2022-04-21 08:48:54 tiny] (main.py 226): INFO Train: [235/300][500/1251]	eta 0:07:42 lr 0.000119	time 0.8842 (0.6152)	loss 2.5630 (3.7179)	grad_norm 5.9217 (7.1440)	mem 5325MB
[2022-04-21 08:49:53 tiny] (main.py 226): INFO Train: [235/300][600/1251]	eta 0:06:37 lr 0.000119	time 0.6784 (0.6099)	loss 2.5137 (3.7210)	grad_norm 8.9557 (7.0629)	mem 5325MB
[2022-04-21 08:50:52 tiny] (main.py 226): INFO Train: [235/300][700/1251]	eta 0:05:34 lr 0.000118	time 0.6176 (0.6068)	loss 3.4545 (3.7258)	grad_norm 4.9632 (7.0942)	mem 5325MB
[2022-04-21 08:51:51 tiny] (main.py 226): INFO Train: [235/300][800/1251]	eta 0:04:32 lr 0.000118	time 0.4713 (0.6046)	loss 4.0713 (3.7236)	grad_norm 12.0121 (7.1355)	mem 5325MB
[2022-04-21 08:52:50 tiny] (main.py 226): INFO Train: [235/300][900/1251]	eta 0:03:31 lr 0.000118	time 0.7264 (0.6034)	loss 3.1455 (3.7190)	grad_norm 5.9309 (7.0539)	mem 5325MB
[2022-04-21 08:53:49 tiny] (main.py 226): INFO Train: [235/300][1000/1251]	eta 0:02:31 lr 0.000118	time 0.3901 (0.6018)	loss 4.0264 (3.7222)	grad_norm 9.5695 (7.1410)	mem 5325MB
[2022-04-21 08:54:48 tiny] (main.py 226): INFO Train: [235/300][1100/1251]	eta 0:01:30 lr 0.000117	time 0.7940 (0.6012)	loss 3.7430 (3.7146)	grad_norm 6.0053 (7.1084)	mem 5325MB
[2022-04-21 08:55:47 tiny] (main.py 226): INFO Train: [235/300][1200/1251]	eta 0:00:30 lr 0.000117	time 0.6131 (0.6001)	loss 4.1194 (3.7131)	grad_norm 11.4360 (7.1556)	mem 5325MB
[2022-04-21 08:56:09 tiny] (main.py 233): INFO EPOCH 235 training takes 0:12:22
[2022-04-21 08:56:21 tiny] (main.py 273): INFO Test: [0/49]	Time 11.745 (11.745)	Loss 1.4554 (1.4554)	Acc@1 72.754 (72.754)	Acc@5 90.137 (90.137)	Mem 5325MB
[2022-04-21 08:56:40 tiny] (main.py 279): INFO  * Acc@1 71.024 Acc@5 90.198
[2022-04-21 08:56:40 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 71.0%
[2022-04-21 08:56:40 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_235.pth saving......
[2022-04-21 08:56:40 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_235.pth saved !!!
[2022-04-21 08:56:40 tiny] (main.py 148): INFO Max accuracy: 71.02%
[2022-04-21 08:56:51 tiny] (main.py 226): INFO Train: [236/300][0/1251]	eta 3:46:51 lr 0.000117	time 10.8806 (10.8806)	loss 2.4859 (2.4859)	grad_norm 7.1524 (7.1524)	mem 5325MB
[2022-04-21 08:57:54 tiny] (main.py 226): INFO Train: [236/300][100/1251]	eta 0:14:03 lr 0.000117	time 0.7224 (0.7325)	loss 3.9963 (3.6064)	grad_norm 11.0115 (7.2241)	mem 5325MB
[2022-04-21 08:58:52 tiny] (main.py 226): INFO Train: [236/300][200/1251]	eta 0:11:31 lr 0.000117	time 0.7027 (0.6579)	loss 3.9493 (3.6880)	grad_norm 13.0510 (7.3759)	mem 5325MB
[2022-04-21 08:59:51 tiny] (main.py 226): INFO Train: [236/300][300/1251]	eta 0:10:02 lr 0.000116	time 0.6333 (0.6341)	loss 3.3949 (3.7051)	grad_norm 4.6825 (7.4022)	mem 5325MB
[2022-04-21 09:00:49 tiny] (main.py 226): INFO Train: [236/300][400/1251]	eta 0:08:49 lr 0.000116	time 0.6402 (0.6222)	loss 3.5248 (3.7081)	grad_norm 7.7864 (7.2145)	mem 5325MB
[2022-04-21 09:01:48 tiny] (main.py 226): INFO Train: [236/300][500/1251]	eta 0:07:41 lr 0.000116	time 0.6925 (0.6148)	loss 3.3242 (3.7116)	grad_norm 6.8508 (7.1731)	mem 5325MB
[2022-04-21 09:02:47 tiny] (main.py 226): INFO Train: [236/300][600/1251]	eta 0:06:37 lr 0.000116	time 0.4933 (0.6103)	loss 3.8576 (3.7067)	grad_norm 6.1876 (nan)	mem 5325MB
[2022-04-21 09:03:46 tiny] (main.py 226): INFO Train: [236/300][700/1251]	eta 0:05:34 lr 0.000115	time 0.5484 (0.6072)	loss 4.1001 (3.7194)	grad_norm 4.4627 (nan)	mem 5325MB
[2022-04-21 09:04:45 tiny] (main.py 226): INFO Train: [236/300][800/1251]	eta 0:04:32 lr 0.000115	time 0.5110 (0.6050)	loss 3.7268 (3.7213)	grad_norm 8.0390 (nan)	mem 5325MB
[2022-04-21 09:05:43 tiny] (main.py 226): INFO Train: [236/300][900/1251]	eta 0:03:31 lr 0.000115	time 0.6768 (0.6032)	loss 4.0325 (3.7259)	grad_norm 9.4435 (nan)	mem 5325MB
[2022-04-21 09:06:42 tiny] (main.py 226): INFO Train: [236/300][1000/1251]	eta 0:02:31 lr 0.000115	time 0.5537 (0.6019)	loss 3.8952 (3.7245)	grad_norm 6.9599 (nan)	mem 5325MB
[2022-04-21 09:07:41 tiny] (main.py 226): INFO Train: [236/300][1100/1251]	eta 0:01:30 lr 0.000114	time 0.4565 (0.6000)	loss 2.4487 (3.7227)	grad_norm 7.5793 (nan)	mem 5325MB
[2022-04-21 09:08:40 tiny] (main.py 226): INFO Train: [236/300][1200/1251]	eta 0:00:30 lr 0.000114	time 0.6793 (0.5996)	loss 4.0662 (3.7207)	grad_norm 4.6296 (nan)	mem 5325MB
[2022-04-21 09:09:02 tiny] (main.py 233): INFO EPOCH 236 training takes 0:12:21
[2022-04-21 09:09:14 tiny] (main.py 273): INFO Test: [0/49]	Time 12.321 (12.321)	Loss 1.4810 (1.4810)	Acc@1 70.996 (70.996)	Acc@5 89.355 (89.355)	Mem 5325MB
[2022-04-21 09:09:33 tiny] (main.py 279): INFO  * Acc@1 71.004 Acc@5 90.234
[2022-04-21 09:09:33 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 71.0%
[2022-04-21 09:09:33 tiny] (main.py 148): INFO Max accuracy: 71.02%
[2022-04-21 09:09:45 tiny] (main.py 226): INFO Train: [237/300][0/1251]	eta 4:08:37 lr 0.000114	time 11.9241 (11.9241)	loss 3.4540 (3.4540)	grad_norm 3.6684 (3.6684)	mem 5325MB
[2022-04-21 09:10:47 tiny] (main.py 226): INFO Train: [237/300][100/1251]	eta 0:14:01 lr 0.000114	time 0.6727 (0.7315)	loss 3.6729 (3.6971)	grad_norm 8.5039 (7.2398)	mem 5325MB
[2022-04-21 09:11:46 tiny] (main.py 226): INFO Train: [237/300][200/1251]	eta 0:11:33 lr 0.000113	time 0.6002 (0.6599)	loss 3.4641 (3.7091)	grad_norm 7.1624 (7.3074)	mem 5325MB
[2022-04-21 09:12:44 tiny] (main.py 226): INFO Train: [237/300][300/1251]	eta 0:10:03 lr 0.000113	time 0.4512 (0.6345)	loss 4.0626 (3.7358)	grad_norm 8.1311 (7.2431)	mem 5325MB
[2022-04-21 09:13:42 tiny] (main.py 226): INFO Train: [237/300][400/1251]	eta 0:08:49 lr 0.000113	time 0.5808 (0.6219)	loss 3.0698 (3.7182)	grad_norm 12.7042 (7.4432)	mem 5325MB
[2022-04-21 09:14:41 tiny] (main.py 226): INFO Train: [237/300][500/1251]	eta 0:07:42 lr 0.000113	time 0.5521 (0.6156)	loss 3.6102 (3.7367)	grad_norm 4.8484 (7.4745)	mem 5325MB
[2022-04-21 09:15:40 tiny] (main.py 226): INFO Train: [237/300][600/1251]	eta 0:06:37 lr 0.000112	time 0.5088 (0.6112)	loss 2.5872 (3.7160)	grad_norm 4.4620 (7.5538)	mem 5325MB
[2022-04-21 09:16:39 tiny] (main.py 226): INFO Train: [237/300][700/1251]	eta 0:05:35 lr 0.000112	time 0.4526 (0.6083)	loss 3.5638 (3.7168)	grad_norm 8.6842 (7.4751)	mem 5325MB
[2022-04-21 09:17:39 tiny] (main.py 226): INFO Train: [237/300][800/1251]	eta 0:04:33 lr 0.000112	time 0.4010 (0.6063)	loss 3.6291 (3.7049)	grad_norm 8.1616 (7.4574)	mem 5325MB
[2022-04-21 09:18:38 tiny] (main.py 226): INFO Train: [237/300][900/1251]	eta 0:03:32 lr 0.000112	time 0.8415 (0.6046)	loss 4.3201 (3.7005)	grad_norm 5.2978 (7.3844)	mem 5325MB
[2022-04-21 09:19:36 tiny] (main.py 226): INFO Train: [237/300][1000/1251]	eta 0:02:31 lr 0.000111	time 0.5972 (0.6025)	loss 3.8138 (3.7040)	grad_norm 7.7543 (7.3837)	mem 5325MB
[2022-04-21 09:20:35 tiny] (main.py 226): INFO Train: [237/300][1100/1251]	eta 0:01:30 lr 0.000111	time 0.5962 (0.6012)	loss 3.9484 (3.7134)	grad_norm 7.0631 (7.3637)	mem 5325MB
[2022-04-21 09:21:34 tiny] (main.py 226): INFO Train: [237/300][1200/1251]	eta 0:00:30 lr 0.000111	time 0.5616 (0.6001)	loss 4.5315 (3.7167)	grad_norm 8.2024 (7.3396)	mem 5325MB
[2022-04-21 09:21:56 tiny] (main.py 233): INFO EPOCH 237 training takes 0:12:22
[2022-04-21 09:22:07 tiny] (main.py 273): INFO Test: [0/49]	Time 11.462 (11.462)	Loss 1.5532 (1.5532)	Acc@1 69.336 (69.336)	Acc@5 88.281 (88.281)	Mem 5325MB
[2022-04-21 09:22:27 tiny] (main.py 279): INFO  * Acc@1 71.050 Acc@5 90.198
[2022-04-21 09:22:27 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 71.1%
[2022-04-21 09:22:27 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_237.pth saving......
[2022-04-21 09:22:27 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_237.pth saved !!!
[2022-04-21 09:22:27 tiny] (main.py 148): INFO Max accuracy: 71.05%
[2022-04-21 09:22:38 tiny] (main.py 226): INFO Train: [238/300][0/1251]	eta 3:58:56 lr 0.000111	time 11.4600 (11.4600)	loss 3.9520 (3.9520)	grad_norm 9.6812 (9.6812)	mem 5325MB
[2022-04-21 09:23:41 tiny] (main.py 226): INFO Train: [238/300][100/1251]	eta 0:14:00 lr 0.000110	time 0.5356 (0.7298)	loss 3.7674 (3.7217)	grad_norm 4.8808 (nan)	mem 5325MB
[2022-04-21 09:24:39 tiny] (main.py 226): INFO Train: [238/300][200/1251]	eta 0:11:29 lr 0.000110	time 0.5882 (0.6565)	loss 2.5697 (3.6880)	grad_norm 8.1504 (nan)	mem 5325MB
[2022-04-21 09:25:37 tiny] (main.py 226): INFO Train: [238/300][300/1251]	eta 0:10:01 lr 0.000110	time 0.4305 (0.6330)	loss 4.0106 (3.6961)	grad_norm 4.7519 (nan)	mem 5325MB
[2022-04-21 09:26:36 tiny] (main.py 226): INFO Train: [238/300][400/1251]	eta 0:08:48 lr 0.000110	time 0.5489 (0.6214)	loss 3.2498 (3.6715)	grad_norm 8.4769 (nan)	mem 5325MB
[2022-04-21 09:27:35 tiny] (main.py 226): INFO Train: [238/300][500/1251]	eta 0:07:41 lr 0.000109	time 0.5489 (0.6141)	loss 3.9075 (3.6641)	grad_norm 6.8260 (nan)	mem 5325MB
[2022-04-21 09:28:33 tiny] (main.py 226): INFO Train: [238/300][600/1251]	eta 0:06:36 lr 0.000109	time 0.7031 (0.6093)	loss 3.4482 (3.6597)	grad_norm 6.2053 (nan)	mem 5325MB
[2022-04-21 09:29:32 tiny] (main.py 226): INFO Train: [238/300][700/1251]	eta 0:05:34 lr 0.000109	time 0.8876 (0.6070)	loss 4.4970 (3.6816)	grad_norm 8.8981 (nan)	mem 5325MB
[2022-04-21 09:30:31 tiny] (main.py 226): INFO Train: [238/300][800/1251]	eta 0:04:32 lr 0.000109	time 0.6395 (0.6044)	loss 2.9189 (3.6870)	grad_norm 9.9651 (nan)	mem 5325MB
[2022-04-21 09:31:30 tiny] (main.py 226): INFO Train: [238/300][900/1251]	eta 0:03:31 lr 0.000108	time 0.5684 (0.6031)	loss 2.8657 (3.6927)	grad_norm 20.9480 (nan)	mem 5325MB
[2022-04-21 09:32:29 tiny] (main.py 226): INFO Train: [238/300][1000/1251]	eta 0:02:31 lr 0.000108	time 0.6872 (0.6019)	loss 3.9154 (3.6959)	grad_norm 6.5139 (nan)	mem 5325MB
[2022-04-21 09:33:28 tiny] (main.py 226): INFO Train: [238/300][1100/1251]	eta 0:01:30 lr 0.000108	time 0.6363 (0.6004)	loss 3.7704 (3.6982)	grad_norm 5.9773 (nan)	mem 5325MB
[2022-04-21 09:34:27 tiny] (main.py 226): INFO Train: [238/300][1200/1251]	eta 0:00:30 lr 0.000108	time 0.3802 (0.5993)	loss 4.1354 (3.7020)	grad_norm nan (nan)	mem 5325MB
[2022-04-21 09:34:51 tiny] (main.py 233): INFO EPOCH 238 training takes 0:12:23
[2022-04-21 09:35:02 tiny] (main.py 273): INFO Test: [0/49]	Time 10.938 (10.938)	Loss 1.4075 (1.4075)	Acc@1 71.777 (71.777)	Acc@5 91.309 (91.309)	Mem 5325MB
[2022-04-21 09:35:21 tiny] (main.py 279): INFO  * Acc@1 70.808 Acc@5 90.184
[2022-04-21 09:35:21 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 70.8%
[2022-04-21 09:35:21 tiny] (main.py 148): INFO Max accuracy: 71.05%
[2022-04-21 09:35:33 tiny] (main.py 226): INFO Train: [239/300][0/1251]	eta 3:57:29 lr 0.000108	time 11.3903 (11.3903)	loss 3.9752 (3.9752)	grad_norm 10.3169 (10.3169)	mem 5325MB
[2022-04-21 09:36:35 tiny] (main.py 226): INFO Train: [239/300][100/1251]	eta 0:14:01 lr 0.000107	time 0.7361 (0.7312)	loss 4.0274 (3.6095)	grad_norm 24.5417 (8.0659)	mem 5325MB
[2022-04-21 09:37:33 tiny] (main.py 226): INFO Train: [239/300][200/1251]	eta 0:11:30 lr 0.000107	time 0.6903 (0.6568)	loss 4.0011 (3.6434)	grad_norm 11.9518 (8.2132)	mem 5325MB
[2022-04-21 09:38:32 tiny] (main.py 226): INFO Train: [239/300][300/1251]	eta 0:10:01 lr 0.000107	time 0.6371 (0.6327)	loss 3.8382 (3.6634)	grad_norm 5.3813 (7.8821)	mem 5325MB
[2022-04-21 09:39:31 tiny] (main.py 226): INFO Train: [239/300][400/1251]	eta 0:08:49 lr 0.000107	time 0.6933 (0.6219)	loss 3.0084 (3.6630)	grad_norm 6.6310 (7.9515)	mem 5325MB
[2022-04-21 09:40:29 tiny] (main.py 226): INFO Train: [239/300][500/1251]	eta 0:07:41 lr 0.000106	time 0.7134 (0.6151)	loss 4.1843 (3.6610)	grad_norm 9.2185 (7.8044)	mem 5325MB
[2022-04-21 09:41:28 tiny] (main.py 226): INFO Train: [239/300][600/1251]	eta 0:06:37 lr 0.000106	time 0.4142 (0.6107)	loss 3.2341 (3.6755)	grad_norm 7.4319 (7.6947)	mem 5325MB
[2022-04-21 09:42:27 tiny] (main.py 226): INFO Train: [239/300][700/1251]	eta 0:05:34 lr 0.000106	time 0.7026 (0.6072)	loss 4.1818 (3.6897)	grad_norm 6.8996 (7.5974)	mem 5325MB
[2022-04-21 09:43:26 tiny] (main.py 226): INFO Train: [239/300][800/1251]	eta 0:04:33 lr 0.000106	time 0.7448 (0.6056)	loss 3.7947 (3.7017)	grad_norm 5.9187 (7.5163)	mem 5325MB
[2022-04-21 09:44:25 tiny] (main.py 226): INFO Train: [239/300][900/1251]	eta 0:03:31 lr 0.000105	time 0.6678 (0.6036)	loss 3.9188 (3.7078)	grad_norm 13.0595 (7.4564)	mem 5325MB
[2022-04-21 09:45:24 tiny] (main.py 226): INFO Train: [239/300][1000/1251]	eta 0:02:31 lr 0.000105	time 0.7058 (0.6020)	loss 4.1312 (3.7035)	grad_norm 7.5233 (7.3992)	mem 5325MB
[2022-04-21 09:46:23 tiny] (main.py 226): INFO Train: [239/300][1100/1251]	eta 0:01:30 lr 0.000105	time 0.4489 (0.6007)	loss 3.5326 (3.7007)	grad_norm 10.1943 (7.4340)	mem 5325MB
[2022-04-21 09:47:22 tiny] (main.py 226): INFO Train: [239/300][1200/1251]	eta 0:00:30 lr 0.000105	time 0.6614 (0.6003)	loss 4.5242 (3.7025)	grad_norm 7.0097 (7.4311)	mem 5325MB
[2022-04-21 09:47:45 tiny] (main.py 233): INFO EPOCH 239 training takes 0:12:23
[2022-04-21 09:47:56 tiny] (main.py 273): INFO Test: [0/49]	Time 11.661 (11.661)	Loss 1.4227 (1.4227)	Acc@1 72.168 (72.168)	Acc@5 90.234 (90.234)	Mem 5325MB
[2022-04-21 09:48:16 tiny] (main.py 279): INFO  * Acc@1 71.170 Acc@5 90.276
[2022-04-21 09:48:16 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 71.2%
[2022-04-21 09:48:16 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_239.pth saving......
[2022-04-21 09:48:16 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_239.pth saved !!!
[2022-04-21 09:48:16 tiny] (main.py 148): INFO Max accuracy: 71.17%
[2022-04-21 09:48:26 tiny] (main.py 226): INFO Train: [240/300][0/1251]	eta 3:36:02 lr 0.000105	time 10.3621 (10.3621)	loss 3.9814 (3.9814)	grad_norm 5.6448 (5.6448)	mem 5325MB
[2022-04-21 09:49:29 tiny] (main.py 226): INFO Train: [240/300][100/1251]	eta 0:13:57 lr 0.000104	time 0.6247 (0.7281)	loss 2.6646 (3.6689)	grad_norm 6.2755 (6.5651)	mem 5325MB
[2022-04-21 09:50:28 tiny] (main.py 226): INFO Train: [240/300][200/1251]	eta 0:11:32 lr 0.000104	time 0.5449 (0.6587)	loss 2.5033 (3.6977)	grad_norm 5.2925 (7.3105)	mem 5325MB
[2022-04-21 09:51:27 tiny] (main.py 226): INFO Train: [240/300][300/1251]	eta 0:10:03 lr 0.000104	time 0.6195 (0.6346)	loss 4.1229 (3.7123)	grad_norm 7.1727 (7.3227)	mem 5325MB
[2022-04-21 09:52:25 tiny] (main.py 226): INFO Train: [240/300][400/1251]	eta 0:08:49 lr 0.000104	time 0.7955 (0.6224)	loss 4.4361 (3.7386)	grad_norm 5.7445 (7.5354)	mem 5325MB
[2022-04-21 09:53:24 tiny] (main.py 226): INFO Train: [240/300][500/1251]	eta 0:07:41 lr 0.000103	time 0.5088 (0.6147)	loss 3.7740 (3.7415)	grad_norm 4.2316 (7.5352)	mem 5325MB
[2022-04-21 09:54:22 tiny] (main.py 226): INFO Train: [240/300][600/1251]	eta 0:06:37 lr 0.000103	time 0.5068 (0.6103)	loss 3.3311 (3.7419)	grad_norm 12.3917 (7.4956)	mem 5325MB
[2022-04-21 09:55:21 tiny] (main.py 226): INFO Train: [240/300][700/1251]	eta 0:05:34 lr 0.000103	time 0.6177 (0.6073)	loss 3.7889 (3.7258)	grad_norm 4.8926 (7.4725)	mem 5325MB
[2022-04-21 09:56:20 tiny] (main.py 226): INFO Train: [240/300][800/1251]	eta 0:04:32 lr 0.000103	time 0.7042 (0.6044)	loss 3.8838 (3.7171)	grad_norm 4.8616 (7.6059)	mem 5325MB
[2022-04-21 09:57:19 tiny] (main.py 226): INFO Train: [240/300][900/1251]	eta 0:03:31 lr 0.000102	time 0.4400 (0.6026)	loss 3.2128 (3.7183)	grad_norm 8.4809 (7.5639)	mem 5325MB
[2022-04-21 09:58:18 tiny] (main.py 226): INFO Train: [240/300][1000/1251]	eta 0:02:30 lr 0.000102	time 0.6247 (0.6015)	loss 3.5168 (3.7227)	grad_norm 5.4250 (7.5659)	mem 5325MB
[2022-04-21 09:59:17 tiny] (main.py 226): INFO Train: [240/300][1100/1251]	eta 0:01:30 lr 0.000102	time 0.6391 (0.6003)	loss 4.6681 (3.7148)	grad_norm 6.0461 (7.6255)	mem 5325MB
[2022-04-21 10:00:15 tiny] (main.py 226): INFO Train: [240/300][1200/1251]	eta 0:00:30 lr 0.000102	time 0.6790 (0.5994)	loss 2.8227 (3.7122)	grad_norm 8.6603 (7.5301)	mem 5325MB
[2022-04-21 10:00:38 tiny] (main.py 233): INFO EPOCH 240 training takes 0:12:22
[2022-04-21 10:00:50 tiny] (main.py 273): INFO Test: [0/49]	Time 12.065 (12.065)	Loss 1.4554 (1.4554)	Acc@1 70.117 (70.117)	Acc@5 90.137 (90.137)	Mem 5325MB
[2022-04-21 10:01:09 tiny] (main.py 279): INFO  * Acc@1 71.184 Acc@5 90.412
[2022-04-21 10:01:09 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 71.2%
[2022-04-21 10:01:09 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_240.pth saving......
[2022-04-21 10:01:09 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_240.pth saved !!!
[2022-04-21 10:01:09 tiny] (main.py 148): INFO Max accuracy: 71.18%
[2022-04-21 10:01:21 tiny] (main.py 226): INFO Train: [241/300][0/1251]	eta 4:07:41 lr 0.000102	time 11.8798 (11.8798)	loss 4.0205 (4.0205)	grad_norm 11.7281 (11.7281)	mem 5325MB
[2022-04-21 10:02:22 tiny] (main.py 226): INFO Train: [241/300][100/1251]	eta 0:13:56 lr 0.000101	time 0.6698 (0.7268)	loss 3.9805 (3.7691)	grad_norm 7.1148 (7.5746)	mem 5325MB
[2022-04-21 10:03:21 tiny] (main.py 226): INFO Train: [241/300][200/1251]	eta 0:11:31 lr 0.000101	time 0.7096 (0.6582)	loss 4.5447 (3.7317)	grad_norm 6.0795 (7.3458)	mem 5325MB
[2022-04-21 10:04:19 tiny] (main.py 226): INFO Train: [241/300][300/1251]	eta 0:10:01 lr 0.000101	time 0.6356 (0.6325)	loss 4.0908 (3.7302)	grad_norm 6.1439 (7.2277)	mem 5325MB
[2022-04-21 10:05:18 tiny] (main.py 226): INFO Train: [241/300][400/1251]	eta 0:08:48 lr 0.000101	time 0.5426 (0.6212)	loss 4.2397 (3.7160)	grad_norm 6.4126 (7.3394)	mem 5325MB
[2022-04-21 10:06:17 tiny] (main.py 226): INFO Train: [241/300][500/1251]	eta 0:07:41 lr 0.000100	time 0.5462 (0.6141)	loss 3.4321 (3.6892)	grad_norm 8.2697 (7.5744)	mem 5325MB
[2022-04-21 10:07:15 tiny] (main.py 226): INFO Train: [241/300][600/1251]	eta 0:06:36 lr 0.000100	time 0.5861 (0.6096)	loss 3.9666 (3.6860)	grad_norm 15.2828 (7.6265)	mem 5325MB
[2022-04-21 10:08:14 tiny] (main.py 226): INFO Train: [241/300][700/1251]	eta 0:05:34 lr 0.000100	time 0.5081 (0.6067)	loss 3.8568 (3.6900)	grad_norm 4.7781 (7.6122)	mem 5325MB
[2022-04-21 10:09:13 tiny] (main.py 226): INFO Train: [241/300][800/1251]	eta 0:04:32 lr 0.000100	time 0.5276 (0.6047)	loss 3.2169 (3.6844)	grad_norm 6.0895 (7.6406)	mem 5325MB
[2022-04-21 10:10:13 tiny] (main.py 226): INFO Train: [241/300][900/1251]	eta 0:03:31 lr 0.000099	time 0.5767 (0.6034)	loss 3.2249 (3.6729)	grad_norm 9.3949 (7.6453)	mem 5325MB
[2022-04-21 10:11:12 tiny] (main.py 226): INFO Train: [241/300][1000/1251]	eta 0:02:31 lr 0.000099	time 0.6299 (0.6020)	loss 2.7977 (3.6830)	grad_norm 5.9885 (7.5582)	mem 5325MB
[2022-04-21 10:12:11 tiny] (main.py 226): INFO Train: [241/300][1100/1251]	eta 0:01:30 lr 0.000099	time 0.8356 (0.6011)	loss 3.5751 (3.6837)	grad_norm 6.9131 (7.5680)	mem 5325MB
[2022-04-21 10:13:10 tiny] (main.py 226): INFO Train: [241/300][1200/1251]	eta 0:00:30 lr 0.000099	time 0.7304 (0.6001)	loss 4.1073 (3.6943)	grad_norm 6.0504 (7.5375)	mem 5325MB
[2022-04-21 10:13:32 tiny] (main.py 233): INFO EPOCH 241 training takes 0:12:22
[2022-04-21 10:13:43 tiny] (main.py 273): INFO Test: [0/49]	Time 11.307 (11.307)	Loss 1.5428 (1.5428)	Acc@1 70.508 (70.508)	Acc@5 88.477 (88.477)	Mem 5325MB
[2022-04-21 10:14:03 tiny] (main.py 279): INFO  * Acc@1 70.974 Acc@5 90.168
[2022-04-21 10:14:03 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 71.0%
[2022-04-21 10:14:03 tiny] (main.py 148): INFO Max accuracy: 71.18%
[2022-04-21 10:14:13 tiny] (main.py 226): INFO Train: [242/300][0/1251]	eta 3:43:51 lr 0.000099	time 10.7369 (10.7369)	loss 3.9125 (3.9125)	grad_norm 4.5879 (4.5879)	mem 5325MB
[2022-04-21 10:15:16 tiny] (main.py 226): INFO Train: [242/300][100/1251]	eta 0:14:01 lr 0.000098	time 0.5325 (0.7310)	loss 4.2136 (3.7416)	grad_norm 5.5512 (6.9083)	mem 5325MB
[2022-04-21 10:16:16 tiny] (main.py 226): INFO Train: [242/300][200/1251]	eta 0:11:35 lr 0.000098	time 0.6921 (0.6614)	loss 4.1102 (3.7121)	grad_norm 4.1272 (7.2380)	mem 5325MB
[2022-04-21 10:17:14 tiny] (main.py 226): INFO Train: [242/300][300/1251]	eta 0:10:04 lr 0.000098	time 0.5958 (0.6359)	loss 2.8418 (3.6966)	grad_norm 8.7112 (nan)	mem 5325MB
[2022-04-21 10:18:12 tiny] (main.py 226): INFO Train: [242/300][400/1251]	eta 0:08:50 lr 0.000098	time 0.5587 (0.6229)	loss 3.7226 (3.6939)	grad_norm 8.7217 (nan)	mem 5325MB
[2022-04-21 10:19:11 tiny] (main.py 226): INFO Train: [242/300][500/1251]	eta 0:07:42 lr 0.000097	time 0.6800 (0.6158)	loss 2.8991 (3.6909)	grad_norm 8.8099 (nan)	mem 5325MB
[2022-04-21 10:20:10 tiny] (main.py 226): INFO Train: [242/300][600/1251]	eta 0:06:37 lr 0.000097	time 0.4734 (0.6111)	loss 4.5929 (3.7053)	grad_norm 5.6405 (nan)	mem 5325MB
[2022-04-21 10:21:08 tiny] (main.py 226): INFO Train: [242/300][700/1251]	eta 0:05:34 lr 0.000097	time 0.5148 (0.6073)	loss 2.7979 (3.7070)	grad_norm 8.0069 (nan)	mem 5325MB
[2022-04-21 10:22:07 tiny] (main.py 226): INFO Train: [242/300][800/1251]	eta 0:04:32 lr 0.000097	time 0.4376 (0.6052)	loss 3.4442 (3.7165)	grad_norm 7.4815 (nan)	mem 5325MB
[2022-04-21 10:23:07 tiny] (main.py 226): INFO Train: [242/300][900/1251]	eta 0:03:31 lr 0.000096	time 0.6356 (0.6037)	loss 3.7348 (3.7135)	grad_norm 22.2683 (nan)	mem 5325MB
[2022-04-21 10:24:05 tiny] (main.py 226): INFO Train: [242/300][1000/1251]	eta 0:02:31 lr 0.000096	time 0.4297 (0.6020)	loss 4.0863 (3.7139)	grad_norm 4.6085 (nan)	mem 5325MB
[2022-04-21 10:25:04 tiny] (main.py 226): INFO Train: [242/300][1100/1251]	eta 0:01:30 lr 0.000096	time 0.5521 (0.6009)	loss 4.3387 (3.7136)	grad_norm 7.7327 (nan)	mem 5325MB
[2022-04-21 10:26:03 tiny] (main.py 226): INFO Train: [242/300][1200/1251]	eta 0:00:30 lr 0.000096	time 0.6603 (0.6002)	loss 4.3192 (3.7197)	grad_norm 5.0680 (nan)	mem 5325MB
[2022-04-21 10:26:25 tiny] (main.py 233): INFO EPOCH 242 training takes 0:12:22
[2022-04-21 10:26:38 tiny] (main.py 273): INFO Test: [0/49]	Time 12.192 (12.192)	Loss 1.5122 (1.5122)	Acc@1 70.215 (70.215)	Acc@5 89.844 (89.844)	Mem 5325MB
[2022-04-21 10:26:56 tiny] (main.py 279): INFO  * Acc@1 71.368 Acc@5 90.206
[2022-04-21 10:26:56 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 71.4%
[2022-04-21 10:26:56 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_242.pth saving......
[2022-04-21 10:26:56 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_242.pth saved !!!
[2022-04-21 10:26:56 tiny] (main.py 148): INFO Max accuracy: 71.37%
[2022-04-21 10:27:08 tiny] (main.py 226): INFO Train: [243/300][0/1251]	eta 4:05:12 lr 0.000096	time 11.7602 (11.7602)	loss 3.7314 (3.7314)	grad_norm 5.9203 (5.9203)	mem 5325MB
[2022-04-21 10:28:10 tiny] (main.py 226): INFO Train: [243/300][100/1251]	eta 0:13:56 lr 0.000095	time 0.6497 (0.7269)	loss 2.7494 (3.6804)	grad_norm 12.1696 (7.8476)	mem 5325MB
[2022-04-21 10:29:09 tiny] (main.py 226): INFO Train: [243/300][200/1251]	eta 0:11:30 lr 0.000095	time 0.5570 (0.6572)	loss 4.0815 (3.7271)	grad_norm 9.7485 (7.5609)	mem 5325MB
[2022-04-21 10:30:07 tiny] (main.py 226): INFO Train: [243/300][300/1251]	eta 0:10:03 lr 0.000095	time 0.5941 (0.6346)	loss 3.6081 (3.7468)	grad_norm 12.9322 (7.4095)	mem 5325MB
[2022-04-21 10:31:06 tiny] (main.py 226): INFO Train: [243/300][400/1251]	eta 0:08:49 lr 0.000095	time 0.5429 (0.6219)	loss 4.2788 (3.7466)	grad_norm 8.3328 (7.6925)	mem 5325MB
[2022-04-21 10:32:05 tiny] (main.py 226): INFO Train: [243/300][500/1251]	eta 0:07:42 lr 0.000094	time 0.8115 (0.6154)	loss 3.9899 (3.7454)	grad_norm 5.4324 (7.5756)	mem 5325MB
[2022-04-21 10:33:03 tiny] (main.py 226): INFO Train: [243/300][600/1251]	eta 0:06:37 lr 0.000094	time 0.4922 (0.6106)	loss 4.2723 (3.7249)	grad_norm 6.3554 (7.4672)	mem 5325MB
[2022-04-21 10:34:02 tiny] (main.py 226): INFO Train: [243/300][700/1251]	eta 0:05:34 lr 0.000094	time 0.5920 (0.6074)	loss 4.5851 (3.7327)	grad_norm 6.7990 (7.4374)	mem 5325MB
[2022-04-21 10:35:01 tiny] (main.py 226): INFO Train: [243/300][800/1251]	eta 0:04:32 lr 0.000094	time 0.5128 (0.6047)	loss 3.4233 (3.7253)	grad_norm 4.6570 (7.4627)	mem 5325MB
[2022-04-21 10:36:00 tiny] (main.py 226): INFO Train: [243/300][900/1251]	eta 0:03:31 lr 0.000094	time 0.5109 (0.6034)	loss 3.5894 (3.7334)	grad_norm 6.4597 (7.4737)	mem 5325MB
[2022-04-21 10:36:59 tiny] (main.py 226): INFO Train: [243/300][1000/1251]	eta 0:02:31 lr 0.000093	time 0.5963 (0.6022)	loss 4.5659 (3.7320)	grad_norm 10.2130 (7.5687)	mem 5325MB
[2022-04-21 10:37:58 tiny] (main.py 226): INFO Train: [243/300][1100/1251]	eta 0:01:30 lr 0.000093	time 0.5155 (0.6010)	loss 2.4926 (3.7266)	grad_norm 10.9851 (7.5236)	mem 5325MB
[2022-04-21 10:38:57 tiny] (main.py 226): INFO Train: [243/300][1200/1251]	eta 0:00:30 lr 0.000093	time 0.7210 (0.5999)	loss 3.0166 (3.7199)	grad_norm 5.8971 (7.6138)	mem 5325MB
[2022-04-21 10:39:20 tiny] (main.py 233): INFO EPOCH 243 training takes 0:12:23
[2022-04-21 10:39:31 tiny] (main.py 273): INFO Test: [0/49]	Time 11.544 (11.544)	Loss 1.4362 (1.4362)	Acc@1 72.559 (72.559)	Acc@5 90.527 (90.527)	Mem 5325MB
[2022-04-21 10:39:50 tiny] (main.py 279): INFO  * Acc@1 71.272 Acc@5 90.386
[2022-04-21 10:39:50 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 71.3%
[2022-04-21 10:39:50 tiny] (main.py 148): INFO Max accuracy: 71.37%
[2022-04-21 10:40:03 tiny] (main.py 226): INFO Train: [244/300][0/1251]	eta 4:15:42 lr 0.000093	time 12.2641 (12.2641)	loss 3.4353 (3.4353)	grad_norm 4.4648 (4.4648)	mem 5325MB
[2022-04-21 10:41:04 tiny] (main.py 226): INFO Train: [244/300][100/1251]	eta 0:14:03 lr 0.000092	time 0.6894 (0.7331)	loss 3.4434 (3.6904)	grad_norm 5.7409 (7.1784)	mem 5325MB
[2022-04-21 10:42:02 tiny] (main.py 226): INFO Train: [244/300][200/1251]	eta 0:11:30 lr 0.000092	time 0.4881 (0.6574)	loss 2.3494 (3.7372)	grad_norm 4.6797 (7.6308)	mem 5325MB
[2022-04-21 10:43:02 tiny] (main.py 226): INFO Train: [244/300][300/1251]	eta 0:10:04 lr 0.000092	time 0.7256 (0.6355)	loss 4.5987 (3.7214)	grad_norm 11.1436 (7.7245)	mem 5325MB
[2022-04-21 10:44:00 tiny] (main.py 226): INFO Train: [244/300][400/1251]	eta 0:08:50 lr 0.000092	time 0.6962 (0.6235)	loss 4.3786 (3.7284)	grad_norm 4.2208 (7.6546)	mem 5325MB
[2022-04-21 10:44:59 tiny] (main.py 226): INFO Train: [244/300][500/1251]	eta 0:07:42 lr 0.000092	time 0.6473 (0.6153)	loss 4.0328 (3.7284)	grad_norm 6.9525 (7.5479)	mem 5325MB
[2022-04-21 10:45:57 tiny] (main.py 226): INFO Train: [244/300][600/1251]	eta 0:06:37 lr 0.000091	time 0.7296 (0.6107)	loss 3.9576 (3.7397)	grad_norm 12.1893 (7.6043)	mem 5325MB
[2022-04-21 10:46:56 tiny] (main.py 226): INFO Train: [244/300][700/1251]	eta 0:05:34 lr 0.000091	time 0.5019 (0.6074)	loss 3.0606 (3.7269)	grad_norm 7.9609 (7.6003)	mem 5325MB
[2022-04-21 10:47:56 tiny] (main.py 226): INFO Train: [244/300][800/1251]	eta 0:04:33 lr 0.000091	time 0.6986 (0.6062)	loss 4.4049 (3.7179)	grad_norm 7.1644 (7.5851)	mem 5325MB
[2022-04-21 10:48:54 tiny] (main.py 226): INFO Train: [244/300][900/1251]	eta 0:03:31 lr 0.000091	time 0.5657 (0.6038)	loss 3.6462 (3.7144)	grad_norm 7.4497 (7.6927)	mem 5325MB
[2022-04-21 10:49:53 tiny] (main.py 226): INFO Train: [244/300][1000/1251]	eta 0:02:31 lr 0.000090	time 0.6451 (0.6021)	loss 3.7771 (3.7074)	grad_norm 7.3581 (7.7017)	mem 5325MB
[2022-04-21 10:50:52 tiny] (main.py 226): INFO Train: [244/300][1100/1251]	eta 0:01:30 lr 0.000090	time 0.7404 (0.6009)	loss 3.7652 (3.7099)	grad_norm 9.0578 (7.6733)	mem 5325MB
[2022-04-21 10:51:51 tiny] (main.py 226): INFO Train: [244/300][1200/1251]	eta 0:00:30 lr 0.000090	time 0.6448 (0.5999)	loss 3.8076 (3.7212)	grad_norm 6.0344 (7.6303)	mem 5325MB
[2022-04-21 10:52:13 tiny] (main.py 233): INFO EPOCH 244 training takes 0:12:23
[2022-04-21 10:52:26 tiny] (main.py 273): INFO Test: [0/49]	Time 12.103 (12.103)	Loss 1.3741 (1.3741)	Acc@1 71.484 (71.484)	Acc@5 90.820 (90.820)	Mem 5325MB
[2022-04-21 10:52:44 tiny] (main.py 279): INFO  * Acc@1 71.468 Acc@5 90.454
[2022-04-21 10:52:44 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 71.5%
[2022-04-21 10:52:44 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_244.pth saving......
[2022-04-21 10:52:44 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_244.pth saved !!!
[2022-04-21 10:52:44 tiny] (main.py 148): INFO Max accuracy: 71.47%
[2022-04-21 10:52:55 tiny] (main.py 226): INFO Train: [245/300][0/1251]	eta 3:51:10 lr 0.000090	time 11.0879 (11.0879)	loss 2.5539 (2.5539)	grad_norm 6.6075 (6.6075)	mem 5325MB
[2022-04-21 10:53:58 tiny] (main.py 226): INFO Train: [245/300][100/1251]	eta 0:14:00 lr 0.000090	time 0.7589 (0.7302)	loss 3.9270 (3.6583)	grad_norm 9.3143 (7.4283)	mem 5325MB
[2022-04-21 10:54:56 tiny] (main.py 226): INFO Train: [245/300][200/1251]	eta 0:11:31 lr 0.000089	time 0.6835 (0.6576)	loss 3.4837 (3.6610)	grad_norm 6.8868 (7.2298)	mem 5325MB
[2022-04-21 10:55:55 tiny] (main.py 226): INFO Train: [245/300][300/1251]	eta 0:10:01 lr 0.000089	time 0.4742 (0.6328)	loss 4.0798 (3.6731)	grad_norm 5.4055 (7.4401)	mem 5325MB
[2022-04-21 10:56:54 tiny] (main.py 226): INFO Train: [245/300][400/1251]	eta 0:08:49 lr 0.000089	time 0.6632 (0.6224)	loss 4.4377 (3.7158)	grad_norm 5.1235 (7.5940)	mem 5325MB
[2022-04-21 10:57:52 tiny] (main.py 226): INFO Train: [245/300][500/1251]	eta 0:07:42 lr 0.000089	time 0.6444 (0.6153)	loss 4.6339 (3.7249)	grad_norm 5.8000 (7.5941)	mem 5325MB
[2022-04-21 10:58:51 tiny] (main.py 226): INFO Train: [245/300][600/1251]	eta 0:06:37 lr 0.000089	time 0.5364 (0.6108)	loss 3.7822 (3.7151)	grad_norm 5.2818 (7.6376)	mem 5325MB
[2022-04-21 10:59:50 tiny] (main.py 226): INFO Train: [245/300][700/1251]	eta 0:05:35 lr 0.000088	time 0.5221 (0.6081)	loss 3.6587 (3.7260)	grad_norm 5.8085 (7.7493)	mem 5325MB
[2022-04-21 11:00:49 tiny] (main.py 226): INFO Train: [245/300][800/1251]	eta 0:04:33 lr 0.000088	time 0.6168 (0.6059)	loss 3.0726 (3.7084)	grad_norm 11.2877 (7.7617)	mem 5325MB
[2022-04-21 11:01:48 tiny] (main.py 226): INFO Train: [245/300][900/1251]	eta 0:03:31 lr 0.000088	time 0.7497 (0.6038)	loss 3.8828 (3.7225)	grad_norm 6.5534 (7.7938)	mem 5325MB
[2022-04-21 11:02:47 tiny] (main.py 226): INFO Train: [245/300][1000/1251]	eta 0:02:31 lr 0.000088	time 0.6759 (0.6025)	loss 3.6825 (3.7209)	grad_norm 4.8077 (7.8128)	mem 5325MB
[2022-04-21 11:03:46 tiny] (main.py 226): INFO Train: [245/300][1100/1251]	eta 0:01:30 lr 0.000087	time 0.5649 (0.6010)	loss 3.6285 (3.7157)	grad_norm 8.3463 (7.8191)	mem 5325MB
[2022-04-21 11:04:45 tiny] (main.py 226): INFO Train: [245/300][1200/1251]	eta 0:00:30 lr 0.000087	time 0.5858 (0.5998)	loss 4.3640 (3.7048)	grad_norm 7.7103 (7.8718)	mem 5325MB
[2022-04-21 11:05:07 tiny] (main.py 233): INFO EPOCH 245 training takes 0:12:22
[2022-04-21 11:05:18 tiny] (main.py 273): INFO Test: [0/49]	Time 11.019 (11.019)	Loss 1.4355 (1.4355)	Acc@1 72.656 (72.656)	Acc@5 91.504 (91.504)	Mem 5325MB
[2022-04-21 11:05:38 tiny] (main.py 279): INFO  * Acc@1 71.480 Acc@5 90.416
[2022-04-21 11:05:38 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 71.5%
[2022-04-21 11:05:38 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_245.pth saving......
[2022-04-21 11:05:38 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_245.pth saved !!!
[2022-04-21 11:05:38 tiny] (main.py 148): INFO Max accuracy: 71.48%
[2022-04-21 11:05:50 tiny] (main.py 226): INFO Train: [246/300][0/1251]	eta 4:09:59 lr 0.000087	time 11.9898 (11.9898)	loss 4.2037 (4.2037)	grad_norm 8.1942 (8.1942)	mem 5325MB
[2022-04-21 11:06:51 tiny] (main.py 226): INFO Train: [246/300][100/1251]	eta 0:13:56 lr 0.000087	time 0.4675 (0.7265)	loss 3.4946 (3.6957)	grad_norm 6.4606 (7.4244)	mem 5325MB
[2022-04-21 11:07:50 tiny] (main.py 226): INFO Train: [246/300][200/1251]	eta 0:11:27 lr 0.000087	time 0.4446 (0.6544)	loss 3.8040 (3.6849)	grad_norm 7.3059 (7.5612)	mem 5325MB
[2022-04-21 11:08:48 tiny] (main.py 226): INFO Train: [246/300][300/1251]	eta 0:10:01 lr 0.000086	time 0.5594 (0.6326)	loss 4.5946 (3.7085)	grad_norm 9.2125 (nan)	mem 5325MB
[2022-04-21 11:09:47 tiny] (main.py 226): INFO Train: [246/300][400/1251]	eta 0:08:48 lr 0.000086	time 0.4831 (0.6213)	loss 4.3270 (3.7240)	grad_norm 7.4522 (nan)	mem 5325MB
[2022-04-21 11:10:46 tiny] (main.py 226): INFO Train: [246/300][500/1251]	eta 0:07:41 lr 0.000086	time 0.5318 (0.6148)	loss 2.6173 (3.6974)	grad_norm 7.4896 (nan)	mem 5325MB
[2022-04-21 11:11:45 tiny] (main.py 226): INFO Train: [246/300][600/1251]	eta 0:06:37 lr 0.000086	time 0.4799 (0.6104)	loss 4.0750 (3.6954)	grad_norm 6.4789 (nan)	mem 5325MB
[2022-04-21 11:12:44 tiny] (main.py 226): INFO Train: [246/300][700/1251]	eta 0:05:34 lr 0.000086	time 0.4438 (0.6073)	loss 3.5109 (3.7049)	grad_norm 7.8175 (nan)	mem 5325MB
[2022-04-21 11:13:43 tiny] (main.py 226): INFO Train: [246/300][800/1251]	eta 0:04:32 lr 0.000085	time 0.4679 (0.6050)	loss 2.5233 (3.7003)	grad_norm 5.8941 (nan)	mem 5325MB
[2022-04-21 11:14:41 tiny] (main.py 226): INFO Train: [246/300][900/1251]	eta 0:03:31 lr 0.000085	time 0.4973 (0.6029)	loss 3.4953 (3.7148)	grad_norm 5.4035 (nan)	mem 5325MB
[2022-04-21 11:15:40 tiny] (main.py 226): INFO Train: [246/300][1000/1251]	eta 0:02:30 lr 0.000085	time 0.6442 (0.6016)	loss 3.1355 (3.7139)	grad_norm 9.0815 (nan)	mem 5325MB
[2022-04-21 11:16:39 tiny] (main.py 226): INFO Train: [246/300][1100/1251]	eta 0:01:30 lr 0.000085	time 0.5219 (0.6008)	loss 3.2874 (3.7157)	grad_norm 7.0424 (nan)	mem 5325MB
[2022-04-21 11:17:38 tiny] (main.py 226): INFO Train: [246/300][1200/1251]	eta 0:00:30 lr 0.000084	time 0.7884 (0.5998)	loss 2.6559 (3.7162)	grad_norm 10.5195 (nan)	mem 5325MB
[2022-04-21 11:18:01 tiny] (main.py 233): INFO EPOCH 246 training takes 0:12:22
[2022-04-21 11:18:13 tiny] (main.py 273): INFO Test: [0/49]	Time 11.963 (11.963)	Loss 1.5003 (1.5003)	Acc@1 70.508 (70.508)	Acc@5 89.844 (89.844)	Mem 5325MB
[2022-04-21 11:18:32 tiny] (main.py 279): INFO  * Acc@1 71.466 Acc@5 90.384
[2022-04-21 11:18:32 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 71.5%
[2022-04-21 11:18:32 tiny] (main.py 148): INFO Max accuracy: 71.48%
[2022-04-21 11:18:44 tiny] (main.py 226): INFO Train: [247/300][0/1251]	eta 4:07:06 lr 0.000084	time 11.8518 (11.8518)	loss 3.8176 (3.8176)	grad_norm 4.7041 (4.7041)	mem 5325MB
[2022-04-21 11:19:46 tiny] (main.py 226): INFO Train: [247/300][100/1251]	eta 0:14:03 lr 0.000084	time 0.3835 (0.7332)	loss 4.4680 (3.7823)	grad_norm 6.9074 (8.8020)	mem 5325MB
[2022-04-21 11:20:44 tiny] (main.py 226): INFO Train: [247/300][200/1251]	eta 0:11:33 lr 0.000084	time 0.6157 (0.6601)	loss 2.4542 (3.6958)	grad_norm 16.3719 (8.6863)	mem 5325MB
[2022-04-21 11:21:43 tiny] (main.py 226): INFO Train: [247/300][300/1251]	eta 0:10:04 lr 0.000084	time 0.6610 (0.6358)	loss 3.8417 (3.6698)	grad_norm 15.7830 (8.2465)	mem 5325MB
[2022-04-21 11:22:42 tiny] (main.py 226): INFO Train: [247/300][400/1251]	eta 0:08:50 lr 0.000083	time 0.5928 (0.6231)	loss 3.6211 (3.6677)	grad_norm 7.1834 (8.1553)	mem 5325MB
[2022-04-21 11:23:40 tiny] (main.py 226): INFO Train: [247/300][500/1251]	eta 0:07:42 lr 0.000083	time 0.5450 (0.6158)	loss 3.5914 (3.6722)	grad_norm 8.3952 (8.1563)	mem 5325MB
[2022-04-21 11:24:39 tiny] (main.py 226): INFO Train: [247/300][600/1251]	eta 0:06:37 lr 0.000083	time 0.6743 (0.6113)	loss 3.4770 (3.6745)	grad_norm 8.8558 (8.3065)	mem 5325MB
[2022-04-21 11:25:37 tiny] (main.py 226): INFO Train: [247/300][700/1251]	eta 0:05:34 lr 0.000083	time 0.5112 (0.6073)	loss 3.3353 (3.6671)	grad_norm 8.9731 (8.1301)	mem 5325MB
[2022-04-21 11:26:36 tiny] (main.py 226): INFO Train: [247/300][800/1251]	eta 0:04:32 lr 0.000083	time 0.3607 (0.6050)	loss 3.2126 (3.6595)	grad_norm 6.5744 (8.0698)	mem 5325MB
[2022-04-21 11:27:36 tiny] (main.py 226): INFO Train: [247/300][900/1251]	eta 0:03:31 lr 0.000082	time 0.5578 (0.6036)	loss 4.4522 (3.6592)	grad_norm 5.0358 (8.0355)	mem 5325MB
[2022-04-21 11:28:35 tiny] (main.py 226): INFO Train: [247/300][1000/1251]	eta 0:02:31 lr 0.000082	time 0.6064 (0.6025)	loss 2.9481 (3.6619)	grad_norm 9.0419 (8.1060)	mem 5325MB
[2022-04-21 11:29:33 tiny] (main.py 226): INFO Train: [247/300][1100/1251]	eta 0:01:30 lr 0.000082	time 0.6440 (0.6009)	loss 3.8393 (3.6637)	grad_norm 7.0290 (8.0704)	mem 5325MB
[2022-04-21 11:30:32 tiny] (main.py 226): INFO Train: [247/300][1200/1251]	eta 0:00:30 lr 0.000082	time 0.4413 (0.5997)	loss 4.4809 (3.6645)	grad_norm 11.6585 (8.1199)	mem 5325MB
[2022-04-21 11:30:54 tiny] (main.py 233): INFO EPOCH 247 training takes 0:12:22
[2022-04-21 11:31:05 tiny] (main.py 273): INFO Test: [0/49]	Time 10.755 (10.755)	Loss 1.5423 (1.5423)	Acc@1 69.727 (69.727)	Acc@5 88.770 (88.770)	Mem 5325MB
[2022-04-21 11:31:25 tiny] (main.py 279): INFO  * Acc@1 71.644 Acc@5 90.526
[2022-04-21 11:31:25 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 71.6%
[2022-04-21 11:31:25 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_247.pth saving......
[2022-04-21 11:31:25 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_247.pth saved !!!
[2022-04-21 11:31:25 tiny] (main.py 148): INFO Max accuracy: 71.64%
[2022-04-21 11:31:36 tiny] (main.py 226): INFO Train: [248/300][0/1251]	eta 3:41:00 lr 0.000082	time 10.5998 (10.5998)	loss 4.0551 (4.0551)	grad_norm 8.5585 (8.5585)	mem 5325MB
[2022-04-21 11:32:38 tiny] (main.py 226): INFO Train: [248/300][100/1251]	eta 0:13:56 lr 0.000081	time 0.4741 (0.7272)	loss 3.7195 (3.7895)	grad_norm 6.1178 (8.3697)	mem 5325MB
[2022-04-21 11:33:37 tiny] (main.py 226): INFO Train: [248/300][200/1251]	eta 0:11:30 lr 0.000081	time 0.7418 (0.6567)	loss 3.7763 (3.7245)	grad_norm 11.7476 (7.8024)	mem 5325MB
[2022-04-21 11:34:36 tiny] (main.py 226): INFO Train: [248/300][300/1251]	eta 0:10:03 lr 0.000081	time 0.6459 (0.6346)	loss 3.6473 (3.7317)	grad_norm 4.8059 (7.7305)	mem 5325MB
[2022-04-21 11:35:35 tiny] (main.py 226): INFO Train: [248/300][400/1251]	eta 0:08:49 lr 0.000081	time 0.6380 (0.6225)	loss 2.7640 (3.6956)	grad_norm 5.7552 (7.8283)	mem 5325MB
[2022-04-21 11:36:33 tiny] (main.py 226): INFO Train: [248/300][500/1251]	eta 0:07:41 lr 0.000081	time 0.5752 (0.6147)	loss 3.8032 (3.7065)	grad_norm 4.2124 (7.7847)	mem 5325MB
[2022-04-21 11:37:32 tiny] (main.py 226): INFO Train: [248/300][600/1251]	eta 0:06:37 lr 0.000080	time 0.5447 (0.6102)	loss 3.4762 (3.6964)	grad_norm 6.0486 (7.7510)	mem 5325MB
[2022-04-21 11:38:30 tiny] (main.py 226): INFO Train: [248/300][700/1251]	eta 0:05:34 lr 0.000080	time 0.4407 (0.6070)	loss 4.5628 (3.6807)	grad_norm 4.1839 (7.8515)	mem 5325MB
[2022-04-21 11:39:30 tiny] (main.py 226): INFO Train: [248/300][800/1251]	eta 0:04:33 lr 0.000080	time 0.6433 (0.6053)	loss 4.3915 (3.6897)	grad_norm 5.1917 (7.8318)	mem 5325MB
[2022-04-21 11:40:29 tiny] (main.py 226): INFO Train: [248/300][900/1251]	eta 0:03:31 lr 0.000080	time 0.5564 (0.6038)	loss 3.9114 (3.6851)	grad_norm 4.8196 (7.8047)	mem 5325MB
[2022-04-21 11:41:28 tiny] (main.py 226): INFO Train: [248/300][1000/1251]	eta 0:02:31 lr 0.000079	time 0.6179 (0.6021)	loss 3.0465 (3.6721)	grad_norm 5.4183 (7.8199)	mem 5325MB
[2022-04-21 11:42:27 tiny] (main.py 226): INFO Train: [248/300][1100/1251]	eta 0:01:30 lr 0.000079	time 1.0004 (0.6015)	loss 3.9782 (3.6762)	grad_norm 8.6134 (7.8948)	mem 5325MB
[2022-04-21 11:43:25 tiny] (main.py 226): INFO Train: [248/300][1200/1251]	eta 0:00:30 lr 0.000079	time 0.5503 (0.5999)	loss 2.5322 (3.6737)	grad_norm 5.2041 (7.8932)	mem 5325MB
[2022-04-21 11:43:48 tiny] (main.py 233): INFO EPOCH 248 training takes 0:12:22
[2022-04-21 11:43:59 tiny] (main.py 273): INFO Test: [0/49]	Time 11.675 (11.675)	Loss 1.5319 (1.5319)	Acc@1 69.727 (69.727)	Acc@5 91.211 (91.211)	Mem 5325MB
[2022-04-21 11:44:18 tiny] (main.py 279): INFO  * Acc@1 71.700 Acc@5 90.486
[2022-04-21 11:44:18 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 71.7%
[2022-04-21 11:44:18 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_248.pth saving......
[2022-04-21 11:44:19 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_248.pth saved !!!
[2022-04-21 11:44:19 tiny] (main.py 148): INFO Max accuracy: 71.70%
[2022-04-21 11:44:30 tiny] (main.py 226): INFO Train: [249/300][0/1251]	eta 4:02:23 lr 0.000079	time 11.6253 (11.6253)	loss 3.5873 (3.5873)	grad_norm 5.5011 (5.5011)	mem 5325MB
[2022-04-21 11:45:33 tiny] (main.py 226): INFO Train: [249/300][100/1251]	eta 0:14:06 lr 0.000079	time 0.7658 (0.7352)	loss 3.5169 (3.7169)	grad_norm 5.0019 (7.7885)	mem 5325MB
[2022-04-21 11:46:31 tiny] (main.py 226): INFO Train: [249/300][200/1251]	eta 0:11:31 lr 0.000079	time 0.5197 (0.6583)	loss 2.6599 (3.6815)	grad_norm 7.0174 (8.0869)	mem 5325MB
[2022-04-21 11:47:30 tiny] (main.py 226): INFO Train: [249/300][300/1251]	eta 0:10:03 lr 0.000078	time 0.6150 (0.6348)	loss 3.8773 (3.6787)	grad_norm 10.7564 (7.8000)	mem 5325MB
[2022-04-21 11:48:28 tiny] (main.py 226): INFO Train: [249/300][400/1251]	eta 0:08:50 lr 0.000078	time 0.6667 (0.6231)	loss 3.5674 (3.6915)	grad_norm 4.3829 (7.9191)	mem 5325MB
[2022-04-21 11:49:27 tiny] (main.py 226): INFO Train: [249/300][500/1251]	eta 0:07:42 lr 0.000078	time 0.6493 (0.6160)	loss 2.5480 (3.6939)	grad_norm 6.8052 (8.0671)	mem 5325MB
[2022-04-21 11:50:26 tiny] (main.py 226): INFO Train: [249/300][600/1251]	eta 0:06:37 lr 0.000078	time 0.5701 (0.6110)	loss 3.7800 (3.7027)	grad_norm 10.6106 (8.1017)	mem 5325MB
[2022-04-21 11:51:24 tiny] (main.py 226): INFO Train: [249/300][700/1251]	eta 0:05:34 lr 0.000077	time 0.4172 (0.6076)	loss 2.2396 (3.6860)	grad_norm 7.1702 (8.0784)	mem 5325MB
[2022-04-21 11:52:23 tiny] (main.py 226): INFO Train: [249/300][800/1251]	eta 0:04:32 lr 0.000077	time 0.4358 (0.6047)	loss 3.3884 (3.6811)	grad_norm 7.6621 (8.1547)	mem 5325MB
[2022-04-21 11:53:22 tiny] (main.py 226): INFO Train: [249/300][900/1251]	eta 0:03:31 lr 0.000077	time 0.5073 (0.6029)	loss 3.4163 (3.6792)	grad_norm 9.6488 (8.0967)	mem 5325MB
[2022-04-21 11:54:20 tiny] (main.py 226): INFO Train: [249/300][1000/1251]	eta 0:02:30 lr 0.000077	time 0.5372 (0.6013)	loss 3.8885 (3.6860)	grad_norm 5.6383 (8.0711)	mem 5325MB
[2022-04-21 11:55:19 tiny] (main.py 226): INFO Train: [249/300][1100/1251]	eta 0:01:30 lr 0.000077	time 0.5251 (0.6003)	loss 4.1097 (3.6824)	grad_norm 10.0777 (8.0022)	mem 5325MB
[2022-04-21 11:56:19 tiny] (main.py 226): INFO Train: [249/300][1200/1251]	eta 0:00:30 lr 0.000076	time 0.5504 (0.5995)	loss 3.6187 (3.6821)	grad_norm 14.2601 (8.0225)	mem 5325MB
[2022-04-21 11:56:41 tiny] (main.py 233): INFO EPOCH 249 training takes 0:12:22
[2022-04-21 11:56:52 tiny] (main.py 273): INFO Test: [0/49]	Time 10.948 (10.948)	Loss 1.4097 (1.4097)	Acc@1 71.582 (71.582)	Acc@5 89.648 (89.648)	Mem 5325MB
[2022-04-21 11:57:12 tiny] (main.py 279): INFO  * Acc@1 71.774 Acc@5 90.660
[2022-04-21 11:57:12 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 71.8%
[2022-04-21 11:57:12 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_249.pth saving......
[2022-04-21 11:57:12 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_249.pth saved !!!
[2022-04-21 11:57:12 tiny] (main.py 148): INFO Max accuracy: 71.77%
[2022-04-21 11:57:24 tiny] (main.py 226): INFO Train: [250/300][0/1251]	eta 4:14:09 lr 0.000076	time 12.1896 (12.1896)	loss 4.2499 (4.2499)	grad_norm 9.7494 (9.7494)	mem 5325MB
[2022-04-21 11:58:25 tiny] (main.py 226): INFO Train: [250/300][100/1251]	eta 0:13:54 lr 0.000076	time 0.4980 (0.7254)	loss 3.9102 (3.8119)	grad_norm 10.6052 (7.3638)	mem 5325MB
[2022-04-21 11:59:24 tiny] (main.py 226): INFO Train: [250/300][200/1251]	eta 0:11:29 lr 0.000076	time 0.5943 (0.6565)	loss 4.1181 (3.7374)	grad_norm 6.7522 (7.7887)	mem 5325MB
[2022-04-21 12:00:22 tiny] (main.py 226): INFO Train: [250/300][300/1251]	eta 0:10:01 lr 0.000076	time 0.5245 (0.6322)	loss 3.2746 (3.7101)	grad_norm 8.6250 (7.9034)	mem 5325MB
[2022-04-21 12:01:21 tiny] (main.py 226): INFO Train: [250/300][400/1251]	eta 0:08:48 lr 0.000075	time 0.4887 (0.6209)	loss 3.9018 (3.7128)	grad_norm 10.4440 (8.2747)	mem 5325MB
[2022-04-21 12:02:19 tiny] (main.py 226): INFO Train: [250/300][500/1251]	eta 0:07:40 lr 0.000075	time 0.5876 (0.6137)	loss 2.4512 (3.7045)	grad_norm 6.6319 (8.0472)	mem 5325MB
[2022-04-21 12:03:18 tiny] (main.py 226): INFO Train: [250/300][600/1251]	eta 0:06:37 lr 0.000075	time 0.6712 (0.6099)	loss 3.8637 (3.6996)	grad_norm 8.6314 (nan)	mem 5325MB
[2022-04-21 12:04:17 tiny] (main.py 226): INFO Train: [250/300][700/1251]	eta 0:05:34 lr 0.000075	time 0.7015 (0.6068)	loss 3.9608 (3.6975)	grad_norm 5.2034 (nan)	mem 5325MB
[2022-04-21 12:05:16 tiny] (main.py 226): INFO Train: [250/300][800/1251]	eta 0:04:32 lr 0.000075	time 0.6863 (0.6047)	loss 3.9693 (3.6914)	grad_norm 5.1906 (nan)	mem 5325MB
[2022-04-21 12:06:15 tiny] (main.py 226): INFO Train: [250/300][900/1251]	eta 0:03:31 lr 0.000074	time 0.5496 (0.6026)	loss 3.6110 (3.6843)	grad_norm 18.8936 (nan)	mem 5325MB
[2022-04-21 12:07:14 tiny] (main.py 226): INFO Train: [250/300][1000/1251]	eta 0:02:30 lr 0.000074	time 0.4719 (0.6012)	loss 4.3258 (3.6770)	grad_norm 5.6853 (nan)	mem 5325MB
[2022-04-21 12:08:12 tiny] (main.py 226): INFO Train: [250/300][1100/1251]	eta 0:01:30 lr 0.000074	time 0.5294 (0.6000)	loss 2.6192 (3.6761)	grad_norm 7.5265 (nan)	mem 5325MB
[2022-04-21 12:09:12 tiny] (main.py 226): INFO Train: [250/300][1200/1251]	eta 0:00:30 lr 0.000074	time 0.7659 (0.5993)	loss 4.2750 (3.6713)	grad_norm 6.2705 (nan)	mem 5325MB
[2022-04-21 12:09:34 tiny] (main.py 233): INFO EPOCH 250 training takes 0:12:21
[2022-04-21 12:09:45 tiny] (main.py 273): INFO Test: [0/49]	Time 11.629 (11.629)	Loss 1.4547 (1.4547)	Acc@1 71.289 (71.289)	Acc@5 90.039 (90.039)	Mem 5325MB
[2022-04-21 12:10:05 tiny] (main.py 279): INFO  * Acc@1 71.598 Acc@5 90.600
[2022-04-21 12:10:05 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 71.6%
[2022-04-21 12:10:05 tiny] (main.py 148): INFO Max accuracy: 71.77%
[2022-04-21 12:10:16 tiny] (main.py 226): INFO Train: [251/300][0/1251]	eta 3:50:26 lr 0.000074	time 11.0526 (11.0526)	loss 2.6183 (2.6183)	grad_norm 11.6965 (11.6965)	mem 5325MB
[2022-04-21 12:11:19 tiny] (main.py 226): INFO Train: [251/300][100/1251]	eta 0:14:04 lr 0.000074	time 0.5334 (0.7334)	loss 3.9333 (3.7580)	grad_norm 5.9921 (8.0740)	mem 5325MB
[2022-04-21 12:12:17 tiny] (main.py 226): INFO Train: [251/300][200/1251]	eta 0:11:33 lr 0.000073	time 0.5922 (0.6600)	loss 3.9017 (3.7015)	grad_norm 10.6067 (7.9681)	mem 5325MB
[2022-04-21 12:13:16 tiny] (main.py 226): INFO Train: [251/300][300/1251]	eta 0:10:04 lr 0.000073	time 0.7073 (0.6351)	loss 4.0804 (3.6930)	grad_norm 18.1940 (7.8054)	mem 5325MB
[2022-04-21 12:14:14 tiny] (main.py 226): INFO Train: [251/300][400/1251]	eta 0:08:50 lr 0.000073	time 0.4835 (0.6231)	loss 4.0924 (3.6576)	grad_norm 10.3022 (7.9612)	mem 5325MB
[2022-04-21 12:15:13 tiny] (main.py 226): INFO Train: [251/300][500/1251]	eta 0:07:42 lr 0.000073	time 0.5415 (0.6160)	loss 4.1238 (3.6690)	grad_norm 6.2874 (7.9857)	mem 5325MB
[2022-04-21 12:16:12 tiny] (main.py 226): INFO Train: [251/300][600/1251]	eta 0:06:38 lr 0.000073	time 0.6708 (0.6116)	loss 3.2943 (3.6798)	grad_norm 5.7314 (7.9661)	mem 5325MB
[2022-04-21 12:17:11 tiny] (main.py 226): INFO Train: [251/300][700/1251]	eta 0:05:35 lr 0.000072	time 0.6180 (0.6084)	loss 3.5957 (3.6730)	grad_norm 9.5649 (7.9201)	mem 5325MB
[2022-04-21 12:18:10 tiny] (main.py 226): INFO Train: [251/300][800/1251]	eta 0:04:33 lr 0.000072	time 0.4940 (0.6056)	loss 4.0618 (3.6764)	grad_norm 5.9338 (7.9750)	mem 5325MB
[2022-04-21 12:19:09 tiny] (main.py 226): INFO Train: [251/300][900/1251]	eta 0:03:32 lr 0.000072	time 0.7678 (0.6041)	loss 3.9316 (3.6683)	grad_norm 8.6856 (7.9338)	mem 5325MB
[2022-04-21 12:20:07 tiny] (main.py 226): INFO Train: [251/300][1000/1251]	eta 0:02:31 lr 0.000072	time 0.4854 (0.6023)	loss 2.8791 (3.6670)	grad_norm 13.9204 (8.0454)	mem 5325MB
[2022-04-21 12:21:06 tiny] (main.py 226): INFO Train: [251/300][1100/1251]	eta 0:01:30 lr 0.000072	time 0.5771 (0.6011)	loss 2.6842 (3.6567)	grad_norm 11.8016 (8.0978)	mem 5325MB
[2022-04-21 12:22:05 tiny] (main.py 226): INFO Train: [251/300][1200/1251]	eta 0:00:30 lr 0.000071	time 0.4473 (0.6001)	loss 4.1366 (3.6595)	grad_norm 5.6138 (8.1084)	mem 5325MB
[2022-04-21 12:22:27 tiny] (main.py 233): INFO EPOCH 251 training takes 0:12:22
[2022-04-21 12:22:39 tiny] (main.py 273): INFO Test: [0/49]	Time 11.691 (11.691)	Loss 1.4673 (1.4673)	Acc@1 71.680 (71.680)	Acc@5 91.016 (91.016)	Mem 5325MB
[2022-04-21 12:22:58 tiny] (main.py 279): INFO  * Acc@1 71.732 Acc@5 90.672
[2022-04-21 12:22:58 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 71.7%
[2022-04-21 12:22:58 tiny] (main.py 148): INFO Max accuracy: 71.77%
[2022-04-21 12:23:10 tiny] (main.py 226): INFO Train: [252/300][0/1251]	eta 4:02:39 lr 0.000071	time 11.6386 (11.6386)	loss 4.2262 (4.2262)	grad_norm 5.5952 (5.5952)	mem 5325MB
[2022-04-21 12:24:12 tiny] (main.py 226): INFO Train: [252/300][100/1251]	eta 0:14:05 lr 0.000071	time 0.5908 (0.7344)	loss 3.4892 (3.6661)	grad_norm 8.8649 (8.8220)	mem 5325MB
[2022-04-21 12:25:11 tiny] (main.py 226): INFO Train: [252/300][200/1251]	eta 0:11:34 lr 0.000071	time 0.6391 (0.6604)	loss 4.0448 (3.6663)	grad_norm 5.8250 (8.2278)	mem 5325MB
[2022-04-21 12:26:09 tiny] (main.py 226): INFO Train: [252/300][300/1251]	eta 0:10:03 lr 0.000071	time 0.5658 (0.6349)	loss 3.9965 (3.6578)	grad_norm 9.7907 (8.0344)	mem 5325MB
[2022-04-21 12:27:07 tiny] (main.py 226): INFO Train: [252/300][400/1251]	eta 0:08:49 lr 0.000070	time 0.5778 (0.6220)	loss 4.1736 (3.6615)	grad_norm 13.4931 (8.0617)	mem 5325MB
[2022-04-21 12:28:07 tiny] (main.py 226): INFO Train: [252/300][500/1251]	eta 0:07:42 lr 0.000070	time 0.4513 (0.6165)	loss 3.8194 (3.6545)	grad_norm 5.7916 (8.1445)	mem 5325MB
[2022-04-21 12:29:05 tiny] (main.py 226): INFO Train: [252/300][600/1251]	eta 0:06:37 lr 0.000070	time 0.5934 (0.6113)	loss 3.1911 (3.6746)	grad_norm 7.0987 (8.1113)	mem 5325MB
[2022-04-21 12:30:04 tiny] (main.py 226): INFO Train: [252/300][700/1251]	eta 0:05:35 lr 0.000070	time 0.6510 (0.6081)	loss 4.0977 (3.6718)	grad_norm 5.6518 (8.1081)	mem 5325MB
[2022-04-21 12:31:03 tiny] (main.py 226): INFO Train: [252/300][800/1251]	eta 0:04:33 lr 0.000070	time 0.4787 (0.6060)	loss 4.1311 (3.6810)	grad_norm 12.5982 (8.1262)	mem 5325MB
[2022-04-21 12:32:03 tiny] (main.py 226): INFO Train: [252/300][900/1251]	eta 0:03:32 lr 0.000069	time 0.8255 (0.6045)	loss 2.6783 (3.6655)	grad_norm 7.5413 (8.0399)	mem 5325MB
[2022-04-21 12:33:01 tiny] (main.py 226): INFO Train: [252/300][1000/1251]	eta 0:02:31 lr 0.000069	time 0.5852 (0.6027)	loss 4.3165 (3.6606)	grad_norm 8.8622 (8.0771)	mem 5325MB
[2022-04-21 12:34:00 tiny] (main.py 226): INFO Train: [252/300][1100/1251]	eta 0:01:30 lr 0.000069	time 0.5695 (0.6015)	loss 3.9519 (3.6640)	grad_norm 6.4269 (8.0345)	mem 5325MB
[2022-04-21 12:34:59 tiny] (main.py 226): INFO Train: [252/300][1200/1251]	eta 0:00:30 lr 0.000069	time 0.7210 (0.6003)	loss 3.9402 (3.6672)	grad_norm 9.2004 (8.0395)	mem 5325MB
[2022-04-21 12:35:21 tiny] (main.py 233): INFO EPOCH 252 training takes 0:12:22
[2022-04-21 12:35:33 tiny] (main.py 273): INFO Test: [0/49]	Time 11.993 (11.993)	Loss 1.4459 (1.4459)	Acc@1 72.168 (72.168)	Acc@5 91.016 (91.016)	Mem 5325MB
[2022-04-21 12:35:52 tiny] (main.py 279): INFO  * Acc@1 71.718 Acc@5 90.668
[2022-04-21 12:35:52 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 71.7%
[2022-04-21 12:35:52 tiny] (main.py 148): INFO Max accuracy: 71.77%
[2022-04-21 12:36:04 tiny] (main.py 226): INFO Train: [253/300][0/1251]	eta 4:16:28 lr 0.000069	time 12.3011 (12.3011)	loss 3.9375 (3.9375)	grad_norm 5.7694 (5.7694)	mem 5325MB
[2022-04-21 12:37:06 tiny] (main.py 226): INFO Train: [253/300][100/1251]	eta 0:13:58 lr 0.000069	time 0.4683 (0.7288)	loss 2.8795 (3.7220)	grad_norm 5.9322 (7.8719)	mem 5325MB
[2022-04-21 12:38:04 tiny] (main.py 226): INFO Train: [253/300][200/1251]	eta 0:11:31 lr 0.000068	time 0.5229 (0.6580)	loss 4.0809 (3.6994)	grad_norm 9.7518 (8.2934)	mem 5325MB
[2022-04-21 12:39:03 tiny] (main.py 226): INFO Train: [253/300][300/1251]	eta 0:10:03 lr 0.000068	time 0.5150 (0.6343)	loss 4.0029 (3.6656)	grad_norm 7.1384 (8.4370)	mem 5325MB
[2022-04-21 12:40:02 tiny] (main.py 226): INFO Train: [253/300][400/1251]	eta 0:08:49 lr 0.000068	time 0.6004 (0.6224)	loss 4.0564 (3.6690)	grad_norm 8.5947 (8.2044)	mem 5325MB
[2022-04-21 12:41:00 tiny] (main.py 226): INFO Train: [253/300][500/1251]	eta 0:07:42 lr 0.000068	time 0.5710 (0.6153)	loss 3.8387 (3.6804)	grad_norm 9.9272 (8.2285)	mem 5325MB
[2022-04-21 12:41:59 tiny] (main.py 226): INFO Train: [253/300][600/1251]	eta 0:06:37 lr 0.000068	time 0.5854 (0.6104)	loss 4.0144 (3.6842)	grad_norm 6.5379 (8.3171)	mem 5325MB
[2022-04-21 12:42:57 tiny] (main.py 226): INFO Train: [253/300][700/1251]	eta 0:05:34 lr 0.000067	time 0.6014 (0.6070)	loss 3.6507 (3.6896)	grad_norm 5.1687 (8.2475)	mem 5325MB
[2022-04-21 12:43:56 tiny] (main.py 226): INFO Train: [253/300][800/1251]	eta 0:04:32 lr 0.000067	time 0.5347 (0.6048)	loss 3.8409 (3.6953)	grad_norm 17.6221 (8.3177)	mem 5325MB
[2022-04-21 12:44:55 tiny] (main.py 226): INFO Train: [253/300][900/1251]	eta 0:03:31 lr 0.000067	time 0.4820 (0.6032)	loss 3.8713 (3.6850)	grad_norm 8.3504 (nan)	mem 5325MB
[2022-04-21 12:45:54 tiny] (main.py 226): INFO Train: [253/300][1000/1251]	eta 0:02:31 lr 0.000067	time 0.4933 (0.6018)	loss 3.5420 (3.6867)	grad_norm 5.2989 (nan)	mem 5325MB
[2022-04-21 12:46:53 tiny] (main.py 226): INFO Train: [253/300][1100/1251]	eta 0:01:30 lr 0.000067	time 0.5014 (0.6007)	loss 3.8177 (3.6807)	grad_norm 8.7884 (nan)	mem 5325MB
[2022-04-21 12:47:52 tiny] (main.py 226): INFO Train: [253/300][1200/1251]	eta 0:00:30 lr 0.000066	time 0.5193 (0.5996)	loss 3.2273 (3.6776)	grad_norm 8.3008 (nan)	mem 5325MB
[2022-04-21 12:48:15 tiny] (main.py 233): INFO EPOCH 253 training takes 0:12:23
[2022-04-21 12:48:28 tiny] (main.py 273): INFO Test: [0/49]	Time 12.332 (12.332)	Loss 1.4987 (1.4987)	Acc@1 70.312 (70.312)	Acc@5 89.941 (89.941)	Mem 5325MB
[2022-04-21 12:48:46 tiny] (main.py 279): INFO  * Acc@1 71.706 Acc@5 90.634
[2022-04-21 12:48:46 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 71.7%
[2022-04-21 12:48:46 tiny] (main.py 148): INFO Max accuracy: 71.77%
[2022-04-21 12:48:58 tiny] (main.py 226): INFO Train: [254/300][0/1251]	eta 4:06:28 lr 0.000066	time 11.8216 (11.8216)	loss 3.9678 (3.9678)	grad_norm 7.2958 (7.2958)	mem 5325MB
[2022-04-21 12:50:00 tiny] (main.py 226): INFO Train: [254/300][100/1251]	eta 0:13:58 lr 0.000066	time 0.6430 (0.7284)	loss 3.1215 (3.6204)	grad_norm 6.8165 (7.9581)	mem 5325MB
[2022-04-21 12:50:59 tiny] (main.py 226): INFO Train: [254/300][200/1251]	eta 0:11:31 lr 0.000066	time 0.6531 (0.6580)	loss 3.6310 (3.6069)	grad_norm 6.3307 (8.2504)	mem 5325MB
[2022-04-21 12:51:57 tiny] (main.py 226): INFO Train: [254/300][300/1251]	eta 0:10:02 lr 0.000066	time 0.3952 (0.6338)	loss 3.5801 (3.6056)	grad_norm 5.8414 (8.1309)	mem 5325MB
[2022-04-21 12:52:56 tiny] (main.py 226): INFO Train: [254/300][400/1251]	eta 0:08:49 lr 0.000066	time 0.5738 (0.6224)	loss 3.6309 (3.6277)	grad_norm 8.6693 (7.9841)	mem 5325MB
[2022-04-21 12:53:55 tiny] (main.py 226): INFO Train: [254/300][500/1251]	eta 0:07:41 lr 0.000065	time 0.6033 (0.6150)	loss 2.8813 (3.6339)	grad_norm 8.0254 (7.9282)	mem 5325MB
[2022-04-21 12:54:54 tiny] (main.py 226): INFO Train: [254/300][600/1251]	eta 0:06:37 lr 0.000065	time 0.8564 (0.6113)	loss 3.8379 (3.6393)	grad_norm 8.9195 (7.8972)	mem 5325MB
[2022-04-21 12:55:53 tiny] (main.py 226): INFO Train: [254/300][700/1251]	eta 0:05:34 lr 0.000065	time 0.6796 (0.6078)	loss 3.6939 (3.6520)	grad_norm 6.1685 (8.0021)	mem 5325MB
[2022-04-21 12:56:52 tiny] (main.py 226): INFO Train: [254/300][800/1251]	eta 0:04:33 lr 0.000065	time 0.4554 (0.6057)	loss 3.6963 (3.6488)	grad_norm 18.2608 (8.1196)	mem 5325MB
[2022-04-21 12:57:50 tiny] (main.py 226): INFO Train: [254/300][900/1251]	eta 0:03:31 lr 0.000065	time 0.4456 (0.6037)	loss 2.3039 (3.6447)	grad_norm 5.5467 (8.2380)	mem 5325MB
[2022-04-21 12:58:49 tiny] (main.py 226): INFO Train: [254/300][1000/1251]	eta 0:02:31 lr 0.000064	time 0.5404 (0.6023)	loss 4.4402 (3.6403)	grad_norm 13.9461 (8.2331)	mem 5325MB
[2022-04-21 12:59:48 tiny] (main.py 226): INFO Train: [254/300][1100/1251]	eta 0:01:30 lr 0.000064	time 0.5251 (0.6012)	loss 3.6426 (3.6397)	grad_norm 5.6293 (8.4612)	mem 5325MB
[2022-04-21 13:00:47 tiny] (main.py 226): INFO Train: [254/300][1200/1251]	eta 0:00:30 lr 0.000064	time 0.4691 (0.6000)	loss 4.5155 (3.6407)	grad_norm 6.0778 (8.4109)	mem 5325MB
[2022-04-21 13:01:09 tiny] (main.py 233): INFO EPOCH 254 training takes 0:12:22
[2022-04-21 13:01:21 tiny] (main.py 273): INFO Test: [0/49]	Time 11.149 (11.149)	Loss 1.4935 (1.4935)	Acc@1 71.387 (71.387)	Acc@5 90.430 (90.430)	Mem 5325MB
[2022-04-21 13:01:40 tiny] (main.py 279): INFO  * Acc@1 71.604 Acc@5 90.584
[2022-04-21 13:01:40 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 71.6%
[2022-04-21 13:01:40 tiny] (main.py 148): INFO Max accuracy: 71.77%
[2022-04-21 13:01:51 tiny] (main.py 226): INFO Train: [255/300][0/1251]	eta 3:54:05 lr 0.000064	time 11.2278 (11.2278)	loss 3.0073 (3.0073)	grad_norm 10.1356 (10.1356)	mem 5325MB
[2022-04-21 13:02:54 tiny] (main.py 226): INFO Train: [255/300][100/1251]	eta 0:14:03 lr 0.000064	time 0.6243 (0.7326)	loss 4.0514 (3.6044)	grad_norm 6.7251 (8.0041)	mem 5325MB
[2022-04-21 13:03:53 tiny] (main.py 226): INFO Train: [255/300][200/1251]	eta 0:11:32 lr 0.000064	time 0.8785 (0.6590)	loss 3.4915 (3.6547)	grad_norm 7.1205 (7.7625)	mem 5325MB
[2022-04-21 13:04:51 tiny] (main.py 226): INFO Train: [255/300][300/1251]	eta 0:10:03 lr 0.000063	time 0.5707 (0.6346)	loss 2.5402 (3.6459)	grad_norm 14.1981 (8.3754)	mem 5325MB
[2022-04-21 13:05:50 tiny] (main.py 226): INFO Train: [255/300][400/1251]	eta 0:08:50 lr 0.000063	time 0.6283 (0.6233)	loss 3.6603 (3.6756)	grad_norm 7.2999 (8.2642)	mem 5325MB
[2022-04-21 13:06:49 tiny] (main.py 226): INFO Train: [255/300][500/1251]	eta 0:07:42 lr 0.000063	time 0.4587 (0.6161)	loss 4.1381 (3.6767)	grad_norm 5.8858 (8.2679)	mem 5325MB
[2022-04-21 13:07:48 tiny] (main.py 226): INFO Train: [255/300][600/1251]	eta 0:06:38 lr 0.000063	time 0.4668 (0.6115)	loss 3.2725 (3.6757)	grad_norm 5.5810 (8.1961)	mem 5325MB
[2022-04-21 13:08:47 tiny] (main.py 226): INFO Train: [255/300][700/1251]	eta 0:05:35 lr 0.000063	time 0.6712 (0.6084)	loss 3.3505 (3.6661)	grad_norm 11.1221 (8.2282)	mem 5325MB
[2022-04-21 13:09:46 tiny] (main.py 226): INFO Train: [255/300][800/1251]	eta 0:04:33 lr 0.000062	time 0.4560 (0.6061)	loss 2.5387 (3.6762)	grad_norm 5.1470 (8.1409)	mem 5325MB
[2022-04-21 13:10:44 tiny] (main.py 226): INFO Train: [255/300][900/1251]	eta 0:03:31 lr 0.000062	time 0.4894 (0.6039)	loss 4.4456 (3.6797)	grad_norm 5.8310 (8.2510)	mem 5325MB
[2022-04-21 13:11:43 tiny] (main.py 226): INFO Train: [255/300][1000/1251]	eta 0:02:31 lr 0.000062	time 0.5128 (0.6027)	loss 2.6665 (3.6733)	grad_norm 8.5032 (8.2650)	mem 5325MB
[2022-04-21 13:12:42 tiny] (main.py 226): INFO Train: [255/300][1100/1251]	eta 0:01:30 lr 0.000062	time 0.6301 (0.6012)	loss 3.4832 (3.6688)	grad_norm 10.4561 (8.2588)	mem 5325MB
[2022-04-21 13:13:41 tiny] (main.py 226): INFO Train: [255/300][1200/1251]	eta 0:00:30 lr 0.000062	time 0.5727 (0.6001)	loss 3.2031 (3.6706)	grad_norm 16.9833 (8.2256)	mem 5325MB
[2022-04-21 13:14:03 tiny] (main.py 233): INFO EPOCH 255 training takes 0:12:22
[2022-04-21 13:14:15 tiny] (main.py 273): INFO Test: [0/49]	Time 11.928 (11.928)	Loss 1.5243 (1.5243)	Acc@1 69.336 (69.336)	Acc@5 90.137 (90.137)	Mem 5325MB
[2022-04-21 13:14:34 tiny] (main.py 279): INFO  * Acc@1 71.884 Acc@5 90.652
[2022-04-21 13:14:34 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 71.9%
[2022-04-21 13:14:34 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_255.pth saving......
[2022-04-21 13:14:34 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_255.pth saved !!!
[2022-04-21 13:14:34 tiny] (main.py 148): INFO Max accuracy: 71.88%
[2022-04-21 13:14:45 tiny] (main.py 226): INFO Train: [256/300][0/1251]	eta 4:03:34 lr 0.000062	time 11.6825 (11.6825)	loss 2.5324 (2.5324)	grad_norm 7.5898 (7.5898)	mem 5325MB
[2022-04-21 13:15:48 tiny] (main.py 226): INFO Train: [256/300][100/1251]	eta 0:14:01 lr 0.000061	time 0.6042 (0.7309)	loss 3.0966 (3.7007)	grad_norm 6.4227 (7.6568)	mem 5325MB
[2022-04-21 13:16:47 tiny] (main.py 226): INFO Train: [256/300][200/1251]	eta 0:11:34 lr 0.000061	time 0.6680 (0.6605)	loss 4.4569 (3.6716)	grad_norm 8.1607 (8.1132)	mem 5325MB
[2022-04-21 13:17:45 tiny] (main.py 226): INFO Train: [256/300][300/1251]	eta 0:10:04 lr 0.000061	time 0.6770 (0.6353)	loss 3.7943 (3.6695)	grad_norm 4.9948 (nan)	mem 5325MB
[2022-04-21 13:18:43 tiny] (main.py 226): INFO Train: [256/300][400/1251]	eta 0:08:49 lr 0.000061	time 0.5100 (0.6227)	loss 3.5965 (3.6367)	grad_norm 4.9015 (nan)	mem 5325MB
[2022-04-21 13:19:42 tiny] (main.py 226): INFO Train: [256/300][500/1251]	eta 0:07:42 lr 0.000061	time 0.5040 (0.6156)	loss 4.3689 (3.6428)	grad_norm 8.7977 (nan)	mem 5325MB
[2022-04-21 13:20:41 tiny] (main.py 226): INFO Train: [256/300][600/1251]	eta 0:06:37 lr 0.000061	time 0.7039 (0.6113)	loss 3.4989 (3.6451)	grad_norm 8.7050 (nan)	mem 5325MB
[2022-04-21 13:21:40 tiny] (main.py 226): INFO Train: [256/300][700/1251]	eta 0:05:34 lr 0.000060	time 0.4831 (0.6074)	loss 2.8215 (3.6473)	grad_norm 6.9844 (nan)	mem 5325MB
[2022-04-21 13:22:39 tiny] (main.py 226): INFO Train: [256/300][800/1251]	eta 0:04:32 lr 0.000060	time 0.5260 (0.6053)	loss 3.3453 (3.6439)	grad_norm 5.1726 (nan)	mem 5325MB
[2022-04-21 13:23:38 tiny] (main.py 226): INFO Train: [256/300][900/1251]	eta 0:03:31 lr 0.000060	time 1.3135 (0.6039)	loss 3.6390 (3.6435)	grad_norm 8.7726 (nan)	mem 5325MB
[2022-04-21 13:24:36 tiny] (main.py 226): INFO Train: [256/300][1000/1251]	eta 0:02:31 lr 0.000060	time 0.5886 (0.6020)	loss 2.9703 (3.6405)	grad_norm 5.0950 (nan)	mem 5325MB
[2022-04-21 13:25:35 tiny] (main.py 226): INFO Train: [256/300][1100/1251]	eta 0:01:30 lr 0.000060	time 0.6023 (0.6007)	loss 3.8572 (3.6441)	grad_norm 7.2291 (nan)	mem 5325MB
[2022-04-21 13:26:34 tiny] (main.py 226): INFO Train: [256/300][1200/1251]	eta 0:00:30 lr 0.000059	time 0.5483 (0.5996)	loss 3.4405 (3.6467)	grad_norm 9.0977 (nan)	mem 5325MB
[2022-04-21 13:26:56 tiny] (main.py 233): INFO EPOCH 256 training takes 0:12:21
[2022-04-21 13:27:08 tiny] (main.py 273): INFO Test: [0/49]	Time 12.102 (12.102)	Loss 1.4203 (1.4203)	Acc@1 73.438 (73.438)	Acc@5 90.723 (90.723)	Mem 5325MB
[2022-04-21 13:27:28 tiny] (main.py 279): INFO  * Acc@1 72.128 Acc@5 90.750
[2022-04-21 13:27:28 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.1%
[2022-04-21 13:27:28 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_256.pth saving......
[2022-04-21 13:27:28 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_256.pth saved !!!
[2022-04-21 13:27:28 tiny] (main.py 148): INFO Max accuracy: 72.13%
[2022-04-21 13:27:40 tiny] (main.py 226): INFO Train: [257/300][0/1251]	eta 4:06:26 lr 0.000059	time 11.8194 (11.8194)	loss 3.4033 (3.4033)	grad_norm 7.5743 (7.5743)	mem 5325MB
[2022-04-21 13:28:41 tiny] (main.py 226): INFO Train: [257/300][100/1251]	eta 0:14:00 lr 0.000059	time 0.7760 (0.7299)	loss 4.4981 (3.6235)	grad_norm 8.7110 (8.0223)	mem 5325MB
[2022-04-21 13:29:40 tiny] (main.py 226): INFO Train: [257/300][200/1251]	eta 0:11:30 lr 0.000059	time 0.6794 (0.6569)	loss 3.7609 (3.6988)	grad_norm 5.7861 (7.8114)	mem 5325MB
[2022-04-21 13:30:39 tiny] (main.py 226): INFO Train: [257/300][300/1251]	eta 0:10:03 lr 0.000059	time 0.6230 (0.6342)	loss 4.2834 (3.6753)	grad_norm 5.7389 (7.6127)	mem 5325MB
[2022-04-21 13:31:37 tiny] (main.py 226): INFO Train: [257/300][400/1251]	eta 0:08:49 lr 0.000059	time 0.6755 (0.6224)	loss 4.1554 (3.6935)	grad_norm 11.7190 (7.7846)	mem 5325MB
[2022-04-21 13:32:36 tiny] (main.py 226): INFO Train: [257/300][500/1251]	eta 0:07:41 lr 0.000058	time 0.5941 (0.6151)	loss 4.3196 (3.7083)	grad_norm 9.4588 (7.8602)	mem 5325MB
[2022-04-21 13:33:34 tiny] (main.py 226): INFO Train: [257/300][600/1251]	eta 0:06:37 lr 0.000058	time 0.6116 (0.6102)	loss 3.5814 (3.6889)	grad_norm 12.6879 (7.8937)	mem 5325MB
[2022-04-21 13:34:33 tiny] (main.py 226): INFO Train: [257/300][700/1251]	eta 0:05:34 lr 0.000058	time 0.7405 (0.6074)	loss 3.8592 (3.6761)	grad_norm 5.5087 (8.1233)	mem 5325MB
[2022-04-21 13:35:32 tiny] (main.py 226): INFO Train: [257/300][800/1251]	eta 0:04:32 lr 0.000058	time 0.5364 (0.6050)	loss 4.4700 (3.6676)	grad_norm 8.2003 (8.1419)	mem 5325MB
[2022-04-21 13:36:31 tiny] (main.py 226): INFO Train: [257/300][900/1251]	eta 0:03:31 lr 0.000058	time 0.5035 (0.6035)	loss 3.7897 (3.6715)	grad_norm 9.9781 (8.2108)	mem 5325MB
[2022-04-21 13:37:31 tiny] (main.py 226): INFO Train: [257/300][1000/1251]	eta 0:02:31 lr 0.000058	time 0.5711 (0.6025)	loss 3.6570 (3.6672)	grad_norm 5.8610 (8.1488)	mem 5325MB
[2022-04-21 13:38:30 tiny] (main.py 226): INFO Train: [257/300][1100/1251]	eta 0:01:30 lr 0.000057	time 0.5253 (0.6012)	loss 3.7823 (3.6721)	grad_norm 10.6830 (8.1344)	mem 5325MB
[2022-04-21 13:39:29 tiny] (main.py 226): INFO Train: [257/300][1200/1251]	eta 0:00:30 lr 0.000057	time 0.6917 (0.6002)	loss 3.5256 (3.6740)	grad_norm 15.0713 (8.2682)	mem 5325MB
[2022-04-21 13:39:51 tiny] (main.py 233): INFO EPOCH 257 training takes 0:12:23
[2022-04-21 13:40:02 tiny] (main.py 273): INFO Test: [0/49]	Time 10.573 (10.573)	Loss 1.4707 (1.4707)	Acc@1 71.094 (71.094)	Acc@5 89.746 (89.746)	Mem 5325MB
[2022-04-21 13:40:22 tiny] (main.py 279): INFO  * Acc@1 72.026 Acc@5 90.754
[2022-04-21 13:40:22 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.0%
[2022-04-21 13:40:22 tiny] (main.py 148): INFO Max accuracy: 72.13%
[2022-04-21 13:40:33 tiny] (main.py 226): INFO Train: [258/300][0/1251]	eta 3:56:03 lr 0.000057	time 11.3221 (11.3221)	loss 3.8376 (3.8376)	grad_norm 9.8189 (9.8189)	mem 5325MB
[2022-04-21 13:41:36 tiny] (main.py 226): INFO Train: [258/300][100/1251]	eta 0:14:03 lr 0.000057	time 0.6268 (0.7331)	loss 3.3564 (3.6575)	grad_norm 6.1400 (8.1167)	mem 5325MB
[2022-04-21 13:42:34 tiny] (main.py 226): INFO Train: [258/300][200/1251]	eta 0:11:30 lr 0.000057	time 0.6885 (0.6574)	loss 4.2813 (3.6123)	grad_norm 5.0061 (8.0533)	mem 5325MB
[2022-04-21 13:43:32 tiny] (main.py 226): INFO Train: [258/300][300/1251]	eta 0:10:01 lr 0.000057	time 0.4947 (0.6326)	loss 2.4555 (3.6296)	grad_norm 6.1767 (8.0910)	mem 5325MB
[2022-04-21 13:44:31 tiny] (main.py 226): INFO Train: [258/300][400/1251]	eta 0:08:49 lr 0.000056	time 0.7530 (0.6220)	loss 3.9768 (3.6284)	grad_norm 7.5061 (nan)	mem 5325MB
[2022-04-21 13:45:30 tiny] (main.py 226): INFO Train: [258/300][500/1251]	eta 0:07:41 lr 0.000056	time 0.6108 (0.6148)	loss 3.7465 (3.6340)	grad_norm 8.1266 (nan)	mem 5325MB
[2022-04-21 13:46:29 tiny] (main.py 226): INFO Train: [258/300][600/1251]	eta 0:06:37 lr 0.000056	time 0.6687 (0.6108)	loss 3.8662 (3.6494)	grad_norm 7.6804 (nan)	mem 5325MB
[2022-04-21 13:47:27 tiny] (main.py 226): INFO Train: [258/300][700/1251]	eta 0:05:34 lr 0.000056	time 0.6455 (0.6073)	loss 3.0021 (3.6525)	grad_norm 7.1226 (nan)	mem 5325MB
[2022-04-21 13:48:27 tiny] (main.py 226): INFO Train: [258/300][800/1251]	eta 0:04:32 lr 0.000056	time 0.5987 (0.6053)	loss 3.1808 (3.6444)	grad_norm 13.5608 (nan)	mem 5325MB
[2022-04-21 13:49:26 tiny] (main.py 226): INFO Train: [258/300][900/1251]	eta 0:03:31 lr 0.000056	time 0.5085 (0.6037)	loss 3.7703 (3.6443)	grad_norm 7.1665 (nan)	mem 5325MB
[2022-04-21 13:50:24 tiny] (main.py 226): INFO Train: [258/300][1000/1251]	eta 0:02:31 lr 0.000055	time 0.5945 (0.6019)	loss 2.6329 (3.6405)	grad_norm 7.4398 (nan)	mem 5325MB
[2022-04-21 13:51:23 tiny] (main.py 226): INFO Train: [258/300][1100/1251]	eta 0:01:30 lr 0.000055	time 0.5707 (0.6010)	loss 3.5573 (3.6374)	grad_norm 7.3923 (nan)	mem 5325MB
[2022-04-21 13:52:23 tiny] (main.py 226): INFO Train: [258/300][1200/1251]	eta 0:00:30 lr 0.000055	time 0.7168 (0.6001)	loss 3.7664 (3.6367)	grad_norm 5.9022 (nan)	mem 5325MB
[2022-04-21 13:52:44 tiny] (main.py 233): INFO EPOCH 258 training takes 0:12:22
[2022-04-21 13:52:55 tiny] (main.py 273): INFO Test: [0/49]	Time 10.667 (10.667)	Loss 1.4644 (1.4644)	Acc@1 70.605 (70.605)	Acc@5 91.113 (91.113)	Mem 5325MB
[2022-04-21 13:53:15 tiny] (main.py 279): INFO  * Acc@1 71.940 Acc@5 90.658
[2022-04-21 13:53:15 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 71.9%
[2022-04-21 13:53:15 tiny] (main.py 148): INFO Max accuracy: 72.13%
[2022-04-21 13:53:26 tiny] (main.py 226): INFO Train: [259/300][0/1251]	eta 3:35:51 lr 0.000055	time 10.3532 (10.3532)	loss 2.5068 (2.5068)	grad_norm 6.7943 (6.7943)	mem 5325MB
[2022-04-21 13:54:30 tiny] (main.py 226): INFO Train: [259/300][100/1251]	eta 0:14:04 lr 0.000055	time 0.7111 (0.7339)	loss 3.9114 (3.6900)	grad_norm 6.0612 (8.9073)	mem 5325MB
[2022-04-21 13:55:28 tiny] (main.py 226): INFO Train: [259/300][200/1251]	eta 0:11:34 lr 0.000055	time 0.5652 (0.6607)	loss 3.7546 (3.6938)	grad_norm 9.1339 (8.8437)	mem 5325MB
[2022-04-21 13:56:26 tiny] (main.py 226): INFO Train: [259/300][300/1251]	eta 0:10:03 lr 0.000054	time 0.5616 (0.6345)	loss 3.5558 (3.6656)	grad_norm 7.4513 (8.8679)	mem 5325MB
[2022-04-21 13:57:25 tiny] (main.py 226): INFO Train: [259/300][400/1251]	eta 0:08:50 lr 0.000054	time 0.4344 (0.6229)	loss 3.8096 (3.6563)	grad_norm 6.1707 (8.7519)	mem 5325MB
[2022-04-21 13:58:24 tiny] (main.py 226): INFO Train: [259/300][500/1251]	eta 0:07:42 lr 0.000054	time 0.4964 (0.6157)	loss 2.4559 (3.6468)	grad_norm 12.8816 (8.6593)	mem 5325MB
[2022-04-21 13:59:22 tiny] (main.py 226): INFO Train: [259/300][600/1251]	eta 0:06:37 lr 0.000054	time 0.6458 (0.6104)	loss 3.5086 (3.6518)	grad_norm 5.5364 (8.6419)	mem 5325MB
[2022-04-21 14:00:21 tiny] (main.py 226): INFO Train: [259/300][700/1251]	eta 0:05:34 lr 0.000054	time 0.5231 (0.6074)	loss 4.1412 (3.6670)	grad_norm 6.6171 (8.6341)	mem 5325MB
[2022-04-21 14:01:20 tiny] (main.py 226): INFO Train: [259/300][800/1251]	eta 0:04:33 lr 0.000054	time 0.5986 (0.6053)	loss 3.8717 (3.6733)	grad_norm 6.6762 (8.6472)	mem 5325MB
[2022-04-21 14:02:19 tiny] (main.py 226): INFO Train: [259/300][900/1251]	eta 0:03:31 lr 0.000053	time 0.7549 (0.6038)	loss 4.2679 (3.6824)	grad_norm 5.6707 (8.5797)	mem 5325MB
[2022-04-21 14:03:19 tiny] (main.py 226): INFO Train: [259/300][1000/1251]	eta 0:02:31 lr 0.000053	time 0.6195 (0.6025)	loss 3.7193 (3.6839)	grad_norm 8.8588 (8.5965)	mem 5325MB
[2022-04-21 14:04:17 tiny] (main.py 226): INFO Train: [259/300][1100/1251]	eta 0:01:30 lr 0.000053	time 0.4908 (0.6013)	loss 4.6162 (3.6854)	grad_norm 7.0580 (8.5794)	mem 5325MB
[2022-04-21 14:05:16 tiny] (main.py 226): INFO Train: [259/300][1200/1251]	eta 0:00:30 lr 0.000053	time 0.6780 (0.6002)	loss 4.3317 (3.6828)	grad_norm 6.8020 (8.5604)	mem 5325MB
[2022-04-21 14:05:38 tiny] (main.py 233): INFO EPOCH 259 training takes 0:12:22
[2022-04-21 14:05:50 tiny] (main.py 273): INFO Test: [0/49]	Time 11.451 (11.451)	Loss 1.3918 (1.3918)	Acc@1 72.363 (72.363)	Acc@5 91.602 (91.602)	Mem 5325MB
[2022-04-21 14:06:09 tiny] (main.py 279): INFO  * Acc@1 72.016 Acc@5 90.716
[2022-04-21 14:06:09 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.0%
[2022-04-21 14:06:09 tiny] (main.py 148): INFO Max accuracy: 72.13%
[2022-04-21 14:06:20 tiny] (main.py 226): INFO Train: [260/300][0/1251]	eta 3:41:26 lr 0.000053	time 10.6204 (10.6204)	loss 3.7437 (3.7437)	grad_norm 9.4731 (9.4731)	mem 5325MB
[2022-04-21 14:07:23 tiny] (main.py 226): INFO Train: [260/300][100/1251]	eta 0:14:00 lr 0.000053	time 0.4660 (0.7299)	loss 4.0720 (3.6159)	grad_norm 12.1229 (8.3755)	mem 5325MB
[2022-04-21 14:08:22 tiny] (main.py 226): INFO Train: [260/300][200/1251]	eta 0:11:34 lr 0.000052	time 0.5200 (0.6604)	loss 3.7994 (3.6696)	grad_norm 11.4150 (8.4123)	mem 5325MB
[2022-04-21 14:09:21 tiny] (main.py 226): INFO Train: [260/300][300/1251]	eta 0:10:05 lr 0.000052	time 0.5917 (0.6370)	loss 3.0332 (3.6432)	grad_norm 9.7366 (8.3232)	mem 5325MB
[2022-04-21 14:10:20 tiny] (main.py 226): INFO Train: [260/300][400/1251]	eta 0:08:52 lr 0.000052	time 0.6075 (0.6256)	loss 2.3367 (3.6298)	grad_norm 6.4807 (8.5271)	mem 5325MB
[2022-04-21 14:11:19 tiny] (main.py 226): INFO Train: [260/300][500/1251]	eta 0:07:44 lr 0.000052	time 0.6473 (0.6179)	loss 3.0401 (3.6292)	grad_norm 5.9023 (8.4568)	mem 5325MB
[2022-04-21 14:12:18 tiny] (main.py 226): INFO Train: [260/300][600/1251]	eta 0:06:39 lr 0.000052	time 0.5729 (0.6143)	loss 3.4059 (3.6343)	grad_norm 30.9052 (8.5548)	mem 5325MB
[2022-04-21 14:13:18 tiny] (main.py 226): INFO Train: [260/300][700/1251]	eta 0:05:36 lr 0.000052	time 0.6582 (0.6113)	loss 4.5874 (3.6436)	grad_norm 6.4513 (8.7701)	mem 5325MB
[2022-04-21 14:14:16 tiny] (main.py 226): INFO Train: [260/300][800/1251]	eta 0:04:34 lr 0.000051	time 0.7469 (0.6080)	loss 2.7988 (3.6350)	grad_norm 15.1082 (8.7028)	mem 5325MB
[2022-04-21 14:15:15 tiny] (main.py 226): INFO Train: [260/300][900/1251]	eta 0:03:32 lr 0.000051	time 0.6393 (0.6063)	loss 3.8468 (3.6341)	grad_norm 7.5234 (nan)	mem 5325MB
[2022-04-21 14:16:14 tiny] (main.py 226): INFO Train: [260/300][1000/1251]	eta 0:02:31 lr 0.000051	time 0.4669 (0.6046)	loss 3.9443 (3.6434)	grad_norm 8.0973 (nan)	mem 5325MB
[2022-04-21 14:17:13 tiny] (main.py 226): INFO Train: [260/300][1100/1251]	eta 0:01:31 lr 0.000051	time 0.4446 (0.6032)	loss 3.9287 (3.6364)	grad_norm 4.7301 (nan)	mem 5325MB
[2022-04-21 14:18:12 tiny] (main.py 226): INFO Train: [260/300][1200/1251]	eta 0:00:30 lr 0.000051	time 0.5152 (0.6020)	loss 2.6001 (3.6322)	grad_norm 10.5650 (nan)	mem 5325MB
[2022-04-21 14:18:34 tiny] (main.py 233): INFO EPOCH 260 training takes 0:12:24
[2022-04-21 14:18:46 tiny] (main.py 273): INFO Test: [0/49]	Time 12.072 (12.072)	Loss 1.3711 (1.3711)	Acc@1 73.340 (73.340)	Acc@5 90.625 (90.625)	Mem 5325MB
[2022-04-21 14:19:05 tiny] (main.py 279): INFO  * Acc@1 72.108 Acc@5 90.746
[2022-04-21 14:19:05 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.1%
[2022-04-21 14:19:05 tiny] (main.py 148): INFO Max accuracy: 72.13%
[2022-04-21 14:19:17 tiny] (main.py 226): INFO Train: [261/300][0/1251]	eta 4:18:08 lr 0.000051	time 12.3811 (12.3811)	loss 3.3226 (3.3226)	grad_norm 18.2734 (18.2734)	mem 5325MB
[2022-04-21 14:20:19 tiny] (main.py 226): INFO Train: [261/300][100/1251]	eta 0:14:02 lr 0.000051	time 0.5286 (0.7321)	loss 2.8916 (3.5988)	grad_norm 7.9632 (8.5264)	mem 5325MB
[2022-04-21 14:21:17 tiny] (main.py 226): INFO Train: [261/300][200/1251]	eta 0:11:32 lr 0.000050	time 0.5218 (0.6588)	loss 2.9766 (3.6075)	grad_norm 23.0737 (8.9103)	mem 5325MB
[2022-04-21 14:22:16 tiny] (main.py 226): INFO Train: [261/300][300/1251]	eta 0:10:04 lr 0.000050	time 0.5181 (0.6354)	loss 3.9085 (3.6312)	grad_norm 6.2682 (8.7485)	mem 5325MB
[2022-04-21 14:23:15 tiny] (main.py 226): INFO Train: [261/300][400/1251]	eta 0:08:51 lr 0.000050	time 0.6843 (0.6247)	loss 4.5583 (3.6545)	grad_norm 5.9920 (8.9755)	mem 5325MB
[2022-04-21 14:24:14 tiny] (main.py 226): INFO Train: [261/300][500/1251]	eta 0:07:43 lr 0.000050	time 0.5861 (0.6175)	loss 3.8871 (3.6570)	grad_norm 9.7983 (8.7880)	mem 5325MB
[2022-04-21 14:25:14 tiny] (main.py 226): INFO Train: [261/300][600/1251]	eta 0:06:39 lr 0.000050	time 0.5588 (0.6136)	loss 3.6516 (3.6594)	grad_norm 6.1025 (8.8090)	mem 5325MB
[2022-04-21 14:26:12 tiny] (main.py 226): INFO Train: [261/300][700/1251]	eta 0:05:36 lr 0.000050	time 0.5805 (0.6101)	loss 2.8886 (3.6655)	grad_norm 14.2654 (8.7249)	mem 5325MB
[2022-04-21 14:27:12 tiny] (main.py 226): INFO Train: [261/300][800/1251]	eta 0:04:34 lr 0.000049	time 0.4765 (0.6081)	loss 3.9681 (3.6524)	grad_norm 11.2368 (8.7002)	mem 5325MB
[2022-04-21 14:28:11 tiny] (main.py 226): INFO Train: [261/300][900/1251]	eta 0:03:32 lr 0.000049	time 0.6497 (0.6058)	loss 4.0409 (3.6555)	grad_norm 7.6493 (8.6997)	mem 5325MB
[2022-04-21 14:29:09 tiny] (main.py 226): INFO Train: [261/300][1000/1251]	eta 0:02:31 lr 0.000049	time 0.4244 (0.6040)	loss 4.0857 (3.6667)	grad_norm 8.2095 (8.7202)	mem 5325MB
[2022-04-21 14:30:08 tiny] (main.py 226): INFO Train: [261/300][1100/1251]	eta 0:01:30 lr 0.000049	time 0.4962 (0.6024)	loss 2.6956 (3.6578)	grad_norm 6.2926 (8.8171)	mem 5325MB
[2022-04-21 14:31:07 tiny] (main.py 226): INFO Train: [261/300][1200/1251]	eta 0:00:30 lr 0.000049	time 0.5140 (0.6016)	loss 2.8277 (3.6579)	grad_norm 6.9256 (8.8482)	mem 5325MB
[2022-04-21 14:31:30 tiny] (main.py 233): INFO EPOCH 261 training takes 0:12:25
[2022-04-21 14:31:42 tiny] (main.py 273): INFO Test: [0/49]	Time 11.850 (11.850)	Loss 1.4027 (1.4027)	Acc@1 72.656 (72.656)	Acc@5 90.625 (90.625)	Mem 5325MB
[2022-04-21 14:32:01 tiny] (main.py 279): INFO  * Acc@1 72.006 Acc@5 90.710
[2022-04-21 14:32:01 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.0%
[2022-04-21 14:32:01 tiny] (main.py 148): INFO Max accuracy: 72.13%
[2022-04-21 14:32:12 tiny] (main.py 226): INFO Train: [262/300][0/1251]	eta 3:57:22 lr 0.000049	time 11.3846 (11.3846)	loss 2.2302 (2.2302)	grad_norm 5.4318 (5.4318)	mem 5325MB
[2022-04-21 14:33:15 tiny] (main.py 226): INFO Train: [262/300][100/1251]	eta 0:14:02 lr 0.000049	time 0.5933 (0.7318)	loss 4.0570 (3.5631)	grad_norm 16.9729 (9.2758)	mem 5325MB
[2022-04-21 14:34:14 tiny] (main.py 226): INFO Train: [262/300][200/1251]	eta 0:11:32 lr 0.000048	time 0.5587 (0.6589)	loss 3.1536 (3.6230)	grad_norm 9.9107 (9.1787)	mem 5325MB
[2022-04-21 14:35:12 tiny] (main.py 226): INFO Train: [262/300][300/1251]	eta 0:10:03 lr 0.000048	time 0.5070 (0.6343)	loss 2.8559 (3.6060)	grad_norm 6.7892 (9.1681)	mem 5325MB
[2022-04-21 14:36:11 tiny] (main.py 226): INFO Train: [262/300][400/1251]	eta 0:08:50 lr 0.000048	time 0.5469 (0.6236)	loss 3.8478 (3.6353)	grad_norm 8.8465 (8.9175)	mem 5325MB
[2022-04-21 14:37:10 tiny] (main.py 226): INFO Train: [262/300][500/1251]	eta 0:07:42 lr 0.000048	time 0.6972 (0.6157)	loss 4.0670 (3.6330)	grad_norm 7.3160 (8.8006)	mem 5325MB
[2022-04-21 14:38:08 tiny] (main.py 226): INFO Train: [262/300][600/1251]	eta 0:06:37 lr 0.000048	time 0.5747 (0.6110)	loss 2.3375 (3.6227)	grad_norm 9.3462 (8.8045)	mem 5325MB
[2022-04-21 14:39:07 tiny] (main.py 226): INFO Train: [262/300][700/1251]	eta 0:05:35 lr 0.000048	time 0.7084 (0.6082)	loss 4.6206 (3.6313)	grad_norm 8.2583 (8.7391)	mem 5325MB
[2022-04-21 14:40:06 tiny] (main.py 226): INFO Train: [262/300][800/1251]	eta 0:04:33 lr 0.000047	time 0.7309 (0.6058)	loss 3.5114 (3.6378)	grad_norm 8.3510 (8.7378)	mem 5325MB
[2022-04-21 14:41:05 tiny] (main.py 226): INFO Train: [262/300][900/1251]	eta 0:03:32 lr 0.000047	time 0.5791 (0.6041)	loss 3.7621 (3.6301)	grad_norm 13.7019 (8.7388)	mem 5325MB
[2022-04-21 14:42:04 tiny] (main.py 226): INFO Train: [262/300][1000/1251]	eta 0:02:31 lr 0.000047	time 0.8006 (0.6027)	loss 3.5358 (3.6426)	grad_norm 6.0846 (8.6874)	mem 5325MB
[2022-04-21 14:43:03 tiny] (main.py 226): INFO Train: [262/300][1100/1251]	eta 0:01:30 lr 0.000047	time 0.6987 (0.6012)	loss 3.8156 (3.6383)	grad_norm 7.6156 (8.7238)	mem 5325MB
[2022-04-21 14:44:02 tiny] (main.py 226): INFO Train: [262/300][1200/1251]	eta 0:00:30 lr 0.000047	time 0.5950 (0.6004)	loss 3.9923 (3.6346)	grad_norm 9.1375 (8.7755)	mem 5325MB
[2022-04-21 14:44:24 tiny] (main.py 233): INFO EPOCH 262 training takes 0:12:23
[2022-04-21 14:44:36 tiny] (main.py 273): INFO Test: [0/49]	Time 11.939 (11.939)	Loss 1.4298 (1.4298)	Acc@1 72.852 (72.852)	Acc@5 91.016 (91.016)	Mem 5325MB
[2022-04-21 14:44:55 tiny] (main.py 279): INFO  * Acc@1 71.950 Acc@5 90.690
[2022-04-21 14:44:55 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.0%
[2022-04-21 14:44:55 tiny] (main.py 148): INFO Max accuracy: 72.13%
[2022-04-21 14:45:06 tiny] (main.py 226): INFO Train: [263/300][0/1251]	eta 3:39:03 lr 0.000047	time 10.5067 (10.5067)	loss 3.9628 (3.9628)	grad_norm 13.8668 (13.8668)	mem 5325MB
[2022-04-21 14:46:09 tiny] (main.py 226): INFO Train: [263/300][100/1251]	eta 0:14:01 lr 0.000047	time 0.4447 (0.7308)	loss 4.5162 (3.5922)	grad_norm 9.3904 (9.2989)	mem 5325MB
[2022-04-21 14:47:07 tiny] (main.py 226): INFO Train: [263/300][200/1251]	eta 0:11:30 lr 0.000046	time 0.6042 (0.6573)	loss 3.2587 (3.6263)	grad_norm 7.1160 (9.0873)	mem 5325MB
[2022-04-21 14:48:05 tiny] (main.py 226): INFO Train: [263/300][300/1251]	eta 0:10:00 lr 0.000046	time 0.6031 (0.6317)	loss 3.9452 (3.6341)	grad_norm 5.2472 (8.9314)	mem 5325MB
[2022-04-21 14:49:04 tiny] (main.py 226): INFO Train: [263/300][400/1251]	eta 0:08:48 lr 0.000046	time 0.5621 (0.6211)	loss 3.4732 (3.6531)	grad_norm 9.3578 (8.9377)	mem 5325MB
[2022-04-21 14:50:03 tiny] (main.py 226): INFO Train: [263/300][500/1251]	eta 0:07:41 lr 0.000046	time 0.5669 (0.6145)	loss 2.3578 (3.6585)	grad_norm 8.6654 (8.9403)	mem 5325MB
[2022-04-21 14:51:02 tiny] (main.py 226): INFO Train: [263/300][600/1251]	eta 0:06:37 lr 0.000046	time 0.6101 (0.6107)	loss 3.9908 (3.6723)	grad_norm 8.4823 (8.8830)	mem 5325MB
[2022-04-21 14:52:01 tiny] (main.py 226): INFO Train: [263/300][700/1251]	eta 0:05:34 lr 0.000046	time 0.5631 (0.6074)	loss 3.9367 (3.6742)	grad_norm 7.1681 (8.7380)	mem 5325MB
[2022-04-21 14:53:00 tiny] (main.py 226): INFO Train: [263/300][800/1251]	eta 0:04:32 lr 0.000045	time 0.7228 (0.6050)	loss 2.4944 (3.6731)	grad_norm 6.4277 (8.8732)	mem 5325MB
[2022-04-21 14:53:59 tiny] (main.py 226): INFO Train: [263/300][900/1251]	eta 0:03:31 lr 0.000045	time 0.5563 (0.6037)	loss 3.3130 (3.6725)	grad_norm 9.4591 (8.8423)	mem 5325MB
[2022-04-21 14:54:58 tiny] (main.py 226): INFO Train: [263/300][1000/1251]	eta 0:02:31 lr 0.000045	time 0.5649 (0.6023)	loss 3.4197 (3.6659)	grad_norm 5.5730 (8.8268)	mem 5325MB
[2022-04-21 14:55:57 tiny] (main.py 226): INFO Train: [263/300][1100/1251]	eta 0:01:30 lr 0.000045	time 0.5548 (0.6010)	loss 3.8218 (3.6630)	grad_norm 5.2839 (nan)	mem 5325MB
[2022-04-21 14:56:56 tiny] (main.py 226): INFO Train: [263/300][1200/1251]	eta 0:00:30 lr 0.000045	time 0.7190 (0.6004)	loss 3.7215 (3.6577)	grad_norm 17.0314 (nan)	mem 5325MB
[2022-04-21 14:57:19 tiny] (main.py 233): INFO EPOCH 263 training takes 0:12:23
[2022-04-21 14:57:29 tiny] (main.py 273): INFO Test: [0/49]	Time 10.592 (10.592)	Loss 1.3338 (1.3338)	Acc@1 73.926 (73.926)	Acc@5 91.309 (91.309)	Mem 5325MB
[2022-04-21 14:57:49 tiny] (main.py 279): INFO  * Acc@1 72.192 Acc@5 90.740
[2022-04-21 14:57:49 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.2%
[2022-04-21 14:57:49 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_263.pth saving......
[2022-04-21 14:57:50 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_263.pth saved !!!
[2022-04-21 14:57:50 tiny] (main.py 148): INFO Max accuracy: 72.19%
[2022-04-21 14:58:01 tiny] (main.py 226): INFO Train: [264/300][0/1251]	eta 3:54:07 lr 0.000045	time 11.2290 (11.2290)	loss 3.8174 (3.8174)	grad_norm 6.2665 (6.2665)	mem 5325MB
[2022-04-21 14:59:03 tiny] (main.py 226): INFO Train: [264/300][100/1251]	eta 0:14:02 lr 0.000045	time 0.5003 (0.7322)	loss 3.2389 (3.5809)	grad_norm 16.0683 (9.4361)	mem 5325MB
[2022-04-21 15:00:02 tiny] (main.py 226): INFO Train: [264/300][200/1251]	eta 0:11:31 lr 0.000044	time 0.7347 (0.6580)	loss 4.3149 (3.6060)	grad_norm 8.0595 (9.2863)	mem 5325MB
[2022-04-21 15:01:00 tiny] (main.py 226): INFO Train: [264/300][300/1251]	eta 0:10:02 lr 0.000044	time 0.5963 (0.6336)	loss 3.6586 (3.6236)	grad_norm 6.6952 (9.0653)	mem 5325MB
[2022-04-21 15:01:59 tiny] (main.py 226): INFO Train: [264/300][400/1251]	eta 0:08:49 lr 0.000044	time 0.5349 (0.6216)	loss 3.0318 (3.6268)	grad_norm 8.3048 (8.9152)	mem 5325MB
[2022-04-21 15:02:58 tiny] (main.py 226): INFO Train: [264/300][500/1251]	eta 0:07:42 lr 0.000044	time 0.7596 (0.6152)	loss 3.2831 (3.6225)	grad_norm 13.3931 (8.9234)	mem 5325MB
[2022-04-21 15:03:57 tiny] (main.py 226): INFO Train: [264/300][600/1251]	eta 0:06:37 lr 0.000044	time 0.6006 (0.6107)	loss 4.2024 (3.6449)	grad_norm 11.0910 (8.9623)	mem 5325MB
[2022-04-21 15:04:55 tiny] (main.py 226): INFO Train: [264/300][700/1251]	eta 0:05:34 lr 0.000044	time 0.6740 (0.6072)	loss 4.0155 (3.6396)	grad_norm 18.0749 (9.0096)	mem 5325MB
[2022-04-21 15:05:54 tiny] (main.py 226): INFO Train: [264/300][800/1251]	eta 0:04:32 lr 0.000044	time 0.5070 (0.6051)	loss 2.8150 (3.6395)	grad_norm 7.8694 (9.1267)	mem 5325MB
[2022-04-21 15:06:53 tiny] (main.py 226): INFO Train: [264/300][900/1251]	eta 0:03:31 lr 0.000043	time 0.6250 (0.6036)	loss 3.6621 (3.6422)	grad_norm 7.8847 (9.1141)	mem 5325MB
[2022-04-21 15:07:53 tiny] (main.py 226): INFO Train: [264/300][1000/1251]	eta 0:02:31 lr 0.000043	time 0.6324 (0.6025)	loss 2.9297 (3.6507)	grad_norm 22.9673 (9.1558)	mem 5325MB
[2022-04-21 15:08:51 tiny] (main.py 226): INFO Train: [264/300][1100/1251]	eta 0:01:30 lr 0.000043	time 0.5686 (0.6011)	loss 3.9789 (3.6539)	grad_norm 7.7395 (9.0669)	mem 5325MB
[2022-04-21 15:09:51 tiny] (main.py 226): INFO Train: [264/300][1200/1251]	eta 0:00:30 lr 0.000043	time 0.5818 (0.6007)	loss 3.9892 (3.6489)	grad_norm 10.5072 (9.1246)	mem 5325MB
[2022-04-21 15:10:14 tiny] (main.py 233): INFO EPOCH 264 training takes 0:12:24
[2022-04-21 15:10:24 tiny] (main.py 273): INFO Test: [0/49]	Time 10.626 (10.626)	Loss 1.4587 (1.4587)	Acc@1 71.387 (71.387)	Acc@5 90.918 (90.918)	Mem 5325MB
[2022-04-21 15:10:45 tiny] (main.py 279): INFO  * Acc@1 72.294 Acc@5 90.828
[2022-04-21 15:10:45 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.3%
[2022-04-21 15:10:45 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_264.pth saving......
[2022-04-21 15:10:45 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_264.pth saved !!!
[2022-04-21 15:10:45 tiny] (main.py 148): INFO Max accuracy: 72.29%
[2022-04-21 15:10:55 tiny] (main.py 226): INFO Train: [265/300][0/1251]	eta 3:38:56 lr 0.000043	time 10.5008 (10.5008)	loss 3.5584 (3.5584)	grad_norm 11.5743 (11.5743)	mem 5325MB
[2022-04-21 15:11:59 tiny] (main.py 226): INFO Train: [265/300][100/1251]	eta 0:14:01 lr 0.000043	time 0.5354 (0.7311)	loss 4.4572 (3.6105)	grad_norm 8.6142 (8.5988)	mem 5325MB
[2022-04-21 15:12:57 tiny] (main.py 226): INFO Train: [265/300][200/1251]	eta 0:11:34 lr 0.000043	time 0.6005 (0.6604)	loss 3.6765 (3.6450)	grad_norm 11.5794 (8.6228)	mem 5325MB
[2022-04-21 15:13:56 tiny] (main.py 226): INFO Train: [265/300][300/1251]	eta 0:10:04 lr 0.000042	time 0.5674 (0.6359)	loss 4.4599 (3.6536)	grad_norm 12.6119 (8.8979)	mem 5325MB
[2022-04-21 15:14:55 tiny] (main.py 226): INFO Train: [265/300][400/1251]	eta 0:08:50 lr 0.000042	time 0.5276 (0.6237)	loss 4.2495 (3.6582)	grad_norm 9.2512 (8.9090)	mem 5325MB
[2022-04-21 15:15:53 tiny] (main.py 226): INFO Train: [265/300][500/1251]	eta 0:07:42 lr 0.000042	time 0.5348 (0.6158)	loss 3.6109 (3.6503)	grad_norm 17.0009 (9.2110)	mem 5325MB
[2022-04-21 15:16:53 tiny] (main.py 226): INFO Train: [265/300][600/1251]	eta 0:06:38 lr 0.000042	time 0.5132 (0.6122)	loss 3.8938 (3.6640)	grad_norm 12.0757 (9.1922)	mem 5325MB
[2022-04-21 15:17:51 tiny] (main.py 226): INFO Train: [265/300][700/1251]	eta 0:05:35 lr 0.000042	time 0.5650 (0.6085)	loss 3.8410 (3.6704)	grad_norm 6.5477 (9.0630)	mem 5325MB
[2022-04-21 15:18:50 tiny] (main.py 226): INFO Train: [265/300][800/1251]	eta 0:04:33 lr 0.000042	time 0.5247 (0.6062)	loss 2.7647 (3.6641)	grad_norm 9.9542 (9.0210)	mem 5325MB
[2022-04-21 15:19:49 tiny] (main.py 226): INFO Train: [265/300][900/1251]	eta 0:03:32 lr 0.000042	time 0.5117 (0.6044)	loss 2.3149 (3.6549)	grad_norm 6.5730 (8.8905)	mem 5325MB
[2022-04-21 15:20:48 tiny] (main.py 226): INFO Train: [265/300][1000/1251]	eta 0:02:31 lr 0.000041	time 0.5072 (0.6023)	loss 2.8255 (3.6411)	grad_norm 6.1465 (8.9409)	mem 5325MB
[2022-04-21 15:21:48 tiny] (main.py 226): INFO Train: [265/300][1100/1251]	eta 0:01:31 lr 0.000041	time 0.7037 (0.6028)	loss 2.6740 (3.6479)	grad_norm 12.8456 (8.9210)	mem 5325MB
[2022-04-21 15:22:50 tiny] (main.py 226): INFO Train: [265/300][1200/1251]	eta 0:00:30 lr 0.000041	time 0.7437 (0.6042)	loss 4.2433 (3.6482)	grad_norm 11.7769 (8.9372)	mem 5325MB
[2022-04-21 15:23:13 tiny] (main.py 233): INFO EPOCH 265 training takes 0:12:27
[2022-04-21 15:23:24 tiny] (main.py 273): INFO Test: [0/49]	Time 11.771 (11.771)	Loss 1.4861 (1.4861)	Acc@1 71.094 (71.094)	Acc@5 90.137 (90.137)	Mem 5325MB
[2022-04-21 15:23:44 tiny] (main.py 279): INFO  * Acc@1 72.242 Acc@5 90.852
[2022-04-21 15:23:44 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.2%
[2022-04-21 15:23:44 tiny] (main.py 148): INFO Max accuracy: 72.29%
[2022-04-21 15:23:55 tiny] (main.py 226): INFO Train: [266/300][0/1251]	eta 4:04:12 lr 0.000041	time 11.7123 (11.7123)	loss 4.1575 (4.1575)	grad_norm 9.7713 (9.7713)	mem 5325MB
[2022-04-21 15:24:57 tiny] (main.py 226): INFO Train: [266/300][100/1251]	eta 0:14:02 lr 0.000041	time 0.6538 (0.7323)	loss 4.2579 (3.6136)	grad_norm 9.4649 (8.6015)	mem 5325MB
[2022-04-21 15:25:56 tiny] (main.py 226): INFO Train: [266/300][200/1251]	eta 0:11:31 lr 0.000041	time 0.4465 (0.6582)	loss 3.3835 (3.6012)	grad_norm 8.6915 (8.9303)	mem 5325MB
[2022-04-21 15:26:54 tiny] (main.py 226): INFO Train: [266/300][300/1251]	eta 0:10:02 lr 0.000041	time 0.5617 (0.6338)	loss 4.4162 (3.6232)	grad_norm 10.6512 (nan)	mem 5325MB
[2022-04-21 15:27:53 tiny] (main.py 226): INFO Train: [266/300][400/1251]	eta 0:08:50 lr 0.000040	time 0.3190 (0.6230)	loss 4.1689 (3.6302)	grad_norm 10.0176 (nan)	mem 5325MB
[2022-04-21 15:28:52 tiny] (main.py 226): INFO Train: [266/300][500/1251]	eta 0:07:42 lr 0.000040	time 0.5738 (0.6161)	loss 2.4046 (3.6288)	grad_norm 5.8030 (nan)	mem 5325MB
[2022-04-21 15:29:51 tiny] (main.py 226): INFO Train: [266/300][600/1251]	eta 0:06:38 lr 0.000040	time 0.5537 (0.6119)	loss 3.3372 (3.6441)	grad_norm 6.9653 (nan)	mem 5325MB
[2022-04-21 15:30:50 tiny] (main.py 226): INFO Train: [266/300][700/1251]	eta 0:05:34 lr 0.000040	time 0.5869 (0.6078)	loss 2.8177 (3.6381)	grad_norm 9.2459 (nan)	mem 5325MB
[2022-04-21 15:31:49 tiny] (main.py 226): INFO Train: [266/300][800/1251]	eta 0:04:33 lr 0.000040	time 0.3861 (0.6063)	loss 3.9524 (3.6441)	grad_norm 5.5856 (nan)	mem 5325MB
[2022-04-21 15:32:48 tiny] (main.py 226): INFO Train: [266/300][900/1251]	eta 0:03:32 lr 0.000040	time 0.4742 (0.6046)	loss 4.0797 (3.6534)	grad_norm 13.6079 (nan)	mem 5325MB
[2022-04-21 15:33:47 tiny] (main.py 226): INFO Train: [266/300][1000/1251]	eta 0:02:31 lr 0.000040	time 0.6800 (0.6028)	loss 4.1041 (3.6542)	grad_norm 6.2549 (nan)	mem 5325MB
[2022-04-21 15:34:46 tiny] (main.py 226): INFO Train: [266/300][1100/1251]	eta 0:01:30 lr 0.000039	time 0.5851 (0.6017)	loss 3.4303 (3.6623)	grad_norm 8.6286 (nan)	mem 5325MB
[2022-04-21 15:35:45 tiny] (main.py 226): INFO Train: [266/300][1200/1251]	eta 0:00:30 lr 0.000039	time 0.4433 (0.6007)	loss 2.4961 (3.6567)	grad_norm 9.5111 (nan)	mem 5325MB
[2022-04-21 15:36:07 tiny] (main.py 233): INFO EPOCH 266 training takes 0:12:23
[2022-04-21 15:36:18 tiny] (main.py 273): INFO Test: [0/49]	Time 11.209 (11.209)	Loss 1.4711 (1.4711)	Acc@1 70.801 (70.801)	Acc@5 89.941 (89.941)	Mem 5325MB
[2022-04-21 15:36:37 tiny] (main.py 279): INFO  * Acc@1 72.128 Acc@5 90.754
[2022-04-21 15:36:37 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.1%
[2022-04-21 15:36:37 tiny] (main.py 148): INFO Max accuracy: 72.29%
[2022-04-21 15:36:50 tiny] (main.py 226): INFO Train: [267/300][0/1251]	eta 4:12:49 lr 0.000039	time 12.1262 (12.1262)	loss 4.0050 (4.0050)	grad_norm 6.7039 (6.7039)	mem 5325MB
[2022-04-21 15:37:51 tiny] (main.py 226): INFO Train: [267/300][100/1251]	eta 0:14:01 lr 0.000039	time 0.4398 (0.7310)	loss 4.1598 (3.6054)	grad_norm 9.3089 (9.1314)	mem 5325MB
[2022-04-21 15:38:50 tiny] (main.py 226): INFO Train: [267/300][200/1251]	eta 0:11:32 lr 0.000039	time 0.6474 (0.6593)	loss 3.9897 (3.5592)	grad_norm 7.5696 (8.7671)	mem 5325MB
[2022-04-21 15:39:48 tiny] (main.py 226): INFO Train: [267/300][300/1251]	eta 0:10:03 lr 0.000039	time 0.4802 (0.6344)	loss 3.7411 (3.5823)	grad_norm 11.5316 (8.8039)	mem 5325MB
[2022-04-21 15:40:47 tiny] (main.py 226): INFO Train: [267/300][400/1251]	eta 0:08:50 lr 0.000039	time 0.5435 (0.6229)	loss 4.0703 (3.6041)	grad_norm 7.9885 (8.9540)	mem 5325MB
[2022-04-21 15:41:46 tiny] (main.py 226): INFO Train: [267/300][500/1251]	eta 0:07:42 lr 0.000039	time 0.6340 (0.6154)	loss 3.4021 (3.6015)	grad_norm 7.8490 (9.3284)	mem 5325MB
[2022-04-21 15:42:45 tiny] (main.py 226): INFO Train: [267/300][600/1251]	eta 0:06:37 lr 0.000038	time 0.5681 (0.6110)	loss 3.1522 (3.6118)	grad_norm 4.9013 (9.2760)	mem 5325MB
[2022-04-21 15:43:44 tiny] (main.py 226): INFO Train: [267/300][700/1251]	eta 0:05:35 lr 0.000038	time 0.4742 (0.6082)	loss 4.0469 (3.6154)	grad_norm 7.4368 (9.2627)	mem 5325MB
[2022-04-21 15:44:43 tiny] (main.py 226): INFO Train: [267/300][800/1251]	eta 0:04:33 lr 0.000038	time 0.4141 (0.6057)	loss 2.5471 (3.6144)	grad_norm 6.4240 (9.1214)	mem 5325MB
[2022-04-21 15:45:41 tiny] (main.py 226): INFO Train: [267/300][900/1251]	eta 0:03:31 lr 0.000038	time 0.6310 (0.6037)	loss 3.1942 (3.6084)	grad_norm 9.9822 (9.0777)	mem 5325MB
[2022-04-21 15:46:40 tiny] (main.py 226): INFO Train: [267/300][1000/1251]	eta 0:02:31 lr 0.000038	time 0.5758 (0.6022)	loss 3.4789 (3.6090)	grad_norm 11.4208 (9.0636)	mem 5325MB
[2022-04-21 15:47:39 tiny] (main.py 226): INFO Train: [267/300][1100/1251]	eta 0:01:30 lr 0.000038	time 0.6988 (0.6010)	loss 3.9193 (3.6164)	grad_norm 6.8569 (8.9996)	mem 5325MB
[2022-04-21 15:48:38 tiny] (main.py 226): INFO Train: [267/300][1200/1251]	eta 0:00:30 lr 0.000038	time 0.6266 (0.6002)	loss 4.1926 (3.6210)	grad_norm 7.3407 (9.0050)	mem 5325MB
[2022-04-21 15:49:01 tiny] (main.py 233): INFO EPOCH 267 training takes 0:12:23
[2022-04-21 15:49:13 tiny] (main.py 273): INFO Test: [0/49]	Time 12.036 (12.036)	Loss 1.4961 (1.4961)	Acc@1 70.215 (70.215)	Acc@5 90.332 (90.332)	Mem 5325MB
[2022-04-21 15:49:32 tiny] (main.py 279): INFO  * Acc@1 72.254 Acc@5 90.950
[2022-04-21 15:49:32 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.3%
[2022-04-21 15:49:32 tiny] (main.py 148): INFO Max accuracy: 72.29%
[2022-04-21 15:49:43 tiny] (main.py 226): INFO Train: [268/300][0/1251]	eta 3:56:49 lr 0.000038	time 11.3587 (11.3587)	loss 3.8995 (3.8995)	grad_norm 6.7030 (6.7030)	mem 5325MB
[2022-04-21 15:50:45 tiny] (main.py 226): INFO Train: [268/300][100/1251]	eta 0:14:01 lr 0.000037	time 0.5663 (0.7314)	loss 3.7565 (3.6103)	grad_norm 10.4005 (8.5754)	mem 5325MB
[2022-04-21 15:51:44 tiny] (main.py 226): INFO Train: [268/300][200/1251]	eta 0:11:31 lr 0.000037	time 0.4472 (0.6582)	loss 3.5834 (3.5942)	grad_norm 27.2577 (8.8382)	mem 5325MB
[2022-04-21 15:52:42 tiny] (main.py 226): INFO Train: [268/300][300/1251]	eta 0:10:02 lr 0.000037	time 0.4694 (0.6339)	loss 2.9475 (3.5888)	grad_norm 6.8690 (8.7944)	mem 5325MB
[2022-04-21 15:53:41 tiny] (main.py 226): INFO Train: [268/300][400/1251]	eta 0:08:50 lr 0.000037	time 0.8537 (0.6232)	loss 3.2380 (3.6088)	grad_norm 8.3687 (8.7394)	mem 5325MB
[2022-04-21 15:54:40 tiny] (main.py 226): INFO Train: [268/300][500/1251]	eta 0:07:41 lr 0.000037	time 0.5575 (0.6149)	loss 3.6673 (3.6346)	grad_norm 9.5564 (8.9529)	mem 5325MB
[2022-04-21 15:55:39 tiny] (main.py 226): INFO Train: [268/300][600/1251]	eta 0:06:37 lr 0.000037	time 0.5055 (0.6105)	loss 2.8472 (3.6352)	grad_norm 6.2540 (8.9910)	mem 5325MB
[2022-04-21 15:56:38 tiny] (main.py 226): INFO Train: [268/300][700/1251]	eta 0:05:34 lr 0.000037	time 0.8435 (0.6077)	loss 3.6638 (3.6478)	grad_norm 6.9524 (8.8204)	mem 5325MB
[2022-04-21 15:57:36 tiny] (main.py 226): INFO Train: [268/300][800/1251]	eta 0:04:32 lr 0.000036	time 0.5127 (0.6052)	loss 4.4219 (3.6330)	grad_norm 8.9473 (nan)	mem 5325MB
[2022-04-21 15:58:36 tiny] (main.py 226): INFO Train: [268/300][900/1251]	eta 0:03:31 lr 0.000036	time 0.6897 (0.6039)	loss 3.3196 (3.6261)	grad_norm 7.1255 (nan)	mem 5325MB
[2022-04-21 15:59:34 tiny] (main.py 226): INFO Train: [268/300][1000/1251]	eta 0:02:31 lr 0.000036	time 0.4559 (0.6022)	loss 4.1498 (3.6261)	grad_norm 6.7715 (nan)	mem 5325MB
[2022-04-21 16:00:33 tiny] (main.py 226): INFO Train: [268/300][1100/1251]	eta 0:01:30 lr 0.000036	time 0.3793 (0.6009)	loss 3.5737 (3.6198)	grad_norm 6.2164 (nan)	mem 5325MB
[2022-04-21 16:01:32 tiny] (main.py 226): INFO Train: [268/300][1200/1251]	eta 0:00:30 lr 0.000036	time 0.6791 (0.6002)	loss 3.0656 (3.6233)	grad_norm 12.2444 (nan)	mem 5325MB
[2022-04-21 16:01:54 tiny] (main.py 233): INFO EPOCH 268 training takes 0:12:22
[2022-04-21 16:02:06 tiny] (main.py 273): INFO Test: [0/49]	Time 11.718 (11.718)	Loss 1.4220 (1.4220)	Acc@1 71.387 (71.387)	Acc@5 91.602 (91.602)	Mem 5325MB
[2022-04-21 16:02:25 tiny] (main.py 279): INFO  * Acc@1 72.216 Acc@5 90.962
[2022-04-21 16:02:25 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.2%
[2022-04-21 16:02:25 tiny] (main.py 148): INFO Max accuracy: 72.29%
[2022-04-21 16:02:36 tiny] (main.py 226): INFO Train: [269/300][0/1251]	eta 3:50:40 lr 0.000036	time 11.0635 (11.0635)	loss 3.5100 (3.5100)	grad_norm 7.2227 (7.2227)	mem 5325MB
[2022-04-21 16:03:39 tiny] (main.py 226): INFO Train: [269/300][100/1251]	eta 0:14:03 lr 0.000036	time 0.5764 (0.7327)	loss 3.9752 (3.6040)	grad_norm 7.5846 (8.9281)	mem 5325MB
[2022-04-21 16:04:38 tiny] (main.py 226): INFO Train: [269/300][200/1251]	eta 0:11:32 lr 0.000036	time 0.5727 (0.6588)	loss 3.3462 (3.6096)	grad_norm 20.0710 (8.9101)	mem 5325MB
[2022-04-21 16:05:36 tiny] (main.py 226): INFO Train: [269/300][300/1251]	eta 0:10:03 lr 0.000035	time 0.7527 (0.6346)	loss 3.3133 (3.6166)	grad_norm 10.8185 (9.1449)	mem 5325MB
[2022-04-21 16:06:35 tiny] (main.py 226): INFO Train: [269/300][400/1251]	eta 0:08:50 lr 0.000035	time 0.6318 (0.6233)	loss 3.6110 (3.6141)	grad_norm 7.4005 (9.2195)	mem 5325MB
[2022-04-21 16:07:34 tiny] (main.py 226): INFO Train: [269/300][500/1251]	eta 0:07:42 lr 0.000035	time 0.6253 (0.6163)	loss 3.2747 (3.6110)	grad_norm 7.7482 (9.0742)	mem 5325MB
[2022-04-21 16:08:33 tiny] (main.py 226): INFO Train: [269/300][600/1251]	eta 0:06:38 lr 0.000035	time 0.5905 (0.6115)	loss 4.4167 (3.6209)	grad_norm 7.0069 (9.0459)	mem 5325MB
[2022-04-21 16:09:32 tiny] (main.py 226): INFO Train: [269/300][700/1251]	eta 0:05:35 lr 0.000035	time 0.7783 (0.6085)	loss 3.2996 (3.6131)	grad_norm 12.6148 (9.0617)	mem 5325MB
[2022-04-21 16:10:31 tiny] (main.py 226): INFO Train: [269/300][800/1251]	eta 0:04:33 lr 0.000035	time 0.4226 (0.6060)	loss 4.5019 (3.6207)	grad_norm 8.8674 (9.0260)	mem 5325MB
[2022-04-21 16:11:30 tiny] (main.py 226): INFO Train: [269/300][900/1251]	eta 0:03:32 lr 0.000035	time 0.5687 (0.6041)	loss 3.8045 (3.6309)	grad_norm 8.7556 (9.0556)	mem 5325MB
[2022-04-21 16:12:28 tiny] (main.py 226): INFO Train: [269/300][1000/1251]	eta 0:02:31 lr 0.000035	time 0.6044 (0.6023)	loss 3.6742 (3.6339)	grad_norm 16.1353 (9.1375)	mem 5325MB
[2022-04-21 16:13:27 tiny] (main.py 226): INFO Train: [269/300][1100/1251]	eta 0:01:30 lr 0.000034	time 0.7931 (0.6008)	loss 3.3014 (3.6328)	grad_norm 11.5357 (9.0935)	mem 5325MB
[2022-04-21 16:14:26 tiny] (main.py 226): INFO Train: [269/300][1200/1251]	eta 0:00:30 lr 0.000034	time 0.5374 (0.6000)	loss 3.8639 (3.6309)	grad_norm 6.9628 (9.0671)	mem 5325MB
[2022-04-21 16:14:47 tiny] (main.py 233): INFO EPOCH 269 training takes 0:12:22
[2022-04-21 16:14:59 tiny] (main.py 273): INFO Test: [0/49]	Time 11.585 (11.585)	Loss 1.3993 (1.3993)	Acc@1 72.168 (72.168)	Acc@5 91.699 (91.699)	Mem 5325MB
[2022-04-21 16:15:19 tiny] (main.py 279): INFO  * Acc@1 72.366 Acc@5 90.964
[2022-04-21 16:15:19 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.4%
[2022-04-21 16:15:19 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_269.pth saving......
[2022-04-21 16:15:19 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_269.pth saved !!!
[2022-04-21 16:15:19 tiny] (main.py 148): INFO Max accuracy: 72.37%
[2022-04-21 16:15:31 tiny] (main.py 226): INFO Train: [270/300][0/1251]	eta 4:09:32 lr 0.000034	time 11.9688 (11.9688)	loss 2.9694 (2.9694)	grad_norm 8.5432 (8.5432)	mem 5325MB
[2022-04-21 16:16:33 tiny] (main.py 226): INFO Train: [270/300][100/1251]	eta 0:14:01 lr 0.000034	time 0.6342 (0.7309)	loss 4.4356 (3.5603)	grad_norm 7.6575 (9.4932)	mem 5325MB
[2022-04-21 16:17:31 tiny] (main.py 226): INFO Train: [270/300][200/1251]	eta 0:11:33 lr 0.000034	time 0.6870 (0.6599)	loss 3.8717 (3.5765)	grad_norm 10.3523 (9.4268)	mem 5325MB
[2022-04-21 16:18:31 tiny] (main.py 226): INFO Train: [270/300][300/1251]	eta 0:10:05 lr 0.000034	time 0.6545 (0.6371)	loss 3.4489 (3.5745)	grad_norm 6.1476 (9.2603)	mem 5325MB
[2022-04-21 16:19:29 tiny] (main.py 226): INFO Train: [270/300][400/1251]	eta 0:08:50 lr 0.000034	time 0.6907 (0.6230)	loss 2.6994 (3.5932)	grad_norm 10.2700 (9.1806)	mem 5325MB
[2022-04-21 16:20:27 tiny] (main.py 226): INFO Train: [270/300][500/1251]	eta 0:07:42 lr 0.000034	time 0.5707 (0.6161)	loss 2.7253 (3.6036)	grad_norm 12.4465 (9.1914)	mem 5325MB
[2022-04-21 16:21:26 tiny] (main.py 226): INFO Train: [270/300][600/1251]	eta 0:06:38 lr 0.000033	time 0.6419 (0.6114)	loss 3.9615 (3.6138)	grad_norm 5.9189 (9.2044)	mem 5325MB
[2022-04-21 16:22:25 tiny] (main.py 226): INFO Train: [270/300][700/1251]	eta 0:05:35 lr 0.000033	time 0.7030 (0.6083)	loss 4.0335 (3.6236)	grad_norm 6.2097 (9.0890)	mem 5325MB
[2022-04-21 16:23:24 tiny] (main.py 226): INFO Train: [270/300][800/1251]	eta 0:04:33 lr 0.000033	time 0.4962 (0.6057)	loss 2.9525 (3.6399)	grad_norm 7.9866 (9.0211)	mem 5325MB
[2022-04-21 16:24:23 tiny] (main.py 226): INFO Train: [270/300][900/1251]	eta 0:03:31 lr 0.000033	time 0.3212 (0.6038)	loss 2.7748 (3.6352)	grad_norm 5.4905 (8.9872)	mem 5325MB
[2022-04-21 16:25:22 tiny] (main.py 226): INFO Train: [270/300][1000/1251]	eta 0:02:31 lr 0.000033	time 0.5925 (0.6024)	loss 2.3033 (3.6328)	grad_norm 7.1787 (8.9958)	mem 5325MB
[2022-04-21 16:26:21 tiny] (main.py 226): INFO Train: [270/300][1100/1251]	eta 0:01:30 lr 0.000033	time 0.4106 (0.6013)	loss 3.4860 (3.6284)	grad_norm 11.9486 (8.9811)	mem 5325MB
[2022-04-21 16:27:20 tiny] (main.py 226): INFO Train: [270/300][1200/1251]	eta 0:00:30 lr 0.000033	time 0.6227 (0.6004)	loss 4.3707 (3.6350)	grad_norm 8.6531 (8.9901)	mem 5325MB
[2022-04-21 16:27:42 tiny] (main.py 233): INFO EPOCH 270 training takes 0:12:22
[2022-04-21 16:27:53 tiny] (main.py 273): INFO Test: [0/49]	Time 11.493 (11.493)	Loss 1.4711 (1.4711)	Acc@1 70.996 (70.996)	Acc@5 90.332 (90.332)	Mem 5325MB
[2022-04-21 16:28:13 tiny] (main.py 279): INFO  * Acc@1 72.314 Acc@5 90.896
[2022-04-21 16:28:13 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.3%
[2022-04-21 16:28:13 tiny] (main.py 148): INFO Max accuracy: 72.37%
[2022-04-21 16:28:25 tiny] (main.py 226): INFO Train: [271/300][0/1251]	eta 4:02:15 lr 0.000033	time 11.6193 (11.6193)	loss 2.9990 (2.9990)	grad_norm 6.2652 (6.2652)	mem 5325MB
[2022-04-21 16:29:27 tiny] (main.py 226): INFO Train: [271/300][100/1251]	eta 0:13:59 lr 0.000033	time 0.6259 (0.7290)	loss 3.4078 (3.6391)	grad_norm 11.1807 (9.4349)	mem 5325MB
[2022-04-21 16:30:25 tiny] (main.py 226): INFO Train: [271/300][200/1251]	eta 0:11:31 lr 0.000032	time 0.4057 (0.6578)	loss 3.1054 (3.6497)	grad_norm 5.7147 (8.8626)	mem 5325MB
[2022-04-21 16:31:24 tiny] (main.py 226): INFO Train: [271/300][300/1251]	eta 0:10:03 lr 0.000032	time 0.4697 (0.6346)	loss 3.7521 (3.6418)	grad_norm 8.6347 (8.8878)	mem 5325MB
[2022-04-21 16:32:23 tiny] (main.py 226): INFO Train: [271/300][400/1251]	eta 0:08:49 lr 0.000032	time 0.4776 (0.6226)	loss 3.9201 (3.6440)	grad_norm 5.7927 (8.9521)	mem 5325MB
[2022-04-21 16:33:21 tiny] (main.py 226): INFO Train: [271/300][500/1251]	eta 0:07:42 lr 0.000032	time 0.4937 (0.6155)	loss 3.7439 (3.6207)	grad_norm 7.5361 (8.7864)	mem 5325MB
[2022-04-21 16:34:20 tiny] (main.py 226): INFO Train: [271/300][600/1251]	eta 0:06:37 lr 0.000032	time 0.9156 (0.6108)	loss 3.6243 (3.6344)	grad_norm 7.0541 (8.9791)	mem 5325MB
[2022-04-21 16:35:19 tiny] (main.py 226): INFO Train: [271/300][700/1251]	eta 0:05:34 lr 0.000032	time 0.4748 (0.6074)	loss 3.0413 (3.6398)	grad_norm 12.3340 (8.9317)	mem 5325MB
[2022-04-21 16:36:18 tiny] (main.py 226): INFO Train: [271/300][800/1251]	eta 0:04:32 lr 0.000032	time 0.5567 (0.6053)	loss 3.6953 (3.6308)	grad_norm 8.4695 (9.0989)	mem 5325MB
[2022-04-21 16:37:17 tiny] (main.py 226): INFO Train: [271/300][900/1251]	eta 0:03:31 lr 0.000032	time 0.5636 (0.6034)	loss 2.9389 (3.6292)	grad_norm 13.8856 (9.2101)	mem 5325MB
[2022-04-21 16:38:16 tiny] (main.py 226): INFO Train: [271/300][1000/1251]	eta 0:02:31 lr 0.000031	time 0.7668 (0.6019)	loss 2.6968 (3.6284)	grad_norm 8.4920 (9.2167)	mem 5325MB
[2022-04-21 16:39:15 tiny] (main.py 226): INFO Train: [271/300][1100/1251]	eta 0:01:30 lr 0.000031	time 0.5953 (0.6011)	loss 3.7925 (3.6350)	grad_norm 5.7572 (9.2214)	mem 5325MB
[2022-04-21 16:40:14 tiny] (main.py 226): INFO Train: [271/300][1200/1251]	eta 0:00:30 lr 0.000031	time 0.6447 (0.6001)	loss 3.7953 (3.6350)	grad_norm 8.2711 (nan)	mem 5325MB
[2022-04-21 16:40:36 tiny] (main.py 233): INFO EPOCH 271 training takes 0:12:23
[2022-04-21 16:40:48 tiny] (main.py 273): INFO Test: [0/49]	Time 12.214 (12.214)	Loss 1.4333 (1.4333)	Acc@1 72.656 (72.656)	Acc@5 90.820 (90.820)	Mem 5325MB
[2022-04-21 16:41:07 tiny] (main.py 279): INFO  * Acc@1 72.340 Acc@5 90.978
[2022-04-21 16:41:07 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.3%
[2022-04-21 16:41:07 tiny] (main.py 148): INFO Max accuracy: 72.37%
[2022-04-21 16:41:18 tiny] (main.py 226): INFO Train: [272/300][0/1251]	eta 3:52:45 lr 0.000031	time 11.1636 (11.1636)	loss 3.8039 (3.8039)	grad_norm 14.0804 (14.0804)	mem 5325MB
[2022-04-21 16:42:21 tiny] (main.py 226): INFO Train: [272/300][100/1251]	eta 0:13:57 lr 0.000031	time 0.6108 (0.7275)	loss 3.0511 (3.5783)	grad_norm 6.3151 (9.3797)	mem 5325MB
[2022-04-21 16:43:19 tiny] (main.py 226): INFO Train: [272/300][200/1251]	eta 0:11:30 lr 0.000031	time 0.5695 (0.6567)	loss 4.4261 (3.5909)	grad_norm 7.4588 (9.5753)	mem 5325MB
[2022-04-21 16:44:18 tiny] (main.py 226): INFO Train: [272/300][300/1251]	eta 0:10:02 lr 0.000031	time 0.5487 (0.6336)	loss 3.9876 (3.6155)	grad_norm 6.6856 (9.1389)	mem 5325MB
[2022-04-21 16:45:17 tiny] (main.py 226): INFO Train: [272/300][400/1251]	eta 0:08:50 lr 0.000031	time 0.5215 (0.6239)	loss 3.0879 (3.6149)	grad_norm 10.5137 (9.2660)	mem 5325MB
[2022-04-21 16:46:15 tiny] (main.py 226): INFO Train: [272/300][500/1251]	eta 0:07:41 lr 0.000031	time 0.5824 (0.6150)	loss 3.5974 (3.6263)	grad_norm 11.7893 (nan)	mem 5325MB
[2022-04-21 16:47:14 tiny] (main.py 226): INFO Train: [272/300][600/1251]	eta 0:06:37 lr 0.000030	time 0.4243 (0.6106)	loss 3.9634 (3.6344)	grad_norm 8.5492 (nan)	mem 5325MB
[2022-04-21 16:48:14 tiny] (main.py 226): INFO Train: [272/300][700/1251]	eta 0:05:35 lr 0.000030	time 0.6267 (0.6087)	loss 3.6316 (3.6298)	grad_norm 9.3989 (nan)	mem 5325MB
[2022-04-21 16:49:12 tiny] (main.py 226): INFO Train: [272/300][800/1251]	eta 0:04:33 lr 0.000030	time 0.5333 (0.6056)	loss 2.5233 (3.6262)	grad_norm 7.8397 (nan)	mem 5325MB
[2022-04-21 16:50:11 tiny] (main.py 226): INFO Train: [272/300][900/1251]	eta 0:03:31 lr 0.000030	time 0.6802 (0.6037)	loss 2.5916 (3.6400)	grad_norm 6.1576 (nan)	mem 5325MB
[2022-04-21 16:51:10 tiny] (main.py 226): INFO Train: [272/300][1000/1251]	eta 0:02:31 lr 0.000030	time 0.5895 (0.6027)	loss 3.2493 (3.6363)	grad_norm 10.6956 (nan)	mem 5325MB
[2022-04-21 16:52:09 tiny] (main.py 226): INFO Train: [272/300][1100/1251]	eta 0:01:30 lr 0.000030	time 0.5309 (0.6011)	loss 3.7805 (3.6436)	grad_norm 8.4881 (nan)	mem 5325MB
[2022-04-21 16:53:08 tiny] (main.py 226): INFO Train: [272/300][1200/1251]	eta 0:00:30 lr 0.000030	time 0.6242 (0.6003)	loss 4.0614 (3.6438)	grad_norm 7.5534 (nan)	mem 5325MB
[2022-04-21 16:53:31 tiny] (main.py 233): INFO EPOCH 272 training takes 0:12:23
[2022-04-21 16:53:42 tiny] (main.py 273): INFO Test: [0/49]	Time 11.558 (11.558)	Loss 1.4422 (1.4422)	Acc@1 71.680 (71.680)	Acc@5 90.039 (90.039)	Mem 5325MB
[2022-04-21 16:54:02 tiny] (main.py 279): INFO  * Acc@1 72.356 Acc@5 90.978
[2022-04-21 16:54:02 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.4%
[2022-04-21 16:54:02 tiny] (main.py 148): INFO Max accuracy: 72.37%
[2022-04-21 16:54:14 tiny] (main.py 226): INFO Train: [273/300][0/1251]	eta 4:11:02 lr 0.000030	time 12.0406 (12.0406)	loss 4.4191 (4.4191)	grad_norm 6.7833 (6.7833)	mem 5325MB
[2022-04-21 16:55:15 tiny] (main.py 226): INFO Train: [273/300][100/1251]	eta 0:13:59 lr 0.000030	time 0.6787 (0.7292)	loss 2.5504 (3.6549)	grad_norm 7.5049 (8.8355)	mem 5325MB
[2022-04-21 16:56:14 tiny] (main.py 226): INFO Train: [273/300][200/1251]	eta 0:11:32 lr 0.000029	time 0.5651 (0.6585)	loss 2.3711 (3.6270)	grad_norm 7.2549 (9.0526)	mem 5325MB
[2022-04-21 16:57:13 tiny] (main.py 226): INFO Train: [273/300][300/1251]	eta 0:10:02 lr 0.000029	time 0.7423 (0.6339)	loss 4.3000 (3.6254)	grad_norm 7.7215 (8.9649)	mem 5325MB
[2022-04-21 16:58:11 tiny] (main.py 226): INFO Train: [273/300][400/1251]	eta 0:08:48 lr 0.000029	time 0.4744 (0.6212)	loss 4.3316 (3.6275)	grad_norm 15.1390 (8.8708)	mem 5325MB
[2022-04-21 16:59:09 tiny] (main.py 226): INFO Train: [273/300][500/1251]	eta 0:07:41 lr 0.000029	time 0.5383 (0.6141)	loss 3.7573 (3.6277)	grad_norm 6.8131 (8.8614)	mem 5325MB
[2022-04-21 17:00:09 tiny] (main.py 226): INFO Train: [273/300][600/1251]	eta 0:06:37 lr 0.000029	time 0.8011 (0.6108)	loss 3.1599 (3.6259)	grad_norm 7.2307 (8.8915)	mem 5325MB
[2022-04-21 17:01:07 tiny] (main.py 226): INFO Train: [273/300][700/1251]	eta 0:05:34 lr 0.000029	time 0.7154 (0.6073)	loss 4.0050 (3.6311)	grad_norm 9.9306 (8.9072)	mem 5325MB
[2022-04-21 17:02:07 tiny] (main.py 226): INFO Train: [273/300][800/1251]	eta 0:04:33 lr 0.000029	time 0.5843 (0.6054)	loss 2.5125 (3.6314)	grad_norm 13.8604 (9.0665)	mem 5325MB
[2022-04-21 17:03:06 tiny] (main.py 226): INFO Train: [273/300][900/1251]	eta 0:03:31 lr 0.000029	time 0.4150 (0.6039)	loss 3.4447 (3.6219)	grad_norm 10.4501 (9.1299)	mem 5325MB
[2022-04-21 17:04:05 tiny] (main.py 226): INFO Train: [273/300][1000/1251]	eta 0:02:31 lr 0.000029	time 0.6734 (0.6028)	loss 4.2918 (3.6151)	grad_norm 8.4495 (9.0770)	mem 5325MB
[2022-04-21 17:05:04 tiny] (main.py 226): INFO Train: [273/300][1100/1251]	eta 0:01:30 lr 0.000028	time 0.6892 (0.6016)	loss 2.6311 (3.6089)	grad_norm 11.0815 (9.1706)	mem 5325MB
[2022-04-21 17:06:03 tiny] (main.py 226): INFO Train: [273/300][1200/1251]	eta 0:00:30 lr 0.000028	time 0.6107 (0.6005)	loss 2.4591 (3.6062)	grad_norm 7.0981 (9.1535)	mem 5325MB
[2022-04-21 17:06:27 tiny] (main.py 233): INFO EPOCH 273 training takes 0:12:24
[2022-04-21 17:06:38 tiny] (main.py 273): INFO Test: [0/49]	Time 11.921 (11.921)	Loss 1.3218 (1.3218)	Acc@1 74.609 (74.609)	Acc@5 91.992 (91.992)	Mem 5325MB
[2022-04-21 17:06:58 tiny] (main.py 279): INFO  * Acc@1 72.382 Acc@5 91.024
[2022-04-21 17:06:58 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.4%
[2022-04-21 17:06:58 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_273.pth saving......
[2022-04-21 17:06:58 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_273.pth saved !!!
[2022-04-21 17:06:58 tiny] (main.py 148): INFO Max accuracy: 72.38%
[2022-04-21 17:07:10 tiny] (main.py 226): INFO Train: [274/300][0/1251]	eta 3:59:36 lr 0.000028	time 11.4917 (11.4917)	loss 3.3747 (3.3747)	grad_norm 10.3569 (10.3569)	mem 5325MB
[2022-04-21 17:08:11 tiny] (main.py 226): INFO Train: [274/300][100/1251]	eta 0:13:57 lr 0.000028	time 0.6800 (0.7274)	loss 3.8652 (3.6307)	grad_norm 6.3959 (8.9928)	mem 5325MB
[2022-04-21 17:09:10 tiny] (main.py 226): INFO Train: [274/300][200/1251]	eta 0:11:29 lr 0.000028	time 0.6249 (0.6561)	loss 3.9359 (3.5989)	grad_norm 6.6190 (8.9732)	mem 5325MB
[2022-04-21 17:10:08 tiny] (main.py 226): INFO Train: [274/300][300/1251]	eta 0:10:00 lr 0.000028	time 0.3563 (0.6318)	loss 3.8373 (3.5899)	grad_norm 10.1803 (8.9304)	mem 5325MB
[2022-04-21 17:11:07 tiny] (main.py 226): INFO Train: [274/300][400/1251]	eta 0:08:48 lr 0.000028	time 0.6211 (0.6210)	loss 3.4297 (3.5839)	grad_norm 8.1058 (8.9674)	mem 5325MB
[2022-04-21 17:12:06 tiny] (main.py 226): INFO Train: [274/300][500/1251]	eta 0:07:41 lr 0.000028	time 0.6239 (0.6146)	loss 3.7717 (3.5793)	grad_norm 6.4896 (9.0561)	mem 5325MB
[2022-04-21 17:13:05 tiny] (main.py 226): INFO Train: [274/300][600/1251]	eta 0:06:37 lr 0.000028	time 0.6656 (0.6101)	loss 3.8824 (3.6026)	grad_norm 15.1446 (9.1679)	mem 5325MB
[2022-04-21 17:14:04 tiny] (main.py 226): INFO Train: [274/300][700/1251]	eta 0:05:34 lr 0.000027	time 0.5490 (0.6075)	loss 3.5388 (3.6002)	grad_norm 11.2230 (9.1814)	mem 5325MB
[2022-04-21 17:15:03 tiny] (main.py 226): INFO Train: [274/300][800/1251]	eta 0:04:32 lr 0.000027	time 0.7061 (0.6049)	loss 3.7332 (3.6016)	grad_norm 6.2835 (9.1915)	mem 5325MB
[2022-04-21 17:16:02 tiny] (main.py 226): INFO Train: [274/300][900/1251]	eta 0:03:31 lr 0.000027	time 0.5267 (0.6032)	loss 3.0269 (3.6002)	grad_norm 5.7826 (9.2611)	mem 5325MB
[2022-04-21 17:17:01 tiny] (main.py 226): INFO Train: [274/300][1000/1251]	eta 0:02:31 lr 0.000027	time 0.4452 (0.6019)	loss 3.6833 (3.6093)	grad_norm 9.0512 (9.3086)	mem 5325MB
[2022-04-21 17:18:00 tiny] (main.py 226): INFO Train: [274/300][1100/1251]	eta 0:01:30 lr 0.000027	time 0.6639 (0.6009)	loss 3.5673 (3.6128)	grad_norm 7.3860 (9.2741)	mem 5325MB
[2022-04-21 17:18:58 tiny] (main.py 226): INFO Train: [274/300][1200/1251]	eta 0:00:30 lr 0.000027	time 0.6612 (0.5997)	loss 2.7216 (3.6107)	grad_norm 7.9335 (9.2483)	mem 5325MB
[2022-04-21 17:19:20 tiny] (main.py 233): INFO EPOCH 274 training takes 0:12:22
[2022-04-21 17:19:32 tiny] (main.py 273): INFO Test: [0/49]	Time 11.383 (11.383)	Loss 1.4586 (1.4586)	Acc@1 71.875 (71.875)	Acc@5 89.844 (89.844)	Mem 5325MB
[2022-04-21 17:19:52 tiny] (main.py 279): INFO  * Acc@1 72.364 Acc@5 90.904
[2022-04-21 17:19:52 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.4%
[2022-04-21 17:19:52 tiny] (main.py 148): INFO Max accuracy: 72.38%
[2022-04-21 17:20:02 tiny] (main.py 226): INFO Train: [275/300][0/1251]	eta 3:33:58 lr 0.000027	time 10.2623 (10.2623)	loss 3.7128 (3.7128)	grad_norm 6.6590 (6.6590)	mem 5325MB
[2022-04-21 17:21:05 tiny] (main.py 226): INFO Train: [275/300][100/1251]	eta 0:14:01 lr 0.000027	time 0.6167 (0.7308)	loss 3.2127 (3.6260)	grad_norm 6.6712 (8.8741)	mem 5325MB
[2022-04-21 17:22:04 tiny] (main.py 226): INFO Train: [275/300][200/1251]	eta 0:11:33 lr 0.000027	time 0.7642 (0.6594)	loss 3.2108 (3.6314)	grad_norm 9.8189 (8.7016)	mem 5325MB
[2022-04-21 17:23:02 tiny] (main.py 226): INFO Train: [275/300][300/1251]	eta 0:10:02 lr 0.000027	time 0.4141 (0.6331)	loss 4.4781 (3.6185)	grad_norm 8.8660 (8.8547)	mem 5325MB
[2022-04-21 17:24:01 tiny] (main.py 226): INFO Train: [275/300][400/1251]	eta 0:08:49 lr 0.000026	time 0.5467 (0.6222)	loss 3.8849 (3.6078)	grad_norm 7.0144 (8.9999)	mem 5325MB
[2022-04-21 17:25:00 tiny] (main.py 226): INFO Train: [275/300][500/1251]	eta 0:07:42 lr 0.000026	time 0.6043 (0.6157)	loss 3.5580 (3.6057)	grad_norm 6.5464 (9.0196)	mem 5325MB
[2022-04-21 17:25:59 tiny] (main.py 226): INFO Train: [275/300][600/1251]	eta 0:06:38 lr 0.000026	time 0.7847 (0.6116)	loss 3.8168 (3.5940)	grad_norm 12.7139 (9.1223)	mem 5325MB
[2022-04-21 17:26:58 tiny] (main.py 226): INFO Train: [275/300][700/1251]	eta 0:05:35 lr 0.000026	time 0.5216 (0.6081)	loss 3.3918 (3.5977)	grad_norm 9.2386 (9.1825)	mem 5325MB
[2022-04-21 17:27:57 tiny] (main.py 226): INFO Train: [275/300][800/1251]	eta 0:04:33 lr 0.000026	time 0.7271 (0.6058)	loss 4.1107 (3.5985)	grad_norm 12.2712 (9.2938)	mem 5325MB
[2022-04-21 17:28:56 tiny] (main.py 226): INFO Train: [275/300][900/1251]	eta 0:03:31 lr 0.000026	time 0.6293 (0.6038)	loss 4.3401 (3.6094)	grad_norm 7.8026 (9.2942)	mem 5325MB
[2022-04-21 17:29:55 tiny] (main.py 226): INFO Train: [275/300][1000/1251]	eta 0:02:31 lr 0.000026	time 0.5664 (0.6025)	loss 4.3357 (3.6154)	grad_norm 11.9504 (9.3039)	mem 5325MB
[2022-04-21 17:30:54 tiny] (main.py 226): INFO Train: [275/300][1100/1251]	eta 0:01:30 lr 0.000026	time 0.6908 (0.6014)	loss 4.5729 (3.6241)	grad_norm 9.8101 (9.3241)	mem 5325MB
[2022-04-21 17:31:53 tiny] (main.py 226): INFO Train: [275/300][1200/1251]	eta 0:00:30 lr 0.000026	time 0.5942 (0.6003)	loss 3.5233 (3.6211)	grad_norm 5.8148 (9.3245)	mem 5325MB
[2022-04-21 17:32:14 tiny] (main.py 233): INFO EPOCH 275 training takes 0:12:22
[2022-04-21 17:32:25 tiny] (main.py 273): INFO Test: [0/49]	Time 11.234 (11.234)	Loss 1.4496 (1.4496)	Acc@1 72.852 (72.852)	Acc@5 90.332 (90.332)	Mem 5325MB
[2022-04-21 17:32:45 tiny] (main.py 279): INFO  * Acc@1 72.432 Acc@5 90.906
[2022-04-21 17:32:45 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.4%
[2022-04-21 17:32:45 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_275.pth saving......
[2022-04-21 17:32:45 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_275.pth saved !!!
[2022-04-21 17:32:45 tiny] (main.py 148): INFO Max accuracy: 72.43%
[2022-04-21 17:32:57 tiny] (main.py 226): INFO Train: [276/300][0/1251]	eta 4:05:11 lr 0.000026	time 11.7598 (11.7598)	loss 2.9260 (2.9260)	grad_norm 10.4687 (10.4687)	mem 5325MB
[2022-04-21 17:34:00 tiny] (main.py 226): INFO Train: [276/300][100/1251]	eta 0:14:09 lr 0.000025	time 0.5131 (0.7383)	loss 3.9454 (3.6166)	grad_norm 10.7653 (9.1215)	mem 5325MB
[2022-04-21 17:34:57 tiny] (main.py 226): INFO Train: [276/300][200/1251]	eta 0:11:32 lr 0.000025	time 0.4997 (0.6592)	loss 3.8734 (3.5864)	grad_norm 8.1336 (8.9676)	mem 5325MB
[2022-04-21 17:35:56 tiny] (main.py 226): INFO Train: [276/300][300/1251]	eta 0:10:04 lr 0.000025	time 0.5258 (0.6356)	loss 3.8138 (3.5687)	grad_norm 5.6737 (8.9177)	mem 5325MB
[2022-04-21 17:36:54 tiny] (main.py 226): INFO Train: [276/300][400/1251]	eta 0:08:49 lr 0.000025	time 0.4549 (0.6221)	loss 3.0129 (3.5612)	grad_norm 4.7360 (9.2904)	mem 5325MB
[2022-04-21 17:37:54 tiny] (main.py 226): INFO Train: [276/300][500/1251]	eta 0:07:42 lr 0.000025	time 0.6452 (0.6163)	loss 3.2871 (3.5671)	grad_norm 7.2281 (9.1483)	mem 5325MB
[2022-04-21 17:38:52 tiny] (main.py 226): INFO Train: [276/300][600/1251]	eta 0:06:37 lr 0.000025	time 0.5711 (0.6112)	loss 2.8238 (3.5698)	grad_norm 11.3328 (nan)	mem 5325MB
[2022-04-21 17:39:51 tiny] (main.py 226): INFO Train: [276/300][700/1251]	eta 0:05:34 lr 0.000025	time 0.5731 (0.6076)	loss 3.6869 (3.5886)	grad_norm 9.7864 (nan)	mem 5325MB
[2022-04-21 17:40:50 tiny] (main.py 226): INFO Train: [276/300][800/1251]	eta 0:04:33 lr 0.000025	time 0.6692 (0.6057)	loss 4.4195 (3.5986)	grad_norm 8.8523 (nan)	mem 5325MB
[2022-04-21 17:41:49 tiny] (main.py 226): INFO Train: [276/300][900/1251]	eta 0:03:32 lr 0.000025	time 0.4366 (0.6041)	loss 2.6956 (3.5974)	grad_norm 9.0059 (nan)	mem 5325MB
[2022-04-21 17:42:48 tiny] (main.py 226): INFO Train: [276/300][1000/1251]	eta 0:02:31 lr 0.000025	time 0.7544 (0.6023)	loss 3.7884 (3.6032)	grad_norm 8.7401 (nan)	mem 5325MB
[2022-04-21 17:43:47 tiny] (main.py 226): INFO Train: [276/300][1100/1251]	eta 0:01:30 lr 0.000024	time 0.8005 (0.6014)	loss 3.4901 (3.6017)	grad_norm 9.8221 (nan)	mem 5325MB
[2022-04-21 17:44:46 tiny] (main.py 226): INFO Train: [276/300][1200/1251]	eta 0:00:30 lr 0.000024	time 0.4975 (0.6004)	loss 3.9279 (3.5972)	grad_norm 6.0660 (nan)	mem 5325MB
[2022-04-21 17:45:08 tiny] (main.py 233): INFO EPOCH 276 training takes 0:12:23
[2022-04-21 17:45:20 tiny] (main.py 273): INFO Test: [0/49]	Time 11.629 (11.629)	Loss 1.3844 (1.3844)	Acc@1 71.387 (71.387)	Acc@5 91.602 (91.602)	Mem 5325MB
[2022-04-21 17:45:39 tiny] (main.py 279): INFO  * Acc@1 72.506 Acc@5 90.868
[2022-04-21 17:45:39 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.5%
[2022-04-21 17:45:39 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_276.pth saving......
[2022-04-21 17:45:39 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_276.pth saved !!!
[2022-04-21 17:45:39 tiny] (main.py 148): INFO Max accuracy: 72.51%
[2022-04-21 17:45:51 tiny] (main.py 226): INFO Train: [277/300][0/1251]	eta 4:04:48 lr 0.000024	time 11.7415 (11.7415)	loss 3.8285 (3.8285)	grad_norm 12.9975 (12.9975)	mem 5325MB
[2022-04-21 17:46:53 tiny] (main.py 226): INFO Train: [277/300][100/1251]	eta 0:14:04 lr 0.000024	time 0.4709 (0.7336)	loss 2.6925 (3.5858)	grad_norm 6.3435 (9.7802)	mem 5325MB
[2022-04-21 17:47:51 tiny] (main.py 226): INFO Train: [277/300][200/1251]	eta 0:11:32 lr 0.000024	time 0.5703 (0.6587)	loss 4.4224 (3.6000)	grad_norm 9.1476 (9.3926)	mem 5325MB
[2022-04-21 17:48:50 tiny] (main.py 226): INFO Train: [277/300][300/1251]	eta 0:10:04 lr 0.000024	time 0.7528 (0.6355)	loss 3.7639 (3.5787)	grad_norm 10.2941 (9.2849)	mem 5325MB
[2022-04-21 17:49:49 tiny] (main.py 226): INFO Train: [277/300][400/1251]	eta 0:08:50 lr 0.000024	time 0.6697 (0.6231)	loss 4.3764 (3.5935)	grad_norm 6.7344 (9.1673)	mem 5325MB
[2022-04-21 17:50:47 tiny] (main.py 226): INFO Train: [277/300][500/1251]	eta 0:07:41 lr 0.000024	time 0.7139 (0.6150)	loss 2.6563 (3.6000)	grad_norm 8.5954 (9.1906)	mem 5325MB
[2022-04-21 17:51:47 tiny] (main.py 226): INFO Train: [277/300][600/1251]	eta 0:06:38 lr 0.000024	time 0.7831 (0.6115)	loss 3.5963 (3.5760)	grad_norm 10.1839 (9.4926)	mem 5325MB
[2022-04-21 17:52:45 tiny] (main.py 226): INFO Train: [277/300][700/1251]	eta 0:05:35 lr 0.000024	time 0.5518 (0.6080)	loss 4.5335 (3.5894)	grad_norm 10.3637 (9.5946)	mem 5325MB
[2022-04-21 17:53:45 tiny] (main.py 226): INFO Train: [277/300][800/1251]	eta 0:04:33 lr 0.000024	time 0.8754 (0.6061)	loss 4.1398 (3.5983)	grad_norm 7.4915 (9.6053)	mem 5325MB
[2022-04-21 17:54:43 tiny] (main.py 226): INFO Train: [277/300][900/1251]	eta 0:03:31 lr 0.000023	time 0.6796 (0.6039)	loss 3.8425 (3.6033)	grad_norm 22.9897 (9.6613)	mem 5325MB
[2022-04-21 17:55:42 tiny] (main.py 226): INFO Train: [277/300][1000/1251]	eta 0:02:31 lr 0.000023	time 0.4702 (0.6020)	loss 3.5785 (3.5977)	grad_norm 15.2017 (9.5754)	mem 5325MB
[2022-04-21 17:56:41 tiny] (main.py 226): INFO Train: [277/300][1100/1251]	eta 0:01:30 lr 0.000023	time 0.5458 (0.6011)	loss 4.5018 (3.6054)	grad_norm 8.6642 (9.6347)	mem 5325MB
[2022-04-21 17:57:39 tiny] (main.py 226): INFO Train: [277/300][1200/1251]	eta 0:00:30 lr 0.000023	time 0.4631 (0.5998)	loss 2.8672 (3.6016)	grad_norm 11.0244 (9.6471)	mem 5325MB
[2022-04-21 17:58:01 tiny] (main.py 233): INFO EPOCH 277 training takes 0:12:22
[2022-04-21 17:58:13 tiny] (main.py 273): INFO Test: [0/49]	Time 11.663 (11.663)	Loss 1.4851 (1.4851)	Acc@1 72.266 (72.266)	Acc@5 90.723 (90.723)	Mem 5325MB
[2022-04-21 17:58:32 tiny] (main.py 279): INFO  * Acc@1 72.480 Acc@5 90.958
[2022-04-21 17:58:32 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.5%
[2022-04-21 17:58:32 tiny] (main.py 148): INFO Max accuracy: 72.51%
[2022-04-21 17:58:43 tiny] (main.py 226): INFO Train: [278/300][0/1251]	eta 3:53:44 lr 0.000023	time 11.2107 (11.2107)	loss 3.5758 (3.5758)	grad_norm 11.4028 (11.4028)	mem 5325MB
[2022-04-21 17:59:46 tiny] (main.py 226): INFO Train: [278/300][100/1251]	eta 0:14:01 lr 0.000023	time 0.5761 (0.7311)	loss 3.2193 (3.4592)	grad_norm 7.6930 (8.9525)	mem 5325MB
[2022-04-21 18:00:45 tiny] (main.py 226): INFO Train: [278/300][200/1251]	eta 0:11:33 lr 0.000023	time 0.5203 (0.6597)	loss 2.9924 (3.5267)	grad_norm 8.4510 (9.0308)	mem 5325MB
[2022-04-21 18:01:43 tiny] (main.py 226): INFO Train: [278/300][300/1251]	eta 0:10:03 lr 0.000023	time 0.5846 (0.6346)	loss 3.4093 (3.5630)	grad_norm 9.1977 (9.1607)	mem 5325MB
[2022-04-21 18:02:42 tiny] (main.py 226): INFO Train: [278/300][400/1251]	eta 0:08:50 lr 0.000023	time 0.6920 (0.6235)	loss 3.3968 (3.5742)	grad_norm 9.6874 (9.2358)	mem 5325MB
[2022-04-21 18:03:40 tiny] (main.py 226): INFO Train: [278/300][500/1251]	eta 0:07:42 lr 0.000023	time 0.5332 (0.6154)	loss 4.0906 (3.5545)	grad_norm 9.2697 (9.3664)	mem 5325MB
[2022-04-21 18:04:39 tiny] (main.py 226): INFO Train: [278/300][600/1251]	eta 0:06:37 lr 0.000023	time 0.6343 (0.6104)	loss 3.4301 (3.5452)	grad_norm 9.6077 (9.3248)	mem 5325MB
[2022-04-21 18:05:38 tiny] (main.py 226): INFO Train: [278/300][700/1251]	eta 0:05:34 lr 0.000022	time 0.6073 (0.6078)	loss 3.9426 (3.5530)	grad_norm 14.3281 (9.3057)	mem 5325MB
[2022-04-21 18:06:37 tiny] (main.py 226): INFO Train: [278/300][800/1251]	eta 0:04:32 lr 0.000022	time 0.5532 (0.6051)	loss 3.8775 (3.5507)	grad_norm 8.1686 (9.3267)	mem 5325MB
[2022-04-21 18:07:36 tiny] (main.py 226): INFO Train: [278/300][900/1251]	eta 0:03:31 lr 0.000022	time 0.6370 (0.6036)	loss 4.5149 (3.5642)	grad_norm 7.3974 (9.3837)	mem 5325MB
[2022-04-21 18:08:35 tiny] (main.py 226): INFO Train: [278/300][1000/1251]	eta 0:02:31 lr 0.000022	time 0.6128 (0.6023)	loss 3.7706 (3.5656)	grad_norm 12.2919 (9.3960)	mem 5325MB
[2022-04-21 18:09:34 tiny] (main.py 226): INFO Train: [278/300][1100/1251]	eta 0:01:30 lr 0.000022	time 0.6153 (0.6010)	loss 3.8198 (3.5636)	grad_norm 6.7082 (9.5410)	mem 5325MB
[2022-04-21 18:10:33 tiny] (main.py 226): INFO Train: [278/300][1200/1251]	eta 0:00:30 lr 0.000022	time 0.5685 (0.6001)	loss 2.7340 (3.5621)	grad_norm 7.0470 (9.4812)	mem 5325MB
[2022-04-21 18:10:55 tiny] (main.py 233): INFO EPOCH 278 training takes 0:12:22
[2022-04-21 18:11:07 tiny] (main.py 273): INFO Test: [0/49]	Time 12.046 (12.046)	Loss 1.3651 (1.3651)	Acc@1 73.828 (73.828)	Acc@5 92.969 (92.969)	Mem 5325MB
[2022-04-21 18:11:26 tiny] (main.py 279): INFO  * Acc@1 72.676 Acc@5 90.954
[2022-04-21 18:11:26 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.7%
[2022-04-21 18:11:26 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_278.pth saving......
[2022-04-21 18:11:26 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_278.pth saved !!!
[2022-04-21 18:11:26 tiny] (main.py 148): INFO Max accuracy: 72.68%
[2022-04-21 18:11:37 tiny] (main.py 226): INFO Train: [279/300][0/1251]	eta 3:50:11 lr 0.000022	time 11.0404 (11.0404)	loss 3.5763 (3.5763)	grad_norm 7.8233 (7.8233)	mem 5325MB
[2022-04-21 18:12:40 tiny] (main.py 226): INFO Train: [279/300][100/1251]	eta 0:14:02 lr 0.000022	time 0.8020 (0.7322)	loss 3.8913 (3.5902)	grad_norm 9.6144 (10.0842)	mem 5325MB
[2022-04-21 18:13:38 tiny] (main.py 226): INFO Train: [279/300][200/1251]	eta 0:11:32 lr 0.000022	time 0.5023 (0.6591)	loss 2.3781 (3.6028)	grad_norm 9.9694 (9.5800)	mem 5325MB
[2022-04-21 18:14:37 tiny] (main.py 226): INFO Train: [279/300][300/1251]	eta 0:10:03 lr 0.000022	time 0.7190 (0.6350)	loss 4.5019 (3.5609)	grad_norm 6.0382 (9.7399)	mem 5325MB
[2022-04-21 18:15:36 tiny] (main.py 226): INFO Train: [279/300][400/1251]	eta 0:08:50 lr 0.000022	time 0.6130 (0.6235)	loss 3.7635 (3.5917)	grad_norm 6.2997 (9.5477)	mem 5325MB
[2022-04-21 18:16:35 tiny] (main.py 226): INFO Train: [279/300][500/1251]	eta 0:07:43 lr 0.000021	time 0.4395 (0.6169)	loss 2.9064 (3.5954)	grad_norm 6.4399 (9.5378)	mem 5325MB
[2022-04-21 18:17:33 tiny] (main.py 226): INFO Train: [279/300][600/1251]	eta 0:06:38 lr 0.000021	time 0.5431 (0.6115)	loss 2.7733 (3.6063)	grad_norm 7.3475 (9.5712)	mem 5325MB
[2022-04-21 18:18:32 tiny] (main.py 226): INFO Train: [279/300][700/1251]	eta 0:05:35 lr 0.000021	time 0.5149 (0.6080)	loss 3.9349 (3.5933)	grad_norm 13.1683 (9.5540)	mem 5325MB
[2022-04-21 18:19:31 tiny] (main.py 226): INFO Train: [279/300][800/1251]	eta 0:04:33 lr 0.000021	time 0.6493 (0.6062)	loss 4.1766 (3.5914)	grad_norm 7.3263 (9.5450)	mem 5325MB
[2022-04-21 18:20:30 tiny] (main.py 226): INFO Train: [279/300][900/1251]	eta 0:03:32 lr 0.000021	time 0.4444 (0.6041)	loss 4.0301 (3.5940)	grad_norm 13.6569 (9.5091)	mem 5325MB
[2022-04-21 18:21:29 tiny] (main.py 226): INFO Train: [279/300][1000/1251]	eta 0:02:31 lr 0.000021	time 0.7099 (0.6028)	loss 3.5306 (3.5951)	grad_norm 13.8823 (9.5387)	mem 5325MB
[2022-04-21 18:22:28 tiny] (main.py 226): INFO Train: [279/300][1100/1251]	eta 0:01:30 lr 0.000021	time 0.8044 (0.6019)	loss 3.6610 (3.5988)	grad_norm 6.1879 (9.5092)	mem 5325MB
[2022-04-21 18:23:27 tiny] (main.py 226): INFO Train: [279/300][1200/1251]	eta 0:00:30 lr 0.000021	time 0.7657 (0.6007)	loss 2.8973 (3.5942)	grad_norm 8.7712 (9.6088)	mem 5325MB
[2022-04-21 18:23:49 tiny] (main.py 233): INFO EPOCH 279 training takes 0:12:23
[2022-04-21 18:24:01 tiny] (main.py 273): INFO Test: [0/49]	Time 12.102 (12.102)	Loss 1.5044 (1.5044)	Acc@1 69.336 (69.336)	Acc@5 88.184 (88.184)	Mem 5325MB
[2022-04-21 18:24:20 tiny] (main.py 279): INFO  * Acc@1 72.674 Acc@5 90.998
[2022-04-21 18:24:20 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.7%
[2022-04-21 18:24:20 tiny] (main.py 148): INFO Max accuracy: 72.68%
[2022-04-21 18:24:30 tiny] (main.py 226): INFO Train: [280/300][0/1251]	eta 3:27:07 lr 0.000021	time 9.9343 (9.9343)	loss 4.0214 (4.0214)	grad_norm 12.3557 (12.3557)	mem 5325MB
[2022-04-21 18:25:34 tiny] (main.py 226): INFO Train: [280/300][100/1251]	eta 0:14:01 lr 0.000021	time 0.5445 (0.7314)	loss 3.8849 (3.5931)	grad_norm 4.9185 (9.6512)	mem 5325MB
[2022-04-21 18:26:33 tiny] (main.py 226): INFO Train: [280/300][200/1251]	eta 0:11:34 lr 0.000021	time 0.5488 (0.6607)	loss 3.8778 (3.6341)	grad_norm 8.8998 (9.7446)	mem 5325MB
[2022-04-21 18:27:32 tiny] (main.py 226): INFO Train: [280/300][300/1251]	eta 0:10:04 lr 0.000021	time 0.5481 (0.6354)	loss 3.7094 (3.6376)	grad_norm 8.0191 (9.5352)	mem 5325MB
[2022-04-21 18:28:30 tiny] (main.py 226): INFO Train: [280/300][400/1251]	eta 0:08:50 lr 0.000020	time 0.5059 (0.6233)	loss 4.1656 (3.6335)	grad_norm 8.3561 (9.6902)	mem 5325MB
[2022-04-21 18:29:29 tiny] (main.py 226): INFO Train: [280/300][500/1251]	eta 0:07:42 lr 0.000020	time 0.7524 (0.6158)	loss 3.5424 (3.6294)	grad_norm 13.8225 (9.5280)	mem 5325MB
[2022-04-21 18:30:28 tiny] (main.py 226): INFO Train: [280/300][600/1251]	eta 0:06:38 lr 0.000020	time 0.4565 (0.6115)	loss 3.2292 (3.6404)	grad_norm 11.8233 (9.4590)	mem 5325MB
[2022-04-21 18:31:27 tiny] (main.py 226): INFO Train: [280/300][700/1251]	eta 0:05:35 lr 0.000020	time 0.5943 (0.6081)	loss 3.6122 (3.6475)	grad_norm 9.2321 (9.5360)	mem 5325MB
[2022-04-21 18:32:26 tiny] (main.py 226): INFO Train: [280/300][800/1251]	eta 0:04:33 lr 0.000020	time 0.6522 (0.6062)	loss 3.0132 (3.6414)	grad_norm 11.5872 (9.5356)	mem 5325MB
[2022-04-21 18:33:25 tiny] (main.py 226): INFO Train: [280/300][900/1251]	eta 0:03:32 lr 0.000020	time 0.5481 (0.6043)	loss 3.8396 (3.6383)	grad_norm 7.5319 (9.6872)	mem 5325MB
[2022-04-21 18:34:24 tiny] (main.py 226): INFO Train: [280/300][1000/1251]	eta 0:02:31 lr 0.000020	time 0.7316 (0.6034)	loss 4.4248 (3.6395)	grad_norm 11.2464 (9.6187)	mem 5325MB
[2022-04-21 18:35:23 tiny] (main.py 226): INFO Train: [280/300][1100/1251]	eta 0:01:30 lr 0.000020	time 0.7224 (0.6019)	loss 3.6843 (3.6402)	grad_norm 7.9368 (9.6720)	mem 5325MB
[2022-04-21 18:36:22 tiny] (main.py 226): INFO Train: [280/300][1200/1251]	eta 0:00:30 lr 0.000020	time 0.5675 (0.6010)	loss 4.1188 (3.6338)	grad_norm 5.9488 (9.6763)	mem 5325MB
[2022-04-21 18:36:45 tiny] (main.py 233): INFO EPOCH 280 training takes 0:12:25
[2022-04-21 18:36:57 tiny] (main.py 273): INFO Test: [0/49]	Time 11.749 (11.749)	Loss 1.3107 (1.3107)	Acc@1 74.219 (74.219)	Acc@5 91.602 (91.602)	Mem 5325MB
[2022-04-21 18:37:16 tiny] (main.py 279): INFO  * Acc@1 72.638 Acc@5 90.946
[2022-04-21 18:37:16 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.6%
[2022-04-21 18:37:16 tiny] (main.py 148): INFO Max accuracy: 72.68%
[2022-04-21 18:37:27 tiny] (main.py 226): INFO Train: [281/300][0/1251]	eta 3:54:33 lr 0.000020	time 11.2501 (11.2501)	loss 3.8164 (3.8164)	grad_norm 5.8502 (5.8502)	mem 5325MB
[2022-04-21 18:38:30 tiny] (main.py 226): INFO Train: [281/300][100/1251]	eta 0:14:03 lr 0.000020	time 0.5412 (0.7326)	loss 3.7806 (3.6566)	grad_norm 6.3419 (9.0934)	mem 5325MB
[2022-04-21 18:39:28 tiny] (main.py 226): INFO Train: [281/300][200/1251]	eta 0:11:31 lr 0.000020	time 0.6027 (0.6581)	loss 2.4101 (3.6455)	grad_norm 8.2317 (9.1979)	mem 5325MB
[2022-04-21 18:40:27 tiny] (main.py 226): INFO Train: [281/300][300/1251]	eta 0:10:02 lr 0.000020	time 0.5007 (0.6339)	loss 3.0071 (3.6023)	grad_norm 13.3575 (8.9611)	mem 5325MB
[2022-04-21 18:41:26 tiny] (main.py 226): INFO Train: [281/300][400/1251]	eta 0:08:49 lr 0.000019	time 0.7265 (0.6221)	loss 2.9436 (3.5881)	grad_norm 10.4686 (9.2509)	mem 5325MB
[2022-04-21 18:42:24 tiny] (main.py 226): INFO Train: [281/300][500/1251]	eta 0:07:41 lr 0.000019	time 0.7059 (0.6144)	loss 3.0187 (3.5937)	grad_norm 11.1311 (9.4270)	mem 5325MB
[2022-04-21 18:43:23 tiny] (main.py 226): INFO Train: [281/300][600/1251]	eta 0:06:37 lr 0.000019	time 0.6288 (0.6110)	loss 4.0664 (3.5954)	grad_norm 11.5280 (9.5163)	mem 5325MB
[2022-04-21 18:44:23 tiny] (main.py 226): INFO Train: [281/300][700/1251]	eta 0:05:35 lr 0.000019	time 0.7274 (0.6082)	loss 4.4502 (3.6060)	grad_norm 12.7826 (9.7383)	mem 5325MB
[2022-04-21 18:45:21 tiny] (main.py 226): INFO Train: [281/300][800/1251]	eta 0:04:32 lr 0.000019	time 0.5445 (0.6053)	loss 3.8087 (3.6082)	grad_norm 6.1922 (nan)	mem 5325MB
[2022-04-21 18:46:20 tiny] (main.py 226): INFO Train: [281/300][900/1251]	eta 0:03:32 lr 0.000019	time 0.8329 (0.6041)	loss 4.1364 (3.6087)	grad_norm 8.5543 (nan)	mem 5325MB
[2022-04-21 18:47:19 tiny] (main.py 226): INFO Train: [281/300][1000/1251]	eta 0:02:31 lr 0.000019	time 0.7671 (0.6027)	loss 3.8050 (3.5983)	grad_norm 12.4513 (nan)	mem 5325MB
[2022-04-21 18:48:19 tiny] (main.py 226): INFO Train: [281/300][1100/1251]	eta 0:01:30 lr 0.000019	time 0.7040 (0.6018)	loss 3.4816 (3.6018)	grad_norm 14.2082 (nan)	mem 5325MB
[2022-04-21 18:49:17 tiny] (main.py 226): INFO Train: [281/300][1200/1251]	eta 0:00:30 lr 0.000019	time 0.7450 (0.6005)	loss 4.2675 (3.5916)	grad_norm 11.3733 (nan)	mem 5325MB
[2022-04-21 18:49:40 tiny] (main.py 233): INFO EPOCH 281 training takes 0:12:23
[2022-04-21 18:49:51 tiny] (main.py 273): INFO Test: [0/49]	Time 11.143 (11.143)	Loss 1.3740 (1.3740)	Acc@1 72.266 (72.266)	Acc@5 91.113 (91.113)	Mem 5325MB
[2022-04-21 18:50:10 tiny] (main.py 279): INFO  * Acc@1 72.724 Acc@5 91.072
[2022-04-21 18:50:10 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.7%
[2022-04-21 18:50:10 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_281.pth saving......
[2022-04-21 18:50:10 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_281.pth saved !!!
[2022-04-21 18:50:10 tiny] (main.py 148): INFO Max accuracy: 72.72%
[2022-04-21 18:50:22 tiny] (main.py 226): INFO Train: [282/300][0/1251]	eta 4:04:07 lr 0.000019	time 11.7089 (11.7089)	loss 2.5845 (2.5845)	grad_norm 8.0160 (8.0160)	mem 5325MB
[2022-04-21 18:51:24 tiny] (main.py 226): INFO Train: [282/300][100/1251]	eta 0:13:57 lr 0.000019	time 0.6452 (0.7272)	loss 3.4949 (3.6760)	grad_norm 13.1545 (9.5419)	mem 5325MB
[2022-04-21 18:52:23 tiny] (main.py 226): INFO Train: [282/300][200/1251]	eta 0:11:32 lr 0.000019	time 0.6205 (0.6587)	loss 2.4542 (3.6575)	grad_norm 13.8757 (9.9053)	mem 5325MB
[2022-04-21 18:53:22 tiny] (main.py 226): INFO Train: [282/300][300/1251]	eta 0:10:03 lr 0.000019	time 0.8027 (0.6349)	loss 3.8051 (3.6619)	grad_norm 9.6601 (9.7928)	mem 5325MB
[2022-04-21 18:54:20 tiny] (main.py 226): INFO Train: [282/300][400/1251]	eta 0:08:49 lr 0.000018	time 0.6852 (0.6224)	loss 3.3739 (3.6602)	grad_norm 8.2727 (9.6844)	mem 5325MB
[2022-04-21 18:55:18 tiny] (main.py 226): INFO Train: [282/300][500/1251]	eta 0:07:41 lr 0.000018	time 0.5382 (0.6144)	loss 2.3875 (3.6657)	grad_norm 5.0557 (9.7506)	mem 5325MB
[2022-04-21 18:56:17 tiny] (main.py 226): INFO Train: [282/300][600/1251]	eta 0:06:37 lr 0.000018	time 0.6684 (0.6107)	loss 3.7980 (3.6529)	grad_norm 8.1890 (9.5913)	mem 5325MB
[2022-04-21 18:57:17 tiny] (main.py 226): INFO Train: [282/300][700/1251]	eta 0:05:35 lr 0.000018	time 0.5983 (0.6081)	loss 3.8755 (3.6460)	grad_norm 7.9420 (9.5319)	mem 5325MB
[2022-04-21 18:58:16 tiny] (main.py 226): INFO Train: [282/300][800/1251]	eta 0:04:33 lr 0.000018	time 0.5313 (0.6059)	loss 2.4890 (3.6384)	grad_norm 9.7876 (9.4699)	mem 5325MB
[2022-04-21 18:59:15 tiny] (main.py 226): INFO Train: [282/300][900/1251]	eta 0:03:31 lr 0.000018	time 0.4111 (0.6038)	loss 2.4303 (3.6332)	grad_norm 6.3708 (9.4029)	mem 5325MB
[2022-04-21 19:00:14 tiny] (main.py 226): INFO Train: [282/300][1000/1251]	eta 0:02:31 lr 0.000018	time 0.6352 (0.6026)	loss 2.8214 (3.6314)	grad_norm 6.3861 (9.4159)	mem 5325MB
[2022-04-21 19:01:12 tiny] (main.py 226): INFO Train: [282/300][1100/1251]	eta 0:01:30 lr 0.000018	time 0.6069 (0.6011)	loss 4.6017 (3.6337)	grad_norm 21.8701 (9.5058)	mem 5325MB
[2022-04-21 19:02:11 tiny] (main.py 226): INFO Train: [282/300][1200/1251]	eta 0:00:30 lr 0.000018	time 0.4521 (0.6002)	loss 3.5405 (3.6190)	grad_norm 10.6874 (9.4615)	mem 5325MB
[2022-04-21 19:02:34 tiny] (main.py 233): INFO EPOCH 282 training takes 0:12:23
[2022-04-21 19:02:45 tiny] (main.py 273): INFO Test: [0/49]	Time 11.095 (11.095)	Loss 1.4166 (1.4166)	Acc@1 71.973 (71.973)	Acc@5 91.504 (91.504)	Mem 5325MB
[2022-04-21 19:03:05 tiny] (main.py 279): INFO  * Acc@1 72.650 Acc@5 91.090
[2022-04-21 19:03:05 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.7%
[2022-04-21 19:03:05 tiny] (main.py 148): INFO Max accuracy: 72.72%
[2022-04-21 19:03:17 tiny] (main.py 226): INFO Train: [283/300][0/1251]	eta 4:05:53 lr 0.000018	time 11.7936 (11.7936)	loss 3.8193 (3.8193)	grad_norm 7.0941 (7.0941)	mem 5325MB
[2022-04-21 19:04:19 tiny] (main.py 226): INFO Train: [283/300][100/1251]	eta 0:14:02 lr 0.000018	time 0.5552 (0.7316)	loss 3.8332 (3.6382)	grad_norm 11.7221 (9.8884)	mem 5325MB
[2022-04-21 19:05:17 tiny] (main.py 226): INFO Train: [283/300][200/1251]	eta 0:11:31 lr 0.000018	time 0.6080 (0.6577)	loss 4.1033 (3.5791)	grad_norm 12.2921 (10.1357)	mem 5325MB
[2022-04-21 19:06:15 tiny] (main.py 226): INFO Train: [283/300][300/1251]	eta 0:10:01 lr 0.000018	time 0.5216 (0.6322)	loss 2.2664 (3.5737)	grad_norm 7.4065 (9.6625)	mem 5325MB
[2022-04-21 19:07:14 tiny] (main.py 226): INFO Train: [283/300][400/1251]	eta 0:08:49 lr 0.000018	time 0.6561 (0.6218)	loss 4.2874 (3.5717)	grad_norm 9.8193 (9.4767)	mem 5325MB
[2022-04-21 19:08:13 tiny] (main.py 226): INFO Train: [283/300][500/1251]	eta 0:07:41 lr 0.000017	time 0.5043 (0.6147)	loss 4.4530 (3.5815)	grad_norm 10.7709 (9.4896)	mem 5325MB
[2022-04-21 19:09:11 tiny] (main.py 226): INFO Train: [283/300][600/1251]	eta 0:06:37 lr 0.000017	time 0.5187 (0.6100)	loss 2.5679 (3.5671)	grad_norm 8.4924 (9.5738)	mem 5325MB
[2022-04-21 19:10:10 tiny] (main.py 226): INFO Train: [283/300][700/1251]	eta 0:05:34 lr 0.000017	time 0.5337 (0.6070)	loss 4.0250 (3.5721)	grad_norm 10.0720 (9.4720)	mem 5325MB
[2022-04-21 19:11:09 tiny] (main.py 226): INFO Train: [283/300][800/1251]	eta 0:04:32 lr 0.000017	time 0.5956 (0.6050)	loss 2.8921 (3.5888)	grad_norm 13.1601 (9.5300)	mem 5325MB
[2022-04-21 19:12:08 tiny] (main.py 226): INFO Train: [283/300][900/1251]	eta 0:03:31 lr 0.000017	time 0.5918 (0.6034)	loss 3.5646 (3.5940)	grad_norm 13.0180 (9.4694)	mem 5325MB
[2022-04-21 19:13:07 tiny] (main.py 226): INFO Train: [283/300][1000/1251]	eta 0:02:31 lr 0.000017	time 0.5388 (0.6017)	loss 2.4492 (3.5993)	grad_norm 9.5323 (9.4386)	mem 5325MB
[2022-04-21 19:14:06 tiny] (main.py 226): INFO Train: [283/300][1100/1251]	eta 0:01:30 lr 0.000017	time 0.5005 (0.6005)	loss 2.5994 (3.6029)	grad_norm 8.9705 (9.5022)	mem 5325MB
[2022-04-21 19:15:05 tiny] (main.py 226): INFO Train: [283/300][1200/1251]	eta 0:00:30 lr 0.000017	time 0.4500 (0.5999)	loss 4.3730 (3.6044)	grad_norm 8.0644 (9.4597)	mem 5325MB
[2022-04-21 19:15:28 tiny] (main.py 233): INFO EPOCH 283 training takes 0:12:23
[2022-04-21 19:15:39 tiny] (main.py 273): INFO Test: [0/49]	Time 10.938 (10.938)	Loss 1.3812 (1.3812)	Acc@1 72.363 (72.363)	Acc@5 91.309 (91.309)	Mem 5325MB
[2022-04-21 19:15:59 tiny] (main.py 279): INFO  * Acc@1 72.652 Acc@5 91.068
[2022-04-21 19:15:59 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.7%
[2022-04-21 19:15:59 tiny] (main.py 148): INFO Max accuracy: 72.72%
[2022-04-21 19:16:11 tiny] (main.py 226): INFO Train: [284/300][0/1251]	eta 4:06:09 lr 0.000017	time 11.8060 (11.8060)	loss 3.0724 (3.0724)	grad_norm 9.4121 (9.4121)	mem 5325MB
[2022-04-21 19:17:12 tiny] (main.py 226): INFO Train: [284/300][100/1251]	eta 0:13:57 lr 0.000017	time 0.5848 (0.7278)	loss 3.3951 (3.5138)	grad_norm 7.1593 (9.5812)	mem 5325MB
[2022-04-21 19:18:11 tiny] (main.py 226): INFO Train: [284/300][200/1251]	eta 0:11:30 lr 0.000017	time 0.6502 (0.6565)	loss 3.3393 (3.5870)	grad_norm 7.4769 (9.3901)	mem 5325MB
[2022-04-21 19:19:09 tiny] (main.py 226): INFO Train: [284/300][300/1251]	eta 0:10:02 lr 0.000017	time 0.5453 (0.6330)	loss 3.5127 (3.5767)	grad_norm 8.2204 (9.6127)	mem 5325MB
[2022-04-21 19:20:08 tiny] (main.py 226): INFO Train: [284/300][400/1251]	eta 0:08:49 lr 0.000017	time 0.6714 (0.6221)	loss 2.7700 (3.5748)	grad_norm 24.8037 (9.7360)	mem 5325MB
[2022-04-21 19:21:07 tiny] (main.py 226): INFO Train: [284/300][500/1251]	eta 0:07:42 lr 0.000017	time 0.5498 (0.6154)	loss 3.5078 (3.5987)	grad_norm 8.7553 (9.6479)	mem 5325MB
[2022-04-21 19:22:06 tiny] (main.py 226): INFO Train: [284/300][600/1251]	eta 0:06:37 lr 0.000017	time 0.5296 (0.6107)	loss 3.3258 (3.6139)	grad_norm 7.6830 (9.6816)	mem 5325MB
[2022-04-21 19:23:05 tiny] (main.py 226): INFO Train: [284/300][700/1251]	eta 0:05:34 lr 0.000016	time 0.5464 (0.6075)	loss 3.9027 (3.6238)	grad_norm 8.8697 (9.6052)	mem 5325MB
[2022-04-21 19:24:04 tiny] (main.py 226): INFO Train: [284/300][800/1251]	eta 0:04:32 lr 0.000016	time 0.5085 (0.6050)	loss 3.4565 (3.6152)	grad_norm 9.9093 (9.5837)	mem 5325MB
[2022-04-21 19:25:02 tiny] (main.py 226): INFO Train: [284/300][900/1251]	eta 0:03:31 lr 0.000016	time 0.7679 (0.6033)	loss 3.2503 (3.6081)	grad_norm 5.9875 (nan)	mem 5325MB
[2022-04-21 19:26:02 tiny] (main.py 226): INFO Train: [284/300][1000/1251]	eta 0:02:31 lr 0.000016	time 0.6654 (0.6020)	loss 3.3883 (3.6066)	grad_norm 20.4713 (nan)	mem 5325MB
[2022-04-21 19:27:00 tiny] (main.py 226): INFO Train: [284/300][1100/1251]	eta 0:01:30 lr 0.000016	time 0.5161 (0.6007)	loss 4.3608 (3.6087)	grad_norm 14.3345 (nan)	mem 5325MB
[2022-04-21 19:28:00 tiny] (main.py 226): INFO Train: [284/300][1200/1251]	eta 0:00:30 lr 0.000016	time 0.6649 (0.6001)	loss 3.1959 (3.6087)	grad_norm 6.5634 (nan)	mem 5325MB
[2022-04-21 19:28:22 tiny] (main.py 233): INFO EPOCH 284 training takes 0:12:22
[2022-04-21 19:28:32 tiny] (main.py 273): INFO Test: [0/49]	Time 10.479 (10.479)	Loss 1.5306 (1.5306)	Acc@1 72.656 (72.656)	Acc@5 90.430 (90.430)	Mem 5325MB
[2022-04-21 19:28:53 tiny] (main.py 279): INFO  * Acc@1 72.664 Acc@5 91.046
[2022-04-21 19:28:53 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.7%
[2022-04-21 19:28:53 tiny] (main.py 148): INFO Max accuracy: 72.72%
[2022-04-21 19:29:04 tiny] (main.py 226): INFO Train: [285/300][0/1251]	eta 4:00:45 lr 0.000016	time 11.5469 (11.5469)	loss 2.8627 (2.8627)	grad_norm 6.3401 (6.3401)	mem 5325MB
[2022-04-21 19:30:07 tiny] (main.py 226): INFO Train: [285/300][100/1251]	eta 0:14:00 lr 0.000016	time 0.5772 (0.7304)	loss 3.9551 (3.5987)	grad_norm 8.3992 (9.2964)	mem 5325MB
[2022-04-21 19:31:05 tiny] (main.py 226): INFO Train: [285/300][200/1251]	eta 0:11:31 lr 0.000016	time 0.6594 (0.6577)	loss 3.8875 (3.6264)	grad_norm 7.0125 (9.4503)	mem 5325MB
[2022-04-21 19:32:03 tiny] (main.py 226): INFO Train: [285/300][300/1251]	eta 0:10:01 lr 0.000016	time 0.5055 (0.6328)	loss 3.0132 (3.6197)	grad_norm 17.1538 (9.3794)	mem 5325MB
[2022-04-21 19:33:02 tiny] (main.py 226): INFO Train: [285/300][400/1251]	eta 0:08:49 lr 0.000016	time 0.5522 (0.6223)	loss 3.4761 (3.5943)	grad_norm 10.9781 (9.5067)	mem 5325MB
[2022-04-21 19:34:01 tiny] (main.py 226): INFO Train: [285/300][500/1251]	eta 0:07:41 lr 0.000016	time 0.4655 (0.6141)	loss 3.8663 (3.5851)	grad_norm 13.4905 (9.5441)	mem 5325MB
[2022-04-21 19:35:00 tiny] (main.py 226): INFO Train: [285/300][600/1251]	eta 0:06:37 lr 0.000016	time 0.6235 (0.6102)	loss 2.9350 (3.5813)	grad_norm 14.1545 (9.5129)	mem 5325MB
[2022-04-21 19:35:59 tiny] (main.py 226): INFO Train: [285/300][700/1251]	eta 0:05:34 lr 0.000016	time 0.6791 (0.6077)	loss 2.6011 (3.5831)	grad_norm 6.8605 (9.5442)	mem 5325MB
[2022-04-21 19:36:57 tiny] (main.py 226): INFO Train: [285/300][800/1251]	eta 0:04:32 lr 0.000016	time 0.5162 (0.6049)	loss 3.9247 (3.5900)	grad_norm 7.1109 (9.5694)	mem 5325MB
[2022-04-21 19:37:57 tiny] (main.py 226): INFO Train: [285/300][900/1251]	eta 0:03:31 lr 0.000016	time 0.6560 (0.6035)	loss 3.7163 (3.5779)	grad_norm 14.0213 (9.5701)	mem 5325MB
[2022-04-21 19:38:55 tiny] (main.py 226): INFO Train: [285/300][1000/1251]	eta 0:02:31 lr 0.000015	time 0.4064 (0.6017)	loss 2.6552 (3.5807)	grad_norm 13.1054 (9.5251)	mem 5325MB
[2022-04-21 19:39:54 tiny] (main.py 226): INFO Train: [285/300][1100/1251]	eta 0:01:30 lr 0.000015	time 0.6054 (0.6008)	loss 2.5212 (3.5835)	grad_norm 8.1231 (9.5161)	mem 5325MB
[2022-04-21 19:40:53 tiny] (main.py 226): INFO Train: [285/300][1200/1251]	eta 0:00:30 lr 0.000015	time 0.5976 (0.5999)	loss 4.2780 (3.5814)	grad_norm 7.7622 (9.5058)	mem 5325MB
[2022-04-21 19:41:15 tiny] (main.py 233): INFO EPOCH 285 training takes 0:12:22
[2022-04-21 19:41:28 tiny] (main.py 273): INFO Test: [0/49]	Time 12.448 (12.448)	Loss 1.4584 (1.4584)	Acc@1 72.266 (72.266)	Acc@5 90.625 (90.625)	Mem 5325MB
[2022-04-21 19:41:46 tiny] (main.py 279): INFO  * Acc@1 72.716 Acc@5 91.052
[2022-04-21 19:41:46 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.7%
[2022-04-21 19:41:46 tiny] (main.py 148): INFO Max accuracy: 72.72%
[2022-04-21 19:41:57 tiny] (main.py 226): INFO Train: [286/300][0/1251]	eta 3:37:16 lr 0.000015	time 10.4213 (10.4213)	loss 3.0375 (3.0375)	grad_norm 10.9169 (10.9169)	mem 5325MB
[2022-04-21 19:43:00 tiny] (main.py 226): INFO Train: [286/300][100/1251]	eta 0:14:02 lr 0.000015	time 0.4909 (0.7319)	loss 4.0277 (3.5752)	grad_norm 9.2817 (10.2272)	mem 5325MB
[2022-04-21 19:43:58 tiny] (main.py 226): INFO Train: [286/300][200/1251]	eta 0:11:27 lr 0.000015	time 0.5964 (0.6543)	loss 3.1603 (3.5818)	grad_norm 11.2384 (10.1647)	mem 5325MB
[2022-04-21 19:44:57 tiny] (main.py 226): INFO Train: [286/300][300/1251]	eta 0:10:02 lr 0.000015	time 0.7216 (0.6334)	loss 3.6545 (3.5843)	grad_norm 12.0564 (10.1032)	mem 5325MB
[2022-04-21 19:45:55 tiny] (main.py 226): INFO Train: [286/300][400/1251]	eta 0:08:48 lr 0.000015	time 0.5162 (0.6215)	loss 4.4679 (3.5929)	grad_norm 9.6660 (9.9068)	mem 5325MB
[2022-04-21 19:46:55 tiny] (main.py 226): INFO Train: [286/300][500/1251]	eta 0:07:42 lr 0.000015	time 0.5087 (0.6156)	loss 3.9389 (3.6014)	grad_norm 7.4606 (9.8650)	mem 5325MB
[2022-04-21 19:47:53 tiny] (main.py 226): INFO Train: [286/300][600/1251]	eta 0:06:37 lr 0.000015	time 0.7654 (0.6107)	loss 3.7955 (3.5988)	grad_norm 6.8850 (9.8113)	mem 5325MB
[2022-04-21 19:48:52 tiny] (main.py 226): INFO Train: [286/300][700/1251]	eta 0:05:34 lr 0.000015	time 0.4363 (0.6076)	loss 4.0925 (3.6104)	grad_norm 9.0423 (9.8079)	mem 5325MB
[2022-04-21 19:49:52 tiny] (main.py 226): INFO Train: [286/300][800/1251]	eta 0:04:33 lr 0.000015	time 0.5947 (0.6061)	loss 4.3800 (3.5991)	grad_norm 11.1996 (9.8405)	mem 5325MB
[2022-04-21 19:50:51 tiny] (main.py 226): INFO Train: [286/300][900/1251]	eta 0:03:32 lr 0.000015	time 0.5158 (0.6043)	loss 3.8780 (3.6069)	grad_norm 6.4044 (9.8113)	mem 5325MB
[2022-04-21 19:51:50 tiny] (main.py 226): INFO Train: [286/300][1000/1251]	eta 0:02:31 lr 0.000015	time 0.7020 (0.6028)	loss 3.8283 (3.6037)	grad_norm 6.4206 (9.7532)	mem 5325MB
[2022-04-21 19:52:48 tiny] (main.py 226): INFO Train: [286/300][1100/1251]	eta 0:01:30 lr 0.000015	time 0.7255 (0.6015)	loss 3.3765 (3.5983)	grad_norm 6.6672 (9.7143)	mem 5325MB
[2022-04-21 19:53:48 tiny] (main.py 226): INFO Train: [286/300][1200/1251]	eta 0:00:30 lr 0.000015	time 0.6232 (0.6006)	loss 3.1555 (3.5969)	grad_norm 7.0453 (nan)	mem 5325MB
[2022-04-21 19:54:10 tiny] (main.py 233): INFO EPOCH 286 training takes 0:12:23
[2022-04-21 19:54:20 tiny] (main.py 273): INFO Test: [0/49]	Time 10.618 (10.618)	Loss 1.3919 (1.3919)	Acc@1 73.145 (73.145)	Acc@5 91.309 (91.309)	Mem 5325MB
[2022-04-21 19:54:41 tiny] (main.py 279): INFO  * Acc@1 72.794 Acc@5 91.072
[2022-04-21 19:54:41 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.8%
[2022-04-21 19:54:41 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_286.pth saving......
[2022-04-21 19:54:41 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_286.pth saved !!!
[2022-04-21 19:54:41 tiny] (main.py 148): INFO Max accuracy: 72.79%
[2022-04-21 19:54:52 tiny] (main.py 226): INFO Train: [287/300][0/1251]	eta 3:40:44 lr 0.000015	time 10.5868 (10.5868)	loss 2.2876 (2.2876)	grad_norm 14.1151 (14.1151)	mem 5325MB
[2022-04-21 19:55:55 tiny] (main.py 226): INFO Train: [287/300][100/1251]	eta 0:14:01 lr 0.000015	time 0.5303 (0.7312)	loss 3.9032 (3.5936)	grad_norm 8.5652 (10.1867)	mem 5325MB
[2022-04-21 19:56:54 tiny] (main.py 226): INFO Train: [287/300][200/1251]	eta 0:11:31 lr 0.000014	time 0.6871 (0.6582)	loss 2.5773 (3.6327)	grad_norm 9.4521 (9.5878)	mem 5325MB
[2022-04-21 19:57:52 tiny] (main.py 226): INFO Train: [287/300][300/1251]	eta 0:10:02 lr 0.000014	time 0.6080 (0.6337)	loss 3.7691 (3.6263)	grad_norm 15.8986 (9.5903)	mem 5325MB
[2022-04-21 19:58:51 tiny] (main.py 226): INFO Train: [287/300][400/1251]	eta 0:08:49 lr 0.000014	time 0.6519 (0.6225)	loss 2.5110 (3.6211)	grad_norm 18.3340 (9.6262)	mem 5325MB
[2022-04-21 19:59:50 tiny] (main.py 226): INFO Train: [287/300][500/1251]	eta 0:07:42 lr 0.000014	time 0.7555 (0.6154)	loss 3.9167 (3.6047)	grad_norm 7.6627 (9.6208)	mem 5325MB
[2022-04-21 20:00:49 tiny] (main.py 226): INFO Train: [287/300][600/1251]	eta 0:06:37 lr 0.000014	time 0.7103 (0.6110)	loss 4.4572 (3.5991)	grad_norm 12.5410 (9.5695)	mem 5325MB
[2022-04-21 20:01:47 tiny] (main.py 226): INFO Train: [287/300][700/1251]	eta 0:05:34 lr 0.000014	time 0.4428 (0.6072)	loss 4.4064 (3.6107)	grad_norm 8.4503 (9.5309)	mem 5325MB
[2022-04-21 20:02:47 tiny] (main.py 226): INFO Train: [287/300][800/1251]	eta 0:04:33 lr 0.000014	time 0.5300 (0.6057)	loss 2.8961 (3.6067)	grad_norm 10.1010 (9.5498)	mem 5325MB
[2022-04-21 20:03:46 tiny] (main.py 226): INFO Train: [287/300][900/1251]	eta 0:03:31 lr 0.000014	time 0.6648 (0.6040)	loss 3.9599 (3.6113)	grad_norm 7.6185 (9.5154)	mem 5325MB
[2022-04-21 20:04:44 tiny] (main.py 226): INFO Train: [287/300][1000/1251]	eta 0:02:31 lr 0.000014	time 0.4182 (0.6023)	loss 2.8952 (3.6128)	grad_norm 13.1079 (9.4880)	mem 5325MB
[2022-04-21 20:05:43 tiny] (main.py 226): INFO Train: [287/300][1100/1251]	eta 0:01:30 lr 0.000014	time 0.4628 (0.6012)	loss 3.8654 (3.6066)	grad_norm 6.7772 (9.4916)	mem 5325MB
[2022-04-21 20:06:42 tiny] (main.py 226): INFO Train: [287/300][1200/1251]	eta 0:00:30 lr 0.000014	time 0.5654 (0.6004)	loss 4.2083 (3.5958)	grad_norm 8.9712 (9.5567)	mem 5325MB
[2022-04-21 20:07:05 tiny] (main.py 233): INFO EPOCH 287 training takes 0:12:23
[2022-04-21 20:07:17 tiny] (main.py 273): INFO Test: [0/49]	Time 12.227 (12.227)	Loss 1.3942 (1.3942)	Acc@1 72.754 (72.754)	Acc@5 89.844 (89.844)	Mem 5325MB
[2022-04-21 20:07:36 tiny] (main.py 279): INFO  * Acc@1 72.898 Acc@5 91.106
[2022-04-21 20:07:36 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.9%
[2022-04-21 20:07:36 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_287.pth saving......
[2022-04-21 20:07:36 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_287.pth saved !!!
[2022-04-21 20:07:36 tiny] (main.py 148): INFO Max accuracy: 72.90%
[2022-04-21 20:07:47 tiny] (main.py 226): INFO Train: [288/300][0/1251]	eta 3:47:05 lr 0.000014	time 10.8914 (10.8914)	loss 3.3679 (3.3679)	grad_norm 7.9220 (7.9220)	mem 5325MB
[2022-04-21 20:08:50 tiny] (main.py 226): INFO Train: [288/300][100/1251]	eta 0:14:01 lr 0.000014	time 0.7772 (0.7311)	loss 3.4186 (3.6754)	grad_norm 21.3591 (9.2224)	mem 5325MB
[2022-04-21 20:09:49 tiny] (main.py 226): INFO Train: [288/300][200/1251]	eta 0:11:31 lr 0.000014	time 0.6049 (0.6582)	loss 3.1127 (3.6381)	grad_norm 5.8908 (9.3747)	mem 5325MB
[2022-04-21 20:10:47 tiny] (main.py 226): INFO Train: [288/300][300/1251]	eta 0:10:03 lr 0.000014	time 0.7837 (0.6350)	loss 4.2996 (3.6259)	grad_norm 9.7593 (9.4483)	mem 5325MB
[2022-04-21 20:11:46 tiny] (main.py 226): INFO Train: [288/300][400/1251]	eta 0:08:51 lr 0.000014	time 0.6233 (0.6240)	loss 3.3669 (3.5934)	grad_norm 9.3758 (9.3936)	mem 5325MB
[2022-04-21 20:12:45 tiny] (main.py 226): INFO Train: [288/300][500/1251]	eta 0:07:42 lr 0.000014	time 0.5341 (0.6161)	loss 3.1181 (3.5839)	grad_norm 5.0039 (9.3681)	mem 5325MB
[2022-04-21 20:13:44 tiny] (main.py 226): INFO Train: [288/300][600/1251]	eta 0:06:38 lr 0.000014	time 0.6029 (0.6120)	loss 2.7391 (3.5826)	grad_norm 5.2900 (9.3463)	mem 5325MB
[2022-04-21 20:14:43 tiny] (main.py 226): INFO Train: [288/300][700/1251]	eta 0:05:35 lr 0.000014	time 0.5663 (0.6083)	loss 2.7109 (3.5880)	grad_norm 13.7066 (9.3895)	mem 5325MB
[2022-04-21 20:15:42 tiny] (main.py 226): INFO Train: [288/300][800/1251]	eta 0:04:33 lr 0.000013	time 0.5153 (0.6062)	loss 3.4568 (3.5829)	grad_norm 8.7280 (9.4622)	mem 5325MB
[2022-04-21 20:16:41 tiny] (main.py 226): INFO Train: [288/300][900/1251]	eta 0:03:32 lr 0.000013	time 0.6853 (0.6042)	loss 2.9774 (3.5820)	grad_norm 15.0704 (9.5082)	mem 5325MB
[2022-04-21 20:17:40 tiny] (main.py 226): INFO Train: [288/300][1000/1251]	eta 0:02:31 lr 0.000013	time 0.5347 (0.6032)	loss 4.0511 (3.5851)	grad_norm 14.4079 (9.5039)	mem 5325MB
[2022-04-21 20:18:39 tiny] (main.py 226): INFO Train: [288/300][1100/1251]	eta 0:01:30 lr 0.000013	time 0.5978 (0.6018)	loss 3.3303 (3.5788)	grad_norm 5.4620 (9.4599)	mem 5325MB
[2022-04-21 20:19:38 tiny] (main.py 226): INFO Train: [288/300][1200/1251]	eta 0:00:30 lr 0.000013	time 0.4695 (0.6009)	loss 3.2009 (3.5823)	grad_norm 9.9673 (9.4646)	mem 5325MB
[2022-04-21 20:20:00 tiny] (main.py 233): INFO EPOCH 288 training takes 0:12:23
[2022-04-21 20:20:11 tiny] (main.py 273): INFO Test: [0/49]	Time 11.129 (11.129)	Loss 1.4087 (1.4087)	Acc@1 72.266 (72.266)	Acc@5 90.625 (90.625)	Mem 5325MB
[2022-04-21 20:20:31 tiny] (main.py 279): INFO  * Acc@1 72.730 Acc@5 91.072
[2022-04-21 20:20:31 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.7%
[2022-04-21 20:20:31 tiny] (main.py 148): INFO Max accuracy: 72.90%
[2022-04-21 20:20:42 tiny] (main.py 226): INFO Train: [289/300][0/1251]	eta 3:43:52 lr 0.000013	time 10.7372 (10.7372)	loss 3.4819 (3.4819)	grad_norm 7.4410 (7.4410)	mem 5325MB
[2022-04-21 20:21:45 tiny] (main.py 226): INFO Train: [289/300][100/1251]	eta 0:13:58 lr 0.000013	time 0.6259 (0.7289)	loss 2.6339 (3.6166)	grad_norm 9.0974 (10.2086)	mem 5325MB
[2022-04-21 20:22:43 tiny] (main.py 226): INFO Train: [289/300][200/1251]	eta 0:11:31 lr 0.000013	time 0.5918 (0.6583)	loss 4.0687 (3.6060)	grad_norm 8.2474 (10.0232)	mem 5325MB
[2022-04-21 20:23:42 tiny] (main.py 226): INFO Train: [289/300][300/1251]	eta 0:10:02 lr 0.000013	time 0.6020 (0.6339)	loss 2.2879 (3.5774)	grad_norm 9.9891 (9.8406)	mem 5325MB
[2022-04-21 20:24:41 tiny] (main.py 226): INFO Train: [289/300][400/1251]	eta 0:08:50 lr 0.000013	time 0.5052 (0.6229)	loss 2.3197 (3.5954)	grad_norm 11.8224 (9.7258)	mem 5325MB
[2022-04-21 20:25:39 tiny] (main.py 226): INFO Train: [289/300][500/1251]	eta 0:07:42 lr 0.000013	time 0.4712 (0.6157)	loss 3.8528 (3.6063)	grad_norm 13.3944 (9.8121)	mem 5325MB
[2022-04-21 20:26:38 tiny] (main.py 226): INFO Train: [289/300][600/1251]	eta 0:06:37 lr 0.000013	time 0.7885 (0.6113)	loss 4.0227 (3.5947)	grad_norm 21.9240 (9.8775)	mem 5325MB
[2022-04-21 20:27:37 tiny] (main.py 226): INFO Train: [289/300][700/1251]	eta 0:05:35 lr 0.000013	time 0.6862 (0.6084)	loss 3.2678 (3.6044)	grad_norm 8.0804 (9.7854)	mem 5325MB
[2022-04-21 20:28:36 tiny] (main.py 226): INFO Train: [289/300][800/1251]	eta 0:04:33 lr 0.000013	time 0.5930 (0.6055)	loss 4.0305 (3.6065)	grad_norm 11.6140 (9.7305)	mem 5325MB
[2022-04-21 20:29:35 tiny] (main.py 226): INFO Train: [289/300][900/1251]	eta 0:03:31 lr 0.000013	time 0.7916 (0.6038)	loss 3.9641 (3.6103)	grad_norm 11.2355 (9.7861)	mem 5325MB
[2022-04-21 20:30:34 tiny] (main.py 226): INFO Train: [289/300][1000/1251]	eta 0:02:31 lr 0.000013	time 0.6852 (0.6022)	loss 2.7190 (3.6100)	grad_norm 8.8133 (9.7312)	mem 5325MB
[2022-04-21 20:31:33 tiny] (main.py 226): INFO Train: [289/300][1100/1251]	eta 0:01:30 lr 0.000013	time 0.7119 (0.6010)	loss 2.6127 (3.6092)	grad_norm 6.1483 (9.7182)	mem 5325MB
[2022-04-21 20:32:32 tiny] (main.py 226): INFO Train: [289/300][1200/1251]	eta 0:00:30 lr 0.000013	time 0.5423 (0.6003)	loss 4.2473 (3.6075)	grad_norm 5.8292 (9.6808)	mem 5325MB
[2022-04-21 20:32:55 tiny] (main.py 233): INFO EPOCH 289 training takes 0:12:24
[2022-04-21 20:33:06 tiny] (main.py 273): INFO Test: [0/49]	Time 10.675 (10.675)	Loss 1.4122 (1.4122)	Acc@1 72.949 (72.949)	Acc@5 91.113 (91.113)	Mem 5325MB
[2022-04-21 20:33:26 tiny] (main.py 279): INFO  * Acc@1 72.710 Acc@5 91.092
[2022-04-21 20:33:26 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.7%
[2022-04-21 20:33:26 tiny] (main.py 148): INFO Max accuracy: 72.90%
[2022-04-21 20:33:37 tiny] (main.py 226): INFO Train: [290/300][0/1251]	eta 4:07:37 lr 0.000013	time 11.8768 (11.8768)	loss 2.6549 (2.6549)	grad_norm 11.1815 (11.1815)	mem 5325MB
[2022-04-21 20:34:39 tiny] (main.py 226): INFO Train: [290/300][100/1251]	eta 0:13:58 lr 0.000013	time 0.4844 (0.7285)	loss 2.2913 (3.6033)	grad_norm 11.9440 (10.4190)	mem 5325MB
[2022-04-21 20:35:38 tiny] (main.py 226): INFO Train: [290/300][200/1251]	eta 0:11:31 lr 0.000013	time 0.5091 (0.6576)	loss 3.9147 (3.5930)	grad_norm 14.0296 (9.8429)	mem 5325MB
[2022-04-21 20:36:36 tiny] (main.py 226): INFO Train: [290/300][300/1251]	eta 0:10:02 lr 0.000013	time 0.5821 (0.6334)	loss 4.3399 (3.5930)	grad_norm 12.5395 (9.7092)	mem 5325MB
[2022-04-21 20:37:35 tiny] (main.py 226): INFO Train: [290/300][400/1251]	eta 0:08:48 lr 0.000013	time 0.5654 (0.6213)	loss 3.7689 (3.5970)	grad_norm 10.7210 (9.7751)	mem 5325MB
[2022-04-21 20:38:33 tiny] (main.py 226): INFO Train: [290/300][500/1251]	eta 0:07:40 lr 0.000012	time 0.4820 (0.6138)	loss 3.5282 (3.5861)	grad_norm 7.6999 (9.7769)	mem 5325MB
[2022-04-21 20:39:32 tiny] (main.py 226): INFO Train: [290/300][600/1251]	eta 0:06:36 lr 0.000012	time 0.6990 (0.6095)	loss 3.0155 (3.5884)	grad_norm 12.6544 (9.7164)	mem 5325MB
[2022-04-21 20:40:31 tiny] (main.py 226): INFO Train: [290/300][700/1251]	eta 0:05:34 lr 0.000012	time 0.5528 (0.6069)	loss 4.4459 (3.5894)	grad_norm 8.4609 (9.7983)	mem 5325MB
[2022-04-21 20:41:30 tiny] (main.py 226): INFO Train: [290/300][800/1251]	eta 0:04:32 lr 0.000012	time 0.5878 (0.6052)	loss 3.7486 (3.5840)	grad_norm 8.2961 (nan)	mem 5325MB
[2022-04-21 20:42:29 tiny] (main.py 226): INFO Train: [290/300][900/1251]	eta 0:03:31 lr 0.000012	time 0.4895 (0.6033)	loss 3.7321 (3.5803)	grad_norm 7.4842 (nan)	mem 5325MB
[2022-04-21 20:43:28 tiny] (main.py 226): INFO Train: [290/300][1000/1251]	eta 0:02:31 lr 0.000012	time 0.5919 (0.6020)	loss 3.0995 (3.5839)	grad_norm 20.3791 (nan)	mem 5325MB
[2022-04-21 20:44:27 tiny] (main.py 226): INFO Train: [290/300][1100/1251]	eta 0:01:30 lr 0.000012	time 0.5982 (0.6010)	loss 3.7970 (3.5828)	grad_norm 18.8310 (nan)	mem 5325MB
[2022-04-21 20:45:26 tiny] (main.py 226): INFO Train: [290/300][1200/1251]	eta 0:00:30 lr 0.000012	time 0.5968 (0.5997)	loss 4.0078 (3.5851)	grad_norm 8.9520 (nan)	mem 5325MB
[2022-04-21 20:45:49 tiny] (main.py 233): INFO EPOCH 290 training takes 0:12:23
[2022-04-21 20:46:01 tiny] (main.py 273): INFO Test: [0/49]	Time 11.595 (11.595)	Loss 1.2383 (1.2383)	Acc@1 76.660 (76.660)	Acc@5 93.750 (93.750)	Mem 5325MB
[2022-04-21 20:46:20 tiny] (main.py 279): INFO  * Acc@1 72.782 Acc@5 91.132
[2022-04-21 20:46:20 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.8%
[2022-04-21 20:46:20 tiny] (main.py 148): INFO Max accuracy: 72.90%
[2022-04-21 20:46:31 tiny] (main.py 226): INFO Train: [291/300][0/1251]	eta 3:50:02 lr 0.000012	time 11.0331 (11.0331)	loss 4.0257 (4.0257)	grad_norm 11.6967 (11.6967)	mem 5325MB
[2022-04-21 20:47:34 tiny] (main.py 226): INFO Train: [291/300][100/1251]	eta 0:14:03 lr 0.000012	time 0.6774 (0.7326)	loss 4.2938 (3.6733)	grad_norm 7.7525 (10.3554)	mem 5325MB
[2022-04-21 20:48:32 tiny] (main.py 226): INFO Train: [291/300][200/1251]	eta 0:11:33 lr 0.000012	time 0.5511 (0.6599)	loss 3.9685 (3.6306)	grad_norm 8.0773 (9.8067)	mem 5325MB
[2022-04-21 20:49:31 tiny] (main.py 226): INFO Train: [291/300][300/1251]	eta 0:10:03 lr 0.000012	time 0.7015 (0.6351)	loss 4.0970 (3.6796)	grad_norm 9.1993 (9.9526)	mem 5325MB
[2022-04-21 20:50:30 tiny] (main.py 226): INFO Train: [291/300][400/1251]	eta 0:08:50 lr 0.000012	time 0.5325 (0.6237)	loss 3.8697 (3.6530)	grad_norm 11.3764 (9.9263)	mem 5325MB
[2022-04-21 20:51:29 tiny] (main.py 226): INFO Train: [291/300][500/1251]	eta 0:07:43 lr 0.000012	time 0.5363 (0.6166)	loss 3.6988 (3.6307)	grad_norm 7.6354 (9.9683)	mem 5325MB
[2022-04-21 20:52:27 tiny] (main.py 226): INFO Train: [291/300][600/1251]	eta 0:06:38 lr 0.000012	time 0.5034 (0.6115)	loss 4.4620 (3.6232)	grad_norm 11.6008 (9.9183)	mem 5325MB
[2022-04-21 20:53:26 tiny] (main.py 226): INFO Train: [291/300][700/1251]	eta 0:05:35 lr 0.000012	time 0.6892 (0.6086)	loss 2.9722 (3.6292)	grad_norm 20.3145 (9.8441)	mem 5325MB
[2022-04-21 20:54:25 tiny] (main.py 226): INFO Train: [291/300][800/1251]	eta 0:04:33 lr 0.000012	time 0.5883 (0.6062)	loss 4.1247 (3.6246)	grad_norm 11.3771 (9.8275)	mem 5325MB
[2022-04-21 20:55:24 tiny] (main.py 226): INFO Train: [291/300][900/1251]	eta 0:03:32 lr 0.000012	time 0.6274 (0.6043)	loss 4.3563 (3.6208)	grad_norm 9.7599 (9.7826)	mem 5325MB
[2022-04-21 20:56:23 tiny] (main.py 226): INFO Train: [291/300][1000/1251]	eta 0:02:31 lr 0.000012	time 0.5158 (0.6026)	loss 3.9247 (3.6083)	grad_norm 11.6294 (9.6995)	mem 5325MB
[2022-04-21 20:57:22 tiny] (main.py 226): INFO Train: [291/300][1100/1251]	eta 0:01:30 lr 0.000012	time 0.6449 (0.6012)	loss 3.4894 (3.6047)	grad_norm 6.1976 (9.7845)	mem 5325MB
[2022-04-21 20:58:21 tiny] (main.py 226): INFO Train: [291/300][1200/1251]	eta 0:00:30 lr 0.000012	time 0.8343 (0.6004)	loss 4.1621 (3.6029)	grad_norm 7.0617 (9.7907)	mem 5325MB
[2022-04-21 20:58:44 tiny] (main.py 233): INFO EPOCH 291 training takes 0:12:23
[2022-04-21 20:58:55 tiny] (main.py 273): INFO Test: [0/49]	Time 11.432 (11.432)	Loss 1.3611 (1.3611)	Acc@1 74.121 (74.121)	Acc@5 91.992 (91.992)	Mem 5325MB
[2022-04-21 20:59:15 tiny] (main.py 279): INFO  * Acc@1 72.702 Acc@5 91.082
[2022-04-21 20:59:15 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.7%
[2022-04-21 20:59:15 tiny] (main.py 148): INFO Max accuracy: 72.90%
[2022-04-21 20:59:26 tiny] (main.py 226): INFO Train: [292/300][0/1251]	eta 3:43:52 lr 0.000012	time 10.7375 (10.7375)	loss 3.7927 (3.7927)	grad_norm 11.6737 (11.6737)	mem 5325MB
[2022-04-21 21:00:29 tiny] (main.py 226): INFO Train: [292/300][100/1251]	eta 0:14:02 lr 0.000012	time 0.7227 (0.7322)	loss 3.9564 (3.6320)	grad_norm 11.2520 (9.8873)	mem 5325MB
[2022-04-21 21:01:28 tiny] (main.py 226): INFO Train: [292/300][200/1251]	eta 0:11:35 lr 0.000012	time 0.4527 (0.6613)	loss 2.9906 (3.5172)	grad_norm 7.4336 (9.4731)	mem 5325MB
[2022-04-21 21:02:27 tiny] (main.py 226): INFO Train: [292/300][300/1251]	eta 0:10:05 lr 0.000012	time 0.6881 (0.6369)	loss 3.1795 (3.5377)	grad_norm 6.9204 (9.3943)	mem 5325MB
[2022-04-21 21:03:26 tiny] (main.py 226): INFO Train: [292/300][400/1251]	eta 0:08:52 lr 0.000012	time 0.4452 (0.6262)	loss 2.4704 (3.5449)	grad_norm 8.5866 (9.6927)	mem 5325MB
[2022-04-21 21:04:25 tiny] (main.py 226): INFO Train: [292/300][500/1251]	eta 0:07:43 lr 0.000012	time 0.5445 (0.6173)	loss 4.0256 (3.5570)	grad_norm 9.7258 (9.6652)	mem 5325MB
[2022-04-21 21:05:23 tiny] (main.py 226): INFO Train: [292/300][600/1251]	eta 0:06:38 lr 0.000012	time 0.7384 (0.6124)	loss 3.3324 (3.5655)	grad_norm 6.4662 (9.6163)	mem 5325MB
[2022-04-21 21:06:22 tiny] (main.py 226): INFO Train: [292/300][700/1251]	eta 0:05:35 lr 0.000012	time 0.7209 (0.6088)	loss 2.9594 (3.5669)	grad_norm 6.9431 (9.5934)	mem 5325MB
[2022-04-21 21:07:21 tiny] (main.py 226): INFO Train: [292/300][800/1251]	eta 0:04:33 lr 0.000011	time 0.5800 (0.6060)	loss 3.6291 (3.5714)	grad_norm 9.0955 (9.5716)	mem 5325MB
[2022-04-21 21:08:19 tiny] (main.py 226): INFO Train: [292/300][900/1251]	eta 0:03:31 lr 0.000011	time 0.6557 (0.6037)	loss 3.2816 (3.5607)	grad_norm 6.4234 (9.4993)	mem 5325MB
[2022-04-21 21:09:18 tiny] (main.py 226): INFO Train: [292/300][1000/1251]	eta 0:02:31 lr 0.000011	time 0.5848 (0.6023)	loss 2.2480 (3.5624)	grad_norm 10.3567 (nan)	mem 5325MB
[2022-04-21 21:10:17 tiny] (main.py 226): INFO Train: [292/300][1100/1251]	eta 0:01:30 lr 0.000011	time 0.5857 (0.6011)	loss 4.3666 (3.5696)	grad_norm 11.5347 (nan)	mem 5325MB
[2022-04-21 21:11:16 tiny] (main.py 226): INFO Train: [292/300][1200/1251]	eta 0:00:30 lr 0.000011	time 0.6278 (0.6001)	loss 3.9228 (3.5728)	grad_norm 9.5559 (nan)	mem 5325MB
[2022-04-21 21:11:38 tiny] (main.py 233): INFO EPOCH 292 training takes 0:12:22
[2022-04-21 21:11:49 tiny] (main.py 273): INFO Test: [0/49]	Time 11.378 (11.378)	Loss 1.4439 (1.4439)	Acc@1 71.875 (71.875)	Acc@5 90.820 (90.820)	Mem 5325MB
[2022-04-21 21:12:09 tiny] (main.py 279): INFO  * Acc@1 72.804 Acc@5 91.172
[2022-04-21 21:12:09 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.8%
[2022-04-21 21:12:09 tiny] (main.py 148): INFO Max accuracy: 72.90%
[2022-04-21 21:12:21 tiny] (main.py 226): INFO Train: [293/300][0/1251]	eta 4:08:38 lr 0.000011	time 11.9256 (11.9256)	loss 3.9169 (3.9169)	grad_norm 13.2698 (13.2698)	mem 5325MB
[2022-04-21 21:13:22 tiny] (main.py 226): INFO Train: [293/300][100/1251]	eta 0:13:54 lr 0.000011	time 0.4431 (0.7252)	loss 3.9291 (3.5510)	grad_norm 8.5937 (9.8236)	mem 5325MB
[2022-04-21 21:14:21 tiny] (main.py 226): INFO Train: [293/300][200/1251]	eta 0:11:32 lr 0.000011	time 0.6846 (0.6589)	loss 4.3816 (3.5570)	grad_norm 12.0975 (9.9188)	mem 5325MB
[2022-04-21 21:15:20 tiny] (main.py 226): INFO Train: [293/300][300/1251]	eta 0:10:03 lr 0.000011	time 0.5558 (0.6347)	loss 3.9780 (3.5618)	grad_norm 8.9457 (9.7528)	mem 5325MB
[2022-04-21 21:16:18 tiny] (main.py 226): INFO Train: [293/300][400/1251]	eta 0:08:48 lr 0.000011	time 0.7018 (0.6211)	loss 3.3059 (3.5538)	grad_norm 7.0267 (9.7185)	mem 5325MB
[2022-04-21 21:17:17 tiny] (main.py 226): INFO Train: [293/300][500/1251]	eta 0:07:42 lr 0.000011	time 0.5774 (0.6152)	loss 2.6540 (3.5692)	grad_norm 7.0540 (9.7927)	mem 5325MB
[2022-04-21 21:18:16 tiny] (main.py 226): INFO Train: [293/300][600/1251]	eta 0:06:37 lr 0.000011	time 0.5740 (0.6102)	loss 3.7386 (3.5705)	grad_norm 5.6906 (9.7585)	mem 5325MB
[2022-04-21 21:19:15 tiny] (main.py 226): INFO Train: [293/300][700/1251]	eta 0:05:34 lr 0.000011	time 0.6047 (0.6075)	loss 4.4706 (3.5656)	grad_norm 8.2475 (9.8892)	mem 5325MB
[2022-04-21 21:20:13 tiny] (main.py 226): INFO Train: [293/300][800/1251]	eta 0:04:32 lr 0.000011	time 0.5323 (0.6048)	loss 2.5848 (3.5672)	grad_norm 7.9065 (9.8787)	mem 5325MB
[2022-04-21 21:21:12 tiny] (main.py 226): INFO Train: [293/300][900/1251]	eta 0:03:31 lr 0.000011	time 0.5049 (0.6031)	loss 2.7118 (3.5760)	grad_norm 10.9256 (9.7819)	mem 5325MB
[2022-04-21 21:22:11 tiny] (main.py 226): INFO Train: [293/300][1000/1251]	eta 0:02:31 lr 0.000011	time 0.5228 (0.6018)	loss 3.7585 (3.5911)	grad_norm 11.9268 (9.7449)	mem 5325MB
[2022-04-21 21:23:11 tiny] (main.py 226): INFO Train: [293/300][1100/1251]	eta 0:01:30 lr 0.000011	time 0.5540 (0.6008)	loss 3.0666 (3.5969)	grad_norm 11.7328 (9.7017)	mem 5325MB
[2022-04-21 21:24:10 tiny] (main.py 226): INFO Train: [293/300][1200/1251]	eta 0:00:30 lr 0.000011	time 0.5375 (0.6003)	loss 3.7575 (3.5934)	grad_norm 7.6389 (9.7749)	mem 5325MB
[2022-04-21 21:24:32 tiny] (main.py 233): INFO EPOCH 293 training takes 0:12:22
[2022-04-21 21:24:43 tiny] (main.py 273): INFO Test: [0/49]	Time 11.047 (11.047)	Loss 1.4197 (1.4197)	Acc@1 73.926 (73.926)	Acc@5 91.504 (91.504)	Mem 5325MB
[2022-04-21 21:25:03 tiny] (main.py 279): INFO  * Acc@1 72.826 Acc@5 91.158
[2022-04-21 21:25:03 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.8%
[2022-04-21 21:25:03 tiny] (main.py 148): INFO Max accuracy: 72.90%
[2022-04-21 21:25:15 tiny] (main.py 226): INFO Train: [294/300][0/1251]	eta 4:17:04 lr 0.000011	time 12.3300 (12.3300)	loss 3.7931 (3.7931)	grad_norm 11.9797 (11.9797)	mem 5325MB
[2022-04-21 21:26:17 tiny] (main.py 226): INFO Train: [294/300][100/1251]	eta 0:13:59 lr 0.000011	time 0.5551 (0.7292)	loss 3.5731 (3.4924)	grad_norm 6.4296 (9.8235)	mem 5325MB
[2022-04-21 21:27:15 tiny] (main.py 226): INFO Train: [294/300][200/1251]	eta 0:11:32 lr 0.000011	time 0.5448 (0.6591)	loss 3.9475 (3.5351)	grad_norm 9.4812 (9.7231)	mem 5325MB
[2022-04-21 21:28:14 tiny] (main.py 226): INFO Train: [294/300][300/1251]	eta 0:10:04 lr 0.000011	time 0.5196 (0.6360)	loss 4.4328 (3.5740)	grad_norm 10.2253 (9.6431)	mem 5325MB
[2022-04-21 21:29:13 tiny] (main.py 226): INFO Train: [294/300][400/1251]	eta 0:08:51 lr 0.000011	time 0.6893 (0.6244)	loss 3.9901 (3.5644)	grad_norm 8.3956 (9.6483)	mem 5325MB
[2022-04-21 21:30:12 tiny] (main.py 226): INFO Train: [294/300][500/1251]	eta 0:07:42 lr 0.000011	time 0.6347 (0.6164)	loss 4.1143 (3.5656)	grad_norm 5.9492 (9.5973)	mem 5325MB
[2022-04-21 21:31:10 tiny] (main.py 226): INFO Train: [294/300][600/1251]	eta 0:06:38 lr 0.000011	time 0.4769 (0.6115)	loss 4.1247 (3.5638)	grad_norm 8.4697 (9.6037)	mem 5325MB
[2022-04-21 21:32:09 tiny] (main.py 226): INFO Train: [294/300][700/1251]	eta 0:05:35 lr 0.000011	time 0.6029 (0.6083)	loss 3.7850 (3.5755)	grad_norm 9.0253 (9.6148)	mem 5325MB
[2022-04-21 21:33:08 tiny] (main.py 226): INFO Train: [294/300][800/1251]	eta 0:04:33 lr 0.000011	time 0.5009 (0.6062)	loss 3.5911 (3.5810)	grad_norm 6.7873 (9.6037)	mem 5325MB
[2022-04-21 21:34:08 tiny] (main.py 226): INFO Train: [294/300][900/1251]	eta 0:03:32 lr 0.000011	time 0.6246 (0.6048)	loss 3.2775 (3.5844)	grad_norm 6.6596 (nan)	mem 5325MB
[2022-04-21 21:35:06 tiny] (main.py 226): INFO Train: [294/300][1000/1251]	eta 0:02:31 lr 0.000011	time 0.4166 (0.6029)	loss 3.1768 (3.5858)	grad_norm 8.2891 (nan)	mem 5325MB
[2022-04-21 21:36:05 tiny] (main.py 226): INFO Train: [294/300][1100/1251]	eta 0:01:30 lr 0.000011	time 0.7074 (0.6017)	loss 4.2445 (3.5895)	grad_norm 7.6169 (nan)	mem 5325MB
[2022-04-21 21:37:04 tiny] (main.py 226): INFO Train: [294/300][1200/1251]	eta 0:00:30 lr 0.000011	time 0.5970 (0.6006)	loss 3.8024 (3.5811)	grad_norm 10.4512 (nan)	mem 5325MB
[2022-04-21 21:37:26 tiny] (main.py 233): INFO EPOCH 294 training takes 0:12:23
[2022-04-21 21:37:38 tiny] (main.py 273): INFO Test: [0/49]	Time 11.974 (11.974)	Loss 1.4380 (1.4380)	Acc@1 72.461 (72.461)	Acc@5 90.625 (90.625)	Mem 5325MB
[2022-04-21 21:37:57 tiny] (main.py 279): INFO  * Acc@1 72.874 Acc@5 91.134
[2022-04-21 21:37:57 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.9%
[2022-04-21 21:37:57 tiny] (main.py 148): INFO Max accuracy: 72.90%
[2022-04-21 21:38:09 tiny] (main.py 226): INFO Train: [295/300][0/1251]	eta 4:02:04 lr 0.000011	time 11.6107 (11.6107)	loss 4.1973 (4.1973)	grad_norm 6.9468 (6.9468)	mem 5325MB
[2022-04-21 21:39:11 tiny] (main.py 226): INFO Train: [295/300][100/1251]	eta 0:13:58 lr 0.000011	time 0.4870 (0.7282)	loss 4.3628 (3.6451)	grad_norm 10.4102 (9.6306)	mem 5325MB
[2022-04-21 21:40:09 tiny] (main.py 226): INFO Train: [295/300][200/1251]	eta 0:11:28 lr 0.000011	time 0.5456 (0.6547)	loss 3.8992 (3.5630)	grad_norm 18.2533 (9.8515)	mem 5325MB
[2022-04-21 21:41:08 tiny] (main.py 226): INFO Train: [295/300][300/1251]	eta 0:10:02 lr 0.000011	time 0.6540 (0.6335)	loss 3.6874 (3.5677)	grad_norm 12.5720 (9.8439)	mem 5325MB
[2022-04-21 21:42:06 tiny] (main.py 226): INFO Train: [295/300][400/1251]	eta 0:08:49 lr 0.000011	time 0.6051 (0.6218)	loss 2.8376 (3.5700)	grad_norm 8.2065 (9.8101)	mem 5325MB
[2022-04-21 21:43:05 tiny] (main.py 226): INFO Train: [295/300][500/1251]	eta 0:07:42 lr 0.000011	time 0.7874 (0.6154)	loss 3.9799 (3.5764)	grad_norm 13.2318 (9.7638)	mem 5325MB
[2022-04-21 21:44:04 tiny] (main.py 226): INFO Train: [295/300][600/1251]	eta 0:06:37 lr 0.000011	time 0.5690 (0.6107)	loss 3.4526 (3.5699)	grad_norm 7.2418 (9.8126)	mem 5325MB
[2022-04-21 21:45:03 tiny] (main.py 226): INFO Train: [295/300][700/1251]	eta 0:05:34 lr 0.000011	time 0.4422 (0.6078)	loss 3.9721 (3.5750)	grad_norm 6.8889 (9.8982)	mem 5325MB
[2022-04-21 21:46:02 tiny] (main.py 226): INFO Train: [295/300][800/1251]	eta 0:04:32 lr 0.000011	time 0.4886 (0.6052)	loss 4.2220 (3.5744)	grad_norm 9.9590 (nan)	mem 5325MB
[2022-04-21 21:47:01 tiny] (main.py 226): INFO Train: [295/300][900/1251]	eta 0:03:31 lr 0.000010	time 0.6581 (0.6037)	loss 3.6926 (3.5794)	grad_norm 10.5178 (nan)	mem 5325MB
[2022-04-21 21:48:00 tiny] (main.py 226): INFO Train: [295/300][1000/1251]	eta 0:02:31 lr 0.000010	time 0.7072 (0.6023)	loss 3.3971 (3.5789)	grad_norm 10.2243 (nan)	mem 5325MB
[2022-04-21 21:48:58 tiny] (main.py 226): INFO Train: [295/300][1100/1251]	eta 0:01:30 lr 0.000010	time 0.5923 (0.6008)	loss 3.6298 (3.5789)	grad_norm 6.1507 (nan)	mem 5325MB
[2022-04-21 21:49:57 tiny] (main.py 226): INFO Train: [295/300][1200/1251]	eta 0:00:30 lr 0.000010	time 0.6231 (0.5999)	loss 2.7753 (3.5715)	grad_norm 11.8018 (nan)	mem 5325MB
[2022-04-21 21:50:20 tiny] (main.py 233): INFO EPOCH 295 training takes 0:12:22
[2022-04-21 21:50:32 tiny] (main.py 273): INFO Test: [0/49]	Time 12.436 (12.436)	Loss 1.4253 (1.4253)	Acc@1 72.266 (72.266)	Acc@5 91.602 (91.602)	Mem 5325MB
[2022-04-21 21:50:51 tiny] (main.py 279): INFO  * Acc@1 72.904 Acc@5 91.134
[2022-04-21 21:50:51 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.9%
[2022-04-21 21:50:51 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_295.pth saving......
[2022-04-21 21:50:51 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_295.pth saved !!!
[2022-04-21 21:50:51 tiny] (main.py 148): INFO Max accuracy: 72.90%
[2022-04-21 21:51:02 tiny] (main.py 226): INFO Train: [296/300][0/1251]	eta 4:05:57 lr 0.000010	time 11.7969 (11.7969)	loss 3.4520 (3.4520)	grad_norm 9.7637 (9.7637)	mem 5325MB
[2022-04-21 21:52:04 tiny] (main.py 226): INFO Train: [296/300][100/1251]	eta 0:14:01 lr 0.000010	time 0.7211 (0.7310)	loss 4.0167 (3.6201)	grad_norm 9.1797 (9.5785)	mem 5325MB
[2022-04-21 21:53:03 tiny] (main.py 226): INFO Train: [296/300][200/1251]	eta 0:11:30 lr 0.000010	time 0.5859 (0.6568)	loss 3.9780 (3.6127)	grad_norm 8.7340 (9.9408)	mem 5325MB
[2022-04-21 21:54:01 tiny] (main.py 226): INFO Train: [296/300][300/1251]	eta 0:10:01 lr 0.000010	time 0.7993 (0.6327)	loss 3.7710 (3.6018)	grad_norm 8.4193 (9.9528)	mem 5325MB
[2022-04-21 21:55:00 tiny] (main.py 226): INFO Train: [296/300][400/1251]	eta 0:08:49 lr 0.000010	time 0.4432 (0.6218)	loss 2.8419 (3.6200)	grad_norm 13.4273 (9.9311)	mem 5325MB
[2022-04-21 21:55:58 tiny] (main.py 226): INFO Train: [296/300][500/1251]	eta 0:07:41 lr 0.000010	time 0.5622 (0.6144)	loss 3.3289 (3.6104)	grad_norm 14.5169 (9.8249)	mem 5325MB
[2022-04-21 21:56:58 tiny] (main.py 226): INFO Train: [296/300][600/1251]	eta 0:06:37 lr 0.000010	time 0.5363 (0.6107)	loss 3.7633 (3.6180)	grad_norm 8.7201 (9.7667)	mem 5325MB
[2022-04-21 21:57:56 tiny] (main.py 226): INFO Train: [296/300][700/1251]	eta 0:05:34 lr 0.000010	time 0.5220 (0.6074)	loss 4.4154 (3.6217)	grad_norm 7.9630 (9.7215)	mem 5325MB
[2022-04-21 21:58:55 tiny] (main.py 226): INFO Train: [296/300][800/1251]	eta 0:04:32 lr 0.000010	time 0.4972 (0.6051)	loss 3.9926 (3.6277)	grad_norm 9.1036 (9.6925)	mem 5325MB
[2022-04-21 21:59:54 tiny] (main.py 226): INFO Train: [296/300][900/1251]	eta 0:03:31 lr 0.000010	time 0.4665 (0.6036)	loss 3.9950 (3.6309)	grad_norm 10.1334 (9.7012)	mem 5325MB
[2022-04-21 22:00:53 tiny] (main.py 226): INFO Train: [296/300][1000/1251]	eta 0:02:31 lr 0.000010	time 0.5625 (0.6018)	loss 3.7318 (3.6310)	grad_norm 11.9540 (9.7057)	mem 5325MB
[2022-04-21 22:01:53 tiny] (main.py 226): INFO Train: [296/300][1100/1251]	eta 0:01:30 lr 0.000010	time 0.6690 (0.6013)	loss 3.1655 (3.6288)	grad_norm 9.6447 (9.6543)	mem 5325MB
[2022-04-21 22:02:51 tiny] (main.py 226): INFO Train: [296/300][1200/1251]	eta 0:00:30 lr 0.000010	time 0.6045 (0.6002)	loss 2.6008 (3.6209)	grad_norm 10.5737 (9.6743)	mem 5325MB
[2022-04-21 22:03:14 tiny] (main.py 233): INFO EPOCH 296 training takes 0:12:23
[2022-04-21 22:03:24 tiny] (main.py 273): INFO Test: [0/49]	Time 10.799 (10.799)	Loss 1.3361 (1.3361)	Acc@1 73.438 (73.438)	Acc@5 91.211 (91.211)	Mem 5325MB
[2022-04-21 22:03:45 tiny] (main.py 279): INFO  * Acc@1 72.950 Acc@5 91.186
[2022-04-21 22:03:45 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.9%
[2022-04-21 22:03:45 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_296.pth saving......
[2022-04-21 22:03:45 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_296.pth saved !!!
[2022-04-21 22:03:45 tiny] (main.py 148): INFO Max accuracy: 72.95%
[2022-04-21 22:03:57 tiny] (main.py 226): INFO Train: [297/300][0/1251]	eta 4:13:13 lr 0.000010	time 12.1452 (12.1452)	loss 3.5927 (3.5927)	grad_norm 10.5983 (10.5983)	mem 5325MB
[2022-04-21 22:04:59 tiny] (main.py 226): INFO Train: [297/300][100/1251]	eta 0:14:02 lr 0.000010	time 1.0209 (0.7318)	loss 3.6998 (3.5020)	grad_norm 13.6383 (9.9778)	mem 5325MB
[2022-04-21 22:05:57 tiny] (main.py 226): INFO Train: [297/300][200/1251]	eta 0:11:30 lr 0.000010	time 0.5658 (0.6574)	loss 2.8617 (3.5794)	grad_norm 6.7856 (9.6813)	mem 5325MB
[2022-04-21 22:06:55 tiny] (main.py 226): INFO Train: [297/300][300/1251]	eta 0:10:00 lr 0.000010	time 0.6166 (0.6317)	loss 3.2273 (3.5954)	grad_norm 7.6414 (9.6456)	mem 5325MB
[2022-04-21 22:07:54 tiny] (main.py 226): INFO Train: [297/300][400/1251]	eta 0:08:49 lr 0.000010	time 0.6492 (0.6221)	loss 3.5066 (3.6088)	grad_norm 9.3374 (9.5886)	mem 5325MB
[2022-04-21 22:08:53 tiny] (main.py 226): INFO Train: [297/300][500/1251]	eta 0:07:41 lr 0.000010	time 0.5184 (0.6146)	loss 2.6177 (3.6206)	grad_norm 11.0617 (9.5904)	mem 5325MB
[2022-04-21 22:09:51 tiny] (main.py 226): INFO Train: [297/300][600/1251]	eta 0:06:37 lr 0.000010	time 0.5935 (0.6099)	loss 4.1038 (3.6156)	grad_norm 11.4896 (9.6145)	mem 5325MB
[2022-04-21 22:10:51 tiny] (main.py 226): INFO Train: [297/300][700/1251]	eta 0:05:34 lr 0.000010	time 0.6264 (0.6073)	loss 3.5833 (3.6145)	grad_norm 10.0847 (9.6494)	mem 5325MB
[2022-04-21 22:11:49 tiny] (main.py 226): INFO Train: [297/300][800/1251]	eta 0:04:32 lr 0.000010	time 0.4890 (0.6049)	loss 3.8673 (3.6123)	grad_norm 12.4541 (9.6722)	mem 5325MB
[2022-04-21 22:12:49 tiny] (main.py 226): INFO Train: [297/300][900/1251]	eta 0:03:31 lr 0.000010	time 0.6290 (0.6036)	loss 4.0476 (3.6080)	grad_norm 8.6969 (9.6373)	mem 5325MB
[2022-04-21 22:13:47 tiny] (main.py 226): INFO Train: [297/300][1000/1251]	eta 0:02:31 lr 0.000010	time 0.5026 (0.6020)	loss 4.2156 (3.5983)	grad_norm 8.8689 (9.5826)	mem 5325MB
[2022-04-21 22:14:46 tiny] (main.py 226): INFO Train: [297/300][1100/1251]	eta 0:01:30 lr 0.000010	time 0.5877 (0.6007)	loss 3.6403 (3.5961)	grad_norm 8.4756 (9.5949)	mem 5325MB
[2022-04-21 22:15:45 tiny] (main.py 226): INFO Train: [297/300][1200/1251]	eta 0:00:30 lr 0.000010	time 0.8276 (0.6000)	loss 3.3535 (3.5945)	grad_norm 8.2329 (9.5797)	mem 5325MB
[2022-04-21 22:16:08 tiny] (main.py 233): INFO EPOCH 297 training takes 0:12:22
[2022-04-21 22:16:19 tiny] (main.py 273): INFO Test: [0/49]	Time 11.572 (11.572)	Loss 1.4559 (1.4559)	Acc@1 69.336 (69.336)	Acc@5 91.309 (91.309)	Mem 5325MB
[2022-04-21 22:16:38 tiny] (main.py 279): INFO  * Acc@1 72.872 Acc@5 91.112
[2022-04-21 22:16:38 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.9%
[2022-04-21 22:16:38 tiny] (main.py 148): INFO Max accuracy: 72.95%
[2022-04-21 22:16:49 tiny] (main.py 226): INFO Train: [298/300][0/1251]	eta 3:45:54 lr 0.000010	time 10.8346 (10.8346)	loss 3.8625 (3.8625)	grad_norm 6.8054 (6.8054)	mem 5325MB
[2022-04-21 22:17:52 tiny] (main.py 226): INFO Train: [298/300][100/1251]	eta 0:13:56 lr 0.000010	time 0.5433 (0.7272)	loss 3.9842 (3.6771)	grad_norm 10.0514 (9.8300)	mem 5325MB
[2022-04-21 22:18:50 tiny] (main.py 226): INFO Train: [298/300][200/1251]	eta 0:11:30 lr 0.000010	time 0.6505 (0.6570)	loss 3.8774 (3.6504)	grad_norm 11.2230 (9.7711)	mem 5325MB
[2022-04-21 22:19:49 tiny] (main.py 226): INFO Train: [298/300][300/1251]	eta 0:10:02 lr 0.000010	time 0.4252 (0.6333)	loss 2.4171 (3.6562)	grad_norm 7.9176 (9.7898)	mem 5325MB
[2022-04-21 22:20:48 tiny] (main.py 226): INFO Train: [298/300][400/1251]	eta 0:08:49 lr 0.000010	time 0.7970 (0.6225)	loss 2.7484 (3.6349)	grad_norm 6.7535 (9.7453)	mem 5325MB
[2022-04-21 22:21:47 tiny] (main.py 226): INFO Train: [298/300][500/1251]	eta 0:07:41 lr 0.000010	time 0.6055 (0.6151)	loss 3.9696 (3.6365)	grad_norm 15.4716 (9.7016)	mem 5325MB
[2022-04-21 22:22:46 tiny] (main.py 226): INFO Train: [298/300][600/1251]	eta 0:06:37 lr 0.000010	time 0.4991 (0.6110)	loss 3.5293 (3.6267)	grad_norm 14.6408 (9.6948)	mem 5325MB
[2022-04-21 22:23:44 tiny] (main.py 226): INFO Train: [298/300][700/1251]	eta 0:05:34 lr 0.000010	time 0.6078 (0.6071)	loss 4.5013 (3.6247)	grad_norm 10.9245 (9.8088)	mem 5325MB
[2022-04-21 22:24:43 tiny] (main.py 226): INFO Train: [298/300][800/1251]	eta 0:04:32 lr 0.000010	time 0.4585 (0.6051)	loss 2.7795 (3.6284)	grad_norm 6.5195 (9.8164)	mem 5325MB
[2022-04-21 22:25:42 tiny] (main.py 226): INFO Train: [298/300][900/1251]	eta 0:03:31 lr 0.000010	time 0.4160 (0.6030)	loss 2.3872 (3.6233)	grad_norm 13.9574 (9.9269)	mem 5325MB
[2022-04-21 22:26:41 tiny] (main.py 226): INFO Train: [298/300][1000/1251]	eta 0:02:31 lr 0.000010	time 0.6204 (0.6018)	loss 4.4587 (3.6182)	grad_norm 11.2235 (10.0158)	mem 5325MB
[2022-04-21 22:27:40 tiny] (main.py 226): INFO Train: [298/300][1100/1251]	eta 0:01:30 lr 0.000010	time 0.5319 (0.6006)	loss 3.5578 (3.6165)	grad_norm 11.4895 (9.9472)	mem 5325MB
[2022-04-21 22:28:39 tiny] (main.py 226): INFO Train: [298/300][1200/1251]	eta 0:00:30 lr 0.000010	time 0.8289 (0.5999)	loss 3.4055 (3.6114)	grad_norm 10.4584 (9.9329)	mem 5325MB
[2022-04-21 22:29:01 tiny] (main.py 233): INFO EPOCH 298 training takes 0:12:22
[2022-04-21 22:29:12 tiny] (main.py 273): INFO Test: [0/49]	Time 10.942 (10.942)	Loss 1.3923 (1.3923)	Acc@1 73.047 (73.047)	Acc@5 91.016 (91.016)	Mem 5325MB
[2022-04-21 22:29:31 tiny] (main.py 279): INFO  * Acc@1 72.924 Acc@5 91.160
[2022-04-21 22:29:31 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.9%
[2022-04-21 22:29:31 tiny] (main.py 148): INFO Max accuracy: 72.95%
[2022-04-21 22:29:42 tiny] (main.py 226): INFO Train: [299/300][0/1251]	eta 3:36:12 lr 0.000010	time 10.3694 (10.3694)	loss 3.1714 (3.1714)	grad_norm 8.4777 (8.4777)	mem 5325MB
[2022-04-21 22:30:45 tiny] (main.py 226): INFO Train: [299/300][100/1251]	eta 0:14:02 lr 0.000010	time 0.6421 (0.7320)	loss 4.4413 (3.5388)	grad_norm 11.4390 (9.4640)	mem 5325MB
[2022-04-21 22:31:44 tiny] (main.py 226): INFO Train: [299/300][200/1251]	eta 0:11:34 lr 0.000010	time 0.8414 (0.6606)	loss 2.4555 (3.5839)	grad_norm 13.3480 (9.3361)	mem 5325MB
[2022-04-21 22:32:42 tiny] (main.py 226): INFO Train: [299/300][300/1251]	eta 0:10:02 lr 0.000010	time 0.4667 (0.6340)	loss 3.1789 (3.5844)	grad_norm 5.9610 (9.7836)	mem 5325MB
[2022-04-21 22:33:41 tiny] (main.py 226): INFO Train: [299/300][400/1251]	eta 0:08:49 lr 0.000010	time 0.6832 (0.6217)	loss 3.7290 (3.6200)	grad_norm 10.3421 (9.8227)	mem 5325MB
[2022-04-21 22:34:40 tiny] (main.py 226): INFO Train: [299/300][500/1251]	eta 0:07:42 lr 0.000010	time 0.5006 (0.6157)	loss 3.7748 (3.5951)	grad_norm 7.7797 (9.8300)	mem 5325MB
[2022-04-21 22:35:38 tiny] (main.py 226): INFO Train: [299/300][600/1251]	eta 0:06:37 lr 0.000010	time 0.6330 (0.6106)	loss 2.8466 (3.5912)	grad_norm 10.5709 (nan)	mem 5325MB
[2022-04-21 22:36:37 tiny] (main.py 226): INFO Train: [299/300][700/1251]	eta 0:05:34 lr 0.000010	time 0.5871 (0.6075)	loss 3.1806 (3.6042)	grad_norm 14.4098 (nan)	mem 5325MB
[2022-04-21 22:37:36 tiny] (main.py 226): INFO Train: [299/300][800/1251]	eta 0:04:33 lr 0.000010	time 0.5509 (0.6054)	loss 3.3587 (3.6113)	grad_norm 13.7698 (nan)	mem 5325MB
[2022-04-21 22:38:35 tiny] (main.py 226): INFO Train: [299/300][900/1251]	eta 0:03:31 lr 0.000010	time 0.5652 (0.6034)	loss 4.2414 (3.6082)	grad_norm 7.4105 (nan)	mem 5325MB
[2022-04-21 22:39:34 tiny] (main.py 226): INFO Train: [299/300][1000/1251]	eta 0:02:31 lr 0.000010	time 0.4795 (0.6021)	loss 4.3505 (3.6047)	grad_norm 9.3776 (nan)	mem 5325MB
[2022-04-21 22:40:33 tiny] (main.py 226): INFO Train: [299/300][1100/1251]	eta 0:01:30 lr 0.000010	time 0.5662 (0.6010)	loss 3.5781 (3.6004)	grad_norm 10.1009 (nan)	mem 5325MB
[2022-04-21 22:41:32 tiny] (main.py 226): INFO Train: [299/300][1200/1251]	eta 0:00:30 lr 0.000010	time 0.6011 (0.6000)	loss 3.0379 (3.5927)	grad_norm 13.1533 (nan)	mem 5325MB
[2022-04-21 22:41:53 tiny] (main.py 233): INFO EPOCH 299 training takes 0:12:22
[2022-04-21 22:41:53 tiny] (utils.py 57): INFO output/tiny/default/ckpt_epoch_299.pth saving......
[2022-04-21 22:41:54 tiny] (utils.py 59): INFO output/tiny/default/ckpt_epoch_299.pth saved !!!
[2022-04-21 22:42:04 tiny] (main.py 273): INFO Test: [0/49]	Time 10.625 (10.625)	Loss 1.4172 (1.4172)	Acc@1 72.168 (72.168)	Acc@5 91.406 (91.406)	Mem 5325MB
[2022-04-21 22:42:25 tiny] (main.py 279): INFO  * Acc@1 72.850 Acc@5 91.164
[2022-04-21 22:42:25 tiny] (main.py 144): INFO Accuracy of the network on the 50000 test images: 72.8%
[2022-04-21 22:42:25 tiny] (main.py 148): INFO Max accuracy: 72.95%
[2022-04-21 22:42:25 tiny] (main.py 152): INFO Training time 20:25:29
